[20:35:40.982] Namespace(root_path='../data/ACDC', exp='ACDC/Mean_Teacher', model='swinunet', max_iterations=30000, batch_size=8, deterministic=1, base_lr=0.01, patch_size=[384, 384], seed=1337, num_classes=5, cfg='../code/configs/swin_tiny_patch4_window7_224_lite.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, labeled_bs=4, labeled_num=3, ema_decay=0.99, consistency_type='mse', consistency=0.1, consistency_rampup=200.0)
[20:35:42.820] 545 iterations per epoch
[20:35:44.906] iteration 1 : loss : 1.293013, loss_ce: 1.732813, loss_dice: 0.853212
[20:35:45.370] iteration 2 : loss : 1.205604, loss_ce: 1.582746, loss_dice: 0.828463
[20:35:45.851] iteration 3 : loss : 1.055701, loss_ce: 1.286844, loss_dice: 0.824558
[20:35:46.333] iteration 4 : loss : 0.894893, loss_ce: 0.958428, loss_dice: 0.831357
[20:35:46.814] iteration 5 : loss : 0.798666, loss_ce: 0.869589, loss_dice: 0.727743
[20:35:47.296] iteration 6 : loss : 0.654415, loss_ce: 0.543545, loss_dice: 0.765285
[20:35:47.773] iteration 7 : loss : 0.633886, loss_ce: 0.527190, loss_dice: 0.740582
[20:35:48.252] iteration 8 : loss : 0.620313, loss_ce: 0.482825, loss_dice: 0.757800
[20:35:48.737] iteration 9 : loss : 0.487390, loss_ce: 0.192752, loss_dice: 0.782028
[20:35:49.218] iteration 10 : loss : 0.577092, loss_ce: 0.357584, loss_dice: 0.796600
[20:35:49.701] iteration 11 : loss : 0.661597, loss_ce: 0.526440, loss_dice: 0.796754
[20:35:50.184] iteration 12 : loss : 0.556307, loss_ce: 0.322163, loss_dice: 0.790450
[20:35:50.666] iteration 13 : loss : 0.627323, loss_ce: 0.454391, loss_dice: 0.800255
[20:35:51.147] iteration 14 : loss : 0.598624, loss_ce: 0.397329, loss_dice: 0.799918
[20:35:51.625] iteration 15 : loss : 0.576475, loss_ce: 0.353910, loss_dice: 0.799040
[20:35:52.105] iteration 16 : loss : 0.627202, loss_ce: 0.454794, loss_dice: 0.799611
[20:35:52.585] iteration 17 : loss : 0.410058, loss_ce: 0.020074, loss_dice: 0.800042
[20:35:53.066] iteration 18 : loss : 0.531973, loss_ce: 0.265391, loss_dice: 0.798554
[20:35:53.546] iteration 19 : loss : 0.541255, loss_ce: 0.283263, loss_dice: 0.799248
[20:35:54.029] iteration 20 : loss : 0.475163, loss_ce: 0.154264, loss_dice: 0.796062
[20:35:54.821] iteration 21 : loss : 0.475510, loss_ce: 0.152578, loss_dice: 0.798443
[20:35:55.299] iteration 22 : loss : 0.472334, loss_ce: 0.146658, loss_dice: 0.798009
[20:35:55.782] iteration 23 : loss : 0.501289, loss_ce: 0.203817, loss_dice: 0.798762
[20:35:56.309] iteration 24 : loss : 0.587806, loss_ce: 0.376369, loss_dice: 0.799242
[20:35:56.801] iteration 25 : loss : 0.551182, loss_ce: 0.305322, loss_dice: 0.797042
[20:35:57.291] iteration 26 : loss : 0.579706, loss_ce: 0.364417, loss_dice: 0.794994
[20:35:57.770] iteration 27 : loss : 0.498095, loss_ce: 0.202657, loss_dice: 0.793532
[20:35:58.253] iteration 28 : loss : 0.640521, loss_ce: 0.486911, loss_dice: 0.794132
[20:35:58.734] iteration 29 : loss : 0.471663, loss_ce: 0.151828, loss_dice: 0.791498
[20:35:59.215] iteration 30 : loss : 0.527179, loss_ce: 0.267644, loss_dice: 0.786714
[20:35:59.703] iteration 31 : loss : 0.534462, loss_ce: 0.282617, loss_dice: 0.786307
[20:36:00.184] iteration 32 : loss : 0.582290, loss_ce: 0.381000, loss_dice: 0.783579
[20:36:00.925] iteration 33 : loss : 0.556898, loss_ce: 0.334345, loss_dice: 0.779451
[20:36:01.566] iteration 34 : loss : 0.567626, loss_ce: 0.359151, loss_dice: 0.776101
[20:36:02.184] iteration 35 : loss : 0.585450, loss_ce: 0.409229, loss_dice: 0.761671
[20:36:02.619] iteration 36 : loss : 0.536347, loss_ce: 0.304033, loss_dice: 0.768662
[20:36:03.054] iteration 37 : loss : 0.563546, loss_ce: 0.377385, loss_dice: 0.749706
