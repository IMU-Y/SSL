[21:23:43.194] Namespace(root_path='../data/ACDC', exp='ACDC/Semi_Mamba_UNet', model='mambaunet', max_iterations=30000, batch_size=8, deterministic=1, base_lr=0.01, patch_size=[384, 384], seed=1337, num_classes=5, cfg='../code/configs/vmamba_tiny.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, labeled_bs=4, labeled_num=3, ema_decay=0.99, consistency_type='mse', consistency=0.1, consistency_rampup=200.0)
[21:23:44.071] 545 iterations per epoch
[21:23:46.089] iteration 1 : model1 loss : 1.245737 model2 loss : 1.311362
[21:23:46.424] iteration 2 : model1 loss : 1.160307 model2 loss : 1.245026
[21:23:46.757] iteration 3 : model1 loss : 1.014677 model2 loss : 1.250390
[21:23:47.091] iteration 4 : model1 loss : 0.837152 model2 loss : 1.241736
[21:23:47.422] iteration 5 : model1 loss : 0.740759 model2 loss : 1.092100
[21:24:43.041] Namespace(root_path='../data/ACDC', exp='ACDC/Semi_Mamba_UNet', model='mambaunet', max_iterations=30000, batch_size=8, deterministic=1, base_lr=0.01, patch_size=[384, 384], seed=1337, num_classes=5, cfg='../code/configs/vmamba_tiny.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, labeled_bs=4, labeled_num=3, ema_decay=0.99, consistency_type='mse', consistency=0.1, consistency_rampup=200.0)
[21:24:43.904] 545 iterations per epoch
[21:24:46.079] iteration 1 : model1 loss : 1.245737 model2 loss : 1.311362
[21:24:46.416] iteration 2 : model1 loss : 1.160307 model2 loss : 1.245026
[21:24:46.750] iteration 3 : model1 loss : 1.014677 model2 loss : 1.250389
[21:24:47.083] iteration 4 : model1 loss : 0.837152 model2 loss : 1.241737
[21:24:47.417] iteration 5 : model1 loss : 0.740759 model2 loss : 1.092096
[21:24:47.748] iteration 6 : model1 loss : 0.578478 model2 loss : 1.071015
[21:24:48.083] iteration 7 : model1 loss : 0.606011 model2 loss : 0.998721
[21:24:48.414] iteration 8 : model1 loss : 0.600387 model2 loss : 0.920849
[21:24:48.746] iteration 9 : model1 loss : 0.472153 model2 loss : 0.858043
[21:24:49.078] iteration 10 : model1 loss : 0.567225 model2 loss : 0.790536
[21:24:49.415] iteration 11 : model1 loss : 0.664350 model2 loss : 0.687591
[21:24:49.746] iteration 12 : model1 loss : 0.562595 model2 loss : 0.604560
[21:24:50.080] iteration 13 : model1 loss : 0.634022 model2 loss : 0.558203
[21:24:50.416] iteration 14 : model1 loss : 0.593753 model2 loss : 0.505922
[21:24:50.752] iteration 15 : model1 loss : 0.580410 model2 loss : 0.488261
[21:24:51.085] iteration 16 : model1 loss : 0.625618 model2 loss : 0.482703
[21:24:51.418] iteration 17 : model1 loss : 0.410527 model2 loss : 0.517725
[21:24:51.753] iteration 18 : model1 loss : 0.529718 model2 loss : 0.442073
[21:24:52.088] iteration 19 : model1 loss : 0.534156 model2 loss : 0.409526
[21:24:52.424] iteration 20 : model1 loss : 0.474398 model2 loss : 0.442251
[21:24:52.759] iteration 21 : model1 loss : 0.473143 model2 loss : 0.412005
[21:24:53.091] iteration 22 : model1 loss : 0.474582 model2 loss : 0.433993
[21:24:53.421] iteration 23 : model1 loss : 0.497951 model2 loss : 0.407924
[21:24:53.754] iteration 24 : model1 loss : 0.583861 model2 loss : 0.449367
[21:24:54.090] iteration 25 : model1 loss : 0.545974 model2 loss : 0.426023
[21:24:54.422] iteration 26 : model1 loss : 0.574855 model2 loss : 0.368251
[21:24:54.759] iteration 27 : model1 loss : 0.498816 model2 loss : 0.377564
[21:24:55.094] iteration 28 : model1 loss : 0.635640 model2 loss : 0.451301
[21:24:55.426] iteration 29 : model1 loss : 0.475240 model2 loss : 0.405157
[21:24:55.758] iteration 30 : model1 loss : 0.529089 model2 loss : 0.408453
[21:24:56.086] iteration 31 : model1 loss : 0.541247 model2 loss : 0.387614
[21:24:56.420] iteration 32 : model1 loss : 0.590953 model2 loss : 0.422222
[21:24:56.753] iteration 33 : model1 loss : 0.565871 model2 loss : 0.414049
[21:24:57.085] iteration 34 : model1 loss : 0.584073 model2 loss : 0.407824
[21:24:57.414] iteration 35 : model1 loss : 0.601810 model2 loss : 0.409357
[21:24:57.746] iteration 36 : model1 loss : 0.548115 model2 loss : 0.427094
[21:24:58.078] iteration 37 : model1 loss : 0.579130 model2 loss : 0.392355
[21:24:58.410] iteration 38 : model1 loss : 0.568678 model2 loss : 0.365535
[21:24:58.744] iteration 39 : model1 loss : 0.600275 model2 loss : 0.451912
[21:24:59.077] iteration 40 : model1 loss : 0.492219 model2 loss : 0.401902
[21:24:59.410] iteration 41 : model1 loss : 0.550820 model2 loss : 0.338800
[21:24:59.743] iteration 42 : model1 loss : 0.477376 model2 loss : 0.410980
[21:25:00.077] iteration 43 : model1 loss : 0.577550 model2 loss : 0.403956
[21:25:00.410] iteration 44 : model1 loss : 0.588888 model2 loss : 0.480448
[21:25:00.743] iteration 45 : model1 loss : 0.497304 model2 loss : 0.375638
[21:25:01.075] iteration 46 : model1 loss : 0.524559 model2 loss : 0.423151
[21:25:01.410] iteration 47 : model1 loss : 0.543728 model2 loss : 0.377754
[21:25:01.743] iteration 48 : model1 loss : 0.583639 model2 loss : 0.438167
[21:25:02.077] iteration 49 : model1 loss : 0.487831 model2 loss : 0.436088
[21:25:02.414] iteration 50 : model1 loss : 0.525021 model2 loss : 0.356636
[21:25:03.079] iteration 51 : model1 loss : 0.519145 model2 loss : 0.402040
[21:25:03.417] iteration 52 : model1 loss : 0.669496 model2 loss : 0.436045
[21:25:03.752] iteration 53 : model1 loss : 0.462139 model2 loss : 0.444434
[21:25:04.088] iteration 54 : model1 loss : 0.517749 model2 loss : 0.370646
[21:25:04.425] iteration 55 : model1 loss : 0.611452 model2 loss : 0.434123
[21:25:04.762] iteration 56 : model1 loss : 0.593310 model2 loss : 0.383242
[21:25:05.096] iteration 57 : model1 loss : 0.602472 model2 loss : 0.415090
[21:25:05.433] iteration 58 : model1 loss : 0.674495 model2 loss : 0.432151
[21:25:05.769] iteration 59 : model1 loss : 0.511443 model2 loss : 0.368353
[21:25:06.103] iteration 60 : model1 loss : 0.572944 model2 loss : 0.444519
[21:25:06.435] iteration 61 : model1 loss : 0.571104 model2 loss : 0.390694
[21:25:06.770] iteration 62 : model1 loss : 0.528525 model2 loss : 0.355545
[21:25:07.106] iteration 63 : model1 loss : 0.584141 model2 loss : 0.390492
[21:25:07.439] iteration 64 : model1 loss : 0.588587 model2 loss : 0.410744
[21:25:07.772] iteration 65 : model1 loss : 0.578271 model2 loss : 0.384669
[21:25:08.106] iteration 66 : model1 loss : 0.557916 model2 loss : 0.399331
[21:25:08.440] iteration 67 : model1 loss : 0.554766 model2 loss : 0.400505
[21:25:08.775] iteration 68 : model1 loss : 0.515123 model2 loss : 0.382300
[21:25:09.110] iteration 69 : model1 loss : 0.530858 model2 loss : 0.419244
[21:25:09.443] iteration 70 : model1 loss : 0.550408 model2 loss : 0.367072
[21:25:09.776] iteration 71 : model1 loss : 0.577442 model2 loss : 0.398673
[21:25:10.111] iteration 72 : model1 loss : 0.574413 model2 loss : 0.370241
[21:25:10.444] iteration 73 : model1 loss : 0.510913 model2 loss : 0.388950
[21:25:10.778] iteration 74 : model1 loss : 0.560224 model2 loss : 0.374919
[21:25:11.112] iteration 75 : model1 loss : 0.628395 model2 loss : 0.451722
[21:25:11.447] iteration 76 : model1 loss : 0.622478 model2 loss : 0.472504
[21:25:11.785] iteration 77 : model1 loss : 0.483805 model2 loss : 0.378326
[21:25:12.118] iteration 78 : model1 loss : 0.527027 model2 loss : 0.348068
[21:25:12.451] iteration 79 : model1 loss : 0.539610 model2 loss : 0.401293
[21:25:12.788] iteration 80 : model1 loss : 0.454599 model2 loss : 0.373689
[21:25:13.121] iteration 81 : model1 loss : 0.512298 model2 loss : 0.350339
[21:25:13.456] iteration 82 : model1 loss : 0.491276 model2 loss : 0.381329
[21:25:13.793] iteration 83 : model1 loss : 0.453935 model2 loss : 0.355470
[21:25:14.139] iteration 84 : model1 loss : 0.470023 model2 loss : 0.368124
[21:25:14.476] iteration 85 : model1 loss : 0.532488 model2 loss : 0.387103
[21:25:14.820] iteration 86 : model1 loss : 0.477908 model2 loss : 0.344542
[21:25:15.160] iteration 87 : model1 loss : 0.509642 model2 loss : 0.423810
[21:25:15.493] iteration 88 : model1 loss : 0.829136 model2 loss : 0.478733
[21:25:15.836] iteration 89 : model1 loss : 0.581075 model2 loss : 0.402602
[21:25:16.171] iteration 90 : model1 loss : 0.520021 model2 loss : 0.387574
[21:25:16.505] iteration 91 : model1 loss : 0.570561 model2 loss : 0.381345
[21:25:16.838] iteration 92 : model1 loss : 0.482096 model2 loss : 0.356937
[21:25:17.172] iteration 93 : model1 loss : 0.421450 model2 loss : 0.440390
[21:25:17.505] iteration 94 : model1 loss : 0.566847 model2 loss : 0.386746
[21:25:17.841] iteration 95 : model1 loss : 0.543244 model2 loss : 0.386061
[21:25:18.174] iteration 96 : model1 loss : 0.551639 model2 loss : 0.363259
[21:25:18.511] iteration 97 : model1 loss : 0.544681 model2 loss : 0.389702
[21:25:18.844] iteration 98 : model1 loss : 0.602384 model2 loss : 0.458679
[21:25:19.178] iteration 99 : model1 loss : 0.520274 model2 loss : 0.336831
[21:25:19.512] iteration 100 : model1 loss : 0.521632 model2 loss : 0.382039
[21:25:20.144] iteration 101 : model1 loss : 0.653377 model2 loss : 0.420692
[21:25:20.479] iteration 102 : model1 loss : 0.591675 model2 loss : 0.401995
[21:25:20.815] iteration 103 : model1 loss : 0.595895 model2 loss : 0.370194
[21:25:21.149] iteration 104 : model1 loss : 0.633458 model2 loss : 0.389547
[21:25:21.484] iteration 105 : model1 loss : 0.525363 model2 loss : 0.345480
[21:25:21.822] iteration 106 : model1 loss : 0.620975 model2 loss : 0.404088
[21:25:22.163] iteration 107 : model1 loss : 0.551986 model2 loss : 0.373691
[21:25:22.497] iteration 108 : model1 loss : 0.564685 model2 loss : 0.349206
[21:25:22.836] iteration 109 : model1 loss : 0.596865 model2 loss : 0.394931
[21:25:23.168] iteration 110 : model1 loss : 0.580865 model2 loss : 0.387374
[21:25:23.504] iteration 111 : model1 loss : 0.614469 model2 loss : 0.453293
[21:25:23.845] iteration 112 : model1 loss : 0.677311 model2 loss : 0.462472
[21:25:24.179] iteration 113 : model1 loss : 0.552755 model2 loss : 0.335181
[21:25:24.512] iteration 114 : model1 loss : 0.545550 model2 loss : 0.383083
[21:25:24.845] iteration 115 : model1 loss : 0.515230 model2 loss : 0.353695
[21:25:25.181] iteration 116 : model1 loss : 0.540635 model2 loss : 0.376577
[21:25:25.517] iteration 117 : model1 loss : 0.643336 model2 loss : 0.487408
[21:25:25.852] iteration 118 : model1 loss : 0.522359 model2 loss : 0.380353
[21:25:26.193] iteration 119 : model1 loss : 0.568223 model2 loss : 0.381145
[21:25:26.529] iteration 120 : model1 loss : 0.557103 model2 loss : 0.337529
[21:25:26.863] iteration 121 : model1 loss : 0.574044 model2 loss : 0.462348
[21:25:27.201] iteration 122 : model1 loss : 0.501836 model2 loss : 0.398039
[21:25:27.533] iteration 123 : model1 loss : 0.479674 model2 loss : 0.336453
[21:25:27.865] iteration 124 : model1 loss : 0.521305 model2 loss : 0.330894
[21:25:28.198] iteration 125 : model1 loss : 0.564045 model2 loss : 0.345272
[21:25:28.533] iteration 126 : model1 loss : 0.543121 model2 loss : 0.333616
[21:25:28.867] iteration 127 : model1 loss : 0.546126 model2 loss : 0.324580
[21:25:29.201] iteration 128 : model1 loss : 0.566749 model2 loss : 0.430782
[21:25:29.536] iteration 129 : model1 loss : 0.634552 model2 loss : 0.416118
[21:25:29.872] iteration 130 : model1 loss : 0.558917 model2 loss : 0.423381
[21:25:30.207] iteration 131 : model1 loss : 0.611908 model2 loss : 0.371053
[21:25:30.543] iteration 132 : model1 loss : 0.615627 model2 loss : 0.380235
[21:25:30.879] iteration 133 : model1 loss : 0.551768 model2 loss : 0.399612
[21:25:31.216] iteration 134 : model1 loss : 0.537557 model2 loss : 0.387778
[21:25:31.562] iteration 135 : model1 loss : 0.484511 model2 loss : 0.399678
[21:25:31.899] iteration 136 : model1 loss : 0.631023 model2 loss : 0.426701
[21:25:32.239] iteration 137 : model1 loss : 0.660410 model2 loss : 0.441903
[21:25:32.575] iteration 138 : model1 loss : 0.644857 model2 loss : 0.372060
[21:25:32.914] iteration 139 : model1 loss : 0.550274 model2 loss : 0.420343
[21:25:33.248] iteration 140 : model1 loss : 0.536137 model2 loss : 0.440887
[21:25:33.580] iteration 141 : model1 loss : 0.524272 model2 loss : 0.349297
[21:25:33.912] iteration 142 : model1 loss : 0.575167 model2 loss : 0.343772
[21:25:34.249] iteration 143 : model1 loss : 0.688868 model2 loss : 0.460269
[21:25:34.587] iteration 144 : model1 loss : 0.565193 model2 loss : 0.321506
[21:25:34.921] iteration 145 : model1 loss : 0.493412 model2 loss : 0.369702
[21:25:35.257] iteration 146 : model1 loss : 0.562003 model2 loss : 0.388767
[21:25:35.593] iteration 147 : model1 loss : 0.543433 model2 loss : 0.412961
[21:25:35.927] iteration 148 : model1 loss : 0.534677 model2 loss : 0.366179
[21:25:36.261] iteration 149 : model1 loss : 0.523008 model2 loss : 0.394798
[21:25:36.604] iteration 150 : model1 loss : 0.572672 model2 loss : 0.426374
[21:25:37.222] iteration 151 : model1 loss : 0.511488 model2 loss : 0.366944
[21:25:37.557] iteration 152 : model1 loss : 0.640953 model2 loss : 0.391124
[21:25:37.892] iteration 153 : model1 loss : 0.498211 model2 loss : 0.325635
[21:25:38.226] iteration 154 : model1 loss : 0.520245 model2 loss : 0.421694
[21:25:38.563] iteration 155 : model1 loss : 0.581952 model2 loss : 0.376610
[21:25:38.902] iteration 156 : model1 loss : 0.500713 model2 loss : 0.411195
[21:25:39.237] iteration 157 : model1 loss : 0.494300 model2 loss : 0.351493
[21:25:39.570] iteration 158 : model1 loss : 0.610193 model2 loss : 0.395139
[21:25:39.895] iteration 159 : model1 loss : 0.553272 model2 loss : 0.355283
[21:25:40.221] iteration 160 : model1 loss : 0.547472 model2 loss : 0.328786
[21:25:40.546] iteration 161 : model1 loss : 0.505602 model2 loss : 0.357361
[21:25:40.873] iteration 162 : model1 loss : 0.501499 model2 loss : 0.381880
[21:25:41.197] iteration 163 : model1 loss : 0.586713 model2 loss : 0.354513
[21:25:41.524] iteration 164 : model1 loss : 0.538511 model2 loss : 0.411845
[21:25:41.850] iteration 165 : model1 loss : 0.513627 model2 loss : 0.340776
[21:25:42.178] iteration 166 : model1 loss : 0.601501 model2 loss : 0.412621
[21:25:42.503] iteration 167 : model1 loss : 0.550402 model2 loss : 0.368291
[21:25:42.836] iteration 168 : model1 loss : 0.506532 model2 loss : 0.375187
[21:25:43.169] iteration 169 : model1 loss : 0.587406 model2 loss : 0.329841
[21:25:43.502] iteration 170 : model1 loss : 0.527064 model2 loss : 0.318468
[21:25:43.835] iteration 171 : model1 loss : 0.600597 model2 loss : 0.458128
[21:25:44.169] iteration 172 : model1 loss : 0.552495 model2 loss : 0.378827
[21:25:44.505] iteration 173 : model1 loss : 0.707707 model2 loss : 0.414910
[21:25:44.839] iteration 174 : model1 loss : 0.491800 model2 loss : 0.339510
[21:25:45.175] iteration 175 : model1 loss : 0.576232 model2 loss : 0.342336
[21:25:45.510] iteration 176 : model1 loss : 0.478081 model2 loss : 0.351390
[21:25:45.844] iteration 177 : model1 loss : 0.601342 model2 loss : 0.387442
[21:25:46.179] iteration 178 : model1 loss : 0.456497 model2 loss : 0.359984
[21:25:46.521] iteration 179 : model1 loss : 0.523198 model2 loss : 0.321948
[21:25:46.855] iteration 180 : model1 loss : 0.610402 model2 loss : 0.376054
[21:25:47.190] iteration 181 : model1 loss : 0.566835 model2 loss : 0.356298
[21:25:47.527] iteration 182 : model1 loss : 0.580928 model2 loss : 0.335148
[21:25:47.859] iteration 183 : model1 loss : 0.538790 model2 loss : 0.346310
[21:25:48.194] iteration 184 : model1 loss : 0.628159 model2 loss : 0.369112
[21:25:48.529] iteration 185 : model1 loss : 0.481277 model2 loss : 0.345135
[21:25:48.863] iteration 186 : model1 loss : 0.555722 model2 loss : 0.337963
[21:25:49.198] iteration 187 : model1 loss : 0.559215 model2 loss : 0.410775
[21:25:49.533] iteration 188 : model1 loss : 0.532003 model2 loss : 0.325672
[21:25:49.867] iteration 189 : model1 loss : 0.557858 model2 loss : 0.423257
[21:25:50.200] iteration 190 : model1 loss : 0.506129 model2 loss : 0.330054
[21:25:50.533] iteration 191 : model1 loss : 0.521447 model2 loss : 0.376431
[21:25:50.869] iteration 192 : model1 loss : 0.523149 model2 loss : 0.460346
[21:25:51.206] iteration 193 : model1 loss : 0.505240 model2 loss : 0.370292
[21:25:51.540] iteration 194 : model1 loss : 0.563259 model2 loss : 0.347282
[21:25:51.880] iteration 195 : model1 loss : 0.663096 model2 loss : 0.453310
[21:25:52.215] iteration 196 : model1 loss : 0.487998 model2 loss : 0.358213
[21:25:52.550] iteration 197 : model1 loss : 0.606854 model2 loss : 0.382846
[21:25:52.886] iteration 198 : model1 loss : 0.578842 model2 loss : 0.421178
[21:25:53.222] iteration 199 : model1 loss : 0.506851 model2 loss : 0.414943
[21:25:53.556] iteration 200 : model1 loss : 0.468479 model2 loss : 0.309299
[21:25:54.212] iteration 201 : model1 loss : 0.540499 model2 loss : 0.421088
[21:25:54.548] iteration 202 : model1 loss : 0.485666 model2 loss : 0.399730
[21:25:54.883] iteration 203 : model1 loss : 0.539183 model2 loss : 0.350899
[21:25:55.220] iteration 204 : model1 loss : 0.464687 model2 loss : 0.373325
[21:25:55.555] iteration 205 : model1 loss : 0.499062 model2 loss : 0.384835
[21:25:55.890] iteration 206 : model1 loss : 0.416948 model2 loss : 0.366235
[21:25:56.223] iteration 207 : model1 loss : 0.471568 model2 loss : 0.338933
[21:25:56.561] iteration 208 : model1 loss : 0.465588 model2 loss : 0.361931
[21:25:56.896] iteration 209 : model1 loss : 0.416255 model2 loss : 0.317264
[21:25:57.231] iteration 210 : model1 loss : 0.511905 model2 loss : 0.405132
[21:25:57.566] iteration 211 : model1 loss : 0.459431 model2 loss : 0.360561
[21:25:57.902] iteration 212 : model1 loss : 0.434377 model2 loss : 0.322663
[21:25:58.236] iteration 213 : model1 loss : 0.482795 model2 loss : 0.357334
[21:25:58.571] iteration 214 : model1 loss : 0.451269 model2 loss : 0.360310
[21:25:58.905] iteration 215 : model1 loss : 0.432072 model2 loss : 0.348859
[21:25:59.239] iteration 216 : model1 loss : 0.449600 model2 loss : 0.373434
[21:25:59.572] iteration 217 : model1 loss : 0.461872 model2 loss : 0.331203
[21:25:59.907] iteration 218 : model1 loss : 0.434193 model2 loss : 0.371739
[21:26:00.241] iteration 219 : model1 loss : 0.547192 model2 loss : 0.408250
[21:26:00.573] iteration 220 : model1 loss : 0.453722 model2 loss : 0.375317
[21:26:00.910] iteration 221 : model1 loss : 0.447325 model2 loss : 0.356049
[21:26:01.249] iteration 222 : model1 loss : 0.413050 model2 loss : 0.365993
[21:26:01.587] iteration 223 : model1 loss : 0.445948 model2 loss : 0.336388
[21:26:01.922] iteration 224 : model1 loss : 0.476117 model2 loss : 0.428452
[21:26:02.257] iteration 225 : model1 loss : 0.445607 model2 loss : 0.315240
[21:26:02.593] iteration 226 : model1 loss : 0.419560 model2 loss : 0.330989
[21:26:02.930] iteration 227 : model1 loss : 0.477575 model2 loss : 0.425361
[21:26:03.267] iteration 228 : model1 loss : 0.420542 model2 loss : 0.359958
[21:26:03.602] iteration 229 : model1 loss : 0.472298 model2 loss : 0.404172
[21:26:03.941] iteration 230 : model1 loss : 0.449930 model2 loss : 0.349527
[21:26:04.265] iteration 231 : model1 loss : 0.408304 model2 loss : 0.357061
[21:26:04.590] iteration 232 : model1 loss : 0.405230 model2 loss : 0.315009
[21:26:04.915] iteration 233 : model1 loss : 0.478397 model2 loss : 0.381072
[21:26:05.240] iteration 234 : model1 loss : 0.419031 model2 loss : 0.305217
[21:26:05.566] iteration 235 : model1 loss : 0.402138 model2 loss : 0.372711
[21:26:05.891] iteration 236 : model1 loss : 0.415794 model2 loss : 0.381431
[21:26:06.217] iteration 237 : model1 loss : 0.448443 model2 loss : 0.367573
[21:26:06.542] iteration 238 : model1 loss : 0.444812 model2 loss : 0.346014
[21:26:06.867] iteration 239 : model1 loss : 0.456165 model2 loss : 0.410662
[21:26:07.192] iteration 240 : model1 loss : 0.388337 model2 loss : 0.326283
[21:26:07.520] iteration 241 : model1 loss : 0.466594 model2 loss : 0.375380
[21:26:07.845] iteration 242 : model1 loss : 0.455961 model2 loss : 0.380322
[21:26:08.170] iteration 243 : model1 loss : 0.408947 model2 loss : 0.332422
[21:26:08.495] iteration 244 : model1 loss : 0.431910 model2 loss : 0.325086
[21:26:08.821] iteration 245 : model1 loss : 0.405738 model2 loss : 0.300924
[21:26:09.147] iteration 246 : model1 loss : 0.461856 model2 loss : 0.376026
[21:26:09.472] iteration 247 : model1 loss : 0.494783 model2 loss : 0.408167
[21:26:09.798] iteration 248 : model1 loss : 0.420542 model2 loss : 0.331968
[21:26:10.123] iteration 249 : model1 loss : 0.379602 model2 loss : 0.327823
[21:26:10.448] iteration 250 : model1 loss : 0.474035 model2 loss : 0.410399
[21:26:11.026] iteration 251 : model1 loss : 0.460047 model2 loss : 0.395651
[21:26:11.351] iteration 252 : model1 loss : 0.484904 model2 loss : 0.388041
[21:26:11.676] iteration 253 : model1 loss : 0.418392 model2 loss : 0.357031
[21:26:12.001] iteration 254 : model1 loss : 0.448965 model2 loss : 0.379715
[21:26:12.324] iteration 255 : model1 loss : 0.430249 model2 loss : 0.318890
[21:26:12.647] iteration 256 : model1 loss : 0.427101 model2 loss : 0.357658
[21:26:12.972] iteration 257 : model1 loss : 0.446813 model2 loss : 0.385821
[21:26:13.296] iteration 258 : model1 loss : 0.403251 model2 loss : 0.361300
[21:26:13.621] iteration 259 : model1 loss : 0.425694 model2 loss : 0.366613
[21:26:13.946] iteration 260 : model1 loss : 0.463127 model2 loss : 0.404444
[21:26:14.270] iteration 261 : model1 loss : 0.430942 model2 loss : 0.377296
[21:26:14.596] iteration 262 : model1 loss : 0.412373 model2 loss : 0.321602
[21:26:14.920] iteration 263 : model1 loss : 0.431755 model2 loss : 0.343451
[21:26:15.245] iteration 264 : model1 loss : 0.384359 model2 loss : 0.326981
[21:26:15.570] iteration 265 : model1 loss : 0.411803 model2 loss : 0.316647
[21:26:15.895] iteration 266 : model1 loss : 0.445274 model2 loss : 0.395834
[21:26:16.219] iteration 267 : model1 loss : 0.419856 model2 loss : 0.405907
[21:26:16.544] iteration 268 : model1 loss : 0.388207 model2 loss : 0.352244
[21:26:16.867] iteration 269 : model1 loss : 0.401335 model2 loss : 0.311653
[21:26:17.192] iteration 270 : model1 loss : 0.407161 model2 loss : 0.326973
[21:26:17.516] iteration 271 : model1 loss : 0.426377 model2 loss : 0.375262
[21:26:17.841] iteration 272 : model1 loss : 0.400430 model2 loss : 0.322247
[21:26:18.164] iteration 273 : model1 loss : 0.456667 model2 loss : 0.399213
[21:26:18.489] iteration 274 : model1 loss : 0.362195 model2 loss : 0.315281
[21:26:18.814] iteration 275 : model1 loss : 0.381777 model2 loss : 0.312565
[21:26:19.138] iteration 276 : model1 loss : 0.385243 model2 loss : 0.308742
[21:26:19.461] iteration 277 : model1 loss : 0.413741 model2 loss : 0.370662
[21:26:19.783] iteration 278 : model1 loss : 0.405283 model2 loss : 0.304531
[21:26:20.106] iteration 279 : model1 loss : 0.412718 model2 loss : 0.335162
[21:26:20.428] iteration 280 : model1 loss : 0.418516 model2 loss : 0.380319
[21:26:20.752] iteration 281 : model1 loss : 0.425931 model2 loss : 0.342734
[21:26:21.075] iteration 282 : model1 loss : 0.389094 model2 loss : 0.348666
[21:26:21.398] iteration 283 : model1 loss : 0.549008 model2 loss : 0.472237
[21:26:21.722] iteration 284 : model1 loss : 0.383587 model2 loss : 0.318523
[21:26:22.044] iteration 285 : model1 loss : 0.402538 model2 loss : 0.333098
[21:26:22.367] iteration 286 : model1 loss : 0.405932 model2 loss : 0.350063
[21:26:22.690] iteration 287 : model1 loss : 0.434653 model2 loss : 0.390504
[21:26:23.012] iteration 288 : model1 loss : 0.423144 model2 loss : 0.376952
[21:26:23.336] iteration 289 : model1 loss : 0.415232 model2 loss : 0.352602
[21:26:23.659] iteration 290 : model1 loss : 0.419890 model2 loss : 0.337812
[21:26:23.982] iteration 291 : model1 loss : 0.391302 model2 loss : 0.369925
[21:26:24.305] iteration 292 : model1 loss : 0.461287 model2 loss : 0.367885
[21:26:24.628] iteration 293 : model1 loss : 0.575471 model2 loss : 0.472460
[21:26:24.951] iteration 294 : model1 loss : 0.394861 model2 loss : 0.300720
[21:26:25.275] iteration 295 : model1 loss : 0.467991 model2 loss : 0.408023
[21:26:25.598] iteration 296 : model1 loss : 0.434823 model2 loss : 0.436715
[21:26:25.922] iteration 297 : model1 loss : 0.492288 model2 loss : 0.456345
[21:26:26.245] iteration 298 : model1 loss : 0.371855 model2 loss : 0.340166
[21:26:26.568] iteration 299 : model1 loss : 0.418642 model2 loss : 0.332277
[21:26:26.891] iteration 300 : model1 loss : 0.395746 model2 loss : 0.320906
[21:26:27.404] iteration 301 : model1 loss : 0.360872 model2 loss : 0.338299
[21:26:27.727] iteration 302 : model1 loss : 0.426990 model2 loss : 0.391904
[21:26:28.050] iteration 303 : model1 loss : 0.461621 model2 loss : 0.412008
[21:26:28.374] iteration 304 : model1 loss : 0.437704 model2 loss : 0.423101
[21:26:28.697] iteration 305 : model1 loss : 0.442570 model2 loss : 0.388843
[21:26:29.022] iteration 306 : model1 loss : 0.437512 model2 loss : 0.317195
[21:26:29.345] iteration 307 : model1 loss : 0.445491 model2 loss : 0.346774
[21:26:29.668] iteration 308 : model1 loss : 0.390048 model2 loss : 0.357968
[21:26:29.991] iteration 309 : model1 loss : 0.446040 model2 loss : 0.389440
[21:26:30.315] iteration 310 : model1 loss : 0.418665 model2 loss : 0.364401
[21:26:30.638] iteration 311 : model1 loss : 0.390850 model2 loss : 0.356286
[21:26:30.961] iteration 312 : model1 loss : 0.404941 model2 loss : 0.345758
[21:26:31.285] iteration 313 : model1 loss : 0.366686 model2 loss : 0.309488
[21:26:31.608] iteration 314 : model1 loss : 0.376288 model2 loss : 0.360673
[21:26:31.931] iteration 315 : model1 loss : 0.534987 model2 loss : 0.410676
[21:26:32.258] iteration 316 : model1 loss : 0.402705 model2 loss : 0.370430
[21:26:32.580] iteration 317 : model1 loss : 0.453072 model2 loss : 0.396697
[21:26:32.914] iteration 318 : model1 loss : 0.528758 model2 loss : 0.458092
[21:26:33.241] iteration 319 : model1 loss : 0.454610 model2 loss : 0.352071
[21:26:33.564] iteration 320 : model1 loss : 0.451106 model2 loss : 0.361610
[21:26:33.890] iteration 321 : model1 loss : 0.388171 model2 loss : 0.377341
[21:26:34.215] iteration 322 : model1 loss : 0.416257 model2 loss : 0.367490
[21:26:34.541] iteration 323 : model1 loss : 0.406914 model2 loss : 0.326650
[21:26:34.865] iteration 324 : model1 loss : 0.449997 model2 loss : 0.426900
[21:26:35.192] iteration 325 : model1 loss : 0.392456 model2 loss : 0.357148
[21:26:35.517] iteration 326 : model1 loss : 0.396825 model2 loss : 0.323065
[21:26:35.841] iteration 327 : model1 loss : 0.436450 model2 loss : 0.399393
[21:26:36.166] iteration 328 : model1 loss : 0.403146 model2 loss : 0.362040
[21:26:36.493] iteration 329 : model1 loss : 0.409691 model2 loss : 0.320582
[21:26:36.827] iteration 330 : model1 loss : 0.380536 model2 loss : 0.331899
[21:26:37.185] iteration 331 : model1 loss : 0.407680 model2 loss : 0.296429
[21:26:37.519] iteration 332 : model1 loss : 0.365161 model2 loss : 0.277393
[21:26:37.852] iteration 333 : model1 loss : 0.427564 model2 loss : 0.378382
[21:26:38.185] iteration 334 : model1 loss : 0.421895 model2 loss : 0.386587
[21:26:38.541] iteration 335 : model1 loss : 0.368183 model2 loss : 0.306636
[21:26:38.876] iteration 336 : model1 loss : 0.372886 model2 loss : 0.288174
[21:26:39.210] iteration 337 : model1 loss : 0.396209 model2 loss : 0.358263
[21:26:39.544] iteration 338 : model1 loss : 0.428721 model2 loss : 0.373483
[21:26:39.879] iteration 339 : model1 loss : 0.410923 model2 loss : 0.365029
[21:26:40.214] iteration 340 : model1 loss : 0.414090 model2 loss : 0.388489
[21:26:40.548] iteration 341 : model1 loss : 0.367022 model2 loss : 0.300936
[21:26:40.883] iteration 342 : model1 loss : 0.404689 model2 loss : 0.326662
[21:26:41.219] iteration 343 : model1 loss : 0.460442 model2 loss : 0.377456
[21:26:41.563] iteration 344 : model1 loss : 0.409408 model2 loss : 0.352773
[21:26:41.898] iteration 345 : model1 loss : 0.429705 model2 loss : 0.418542
[21:26:42.232] iteration 346 : model1 loss : 0.422336 model2 loss : 0.421074
[21:26:42.568] iteration 347 : model1 loss : 0.433029 model2 loss : 0.339981
[21:26:42.905] iteration 348 : model1 loss : 0.390407 model2 loss : 0.340310
[21:26:43.239] iteration 349 : model1 loss : 0.384735 model2 loss : 0.340915
[21:26:43.574] iteration 350 : model1 loss : 0.400135 model2 loss : 0.360620
[21:26:44.218] iteration 351 : model1 loss : 0.405569 model2 loss : 0.344956
[21:26:44.552] iteration 352 : model1 loss : 0.398841 model2 loss : 0.336931
[21:26:44.887] iteration 353 : model1 loss : 0.381077 model2 loss : 0.304175
[21:26:45.222] iteration 354 : model1 loss : 0.351894 model2 loss : 0.265913
[21:26:45.558] iteration 355 : model1 loss : 0.412330 model2 loss : 0.353931
[21:26:45.891] iteration 356 : model1 loss : 0.423174 model2 loss : 0.368260
[21:26:46.228] iteration 357 : model1 loss : 0.390919 model2 loss : 0.356637
[21:26:46.563] iteration 358 : model1 loss : 0.429989 model2 loss : 0.403031
[21:26:46.898] iteration 359 : model1 loss : 0.396351 model2 loss : 0.343688
[21:26:47.232] iteration 360 : model1 loss : 0.556579 model2 loss : 0.501607
[21:26:47.566] iteration 361 : model1 loss : 0.444668 model2 loss : 0.436172
[21:26:47.900] iteration 362 : model1 loss : 0.392837 model2 loss : 0.349233
[21:26:48.234] iteration 363 : model1 loss : 0.370233 model2 loss : 0.324777
[21:26:48.569] iteration 364 : model1 loss : 0.422258 model2 loss : 0.360238
[21:26:48.903] iteration 365 : model1 loss : 0.424329 model2 loss : 0.343187
[21:26:49.236] iteration 366 : model1 loss : 0.424953 model2 loss : 0.414459
[21:26:49.572] iteration 367 : model1 loss : 0.415358 model2 loss : 0.361232
[21:26:49.905] iteration 368 : model1 loss : 0.403989 model2 loss : 0.374882
[21:26:50.240] iteration 369 : model1 loss : 0.377763 model2 loss : 0.272315
[21:26:50.574] iteration 370 : model1 loss : 0.404539 model2 loss : 0.330652
[21:26:50.909] iteration 371 : model1 loss : 0.396262 model2 loss : 0.362997
[21:26:51.249] iteration 372 : model1 loss : 0.399922 model2 loss : 0.338682
[21:26:51.582] iteration 373 : model1 loss : 0.369480 model2 loss : 0.311340
[21:26:51.917] iteration 374 : model1 loss : 0.369936 model2 loss : 0.321407
[21:26:52.254] iteration 375 : model1 loss : 0.447895 model2 loss : 0.388976
[21:26:52.588] iteration 376 : model1 loss : 0.433381 model2 loss : 0.402930
[21:26:52.922] iteration 377 : model1 loss : 0.467842 model2 loss : 0.392193
[21:26:53.255] iteration 378 : model1 loss : 0.446122 model2 loss : 0.437871
[21:26:53.591] iteration 379 : model1 loss : 0.400039 model2 loss : 0.370435
[21:26:53.925] iteration 380 : model1 loss : 0.400343 model2 loss : 0.340232
[21:26:54.259] iteration 381 : model1 loss : 0.459308 model2 loss : 0.363498
[21:26:54.593] iteration 382 : model1 loss : 0.459084 model2 loss : 0.356821
[21:26:54.926] iteration 383 : model1 loss : 0.420490 model2 loss : 0.375502
[21:26:55.260] iteration 384 : model1 loss : 0.389715 model2 loss : 0.333165
[21:26:55.595] iteration 385 : model1 loss : 0.424786 model2 loss : 0.413875
[21:26:55.931] iteration 386 : model1 loss : 0.384690 model2 loss : 0.353636
[21:26:56.265] iteration 387 : model1 loss : 0.388320 model2 loss : 0.334390
[21:26:56.605] iteration 388 : model1 loss : 0.403601 model2 loss : 0.341164
[21:26:56.947] iteration 389 : model1 loss : 0.373348 model2 loss : 0.281761
[21:26:57.282] iteration 390 : model1 loss : 0.385671 model2 loss : 0.364452
[21:26:57.618] iteration 391 : model1 loss : 0.414462 model2 loss : 0.316159
[21:26:57.952] iteration 392 : model1 loss : 0.398939 model2 loss : 0.292596
[21:26:58.284] iteration 393 : model1 loss : 0.438105 model2 loss : 0.356120
[21:26:58.619] iteration 394 : model1 loss : 0.401630 model2 loss : 0.345149
[21:26:58.953] iteration 395 : model1 loss : 0.433824 model2 loss : 0.374286
[21:26:59.287] iteration 396 : model1 loss : 0.409803 model2 loss : 0.345422
[21:26:59.620] iteration 397 : model1 loss : 0.401805 model2 loss : 0.317368
[21:26:59.953] iteration 398 : model1 loss : 0.493514 model2 loss : 0.456692
[21:27:00.288] iteration 399 : model1 loss : 0.426263 model2 loss : 0.355538
[21:27:00.622] iteration 400 : model1 loss : 0.396429 model2 loss : 0.340297
[21:27:01.268] iteration 401 : model1 loss : 0.464500 model2 loss : 0.403777
[21:27:01.593] iteration 402 : model1 loss : 0.421523 model2 loss : 0.335056
[21:27:01.919] iteration 403 : model1 loss : 0.428659 model2 loss : 0.363399
[21:27:02.244] iteration 404 : model1 loss : 0.392490 model2 loss : 0.311307
[21:27:02.570] iteration 405 : model1 loss : 0.469063 model2 loss : 0.387383
[21:27:02.895] iteration 406 : model1 loss : 0.374916 model2 loss : 0.306862
[21:27:03.220] iteration 407 : model1 loss : 0.368119 model2 loss : 0.319034
[21:27:03.545] iteration 408 : model1 loss : 0.396998 model2 loss : 0.293838
[21:27:03.869] iteration 409 : model1 loss : 0.419774 model2 loss : 0.364760
[21:27:04.194] iteration 410 : model1 loss : 0.377480 model2 loss : 0.380603
[21:27:04.520] iteration 411 : model1 loss : 0.392048 model2 loss : 0.380687
[21:27:04.844] iteration 412 : model1 loss : 0.432140 model2 loss : 0.374597
[21:27:05.168] iteration 413 : model1 loss : 0.407107 model2 loss : 0.307501
[21:27:05.496] iteration 414 : model1 loss : 0.449063 model2 loss : 0.402871
[21:27:05.820] iteration 415 : model1 loss : 0.416384 model2 loss : 0.334768
[21:27:06.145] iteration 416 : model1 loss : 0.409362 model2 loss : 0.334547
[21:27:06.470] iteration 417 : model1 loss : 0.477382 model2 loss : 0.435781
[21:27:06.794] iteration 418 : model1 loss : 0.371307 model2 loss : 0.314046
[21:27:07.118] iteration 419 : model1 loss : 0.352560 model2 loss : 0.299392
[21:27:07.443] iteration 420 : model1 loss : 0.392317 model2 loss : 0.389162
[21:27:07.768] iteration 421 : model1 loss : 0.443383 model2 loss : 0.359742
[21:27:08.093] iteration 422 : model1 loss : 0.396607 model2 loss : 0.369146
[21:27:08.418] iteration 423 : model1 loss : 0.392143 model2 loss : 0.324454
[21:27:08.746] iteration 424 : model1 loss : 0.418379 model2 loss : 0.367197
[21:27:09.071] iteration 425 : model1 loss : 0.429113 model2 loss : 0.359811
[21:27:09.397] iteration 426 : model1 loss : 0.397281 model2 loss : 0.380415
[21:27:09.722] iteration 427 : model1 loss : 0.376625 model2 loss : 0.296315
[21:27:10.047] iteration 428 : model1 loss : 0.384389 model2 loss : 0.329832
[21:27:10.372] iteration 429 : model1 loss : 0.433241 model2 loss : 0.358023
[21:27:10.696] iteration 430 : model1 loss : 0.372476 model2 loss : 0.307240
[21:27:11.022] iteration 431 : model1 loss : 0.417673 model2 loss : 0.366544
[21:27:11.349] iteration 432 : model1 loss : 0.355431 model2 loss : 0.295094
[21:27:11.674] iteration 433 : model1 loss : 0.370659 model2 loss : 0.332790
[21:27:11.998] iteration 434 : model1 loss : 0.396125 model2 loss : 0.344090
[21:27:12.323] iteration 435 : model1 loss : 0.379218 model2 loss : 0.307225
[21:27:12.646] iteration 436 : model1 loss : 0.409622 model2 loss : 0.344434
[21:27:12.971] iteration 437 : model1 loss : 0.361991 model2 loss : 0.323669
[21:27:13.295] iteration 438 : model1 loss : 0.414712 model2 loss : 0.382215
[21:27:13.618] iteration 439 : model1 loss : 0.488843 model2 loss : 0.412812
[21:27:13.941] iteration 440 : model1 loss : 0.383177 model2 loss : 0.346949
[21:27:14.265] iteration 441 : model1 loss : 0.411688 model2 loss : 0.352946
[21:27:14.594] iteration 442 : model1 loss : 0.405818 model2 loss : 0.367225
[21:27:14.929] iteration 443 : model1 loss : 0.431543 model2 loss : 0.346137
[21:27:15.281] iteration 444 : model1 loss : 0.408391 model2 loss : 0.434807
[21:27:15.619] iteration 445 : model1 loss : 0.373957 model2 loss : 0.280131
[21:27:15.954] iteration 446 : model1 loss : 0.377356 model2 loss : 0.344587
[21:27:16.289] iteration 447 : model1 loss : 0.347296 model2 loss : 0.288796
[21:27:16.625] iteration 448 : model1 loss : 0.336665 model2 loss : 0.257779
[21:27:16.960] iteration 449 : model1 loss : 0.382623 model2 loss : 0.313463
[21:27:17.296] iteration 450 : model1 loss : 0.417365 model2 loss : 0.405505
[21:27:17.957] iteration 451 : model1 loss : 0.380470 model2 loss : 0.323901
[21:27:18.292] iteration 452 : model1 loss : 0.409824 model2 loss : 0.358067
[21:27:18.627] iteration 453 : model1 loss : 0.407799 model2 loss : 0.379813
[21:27:18.964] iteration 454 : model1 loss : 0.425159 model2 loss : 0.374180
[21:27:19.299] iteration 455 : model1 loss : 0.342582 model2 loss : 0.325894
[21:27:19.630] iteration 456 : model1 loss : 0.375209 model2 loss : 0.337790
[21:27:19.969] iteration 457 : model1 loss : 0.379128 model2 loss : 0.321760
[21:27:20.304] iteration 458 : model1 loss : 0.379343 model2 loss : 0.351279
[21:27:20.640] iteration 459 : model1 loss : 0.404944 model2 loss : 0.318166
[21:27:20.974] iteration 460 : model1 loss : 0.409858 model2 loss : 0.364843
[21:27:21.309] iteration 461 : model1 loss : 0.360105 model2 loss : 0.333939
[21:27:21.644] iteration 462 : model1 loss : 0.430993 model2 loss : 0.331898
[21:27:21.979] iteration 463 : model1 loss : 0.403569 model2 loss : 0.357739
[21:27:22.313] iteration 464 : model1 loss : 0.459937 model2 loss : 0.434073
[21:27:22.648] iteration 465 : model1 loss : 0.388910 model2 loss : 0.367423
[21:27:22.987] iteration 466 : model1 loss : 0.384313 model2 loss : 0.328120
[21:27:23.322] iteration 467 : model1 loss : 0.432092 model2 loss : 0.384837
[21:27:23.658] iteration 468 : model1 loss : 0.362809 model2 loss : 0.284790
[21:27:23.993] iteration 469 : model1 loss : 0.343141 model2 loss : 0.279241
[21:27:24.329] iteration 470 : model1 loss : 0.334179 model2 loss : 0.273793
[21:27:24.665] iteration 471 : model1 loss : 0.422126 model2 loss : 0.338678
[21:27:25.000] iteration 472 : model1 loss : 0.345043 model2 loss : 0.294898
[21:27:25.339] iteration 473 : model1 loss : 0.351028 model2 loss : 0.328770
[21:27:25.676] iteration 474 : model1 loss : 0.353472 model2 loss : 0.313481
[21:27:26.001] iteration 475 : model1 loss : 0.440915 model2 loss : 0.390077
[21:27:26.327] iteration 476 : model1 loss : 0.394655 model2 loss : 0.347572
[21:27:26.653] iteration 477 : model1 loss : 0.349734 model2 loss : 0.289958
[21:27:26.979] iteration 478 : model1 loss : 0.376328 model2 loss : 0.332068
[21:27:27.305] iteration 479 : model1 loss : 0.429257 model2 loss : 0.379899
[21:27:27.631] iteration 480 : model1 loss : 0.362893 model2 loss : 0.304138
[21:27:27.956] iteration 481 : model1 loss : 0.399095 model2 loss : 0.336154
[21:27:28.281] iteration 482 : model1 loss : 0.424221 model2 loss : 0.380453
[21:27:28.608] iteration 483 : model1 loss : 0.389318 model2 loss : 0.367033
[21:27:28.938] iteration 484 : model1 loss : 0.405906 model2 loss : 0.391325
[21:27:29.264] iteration 485 : model1 loss : 0.392061 model2 loss : 0.340663
[21:27:29.589] iteration 486 : model1 loss : 0.398594 model2 loss : 0.393874
[21:27:29.915] iteration 487 : model1 loss : 0.386156 model2 loss : 0.380090
[21:27:30.241] iteration 488 : model1 loss : 0.376484 model2 loss : 0.370457
[21:27:30.566] iteration 489 : model1 loss : 0.387016 model2 loss : 0.339114
[21:27:30.891] iteration 490 : model1 loss : 0.442077 model2 loss : 0.408146
[21:27:31.215] iteration 491 : model1 loss : 0.364412 model2 loss : 0.308666
[21:27:31.539] iteration 492 : model1 loss : 0.384566 model2 loss : 0.341689
[21:27:31.863] iteration 493 : model1 loss : 0.379686 model2 loss : 0.363391
[21:27:32.189] iteration 494 : model1 loss : 0.344714 model2 loss : 0.264478
[21:27:32.513] iteration 495 : model1 loss : 0.425149 model2 loss : 0.443100
[21:27:32.836] iteration 496 : model1 loss : 0.383040 model2 loss : 0.324036
[21:27:33.158] iteration 497 : model1 loss : 0.432543 model2 loss : 0.364560
[21:27:33.482] iteration 498 : model1 loss : 0.455170 model2 loss : 0.378420
[21:27:33.806] iteration 499 : model1 loss : 0.397035 model2 loss : 0.371713
[21:27:34.129] iteration 500 : model1 loss : 0.443707 model2 loss : 0.425632
[21:27:34.648] iteration 501 : model1 loss : 0.371327 model2 loss : 0.321945
[21:27:34.972] iteration 502 : model1 loss : 0.437147 model2 loss : 0.376156
[21:27:35.296] iteration 503 : model1 loss : 0.378289 model2 loss : 0.277243
[21:27:35.618] iteration 504 : model1 loss : 0.401740 model2 loss : 0.299494
[21:27:35.942] iteration 505 : model1 loss : 0.402851 model2 loss : 0.322623
[21:27:36.267] iteration 506 : model1 loss : 0.375440 model2 loss : 0.311987
[21:27:36.591] iteration 507 : model1 loss : 0.397312 model2 loss : 0.354601
[21:27:36.917] iteration 508 : model1 loss : 0.377495 model2 loss : 0.336562
[21:27:37.242] iteration 509 : model1 loss : 0.379350 model2 loss : 0.328775
[21:27:37.564] iteration 510 : model1 loss : 0.347807 model2 loss : 0.269774
[21:27:37.886] iteration 511 : model1 loss : 0.443027 model2 loss : 0.447449
[21:27:38.210] iteration 512 : model1 loss : 0.425210 model2 loss : 0.387146
[21:27:38.534] iteration 513 : model1 loss : 0.374995 model2 loss : 0.373624
[21:27:38.857] iteration 514 : model1 loss : 0.423016 model2 loss : 0.437079
[21:27:39.181] iteration 515 : model1 loss : 0.405791 model2 loss : 0.379099
[21:27:39.505] iteration 516 : model1 loss : 0.431716 model2 loss : 0.360298
[21:27:39.828] iteration 517 : model1 loss : 0.399358 model2 loss : 0.323767
[21:27:40.152] iteration 518 : model1 loss : 0.362833 model2 loss : 0.308966
[21:27:40.476] iteration 519 : model1 loss : 0.425310 model2 loss : 0.347929
[21:27:40.800] iteration 520 : model1 loss : 0.363940 model2 loss : 0.363246
[21:27:41.125] iteration 521 : model1 loss : 0.382771 model2 loss : 0.384374
[21:27:41.449] iteration 522 : model1 loss : 0.443067 model2 loss : 0.445804
[21:27:41.773] iteration 523 : model1 loss : 0.408722 model2 loss : 0.348519
[21:27:42.098] iteration 524 : model1 loss : 0.390143 model2 loss : 0.398314
[21:27:42.421] iteration 525 : model1 loss : 0.464619 model2 loss : 0.388127
[21:27:42.745] iteration 526 : model1 loss : 0.416376 model2 loss : 0.318242
[21:27:43.068] iteration 527 : model1 loss : 0.360785 model2 loss : 0.346981
[21:27:43.391] iteration 528 : model1 loss : 0.444772 model2 loss : 0.425483
[21:27:43.714] iteration 529 : model1 loss : 0.366134 model2 loss : 0.323169
[21:27:44.038] iteration 530 : model1 loss : 0.390797 model2 loss : 0.380752
[21:27:44.362] iteration 531 : model1 loss : 0.363937 model2 loss : 0.333949
[21:27:44.685] iteration 532 : model1 loss : 0.441894 model2 loss : 0.386386
[21:27:45.009] iteration 533 : model1 loss : 0.469160 model2 loss : 0.392257
[21:27:45.334] iteration 534 : model1 loss : 0.366281 model2 loss : 0.306881
[21:27:45.658] iteration 535 : model1 loss : 0.397788 model2 loss : 0.321264
[21:27:45.982] iteration 536 : model1 loss : 0.360306 model2 loss : 0.322420
[21:27:46.305] iteration 537 : model1 loss : 0.357021 model2 loss : 0.293109
[21:27:46.629] iteration 538 : model1 loss : 0.350155 model2 loss : 0.341076
[21:27:46.954] iteration 539 : model1 loss : 0.362075 model2 loss : 0.291798
[21:27:47.277] iteration 540 : model1 loss : 0.345576 model2 loss : 0.279088
[21:27:47.600] iteration 541 : model1 loss : 0.401375 model2 loss : 0.338407
[21:27:47.923] iteration 542 : model1 loss : 0.489144 model2 loss : 0.337943
[21:27:48.245] iteration 543 : model1 loss : 0.427251 model2 loss : 0.361936
[21:27:48.568] iteration 544 : model1 loss : 0.409781 model2 loss : 0.342585
[21:27:48.890] iteration 545 : model1 loss : 0.373130 model2 loss : 0.319618
[21:27:49.923] iteration 546 : model1 loss : 0.402664 model2 loss : 0.357137
[21:27:50.248] iteration 547 : model1 loss : 0.392670 model2 loss : 0.290811
[21:27:50.572] iteration 548 : model1 loss : 0.359581 model2 loss : 0.323557
[21:27:50.898] iteration 549 : model1 loss : 0.421442 model2 loss : 0.399711
[21:27:51.222] iteration 550 : model1 loss : 0.370453 model2 loss : 0.384228
[21:27:51.803] iteration 551 : model1 loss : 0.382101 model2 loss : 0.364410
[21:27:52.139] iteration 552 : model1 loss : 0.413710 model2 loss : 0.310615
[21:27:52.462] iteration 553 : model1 loss : 0.385816 model2 loss : 0.344397
[21:27:52.788] iteration 554 : model1 loss : 0.398618 model2 loss : 0.328688
[21:27:53.114] iteration 555 : model1 loss : 0.387559 model2 loss : 0.316744
[21:27:53.439] iteration 556 : model1 loss : 0.408532 model2 loss : 0.398290
[21:27:53.764] iteration 557 : model1 loss : 0.385057 model2 loss : 0.357988
[21:27:54.091] iteration 558 : model1 loss : 0.387539 model2 loss : 0.355401
[21:27:54.413] iteration 559 : model1 loss : 0.390183 model2 loss : 0.357426
[21:27:54.739] iteration 560 : model1 loss : 0.406882 model2 loss : 0.373220
[21:27:55.064] iteration 561 : model1 loss : 0.376502 model2 loss : 0.316898
[21:27:55.389] iteration 562 : model1 loss : 0.409290 model2 loss : 0.349426
[21:27:55.720] iteration 563 : model1 loss : 0.414172 model2 loss : 0.393210
[21:27:56.045] iteration 564 : model1 loss : 0.353408 model2 loss : 0.288199
[21:27:56.371] iteration 565 : model1 loss : 0.398937 model2 loss : 0.316367
[21:27:56.698] iteration 566 : model1 loss : 0.398168 model2 loss : 0.341015
[21:27:57.028] iteration 567 : model1 loss : 0.358397 model2 loss : 0.333276
[21:27:57.355] iteration 568 : model1 loss : 0.402151 model2 loss : 0.366314
[21:27:57.681] iteration 569 : model1 loss : 0.362947 model2 loss : 0.293477
[21:27:58.006] iteration 570 : model1 loss : 0.413747 model2 loss : 0.367544
[21:27:58.336] iteration 571 : model1 loss : 0.415217 model2 loss : 0.394649
[21:27:58.663] iteration 572 : model1 loss : 0.401008 model2 loss : 0.372589
[21:27:58.989] iteration 573 : model1 loss : 0.351535 model2 loss : 0.310168
[21:42:07.574] Namespace(root_path='../data/ACDC', exp='ACDC/Semi_Mamba_UNet', model='mambaunet', max_iterations=30000, batch_size=8, deterministic=1, base_lr=0.01, patch_size=[384, 384], seed=1337, num_classes=5, cfg='../code/configs/vmamba_tiny.yaml', opts=None, zip=False, cache_mode='part', resume=None, accumulation_steps=None, use_checkpoint=False, amp_opt_level='O1', tag=None, eval=False, throughput=False, labeled_bs=4, labeled_num=3, ema_decay=0.99, consistency_type='mse', consistency=0.1, consistency_rampup=200.0)
[21:42:08.499] 545 iterations per epoch
[21:42:10.222] iteration 1 : model1 loss : 1.245737 model2 loss : 1.311362
[21:42:10.544] iteration 2 : model1 loss : 1.160307 model2 loss : 1.245026
[21:42:10.866] iteration 3 : model1 loss : 1.014677 model2 loss : 1.250390
[21:42:11.190] iteration 4 : model1 loss : 0.837152 model2 loss : 1.241737
[21:42:11.516] iteration 5 : model1 loss : 0.740759 model2 loss : 1.092095
[21:42:11.839] iteration 6 : model1 loss : 0.578478 model2 loss : 1.071014
[21:42:12.164] iteration 7 : model1 loss : 0.606011 model2 loss : 0.998723
[21:42:12.488] iteration 8 : model1 loss : 0.600387 model2 loss : 0.920862
[21:42:12.813] iteration 9 : model1 loss : 0.472153 model2 loss : 0.858073
[21:42:13.138] iteration 10 : model1 loss : 0.567225 model2 loss : 0.790572
[21:42:13.462] iteration 11 : model1 loss : 0.664350 model2 loss : 0.687612
[21:42:13.785] iteration 12 : model1 loss : 0.562595 model2 loss : 0.604573
[21:42:14.109] iteration 13 : model1 loss : 0.634022 model2 loss : 0.558220
[21:42:14.440] iteration 14 : model1 loss : 0.593753 model2 loss : 0.505933
[21:42:14.766] iteration 15 : model1 loss : 0.580410 model2 loss : 0.488277
[21:42:15.089] iteration 16 : model1 loss : 0.625618 model2 loss : 0.482703
[21:42:15.414] iteration 17 : model1 loss : 0.410527 model2 loss : 0.517728
[21:42:15.733] iteration 18 : model1 loss : 0.529718 model2 loss : 0.442077
[21:42:16.059] iteration 19 : model1 loss : 0.534156 model2 loss : 0.409515
[21:42:16.383] iteration 20 : model1 loss : 0.474397 model2 loss : 0.442243
[21:42:16.707] iteration 21 : model1 loss : 0.473143 model2 loss : 0.412026
[21:42:17.034] iteration 22 : model1 loss : 0.474582 model2 loss : 0.433983
[21:42:17.359] iteration 23 : model1 loss : 0.497951 model2 loss : 0.407886
[21:42:17.684] iteration 24 : model1 loss : 0.583861 model2 loss : 0.449306
[21:42:18.008] iteration 25 : model1 loss : 0.545974 model2 loss : 0.426006
[21:42:18.330] iteration 26 : model1 loss : 0.574854 model2 loss : 0.368253
[21:42:18.656] iteration 27 : model1 loss : 0.498816 model2 loss : 0.377553
[21:42:18.980] iteration 28 : model1 loss : 0.635640 model2 loss : 0.451307
[21:42:19.304] iteration 29 : model1 loss : 0.475240 model2 loss : 0.405149
[21:42:19.628] iteration 30 : model1 loss : 0.529089 model2 loss : 0.408444
[21:42:19.953] iteration 31 : model1 loss : 0.541247 model2 loss : 0.387617
[21:42:20.277] iteration 32 : model1 loss : 0.590953 model2 loss : 0.422236
[21:42:20.598] iteration 33 : model1 loss : 0.565871 model2 loss : 0.414039
[21:42:20.922] iteration 34 : model1 loss : 0.584073 model2 loss : 0.407807
[21:42:21.247] iteration 35 : model1 loss : 0.601810 model2 loss : 0.409323
[21:42:21.572] iteration 36 : model1 loss : 0.548115 model2 loss : 0.427017
[21:42:21.895] iteration 37 : model1 loss : 0.579130 model2 loss : 0.392374
[21:42:22.216] iteration 38 : model1 loss : 0.568678 model2 loss : 0.365548
[21:42:22.540] iteration 39 : model1 loss : 0.600275 model2 loss : 0.451833
[21:42:22.864] iteration 40 : model1 loss : 0.492219 model2 loss : 0.401900
[21:42:23.188] iteration 41 : model1 loss : 0.550820 model2 loss : 0.338802
[21:42:23.513] iteration 42 : model1 loss : 0.477376 model2 loss : 0.411041
[21:42:23.840] iteration 43 : model1 loss : 0.577550 model2 loss : 0.404074
[21:42:24.163] iteration 44 : model1 loss : 0.588889 model2 loss : 0.480598
[21:42:24.483] iteration 45 : model1 loss : 0.497305 model2 loss : 0.375026
[21:42:24.807] iteration 46 : model1 loss : 0.524559 model2 loss : 0.423409
[21:42:25.131] iteration 47 : model1 loss : 0.543727 model2 loss : 0.378618
[21:42:25.453] iteration 48 : model1 loss : 0.583639 model2 loss : 0.439272
[21:42:25.774] iteration 49 : model1 loss : 0.487832 model2 loss : 0.436514
[21:42:26.095] iteration 50 : model1 loss : 0.525021 model2 loss : 0.356078
[21:42:26.637] iteration 51 : model1 loss : 0.519144 model2 loss : 0.402183
[21:42:26.961] iteration 52 : model1 loss : 0.669496 model2 loss : 0.436363
[21:42:27.282] iteration 53 : model1 loss : 0.462139 model2 loss : 0.444055
[21:42:27.607] iteration 54 : model1 loss : 0.517749 model2 loss : 0.370511
[21:42:27.931] iteration 55 : model1 loss : 0.611453 model2 loss : 0.434234
[21:42:28.255] iteration 56 : model1 loss : 0.593310 model2 loss : 0.383175
[21:42:28.580] iteration 57 : model1 loss : 0.602473 model2 loss : 0.415254
[21:42:28.904] iteration 58 : model1 loss : 0.674495 model2 loss : 0.432117
[21:42:29.224] iteration 59 : model1 loss : 0.511444 model2 loss : 0.368900
[21:42:29.544] iteration 60 : model1 loss : 0.572945 model2 loss : 0.444443
[21:42:29.869] iteration 61 : model1 loss : 0.571104 model2 loss : 0.390736
[21:42:30.191] iteration 62 : model1 loss : 0.528525 model2 loss : 0.355491
[21:42:30.512] iteration 63 : model1 loss : 0.584140 model2 loss : 0.390904
[21:42:30.835] iteration 64 : model1 loss : 0.588587 model2 loss : 0.410699
[21:42:31.160] iteration 65 : model1 loss : 0.578273 model2 loss : 0.384018
[21:42:31.483] iteration 66 : model1 loss : 0.557918 model2 loss : 0.399533
[21:42:31.806] iteration 67 : model1 loss : 0.554767 model2 loss : 0.401207
[21:42:32.131] iteration 68 : model1 loss : 0.515124 model2 loss : 0.383556
[21:42:32.457] iteration 69 : model1 loss : 0.530861 model2 loss : 0.419567
[21:42:32.788] iteration 70 : model1 loss : 0.550408 model2 loss : 0.366827
[21:42:33.125] iteration 71 : model1 loss : 0.577442 model2 loss : 0.399225
[21:42:33.464] iteration 72 : model1 loss : 0.574413 model2 loss : 0.370006
[21:42:33.801] iteration 73 : model1 loss : 0.510912 model2 loss : 0.389632
[21:42:34.139] iteration 74 : model1 loss : 0.560223 model2 loss : 0.375280
[21:42:34.478] iteration 75 : model1 loss : 0.628395 model2 loss : 0.451470
[21:42:34.814] iteration 76 : model1 loss : 0.622478 model2 loss : 0.472267
[21:42:35.153] iteration 77 : model1 loss : 0.483805 model2 loss : 0.378978
[21:42:35.489] iteration 78 : model1 loss : 0.527027 model2 loss : 0.348045
[21:42:35.828] iteration 79 : model1 loss : 0.539609 model2 loss : 0.401387
[21:42:36.167] iteration 80 : model1 loss : 0.454599 model2 loss : 0.373923
[21:42:36.503] iteration 81 : model1 loss : 0.512298 model2 loss : 0.349714
[21:42:36.838] iteration 82 : model1 loss : 0.491275 model2 loss : 0.381420
[21:42:37.175] iteration 83 : model1 loss : 0.453934 model2 loss : 0.355568
[21:42:37.510] iteration 84 : model1 loss : 0.470022 model2 loss : 0.367775
[21:42:37.851] iteration 85 : model1 loss : 0.532489 model2 loss : 0.387489
[21:42:38.191] iteration 86 : model1 loss : 0.477909 model2 loss : 0.344967
[21:42:38.527] iteration 87 : model1 loss : 0.509644 model2 loss : 0.422858
[21:42:38.868] iteration 88 : model1 loss : 0.829109 model2 loss : 0.479109
[21:42:39.206] iteration 89 : model1 loss : 0.581072 model2 loss : 0.402463
[21:42:39.544] iteration 90 : model1 loss : 0.520023 model2 loss : 0.387523
[21:42:39.886] iteration 91 : model1 loss : 0.570562 model2 loss : 0.380339
[21:42:40.223] iteration 92 : model1 loss : 0.482097 model2 loss : 0.356326
[21:42:40.560] iteration 93 : model1 loss : 0.421451 model2 loss : 0.440486
[21:42:40.893] iteration 94 : model1 loss : 0.566848 model2 loss : 0.387078
[21:42:41.232] iteration 95 : model1 loss : 0.543245 model2 loss : 0.385312
[21:42:41.571] iteration 96 : model1 loss : 0.551638 model2 loss : 0.364018
[21:42:41.918] iteration 97 : model1 loss : 0.544678 model2 loss : 0.390834
[21:42:42.256] iteration 98 : model1 loss : 0.602380 model2 loss : 0.459340
[21:42:42.600] iteration 99 : model1 loss : 0.520272 model2 loss : 0.336855
[21:42:42.938] iteration 100 : model1 loss : 0.521629 model2 loss : 0.382055
[21:42:43.567] iteration 101 : model1 loss : 0.653372 model2 loss : 0.420555
[21:42:43.906] iteration 102 : model1 loss : 0.591673 model2 loss : 0.401162
[21:42:44.242] iteration 103 : model1 loss : 0.595894 model2 loss : 0.370390
[21:42:44.579] iteration 104 : model1 loss : 0.633457 model2 loss : 0.387763
[21:42:44.911] iteration 105 : model1 loss : 0.525362 model2 loss : 0.346311
[21:42:45.248] iteration 106 : model1 loss : 0.620975 model2 loss : 0.402755
[21:42:45.577] iteration 107 : model1 loss : 0.551986 model2 loss : 0.373248
[21:42:45.915] iteration 108 : model1 loss : 0.564684 model2 loss : 0.348140
[21:42:46.252] iteration 109 : model1 loss : 0.596864 model2 loss : 0.394842
[21:42:46.588] iteration 110 : model1 loss : 0.580864 model2 loss : 0.387002
[21:42:46.925] iteration 111 : model1 loss : 0.614467 model2 loss : 0.453390
[21:42:47.262] iteration 112 : model1 loss : 0.677312 model2 loss : 0.462621
[21:42:47.598] iteration 113 : model1 loss : 0.552754 model2 loss : 0.334571
[21:42:47.935] iteration 114 : model1 loss : 0.545549 model2 loss : 0.380484
[21:42:48.288] iteration 115 : model1 loss : 0.515218 model2 loss : 0.352960
[21:42:48.625] iteration 116 : model1 loss : 0.540634 model2 loss : 0.374828
[21:42:48.961] iteration 117 : model1 loss : 0.643336 model2 loss : 0.487842
[21:42:49.297] iteration 118 : model1 loss : 0.522358 model2 loss : 0.379447
[21:42:49.633] iteration 119 : model1 loss : 0.568222 model2 loss : 0.381058
[21:42:49.969] iteration 120 : model1 loss : 0.557102 model2 loss : 0.340144
[21:42:50.310] iteration 121 : model1 loss : 0.574044 model2 loss : 0.462015
[21:42:50.637] iteration 122 : model1 loss : 0.501837 model2 loss : 0.396577
[21:42:50.969] iteration 123 : model1 loss : 0.479675 model2 loss : 0.336877
[21:42:51.293] iteration 124 : model1 loss : 0.521305 model2 loss : 0.330733
[21:42:51.621] iteration 125 : model1 loss : 0.564041 model2 loss : 0.342502
[21:42:51.950] iteration 126 : model1 loss : 0.543119 model2 loss : 0.333742
[21:42:52.276] iteration 127 : model1 loss : 0.546122 model2 loss : 0.325361
[21:42:52.604] iteration 128 : model1 loss : 0.566746 model2 loss : 0.430098
[21:42:52.939] iteration 129 : model1 loss : 0.634553 model2 loss : 0.416820
[21:42:53.268] iteration 130 : model1 loss : 0.558915 model2 loss : 0.424249
[21:42:53.596] iteration 131 : model1 loss : 0.611910 model2 loss : 0.372998
[21:42:53.924] iteration 132 : model1 loss : 0.615631 model2 loss : 0.379987
[21:42:54.253] iteration 133 : model1 loss : 0.551766 model2 loss : 0.399384
[21:42:54.581] iteration 134 : model1 loss : 0.537555 model2 loss : 0.387434
[21:42:54.908] iteration 135 : model1 loss : 0.484507 model2 loss : 0.398310
[21:42:55.238] iteration 136 : model1 loss : 0.631029 model2 loss : 0.430456
[21:42:55.566] iteration 137 : model1 loss : 0.660416 model2 loss : 0.440658
[21:42:55.895] iteration 138 : model1 loss : 0.644861 model2 loss : 0.373887
[21:42:56.223] iteration 139 : model1 loss : 0.550270 model2 loss : 0.415928
[21:42:56.552] iteration 140 : model1 loss : 0.536132 model2 loss : 0.438351
[21:42:56.881] iteration 141 : model1 loss : 0.524270 model2 loss : 0.348654
[21:42:57.210] iteration 142 : model1 loss : 0.575168 model2 loss : 0.344493
[21:42:57.538] iteration 143 : model1 loss : 0.688868 model2 loss : 0.459211
[21:42:57.867] iteration 144 : model1 loss : 0.565191 model2 loss : 0.322367
[21:42:58.196] iteration 145 : model1 loss : 0.493410 model2 loss : 0.371790
[21:42:58.524] iteration 146 : model1 loss : 0.562000 model2 loss : 0.386107
[21:42:58.852] iteration 147 : model1 loss : 0.543431 model2 loss : 0.408732
[21:42:59.179] iteration 148 : model1 loss : 0.534677 model2 loss : 0.360921
[21:42:59.506] iteration 149 : model1 loss : 0.523004 model2 loss : 0.392571
[21:42:59.833] iteration 150 : model1 loss : 0.572666 model2 loss : 0.424669
[21:43:00.348] iteration 151 : model1 loss : 0.511484 model2 loss : 0.372576
[21:43:00.676] iteration 152 : model1 loss : 0.640951 model2 loss : 0.391788
[21:43:01.002] iteration 153 : model1 loss : 0.498212 model2 loss : 0.327101
[21:43:01.330] iteration 154 : model1 loss : 0.520245 model2 loss : 0.419711
[21:43:01.657] iteration 155 : model1 loss : 0.581955 model2 loss : 0.378856
[21:43:01.983] iteration 156 : model1 loss : 0.500710 model2 loss : 0.410255
[21:43:02.310] iteration 157 : model1 loss : 0.494297 model2 loss : 0.357986
[21:43:02.637] iteration 158 : model1 loss : 0.610195 model2 loss : 0.395639
[21:43:02.963] iteration 159 : model1 loss : 0.553274 model2 loss : 0.364303
[21:43:03.290] iteration 160 : model1 loss : 0.547482 model2 loss : 0.330226
[21:43:03.617] iteration 161 : model1 loss : 0.505611 model2 loss : 0.364333
[21:43:03.944] iteration 162 : model1 loss : 0.501510 model2 loss : 0.381327
[21:43:04.271] iteration 163 : model1 loss : 0.586721 model2 loss : 0.360474
[21:43:04.598] iteration 164 : model1 loss : 0.538519 model2 loss : 0.406749
[21:43:04.924] iteration 165 : model1 loss : 0.513625 model2 loss : 0.344455
[21:43:05.251] iteration 166 : model1 loss : 0.601515 model2 loss : 0.416400
[21:43:05.577] iteration 167 : model1 loss : 0.550413 model2 loss : 0.366385
[21:43:05.904] iteration 168 : model1 loss : 0.506533 model2 loss : 0.376733
[21:43:06.232] iteration 169 : model1 loss : 0.587416 model2 loss : 0.336062
[21:43:06.559] iteration 170 : model1 loss : 0.527067 model2 loss : 0.321203
[21:43:06.886] iteration 171 : model1 loss : 0.600599 model2 loss : 0.460017
[21:43:07.212] iteration 172 : model1 loss : 0.552498 model2 loss : 0.382063
[21:43:07.539] iteration 173 : model1 loss : 0.707693 model2 loss : 0.416045
[21:43:07.864] iteration 174 : model1 loss : 0.491816 model2 loss : 0.342220
[21:43:08.191] iteration 175 : model1 loss : 0.576241 model2 loss : 0.337191
[21:43:08.518] iteration 176 : model1 loss : 0.478092 model2 loss : 0.351543
[21:43:08.844] iteration 177 : model1 loss : 0.601346 model2 loss : 0.389997
[21:43:09.171] iteration 178 : model1 loss : 0.456498 model2 loss : 0.360255
[21:43:09.499] iteration 179 : model1 loss : 0.523205 model2 loss : 0.323567
[21:43:09.825] iteration 180 : model1 loss : 0.610403 model2 loss : 0.379237
[21:43:10.153] iteration 181 : model1 loss : 0.566857 model2 loss : 0.359539
[21:43:10.479] iteration 182 : model1 loss : 0.580964 model2 loss : 0.331451
[21:43:10.808] iteration 183 : model1 loss : 0.538827 model2 loss : 0.345713
[21:43:11.135] iteration 184 : model1 loss : 0.628262 model2 loss : 0.369811
[21:43:11.462] iteration 185 : model1 loss : 0.481169 model2 loss : 0.348915
[21:43:11.789] iteration 186 : model1 loss : 0.555748 model2 loss : 0.339801
[21:43:12.116] iteration 187 : model1 loss : 0.559230 model2 loss : 0.411382
[21:43:12.444] iteration 188 : model1 loss : 0.532072 model2 loss : 0.328708
[21:43:12.769] iteration 189 : model1 loss : 0.557949 model2 loss : 0.419516
[21:43:13.097] iteration 190 : model1 loss : 0.506158 model2 loss : 0.334667
[21:43:13.426] iteration 191 : model1 loss : 0.521470 model2 loss : 0.374549
[21:43:13.752] iteration 192 : model1 loss : 0.523158 model2 loss : 0.459797
[21:43:14.079] iteration 193 : model1 loss : 0.505358 model2 loss : 0.365083
[21:43:14.406] iteration 194 : model1 loss : 0.563449 model2 loss : 0.348342
[21:43:14.734] iteration 195 : model1 loss : 0.663496 model2 loss : 0.451602
[21:43:15.061] iteration 196 : model1 loss : 0.487363 model2 loss : 0.352701
[21:43:15.388] iteration 197 : model1 loss : 0.607055 model2 loss : 0.384869
[21:43:15.715] iteration 198 : model1 loss : 0.578419 model2 loss : 0.421097
[21:43:16.044] iteration 199 : model1 loss : 0.507234 model2 loss : 0.413956
[21:43:16.371] iteration 200 : model1 loss : 0.468018 model2 loss : 0.308967
[21:43:16.919] iteration 201 : model1 loss : 0.540653 model2 loss : 0.424781
[21:43:17.245] iteration 202 : model1 loss : 0.487299 model2 loss : 0.400055
[21:43:17.573] iteration 203 : model1 loss : 0.540609 model2 loss : 0.350712
[21:43:17.900] iteration 204 : model1 loss : 0.463055 model2 loss : 0.372656
[21:43:18.226] iteration 205 : model1 loss : 0.508546 model2 loss : 0.385797
[21:43:18.555] iteration 206 : model1 loss : 0.417271 model2 loss : 0.371373
[21:43:18.885] iteration 207 : model1 loss : 0.489992 model2 loss : 0.339549
[21:43:19.212] iteration 208 : model1 loss : 0.468865 model2 loss : 0.359823
[21:43:19.540] iteration 209 : model1 loss : 0.421333 model2 loss : 0.318732
[21:43:19.868] iteration 210 : model1 loss : 0.517289 model2 loss : 0.405041
[21:43:20.195] iteration 211 : model1 loss : 0.457424 model2 loss : 0.363857
[21:43:20.523] iteration 212 : model1 loss : 0.433582 model2 loss : 0.326971
[21:43:20.851] iteration 213 : model1 loss : 0.492412 model2 loss : 0.356700
[21:43:21.180] iteration 214 : model1 loss : 0.455248 model2 loss : 0.357645
[21:43:21.508] iteration 215 : model1 loss : 0.436547 model2 loss : 0.347079
[21:43:21.836] iteration 216 : model1 loss : 0.443140 model2 loss : 0.379666
[21:43:22.165] iteration 217 : model1 loss : 0.440636 model2 loss : 0.331807
[21:43:22.495] iteration 218 : model1 loss : 0.429552 model2 loss : 0.372095
[21:43:22.822] iteration 219 : model1 loss : 0.554409 model2 loss : 0.416173
[21:43:23.150] iteration 220 : model1 loss : 0.454684 model2 loss : 0.376105
[21:43:23.478] iteration 221 : model1 loss : 0.440260 model2 loss : 0.356144
[21:43:23.806] iteration 222 : model1 loss : 0.402063 model2 loss : 0.364125
[21:43:24.133] iteration 223 : model1 loss : 0.433233 model2 loss : 0.339880
[21:43:24.460] iteration 224 : model1 loss : 0.475856 model2 loss : 0.427536
[21:43:24.786] iteration 225 : model1 loss : 0.440154 model2 loss : 0.324310
[21:43:25.114] iteration 226 : model1 loss : 0.419414 model2 loss : 0.336985
[21:43:25.442] iteration 227 : model1 loss : 0.479983 model2 loss : 0.425809
[21:43:25.767] iteration 228 : model1 loss : 0.420330 model2 loss : 0.355756
[21:43:26.094] iteration 229 : model1 loss : 0.473512 model2 loss : 0.404634
[21:43:26.422] iteration 230 : model1 loss : 0.442092 model2 loss : 0.344167
[21:43:26.748] iteration 231 : model1 loss : 0.411151 model2 loss : 0.365559
[21:43:27.076] iteration 232 : model1 loss : 0.401550 model2 loss : 0.319649
[21:43:27.403] iteration 233 : model1 loss : 0.472368 model2 loss : 0.389760
[21:43:27.729] iteration 234 : model1 loss : 0.412747 model2 loss : 0.294944
[21:43:28.060] iteration 235 : model1 loss : 0.400542 model2 loss : 0.367195
[21:43:28.387] iteration 236 : model1 loss : 0.414565 model2 loss : 0.379593
[21:43:28.715] iteration 237 : model1 loss : 0.448724 model2 loss : 0.364299
[21:43:29.041] iteration 238 : model1 loss : 0.442308 model2 loss : 0.341151
[21:43:29.370] iteration 239 : model1 loss : 0.454764 model2 loss : 0.404300
[21:43:29.698] iteration 240 : model1 loss : 0.387928 model2 loss : 0.328069
[21:43:30.026] iteration 241 : model1 loss : 0.480029 model2 loss : 0.373680
[21:43:30.360] iteration 242 : model1 loss : 0.453282 model2 loss : 0.386484
[21:43:30.689] iteration 243 : model1 loss : 0.404618 model2 loss : 0.323786
[21:43:31.017] iteration 244 : model1 loss : 0.428015 model2 loss : 0.323542
[21:43:31.345] iteration 245 : model1 loss : 0.405004 model2 loss : 0.298573
[21:43:31.672] iteration 246 : model1 loss : 0.465650 model2 loss : 0.384380
[21:43:31.998] iteration 247 : model1 loss : 0.495945 model2 loss : 0.410493
[21:43:32.324] iteration 248 : model1 loss : 0.416224 model2 loss : 0.326629
[21:43:32.651] iteration 249 : model1 loss : 0.380324 model2 loss : 0.321078
[21:43:32.979] iteration 250 : model1 loss : 0.469112 model2 loss : 0.412482
[21:43:33.539] iteration 251 : model1 loss : 0.459935 model2 loss : 0.396863
[21:43:33.866] iteration 252 : model1 loss : 0.476596 model2 loss : 0.387651
[21:43:34.192] iteration 253 : model1 loss : 0.416070 model2 loss : 0.358941
[21:43:34.519] iteration 254 : model1 loss : 0.447536 model2 loss : 0.385609
[21:43:34.846] iteration 255 : model1 loss : 0.423466 model2 loss : 0.315454
[21:43:35.173] iteration 256 : model1 loss : 0.432799 model2 loss : 0.361766
[21:43:35.500] iteration 257 : model1 loss : 0.442108 model2 loss : 0.392727
[21:43:35.827] iteration 258 : model1 loss : 0.409214 model2 loss : 0.363422
[21:43:36.154] iteration 259 : model1 loss : 0.423257 model2 loss : 0.362375
[21:43:36.481] iteration 260 : model1 loss : 0.471246 model2 loss : 0.395415
[21:43:36.808] iteration 261 : model1 loss : 0.427145 model2 loss : 0.379175
[21:43:37.136] iteration 262 : model1 loss : 0.408506 model2 loss : 0.336776
[21:43:37.470] iteration 263 : model1 loss : 0.427139 model2 loss : 0.347493
[21:43:37.798] iteration 264 : model1 loss : 0.379326 model2 loss : 0.324405
[21:43:38.125] iteration 265 : model1 loss : 0.396687 model2 loss : 0.307739
[21:43:38.454] iteration 266 : model1 loss : 0.445756 model2 loss : 0.397875
[21:43:38.783] iteration 267 : model1 loss : 0.418688 model2 loss : 0.410582
[21:43:39.110] iteration 268 : model1 loss : 0.385778 model2 loss : 0.361661
[21:43:39.435] iteration 269 : model1 loss : 0.404503 model2 loss : 0.310049
[21:43:39.764] iteration 270 : model1 loss : 0.417496 model2 loss : 0.333854
[21:43:40.092] iteration 271 : model1 loss : 0.422793 model2 loss : 0.380527
[21:43:40.419] iteration 272 : model1 loss : 0.397741 model2 loss : 0.324275
[21:43:40.746] iteration 273 : model1 loss : 0.443957 model2 loss : 0.398283
[21:43:41.072] iteration 274 : model1 loss : 0.364348 model2 loss : 0.304848
[21:43:41.400] iteration 275 : model1 loss : 0.385053 model2 loss : 0.307996
[21:43:41.727] iteration 276 : model1 loss : 0.383664 model2 loss : 0.290782
[21:43:42.054] iteration 277 : model1 loss : 0.414515 model2 loss : 0.365318
[21:43:42.380] iteration 278 : model1 loss : 0.403108 model2 loss : 0.306070
[21:43:42.707] iteration 279 : model1 loss : 0.415916 model2 loss : 0.340836
[21:43:43.034] iteration 280 : model1 loss : 0.413605 model2 loss : 0.382485
[21:43:43.361] iteration 281 : model1 loss : 0.419912 model2 loss : 0.326373
[21:43:43.689] iteration 282 : model1 loss : 0.390076 model2 loss : 0.339961
[21:43:44.017] iteration 283 : model1 loss : 0.528596 model2 loss : 0.463937
[21:43:44.344] iteration 284 : model1 loss : 0.383586 model2 loss : 0.315844
[21:43:44.671] iteration 285 : model1 loss : 0.399015 model2 loss : 0.328157
[21:43:44.998] iteration 286 : model1 loss : 0.406448 model2 loss : 0.341271
[21:43:45.326] iteration 287 : model1 loss : 0.432469 model2 loss : 0.386698
[21:43:45.655] iteration 288 : model1 loss : 0.421070 model2 loss : 0.349546
[21:43:45.982] iteration 289 : model1 loss : 0.412823 model2 loss : 0.347921
[21:43:46.311] iteration 290 : model1 loss : 0.410449 model2 loss : 0.311880
[21:43:46.640] iteration 291 : model1 loss : 0.388384 model2 loss : 0.347972
[21:43:46.970] iteration 292 : model1 loss : 0.452206 model2 loss : 0.370882
[21:43:47.298] iteration 293 : model1 loss : 0.571033 model2 loss : 0.470644
[21:43:47.626] iteration 294 : model1 loss : 0.389054 model2 loss : 0.335492
[21:43:47.955] iteration 295 : model1 loss : 0.455968 model2 loss : 0.423667
[21:43:48.283] iteration 296 : model1 loss : 0.432951 model2 loss : 0.447337
[21:43:48.611] iteration 297 : model1 loss : 0.483587 model2 loss : 0.462981
[21:43:48.937] iteration 298 : model1 loss : 0.371193 model2 loss : 0.378292
[21:43:49.266] iteration 299 : model1 loss : 0.417526 model2 loss : 0.329188
[21:43:49.592] iteration 300 : model1 loss : 0.389990 model2 loss : 0.279422
[21:43:50.131] iteration 301 : model1 loss : 0.366862 model2 loss : 0.336455
[21:43:50.459] iteration 302 : model1 loss : 0.430004 model2 loss : 0.365215
[21:43:50.786] iteration 303 : model1 loss : 0.459658 model2 loss : 0.420977
[21:43:51.114] iteration 304 : model1 loss : 0.433728 model2 loss : 0.443875
[21:43:51.442] iteration 305 : model1 loss : 0.438398 model2 loss : 0.404742
[21:43:51.769] iteration 306 : model1 loss : 0.416553 model2 loss : 0.322960
[21:43:52.097] iteration 307 : model1 loss : 0.431528 model2 loss : 0.351422
[21:43:52.423] iteration 308 : model1 loss : 0.391254 model2 loss : 0.358755
[21:43:52.751] iteration 309 : model1 loss : 0.455081 model2 loss : 0.371560
[21:43:53.078] iteration 310 : model1 loss : 0.423492 model2 loss : 0.371541
[21:43:53.405] iteration 311 : model1 loss : 0.396861 model2 loss : 0.350993
[21:43:53.732] iteration 312 : model1 loss : 0.405733 model2 loss : 0.338342
[21:43:54.060] iteration 313 : model1 loss : 0.369192 model2 loss : 0.314557
[21:43:54.388] iteration 314 : model1 loss : 0.372719 model2 loss : 0.354298
[21:43:54.716] iteration 315 : model1 loss : 0.527105 model2 loss : 0.413239
[21:43:55.042] iteration 316 : model1 loss : 0.403822 model2 loss : 0.347405
[21:43:55.370] iteration 317 : model1 loss : 0.453153 model2 loss : 0.396027
[21:43:55.698] iteration 318 : model1 loss : 0.529959 model2 loss : 0.447518
[21:43:56.026] iteration 319 : model1 loss : 0.455989 model2 loss : 0.351667
[21:43:56.355] iteration 320 : model1 loss : 0.438154 model2 loss : 0.372356
[21:43:56.684] iteration 321 : model1 loss : 0.391418 model2 loss : 0.362428
[21:43:57.013] iteration 322 : model1 loss : 0.406901 model2 loss : 0.359211
[21:43:57.341] iteration 323 : model1 loss : 0.403835 model2 loss : 0.319640
[21:43:57.670] iteration 324 : model1 loss : 0.445590 model2 loss : 0.434902
[21:43:57.997] iteration 325 : model1 loss : 0.391516 model2 loss : 0.344520
[21:43:58.324] iteration 326 : model1 loss : 0.396072 model2 loss : 0.326945
[21:43:58.651] iteration 327 : model1 loss : 0.433946 model2 loss : 0.401113
[21:43:58.978] iteration 328 : model1 loss : 0.402018 model2 loss : 0.376838
[21:43:59.305] iteration 329 : model1 loss : 0.406513 model2 loss : 0.353488
[21:43:59.631] iteration 330 : model1 loss : 0.371253 model2 loss : 0.323772
[21:43:59.959] iteration 331 : model1 loss : 0.397214 model2 loss : 0.297020
[21:44:00.287] iteration 332 : model1 loss : 0.361080 model2 loss : 0.290452
[21:44:00.611] iteration 333 : model1 loss : 0.431774 model2 loss : 0.366461
[21:44:00.938] iteration 334 : model1 loss : 0.419309 model2 loss : 0.390288
[21:44:01.265] iteration 335 : model1 loss : 0.368748 model2 loss : 0.281554
[21:44:01.593] iteration 336 : model1 loss : 0.371697 model2 loss : 0.294230
[21:44:01.921] iteration 337 : model1 loss : 0.391765 model2 loss : 0.359408
[21:44:02.247] iteration 338 : model1 loss : 0.423087 model2 loss : 0.379800
[21:44:02.574] iteration 339 : model1 loss : 0.400578 model2 loss : 0.377052
[21:44:02.901] iteration 340 : model1 loss : 0.414212 model2 loss : 0.380524
[21:44:03.228] iteration 341 : model1 loss : 0.364915 model2 loss : 0.290278
[21:44:03.555] iteration 342 : model1 loss : 0.410163 model2 loss : 0.330608
[21:44:03.883] iteration 343 : model1 loss : 0.448956 model2 loss : 0.392127
[21:44:04.211] iteration 344 : model1 loss : 0.409638 model2 loss : 0.337131
[21:44:04.540] iteration 345 : model1 loss : 0.445384 model2 loss : 0.415707
[21:44:04.868] iteration 346 : model1 loss : 0.429742 model2 loss : 0.404891
[21:44:05.196] iteration 347 : model1 loss : 0.443614 model2 loss : 0.340663
[21:44:05.525] iteration 348 : model1 loss : 0.391730 model2 loss : 0.347299
[21:44:05.854] iteration 349 : model1 loss : 0.377399 model2 loss : 0.307813
[21:44:06.182] iteration 350 : model1 loss : 0.401262 model2 loss : 0.356515
[21:44:06.716] iteration 351 : model1 loss : 0.414186 model2 loss : 0.336638
[21:44:07.043] iteration 352 : model1 loss : 0.399359 model2 loss : 0.332884
[21:44:07.371] iteration 353 : model1 loss : 0.380724 model2 loss : 0.300843
[21:44:07.699] iteration 354 : model1 loss : 0.351352 model2 loss : 0.263532
[21:44:08.026] iteration 355 : model1 loss : 0.411847 model2 loss : 0.370439
[21:44:08.356] iteration 356 : model1 loss : 0.422892 model2 loss : 0.330013
[21:44:08.682] iteration 357 : model1 loss : 0.398051 model2 loss : 0.334133
[21:44:09.009] iteration 358 : model1 loss : 0.431206 model2 loss : 0.413267
[21:44:09.337] iteration 359 : model1 loss : 0.394066 model2 loss : 0.350826
[21:44:09.664] iteration 360 : model1 loss : 0.525389 model2 loss : 0.499886
[21:44:09.992] iteration 361 : model1 loss : 0.450111 model2 loss : 0.440409
[21:44:10.320] iteration 362 : model1 loss : 0.392542 model2 loss : 0.353184
[21:44:10.647] iteration 363 : model1 loss : 0.365524 model2 loss : 0.333729
[21:44:10.975] iteration 364 : model1 loss : 0.419561 model2 loss : 0.352350
[21:44:11.303] iteration 365 : model1 loss : 0.423736 model2 loss : 0.358195
[21:44:11.630] iteration 366 : model1 loss : 0.421789 model2 loss : 0.401700
[21:44:11.958] iteration 367 : model1 loss : 0.410339 model2 loss : 0.356512
[21:44:12.285] iteration 368 : model1 loss : 0.401087 model2 loss : 0.368338
[21:44:12.612] iteration 369 : model1 loss : 0.373293 model2 loss : 0.274761
[21:44:12.940] iteration 370 : model1 loss : 0.397670 model2 loss : 0.332602
[21:44:13.269] iteration 371 : model1 loss : 0.397961 model2 loss : 0.358422
[21:44:13.598] iteration 372 : model1 loss : 0.395095 model2 loss : 0.339311
[21:44:13.931] iteration 373 : model1 loss : 0.369648 model2 loss : 0.312422
[21:44:14.271] iteration 374 : model1 loss : 0.366970 model2 loss : 0.328856
[21:44:14.610] iteration 375 : model1 loss : 0.442476 model2 loss : 0.403984
[21:44:14.949] iteration 376 : model1 loss : 0.438479 model2 loss : 0.398287
[21:44:15.287] iteration 377 : model1 loss : 0.456816 model2 loss : 0.394489
[21:44:15.624] iteration 378 : model1 loss : 0.439192 model2 loss : 0.425793
[21:44:15.963] iteration 379 : model1 loss : 0.403978 model2 loss : 0.366385
[21:44:16.300] iteration 380 : model1 loss : 0.400322 model2 loss : 0.344013
[21:44:16.640] iteration 381 : model1 loss : 0.449890 model2 loss : 0.367806
[21:44:16.978] iteration 382 : model1 loss : 0.447942 model2 loss : 0.363493
[21:44:17.317] iteration 383 : model1 loss : 0.413524 model2 loss : 0.387955
[21:44:17.654] iteration 384 : model1 loss : 0.376928 model2 loss : 0.345634
[21:44:17.992] iteration 385 : model1 loss : 0.424956 model2 loss : 0.416648
[21:44:18.331] iteration 386 : model1 loss : 0.384512 model2 loss : 0.351344
[21:44:18.675] iteration 387 : model1 loss : 0.386381 model2 loss : 0.325159
[21:44:19.018] iteration 388 : model1 loss : 0.402053 model2 loss : 0.347616
[21:44:19.355] iteration 389 : model1 loss : 0.368730 model2 loss : 0.278817
[21:44:19.693] iteration 390 : model1 loss : 0.384361 model2 loss : 0.364956
[21:44:20.037] iteration 391 : model1 loss : 0.406895 model2 loss : 0.325847
[21:44:20.375] iteration 392 : model1 loss : 0.387430 model2 loss : 0.305623
[21:44:20.704] iteration 393 : model1 loss : 0.427842 model2 loss : 0.350689
[21:44:21.034] iteration 394 : model1 loss : 0.398671 model2 loss : 0.353392
[21:44:21.362] iteration 395 : model1 loss : 0.436320 model2 loss : 0.362760
[21:44:21.691] iteration 396 : model1 loss : 0.402905 model2 loss : 0.340431
[21:44:22.021] iteration 397 : model1 loss : 0.397290 model2 loss : 0.320825
[21:44:22.351] iteration 398 : model1 loss : 0.492560 model2 loss : 0.452245
[21:44:22.680] iteration 399 : model1 loss : 0.423643 model2 loss : 0.353861
[21:44:23.016] iteration 400 : model1 loss : 0.392615 model2 loss : 0.344013
[21:44:23.567] iteration 401 : model1 loss : 0.444367 model2 loss : 0.413490
[21:44:23.902] iteration 402 : model1 loss : 0.411503 model2 loss : 0.333084
[21:44:24.231] iteration 403 : model1 loss : 0.428598 model2 loss : 0.368437
[21:44:24.560] iteration 404 : model1 loss : 0.403006 model2 loss : 0.303434
[21:44:24.889] iteration 405 : model1 loss : 0.475853 model2 loss : 0.385751
[21:44:25.218] iteration 406 : model1 loss : 0.362995 model2 loss : 0.303561
[21:44:25.547] iteration 407 : model1 loss : 0.354846 model2 loss : 0.326112
[21:44:25.875] iteration 408 : model1 loss : 0.374987 model2 loss : 0.307441
[21:44:26.206] iteration 409 : model1 loss : 0.402034 model2 loss : 0.337722
[21:44:26.535] iteration 410 : model1 loss : 0.378960 model2 loss : 0.378189
[21:44:26.864] iteration 411 : model1 loss : 0.388502 model2 loss : 0.381268
[21:44:27.193] iteration 412 : model1 loss : 0.438186 model2 loss : 0.384515
[21:44:27.522] iteration 413 : model1 loss : 0.416063 model2 loss : 0.304228
[21:44:27.850] iteration 414 : model1 loss : 0.448630 model2 loss : 0.403985
[21:44:28.178] iteration 415 : model1 loss : 0.403468 model2 loss : 0.331029
[21:44:28.507] iteration 416 : model1 loss : 0.405906 model2 loss : 0.325661
[21:44:28.839] iteration 417 : model1 loss : 0.472086 model2 loss : 0.431300
[21:44:29.172] iteration 418 : model1 loss : 0.364988 model2 loss : 0.316034
[21:44:29.502] iteration 419 : model1 loss : 0.349533 model2 loss : 0.295743
[21:44:29.832] iteration 420 : model1 loss : 0.385685 model2 loss : 0.384616
[21:44:30.160] iteration 421 : model1 loss : 0.439343 model2 loss : 0.355972
[21:44:30.489] iteration 422 : model1 loss : 0.395025 model2 loss : 0.369164
[21:44:30.820] iteration 423 : model1 loss : 0.390928 model2 loss : 0.319258
[21:44:31.150] iteration 424 : model1 loss : 0.409753 model2 loss : 0.361157
[21:44:31.482] iteration 425 : model1 loss : 0.409052 model2 loss : 0.359427
[21:44:31.828] iteration 426 : model1 loss : 0.403930 model2 loss : 0.375844
[21:44:32.171] iteration 427 : model1 loss : 0.374880 model2 loss : 0.298572
[21:44:32.514] iteration 428 : model1 loss : 0.387320 model2 loss : 0.336006
[21:44:32.854] iteration 429 : model1 loss : 0.431607 model2 loss : 0.358873
[21:44:33.194] iteration 430 : model1 loss : 0.369595 model2 loss : 0.303375
[21:44:33.533] iteration 431 : model1 loss : 0.417143 model2 loss : 0.368962
[21:44:33.873] iteration 432 : model1 loss : 0.350413 model2 loss : 0.305031
[21:44:34.211] iteration 433 : model1 loss : 0.364811 model2 loss : 0.333618
[21:44:34.551] iteration 434 : model1 loss : 0.389273 model2 loss : 0.341019
[21:44:34.928] iteration 435 : model1 loss : 0.375859 model2 loss : 0.303009
[21:44:35.269] iteration 436 : model1 loss : 0.409513 model2 loss : 0.346704
[21:44:35.615] iteration 437 : model1 loss : 0.357343 model2 loss : 0.314314
[21:44:35.954] iteration 438 : model1 loss : 0.416386 model2 loss : 0.380782
[21:44:36.291] iteration 439 : model1 loss : 0.469456 model2 loss : 0.394935
[21:44:36.625] iteration 440 : model1 loss : 0.386989 model2 loss : 0.347978
[21:44:36.964] iteration 441 : model1 loss : 0.417069 model2 loss : 0.350806
[21:44:37.302] iteration 442 : model1 loss : 0.409261 model2 loss : 0.366023
[21:44:37.640] iteration 443 : model1 loss : 0.428865 model2 loss : 0.354109
[21:44:37.976] iteration 444 : model1 loss : 0.410984 model2 loss : 0.431123
[21:44:38.314] iteration 445 : model1 loss : 0.367479 model2 loss : 0.282670
[21:44:38.652] iteration 446 : model1 loss : 0.377435 model2 loss : 0.346391
[21:44:38.990] iteration 447 : model1 loss : 0.350815 model2 loss : 0.300075
[21:44:39.332] iteration 448 : model1 loss : 0.336422 model2 loss : 0.267328
[21:44:39.663] iteration 449 : model1 loss : 0.384450 model2 loss : 0.304405
[21:44:39.996] iteration 450 : model1 loss : 0.416180 model2 loss : 0.402807
[21:44:40.580] iteration 451 : model1 loss : 0.376627 model2 loss : 0.322456
[21:44:40.910] iteration 452 : model1 loss : 0.406835 model2 loss : 0.341452
[21:44:41.238] iteration 453 : model1 loss : 0.406456 model2 loss : 0.376943
[21:44:41.566] iteration 454 : model1 loss : 0.424727 model2 loss : 0.374908
[21:44:41.896] iteration 455 : model1 loss : 0.340827 model2 loss : 0.339812
[21:44:42.229] iteration 456 : model1 loss : 0.374696 model2 loss : 0.340038
[21:44:42.566] iteration 457 : model1 loss : 0.379633 model2 loss : 0.316816
[21:44:42.911] iteration 458 : model1 loss : 0.379491 model2 loss : 0.350641
[21:44:43.243] iteration 459 : model1 loss : 0.399607 model2 loss : 0.318698
[21:44:43.584] iteration 460 : model1 loss : 0.409610 model2 loss : 0.358424
[21:44:43.925] iteration 461 : model1 loss : 0.358588 model2 loss : 0.327389
[21:44:44.262] iteration 462 : model1 loss : 0.435378 model2 loss : 0.322648
[21:44:44.595] iteration 463 : model1 loss : 0.404570 model2 loss : 0.353420
[21:44:44.934] iteration 464 : model1 loss : 0.464473 model2 loss : 0.419382
[21:44:45.272] iteration 465 : model1 loss : 0.386419 model2 loss : 0.352128
[21:44:45.610] iteration 466 : model1 loss : 0.384378 model2 loss : 0.325490
[21:44:45.947] iteration 467 : model1 loss : 0.431206 model2 loss : 0.387984
[21:44:46.274] iteration 468 : model1 loss : 0.357270 model2 loss : 0.290029
[21:44:46.602] iteration 469 : model1 loss : 0.337282 model2 loss : 0.275587
[21:44:46.930] iteration 470 : model1 loss : 0.329216 model2 loss : 0.270382
[21:44:47.259] iteration 471 : model1 loss : 0.422721 model2 loss : 0.352528
[21:44:47.591] iteration 472 : model1 loss : 0.343725 model2 loss : 0.298221
[21:44:47.920] iteration 473 : model1 loss : 0.347546 model2 loss : 0.365735
[21:44:48.248] iteration 474 : model1 loss : 0.351115 model2 loss : 0.296127
[21:44:48.577] iteration 475 : model1 loss : 0.438124 model2 loss : 0.386591
[21:44:48.907] iteration 476 : model1 loss : 0.392364 model2 loss : 0.349724
[21:44:49.237] iteration 477 : model1 loss : 0.346787 model2 loss : 0.290829
[21:44:49.567] iteration 478 : model1 loss : 0.368592 model2 loss : 0.333642
[21:44:49.895] iteration 479 : model1 loss : 0.436157 model2 loss : 0.374337
[21:44:50.222] iteration 480 : model1 loss : 0.356235 model2 loss : 0.307799
[21:44:50.547] iteration 481 : model1 loss : 0.399161 model2 loss : 0.338244
[21:44:50.872] iteration 482 : model1 loss : 0.423044 model2 loss : 0.402890
[21:44:51.196] iteration 483 : model1 loss : 0.389949 model2 loss : 0.380351
[21:44:51.519] iteration 484 : model1 loss : 0.408827 model2 loss : 0.406629
[21:44:51.843] iteration 485 : model1 loss : 0.389323 model2 loss : 0.351996
[21:44:52.167] iteration 486 : model1 loss : 0.393766 model2 loss : 0.350163
[21:44:52.490] iteration 487 : model1 loss : 0.386515 model2 loss : 0.380985
[21:44:52.819] iteration 488 : model1 loss : 0.375133 model2 loss : 0.354168
[21:44:53.147] iteration 489 : model1 loss : 0.390836 model2 loss : 0.341919
[21:44:53.476] iteration 490 : model1 loss : 0.439357 model2 loss : 0.395887
[21:44:53.804] iteration 491 : model1 loss : 0.362783 model2 loss : 0.319118
[21:44:54.133] iteration 492 : model1 loss : 0.379680 model2 loss : 0.342048
[21:44:54.460] iteration 493 : model1 loss : 0.380157 model2 loss : 0.349352
[21:44:54.788] iteration 494 : model1 loss : 0.343429 model2 loss : 0.263301
[21:44:55.120] iteration 495 : model1 loss : 0.426082 model2 loss : 0.425534
[21:44:55.450] iteration 496 : model1 loss : 0.380828 model2 loss : 0.321976
[21:44:55.777] iteration 497 : model1 loss : 0.431248 model2 loss : 0.363082
[21:44:56.105] iteration 498 : model1 loss : 0.455050 model2 loss : 0.378637
[21:44:56.432] iteration 499 : model1 loss : 0.398957 model2 loss : 0.375372
[21:44:56.761] iteration 500 : model1 loss : 0.440412 model2 loss : 0.428508
[21:44:57.279] iteration 501 : model1 loss : 0.364511 model2 loss : 0.322245
[21:44:57.607] iteration 502 : model1 loss : 0.428198 model2 loss : 0.369449
[21:44:57.936] iteration 503 : model1 loss : 0.372429 model2 loss : 0.284886
[21:44:58.265] iteration 504 : model1 loss : 0.397838 model2 loss : 0.288442
[21:44:58.595] iteration 505 : model1 loss : 0.411145 model2 loss : 0.334203
[21:44:58.923] iteration 506 : model1 loss : 0.367123 model2 loss : 0.301736
[21:44:59.253] iteration 507 : model1 loss : 0.392706 model2 loss : 0.346548
[21:44:59.580] iteration 508 : model1 loss : 0.374580 model2 loss : 0.317340
[21:44:59.908] iteration 509 : model1 loss : 0.375931 model2 loss : 0.328829
[21:45:00.238] iteration 510 : model1 loss : 0.344125 model2 loss : 0.285126
[21:45:00.577] iteration 511 : model1 loss : 0.442548 model2 loss : 0.447530
[21:45:00.917] iteration 512 : model1 loss : 0.422871 model2 loss : 0.373809
[21:45:01.257] iteration 513 : model1 loss : 0.372472 model2 loss : 0.374728
[21:45:01.597] iteration 514 : model1 loss : 0.424749 model2 loss : 0.444415
[21:45:01.936] iteration 515 : model1 loss : 0.401169 model2 loss : 0.369971
[21:45:02.270] iteration 516 : model1 loss : 0.428565 model2 loss : 0.368550
[21:45:02.607] iteration 517 : model1 loss : 0.396079 model2 loss : 0.306394
[21:45:02.943] iteration 518 : model1 loss : 0.358145 model2 loss : 0.306256
[21:45:03.283] iteration 519 : model1 loss : 0.423592 model2 loss : 0.345545
[21:45:03.628] iteration 520 : model1 loss : 0.361511 model2 loss : 0.363040
[21:45:03.975] iteration 521 : model1 loss : 0.380237 model2 loss : 0.379185
[21:45:04.312] iteration 522 : model1 loss : 0.439469 model2 loss : 0.437653
[21:45:04.656] iteration 523 : model1 loss : 0.405850 model2 loss : 0.358134
[21:45:05.001] iteration 524 : model1 loss : 0.388013 model2 loss : 0.396390
[21:45:05.339] iteration 525 : model1 loss : 0.455941 model2 loss : 0.417091
[21:45:05.677] iteration 526 : model1 loss : 0.418860 model2 loss : 0.321044
[21:45:06.016] iteration 527 : model1 loss : 0.359478 model2 loss : 0.324363
[21:45:06.354] iteration 528 : model1 loss : 0.445660 model2 loss : 0.429687
[21:45:06.693] iteration 529 : model1 loss : 0.362601 model2 loss : 0.311723
[21:45:07.031] iteration 530 : model1 loss : 0.388521 model2 loss : 0.367399
[21:45:07.368] iteration 531 : model1 loss : 0.362232 model2 loss : 0.315380
[21:45:07.707] iteration 532 : model1 loss : 0.441767 model2 loss : 0.392665
[21:45:08.044] iteration 533 : model1 loss : 0.471198 model2 loss : 0.388914
[21:45:08.382] iteration 534 : model1 loss : 0.372653 model2 loss : 0.321206
[21:45:08.724] iteration 535 : model1 loss : 0.390693 model2 loss : 0.302668
[21:45:09.050] iteration 536 : model1 loss : 0.359316 model2 loss : 0.338573
[21:45:09.380] iteration 537 : model1 loss : 0.353850 model2 loss : 0.289931
[21:45:09.714] iteration 538 : model1 loss : 0.346184 model2 loss : 0.335435
[21:45:10.042] iteration 539 : model1 loss : 0.364027 model2 loss : 0.306707
[21:45:10.370] iteration 540 : model1 loss : 0.344559 model2 loss : 0.280734
[21:45:10.698] iteration 541 : model1 loss : 0.394274 model2 loss : 0.329460
[21:45:11.026] iteration 542 : model1 loss : 0.490316 model2 loss : 0.348201
[21:45:11.355] iteration 543 : model1 loss : 0.424246 model2 loss : 0.361250
[21:45:11.682] iteration 544 : model1 loss : 0.411240 model2 loss : 0.328544
[21:45:12.010] iteration 545 : model1 loss : 0.368291 model2 loss : 0.325719
[21:45:12.967] iteration 546 : model1 loss : 0.394810 model2 loss : 0.354431
[21:45:13.297] iteration 547 : model1 loss : 0.383501 model2 loss : 0.291564
[21:45:13.626] iteration 548 : model1 loss : 0.352956 model2 loss : 0.323007
[21:45:13.956] iteration 549 : model1 loss : 0.418131 model2 loss : 0.397846
[21:45:14.285] iteration 550 : model1 loss : 0.372443 model2 loss : 0.372169
[21:45:14.877] iteration 551 : model1 loss : 0.378650 model2 loss : 0.381284
[21:45:15.207] iteration 552 : model1 loss : 0.410940 model2 loss : 0.299062
[21:45:15.537] iteration 553 : model1 loss : 0.383278 model2 loss : 0.325122
[21:45:15.867] iteration 554 : model1 loss : 0.398157 model2 loss : 0.331881
[21:45:16.200] iteration 555 : model1 loss : 0.384627 model2 loss : 0.326088
[21:45:16.529] iteration 556 : model1 loss : 0.401808 model2 loss : 0.391736
[21:45:16.867] iteration 557 : model1 loss : 0.380559 model2 loss : 0.352627
[21:45:17.205] iteration 558 : model1 loss : 0.382446 model2 loss : 0.335587
[21:45:17.543] iteration 559 : model1 loss : 0.385223 model2 loss : 0.352205
[21:45:17.880] iteration 560 : model1 loss : 0.400053 model2 loss : 0.352211
[21:45:18.218] iteration 561 : model1 loss : 0.372560 model2 loss : 0.322979
[21:45:18.555] iteration 562 : model1 loss : 0.405559 model2 loss : 0.369628
[21:45:18.900] iteration 563 : model1 loss : 0.407463 model2 loss : 0.400591
[21:45:19.238] iteration 564 : model1 loss : 0.348253 model2 loss : 0.291944
[21:45:19.577] iteration 565 : model1 loss : 0.388329 model2 loss : 0.314815
[21:45:19.915] iteration 566 : model1 loss : 0.400409 model2 loss : 0.340485
[21:45:20.255] iteration 567 : model1 loss : 0.354730 model2 loss : 0.337007
[21:45:20.596] iteration 568 : model1 loss : 0.400028 model2 loss : 0.370039
[21:45:20.936] iteration 569 : model1 loss : 0.367211 model2 loss : 0.305069
[21:45:21.282] iteration 570 : model1 loss : 0.407864 model2 loss : 0.368875
[21:45:21.619] iteration 571 : model1 loss : 0.404160 model2 loss : 0.376398
[21:45:21.959] iteration 572 : model1 loss : 0.411921 model2 loss : 0.375179
[21:45:22.301] iteration 573 : model1 loss : 0.351761 model2 loss : 0.308998
[21:45:22.638] iteration 574 : model1 loss : 0.403365 model2 loss : 0.292072
[21:45:22.974] iteration 575 : model1 loss : 0.383279 model2 loss : 0.354579
[21:45:23.312] iteration 576 : model1 loss : 0.408478 model2 loss : 0.340434
[21:45:23.648] iteration 577 : model1 loss : 0.408489 model2 loss : 0.341108
[21:45:23.986] iteration 578 : model1 loss : 0.495645 model2 loss : 0.390237
[21:45:24.323] iteration 579 : model1 loss : 0.383585 model2 loss : 0.287222
[21:45:24.660] iteration 580 : model1 loss : 0.377484 model2 loss : 0.373475
[21:45:24.997] iteration 581 : model1 loss : 0.356069 model2 loss : 0.300986
[21:45:25.335] iteration 582 : model1 loss : 0.451184 model2 loss : 0.421349
[21:45:25.672] iteration 583 : model1 loss : 0.400625 model2 loss : 0.375090
[21:45:26.012] iteration 584 : model1 loss : 0.432693 model2 loss : 0.369354
[21:45:26.349] iteration 585 : model1 loss : 0.359243 model2 loss : 0.307431
[21:45:26.686] iteration 586 : model1 loss : 0.379748 model2 loss : 0.260189
[21:45:27.025] iteration 587 : model1 loss : 0.379738 model2 loss : 0.254183
[21:45:27.362] iteration 588 : model1 loss : 0.415700 model2 loss : 0.285572
[21:45:27.699] iteration 589 : model1 loss : 0.420288 model2 loss : 0.359914
[21:45:28.036] iteration 590 : model1 loss : 0.335487 model2 loss : 0.280327
[21:45:28.372] iteration 591 : model1 loss : 0.373780 model2 loss : 0.312766
[21:45:28.709] iteration 592 : model1 loss : 0.397012 model2 loss : 0.338658
[21:45:29.046] iteration 593 : model1 loss : 0.404317 model2 loss : 0.384416
[21:45:29.382] iteration 594 : model1 loss : 0.345257 model2 loss : 0.285652
[21:45:29.715] iteration 595 : model1 loss : 0.509202 model2 loss : 0.367594
[21:45:30.048] iteration 596 : model1 loss : 0.411254 model2 loss : 0.331977
[21:45:30.384] iteration 597 : model1 loss : 0.323909 model2 loss : 0.286559
[21:45:30.717] iteration 598 : model1 loss : 0.335516 model2 loss : 0.296554
[21:45:31.061] iteration 599 : model1 loss : 0.444630 model2 loss : 0.414804
[21:45:31.395] iteration 600 : model1 loss : 0.381521 model2 loss : 0.306907
[21:45:32.040] iteration 601 : model1 loss : 0.356053 model2 loss : 0.307004
[21:45:32.378] iteration 602 : model1 loss : 0.380350 model2 loss : 0.364601
[21:45:32.714] iteration 603 : model1 loss : 0.374014 model2 loss : 0.298503
[21:45:33.049] iteration 604 : model1 loss : 0.442552 model2 loss : 0.385343
[21:45:33.385] iteration 605 : model1 loss : 0.366888 model2 loss : 0.378966
[21:45:33.724] iteration 606 : model1 loss : 0.405877 model2 loss : 0.403802
[21:45:34.061] iteration 607 : model1 loss : 0.350180 model2 loss : 0.272950
[21:45:34.397] iteration 608 : model1 loss : 0.383871 model2 loss : 0.336010
[21:45:34.733] iteration 609 : model1 loss : 0.353719 model2 loss : 0.266174
[21:45:35.070] iteration 610 : model1 loss : 0.362414 model2 loss : 0.328181
[21:45:35.406] iteration 611 : model1 loss : 0.411828 model2 loss : 0.373997
[21:45:35.741] iteration 612 : model1 loss : 0.400794 model2 loss : 0.371937
[21:45:36.079] iteration 613 : model1 loss : 0.376284 model2 loss : 0.365498
[21:45:36.417] iteration 614 : model1 loss : 0.365193 model2 loss : 0.319970
[21:45:36.747] iteration 615 : model1 loss : 0.398110 model2 loss : 0.338850
[21:45:37.077] iteration 616 : model1 loss : 0.352591 model2 loss : 0.266466
[21:45:37.405] iteration 617 : model1 loss : 0.328547 model2 loss : 0.253243
[21:45:37.734] iteration 618 : model1 loss : 0.369758 model2 loss : 0.301138
[21:45:38.065] iteration 619 : model1 loss : 0.402484 model2 loss : 0.386438
[21:45:38.394] iteration 620 : model1 loss : 0.396451 model2 loss : 0.341789
[21:45:38.734] iteration 621 : model1 loss : 0.375298 model2 loss : 0.332479
[21:45:39.072] iteration 622 : model1 loss : 0.334089 model2 loss : 0.242924
[21:45:39.408] iteration 623 : model1 loss : 0.338094 model2 loss : 0.272732
[21:45:39.742] iteration 624 : model1 loss : 0.404944 model2 loss : 0.338659
[21:45:40.081] iteration 625 : model1 loss : 0.385232 model2 loss : 0.301995
[21:45:40.418] iteration 626 : model1 loss : 0.366801 model2 loss : 0.322080
[21:45:40.756] iteration 627 : model1 loss : 0.371301 model2 loss : 0.317103
[21:45:41.087] iteration 628 : model1 loss : 0.359249 model2 loss : 0.283146
[21:45:41.424] iteration 629 : model1 loss : 0.407935 model2 loss : 0.344997
[21:45:41.761] iteration 630 : model1 loss : 0.376418 model2 loss : 0.313853
[21:45:42.097] iteration 631 : model1 loss : 0.390362 model2 loss : 0.331016
[21:45:42.457] iteration 632 : model1 loss : 0.323165 model2 loss : 0.302319
[21:45:42.795] iteration 633 : model1 loss : 0.363191 model2 loss : 0.246508
[21:45:43.132] iteration 634 : model1 loss : 0.361122 model2 loss : 0.272137
[21:45:43.470] iteration 635 : model1 loss : 0.375245 model2 loss : 0.320118
[21:45:43.834] iteration 636 : model1 loss : 0.369010 model2 loss : 0.297298
[21:45:44.164] iteration 637 : model1 loss : 0.325042 model2 loss : 0.267041
[21:45:44.493] iteration 638 : model1 loss : 0.389584 model2 loss : 0.359568
[21:45:44.822] iteration 639 : model1 loss : 0.395610 model2 loss : 0.334779
[21:45:45.151] iteration 640 : model1 loss : 0.321770 model2 loss : 0.338193
[21:45:45.479] iteration 641 : model1 loss : 0.407095 model2 loss : 0.405238
[21:45:45.809] iteration 642 : model1 loss : 0.386544 model2 loss : 0.289634
[21:45:46.138] iteration 643 : model1 loss : 0.359172 model2 loss : 0.263529
[21:45:46.467] iteration 644 : model1 loss : 0.362096 model2 loss : 0.319026
[21:45:46.795] iteration 645 : model1 loss : 0.483134 model2 loss : 0.428267
[21:45:47.124] iteration 646 : model1 loss : 0.352217 model2 loss : 0.287429
[21:45:47.453] iteration 647 : model1 loss : 0.379829 model2 loss : 0.327832
[21:45:47.782] iteration 648 : model1 loss : 0.319138 model2 loss : 0.245908
[21:45:48.111] iteration 649 : model1 loss : 0.332306 model2 loss : 0.244942
[21:45:48.440] iteration 650 : model1 loss : 0.425734 model2 loss : 0.314868
[21:45:48.982] iteration 651 : model1 loss : 0.419290 model2 loss : 0.433284
[21:45:49.309] iteration 652 : model1 loss : 0.377932 model2 loss : 0.285519
[21:45:49.636] iteration 653 : model1 loss : 0.378982 model2 loss : 0.345977
[21:45:49.963] iteration 654 : model1 loss : 0.362977 model2 loss : 0.356898
[21:45:50.291] iteration 655 : model1 loss : 0.405669 model2 loss : 0.288481
[21:45:50.619] iteration 656 : model1 loss : 0.356345 model2 loss : 0.337484
[21:45:50.947] iteration 657 : model1 loss : 0.377591 model2 loss : 0.310158
[21:45:51.275] iteration 658 : model1 loss : 0.395347 model2 loss : 0.311567
[21:45:51.604] iteration 659 : model1 loss : 0.420435 model2 loss : 0.375022
[21:45:51.932] iteration 660 : model1 loss : 0.394591 model2 loss : 0.399162
[21:45:52.260] iteration 661 : model1 loss : 0.336195 model2 loss : 0.285995
[21:45:52.587] iteration 662 : model1 loss : 0.383135 model2 loss : 0.313364
[21:45:52.915] iteration 663 : model1 loss : 0.394112 model2 loss : 0.266941
[21:45:53.243] iteration 664 : model1 loss : 0.358326 model2 loss : 0.291335
[21:45:53.571] iteration 665 : model1 loss : 0.406079 model2 loss : 0.390015
[21:45:53.898] iteration 666 : model1 loss : 0.352948 model2 loss : 0.278223
[21:45:54.226] iteration 667 : model1 loss : 0.395731 model2 loss : 0.367770
[21:45:54.553] iteration 668 : model1 loss : 0.349254 model2 loss : 0.332292
[21:45:54.882] iteration 669 : model1 loss : 0.352055 model2 loss : 0.278812
[21:45:55.209] iteration 670 : model1 loss : 0.396689 model2 loss : 0.293401
[21:45:55.535] iteration 671 : model1 loss : 0.399266 model2 loss : 0.362137
[21:45:55.863] iteration 672 : model1 loss : 0.430861 model2 loss : 0.389493
[21:45:56.193] iteration 673 : model1 loss : 0.381076 model2 loss : 0.319471
[21:45:56.521] iteration 674 : model1 loss : 0.373032 model2 loss : 0.307519
[21:45:56.847] iteration 675 : model1 loss : 0.385811 model2 loss : 0.369064
[21:45:57.175] iteration 676 : model1 loss : 0.342992 model2 loss : 0.327241
[21:45:57.503] iteration 677 : model1 loss : 0.388674 model2 loss : 0.362819
[21:45:57.830] iteration 678 : model1 loss : 0.420492 model2 loss : 0.326932
[21:45:58.158] iteration 679 : model1 loss : 0.381842 model2 loss : 0.363312
[21:45:58.486] iteration 680 : model1 loss : 0.390711 model2 loss : 0.386538
[21:45:58.813] iteration 681 : model1 loss : 0.337110 model2 loss : 0.330887
[21:45:59.140] iteration 682 : model1 loss : 0.404912 model2 loss : 0.417129
[21:45:59.467] iteration 683 : model1 loss : 0.370918 model2 loss : 0.301110
[21:45:59.794] iteration 684 : model1 loss : 0.348774 model2 loss : 0.370793
[21:46:00.122] iteration 685 : model1 loss : 0.416636 model2 loss : 0.361347
[21:46:00.450] iteration 686 : model1 loss : 0.367897 model2 loss : 0.316884
[21:46:00.778] iteration 687 : model1 loss : 0.349051 model2 loss : 0.297944
[21:46:01.106] iteration 688 : model1 loss : 0.335760 model2 loss : 0.298745
[21:46:01.433] iteration 689 : model1 loss : 0.386562 model2 loss : 0.329235
[21:46:01.760] iteration 690 : model1 loss : 0.389883 model2 loss : 0.331615
[21:46:02.088] iteration 691 : model1 loss : 0.412916 model2 loss : 0.352345
[21:46:02.416] iteration 692 : model1 loss : 0.359698 model2 loss : 0.314170
[21:46:02.743] iteration 693 : model1 loss : 0.347135 model2 loss : 0.265958
[21:46:03.071] iteration 694 : model1 loss : 0.354556 model2 loss : 0.290703
[21:46:03.399] iteration 695 : model1 loss : 0.355749 model2 loss : 0.354406
[21:46:03.727] iteration 696 : model1 loss : 0.379609 model2 loss : 0.286637
[21:46:04.055] iteration 697 : model1 loss : 0.385247 model2 loss : 0.326771
[21:46:04.383] iteration 698 : model1 loss : 0.436196 model2 loss : 0.409824
[21:46:04.711] iteration 699 : model1 loss : 0.334770 model2 loss : 0.292767
[21:46:05.039] iteration 700 : model1 loss : 0.313452 model2 loss : 0.303040
[21:46:05.598] iteration 701 : model1 loss : 0.368169 model2 loss : 0.286710
[21:46:05.926] iteration 702 : model1 loss : 0.340861 model2 loss : 0.289882
[21:46:06.254] iteration 703 : model1 loss : 0.343859 model2 loss : 0.261337
[21:46:06.581] iteration 704 : model1 loss : 0.373506 model2 loss : 0.383552
[21:46:06.907] iteration 705 : model1 loss : 0.364599 model2 loss : 0.341222
[21:46:07.235] iteration 706 : model1 loss : 0.379006 model2 loss : 0.268442
[21:46:07.562] iteration 707 : model1 loss : 0.379572 model2 loss : 0.360010
[21:46:07.892] iteration 708 : model1 loss : 0.402178 model2 loss : 0.336461
[21:46:08.220] iteration 709 : model1 loss : 0.359235 model2 loss : 0.328592
[21:46:08.546] iteration 710 : model1 loss : 0.412156 model2 loss : 0.402992
[21:46:08.874] iteration 711 : model1 loss : 0.318434 model2 loss : 0.266340
[21:46:09.203] iteration 712 : model1 loss : 0.349358 model2 loss : 0.304314
[21:46:09.531] iteration 713 : model1 loss : 0.387823 model2 loss : 0.344972
[21:46:09.858] iteration 714 : model1 loss : 0.371418 model2 loss : 0.391871
[21:46:10.191] iteration 715 : model1 loss : 0.402622 model2 loss : 0.360127
[21:46:10.519] iteration 716 : model1 loss : 0.346209 model2 loss : 0.339211
[21:46:10.846] iteration 717 : model1 loss : 0.361022 model2 loss : 0.322114
[21:46:11.173] iteration 718 : model1 loss : 0.459616 model2 loss : 0.427286
[21:46:11.501] iteration 719 : model1 loss : 0.339774 model2 loss : 0.305193
[21:46:11.830] iteration 720 : model1 loss : 0.346732 model2 loss : 0.286304
[21:46:12.156] iteration 721 : model1 loss : 0.330143 model2 loss : 0.251721
[21:46:12.484] iteration 722 : model1 loss : 0.392268 model2 loss : 0.353818
[21:46:12.812] iteration 723 : model1 loss : 0.378388 model2 loss : 0.375120
[21:46:13.139] iteration 724 : model1 loss : 0.364801 model2 loss : 0.325130
[21:46:13.466] iteration 725 : model1 loss : 0.371360 model2 loss : 0.358663
[21:46:13.794] iteration 726 : model1 loss : 0.338933 model2 loss : 0.301179
[21:46:14.122] iteration 727 : model1 loss : 0.415644 model2 loss : 0.334807
[21:46:14.449] iteration 728 : model1 loss : 0.361900 model2 loss : 0.284175
[21:46:14.777] iteration 729 : model1 loss : 0.328703 model2 loss : 0.288204
[21:46:15.105] iteration 730 : model1 loss : 0.359099 model2 loss : 0.267617
[21:46:15.433] iteration 731 : model1 loss : 0.413157 model2 loss : 0.342173
[21:46:15.761] iteration 732 : model1 loss : 0.381671 model2 loss : 0.279985
[21:46:16.089] iteration 733 : model1 loss : 0.420297 model2 loss : 0.343648
[21:46:16.417] iteration 734 : model1 loss : 0.396701 model2 loss : 0.329283
[21:46:16.746] iteration 735 : model1 loss : 0.387760 model2 loss : 0.295113
[21:46:17.074] iteration 736 : model1 loss : 0.346982 model2 loss : 0.259113
[21:46:17.402] iteration 737 : model1 loss : 0.364688 model2 loss : 0.336446
[21:46:17.730] iteration 738 : model1 loss : 0.380408 model2 loss : 0.271952
[21:46:18.058] iteration 739 : model1 loss : 0.363399 model2 loss : 0.364787
[21:46:18.386] iteration 740 : model1 loss : 0.406590 model2 loss : 0.316121
[21:46:18.714] iteration 741 : model1 loss : 0.391410 model2 loss : 0.371455
[21:46:19.041] iteration 742 : model1 loss : 0.368275 model2 loss : 0.273952
[21:46:19.369] iteration 743 : model1 loss : 0.351030 model2 loss : 0.278039
[21:46:19.696] iteration 744 : model1 loss : 0.365355 model2 loss : 0.232930
[21:46:20.024] iteration 745 : model1 loss : 0.343612 model2 loss : 0.315151
[21:46:20.351] iteration 746 : model1 loss : 0.345914 model2 loss : 0.325444
[21:46:20.680] iteration 747 : model1 loss : 0.411393 model2 loss : 0.360852
[21:46:21.009] iteration 748 : model1 loss : 0.356649 model2 loss : 0.284727
[21:46:21.337] iteration 749 : model1 loss : 0.454251 model2 loss : 0.432894
[21:46:21.665] iteration 750 : model1 loss : 0.352876 model2 loss : 0.255838
[21:46:22.200] iteration 751 : model1 loss : 0.455274 model2 loss : 0.459157
[21:46:22.528] iteration 752 : model1 loss : 0.335230 model2 loss : 0.253000
[21:46:22.855] iteration 753 : model1 loss : 0.422915 model2 loss : 0.410201
[21:46:23.182] iteration 754 : model1 loss : 0.410612 model2 loss : 0.424312
[21:46:23.511] iteration 755 : model1 loss : 0.351882 model2 loss : 0.328530
[21:46:23.837] iteration 756 : model1 loss : 0.346398 model2 loss : 0.317621
[21:46:24.165] iteration 757 : model1 loss : 0.421818 model2 loss : 0.384276
[21:46:24.492] iteration 758 : model1 loss : 0.405975 model2 loss : 0.442445
[21:46:24.820] iteration 759 : model1 loss : 0.362993 model2 loss : 0.301039
[21:46:25.146] iteration 760 : model1 loss : 0.328443 model2 loss : 0.298921
[21:46:25.475] iteration 761 : model1 loss : 0.370404 model2 loss : 0.387318
[21:46:25.802] iteration 762 : model1 loss : 0.444397 model2 loss : 0.417316
[21:46:26.130] iteration 763 : model1 loss : 0.386937 model2 loss : 0.352844
[21:46:26.457] iteration 764 : model1 loss : 0.530253 model2 loss : 0.463957
[21:46:26.784] iteration 765 : model1 loss : 0.359657 model2 loss : 0.302872
[21:46:27.112] iteration 766 : model1 loss : 0.403362 model2 loss : 0.381791
[21:46:27.440] iteration 767 : model1 loss : 0.343324 model2 loss : 0.299597
[21:46:27.767] iteration 768 : model1 loss : 0.426867 model2 loss : 0.355703
[21:46:28.095] iteration 769 : model1 loss : 0.403499 model2 loss : 0.341055
[21:46:28.423] iteration 770 : model1 loss : 0.415036 model2 loss : 0.293184
[21:46:28.750] iteration 771 : model1 loss : 0.365881 model2 loss : 0.261631
[21:46:29.078] iteration 772 : model1 loss : 0.394566 model2 loss : 0.320799
[21:46:29.405] iteration 773 : model1 loss : 0.387500 model2 loss : 0.380124
[21:46:29.732] iteration 774 : model1 loss : 0.392864 model2 loss : 0.302891
[21:46:30.060] iteration 775 : model1 loss : 0.373476 model2 loss : 0.333437
[21:46:30.388] iteration 776 : model1 loss : 0.467466 model2 loss : 0.400901
[21:46:30.715] iteration 777 : model1 loss : 0.385136 model2 loss : 0.393023
[21:46:31.042] iteration 778 : model1 loss : 0.412550 model2 loss : 0.280205
[21:46:31.371] iteration 779 : model1 loss : 0.390740 model2 loss : 0.283810
[21:46:31.702] iteration 780 : model1 loss : 0.413301 model2 loss : 0.337010
[21:46:32.030] iteration 781 : model1 loss : 0.413657 model2 loss : 0.404242
[21:46:32.357] iteration 782 : model1 loss : 0.395862 model2 loss : 0.339047
[21:46:32.685] iteration 783 : model1 loss : 0.426636 model2 loss : 0.337544
[21:46:33.013] iteration 784 : model1 loss : 0.357360 model2 loss : 0.330715
[21:46:33.340] iteration 785 : model1 loss : 0.319639 model2 loss : 0.257500
[21:46:33.666] iteration 786 : model1 loss : 0.445622 model2 loss : 0.348012
[21:46:33.994] iteration 787 : model1 loss : 0.418258 model2 loss : 0.338867
[21:46:34.322] iteration 788 : model1 loss : 0.342614 model2 loss : 0.319139
[21:46:34.649] iteration 789 : model1 loss : 0.459207 model2 loss : 0.329350
[21:46:34.976] iteration 790 : model1 loss : 0.322049 model2 loss : 0.314255
[21:46:35.304] iteration 791 : model1 loss : 0.360572 model2 loss : 0.347243
[21:46:35.631] iteration 792 : model1 loss : 0.425120 model2 loss : 0.432148
[21:46:35.959] iteration 793 : model1 loss : 0.377660 model2 loss : 0.354598
[21:46:36.286] iteration 794 : model1 loss : 0.340021 model2 loss : 0.236674
[21:46:36.613] iteration 795 : model1 loss : 0.365117 model2 loss : 0.322019
[21:46:36.941] iteration 796 : model1 loss : 0.339895 model2 loss : 0.297801
[21:46:37.268] iteration 797 : model1 loss : 0.381605 model2 loss : 0.262319
[21:46:37.596] iteration 798 : model1 loss : 0.397325 model2 loss : 0.396451
[21:46:37.923] iteration 799 : model1 loss : 0.340476 model2 loss : 0.280022
[21:46:38.251] iteration 800 : model1 loss : 0.415937 model2 loss : 0.404318
[21:46:38.780] iteration 801 : model1 loss : 0.409370 model2 loss : 0.315824
[21:46:39.107] iteration 802 : model1 loss : 0.344014 model2 loss : 0.331984
[21:46:39.435] iteration 803 : model1 loss : 0.348926 model2 loss : 0.292016
[21:46:39.763] iteration 804 : model1 loss : 0.442703 model2 loss : 0.464040
[21:46:40.090] iteration 805 : model1 loss : 0.351093 model2 loss : 0.280554
[21:46:40.417] iteration 806 : model1 loss : 0.385067 model2 loss : 0.297490
[21:46:40.748] iteration 807 : model1 loss : 0.382710 model2 loss : 0.304608
[21:46:41.079] iteration 808 : model1 loss : 0.409317 model2 loss : 0.380995
[21:46:41.407] iteration 809 : model1 loss : 0.426502 model2 loss : 0.383908
[21:46:41.735] iteration 810 : model1 loss : 0.320264 model2 loss : 0.255221
[21:46:42.061] iteration 811 : model1 loss : 0.352545 model2 loss : 0.320228
[21:46:42.391] iteration 812 : model1 loss : 0.393777 model2 loss : 0.369974
[21:46:42.721] iteration 813 : model1 loss : 0.333813 model2 loss : 0.242645
[21:46:43.054] iteration 814 : model1 loss : 0.324669 model2 loss : 0.243566
[21:46:43.385] iteration 815 : model1 loss : 0.361166 model2 loss : 0.311171
[21:46:43.717] iteration 816 : model1 loss : 0.397589 model2 loss : 0.369781
[21:46:44.049] iteration 817 : model1 loss : 0.341039 model2 loss : 0.250163
[21:46:44.380] iteration 818 : model1 loss : 0.403812 model2 loss : 0.306204
[21:46:44.709] iteration 819 : model1 loss : 0.419013 model2 loss : 0.354699
[21:46:45.041] iteration 820 : model1 loss : 0.472835 model2 loss : 0.426720
[21:46:45.369] iteration 821 : model1 loss : 0.368244 model2 loss : 0.279230
[21:46:45.697] iteration 822 : model1 loss : 0.347352 model2 loss : 0.330652
[21:46:46.025] iteration 823 : model1 loss : 0.363513 model2 loss : 0.285379
[21:46:46.352] iteration 824 : model1 loss : 0.413222 model2 loss : 0.385023
[21:46:46.679] iteration 825 : model1 loss : 0.379151 model2 loss : 0.364359
[21:46:47.006] iteration 826 : model1 loss : 0.368433 model2 loss : 0.292804
[21:46:47.334] iteration 827 : model1 loss : 0.364335 model2 loss : 0.332373
[21:46:47.662] iteration 828 : model1 loss : 0.354672 model2 loss : 0.344400
[21:46:47.989] iteration 829 : model1 loss : 0.346655 model2 loss : 0.257851
[21:46:48.317] iteration 830 : model1 loss : 0.386642 model2 loss : 0.351417
[21:46:48.644] iteration 831 : model1 loss : 0.364419 model2 loss : 0.291976
[21:46:48.971] iteration 832 : model1 loss : 0.329033 model2 loss : 0.229890
[21:46:49.298] iteration 833 : model1 loss : 0.398523 model2 loss : 0.358759
[21:46:49.625] iteration 834 : model1 loss : 0.392896 model2 loss : 0.307764
[21:46:49.952] iteration 835 : model1 loss : 0.380656 model2 loss : 0.370968
[21:46:50.285] iteration 836 : model1 loss : 0.374003 model2 loss : 0.328735
[21:46:50.613] iteration 837 : model1 loss : 0.384325 model2 loss : 0.372148
[21:46:50.940] iteration 838 : model1 loss : 0.337896 model2 loss : 0.305610
[21:46:51.267] iteration 839 : model1 loss : 0.329348 model2 loss : 0.325972
[21:46:51.594] iteration 840 : model1 loss : 0.333492 model2 loss : 0.280941
[21:46:51.921] iteration 841 : model1 loss : 0.292281 model2 loss : 0.257713
[21:46:52.249] iteration 842 : model1 loss : 0.296979 model2 loss : 0.278582
[21:46:52.577] iteration 843 : model1 loss : 0.354450 model2 loss : 0.324477
[21:46:52.904] iteration 844 : model1 loss : 0.374514 model2 loss : 0.407249
[21:46:53.231] iteration 845 : model1 loss : 0.386776 model2 loss : 0.375296
[21:46:53.558] iteration 846 : model1 loss : 0.340288 model2 loss : 0.297577
[21:46:53.886] iteration 847 : model1 loss : 0.392608 model2 loss : 0.318352
[21:46:54.216] iteration 848 : model1 loss : 0.387125 model2 loss : 0.388569
[21:46:54.545] iteration 849 : model1 loss : 0.353292 model2 loss : 0.338127
[21:46:54.874] iteration 850 : model1 loss : 0.344350 model2 loss : 0.294559
[21:46:55.405] iteration 851 : model1 loss : 0.390739 model2 loss : 0.330724
[21:46:55.734] iteration 852 : model1 loss : 0.382733 model2 loss : 0.359355
[21:46:56.062] iteration 853 : model1 loss : 0.382749 model2 loss : 0.342361
[21:46:56.393] iteration 854 : model1 loss : 0.400448 model2 loss : 0.288703
[21:46:56.721] iteration 855 : model1 loss : 0.355997 model2 loss : 0.321330
[21:46:57.050] iteration 856 : model1 loss : 0.320504 model2 loss : 0.308105
[21:46:57.378] iteration 857 : model1 loss : 0.377285 model2 loss : 0.368006
[21:46:57.707] iteration 858 : model1 loss : 0.391667 model2 loss : 0.347679
[21:46:58.036] iteration 859 : model1 loss : 0.355617 model2 loss : 0.318321
[21:46:58.366] iteration 860 : model1 loss : 0.363827 model2 loss : 0.302594
[21:46:58.694] iteration 861 : model1 loss : 0.361730 model2 loss : 0.306791
[21:46:59.022] iteration 862 : model1 loss : 0.345652 model2 loss : 0.268207
[21:46:59.351] iteration 863 : model1 loss : 0.369119 model2 loss : 0.352919
[21:46:59.682] iteration 864 : model1 loss : 0.363155 model2 loss : 0.354527
[21:47:00.011] iteration 865 : model1 loss : 0.362325 model2 loss : 0.351937
[21:47:00.339] iteration 866 : model1 loss : 0.407968 model2 loss : 0.366942
[21:47:00.668] iteration 867 : model1 loss : 0.373635 model2 loss : 0.321171
[21:47:00.997] iteration 868 : model1 loss : 0.367919 model2 loss : 0.312293
[21:47:01.325] iteration 869 : model1 loss : 0.379178 model2 loss : 0.304429
[21:47:01.654] iteration 870 : model1 loss : 0.351701 model2 loss : 0.294675
[21:47:01.983] iteration 871 : model1 loss : 0.373565 model2 loss : 0.290959
[21:47:02.312] iteration 872 : model1 loss : 0.378777 model2 loss : 0.373562
[21:47:02.641] iteration 873 : model1 loss : 0.380825 model2 loss : 0.334800
[21:47:02.970] iteration 874 : model1 loss : 0.339448 model2 loss : 0.325615
[21:47:03.298] iteration 875 : model1 loss : 0.420543 model2 loss : 0.391246
[21:47:03.627] iteration 876 : model1 loss : 0.372617 model2 loss : 0.307373
[21:47:03.955] iteration 877 : model1 loss : 0.358041 model2 loss : 0.335350
[21:47:04.284] iteration 878 : model1 loss : 0.379342 model2 loss : 0.311435
[21:47:04.613] iteration 879 : model1 loss : 0.393155 model2 loss : 0.279431
[21:47:04.941] iteration 880 : model1 loss : 0.363228 model2 loss : 0.329406
[21:47:05.270] iteration 881 : model1 loss : 0.358687 model2 loss : 0.362821
[21:47:05.607] iteration 882 : model1 loss : 0.318825 model2 loss : 0.254374
[21:47:05.941] iteration 883 : model1 loss : 0.352935 model2 loss : 0.298607
[21:47:06.278] iteration 884 : model1 loss : 0.349434 model2 loss : 0.248253
[21:47:06.618] iteration 885 : model1 loss : 0.340719 model2 loss : 0.271751
[21:47:06.956] iteration 886 : model1 loss : 0.421371 model2 loss : 0.260814
[21:47:07.293] iteration 887 : model1 loss : 0.409556 model2 loss : 0.379277
[21:47:07.622] iteration 888 : model1 loss : 0.365516 model2 loss : 0.323985
[21:47:07.951] iteration 889 : model1 loss : 0.347588 model2 loss : 0.277803
[21:47:08.280] iteration 890 : model1 loss : 0.473778 model2 loss : 0.401586
[21:47:08.611] iteration 891 : model1 loss : 0.403113 model2 loss : 0.325043
[21:47:08.940] iteration 892 : model1 loss : 0.369048 model2 loss : 0.317552
[21:47:09.268] iteration 893 : model1 loss : 0.363090 model2 loss : 0.250847
[21:47:09.596] iteration 894 : model1 loss : 0.408574 model2 loss : 0.329228
[21:47:09.923] iteration 895 : model1 loss : 0.377499 model2 loss : 0.274094
[21:47:10.250] iteration 896 : model1 loss : 0.500647 model2 loss : 0.440028
[21:47:10.577] iteration 897 : model1 loss : 0.371852 model2 loss : 0.299405
[21:47:10.905] iteration 898 : model1 loss : 0.359770 model2 loss : 0.317161
[21:47:11.233] iteration 899 : model1 loss : 0.403361 model2 loss : 0.351286
[21:47:11.561] iteration 900 : model1 loss : 0.380673 model2 loss : 0.278462
[21:47:12.082] iteration 901 : model1 loss : 0.405107 model2 loss : 0.403769
[21:47:12.412] iteration 902 : model1 loss : 0.401615 model2 loss : 0.365803
[21:47:12.739] iteration 903 : model1 loss : 0.379032 model2 loss : 0.309793
[21:47:13.067] iteration 904 : model1 loss : 0.416553 model2 loss : 0.381170
[21:47:13.394] iteration 905 : model1 loss : 0.326246 model2 loss : 0.293284
[21:47:13.722] iteration 906 : model1 loss : 0.400826 model2 loss : 0.357166
[21:47:14.049] iteration 907 : model1 loss : 0.346382 model2 loss : 0.305915
[21:47:14.378] iteration 908 : model1 loss : 0.351465 model2 loss : 0.315082
[21:47:14.706] iteration 909 : model1 loss : 0.356554 model2 loss : 0.318239
[21:47:15.033] iteration 910 : model1 loss : 0.404684 model2 loss : 0.411393
[21:47:15.361] iteration 911 : model1 loss : 0.337138 model2 loss : 0.266467
[21:47:15.689] iteration 912 : model1 loss : 0.357809 model2 loss : 0.268962
[21:47:16.017] iteration 913 : model1 loss : 0.357456 model2 loss : 0.338175
[21:47:16.345] iteration 914 : model1 loss : 0.468095 model2 loss : 0.404035
[21:47:16.672] iteration 915 : model1 loss : 0.326591 model2 loss : 0.256185
[21:47:17.000] iteration 916 : model1 loss : 0.419852 model2 loss : 0.422273
[21:47:17.329] iteration 917 : model1 loss : 0.392817 model2 loss : 0.338418
[21:47:17.657] iteration 918 : model1 loss : 0.460196 model2 loss : 0.419446
[21:47:17.984] iteration 919 : model1 loss : 0.364807 model2 loss : 0.250920
[21:47:18.313] iteration 920 : model1 loss : 0.423807 model2 loss : 0.368692
[21:47:18.641] iteration 921 : model1 loss : 0.336038 model2 loss : 0.267778
[21:47:18.968] iteration 922 : model1 loss : 0.377964 model2 loss : 0.348023
[21:47:19.295] iteration 923 : model1 loss : 0.341842 model2 loss : 0.315104
[21:47:19.623] iteration 924 : model1 loss : 0.386502 model2 loss : 0.371141
[21:47:19.950] iteration 925 : model1 loss : 0.334486 model2 loss : 0.270697
[21:47:20.278] iteration 926 : model1 loss : 0.361226 model2 loss : 0.257019
[21:47:20.606] iteration 927 : model1 loss : 0.344595 model2 loss : 0.301626
[21:47:20.933] iteration 928 : model1 loss : 0.345303 model2 loss : 0.300919
[21:47:21.260] iteration 929 : model1 loss : 0.342899 model2 loss : 0.290608
[21:47:21.588] iteration 930 : model1 loss : 0.478003 model2 loss : 0.416292
[21:47:21.916] iteration 931 : model1 loss : 0.348966 model2 loss : 0.241614
[21:47:22.243] iteration 932 : model1 loss : 0.412178 model2 loss : 0.340345
[21:47:22.571] iteration 933 : model1 loss : 0.313539 model2 loss : 0.301935
[21:47:22.899] iteration 934 : model1 loss : 0.377103 model2 loss : 0.326622
[21:47:23.226] iteration 935 : model1 loss : 0.366189 model2 loss : 0.309352
[21:47:23.554] iteration 936 : model1 loss : 0.371845 model2 loss : 0.265835
[21:47:23.882] iteration 937 : model1 loss : 0.338809 model2 loss : 0.265674
[21:47:24.208] iteration 938 : model1 loss : 0.359828 model2 loss : 0.314056
[21:47:24.536] iteration 939 : model1 loss : 0.431154 model2 loss : 0.368064
[21:47:24.864] iteration 940 : model1 loss : 0.384058 model2 loss : 0.365372
[21:47:25.191] iteration 941 : model1 loss : 0.378860 model2 loss : 0.268670
[21:47:25.519] iteration 942 : model1 loss : 0.394024 model2 loss : 0.241877
[21:47:25.846] iteration 943 : model1 loss : 0.431039 model2 loss : 0.360778
[21:47:26.174] iteration 944 : model1 loss : 0.319492 model2 loss : 0.316849
[21:47:26.502] iteration 945 : model1 loss : 0.365614 model2 loss : 0.393205
[21:47:26.830] iteration 946 : model1 loss : 0.425462 model2 loss : 0.293195
[21:47:27.157] iteration 947 : model1 loss : 0.375161 model2 loss : 0.266548
[21:47:27.484] iteration 948 : model1 loss : 0.386130 model2 loss : 0.327942
[21:47:27.813] iteration 949 : model1 loss : 0.457255 model2 loss : 0.408332
[21:47:28.140] iteration 950 : model1 loss : 0.314375 model2 loss : 0.245749
[21:47:28.655] iteration 951 : model1 loss : 0.366237 model2 loss : 0.330966
[21:47:28.982] iteration 952 : model1 loss : 0.366308 model2 loss : 0.302903
[21:47:29.310] iteration 953 : model1 loss : 0.382122 model2 loss : 0.356960
[21:47:29.637] iteration 954 : model1 loss : 0.400217 model2 loss : 0.370358
[21:47:29.966] iteration 955 : model1 loss : 0.373359 model2 loss : 0.372343
[21:47:30.294] iteration 956 : model1 loss : 0.349084 model2 loss : 0.331443
[21:47:30.622] iteration 957 : model1 loss : 0.353432 model2 loss : 0.296471
[21:47:30.949] iteration 958 : model1 loss : 0.372826 model2 loss : 0.339411
[21:47:31.276] iteration 959 : model1 loss : 0.336164 model2 loss : 0.276783
[21:47:31.603] iteration 960 : model1 loss : 0.375943 model2 loss : 0.382237
[21:47:31.931] iteration 961 : model1 loss : 0.349251 model2 loss : 0.269170
[21:47:32.259] iteration 962 : model1 loss : 0.341841 model2 loss : 0.313264
[21:47:32.587] iteration 963 : model1 loss : 0.414643 model2 loss : 0.373267
[21:47:32.914] iteration 964 : model1 loss : 0.366012 model2 loss : 0.322916
[21:47:33.242] iteration 965 : model1 loss : 0.307084 model2 loss : 0.260970
[21:47:33.569] iteration 966 : model1 loss : 0.368981 model2 loss : 0.302247
[21:47:33.897] iteration 967 : model1 loss : 0.360372 model2 loss : 0.296432
[21:47:34.224] iteration 968 : model1 loss : 0.366054 model2 loss : 0.413799
[21:47:34.551] iteration 969 : model1 loss : 0.354536 model2 loss : 0.364759
[21:47:34.879] iteration 970 : model1 loss : 0.433860 model2 loss : 0.344706
[21:47:35.206] iteration 971 : model1 loss : 0.382689 model2 loss : 0.387464
[21:47:35.534] iteration 972 : model1 loss : 0.383230 model2 loss : 0.302200
[21:47:35.861] iteration 973 : model1 loss : 0.413400 model2 loss : 0.377728
[21:47:36.187] iteration 974 : model1 loss : 0.398433 model2 loss : 0.436027
[21:47:36.514] iteration 975 : model1 loss : 0.352960 model2 loss : 0.343313
[21:47:36.840] iteration 976 : model1 loss : 0.315050 model2 loss : 0.270759
[21:47:37.168] iteration 977 : model1 loss : 0.393505 model2 loss : 0.354028
[21:47:37.496] iteration 978 : model1 loss : 0.356659 model2 loss : 0.282684
[21:47:37.823] iteration 979 : model1 loss : 0.372577 model2 loss : 0.316321
[21:47:38.152] iteration 980 : model1 loss : 0.340949 model2 loss : 0.289473
[21:47:38.479] iteration 981 : model1 loss : 0.366671 model2 loss : 0.272736
[21:47:38.807] iteration 982 : model1 loss : 0.380724 model2 loss : 0.318226
[21:47:39.134] iteration 983 : model1 loss : 0.389015 model2 loss : 0.310145
[21:47:39.461] iteration 984 : model1 loss : 0.362761 model2 loss : 0.296688
[21:47:39.789] iteration 985 : model1 loss : 0.436421 model2 loss : 0.403560
[21:47:40.117] iteration 986 : model1 loss : 0.506169 model2 loss : 0.465766
[21:47:40.448] iteration 987 : model1 loss : 0.393797 model2 loss : 0.386404
[21:47:40.780] iteration 988 : model1 loss : 0.367519 model2 loss : 0.259460
[21:47:41.109] iteration 989 : model1 loss : 0.363512 model2 loss : 0.316040
[21:47:41.438] iteration 990 : model1 loss : 0.361711 model2 loss : 0.313451
[21:47:41.883] iteration 991 : model1 loss : 0.340935 model2 loss : 0.304443
[21:47:42.211] iteration 992 : model1 loss : 0.328473 model2 loss : 0.294619
[21:47:42.540] iteration 993 : model1 loss : 0.347182 model2 loss : 0.307820
[21:47:42.867] iteration 994 : model1 loss : 0.328335 model2 loss : 0.316230
[21:47:43.195] iteration 995 : model1 loss : 0.442881 model2 loss : 0.369921
[21:47:43.523] iteration 996 : model1 loss : 0.412487 model2 loss : 0.406884
[21:47:43.850] iteration 997 : model1 loss : 0.372830 model2 loss : 0.363660
[21:47:44.177] iteration 998 : model1 loss : 0.400129 model2 loss : 0.380146
[21:47:44.506] iteration 999 : model1 loss : 0.348893 model2 loss : 0.251677
[21:47:44.834] iteration 1000 : model1 loss : 0.374947 model2 loss : 0.305646
[21:47:45.370] iteration 1001 : model1 loss : 0.344512 model2 loss : 0.268308
[21:47:45.698] iteration 1002 : model1 loss : 0.370844 model2 loss : 0.279247
[21:47:46.026] iteration 1003 : model1 loss : 0.361148 model2 loss : 0.337028
[21:47:46.355] iteration 1004 : model1 loss : 0.374721 model2 loss : 0.339851
[21:47:46.682] iteration 1005 : model1 loss : 0.354634 model2 loss : 0.347475
[21:47:47.009] iteration 1006 : model1 loss : 0.382030 model2 loss : 0.333852
[21:47:47.337] iteration 1007 : model1 loss : 0.399266 model2 loss : 0.279788
[21:47:47.665] iteration 1008 : model1 loss : 0.416537 model2 loss : 0.365706
[21:47:47.993] iteration 1009 : model1 loss : 0.420283 model2 loss : 0.372465
[21:47:48.320] iteration 1010 : model1 loss : 0.345857 model2 loss : 0.311937
[21:47:48.648] iteration 1011 : model1 loss : 0.416343 model2 loss : 0.398402
[21:47:48.975] iteration 1012 : model1 loss : 0.382352 model2 loss : 0.369095
[21:47:49.303] iteration 1013 : model1 loss : 0.374198 model2 loss : 0.303245
[21:47:49.632] iteration 1014 : model1 loss : 0.322456 model2 loss : 0.212214
[21:47:49.960] iteration 1015 : model1 loss : 0.325877 model2 loss : 0.223277
[21:47:50.296] iteration 1016 : model1 loss : 0.360719 model2 loss : 0.295132
[21:47:50.631] iteration 1017 : model1 loss : 0.352611 model2 loss : 0.284490
[21:47:50.968] iteration 1018 : model1 loss : 0.328474 model2 loss : 0.282811
[21:47:51.306] iteration 1019 : model1 loss : 0.324002 model2 loss : 0.267536
[21:47:51.643] iteration 1020 : model1 loss : 0.377936 model2 loss : 0.283978
[21:47:51.979] iteration 1021 : model1 loss : 0.395266 model2 loss : 0.376234
[21:47:52.317] iteration 1022 : model1 loss : 0.313773 model2 loss : 0.306943
[21:47:52.655] iteration 1023 : model1 loss : 0.389018 model2 loss : 0.362013
[21:47:52.992] iteration 1024 : model1 loss : 0.318140 model2 loss : 0.230195
[21:47:53.331] iteration 1025 : model1 loss : 0.366052 model2 loss : 0.360020
[21:47:53.668] iteration 1026 : model1 loss : 0.393721 model2 loss : 0.351621
[21:47:54.006] iteration 1027 : model1 loss : 0.408722 model2 loss : 0.382880
[21:47:54.346] iteration 1028 : model1 loss : 0.379984 model2 loss : 0.304570
[21:47:54.684] iteration 1029 : model1 loss : 0.337405 model2 loss : 0.296918
[21:47:55.021] iteration 1030 : model1 loss : 0.411902 model2 loss : 0.351230
[21:47:55.360] iteration 1031 : model1 loss : 0.459665 model2 loss : 0.450179
[21:47:55.698] iteration 1032 : model1 loss : 0.292544 model2 loss : 0.286587
[21:47:56.040] iteration 1033 : model1 loss : 0.374610 model2 loss : 0.339812
[21:47:56.379] iteration 1034 : model1 loss : 0.372442 model2 loss : 0.310586
[21:47:56.716] iteration 1035 : model1 loss : 0.317952 model2 loss : 0.262286
[21:47:57.054] iteration 1036 : model1 loss : 0.388322 model2 loss : 0.332778
[21:47:57.394] iteration 1037 : model1 loss : 0.354486 model2 loss : 0.267621
[21:47:57.731] iteration 1038 : model1 loss : 0.409218 model2 loss : 0.390032
[21:47:58.069] iteration 1039 : model1 loss : 0.379202 model2 loss : 0.339490
[21:47:58.408] iteration 1040 : model1 loss : 0.378769 model2 loss : 0.324178
[21:47:58.746] iteration 1041 : model1 loss : 0.465276 model2 loss : 0.461720
[21:47:59.083] iteration 1042 : model1 loss : 0.396072 model2 loss : 0.233225
[21:47:59.420] iteration 1043 : model1 loss : 0.387596 model2 loss : 0.367989
[21:47:59.758] iteration 1044 : model1 loss : 0.349668 model2 loss : 0.344396
[21:48:00.096] iteration 1045 : model1 loss : 0.322475 model2 loss : 0.268986
[21:48:00.434] iteration 1046 : model1 loss : 0.414399 model2 loss : 0.354613
[21:48:00.771] iteration 1047 : model1 loss : 0.333063 model2 loss : 0.283037
[21:48:01.110] iteration 1048 : model1 loss : 0.324058 model2 loss : 0.320154
[21:48:01.450] iteration 1049 : model1 loss : 0.337989 model2 loss : 0.342359
[21:48:01.788] iteration 1050 : model1 loss : 0.317166 model2 loss : 0.283531
[21:48:02.441] iteration 1051 : model1 loss : 0.403956 model2 loss : 0.402464
[21:48:02.779] iteration 1052 : model1 loss : 0.325711 model2 loss : 0.361772
[21:48:03.117] iteration 1053 : model1 loss : 0.280264 model2 loss : 0.258702
[21:48:03.455] iteration 1054 : model1 loss : 0.379481 model2 loss : 0.337285
[21:48:03.794] iteration 1055 : model1 loss : 0.289981 model2 loss : 0.220641
[21:48:04.134] iteration 1056 : model1 loss : 0.382116 model2 loss : 0.435895
[21:48:04.475] iteration 1057 : model1 loss : 0.395839 model2 loss : 0.349796
[21:48:04.819] iteration 1058 : model1 loss : 0.387241 model2 loss : 0.337005
[21:48:05.161] iteration 1059 : model1 loss : 0.348522 model2 loss : 0.298958
[21:48:05.500] iteration 1060 : model1 loss : 0.338241 model2 loss : 0.341952
[21:48:05.839] iteration 1061 : model1 loss : 0.396923 model2 loss : 0.346959
[21:48:06.179] iteration 1062 : model1 loss : 0.395184 model2 loss : 0.353902
[21:48:06.517] iteration 1063 : model1 loss : 0.349070 model2 loss : 0.340504
[21:48:06.854] iteration 1064 : model1 loss : 0.379240 model2 loss : 0.353821
[21:48:07.192] iteration 1065 : model1 loss : 0.423322 model2 loss : 0.345630
[21:48:07.529] iteration 1066 : model1 loss : 0.338501 model2 loss : 0.302885
[21:48:07.866] iteration 1067 : model1 loss : 0.372520 model2 loss : 0.366637
[21:48:08.204] iteration 1068 : model1 loss : 0.322401 model2 loss : 0.319644
[21:48:08.541] iteration 1069 : model1 loss : 0.363456 model2 loss : 0.284626
[21:48:08.879] iteration 1070 : model1 loss : 0.326927 model2 loss : 0.314213
[21:48:09.216] iteration 1071 : model1 loss : 0.326544 model2 loss : 0.299144
[21:48:09.553] iteration 1072 : model1 loss : 0.372732 model2 loss : 0.254249
[21:48:09.889] iteration 1073 : model1 loss : 0.346825 model2 loss : 0.310041
[21:48:10.227] iteration 1074 : model1 loss : 0.314395 model2 loss : 0.254268
[21:48:10.564] iteration 1075 : model1 loss : 0.350258 model2 loss : 0.344111
[21:48:10.901] iteration 1076 : model1 loss : 0.409424 model2 loss : 0.348902
[21:48:11.238] iteration 1077 : model1 loss : 0.312671 model2 loss : 0.266282
[21:48:11.576] iteration 1078 : model1 loss : 0.368224 model2 loss : 0.292381
[21:48:11.914] iteration 1079 : model1 loss : 0.318363 model2 loss : 0.248239
[21:48:12.251] iteration 1080 : model1 loss : 0.331251 model2 loss : 0.273673
[21:48:12.589] iteration 1081 : model1 loss : 0.334932 model2 loss : 0.276295
[21:48:12.926] iteration 1082 : model1 loss : 0.412695 model2 loss : 0.409471
[21:48:13.264] iteration 1083 : model1 loss : 0.340140 model2 loss : 0.291220
[21:48:13.601] iteration 1084 : model1 loss : 0.329171 model2 loss : 0.209565
[21:48:13.938] iteration 1085 : model1 loss : 0.335705 model2 loss : 0.261141
[21:48:14.275] iteration 1086 : model1 loss : 0.336832 model2 loss : 0.274379
[21:48:14.611] iteration 1087 : model1 loss : 0.354493 model2 loss : 0.310930
[21:48:14.948] iteration 1088 : model1 loss : 0.383815 model2 loss : 0.420219
[21:48:15.285] iteration 1089 : model1 loss : 0.362297 model2 loss : 0.291904
[21:48:15.626] iteration 1090 : model1 loss : 0.382748 model2 loss : 0.368663
[21:48:16.684] iteration 1091 : model1 loss : 0.305862 model2 loss : 0.263215
[21:48:17.021] iteration 1092 : model1 loss : 0.405747 model2 loss : 0.363017
[21:48:17.359] iteration 1093 : model1 loss : 0.327911 model2 loss : 0.349356
[21:48:17.697] iteration 1094 : model1 loss : 0.389226 model2 loss : 0.383811
[21:48:18.039] iteration 1095 : model1 loss : 0.454800 model2 loss : 0.379706
[21:48:18.378] iteration 1096 : model1 loss : 0.312299 model2 loss : 0.261581
[21:48:18.716] iteration 1097 : model1 loss : 0.386576 model2 loss : 0.319513
[21:48:19.052] iteration 1098 : model1 loss : 0.320249 model2 loss : 0.298310
[21:48:19.390] iteration 1099 : model1 loss : 0.340474 model2 loss : 0.278739
[21:48:19.730] iteration 1100 : model1 loss : 0.385563 model2 loss : 0.339091
[21:48:20.434] iteration 1101 : model1 loss : 0.381092 model2 loss : 0.320820
[21:48:20.772] iteration 1102 : model1 loss : 0.478216 model2 loss : 0.402192
[21:48:21.110] iteration 1103 : model1 loss : 0.372778 model2 loss : 0.307677
[21:48:21.447] iteration 1104 : model1 loss : 0.315819 model2 loss : 0.255400
[21:48:21.784] iteration 1105 : model1 loss : 0.381629 model2 loss : 0.272847
[21:48:22.120] iteration 1106 : model1 loss : 0.368767 model2 loss : 0.347969
[21:48:22.454] iteration 1107 : model1 loss : 0.366261 model2 loss : 0.312980
[21:48:22.799] iteration 1108 : model1 loss : 0.333746 model2 loss : 0.231699
[21:48:23.134] iteration 1109 : model1 loss : 0.348071 model2 loss : 0.346751
[21:48:23.472] iteration 1110 : model1 loss : 0.321456 model2 loss : 0.215026
[21:48:23.812] iteration 1111 : model1 loss : 0.362646 model2 loss : 0.273979
[21:48:24.153] iteration 1112 : model1 loss : 0.386896 model2 loss : 0.312532
[21:48:24.492] iteration 1113 : model1 loss : 0.332877 model2 loss : 0.332974
[21:48:24.832] iteration 1114 : model1 loss : 0.401484 model2 loss : 0.373156
[21:48:25.169] iteration 1115 : model1 loss : 0.311767 model2 loss : 0.278841
[21:48:25.506] iteration 1116 : model1 loss : 0.530964 model2 loss : 0.460415
[21:48:25.843] iteration 1117 : model1 loss : 0.372985 model2 loss : 0.309590
[21:48:26.179] iteration 1118 : model1 loss : 0.373303 model2 loss : 0.332778
[21:48:26.516] iteration 1119 : model1 loss : 0.331896 model2 loss : 0.311498
[21:48:26.853] iteration 1120 : model1 loss : 0.355148 model2 loss : 0.314809
[21:48:27.189] iteration 1121 : model1 loss : 0.311907 model2 loss : 0.270309
[21:48:27.526] iteration 1122 : model1 loss : 0.323650 model2 loss : 0.261622
[21:48:27.863] iteration 1123 : model1 loss : 0.356202 model2 loss : 0.297738
[21:48:28.202] iteration 1124 : model1 loss : 0.315150 model2 loss : 0.299025
[21:48:28.539] iteration 1125 : model1 loss : 0.397691 model2 loss : 0.289576
[21:48:28.876] iteration 1126 : model1 loss : 0.328491 model2 loss : 0.260649
[21:48:29.212] iteration 1127 : model1 loss : 0.424886 model2 loss : 0.437873
[21:48:29.548] iteration 1128 : model1 loss : 0.384769 model2 loss : 0.413003
[21:48:29.883] iteration 1129 : model1 loss : 0.375309 model2 loss : 0.376268
[21:48:30.220] iteration 1130 : model1 loss : 0.343456 model2 loss : 0.303992
[21:48:30.558] iteration 1131 : model1 loss : 0.327011 model2 loss : 0.267820
[21:48:30.897] iteration 1132 : model1 loss : 0.420980 model2 loss : 0.282804
[21:48:31.234] iteration 1133 : model1 loss : 0.316174 model2 loss : 0.274198
[21:48:31.571] iteration 1134 : model1 loss : 0.333909 model2 loss : 0.312475
[21:48:31.907] iteration 1135 : model1 loss : 0.328565 model2 loss : 0.268901
[21:48:32.245] iteration 1136 : model1 loss : 0.388771 model2 loss : 0.393700
[21:48:32.583] iteration 1137 : model1 loss : 0.361818 model2 loss : 0.282946
[21:48:32.920] iteration 1138 : model1 loss : 0.375253 model2 loss : 0.333551
[21:48:33.256] iteration 1139 : model1 loss : 0.361794 model2 loss : 0.300996
[21:48:33.595] iteration 1140 : model1 loss : 0.389778 model2 loss : 0.359793
[21:48:33.931] iteration 1141 : model1 loss : 0.400351 model2 loss : 0.358148
[21:48:34.268] iteration 1142 : model1 loss : 0.409913 model2 loss : 0.303418
[21:48:34.604] iteration 1143 : model1 loss : 0.318695 model2 loss : 0.260427
[21:48:34.941] iteration 1144 : model1 loss : 0.305332 model2 loss : 0.258243
[21:48:35.280] iteration 1145 : model1 loss : 0.371602 model2 loss : 0.306307
[21:48:35.615] iteration 1146 : model1 loss : 0.438098 model2 loss : 0.459960
[21:48:35.953] iteration 1147 : model1 loss : 0.376694 model2 loss : 0.331239
[21:48:36.288] iteration 1148 : model1 loss : 0.321957 model2 loss : 0.298721
[21:48:36.623] iteration 1149 : model1 loss : 0.367059 model2 loss : 0.332219
[21:48:36.958] iteration 1150 : model1 loss : 0.366609 model2 loss : 0.319629
[21:48:37.604] iteration 1151 : model1 loss : 0.327976 model2 loss : 0.286127
[21:48:37.942] iteration 1152 : model1 loss : 0.406816 model2 loss : 0.305601
[21:48:38.277] iteration 1153 : model1 loss : 0.399486 model2 loss : 0.350894
[21:48:38.609] iteration 1154 : model1 loss : 0.387174 model2 loss : 0.307917
[21:48:38.946] iteration 1155 : model1 loss : 0.298707 model2 loss : 0.226457
[21:48:39.281] iteration 1156 : model1 loss : 0.434515 model2 loss : 0.426800
[21:48:39.619] iteration 1157 : model1 loss : 0.350291 model2 loss : 0.315540
[21:48:39.955] iteration 1158 : model1 loss : 0.447375 model2 loss : 0.369420
[21:48:40.293] iteration 1159 : model1 loss : 0.370843 model2 loss : 0.352977
[21:48:40.629] iteration 1160 : model1 loss : 0.335091 model2 loss : 0.238349
[21:48:40.966] iteration 1161 : model1 loss : 0.396538 model2 loss : 0.322529
[21:48:41.307] iteration 1162 : model1 loss : 0.356499 model2 loss : 0.312787
[21:48:41.643] iteration 1163 : model1 loss : 0.422960 model2 loss : 0.472587
[21:48:41.979] iteration 1164 : model1 loss : 0.405036 model2 loss : 0.347952
[21:48:42.311] iteration 1165 : model1 loss : 0.381681 model2 loss : 0.378603
[21:48:42.643] iteration 1166 : model1 loss : 0.383129 model2 loss : 0.348340
[21:48:42.976] iteration 1167 : model1 loss : 0.377219 model2 loss : 0.357196
[21:48:43.313] iteration 1168 : model1 loss : 0.367758 model2 loss : 0.286935
[21:48:43.651] iteration 1169 : model1 loss : 0.382609 model2 loss : 0.329740
[21:48:43.988] iteration 1170 : model1 loss : 0.333255 model2 loss : 0.286761
[21:48:44.324] iteration 1171 : model1 loss : 0.401792 model2 loss : 0.389235
[21:48:44.661] iteration 1172 : model1 loss : 0.426146 model2 loss : 0.388168
[21:48:44.997] iteration 1173 : model1 loss : 0.361991 model2 loss : 0.337094
[21:48:45.334] iteration 1174 : model1 loss : 0.353963 model2 loss : 0.327607
[21:48:45.671] iteration 1175 : model1 loss : 0.319288 model2 loss : 0.296994
[21:48:46.030] iteration 1176 : model1 loss : 0.341089 model2 loss : 0.326915
[21:48:46.368] iteration 1177 : model1 loss : 0.356814 model2 loss : 0.321178
[21:48:46.709] iteration 1178 : model1 loss : 0.350079 model2 loss : 0.271093
[21:48:47.049] iteration 1179 : model1 loss : 0.339197 model2 loss : 0.249330
[21:48:47.386] iteration 1180 : model1 loss : 0.376241 model2 loss : 0.294068
[21:48:47.728] iteration 1181 : model1 loss : 0.490300 model2 loss : 0.432995
[21:48:48.057] iteration 1182 : model1 loss : 0.486417 model2 loss : 0.466282
[21:48:48.385] iteration 1183 : model1 loss : 0.307838 model2 loss : 0.223079
[21:48:48.714] iteration 1184 : model1 loss : 0.338361 model2 loss : 0.282549
[21:48:49.041] iteration 1185 : model1 loss : 0.385096 model2 loss : 0.355705
[21:48:49.372] iteration 1186 : model1 loss : 0.325653 model2 loss : 0.326896
[21:48:49.699] iteration 1187 : model1 loss : 0.354225 model2 loss : 0.338490
[21:48:50.026] iteration 1188 : model1 loss : 0.354108 model2 loss : 0.291695
[21:48:50.353] iteration 1189 : model1 loss : 0.335717 model2 loss : 0.296146
[21:48:50.681] iteration 1190 : model1 loss : 0.333991 model2 loss : 0.246243
[21:48:51.008] iteration 1191 : model1 loss : 0.345898 model2 loss : 0.351833
[21:48:51.336] iteration 1192 : model1 loss : 0.366935 model2 loss : 0.347035
[21:48:51.662] iteration 1193 : model1 loss : 0.382792 model2 loss : 0.338154
[21:48:51.993] iteration 1194 : model1 loss : 0.391773 model2 loss : 0.275221
[21:48:52.317] iteration 1195 : model1 loss : 0.384063 model2 loss : 0.266412
[21:48:52.645] iteration 1196 : model1 loss : 0.377271 model2 loss : 0.309550
[21:48:52.978] iteration 1197 : model1 loss : 0.404529 model2 loss : 0.321043
[21:48:53.314] iteration 1198 : model1 loss : 0.376314 model2 loss : 0.297161
[21:48:53.655] iteration 1199 : model1 loss : 0.383258 model2 loss : 0.375302
[21:48:53.987] iteration 1200 : model1 loss : 0.422235 model2 loss : 0.334263
[21:48:54.639] iteration 1201 : model1 loss : 0.383849 model2 loss : 0.294894
[21:48:54.975] iteration 1202 : model1 loss : 0.334147 model2 loss : 0.262213
[21:48:55.311] iteration 1203 : model1 loss : 0.363457 model2 loss : 0.312094
[21:48:55.647] iteration 1204 : model1 loss : 0.328818 model2 loss : 0.310219
[21:48:55.980] iteration 1205 : model1 loss : 0.381376 model2 loss : 0.366249
[21:48:56.319] iteration 1206 : model1 loss : 0.344227 model2 loss : 0.311536
[21:48:56.651] iteration 1207 : model1 loss : 0.364244 model2 loss : 0.319908
[21:48:56.986] iteration 1208 : model1 loss : 0.320027 model2 loss : 0.252790
[21:48:57.318] iteration 1209 : model1 loss : 0.314315 model2 loss : 0.227809
[21:48:57.654] iteration 1210 : model1 loss : 0.347748 model2 loss : 0.360498
[21:48:57.991] iteration 1211 : model1 loss : 0.377658 model2 loss : 0.281732
[21:48:58.324] iteration 1212 : model1 loss : 0.342129 model2 loss : 0.291897
[21:48:58.657] iteration 1213 : model1 loss : 0.331597 model2 loss : 0.270191
[21:48:58.993] iteration 1214 : model1 loss : 0.360964 model2 loss : 0.306512
[21:48:59.325] iteration 1215 : model1 loss : 0.381814 model2 loss : 0.347518
[21:48:59.661] iteration 1216 : model1 loss : 0.471327 model2 loss : 0.430145
[21:48:59.993] iteration 1217 : model1 loss : 0.403311 model2 loss : 0.356770
[21:49:00.329] iteration 1218 : model1 loss : 0.311038 model2 loss : 0.311612
[21:49:00.661] iteration 1219 : model1 loss : 0.371270 model2 loss : 0.326164
[21:49:00.994] iteration 1220 : model1 loss : 0.376195 model2 loss : 0.332365
[21:49:01.330] iteration 1221 : model1 loss : 0.388711 model2 loss : 0.311555
[21:49:01.662] iteration 1222 : model1 loss : 0.325507 model2 loss : 0.285183
[21:49:01.994] iteration 1223 : model1 loss : 0.463372 model2 loss : 0.415521
[21:49:02.327] iteration 1224 : model1 loss : 0.333278 model2 loss : 0.318569
[21:49:02.662] iteration 1225 : model1 loss : 0.347581 model2 loss : 0.362854
[21:49:02.995] iteration 1226 : model1 loss : 0.358848 model2 loss : 0.269015
[21:49:03.326] iteration 1227 : model1 loss : 0.342702 model2 loss : 0.289178
[21:49:03.660] iteration 1228 : model1 loss : 0.388589 model2 loss : 0.356399
[21:49:03.992] iteration 1229 : model1 loss : 0.368137 model2 loss : 0.362447
[21:49:04.324] iteration 1230 : model1 loss : 0.384015 model2 loss : 0.348566
[21:49:04.664] iteration 1231 : model1 loss : 0.319000 model2 loss : 0.262882
[21:49:04.998] iteration 1232 : model1 loss : 0.338851 model2 loss : 0.233369
[21:49:05.335] iteration 1233 : model1 loss : 0.364244 model2 loss : 0.343100
[21:49:05.667] iteration 1234 : model1 loss : 0.303752 model2 loss : 0.262400
[21:49:06.000] iteration 1235 : model1 loss : 0.385296 model2 loss : 0.400754
[21:49:06.336] iteration 1236 : model1 loss : 0.246282 model2 loss : 0.189315
[21:49:06.670] iteration 1237 : model1 loss : 0.346622 model2 loss : 0.324484
[21:49:07.003] iteration 1238 : model1 loss : 0.365105 model2 loss : 0.322629
[21:49:07.340] iteration 1239 : model1 loss : 0.376937 model2 loss : 0.314983
[21:49:07.678] iteration 1240 : model1 loss : 0.373597 model2 loss : 0.333415
[21:49:08.014] iteration 1241 : model1 loss : 0.356310 model2 loss : 0.335410
[21:49:08.350] iteration 1242 : model1 loss : 0.319928 model2 loss : 0.288108
[21:49:08.688] iteration 1243 : model1 loss : 0.350601 model2 loss : 0.309497
[21:49:09.027] iteration 1244 : model1 loss : 0.308560 model2 loss : 0.305225
[21:49:09.363] iteration 1245 : model1 loss : 0.376580 model2 loss : 0.355301
[21:49:09.697] iteration 1246 : model1 loss : 0.416858 model2 loss : 0.359753
[21:49:10.036] iteration 1247 : model1 loss : 0.407952 model2 loss : 0.408905
[21:49:10.374] iteration 1248 : model1 loss : 0.386365 model2 loss : 0.376484
[21:49:10.710] iteration 1249 : model1 loss : 0.322719 model2 loss : 0.245156
[21:49:11.043] iteration 1250 : model1 loss : 0.298991 model2 loss : 0.243365
[21:49:11.658] iteration 1251 : model1 loss : 0.376009 model2 loss : 0.368834
[21:49:11.991] iteration 1252 : model1 loss : 0.370046 model2 loss : 0.282548
[21:49:12.328] iteration 1253 : model1 loss : 0.358663 model2 loss : 0.299289
[21:49:12.664] iteration 1254 : model1 loss : 0.320016 model2 loss : 0.281241
[21:49:13.003] iteration 1255 : model1 loss : 0.395646 model2 loss : 0.336974
[21:49:13.341] iteration 1256 : model1 loss : 0.349001 model2 loss : 0.315913
[21:49:13.678] iteration 1257 : model1 loss : 0.310245 model2 loss : 0.300335
[21:49:14.043] iteration 1258 : model1 loss : 0.373787 model2 loss : 0.295397
[21:49:14.380] iteration 1259 : model1 loss : 0.393540 model2 loss : 0.345453
[21:49:14.718] iteration 1260 : model1 loss : 0.386840 model2 loss : 0.366525
[21:49:15.076] iteration 1261 : model1 loss : 0.391718 model2 loss : 0.291542
[21:49:15.412] iteration 1262 : model1 loss : 0.360912 model2 loss : 0.338164
[21:49:15.750] iteration 1263 : model1 loss : 0.365991 model2 loss : 0.326633
[21:49:16.088] iteration 1264 : model1 loss : 0.353660 model2 loss : 0.255383
[21:49:16.425] iteration 1265 : model1 loss : 0.335116 model2 loss : 0.309867
[21:49:16.762] iteration 1266 : model1 loss : 0.361428 model2 loss : 0.341155
[21:49:17.102] iteration 1267 : model1 loss : 0.390089 model2 loss : 0.315583
[21:49:17.439] iteration 1268 : model1 loss : 0.392054 model2 loss : 0.360142
[21:49:17.774] iteration 1269 : model1 loss : 0.316179 model2 loss : 0.308273
[21:49:18.110] iteration 1270 : model1 loss : 0.364634 model2 loss : 0.329380
[21:49:18.447] iteration 1271 : model1 loss : 0.275367 model2 loss : 0.312536
[21:49:18.784] iteration 1272 : model1 loss : 0.287870 model2 loss : 0.241549
[21:49:19.119] iteration 1273 : model1 loss : 0.363019 model2 loss : 0.343213
[21:49:19.454] iteration 1274 : model1 loss : 0.352927 model2 loss : 0.308428
[21:49:19.792] iteration 1275 : model1 loss : 0.452622 model2 loss : 0.322196
[21:49:20.129] iteration 1276 : model1 loss : 0.389882 model2 loss : 0.429409
[21:49:20.467] iteration 1277 : model1 loss : 0.356722 model2 loss : 0.294198
[21:49:20.804] iteration 1278 : model1 loss : 0.351743 model2 loss : 0.300615
[21:49:21.141] iteration 1279 : model1 loss : 0.333257 model2 loss : 0.257599
[21:49:21.479] iteration 1280 : model1 loss : 0.297215 model2 loss : 0.218183
[21:49:21.817] iteration 1281 : model1 loss : 0.318546 model2 loss : 0.253692
[21:49:22.154] iteration 1282 : model1 loss : 0.297207 model2 loss : 0.248386
[21:49:22.491] iteration 1283 : model1 loss : 0.350057 model2 loss : 0.317700
[21:49:22.832] iteration 1284 : model1 loss : 0.345513 model2 loss : 0.314642
[21:49:23.169] iteration 1285 : model1 loss : 0.367423 model2 loss : 0.357200
[21:49:23.504] iteration 1286 : model1 loss : 0.358186 model2 loss : 0.397948
[21:49:23.840] iteration 1287 : model1 loss : 0.335391 model2 loss : 0.277200
[21:49:24.176] iteration 1288 : model1 loss : 0.339791 model2 loss : 0.310829
[21:49:24.513] iteration 1289 : model1 loss : 0.340443 model2 loss : 0.290191
[21:49:24.845] iteration 1290 : model1 loss : 0.318546 model2 loss : 0.230330
[21:49:25.178] iteration 1291 : model1 loss : 0.386652 model2 loss : 0.361343
[21:49:25.512] iteration 1292 : model1 loss : 0.332713 model2 loss : 0.271914
[21:49:25.845] iteration 1293 : model1 loss : 0.328950 model2 loss : 0.262779
[21:49:26.178] iteration 1294 : model1 loss : 0.286308 model2 loss : 0.302753
[21:49:26.515] iteration 1295 : model1 loss : 0.319366 model2 loss : 0.272810
[21:49:26.848] iteration 1296 : model1 loss : 0.324361 model2 loss : 0.301665
[21:49:27.183] iteration 1297 : model1 loss : 0.345850 model2 loss : 0.289938
[21:49:27.520] iteration 1298 : model1 loss : 0.346244 model2 loss : 0.300727
[21:49:27.857] iteration 1299 : model1 loss : 0.341819 model2 loss : 0.256158
[21:49:28.191] iteration 1300 : model1 loss : 0.373817 model2 loss : 0.314744
[21:49:28.863] iteration 1301 : model1 loss : 0.332777 model2 loss : 0.222084
[21:49:29.196] iteration 1302 : model1 loss : 0.406123 model2 loss : 0.391609
[21:49:29.529] iteration 1303 : model1 loss : 0.435015 model2 loss : 0.426964
[21:49:29.866] iteration 1304 : model1 loss : 0.372218 model2 loss : 0.352271
[21:49:30.203] iteration 1305 : model1 loss : 0.330025 model2 loss : 0.249129
[21:49:30.539] iteration 1306 : model1 loss : 0.355799 model2 loss : 0.389330
[21:49:30.874] iteration 1307 : model1 loss : 0.411480 model2 loss : 0.405440
[21:49:31.207] iteration 1308 : model1 loss : 0.429842 model2 loss : 0.385980
[21:49:31.543] iteration 1309 : model1 loss : 0.376209 model2 loss : 0.340063
[21:49:31.878] iteration 1310 : model1 loss : 0.359851 model2 loss : 0.295490
[21:49:32.213] iteration 1311 : model1 loss : 0.385975 model2 loss : 0.279919
[21:49:32.548] iteration 1312 : model1 loss : 0.412354 model2 loss : 0.378880
[21:49:32.888] iteration 1313 : model1 loss : 0.326647 model2 loss : 0.328405
[21:49:33.225] iteration 1314 : model1 loss : 0.271563 model2 loss : 0.239470
[21:49:33.562] iteration 1315 : model1 loss : 0.312499 model2 loss : 0.234338
[21:49:33.896] iteration 1316 : model1 loss : 0.487807 model2 loss : 0.435292
[21:49:34.236] iteration 1317 : model1 loss : 0.382506 model2 loss : 0.282144
[21:49:34.569] iteration 1318 : model1 loss : 0.489234 model2 loss : 0.354952
[21:49:34.903] iteration 1319 : model1 loss : 0.501474 model2 loss : 0.369630
[21:49:35.239] iteration 1320 : model1 loss : 0.329921 model2 loss : 0.316714
[21:49:35.573] iteration 1321 : model1 loss : 0.386482 model2 loss : 0.371642
[21:49:35.906] iteration 1322 : model1 loss : 0.408153 model2 loss : 0.375511
[21:49:36.243] iteration 1323 : model1 loss : 0.398690 model2 loss : 0.288603
[21:49:36.581] iteration 1324 : model1 loss : 0.355144 model2 loss : 0.330203
[21:49:36.917] iteration 1325 : model1 loss : 0.351218 model2 loss : 0.296196
[21:49:37.251] iteration 1326 : model1 loss : 0.314328 model2 loss : 0.307426
[21:49:37.589] iteration 1327 : model1 loss : 0.376931 model2 loss : 0.341682
[21:49:37.927] iteration 1328 : model1 loss : 0.332934 model2 loss : 0.260429
[21:49:38.267] iteration 1329 : model1 loss : 0.338750 model2 loss : 0.244115
[21:49:38.603] iteration 1330 : model1 loss : 0.346535 model2 loss : 0.303596
[21:49:38.938] iteration 1331 : model1 loss : 0.341890 model2 loss : 0.252818
[21:49:39.274] iteration 1332 : model1 loss : 0.362152 model2 loss : 0.322871
[21:49:39.611] iteration 1333 : model1 loss : 0.356185 model2 loss : 0.292899
[21:49:39.948] iteration 1334 : model1 loss : 0.287410 model2 loss : 0.211435
[21:49:40.285] iteration 1335 : model1 loss : 0.378076 model2 loss : 0.303632
[21:49:40.623] iteration 1336 : model1 loss : 0.352030 model2 loss : 0.333645
[21:49:40.959] iteration 1337 : model1 loss : 0.314893 model2 loss : 0.232477
[21:49:41.297] iteration 1338 : model1 loss : 0.408422 model2 loss : 0.391792
[21:49:41.634] iteration 1339 : model1 loss : 0.330567 model2 loss : 0.265353
[21:49:41.970] iteration 1340 : model1 loss : 0.409794 model2 loss : 0.354570
[21:49:42.320] iteration 1341 : model1 loss : 0.413844 model2 loss : 0.324017
[21:49:42.650] iteration 1342 : model1 loss : 0.352371 model2 loss : 0.323768
[21:49:42.986] iteration 1343 : model1 loss : 0.375094 model2 loss : 0.356103
[21:49:43.323] iteration 1344 : model1 loss : 0.360995 model2 loss : 0.314556
[21:49:43.659] iteration 1345 : model1 loss : 0.351607 model2 loss : 0.264046
[21:49:43.994] iteration 1346 : model1 loss : 0.335674 model2 loss : 0.317355
[21:49:44.330] iteration 1347 : model1 loss : 0.333810 model2 loss : 0.259950
[21:49:44.666] iteration 1348 : model1 loss : 0.370170 model2 loss : 0.344195
[21:49:45.005] iteration 1349 : model1 loss : 0.331790 model2 loss : 0.320788
[21:49:45.341] iteration 1350 : model1 loss : 0.357938 model2 loss : 0.273681
[21:49:46.017] iteration 1351 : model1 loss : 0.321043 model2 loss : 0.293396
[21:49:46.355] iteration 1352 : model1 loss : 0.335962 model2 loss : 0.248331
[21:49:46.691] iteration 1353 : model1 loss : 0.348413 model2 loss : 0.258606
[21:49:47.027] iteration 1354 : model1 loss : 0.393416 model2 loss : 0.374337
[21:49:47.363] iteration 1355 : model1 loss : 0.321099 model2 loss : 0.248933
[21:49:47.705] iteration 1356 : model1 loss : 0.336821 model2 loss : 0.238144
[21:49:48.041] iteration 1357 : model1 loss : 0.445083 model2 loss : 0.354470
[21:49:48.377] iteration 1358 : model1 loss : 0.377036 model2 loss : 0.316995
[21:49:48.714] iteration 1359 : model1 loss : 0.355026 model2 loss : 0.273786
[21:49:49.050] iteration 1360 : model1 loss : 0.277774 model2 loss : 0.238678
[21:49:49.387] iteration 1361 : model1 loss : 0.334195 model2 loss : 0.303356
[21:49:49.722] iteration 1362 : model1 loss : 0.325397 model2 loss : 0.299430
[21:49:50.058] iteration 1363 : model1 loss : 0.364132 model2 loss : 0.358949
[21:49:50.394] iteration 1364 : model1 loss : 0.294984 model2 loss : 0.240180
[21:49:50.732] iteration 1365 : model1 loss : 0.375555 model2 loss : 0.312361
[21:49:51.068] iteration 1366 : model1 loss : 0.340743 model2 loss : 0.304413
[21:49:51.405] iteration 1367 : model1 loss : 0.407249 model2 loss : 0.361474
[21:49:51.741] iteration 1368 : model1 loss : 0.415463 model2 loss : 0.339926
[21:49:52.078] iteration 1369 : model1 loss : 0.335948 model2 loss : 0.301222
[21:49:52.414] iteration 1370 : model1 loss : 0.347881 model2 loss : 0.315137
[21:49:52.750] iteration 1371 : model1 loss : 0.295085 model2 loss : 0.252324
[21:49:53.087] iteration 1372 : model1 loss : 0.345109 model2 loss : 0.281384
[21:49:53.427] iteration 1373 : model1 loss : 0.318367 model2 loss : 0.306950
[21:49:53.766] iteration 1374 : model1 loss : 0.307021 model2 loss : 0.251835
[21:49:54.102] iteration 1375 : model1 loss : 0.372751 model2 loss : 0.342757
[21:49:54.436] iteration 1376 : model1 loss : 0.489707 model2 loss : 0.373390
[21:49:54.772] iteration 1377 : model1 loss : 0.333009 model2 loss : 0.238589
[21:49:55.110] iteration 1378 : model1 loss : 0.265953 model2 loss : 0.184802
[21:49:55.446] iteration 1379 : model1 loss : 0.322416 model2 loss : 0.293323
[21:49:55.785] iteration 1380 : model1 loss : 0.255205 model2 loss : 0.243639
[21:49:56.122] iteration 1381 : model1 loss : 0.315491 model2 loss : 0.243242
[21:49:56.458] iteration 1382 : model1 loss : 0.372090 model2 loss : 0.353502
[21:49:56.797] iteration 1383 : model1 loss : 0.313866 model2 loss : 0.288328
[21:49:57.134] iteration 1384 : model1 loss : 0.367789 model2 loss : 0.302545
[21:49:57.473] iteration 1385 : model1 loss : 0.363312 model2 loss : 0.339666
[21:49:57.809] iteration 1386 : model1 loss : 0.392172 model2 loss : 0.300679
[21:49:58.145] iteration 1387 : model1 loss : 0.354350 model2 loss : 0.366247
[21:49:58.485] iteration 1388 : model1 loss : 0.391314 model2 loss : 0.334612
[21:49:58.823] iteration 1389 : model1 loss : 0.273438 model2 loss : 0.308902
[21:49:59.160] iteration 1390 : model1 loss : 0.407278 model2 loss : 0.384181
[21:49:59.497] iteration 1391 : model1 loss : 0.439285 model2 loss : 0.353719
[21:49:59.835] iteration 1392 : model1 loss : 0.406049 model2 loss : 0.347605
[21:50:00.172] iteration 1393 : model1 loss : 0.369956 model2 loss : 0.305619
[21:50:00.509] iteration 1394 : model1 loss : 0.357456 model2 loss : 0.346351
[21:50:00.846] iteration 1395 : model1 loss : 0.375414 model2 loss : 0.379645
[21:50:01.182] iteration 1396 : model1 loss : 0.356889 model2 loss : 0.343054
[21:50:01.518] iteration 1397 : model1 loss : 0.381505 model2 loss : 0.385918
[21:50:01.853] iteration 1398 : model1 loss : 0.355072 model2 loss : 0.254665
[21:50:02.190] iteration 1399 : model1 loss : 0.344296 model2 loss : 0.279274
[21:50:02.528] iteration 1400 : model1 loss : 0.390073 model2 loss : 0.344759
[21:50:03.170] iteration 1401 : model1 loss : 0.358732 model2 loss : 0.318790
[21:50:03.506] iteration 1402 : model1 loss : 0.338062 model2 loss : 0.328673
[21:50:03.846] iteration 1403 : model1 loss : 0.340261 model2 loss : 0.311943
[21:50:04.184] iteration 1404 : model1 loss : 0.302604 model2 loss : 0.335551
[21:50:04.519] iteration 1405 : model1 loss : 0.415302 model2 loss : 0.428779
[21:50:04.856] iteration 1406 : model1 loss : 0.374289 model2 loss : 0.318245
[21:50:05.193] iteration 1407 : model1 loss : 0.319474 model2 loss : 0.284337
[21:50:05.533] iteration 1408 : model1 loss : 0.353199 model2 loss : 0.363346
[21:50:05.867] iteration 1409 : model1 loss : 0.280257 model2 loss : 0.228794
[21:50:06.204] iteration 1410 : model1 loss : 0.446469 model2 loss : 0.412830
[21:50:06.542] iteration 1411 : model1 loss : 0.378106 model2 loss : 0.332874
[21:50:06.880] iteration 1412 : model1 loss : 0.354701 model2 loss : 0.318016
[21:50:07.217] iteration 1413 : model1 loss : 0.401665 model2 loss : 0.350690
[21:50:07.554] iteration 1414 : model1 loss : 0.401367 model2 loss : 0.336134
[21:50:07.892] iteration 1415 : model1 loss : 0.288555 model2 loss : 0.209009
[21:50:08.230] iteration 1416 : model1 loss : 0.373821 model2 loss : 0.326311
[21:50:08.567] iteration 1417 : model1 loss : 0.386230 model2 loss : 0.366163
[21:50:08.905] iteration 1418 : model1 loss : 0.370035 model2 loss : 0.330240
[21:50:09.243] iteration 1419 : model1 loss : 0.269616 model2 loss : 0.232240
[21:50:09.581] iteration 1420 : model1 loss : 0.291786 model2 loss : 0.243674
[21:50:09.921] iteration 1421 : model1 loss : 0.407118 model2 loss : 0.336118
[21:50:10.259] iteration 1422 : model1 loss : 0.302964 model2 loss : 0.282182
[21:50:10.598] iteration 1423 : model1 loss : 0.364318 model2 loss : 0.271200
[21:50:10.939] iteration 1424 : model1 loss : 0.351933 model2 loss : 0.310945
[21:50:11.277] iteration 1425 : model1 loss : 0.326962 model2 loss : 0.294724
[21:50:11.615] iteration 1426 : model1 loss : 0.449774 model2 loss : 0.376045
[21:50:11.953] iteration 1427 : model1 loss : 0.297790 model2 loss : 0.215981
[21:50:12.292] iteration 1428 : model1 loss : 0.340352 model2 loss : 0.210715
[21:50:12.630] iteration 1429 : model1 loss : 0.371097 model2 loss : 0.277285
[21:50:12.968] iteration 1430 : model1 loss : 0.353092 model2 loss : 0.275560
[21:50:13.306] iteration 1431 : model1 loss : 0.359897 model2 loss : 0.318974
[21:50:13.644] iteration 1432 : model1 loss : 0.321168 model2 loss : 0.289842
[21:50:13.980] iteration 1433 : model1 loss : 0.372829 model2 loss : 0.298604
[21:50:14.318] iteration 1434 : model1 loss : 0.361808 model2 loss : 0.336749
[21:50:14.655] iteration 1435 : model1 loss : 0.341436 model2 loss : 0.305476
[21:50:14.995] iteration 1436 : model1 loss : 0.335432 model2 loss : 0.257395
[21:50:15.332] iteration 1437 : model1 loss : 0.353890 model2 loss : 0.353897
[21:50:15.673] iteration 1438 : model1 loss : 0.379053 model2 loss : 0.399222
[21:50:16.011] iteration 1439 : model1 loss : 0.283468 model2 loss : 0.200028
[21:50:16.350] iteration 1440 : model1 loss : 0.275629 model2 loss : 0.257876
[21:50:16.689] iteration 1441 : model1 loss : 0.431676 model2 loss : 0.378731
[21:50:17.021] iteration 1442 : model1 loss : 0.255871 model2 loss : 0.249016
[21:50:17.350] iteration 1443 : model1 loss : 0.259955 model2 loss : 0.273614
[21:50:17.679] iteration 1444 : model1 loss : 0.340787 model2 loss : 0.295555
[21:50:18.006] iteration 1445 : model1 loss : 0.337360 model2 loss : 0.320610
[21:50:18.335] iteration 1446 : model1 loss : 0.306020 model2 loss : 0.220935
[21:50:18.664] iteration 1447 : model1 loss : 0.399832 model2 loss : 0.271695
[21:50:18.992] iteration 1448 : model1 loss : 0.422322 model2 loss : 0.375734
[21:50:19.318] iteration 1449 : model1 loss : 0.369430 model2 loss : 0.295491
[21:50:19.655] iteration 1450 : model1 loss : 0.284774 model2 loss : 0.336487
[21:50:20.346] iteration 1451 : model1 loss : 0.358684 model2 loss : 0.329734
[21:50:20.684] iteration 1452 : model1 loss : 0.300992 model2 loss : 0.282588
[21:50:21.021] iteration 1453 : model1 loss : 0.277056 model2 loss : 0.280763
[21:50:21.364] iteration 1454 : model1 loss : 0.357969 model2 loss : 0.243557
[21:50:21.697] iteration 1455 : model1 loss : 0.567549 model2 loss : 0.333599
[21:50:22.034] iteration 1456 : model1 loss : 0.342229 model2 loss : 0.334148
[21:50:22.373] iteration 1457 : model1 loss : 0.389726 model2 loss : 0.385119
[21:50:22.712] iteration 1458 : model1 loss : 0.311154 model2 loss : 0.235090
[21:50:23.071] iteration 1459 : model1 loss : 0.294334 model2 loss : 0.241220
[21:50:23.406] iteration 1460 : model1 loss : 0.350907 model2 loss : 0.308413
[21:50:23.741] iteration 1461 : model1 loss : 0.344184 model2 loss : 0.272363
[21:50:24.079] iteration 1462 : model1 loss : 0.345405 model2 loss : 0.342903
[21:50:24.415] iteration 1463 : model1 loss : 0.388693 model2 loss : 0.340175
[21:50:24.753] iteration 1464 : model1 loss : 0.299787 model2 loss : 0.284468
[21:50:25.089] iteration 1465 : model1 loss : 0.316996 model2 loss : 0.289165
[21:50:25.425] iteration 1466 : model1 loss : 0.336336 model2 loss : 0.285075
[21:50:25.762] iteration 1467 : model1 loss : 0.427404 model2 loss : 0.429237
[21:50:26.100] iteration 1468 : model1 loss : 0.400421 model2 loss : 0.387199
[21:50:26.435] iteration 1469 : model1 loss : 0.387586 model2 loss : 0.417261
[21:50:26.770] iteration 1470 : model1 loss : 0.277175 model2 loss : 0.236891
[21:50:27.107] iteration 1471 : model1 loss : 0.272637 model2 loss : 0.253631
[21:50:27.453] iteration 1472 : model1 loss : 0.319226 model2 loss : 0.263549
[21:50:27.780] iteration 1473 : model1 loss : 0.345847 model2 loss : 0.307600
[21:50:28.110] iteration 1474 : model1 loss : 0.323914 model2 loss : 0.258401
[21:50:28.439] iteration 1475 : model1 loss : 0.350891 model2 loss : 0.334515
[21:50:28.767] iteration 1476 : model1 loss : 0.372036 model2 loss : 0.303532
[21:50:29.091] iteration 1477 : model1 loss : 0.364454 model2 loss : 0.352546
[21:50:29.421] iteration 1478 : model1 loss : 0.409631 model2 loss : 0.381065
[21:50:29.752] iteration 1479 : model1 loss : 0.330756 model2 loss : 0.302945
[21:50:30.080] iteration 1480 : model1 loss : 0.344218 model2 loss : 0.303550
[21:50:30.403] iteration 1481 : model1 loss : 0.394042 model2 loss : 0.321508
[21:50:30.733] iteration 1482 : model1 loss : 0.334328 model2 loss : 0.302362
[21:50:31.062] iteration 1483 : model1 loss : 0.335775 model2 loss : 0.332981
[21:50:31.385] iteration 1484 : model1 loss : 0.361118 model2 loss : 0.355270
[21:50:31.708] iteration 1485 : model1 loss : 0.426544 model2 loss : 0.322303
[21:50:32.038] iteration 1486 : model1 loss : 0.326684 model2 loss : 0.296972
[21:50:32.367] iteration 1487 : model1 loss : 0.348609 model2 loss : 0.311510
[21:50:32.692] iteration 1488 : model1 loss : 0.270120 model2 loss : 0.235630
[21:50:33.015] iteration 1489 : model1 loss : 0.340397 model2 loss : 0.349793
[21:50:33.342] iteration 1490 : model1 loss : 0.326322 model2 loss : 0.264953
[21:50:33.670] iteration 1491 : model1 loss : 0.368185 model2 loss : 0.306181
[21:50:33.992] iteration 1492 : model1 loss : 0.362932 model2 loss : 0.320796
[21:50:34.312] iteration 1493 : model1 loss : 0.346134 model2 loss : 0.326549
[21:50:34.641] iteration 1494 : model1 loss : 0.322767 model2 loss : 0.301617
[21:50:34.968] iteration 1495 : model1 loss : 0.475141 model2 loss : 0.424315
[21:50:35.294] iteration 1496 : model1 loss : 0.328214 model2 loss : 0.306421
[21:50:35.618] iteration 1497 : model1 loss : 0.329895 model2 loss : 0.240915
[21:50:35.945] iteration 1498 : model1 loss : 0.343611 model2 loss : 0.283838
[21:50:36.272] iteration 1499 : model1 loss : 0.392952 model2 loss : 0.362514
[21:50:36.597] iteration 1500 : model1 loss : 0.388162 model2 loss : 0.365732
[21:50:37.134] iteration 1501 : model1 loss : 0.350746 model2 loss : 0.305784
[21:50:37.461] iteration 1502 : model1 loss : 0.299902 model2 loss : 0.277324
[21:50:37.788] iteration 1503 : model1 loss : 0.333344 model2 loss : 0.274101
[21:50:38.114] iteration 1504 : model1 loss : 0.356271 model2 loss : 0.296869
[21:50:38.440] iteration 1505 : model1 loss : 0.276475 model2 loss : 0.207140
[21:50:38.768] iteration 1506 : model1 loss : 0.321759 model2 loss : 0.301986
[21:50:39.096] iteration 1507 : model1 loss : 0.401703 model2 loss : 0.401904
[21:50:39.421] iteration 1508 : model1 loss : 0.302663 model2 loss : 0.277475
[21:50:39.741] iteration 1509 : model1 loss : 0.427269 model2 loss : 0.332758
[21:50:40.070] iteration 1510 : model1 loss : 0.296423 model2 loss : 0.212962
[21:50:40.391] iteration 1511 : model1 loss : 0.350236 model2 loss : 0.339636
[21:50:40.717] iteration 1512 : model1 loss : 0.354668 model2 loss : 0.328801
[21:50:41.042] iteration 1513 : model1 loss : 0.344117 model2 loss : 0.313238
[21:50:41.370] iteration 1514 : model1 loss : 0.370210 model2 loss : 0.286507
[21:50:41.696] iteration 1515 : model1 loss : 0.412462 model2 loss : 0.334947
[21:50:42.022] iteration 1516 : model1 loss : 0.375061 model2 loss : 0.236575
[21:50:42.344] iteration 1517 : model1 loss : 0.427008 model2 loss : 0.420910
[21:50:42.669] iteration 1518 : model1 loss : 0.349841 model2 loss : 0.217136
[21:50:42.995] iteration 1519 : model1 loss : 0.332022 model2 loss : 0.338119
[21:50:43.316] iteration 1520 : model1 loss : 0.306739 model2 loss : 0.224675
[21:50:43.641] iteration 1521 : model1 loss : 0.405638 model2 loss : 0.339642
[21:50:43.969] iteration 1522 : model1 loss : 0.360512 model2 loss : 0.288557
[21:50:44.292] iteration 1523 : model1 loss : 0.355013 model2 loss : 0.265321
[21:50:44.618] iteration 1524 : model1 loss : 0.356724 model2 loss : 0.320929
[21:50:44.942] iteration 1525 : model1 loss : 0.362141 model2 loss : 0.355300
[21:50:45.274] iteration 1526 : model1 loss : 0.349254 model2 loss : 0.303118
[21:50:45.602] iteration 1527 : model1 loss : 0.348709 model2 loss : 0.339865
[21:50:45.929] iteration 1528 : model1 loss : 0.279161 model2 loss : 0.277178
[21:50:46.256] iteration 1529 : model1 loss : 0.350453 model2 loss : 0.295477
[21:50:46.586] iteration 1530 : model1 loss : 0.336282 model2 loss : 0.331363
[21:50:46.913] iteration 1531 : model1 loss : 0.384789 model2 loss : 0.370406
[21:50:47.240] iteration 1532 : model1 loss : 0.382630 model2 loss : 0.416937
[21:50:47.566] iteration 1533 : model1 loss : 0.327072 model2 loss : 0.289506
[21:50:47.893] iteration 1534 : model1 loss : 0.362593 model2 loss : 0.343916
[21:50:48.221] iteration 1535 : model1 loss : 0.344188 model2 loss : 0.284590
[21:50:48.559] iteration 1536 : model1 loss : 0.365152 model2 loss : 0.338029
[21:50:48.894] iteration 1537 : model1 loss : 0.366208 model2 loss : 0.284264
[21:50:49.220] iteration 1538 : model1 loss : 0.414876 model2 loss : 0.325043
[21:50:49.547] iteration 1539 : model1 loss : 0.279360 model2 loss : 0.204642
[21:50:49.874] iteration 1540 : model1 loss : 0.397334 model2 loss : 0.332675
[21:50:50.202] iteration 1541 : model1 loss : 0.318910 model2 loss : 0.285063
[21:50:50.530] iteration 1542 : model1 loss : 0.370727 model2 loss : 0.310539
[21:50:50.859] iteration 1543 : model1 loss : 0.400088 model2 loss : 0.334098
[21:50:51.186] iteration 1544 : model1 loss : 0.355862 model2 loss : 0.324893
[21:50:51.513] iteration 1545 : model1 loss : 0.389348 model2 loss : 0.344821
[21:50:51.842] iteration 1546 : model1 loss : 0.354814 model2 loss : 0.294835
[21:50:52.170] iteration 1547 : model1 loss : 0.400348 model2 loss : 0.337818
[21:50:52.498] iteration 1548 : model1 loss : 0.359365 model2 loss : 0.286961
[21:50:52.826] iteration 1549 : model1 loss : 0.439627 model2 loss : 0.414198
[21:50:53.153] iteration 1550 : model1 loss : 0.501440 model2 loss : 0.528830
[21:50:53.702] iteration 1551 : model1 loss : 0.501946 model2 loss : 0.450219
[21:50:54.029] iteration 1552 : model1 loss : 0.306909 model2 loss : 0.271478
[21:50:54.356] iteration 1553 : model1 loss : 0.365049 model2 loss : 0.318570
[21:50:54.685] iteration 1554 : model1 loss : 0.352609 model2 loss : 0.340846
[21:50:55.013] iteration 1555 : model1 loss : 0.433707 model2 loss : 0.387226
[21:50:55.342] iteration 1556 : model1 loss : 0.384166 model2 loss : 0.290723
[21:50:55.669] iteration 1557 : model1 loss : 0.333576 model2 loss : 0.259776
[21:50:55.997] iteration 1558 : model1 loss : 0.400585 model2 loss : 0.370625
[21:50:56.324] iteration 1559 : model1 loss : 0.384415 model2 loss : 0.308341
[21:50:56.650] iteration 1560 : model1 loss : 0.372315 model2 loss : 0.306356
[21:50:56.977] iteration 1561 : model1 loss : 0.373086 model2 loss : 0.305099
[21:50:57.304] iteration 1562 : model1 loss : 0.377330 model2 loss : 0.304136
[21:50:57.632] iteration 1563 : model1 loss : 0.357685 model2 loss : 0.336950
[21:50:57.959] iteration 1564 : model1 loss : 0.386308 model2 loss : 0.387364
[21:50:58.286] iteration 1565 : model1 loss : 0.350770 model2 loss : 0.262364
[21:50:58.613] iteration 1566 : model1 loss : 0.354447 model2 loss : 0.270581
[21:50:58.940] iteration 1567 : model1 loss : 0.355814 model2 loss : 0.344801
[21:50:59.268] iteration 1568 : model1 loss : 0.353297 model2 loss : 0.338157
[21:50:59.602] iteration 1569 : model1 loss : 0.379557 model2 loss : 0.300892
[21:50:59.929] iteration 1570 : model1 loss : 0.341982 model2 loss : 0.244904
[21:51:00.256] iteration 1571 : model1 loss : 0.388789 model2 loss : 0.344583
[21:51:00.584] iteration 1572 : model1 loss : 0.391534 model2 loss : 0.385126
[21:51:00.914] iteration 1573 : model1 loss : 0.320430 model2 loss : 0.247437
[21:51:01.241] iteration 1574 : model1 loss : 0.395630 model2 loss : 0.392798
[21:51:01.569] iteration 1575 : model1 loss : 0.356914 model2 loss : 0.262204
[21:51:01.897] iteration 1576 : model1 loss : 0.391493 model2 loss : 0.312286
[21:51:02.224] iteration 1577 : model1 loss : 0.475122 model2 loss : 0.444675
[21:51:02.552] iteration 1578 : model1 loss : 0.365222 model2 loss : 0.344660
[21:51:02.879] iteration 1579 : model1 loss : 0.329221 model2 loss : 0.284444
[21:51:03.206] iteration 1580 : model1 loss : 0.371037 model2 loss : 0.344641
[21:51:03.534] iteration 1581 : model1 loss : 0.302130 model2 loss : 0.224890
[21:51:03.861] iteration 1582 : model1 loss : 0.333177 model2 loss : 0.271817
[21:51:04.189] iteration 1583 : model1 loss : 0.407374 model2 loss : 0.371673
[21:51:04.517] iteration 1584 : model1 loss : 0.336197 model2 loss : 0.324255
[21:51:04.845] iteration 1585 : model1 loss : 0.393012 model2 loss : 0.389798
[21:51:05.173] iteration 1586 : model1 loss : 0.298297 model2 loss : 0.247012
[21:51:05.502] iteration 1587 : model1 loss : 0.357347 model2 loss : 0.268927
[21:51:05.828] iteration 1588 : model1 loss : 0.361003 model2 loss : 0.375255
[21:51:06.157] iteration 1589 : model1 loss : 0.322805 model2 loss : 0.213811
[21:51:06.486] iteration 1590 : model1 loss : 0.388192 model2 loss : 0.436678
[21:51:06.813] iteration 1591 : model1 loss : 0.353102 model2 loss : 0.294301
[21:51:07.144] iteration 1592 : model1 loss : 0.249374 model2 loss : 0.225422
[21:51:07.472] iteration 1593 : model1 loss : 0.425510 model2 loss : 0.411930
[21:51:07.799] iteration 1594 : model1 loss : 0.312061 model2 loss : 0.325400
[21:51:08.128] iteration 1595 : model1 loss : 0.364630 model2 loss : 0.321083
[21:51:08.456] iteration 1596 : model1 loss : 0.373761 model2 loss : 0.387905
[21:51:08.782] iteration 1597 : model1 loss : 0.291809 model2 loss : 0.251570
[21:51:09.110] iteration 1598 : model1 loss : 0.365526 model2 loss : 0.354819
[21:51:09.440] iteration 1599 : model1 loss : 0.346148 model2 loss : 0.326918
[21:51:09.777] iteration 1600 : model1 loss : 0.303539 model2 loss : 0.250717
[21:51:10.437] iteration 1601 : model1 loss : 0.354699 model2 loss : 0.310232
[21:51:10.771] iteration 1602 : model1 loss : 0.372781 model2 loss : 0.315558
[21:51:11.108] iteration 1603 : model1 loss : 0.429217 model2 loss : 0.364678
[21:51:11.446] iteration 1604 : model1 loss : 0.270013 model2 loss : 0.196093
[21:51:11.781] iteration 1605 : model1 loss : 0.306269 model2 loss : 0.298739
[21:51:12.122] iteration 1606 : model1 loss : 0.330870 model2 loss : 0.364361
[21:51:12.460] iteration 1607 : model1 loss : 0.342683 model2 loss : 0.310829
[21:51:12.795] iteration 1608 : model1 loss : 0.335153 model2 loss : 0.286423
[21:51:13.131] iteration 1609 : model1 loss : 0.328118 model2 loss : 0.318693
[21:51:13.468] iteration 1610 : model1 loss : 0.413268 model2 loss : 0.380799
[21:51:13.804] iteration 1611 : model1 loss : 0.339068 model2 loss : 0.314453
[21:51:14.142] iteration 1612 : model1 loss : 0.355477 model2 loss : 0.338597
[21:51:14.480] iteration 1613 : model1 loss : 0.266316 model2 loss : 0.231225
[21:51:14.817] iteration 1614 : model1 loss : 0.302031 model2 loss : 0.281270
[21:51:15.153] iteration 1615 : model1 loss : 0.381375 model2 loss : 0.363111
[21:51:15.489] iteration 1616 : model1 loss : 0.418106 model2 loss : 0.416481
[21:51:15.824] iteration 1617 : model1 loss : 0.340868 model2 loss : 0.338178
[21:51:16.160] iteration 1618 : model1 loss : 0.302901 model2 loss : 0.225479
[21:51:16.496] iteration 1619 : model1 loss : 0.292384 model2 loss : 0.258813
[21:51:16.839] iteration 1620 : model1 loss : 0.335624 model2 loss : 0.322687
[21:51:17.174] iteration 1621 : model1 loss : 0.389845 model2 loss : 0.373612
[21:51:17.509] iteration 1622 : model1 loss : 0.374263 model2 loss : 0.322171
[21:51:17.845] iteration 1623 : model1 loss : 0.244306 model2 loss : 0.215576
[21:51:18.182] iteration 1624 : model1 loss : 0.374639 model2 loss : 0.315700
[21:51:18.514] iteration 1625 : model1 loss : 0.315490 model2 loss : 0.256446
[21:51:18.852] iteration 1626 : model1 loss : 0.393308 model2 loss : 0.373029
[21:51:19.190] iteration 1627 : model1 loss : 0.354805 model2 loss : 0.292820
[21:51:19.525] iteration 1628 : model1 loss : 0.247887 model2 loss : 0.235464
[21:51:19.858] iteration 1629 : model1 loss : 0.372045 model2 loss : 0.315580
[21:51:20.193] iteration 1630 : model1 loss : 0.368096 model2 loss : 0.247790
[21:51:20.526] iteration 1631 : model1 loss : 0.408443 model2 loss : 0.367863
[21:51:20.861] iteration 1632 : model1 loss : 0.370890 model2 loss : 0.316014
[21:51:21.197] iteration 1633 : model1 loss : 0.343095 model2 loss : 0.254603
[21:51:21.533] iteration 1634 : model1 loss : 0.305259 model2 loss : 0.248877
[21:51:21.868] iteration 1635 : model1 loss : 0.342311 model2 loss : 0.288662
[21:51:22.818] iteration 1636 : model1 loss : 0.309647 model2 loss : 0.301500
[21:51:23.155] iteration 1637 : model1 loss : 0.342077 model2 loss : 0.301132
[21:51:23.491] iteration 1638 : model1 loss : 0.474275 model2 loss : 0.450501
[21:51:23.827] iteration 1639 : model1 loss : 0.302142 model2 loss : 0.240558
[21:51:24.164] iteration 1640 : model1 loss : 0.330608 model2 loss : 0.271505
[21:51:24.500] iteration 1641 : model1 loss : 0.374214 model2 loss : 0.377794
[21:51:24.838] iteration 1642 : model1 loss : 0.328194 model2 loss : 0.297207
[21:51:25.174] iteration 1643 : model1 loss : 0.294776 model2 loss : 0.254951
[21:51:25.510] iteration 1644 : model1 loss : 0.314768 model2 loss : 0.290215
[21:51:25.846] iteration 1645 : model1 loss : 0.242056 model2 loss : 0.195398
[21:51:26.182] iteration 1646 : model1 loss : 0.339456 model2 loss : 0.313583
[21:51:26.521] iteration 1647 : model1 loss : 0.305315 model2 loss : 0.211758
[21:51:26.858] iteration 1648 : model1 loss : 0.397923 model2 loss : 0.395409
[21:51:27.195] iteration 1649 : model1 loss : 0.319338 model2 loss : 0.335404
[21:51:27.530] iteration 1650 : model1 loss : 0.396061 model2 loss : 0.304206
[21:51:28.133] iteration 1651 : model1 loss : 0.243569 model2 loss : 0.196476
[21:51:28.470] iteration 1652 : model1 loss : 0.353652 model2 loss : 0.334219
[21:51:28.804] iteration 1653 : model1 loss : 0.346583 model2 loss : 0.354106
[21:51:29.140] iteration 1654 : model1 loss : 0.392446 model2 loss : 0.418351
[21:51:29.479] iteration 1655 : model1 loss : 0.341934 model2 loss : 0.299201
[21:51:29.819] iteration 1656 : model1 loss : 0.402776 model2 loss : 0.366891
[21:51:30.154] iteration 1657 : model1 loss : 0.384854 model2 loss : 0.310454
[21:51:30.494] iteration 1658 : model1 loss : 0.352140 model2 loss : 0.286850
[21:51:30.829] iteration 1659 : model1 loss : 0.381281 model2 loss : 0.315520
[21:51:31.165] iteration 1660 : model1 loss : 0.328244 model2 loss : 0.296164
[21:51:31.509] iteration 1661 : model1 loss : 0.313389 model2 loss : 0.284258
[21:51:31.842] iteration 1662 : model1 loss : 0.354812 model2 loss : 0.393436
[21:51:32.169] iteration 1663 : model1 loss : 0.365331 model2 loss : 0.311525
[21:51:32.498] iteration 1664 : model1 loss : 0.293169 model2 loss : 0.244779
[21:51:32.834] iteration 1665 : model1 loss : 0.292561 model2 loss : 0.291593
[21:51:33.171] iteration 1666 : model1 loss : 0.354842 model2 loss : 0.332831
[21:51:33.507] iteration 1667 : model1 loss : 0.385285 model2 loss : 0.314724
[21:51:33.844] iteration 1668 : model1 loss : 0.312947 model2 loss : 0.307336
[21:51:34.180] iteration 1669 : model1 loss : 0.297222 model2 loss : 0.316040
[21:51:34.516] iteration 1670 : model1 loss : 0.245052 model2 loss : 0.219886
[21:51:34.852] iteration 1671 : model1 loss : 0.374195 model2 loss : 0.398626
[21:51:35.188] iteration 1672 : model1 loss : 0.361796 model2 loss : 0.293151
[21:51:35.525] iteration 1673 : model1 loss : 0.399575 model2 loss : 0.368111
[21:51:35.863] iteration 1674 : model1 loss : 0.286709 model2 loss : 0.264056
[21:51:36.192] iteration 1675 : model1 loss : 0.366265 model2 loss : 0.334496
[21:51:36.524] iteration 1676 : model1 loss : 0.400524 model2 loss : 0.406685
[21:51:36.852] iteration 1677 : model1 loss : 0.372280 model2 loss : 0.318628
[21:51:37.180] iteration 1678 : model1 loss : 0.390449 model2 loss : 0.306037
[21:51:37.508] iteration 1679 : model1 loss : 0.453305 model2 loss : 0.427433
[21:51:37.835] iteration 1680 : model1 loss : 0.375122 model2 loss : 0.338965
[21:51:38.163] iteration 1681 : model1 loss : 0.284790 model2 loss : 0.284038
[21:51:38.491] iteration 1682 : model1 loss : 0.301874 model2 loss : 0.255699
[21:51:38.819] iteration 1683 : model1 loss : 0.408728 model2 loss : 0.362806
[21:51:39.147] iteration 1684 : model1 loss : 0.287395 model2 loss : 0.184445
[21:51:39.476] iteration 1685 : model1 loss : 0.348589 model2 loss : 0.330207
[21:51:39.803] iteration 1686 : model1 loss : 0.428177 model2 loss : 0.437297
[21:51:40.131] iteration 1687 : model1 loss : 0.326222 model2 loss : 0.269315
[21:51:40.460] iteration 1688 : model1 loss : 0.298184 model2 loss : 0.260619
[21:51:40.787] iteration 1689 : model1 loss : 0.350470 model2 loss : 0.264862
[21:51:41.115] iteration 1690 : model1 loss : 0.351684 model2 loss : 0.308916
[21:51:41.443] iteration 1691 : model1 loss : 0.385000 model2 loss : 0.362644
[21:51:41.772] iteration 1692 : model1 loss : 0.338562 model2 loss : 0.331104
[21:51:42.100] iteration 1693 : model1 loss : 0.409367 model2 loss : 0.402988
[21:51:42.428] iteration 1694 : model1 loss : 0.304903 model2 loss : 0.304690
[21:51:42.756] iteration 1695 : model1 loss : 0.397199 model2 loss : 0.363500
[21:51:43.087] iteration 1696 : model1 loss : 0.445734 model2 loss : 0.363094
[21:51:43.415] iteration 1697 : model1 loss : 0.333368 model2 loss : 0.309184
[21:51:43.744] iteration 1698 : model1 loss : 0.466544 model2 loss : 0.413850
[21:51:44.071] iteration 1699 : model1 loss : 0.292364 model2 loss : 0.249572
[21:51:44.399] iteration 1700 : model1 loss : 0.387032 model2 loss : 0.370328
[21:51:44.957] iteration 1701 : model1 loss : 0.317628 model2 loss : 0.296686
[21:51:45.286] iteration 1702 : model1 loss : 0.406069 model2 loss : 0.272338
[21:51:45.615] iteration 1703 : model1 loss : 0.314809 model2 loss : 0.283327
[21:51:45.943] iteration 1704 : model1 loss : 0.345865 model2 loss : 0.354599
[21:51:46.271] iteration 1705 : model1 loss : 0.249906 model2 loss : 0.193995
[21:51:46.599] iteration 1706 : model1 loss : 0.367894 model2 loss : 0.303991
[21:51:46.928] iteration 1707 : model1 loss : 0.334949 model2 loss : 0.291408
[21:51:47.256] iteration 1708 : model1 loss : 0.452087 model2 loss : 0.398052
[21:51:47.585] iteration 1709 : model1 loss : 0.355951 model2 loss : 0.293216
[21:51:47.924] iteration 1710 : model1 loss : 0.319005 model2 loss : 0.251020
[21:51:48.262] iteration 1711 : model1 loss : 0.351671 model2 loss : 0.327931
[21:51:48.600] iteration 1712 : model1 loss : 0.389173 model2 loss : 0.373652
[21:51:48.938] iteration 1713 : model1 loss : 0.286475 model2 loss : 0.234604
[21:51:49.276] iteration 1714 : model1 loss : 0.372215 model2 loss : 0.312189
[21:51:49.615] iteration 1715 : model1 loss : 0.341549 model2 loss : 0.296274
[21:51:49.953] iteration 1716 : model1 loss : 0.392151 model2 loss : 0.374590
[21:51:50.292] iteration 1717 : model1 loss : 0.216241 model2 loss : 0.203584
[21:51:50.631] iteration 1718 : model1 loss : 0.336823 model2 loss : 0.327897
[21:51:50.969] iteration 1719 : model1 loss : 0.367899 model2 loss : 0.333787
[21:51:51.307] iteration 1720 : model1 loss : 0.324590 model2 loss : 0.285506
[21:51:51.649] iteration 1721 : model1 loss : 0.347057 model2 loss : 0.286597
[21:51:51.990] iteration 1722 : model1 loss : 0.414373 model2 loss : 0.434887
[21:51:52.330] iteration 1723 : model1 loss : 0.361181 model2 loss : 0.335370
[21:51:52.668] iteration 1724 : model1 loss : 0.361378 model2 loss : 0.336192
[21:51:53.007] iteration 1725 : model1 loss : 0.305770 model2 loss : 0.248289
[21:51:53.347] iteration 1726 : model1 loss : 0.313872 model2 loss : 0.257475
[21:51:53.686] iteration 1727 : model1 loss : 0.319026 model2 loss : 0.300615
[21:51:54.025] iteration 1728 : model1 loss : 0.322412 model2 loss : 0.282327
[21:51:54.364] iteration 1729 : model1 loss : 0.269535 model2 loss : 0.226023
[21:51:54.703] iteration 1730 : model1 loss : 0.432031 model2 loss : 0.439253
[21:51:55.042] iteration 1731 : model1 loss : 0.307648 model2 loss : 0.298781
[21:51:55.380] iteration 1732 : model1 loss : 0.280239 model2 loss : 0.255607
[21:51:55.718] iteration 1733 : model1 loss : 0.326707 model2 loss : 0.329334
[21:51:56.056] iteration 1734 : model1 loss : 0.295767 model2 loss : 0.250568
[21:51:56.397] iteration 1735 : model1 loss : 0.322700 model2 loss : 0.282018
[21:51:56.737] iteration 1736 : model1 loss : 0.272777 model2 loss : 0.254155
[21:51:57.081] iteration 1737 : model1 loss : 0.386396 model2 loss : 0.393476
[21:51:57.423] iteration 1738 : model1 loss : 0.355656 model2 loss : 0.269700
[21:51:57.761] iteration 1739 : model1 loss : 0.341129 model2 loss : 0.328794
[21:51:58.098] iteration 1740 : model1 loss : 0.318942 model2 loss : 0.253777
[21:51:58.437] iteration 1741 : model1 loss : 0.350995 model2 loss : 0.311979
[21:51:58.775] iteration 1742 : model1 loss : 0.380317 model2 loss : 0.321721
[21:51:59.115] iteration 1743 : model1 loss : 0.351012 model2 loss : 0.329250
[21:51:59.452] iteration 1744 : model1 loss : 0.335356 model2 loss : 0.317729
[21:51:59.789] iteration 1745 : model1 loss : 0.326013 model2 loss : 0.282950
[21:52:00.127] iteration 1746 : model1 loss : 0.425349 model2 loss : 0.445185
[21:52:00.466] iteration 1747 : model1 loss : 0.332259 model2 loss : 0.274217
[21:52:00.804] iteration 1748 : model1 loss : 0.293867 model2 loss : 0.302860
[21:52:01.140] iteration 1749 : model1 loss : 0.367169 model2 loss : 0.387129
[21:52:01.477] iteration 1750 : model1 loss : 0.361925 model2 loss : 0.310320
[21:52:02.128] iteration 1751 : model1 loss : 0.289172 model2 loss : 0.296699
[21:52:02.469] iteration 1752 : model1 loss : 0.408988 model2 loss : 0.360487
[21:52:02.809] iteration 1753 : model1 loss : 0.324856 model2 loss : 0.294488
[21:52:03.151] iteration 1754 : model1 loss : 0.375206 model2 loss : 0.294451
[21:52:03.497] iteration 1755 : model1 loss : 0.503491 model2 loss : 0.468936
[21:52:03.827] iteration 1756 : model1 loss : 0.343993 model2 loss : 0.316385
[21:52:04.157] iteration 1757 : model1 loss : 0.312169 model2 loss : 0.287138
[21:52:04.486] iteration 1758 : model1 loss : 0.346622 model2 loss : 0.291296
[21:52:04.815] iteration 1759 : model1 loss : 0.380881 model2 loss : 0.317527
[21:52:05.144] iteration 1760 : model1 loss : 0.319234 model2 loss : 0.300829
[21:52:05.474] iteration 1761 : model1 loss : 0.346971 model2 loss : 0.326091
[21:52:05.803] iteration 1762 : model1 loss : 0.307187 model2 loss : 0.301668
[21:52:06.140] iteration 1763 : model1 loss : 0.345120 model2 loss : 0.341490
[21:52:06.477] iteration 1764 : model1 loss : 0.309416 model2 loss : 0.286135
[21:52:06.815] iteration 1765 : model1 loss : 0.290064 model2 loss : 0.187445
[21:52:07.153] iteration 1766 : model1 loss : 0.312968 model2 loss : 0.301350
[21:52:07.491] iteration 1767 : model1 loss : 0.317922 model2 loss : 0.297182
[21:52:07.828] iteration 1768 : model1 loss : 0.354592 model2 loss : 0.314051
[21:52:08.168] iteration 1769 : model1 loss : 0.353034 model2 loss : 0.335958
[21:52:08.510] iteration 1770 : model1 loss : 0.361626 model2 loss : 0.275668
[21:52:08.855] iteration 1771 : model1 loss : 0.370112 model2 loss : 0.306216
[21:52:09.197] iteration 1772 : model1 loss : 0.446751 model2 loss : 0.392808
[21:52:09.535] iteration 1773 : model1 loss : 0.328157 model2 loss : 0.289778
[21:52:09.872] iteration 1774 : model1 loss : 0.295498 model2 loss : 0.290241
[21:52:10.210] iteration 1775 : model1 loss : 0.403785 model2 loss : 0.360898
[21:52:10.548] iteration 1776 : model1 loss : 0.332222 model2 loss : 0.366649
[21:52:10.886] iteration 1777 : model1 loss : 0.308129 model2 loss : 0.249939
[21:52:11.228] iteration 1778 : model1 loss : 0.331702 model2 loss : 0.298998
[21:52:11.566] iteration 1779 : model1 loss : 0.300116 model2 loss : 0.276654
[21:52:11.903] iteration 1780 : model1 loss : 0.344912 model2 loss : 0.338512
[21:52:12.238] iteration 1781 : model1 loss : 0.339573 model2 loss : 0.326850
[21:52:12.575] iteration 1782 : model1 loss : 0.356603 model2 loss : 0.346496
[21:52:12.913] iteration 1783 : model1 loss : 0.312614 model2 loss : 0.264871
[21:52:13.246] iteration 1784 : model1 loss : 0.373517 model2 loss : 0.370396
[21:52:13.580] iteration 1785 : model1 loss : 0.341231 model2 loss : 0.319008
[21:52:13.916] iteration 1786 : model1 loss : 0.325883 model2 loss : 0.242601
[21:52:14.256] iteration 1787 : model1 loss : 0.399760 model2 loss : 0.330391
[21:52:14.598] iteration 1788 : model1 loss : 0.302794 model2 loss : 0.286128
[21:52:14.934] iteration 1789 : model1 loss : 0.389105 model2 loss : 0.320126
[21:52:15.271] iteration 1790 : model1 loss : 0.324279 model2 loss : 0.286890
[21:52:15.610] iteration 1791 : model1 loss : 0.320059 model2 loss : 0.313667
[21:52:15.949] iteration 1792 : model1 loss : 0.367629 model2 loss : 0.324352
[21:52:16.285] iteration 1793 : model1 loss : 0.247298 model2 loss : 0.191802
[21:52:16.621] iteration 1794 : model1 loss : 0.346725 model2 loss : 0.301300
[21:52:16.958] iteration 1795 : model1 loss : 0.326299 model2 loss : 0.330692
[21:52:17.295] iteration 1796 : model1 loss : 0.293116 model2 loss : 0.291272
[21:52:17.631] iteration 1797 : model1 loss : 0.316399 model2 loss : 0.250004
[21:52:17.968] iteration 1798 : model1 loss : 0.331805 model2 loss : 0.315291
[21:52:18.306] iteration 1799 : model1 loss : 0.300690 model2 loss : 0.325224
[21:52:18.643] iteration 1800 : model1 loss : 0.385415 model2 loss : 0.388462
[21:52:19.292] iteration 1801 : model1 loss : 0.387691 model2 loss : 0.358866
[21:52:19.635] iteration 1802 : model1 loss : 0.302660 model2 loss : 0.211399
[21:52:19.971] iteration 1803 : model1 loss : 0.333768 model2 loss : 0.273955
[21:52:20.309] iteration 1804 : model1 loss : 0.354305 model2 loss : 0.313861
[21:52:20.646] iteration 1805 : model1 loss : 0.347510 model2 loss : 0.340067
[21:52:20.984] iteration 1806 : model1 loss : 0.337937 model2 loss : 0.315262
[21:52:21.322] iteration 1807 : model1 loss : 0.336901 model2 loss : 0.317323
[21:52:21.660] iteration 1808 : model1 loss : 0.286057 model2 loss : 0.241044
[21:52:21.996] iteration 1809 : model1 loss : 0.294818 model2 loss : 0.219217
[21:52:22.332] iteration 1810 : model1 loss : 0.358675 model2 loss : 0.238564
[21:52:22.669] iteration 1811 : model1 loss : 0.407900 model2 loss : 0.343180
[21:52:23.008] iteration 1812 : model1 loss : 0.318905 model2 loss : 0.286319
[21:52:23.347] iteration 1813 : model1 loss : 0.313339 model2 loss : 0.287791
[21:52:23.689] iteration 1814 : model1 loss : 0.377454 model2 loss : 0.354072
[21:52:24.026] iteration 1815 : model1 loss : 0.332820 model2 loss : 0.235371
[21:52:24.368] iteration 1816 : model1 loss : 0.401310 model2 loss : 0.425846
[21:52:24.706] iteration 1817 : model1 loss : 0.369067 model2 loss : 0.261289
[21:52:25.043] iteration 1818 : model1 loss : 0.336585 model2 loss : 0.320269
[21:52:25.380] iteration 1819 : model1 loss : 0.381000 model2 loss : 0.357490
[21:52:25.717] iteration 1820 : model1 loss : 0.373850 model2 loss : 0.360744
[21:52:26.058] iteration 1821 : model1 loss : 0.270796 model2 loss : 0.229627
[21:52:26.396] iteration 1822 : model1 loss : 0.411998 model2 loss : 0.368132
[21:52:26.734] iteration 1823 : model1 loss : 0.300491 model2 loss : 0.271919
[21:52:27.070] iteration 1824 : model1 loss : 0.390305 model2 loss : 0.345441
[21:52:27.406] iteration 1825 : model1 loss : 0.405076 model2 loss : 0.304768
[21:52:27.742] iteration 1826 : model1 loss : 0.371537 model2 loss : 0.401066
[21:52:28.083] iteration 1827 : model1 loss : 0.305599 model2 loss : 0.278082
[21:52:28.421] iteration 1828 : model1 loss : 0.332389 model2 loss : 0.329530
[21:52:28.766] iteration 1829 : model1 loss : 0.252503 model2 loss : 0.226013
[21:52:29.102] iteration 1830 : model1 loss : 0.367452 model2 loss : 0.297198
[21:52:29.440] iteration 1831 : model1 loss : 0.381372 model2 loss : 0.349298
[21:52:29.777] iteration 1832 : model1 loss : 0.463213 model2 loss : 0.382877
[21:52:30.115] iteration 1833 : model1 loss : 0.426749 model2 loss : 0.381003
[21:52:30.453] iteration 1834 : model1 loss : 0.405516 model2 loss : 0.415523
[21:52:30.789] iteration 1835 : model1 loss : 0.346674 model2 loss : 0.305130
[21:52:31.129] iteration 1836 : model1 loss : 0.373245 model2 loss : 0.312874
[21:52:31.468] iteration 1837 : model1 loss : 0.324532 model2 loss : 0.288613
[21:52:31.807] iteration 1838 : model1 loss : 0.342176 model2 loss : 0.290848
[21:52:32.145] iteration 1839 : model1 loss : 0.305118 model2 loss : 0.213565
[21:52:32.482] iteration 1840 : model1 loss : 0.281911 model2 loss : 0.335159
[21:52:32.820] iteration 1841 : model1 loss : 0.437472 model2 loss : 0.447050
[21:52:33.160] iteration 1842 : model1 loss : 0.320737 model2 loss : 0.299234
[21:52:33.501] iteration 1843 : model1 loss : 0.310201 model2 loss : 0.273119
[21:52:33.845] iteration 1844 : model1 loss : 0.428412 model2 loss : 0.334412
[21:52:34.181] iteration 1845 : model1 loss : 0.283152 model2 loss : 0.255954
[21:52:34.522] iteration 1846 : model1 loss : 0.323385 model2 loss : 0.275985
[21:52:34.865] iteration 1847 : model1 loss : 0.437518 model2 loss : 0.325679
[21:52:35.204] iteration 1848 : model1 loss : 0.353781 model2 loss : 0.339785
[21:52:35.540] iteration 1849 : model1 loss : 0.365430 model2 loss : 0.356176
[21:52:35.877] iteration 1850 : model1 loss : 0.316154 model2 loss : 0.281021
[21:52:36.521] iteration 1851 : model1 loss : 0.353674 model2 loss : 0.359078
[21:52:36.858] iteration 1852 : model1 loss : 0.412273 model2 loss : 0.271005
[21:52:37.195] iteration 1853 : model1 loss : 0.388686 model2 loss : 0.388490
[21:52:37.532] iteration 1854 : model1 loss : 0.386022 model2 loss : 0.324712
[21:52:37.871] iteration 1855 : model1 loss : 0.383348 model2 loss : 0.336840
[21:52:38.210] iteration 1856 : model1 loss : 0.436142 model2 loss : 0.406672
[21:52:38.547] iteration 1857 : model1 loss : 0.334485 model2 loss : 0.316289
[21:52:38.885] iteration 1858 : model1 loss : 0.382905 model2 loss : 0.391671
[21:52:39.224] iteration 1859 : model1 loss : 0.460918 model2 loss : 0.325206
[21:52:39.563] iteration 1860 : model1 loss : 0.452365 model2 loss : 0.304940
[21:52:39.904] iteration 1861 : model1 loss : 0.378659 model2 loss : 0.370930
[21:52:40.241] iteration 1862 : model1 loss : 0.456963 model2 loss : 0.410722
[21:52:40.585] iteration 1863 : model1 loss : 0.334789 model2 loss : 0.299646
[21:52:40.926] iteration 1864 : model1 loss : 0.286013 model2 loss : 0.240253
[21:52:41.264] iteration 1865 : model1 loss : 0.351867 model2 loss : 0.323534
[21:52:41.606] iteration 1866 : model1 loss : 0.408200 model2 loss : 0.363111
[21:52:41.947] iteration 1867 : model1 loss : 0.304266 model2 loss : 0.212048
[21:52:42.287] iteration 1868 : model1 loss : 0.325022 model2 loss : 0.218055
[21:52:42.629] iteration 1869 : model1 loss : 0.346751 model2 loss : 0.351559
[21:52:42.975] iteration 1870 : model1 loss : 0.328055 model2 loss : 0.283947
[21:52:43.313] iteration 1871 : model1 loss : 0.364704 model2 loss : 0.351857
[21:52:43.652] iteration 1872 : model1 loss : 0.356300 model2 loss : 0.366281
[21:52:43.991] iteration 1873 : model1 loss : 0.281828 model2 loss : 0.249498
[21:52:44.332] iteration 1874 : model1 loss : 0.322196 model2 loss : 0.289468
[21:52:44.663] iteration 1875 : model1 loss : 0.341149 model2 loss : 0.296156
[21:52:45.002] iteration 1876 : model1 loss : 0.297938 model2 loss : 0.291468
[21:52:45.340] iteration 1877 : model1 loss : 0.308765 model2 loss : 0.246603
[21:52:45.678] iteration 1878 : model1 loss : 0.391985 model2 loss : 0.344690
[21:52:46.019] iteration 1879 : model1 loss : 0.324563 model2 loss : 0.252689
[21:52:46.359] iteration 1880 : model1 loss : 0.499677 model2 loss : 0.405330
[21:52:46.698] iteration 1881 : model1 loss : 0.276535 model2 loss : 0.240953
[21:52:47.037] iteration 1882 : model1 loss : 0.386383 model2 loss : 0.351606
[21:52:47.375] iteration 1883 : model1 loss : 0.366921 model2 loss : 0.343768
[21:52:47.715] iteration 1884 : model1 loss : 0.299520 model2 loss : 0.293520
[21:52:48.053] iteration 1885 : model1 loss : 0.358364 model2 loss : 0.367753
[21:52:48.393] iteration 1886 : model1 loss : 0.420798 model2 loss : 0.315398
[21:52:48.732] iteration 1887 : model1 loss : 0.476603 model2 loss : 0.384319
[21:52:49.069] iteration 1888 : model1 loss : 0.360589 model2 loss : 0.291607
[21:52:49.409] iteration 1889 : model1 loss : 0.386596 model2 loss : 0.366943
[21:52:49.749] iteration 1890 : model1 loss : 0.288397 model2 loss : 0.242510
[21:52:50.088] iteration 1891 : model1 loss : 0.318836 model2 loss : 0.271902
[21:52:50.424] iteration 1892 : model1 loss : 0.360051 model2 loss : 0.265726
[21:52:50.762] iteration 1893 : model1 loss : 0.374095 model2 loss : 0.411641
[21:52:51.103] iteration 1894 : model1 loss : 0.405566 model2 loss : 0.411317
[21:52:51.443] iteration 1895 : model1 loss : 0.422181 model2 loss : 0.352016
[21:52:51.782] iteration 1896 : model1 loss : 0.262048 model2 loss : 0.233194
[21:52:52.125] iteration 1897 : model1 loss : 0.358933 model2 loss : 0.360660
[21:52:52.460] iteration 1898 : model1 loss : 0.331620 model2 loss : 0.310832
[21:52:52.797] iteration 1899 : model1 loss : 0.409984 model2 loss : 0.391832
[21:52:53.134] iteration 1900 : model1 loss : 0.370017 model2 loss : 0.297273
[21:52:53.824] iteration 1901 : model1 loss : 0.346897 model2 loss : 0.325193
[21:52:54.160] iteration 1902 : model1 loss : 0.358527 model2 loss : 0.317284
[21:52:54.497] iteration 1903 : model1 loss : 0.365440 model2 loss : 0.326558
[21:52:54.834] iteration 1904 : model1 loss : 0.322418 model2 loss : 0.251220
[21:52:55.170] iteration 1905 : model1 loss : 0.325837 model2 loss : 0.337127
[21:52:55.507] iteration 1906 : model1 loss : 0.292788 model2 loss : 0.221888
[21:52:55.843] iteration 1907 : model1 loss : 0.324320 model2 loss : 0.338167
[21:52:56.179] iteration 1908 : model1 loss : 0.266862 model2 loss : 0.276671
[21:52:56.516] iteration 1909 : model1 loss : 0.365945 model2 loss : 0.326044
[21:52:56.854] iteration 1910 : model1 loss : 0.329605 model2 loss : 0.309964
[21:52:57.189] iteration 1911 : model1 loss : 0.279449 model2 loss : 0.245148
[21:52:57.530] iteration 1912 : model1 loss : 0.321279 model2 loss : 0.296768
[21:52:57.867] iteration 1913 : model1 loss : 0.349092 model2 loss : 0.274165
[21:52:58.203] iteration 1914 : model1 loss : 0.289052 model2 loss : 0.321076
[21:52:58.541] iteration 1915 : model1 loss : 0.362648 model2 loss : 0.312423
[21:52:58.878] iteration 1916 : model1 loss : 0.293576 model2 loss : 0.285517
[21:52:59.214] iteration 1917 : model1 loss : 0.349526 model2 loss : 0.309734
[21:52:59.552] iteration 1918 : model1 loss : 0.345504 model2 loss : 0.297204
[21:52:59.889] iteration 1919 : model1 loss : 0.329507 model2 loss : 0.267260
[21:53:00.226] iteration 1920 : model1 loss : 0.327034 model2 loss : 0.316837
[21:53:00.562] iteration 1921 : model1 loss : 0.239022 model2 loss : 0.228049
[21:53:00.898] iteration 1922 : model1 loss : 0.287785 model2 loss : 0.231290
[21:53:01.235] iteration 1923 : model1 loss : 0.350237 model2 loss : 0.361137
[21:53:01.573] iteration 1924 : model1 loss : 0.316520 model2 loss : 0.288340
[21:53:01.924] iteration 1925 : model1 loss : 0.307038 model2 loss : 0.300469
[21:53:02.261] iteration 1926 : model1 loss : 0.344478 model2 loss : 0.334435
[21:53:02.598] iteration 1927 : model1 loss : 0.328598 model2 loss : 0.359431
[21:53:02.935] iteration 1928 : model1 loss : 0.336095 model2 loss : 0.323885
[21:53:03.271] iteration 1929 : model1 loss : 0.472674 model2 loss : 0.416608
[21:53:03.608] iteration 1930 : model1 loss : 0.329305 model2 loss : 0.320472
[21:53:03.946] iteration 1931 : model1 loss : 0.286263 model2 loss : 0.278805
[21:53:04.282] iteration 1932 : model1 loss : 0.229670 model2 loss : 0.251129
[21:53:04.620] iteration 1933 : model1 loss : 0.360017 model2 loss : 0.335479
[21:53:04.957] iteration 1934 : model1 loss : 0.397850 model2 loss : 0.377240
[21:53:05.295] iteration 1935 : model1 loss : 0.396239 model2 loss : 0.304003
[21:53:05.634] iteration 1936 : model1 loss : 0.297027 model2 loss : 0.299769
[21:53:05.973] iteration 1937 : model1 loss : 0.333017 model2 loss : 0.282288
[21:53:06.314] iteration 1938 : model1 loss : 0.307975 model2 loss : 0.298781
[21:53:06.654] iteration 1939 : model1 loss : 0.351746 model2 loss : 0.338917
[21:53:06.991] iteration 1940 : model1 loss : 0.394701 model2 loss : 0.308021
[21:53:07.329] iteration 1941 : model1 loss : 0.483431 model2 loss : 0.404511
[21:53:07.665] iteration 1942 : model1 loss : 0.280208 model2 loss : 0.257668
[21:53:08.002] iteration 1943 : model1 loss : 0.378525 model2 loss : 0.267112
[21:53:08.341] iteration 1944 : model1 loss : 0.380380 model2 loss : 0.303567
[21:53:08.681] iteration 1945 : model1 loss : 0.345683 model2 loss : 0.279851
[21:53:09.017] iteration 1946 : model1 loss : 0.360257 model2 loss : 0.301500
[21:53:09.354] iteration 1947 : model1 loss : 0.351193 model2 loss : 0.336226
[21:53:09.689] iteration 1948 : model1 loss : 0.344580 model2 loss : 0.266522
[21:53:10.026] iteration 1949 : model1 loss : 0.308540 model2 loss : 0.239383
[21:53:10.363] iteration 1950 : model1 loss : 0.346720 model2 loss : 0.289369
[21:53:10.998] iteration 1951 : model1 loss : 0.362931 model2 loss : 0.333376
[21:53:11.335] iteration 1952 : model1 loss : 0.375994 model2 loss : 0.327001
[21:53:11.672] iteration 1953 : model1 loss : 0.370127 model2 loss : 0.320261
[21:53:12.005] iteration 1954 : model1 loss : 0.379290 model2 loss : 0.340890
[21:53:12.342] iteration 1955 : model1 loss : 0.371176 model2 loss : 0.367319
[21:53:12.681] iteration 1956 : model1 loss : 0.353393 model2 loss : 0.292767
[21:53:13.018] iteration 1957 : model1 loss : 0.362332 model2 loss : 0.296553
[21:53:13.350] iteration 1958 : model1 loss : 0.367717 model2 loss : 0.328397
[21:53:13.687] iteration 1959 : model1 loss : 0.419190 model2 loss : 0.414843
[21:53:14.025] iteration 1960 : model1 loss : 0.343245 model2 loss : 0.312459
[21:53:14.361] iteration 1961 : model1 loss : 0.405241 model2 loss : 0.373843
[21:53:14.695] iteration 1962 : model1 loss : 0.296109 model2 loss : 0.198574
[21:53:15.056] iteration 1963 : model1 loss : 0.454134 model2 loss : 0.301983
[21:53:15.395] iteration 1964 : model1 loss : 0.411152 model2 loss : 0.357320
[21:53:15.733] iteration 1965 : model1 loss : 0.395648 model2 loss : 0.392513
[21:53:16.072] iteration 1966 : model1 loss : 0.356650 model2 loss : 0.260167
[21:53:16.404] iteration 1967 : model1 loss : 0.399176 model2 loss : 0.303030
[21:53:16.741] iteration 1968 : model1 loss : 0.356490 model2 loss : 0.362864
[21:53:17.078] iteration 1969 : model1 loss : 0.354976 model2 loss : 0.255560
[21:53:17.415] iteration 1970 : model1 loss : 0.314773 model2 loss : 0.328491
[21:53:17.773] iteration 1971 : model1 loss : 0.354121 model2 loss : 0.334478
[21:53:18.113] iteration 1972 : model1 loss : 0.431350 model2 loss : 0.406208
[21:53:18.450] iteration 1973 : model1 loss : 0.353881 model2 loss : 0.331448
[21:53:18.787] iteration 1974 : model1 loss : 0.377308 model2 loss : 0.287736
[21:53:19.124] iteration 1975 : model1 loss : 0.329129 model2 loss : 0.311753
[21:53:19.460] iteration 1976 : model1 loss : 0.357268 model2 loss : 0.352822
[21:53:19.798] iteration 1977 : model1 loss : 0.300006 model2 loss : 0.246331
[21:53:20.135] iteration 1978 : model1 loss : 0.378242 model2 loss : 0.365374
[21:53:20.474] iteration 1979 : model1 loss : 0.312744 model2 loss : 0.293845
[21:53:20.811] iteration 1980 : model1 loss : 0.288289 model2 loss : 0.255070
[21:53:21.148] iteration 1981 : model1 loss : 0.352557 model2 loss : 0.349679
[21:53:21.484] iteration 1982 : model1 loss : 0.268544 model2 loss : 0.214806
[21:53:21.822] iteration 1983 : model1 loss : 0.328312 model2 loss : 0.279598
[21:53:22.160] iteration 1984 : model1 loss : 0.325986 model2 loss : 0.279724
[21:53:22.497] iteration 1985 : model1 loss : 0.326725 model2 loss : 0.281648
[21:53:22.835] iteration 1986 : model1 loss : 0.261239 model2 loss : 0.224878
[21:53:23.173] iteration 1987 : model1 loss : 0.293584 model2 loss : 0.315771
[21:53:23.515] iteration 1988 : model1 loss : 0.274881 model2 loss : 0.230817
[21:53:23.852] iteration 1989 : model1 loss : 0.304699 model2 loss : 0.279630
[21:53:24.189] iteration 1990 : model1 loss : 0.280814 model2 loss : 0.289819
[21:53:24.526] iteration 1991 : model1 loss : 0.274962 model2 loss : 0.278607
[21:53:24.868] iteration 1992 : model1 loss : 0.340380 model2 loss : 0.294686
[21:53:25.210] iteration 1993 : model1 loss : 0.317673 model2 loss : 0.273412
[21:53:25.548] iteration 1994 : model1 loss : 0.370338 model2 loss : 0.339676
[21:53:25.884] iteration 1995 : model1 loss : 0.360231 model2 loss : 0.333794
[21:53:26.221] iteration 1996 : model1 loss : 0.372050 model2 loss : 0.300962
[21:53:26.560] iteration 1997 : model1 loss : 0.308791 model2 loss : 0.288460
[21:53:26.896] iteration 1998 : model1 loss : 0.415325 model2 loss : 0.346218
[21:53:27.232] iteration 1999 : model1 loss : 0.301814 model2 loss : 0.236118
[21:53:27.570] iteration 2000 : model1 loss : 0.364099 model2 loss : 0.364688
[21:53:28.222] iteration 2001 : model1 loss : 0.350833 model2 loss : 0.276259
[21:53:28.559] iteration 2002 : model1 loss : 0.270768 model2 loss : 0.228865
[21:53:28.899] iteration 2003 : model1 loss : 0.302868 model2 loss : 0.296350
[21:53:29.237] iteration 2004 : model1 loss : 0.294879 model2 loss : 0.242532
[21:53:29.573] iteration 2005 : model1 loss : 0.277944 model2 loss : 0.263720
[21:53:29.909] iteration 2006 : model1 loss : 0.296767 model2 loss : 0.276265
[21:53:30.245] iteration 2007 : model1 loss : 0.343936 model2 loss : 0.314365
[21:53:30.581] iteration 2008 : model1 loss : 0.305944 model2 loss : 0.237482
[21:53:30.924] iteration 2009 : model1 loss : 0.375394 model2 loss : 0.361378
[21:53:31.260] iteration 2010 : model1 loss : 0.317539 model2 loss : 0.299287
[21:53:31.597] iteration 2011 : model1 loss : 0.291497 model2 loss : 0.285221
[21:53:31.934] iteration 2012 : model1 loss : 0.433717 model2 loss : 0.361675
[21:53:32.270] iteration 2013 : model1 loss : 0.414347 model2 loss : 0.358026
[21:53:32.606] iteration 2014 : model1 loss : 0.457970 model2 loss : 0.335189
[21:53:32.943] iteration 2015 : model1 loss : 0.323047 model2 loss : 0.300378
[21:53:33.279] iteration 2016 : model1 loss : 0.314565 model2 loss : 0.313653
[21:53:33.616] iteration 2017 : model1 loss : 0.392989 model2 loss : 0.364798
[21:53:33.953] iteration 2018 : model1 loss : 0.377028 model2 loss : 0.304825
[21:53:34.289] iteration 2019 : model1 loss : 0.338237 model2 loss : 0.329027
[21:53:34.626] iteration 2020 : model1 loss : 0.358559 model2 loss : 0.276926
[21:53:34.965] iteration 2021 : model1 loss : 0.331056 model2 loss : 0.291997
[21:53:35.302] iteration 2022 : model1 loss : 0.369910 model2 loss : 0.315937
[21:53:35.637] iteration 2023 : model1 loss : 0.365934 model2 loss : 0.276962
[21:53:35.976] iteration 2024 : model1 loss : 0.385708 model2 loss : 0.418054
[21:53:36.314] iteration 2025 : model1 loss : 0.392676 model2 loss : 0.284325
[21:53:36.651] iteration 2026 : model1 loss : 0.335731 model2 loss : 0.295476
[21:53:36.988] iteration 2027 : model1 loss : 0.348819 model2 loss : 0.303670
[21:53:37.324] iteration 2028 : model1 loss : 0.296356 model2 loss : 0.237255
[21:53:37.661] iteration 2029 : model1 loss : 0.296397 model2 loss : 0.287740
[21:53:37.997] iteration 2030 : model1 loss : 0.300498 model2 loss : 0.277249
[21:53:38.334] iteration 2031 : model1 loss : 0.361976 model2 loss : 0.344943
[21:53:38.671] iteration 2032 : model1 loss : 0.319353 model2 loss : 0.215920
[21:53:39.007] iteration 2033 : model1 loss : 0.356596 model2 loss : 0.265329
[21:53:39.344] iteration 2034 : model1 loss : 0.373155 model2 loss : 0.309673
[21:53:39.681] iteration 2035 : model1 loss : 0.420675 model2 loss : 0.401468
[21:53:40.019] iteration 2036 : model1 loss : 0.334426 model2 loss : 0.291571
[21:53:40.360] iteration 2037 : model1 loss : 0.375402 model2 loss : 0.366043
[21:53:40.695] iteration 2038 : model1 loss : 0.321505 model2 loss : 0.300791
[21:53:41.031] iteration 2039 : model1 loss : 0.315751 model2 loss : 0.264757
[21:53:41.368] iteration 2040 : model1 loss : 0.398831 model2 loss : 0.366747
[21:53:41.705] iteration 2041 : model1 loss : 0.345475 model2 loss : 0.328336
[21:53:42.041] iteration 2042 : model1 loss : 0.316651 model2 loss : 0.252052
[21:53:42.377] iteration 2043 : model1 loss : 0.384860 model2 loss : 0.335025
[21:53:42.714] iteration 2044 : model1 loss : 0.344615 model2 loss : 0.302905
[21:53:43.050] iteration 2045 : model1 loss : 0.409190 model2 loss : 0.365044
[21:53:43.386] iteration 2046 : model1 loss : 0.328338 model2 loss : 0.301109
[21:53:43.723] iteration 2047 : model1 loss : 0.310712 model2 loss : 0.267672
[21:53:44.060] iteration 2048 : model1 loss : 0.257878 model2 loss : 0.188016
[21:53:44.397] iteration 2049 : model1 loss : 0.409795 model2 loss : 0.372840
[21:53:44.734] iteration 2050 : model1 loss : 0.466485 model2 loss : 0.392875
[21:53:45.368] iteration 2051 : model1 loss : 0.395528 model2 loss : 0.429981
[21:53:45.706] iteration 2052 : model1 loss : 0.364785 model2 loss : 0.326176
[21:53:46.043] iteration 2053 : model1 loss : 0.412855 model2 loss : 0.342626
[21:53:46.382] iteration 2054 : model1 loss : 0.446616 model2 loss : 0.370157
[21:53:46.721] iteration 2055 : model1 loss : 0.422224 model2 loss : 0.419438
[21:53:47.058] iteration 2056 : model1 loss : 0.397016 model2 loss : 0.328014
[21:53:47.395] iteration 2057 : model1 loss : 0.340094 model2 loss : 0.353904
[21:53:47.733] iteration 2058 : model1 loss : 0.361853 model2 loss : 0.323868
[21:53:48.071] iteration 2059 : model1 loss : 0.352133 model2 loss : 0.342545
[21:53:48.409] iteration 2060 : model1 loss : 0.385598 model2 loss : 0.359595
[21:53:48.749] iteration 2061 : model1 loss : 0.376576 model2 loss : 0.354335
[21:53:49.087] iteration 2062 : model1 loss : 0.326786 model2 loss : 0.244246
[21:53:49.425] iteration 2063 : model1 loss : 0.295788 model2 loss : 0.246844
[21:53:49.762] iteration 2064 : model1 loss : 0.361372 model2 loss : 0.365100
[21:53:50.102] iteration 2065 : model1 loss : 0.339526 model2 loss : 0.303522
[21:53:50.441] iteration 2066 : model1 loss : 0.393577 model2 loss : 0.313001
[21:53:50.780] iteration 2067 : model1 loss : 0.339675 model2 loss : 0.263745
[21:53:51.119] iteration 2068 : model1 loss : 0.351130 model2 loss : 0.342094
[21:53:51.460] iteration 2069 : model1 loss : 0.344716 model2 loss : 0.276687
[21:53:51.797] iteration 2070 : model1 loss : 0.358579 model2 loss : 0.315650
[21:53:52.136] iteration 2071 : model1 loss : 0.302184 model2 loss : 0.262042
[21:53:52.474] iteration 2072 : model1 loss : 0.281837 model2 loss : 0.335350
[21:53:52.811] iteration 2073 : model1 loss : 0.305466 model2 loss : 0.256233
[21:53:53.148] iteration 2074 : model1 loss : 0.321723 model2 loss : 0.282361
[21:53:53.486] iteration 2075 : model1 loss : 0.336294 model2 loss : 0.306287
[21:53:53.833] iteration 2076 : model1 loss : 0.323014 model2 loss : 0.266892
[21:53:54.170] iteration 2077 : model1 loss : 0.263317 model2 loss : 0.258846
[21:53:54.507] iteration 2078 : model1 loss : 0.241075 model2 loss : 0.187941
[21:53:54.845] iteration 2079 : model1 loss : 0.333405 model2 loss : 0.285534
[21:53:55.182] iteration 2080 : model1 loss : 0.402413 model2 loss : 0.378443
[21:53:55.518] iteration 2081 : model1 loss : 0.243444 model2 loss : 0.227933
[21:53:55.856] iteration 2082 : model1 loss : 0.262968 model2 loss : 0.276083
[21:53:56.194] iteration 2083 : model1 loss : 0.322080 model2 loss : 0.335555
[21:53:56.531] iteration 2084 : model1 loss : 0.413919 model2 loss : 0.416573
[21:53:56.867] iteration 2085 : model1 loss : 0.259324 model2 loss : 0.234736
[21:53:57.206] iteration 2086 : model1 loss : 0.321404 model2 loss : 0.309048
[21:53:57.543] iteration 2087 : model1 loss : 0.410635 model2 loss : 0.319991
[21:53:57.880] iteration 2088 : model1 loss : 0.330593 model2 loss : 0.285162
[21:53:58.219] iteration 2089 : model1 loss : 0.359167 model2 loss : 0.343901
[21:53:58.556] iteration 2090 : model1 loss : 0.302865 model2 loss : 0.256798
[21:53:58.895] iteration 2091 : model1 loss : 0.326329 model2 loss : 0.218412
[21:53:59.231] iteration 2092 : model1 loss : 0.406600 model2 loss : 0.316256
[21:53:59.568] iteration 2093 : model1 loss : 0.305110 model2 loss : 0.276974
[21:53:59.905] iteration 2094 : model1 loss : 0.321133 model2 loss : 0.333046
[21:54:00.243] iteration 2095 : model1 loss : 0.335363 model2 loss : 0.313719
[21:54:00.583] iteration 2096 : model1 loss : 0.319700 model2 loss : 0.281061
[21:54:00.921] iteration 2097 : model1 loss : 0.308142 model2 loss : 0.246659
[21:54:01.259] iteration 2098 : model1 loss : 0.361966 model2 loss : 0.341798
[21:54:01.597] iteration 2099 : model1 loss : 0.274612 model2 loss : 0.283553
[21:54:01.934] iteration 2100 : model1 loss : 0.323804 model2 loss : 0.325135
[21:54:02.572] iteration 2101 : model1 loss : 0.251336 model2 loss : 0.223895
[21:54:02.909] iteration 2102 : model1 loss : 0.348508 model2 loss : 0.347896
[21:54:03.248] iteration 2103 : model1 loss : 0.326227 model2 loss : 0.313196
[21:54:03.590] iteration 2104 : model1 loss : 0.279860 model2 loss : 0.297709
[21:54:03.927] iteration 2105 : model1 loss : 0.289773 model2 loss : 0.298767
[21:54:04.265] iteration 2106 : model1 loss : 0.264982 model2 loss : 0.239993
[21:54:04.602] iteration 2107 : model1 loss : 0.357496 model2 loss : 0.368299
[21:54:04.939] iteration 2108 : model1 loss : 0.284413 model2 loss : 0.255236
[21:54:05.277] iteration 2109 : model1 loss : 0.349602 model2 loss : 0.286188
[21:54:05.613] iteration 2110 : model1 loss : 0.338129 model2 loss : 0.239388
[21:54:05.952] iteration 2111 : model1 loss : 0.297994 model2 loss : 0.256642
[21:54:06.290] iteration 2112 : model1 loss : 0.373199 model2 loss : 0.328096
[21:54:06.627] iteration 2113 : model1 loss : 0.218888 model2 loss : 0.175548
[21:54:06.966] iteration 2114 : model1 loss : 0.396360 model2 loss : 0.343748
[21:54:07.304] iteration 2115 : model1 loss : 0.289935 model2 loss : 0.261715
[21:54:07.643] iteration 2116 : model1 loss : 0.258076 model2 loss : 0.222707
[21:54:07.981] iteration 2117 : model1 loss : 0.342887 model2 loss : 0.292866
[21:54:08.321] iteration 2118 : model1 loss : 0.310579 model2 loss : 0.270326
[21:54:08.664] iteration 2119 : model1 loss : 0.410936 model2 loss : 0.436455
[21:54:09.002] iteration 2120 : model1 loss : 0.245960 model2 loss : 0.245550
[21:54:09.339] iteration 2121 : model1 loss : 0.378410 model2 loss : 0.264083
[21:54:09.679] iteration 2122 : model1 loss : 0.456748 model2 loss : 0.465885
[21:54:10.018] iteration 2123 : model1 loss : 0.353984 model2 loss : 0.339049
[21:54:10.356] iteration 2124 : model1 loss : 0.326628 model2 loss : 0.357066
[21:54:10.694] iteration 2125 : model1 loss : 0.309402 model2 loss : 0.232026
[21:54:11.033] iteration 2126 : model1 loss : 0.240794 model2 loss : 0.261399
[21:54:11.372] iteration 2127 : model1 loss : 0.363181 model2 loss : 0.312612
[21:54:11.712] iteration 2128 : model1 loss : 0.296607 model2 loss : 0.300746
[21:54:12.054] iteration 2129 : model1 loss : 0.249312 model2 loss : 0.226821
[21:54:12.392] iteration 2130 : model1 loss : 0.288617 model2 loss : 0.228538
[21:54:12.730] iteration 2131 : model1 loss : 0.263387 model2 loss : 0.325232
[21:54:13.068] iteration 2132 : model1 loss : 0.368241 model2 loss : 0.322170
[21:54:13.406] iteration 2133 : model1 loss : 0.292546 model2 loss : 0.260559
[21:54:13.742] iteration 2134 : model1 loss : 0.364059 model2 loss : 0.356533
[21:54:14.080] iteration 2135 : model1 loss : 0.378635 model2 loss : 0.381899
[21:54:14.421] iteration 2136 : model1 loss : 0.313219 model2 loss : 0.315485
[21:54:14.759] iteration 2137 : model1 loss : 0.293957 model2 loss : 0.279902
[21:54:15.095] iteration 2138 : model1 loss : 0.323407 model2 loss : 0.280409
[21:54:15.424] iteration 2139 : model1 loss : 0.332367 model2 loss : 0.348225
[21:54:15.752] iteration 2140 : model1 loss : 0.352981 model2 loss : 0.367908
[21:54:16.080] iteration 2141 : model1 loss : 0.254889 model2 loss : 0.225175
[21:54:16.408] iteration 2142 : model1 loss : 0.323299 model2 loss : 0.352615
[21:54:16.737] iteration 2143 : model1 loss : 0.265895 model2 loss : 0.204520
[21:54:17.064] iteration 2144 : model1 loss : 0.326146 model2 loss : 0.370306
[21:54:17.393] iteration 2145 : model1 loss : 0.330839 model2 loss : 0.246673
[21:54:17.731] iteration 2146 : model1 loss : 0.414334 model2 loss : 0.355769
[21:54:18.068] iteration 2147 : model1 loss : 0.315714 model2 loss : 0.275833
[21:54:18.406] iteration 2148 : model1 loss : 0.353909 model2 loss : 0.334067
[21:54:18.743] iteration 2149 : model1 loss : 0.319593 model2 loss : 0.304500
[21:54:19.080] iteration 2150 : model1 loss : 0.334805 model2 loss : 0.311920
[21:54:19.705] iteration 2151 : model1 loss : 0.311410 model2 loss : 0.327292
[21:54:20.043] iteration 2152 : model1 loss : 0.346256 model2 loss : 0.316028
[21:54:20.380] iteration 2153 : model1 loss : 0.295959 model2 loss : 0.262843
[21:54:20.718] iteration 2154 : model1 loss : 0.319305 model2 loss : 0.310512
[21:54:21.076] iteration 2155 : model1 loss : 0.367198 model2 loss : 0.336534
[21:54:21.414] iteration 2156 : model1 loss : 0.373701 model2 loss : 0.376724
[21:54:21.752] iteration 2157 : model1 loss : 0.320681 model2 loss : 0.298292
[21:54:22.089] iteration 2158 : model1 loss : 0.418352 model2 loss : 0.405803
[21:54:22.446] iteration 2159 : model1 loss : 0.499260 model2 loss : 0.474553
[21:54:22.775] iteration 2160 : model1 loss : 0.319352 model2 loss : 0.300036
[21:54:23.104] iteration 2161 : model1 loss : 0.319957 model2 loss : 0.295413
[21:54:23.432] iteration 2162 : model1 loss : 0.368700 model2 loss : 0.358475
[21:54:23.760] iteration 2163 : model1 loss : 0.342176 model2 loss : 0.328735
[21:54:24.089] iteration 2164 : model1 loss : 0.310836 model2 loss : 0.321192
[21:54:24.418] iteration 2165 : model1 loss : 0.336324 model2 loss : 0.299593
[21:54:24.746] iteration 2166 : model1 loss : 0.296997 model2 loss : 0.251343
[21:54:25.075] iteration 2167 : model1 loss : 0.316999 model2 loss : 0.311322
[21:54:25.403] iteration 2168 : model1 loss : 0.308364 model2 loss : 0.287734
[21:54:25.732] iteration 2169 : model1 loss : 0.335212 model2 loss : 0.344874
[21:54:26.060] iteration 2170 : model1 loss : 0.372694 model2 loss : 0.303289
[21:54:26.388] iteration 2171 : model1 loss : 0.356698 model2 loss : 0.349405
[21:54:26.717] iteration 2172 : model1 loss : 0.364644 model2 loss : 0.312031
[21:54:27.045] iteration 2173 : model1 loss : 0.346253 model2 loss : 0.315958
[21:54:27.373] iteration 2174 : model1 loss : 0.381376 model2 loss : 0.360246
[21:54:27.700] iteration 2175 : model1 loss : 0.358711 model2 loss : 0.309896
[21:54:28.027] iteration 2176 : model1 loss : 0.453553 model2 loss : 0.426455
[21:54:28.354] iteration 2177 : model1 loss : 0.343400 model2 loss : 0.308310
[21:54:28.681] iteration 2178 : model1 loss : 0.274501 model2 loss : 0.250478
[21:54:29.008] iteration 2179 : model1 loss : 0.313149 model2 loss : 0.314586
[21:54:29.335] iteration 2180 : model1 loss : 0.265660 model2 loss : 0.237736
[21:54:30.278] iteration 2181 : model1 loss : 0.293961 model2 loss : 0.268699
[21:54:30.606] iteration 2182 : model1 loss : 0.366290 model2 loss : 0.327778
[21:54:30.932] iteration 2183 : model1 loss : 0.282531 model2 loss : 0.241267
[21:54:31.260] iteration 2184 : model1 loss : 0.339821 model2 loss : 0.259010
[21:54:31.588] iteration 2185 : model1 loss : 0.301617 model2 loss : 0.248802
[21:54:31.915] iteration 2186 : model1 loss : 0.314945 model2 loss : 0.311483
[21:54:32.242] iteration 2187 : model1 loss : 0.309456 model2 loss : 0.301670
[21:54:32.569] iteration 2188 : model1 loss : 0.330647 model2 loss : 0.280377
[21:54:32.895] iteration 2189 : model1 loss : 0.352323 model2 loss : 0.336502
[21:54:33.224] iteration 2190 : model1 loss : 0.333041 model2 loss : 0.318592
[21:54:33.551] iteration 2191 : model1 loss : 0.383725 model2 loss : 0.295365
[21:54:33.880] iteration 2192 : model1 loss : 0.371850 model2 loss : 0.349576
[21:54:34.216] iteration 2193 : model1 loss : 0.310125 model2 loss : 0.271113
[21:54:34.553] iteration 2194 : model1 loss : 0.291740 model2 loss : 0.287667
[21:54:34.889] iteration 2195 : model1 loss : 0.348862 model2 loss : 0.339613
[21:54:35.226] iteration 2196 : model1 loss : 0.343909 model2 loss : 0.329058
[21:54:35.565] iteration 2197 : model1 loss : 0.339520 model2 loss : 0.282463
[21:54:35.902] iteration 2198 : model1 loss : 0.407555 model2 loss : 0.350105
[21:54:36.239] iteration 2199 : model1 loss : 0.417100 model2 loss : 0.394283
[21:54:36.582] iteration 2200 : model1 loss : 0.316236 model2 loss : 0.324663
[21:54:37.229] iteration 2201 : model1 loss : 0.429613 model2 loss : 0.379477
[21:54:37.566] iteration 2202 : model1 loss : 0.315935 model2 loss : 0.267202
[21:54:37.904] iteration 2203 : model1 loss : 0.336074 model2 loss : 0.356157
[21:54:38.242] iteration 2204 : model1 loss : 0.279887 model2 loss : 0.277470
[21:54:38.578] iteration 2205 : model1 loss : 0.329823 model2 loss : 0.305184
[21:54:38.918] iteration 2206 : model1 loss : 0.342566 model2 loss : 0.306648
[21:54:39.255] iteration 2207 : model1 loss : 0.434417 model2 loss : 0.443238
[21:54:39.594] iteration 2208 : model1 loss : 0.366449 model2 loss : 0.244920
[21:54:39.932] iteration 2209 : model1 loss : 0.405168 model2 loss : 0.262160
[21:54:40.270] iteration 2210 : model1 loss : 0.346469 model2 loss : 0.288649
[21:54:40.606] iteration 2211 : model1 loss : 0.317776 model2 loss : 0.206243
[21:54:40.944] iteration 2212 : model1 loss : 0.352915 model2 loss : 0.326864
[21:54:41.280] iteration 2213 : model1 loss : 0.317266 model2 loss : 0.319363
[21:54:41.617] iteration 2214 : model1 loss : 0.342605 model2 loss : 0.301997
[21:54:41.954] iteration 2215 : model1 loss : 0.331621 model2 loss : 0.340310
[21:54:42.291] iteration 2216 : model1 loss : 0.342727 model2 loss : 0.281677
[21:54:42.628] iteration 2217 : model1 loss : 0.344832 model2 loss : 0.328829
[21:54:42.966] iteration 2218 : model1 loss : 0.363885 model2 loss : 0.363204
[21:54:43.304] iteration 2219 : model1 loss : 0.308957 model2 loss : 0.305654
[21:54:43.642] iteration 2220 : model1 loss : 0.263405 model2 loss : 0.241038
[21:54:43.979] iteration 2221 : model1 loss : 0.371717 model2 loss : 0.327052
[21:54:44.320] iteration 2222 : model1 loss : 0.403405 model2 loss : 0.369941
[21:54:44.657] iteration 2223 : model1 loss : 0.276007 model2 loss : 0.217611
[21:54:44.995] iteration 2224 : model1 loss : 0.248593 model2 loss : 0.218470
[21:54:45.333] iteration 2225 : model1 loss : 0.313849 model2 loss : 0.242184
[21:54:45.668] iteration 2226 : model1 loss : 0.313064 model2 loss : 0.220636
[21:54:46.006] iteration 2227 : model1 loss : 0.340053 model2 loss : 0.339826
[21:54:46.346] iteration 2228 : model1 loss : 0.360282 model2 loss : 0.329190
[21:54:46.683] iteration 2229 : model1 loss : 0.340903 model2 loss : 0.340350
[21:54:47.020] iteration 2230 : model1 loss : 0.367405 model2 loss : 0.373283
[21:54:47.358] iteration 2231 : model1 loss : 0.438746 model2 loss : 0.351682
[21:54:47.700] iteration 2232 : model1 loss : 0.294591 model2 loss : 0.317781
[21:54:48.038] iteration 2233 : model1 loss : 0.360895 model2 loss : 0.318941
[21:54:48.376] iteration 2234 : model1 loss : 0.315265 model2 loss : 0.289526
[21:54:48.714] iteration 2235 : model1 loss : 0.350079 model2 loss : 0.294795
[21:54:49.054] iteration 2236 : model1 loss : 0.345123 model2 loss : 0.306362
[21:54:49.392] iteration 2237 : model1 loss : 0.338332 model2 loss : 0.314875
[21:54:49.730] iteration 2238 : model1 loss : 0.371940 model2 loss : 0.327997
[21:54:50.059] iteration 2239 : model1 loss : 0.273521 model2 loss : 0.215716
[21:54:50.388] iteration 2240 : model1 loss : 0.283838 model2 loss : 0.271210
[21:54:50.716] iteration 2241 : model1 loss : 0.325104 model2 loss : 0.297532
[21:54:51.045] iteration 2242 : model1 loss : 0.370338 model2 loss : 0.365747
[21:54:51.374] iteration 2243 : model1 loss : 0.243480 model2 loss : 0.246123
[21:54:51.702] iteration 2244 : model1 loss : 0.272258 model2 loss : 0.218802
[21:54:52.030] iteration 2245 : model1 loss : 0.380363 model2 loss : 0.367071
[21:54:52.358] iteration 2246 : model1 loss : 0.330603 model2 loss : 0.282951
[21:54:52.849] iteration 2247 : model1 loss : 0.390399 model2 loss : 0.326634
[21:54:53.178] iteration 2248 : model1 loss : 0.301929 model2 loss : 0.282860
[21:54:53.505] iteration 2249 : model1 loss : 0.363784 model2 loss : 0.378460
[21:54:53.833] iteration 2250 : model1 loss : 0.344840 model2 loss : 0.333493
[21:54:54.385] iteration 2251 : model1 loss : 0.322380 model2 loss : 0.290067
[21:54:54.712] iteration 2252 : model1 loss : 0.337134 model2 loss : 0.350416
[21:54:55.041] iteration 2253 : model1 loss : 0.327861 model2 loss : 0.270805
[21:54:55.369] iteration 2254 : model1 loss : 0.301299 model2 loss : 0.293591
[21:54:55.697] iteration 2255 : model1 loss : 0.335926 model2 loss : 0.266440
[21:54:56.025] iteration 2256 : model1 loss : 0.359580 model2 loss : 0.316438
[21:54:56.353] iteration 2257 : model1 loss : 0.352383 model2 loss : 0.288438
[21:54:56.681] iteration 2258 : model1 loss : 0.342443 model2 loss : 0.307530
[21:54:57.009] iteration 2259 : model1 loss : 0.328945 model2 loss : 0.294194
[21:54:57.337] iteration 2260 : model1 loss : 0.321887 model2 loss : 0.293712
[21:54:57.665] iteration 2261 : model1 loss : 0.321822 model2 loss : 0.289220
[21:54:57.995] iteration 2262 : model1 loss : 0.347893 model2 loss : 0.315898
[21:54:58.322] iteration 2263 : model1 loss : 0.250440 model2 loss : 0.199712
[21:54:58.649] iteration 2264 : model1 loss : 0.327668 model2 loss : 0.311403
[21:54:58.978] iteration 2265 : model1 loss : 0.331351 model2 loss : 0.300108
[21:54:59.305] iteration 2266 : model1 loss : 0.343318 model2 loss : 0.330334
[21:54:59.634] iteration 2267 : model1 loss : 0.288705 model2 loss : 0.275012
[21:54:59.962] iteration 2268 : model1 loss : 0.399053 model2 loss : 0.381923
[21:55:00.290] iteration 2269 : model1 loss : 0.398520 model2 loss : 0.391064
[21:55:00.618] iteration 2270 : model1 loss : 0.346826 model2 loss : 0.347804
[21:55:00.946] iteration 2271 : model1 loss : 0.338504 model2 loss : 0.263667
[21:55:01.274] iteration 2272 : model1 loss : 0.338796 model2 loss : 0.247432
[21:55:01.601] iteration 2273 : model1 loss : 0.272717 model2 loss : 0.240234
[21:55:01.930] iteration 2274 : model1 loss : 0.342737 model2 loss : 0.328536
[21:55:02.257] iteration 2275 : model1 loss : 0.366048 model2 loss : 0.314554
[21:55:02.585] iteration 2276 : model1 loss : 0.295117 model2 loss : 0.257433
[21:55:02.913] iteration 2277 : model1 loss : 0.377444 model2 loss : 0.387868
[21:55:03.247] iteration 2278 : model1 loss : 0.308574 model2 loss : 0.275993
[21:55:03.578] iteration 2279 : model1 loss : 0.413427 model2 loss : 0.355412
[21:55:03.906] iteration 2280 : model1 loss : 0.275337 model2 loss : 0.215599
[21:55:04.235] iteration 2281 : model1 loss : 0.481359 model2 loss : 0.449800
[21:55:04.567] iteration 2282 : model1 loss : 0.333817 model2 loss : 0.279666
[21:55:04.895] iteration 2283 : model1 loss : 0.299428 model2 loss : 0.232308
[21:55:05.223] iteration 2284 : model1 loss : 0.275211 model2 loss : 0.211153
[21:55:05.550] iteration 2285 : model1 loss : 0.367662 model2 loss : 0.302263
[21:55:05.878] iteration 2286 : model1 loss : 0.325504 model2 loss : 0.277252
[21:55:06.206] iteration 2287 : model1 loss : 0.302508 model2 loss : 0.292551
[21:55:06.533] iteration 2288 : model1 loss : 0.245686 model2 loss : 0.252379
[21:55:06.861] iteration 2289 : model1 loss : 0.387480 model2 loss : 0.328743
[21:55:07.190] iteration 2290 : model1 loss : 0.388289 model2 loss : 0.343916
[21:55:07.517] iteration 2291 : model1 loss : 0.417431 model2 loss : 0.419544
[21:55:07.845] iteration 2292 : model1 loss : 0.323244 model2 loss : 0.299658
[21:55:08.172] iteration 2293 : model1 loss : 0.329889 model2 loss : 0.266440
[21:55:08.500] iteration 2294 : model1 loss : 0.362690 model2 loss : 0.325843
[21:55:08.827] iteration 2295 : model1 loss : 0.292997 model2 loss : 0.264152
[21:55:09.154] iteration 2296 : model1 loss : 0.319385 model2 loss : 0.296389
[21:55:09.479] iteration 2297 : model1 loss : 0.370385 model2 loss : 0.382880
[21:55:09.806] iteration 2298 : model1 loss : 0.341494 model2 loss : 0.284040
[21:55:10.132] iteration 2299 : model1 loss : 0.261261 model2 loss : 0.227674
[21:55:10.458] iteration 2300 : model1 loss : 0.311682 model2 loss : 0.317874
[21:55:10.985] iteration 2301 : model1 loss : 0.347238 model2 loss : 0.290035
[21:55:11.312] iteration 2302 : model1 loss : 0.361530 model2 loss : 0.349707
[21:55:11.639] iteration 2303 : model1 loss : 0.305054 model2 loss : 0.261312
[21:55:11.965] iteration 2304 : model1 loss : 0.334604 model2 loss : 0.323183
[21:55:12.292] iteration 2305 : model1 loss : 0.335122 model2 loss : 0.313318
[21:55:12.618] iteration 2306 : model1 loss : 0.324307 model2 loss : 0.330379
[21:55:12.946] iteration 2307 : model1 loss : 0.370565 model2 loss : 0.341153
[21:55:13.271] iteration 2308 : model1 loss : 0.349649 model2 loss : 0.331224
[21:55:13.598] iteration 2309 : model1 loss : 0.265261 model2 loss : 0.234434
[21:55:13.924] iteration 2310 : model1 loss : 0.322176 model2 loss : 0.304879
[21:55:14.251] iteration 2311 : model1 loss : 0.376321 model2 loss : 0.365229
[21:55:14.577] iteration 2312 : model1 loss : 0.443084 model2 loss : 0.297356
[21:55:14.903] iteration 2313 : model1 loss : 0.300107 model2 loss : 0.258236
[21:55:15.230] iteration 2314 : model1 loss : 0.329179 model2 loss : 0.275652
[21:55:15.556] iteration 2315 : model1 loss : 0.359779 model2 loss : 0.341821
[21:55:15.881] iteration 2316 : model1 loss : 0.424879 model2 loss : 0.384157
[21:55:16.208] iteration 2317 : model1 loss : 0.401917 model2 loss : 0.344934
[21:55:16.534] iteration 2318 : model1 loss : 0.280755 model2 loss : 0.225124
[21:55:16.861] iteration 2319 : model1 loss : 0.373057 model2 loss : 0.396335
[21:55:17.187] iteration 2320 : model1 loss : 0.318634 model2 loss : 0.285368
[21:55:17.514] iteration 2321 : model1 loss : 0.272792 model2 loss : 0.240433
[21:55:17.840] iteration 2322 : model1 loss : 0.326266 model2 loss : 0.295395
[21:55:18.166] iteration 2323 : model1 loss : 0.274639 model2 loss : 0.262862
[21:55:18.493] iteration 2324 : model1 loss : 0.322857 model2 loss : 0.289587
[21:55:18.819] iteration 2325 : model1 loss : 0.327540 model2 loss : 0.290214
[21:55:19.145] iteration 2326 : model1 loss : 0.343799 model2 loss : 0.314811
[21:55:19.472] iteration 2327 : model1 loss : 0.282590 model2 loss : 0.301644
[21:55:19.798] iteration 2328 : model1 loss : 0.389996 model2 loss : 0.301230
[21:55:20.124] iteration 2329 : model1 loss : 0.371556 model2 loss : 0.345238
[21:55:20.450] iteration 2330 : model1 loss : 0.253547 model2 loss : 0.257889
[21:55:20.777] iteration 2331 : model1 loss : 0.265929 model2 loss : 0.258605
[21:55:21.102] iteration 2332 : model1 loss : 0.320036 model2 loss : 0.280584
[21:55:21.428] iteration 2333 : model1 loss : 0.403892 model2 loss : 0.348458
[21:55:21.755] iteration 2334 : model1 loss : 0.334197 model2 loss : 0.288516
[21:55:22.080] iteration 2335 : model1 loss : 0.316054 model2 loss : 0.209532
[21:55:22.406] iteration 2336 : model1 loss : 0.265964 model2 loss : 0.228370
[21:55:22.732] iteration 2337 : model1 loss : 0.384420 model2 loss : 0.398618
[21:55:23.057] iteration 2338 : model1 loss : 0.307108 model2 loss : 0.234983
[21:55:23.383] iteration 2339 : model1 loss : 0.250554 model2 loss : 0.239753
[21:55:23.714] iteration 2340 : model1 loss : 0.304652 model2 loss : 0.291328
[21:55:24.041] iteration 2341 : model1 loss : 0.272058 model2 loss : 0.249110
[21:55:24.368] iteration 2342 : model1 loss : 0.278611 model2 loss : 0.226900
[21:55:24.694] iteration 2343 : model1 loss : 0.336618 model2 loss : 0.413632
[21:55:25.023] iteration 2344 : model1 loss : 0.398654 model2 loss : 0.357857
[21:55:25.349] iteration 2345 : model1 loss : 0.362790 model2 loss : 0.250640
[21:55:25.675] iteration 2346 : model1 loss : 0.340200 model2 loss : 0.335159
[21:55:26.003] iteration 2347 : model1 loss : 0.258960 model2 loss : 0.227049
[21:55:26.332] iteration 2348 : model1 loss : 0.298347 model2 loss : 0.281924
[21:55:26.658] iteration 2349 : model1 loss : 0.340145 model2 loss : 0.315535
[21:55:26.983] iteration 2350 : model1 loss : 0.325705 model2 loss : 0.333513
[21:55:27.518] iteration 2351 : model1 loss : 0.337304 model2 loss : 0.274393
[21:55:27.846] iteration 2352 : model1 loss : 0.292806 model2 loss : 0.246732
[21:55:28.173] iteration 2353 : model1 loss : 0.343202 model2 loss : 0.305531
[21:55:28.500] iteration 2354 : model1 loss : 0.325826 model2 loss : 0.266703
[21:55:28.827] iteration 2355 : model1 loss : 0.320376 model2 loss : 0.291063
[21:55:29.154] iteration 2356 : model1 loss : 0.267917 model2 loss : 0.227725
[21:55:29.480] iteration 2357 : model1 loss : 0.386117 model2 loss : 0.382219
[21:55:29.805] iteration 2358 : model1 loss : 0.414621 model2 loss : 0.368007
[21:55:30.131] iteration 2359 : model1 loss : 0.243134 model2 loss : 0.223450
[21:55:30.459] iteration 2360 : model1 loss : 0.291083 model2 loss : 0.276031
[21:55:30.785] iteration 2361 : model1 loss : 0.347753 model2 loss : 0.308756
[21:55:31.111] iteration 2362 : model1 loss : 0.268101 model2 loss : 0.215540
[21:55:31.438] iteration 2363 : model1 loss : 0.314612 model2 loss : 0.300739
[21:55:31.766] iteration 2364 : model1 loss : 0.323839 model2 loss : 0.310297
[21:55:32.092] iteration 2365 : model1 loss : 0.320975 model2 loss : 0.283162
[21:55:32.418] iteration 2366 : model1 loss : 0.331932 model2 loss : 0.346213
[21:55:32.744] iteration 2367 : model1 loss : 0.301831 model2 loss : 0.274996
[21:55:33.074] iteration 2368 : model1 loss : 0.384310 model2 loss : 0.322815
[21:55:33.399] iteration 2369 : model1 loss : 0.460228 model2 loss : 0.406225
[21:55:33.726] iteration 2370 : model1 loss : 0.347476 model2 loss : 0.328032
[21:55:34.052] iteration 2371 : model1 loss : 0.372669 model2 loss : 0.329362
[21:55:34.379] iteration 2372 : model1 loss : 0.268977 model2 loss : 0.307550
[21:55:34.704] iteration 2373 : model1 loss : 0.305478 model2 loss : 0.280863
[21:55:35.031] iteration 2374 : model1 loss : 0.237166 model2 loss : 0.231851
[21:55:35.358] iteration 2375 : model1 loss : 0.329494 model2 loss : 0.295861
[21:55:35.685] iteration 2376 : model1 loss : 0.281285 model2 loss : 0.280645
[21:55:36.011] iteration 2377 : model1 loss : 0.339894 model2 loss : 0.326676
[21:55:36.341] iteration 2378 : model1 loss : 0.311094 model2 loss : 0.267230
[21:55:36.668] iteration 2379 : model1 loss : 0.308560 model2 loss : 0.292105
[21:55:36.995] iteration 2380 : model1 loss : 0.357166 model2 loss : 0.317185
[21:55:37.322] iteration 2381 : model1 loss : 0.305072 model2 loss : 0.299102
[21:55:37.648] iteration 2382 : model1 loss : 0.300794 model2 loss : 0.303649
[21:55:37.973] iteration 2383 : model1 loss : 0.284425 model2 loss : 0.264910
[21:55:38.301] iteration 2384 : model1 loss : 0.339757 model2 loss : 0.331479
[21:55:38.627] iteration 2385 : model1 loss : 0.315174 model2 loss : 0.306803
[21:55:38.954] iteration 2386 : model1 loss : 0.418882 model2 loss : 0.372439
[21:55:39.280] iteration 2387 : model1 loss : 0.323137 model2 loss : 0.327947
[21:55:39.607] iteration 2388 : model1 loss : 0.313910 model2 loss : 0.247037
[21:55:39.934] iteration 2389 : model1 loss : 0.289346 model2 loss : 0.279978
[21:55:40.260] iteration 2390 : model1 loss : 0.426991 model2 loss : 0.363834
[21:55:40.586] iteration 2391 : model1 loss : 0.312051 model2 loss : 0.291334
[21:55:40.914] iteration 2392 : model1 loss : 0.284321 model2 loss : 0.302433
[21:55:41.240] iteration 2393 : model1 loss : 0.300590 model2 loss : 0.284927
[21:55:41.568] iteration 2394 : model1 loss : 0.269367 model2 loss : 0.304088
[21:55:41.893] iteration 2395 : model1 loss : 0.362152 model2 loss : 0.284576
[21:55:42.222] iteration 2396 : model1 loss : 0.251886 model2 loss : 0.261109
[21:55:42.548] iteration 2397 : model1 loss : 0.331437 model2 loss : 0.319694
[21:55:42.875] iteration 2398 : model1 loss : 0.321215 model2 loss : 0.341264
[21:55:43.201] iteration 2399 : model1 loss : 0.344143 model2 loss : 0.337496
[21:55:43.529] iteration 2400 : model1 loss : 0.233981 model2 loss : 0.208758
[21:55:44.070] iteration 2401 : model1 loss : 0.264991 model2 loss : 0.230485
[21:55:44.396] iteration 2402 : model1 loss : 0.449295 model2 loss : 0.427492
[21:55:44.723] iteration 2403 : model1 loss : 0.313192 model2 loss : 0.386916
[21:55:45.051] iteration 2404 : model1 loss : 0.393670 model2 loss : 0.273904
[21:55:45.378] iteration 2405 : model1 loss : 0.262459 model2 loss : 0.284826
[21:55:45.704] iteration 2406 : model1 loss : 0.341594 model2 loss : 0.334046
[21:55:46.030] iteration 2407 : model1 loss : 0.362933 model2 loss : 0.348457
[21:55:46.359] iteration 2408 : model1 loss : 0.370504 model2 loss : 0.350927
[21:55:46.685] iteration 2409 : model1 loss : 0.284494 model2 loss : 0.270535
[21:55:47.011] iteration 2410 : model1 loss : 0.342664 model2 loss : 0.349792
[21:55:47.337] iteration 2411 : model1 loss : 0.364375 model2 loss : 0.350624
[21:55:47.665] iteration 2412 : model1 loss : 0.294547 model2 loss : 0.274276
[21:55:47.991] iteration 2413 : model1 loss : 0.318673 model2 loss : 0.255365
[21:55:48.318] iteration 2414 : model1 loss : 0.413076 model2 loss : 0.436397
[21:55:48.644] iteration 2415 : model1 loss : 0.353828 model2 loss : 0.351745
[21:55:48.971] iteration 2416 : model1 loss : 0.318838 model2 loss : 0.343297
[21:55:49.297] iteration 2417 : model1 loss : 0.321139 model2 loss : 0.204666
[21:55:49.624] iteration 2418 : model1 loss : 0.319137 model2 loss : 0.215456
[21:55:49.951] iteration 2419 : model1 loss : 0.432430 model2 loss : 0.357080
[21:55:50.279] iteration 2420 : model1 loss : 0.406130 model2 loss : 0.317513
[21:55:50.605] iteration 2421 : model1 loss : 0.346969 model2 loss : 0.315780
[21:55:50.932] iteration 2422 : model1 loss : 0.289507 model2 loss : 0.230878
[21:55:51.261] iteration 2423 : model1 loss : 0.365728 model2 loss : 0.307074
[21:55:51.589] iteration 2424 : model1 loss : 0.334148 model2 loss : 0.299605
[21:55:51.916] iteration 2425 : model1 loss : 0.346815 model2 loss : 0.321865
[21:55:52.242] iteration 2426 : model1 loss : 0.369462 model2 loss : 0.319395
[21:55:52.569] iteration 2427 : model1 loss : 0.305979 model2 loss : 0.251439
[21:55:52.898] iteration 2428 : model1 loss : 0.347674 model2 loss : 0.277288
[21:55:53.225] iteration 2429 : model1 loss : 0.347098 model2 loss : 0.296436
[21:55:53.554] iteration 2430 : model1 loss : 0.336735 model2 loss : 0.234916
[21:55:53.885] iteration 2431 : model1 loss : 0.262093 model2 loss : 0.218112
[21:55:54.215] iteration 2432 : model1 loss : 0.365479 model2 loss : 0.300128
[21:55:54.542] iteration 2433 : model1 loss : 0.262459 model2 loss : 0.194615
[21:55:54.869] iteration 2434 : model1 loss : 0.317386 model2 loss : 0.231555
[21:55:55.196] iteration 2435 : model1 loss : 0.327152 model2 loss : 0.248148
[21:55:55.527] iteration 2436 : model1 loss : 0.325457 model2 loss : 0.301766
[21:55:55.854] iteration 2437 : model1 loss : 0.321776 model2 loss : 0.253400
[21:55:56.181] iteration 2438 : model1 loss : 0.377744 model2 loss : 0.261826
[21:55:56.507] iteration 2439 : model1 loss : 0.385931 model2 loss : 0.374949
[21:55:56.835] iteration 2440 : model1 loss : 0.284887 model2 loss : 0.217489
[21:55:57.160] iteration 2441 : model1 loss : 0.304231 model2 loss : 0.249884
[21:55:57.486] iteration 2442 : model1 loss : 0.391672 model2 loss : 0.397068
[21:55:57.812] iteration 2443 : model1 loss : 0.383596 model2 loss : 0.352545
[21:55:58.139] iteration 2444 : model1 loss : 0.345217 model2 loss : 0.250475
[21:55:58.466] iteration 2445 : model1 loss : 0.374295 model2 loss : 0.301108
[21:55:58.791] iteration 2446 : model1 loss : 0.336312 model2 loss : 0.316316
[21:55:59.118] iteration 2447 : model1 loss : 0.343920 model2 loss : 0.331302
[21:55:59.448] iteration 2448 : model1 loss : 0.371816 model2 loss : 0.333588
[21:55:59.774] iteration 2449 : model1 loss : 0.329182 model2 loss : 0.255051
[21:56:00.100] iteration 2450 : model1 loss : 0.319024 model2 loss : 0.306038
[21:56:00.649] iteration 2451 : model1 loss : 0.361315 model2 loss : 0.295431
[21:56:00.979] iteration 2452 : model1 loss : 0.280768 model2 loss : 0.225445
[21:56:01.308] iteration 2453 : model1 loss : 0.393324 model2 loss : 0.348824
[21:56:01.635] iteration 2454 : model1 loss : 0.402348 model2 loss : 0.348743
[21:56:01.962] iteration 2455 : model1 loss : 0.346943 model2 loss : 0.356670
[21:56:02.292] iteration 2456 : model1 loss : 0.307844 model2 loss : 0.288605
[21:56:02.619] iteration 2457 : model1 loss : 0.369104 model2 loss : 0.321828
[21:56:02.946] iteration 2458 : model1 loss : 0.345515 model2 loss : 0.274479
[21:56:03.272] iteration 2459 : model1 loss : 0.324153 model2 loss : 0.261319
[21:56:03.601] iteration 2460 : model1 loss : 0.324112 model2 loss : 0.240550
[21:56:03.928] iteration 2461 : model1 loss : 0.310929 model2 loss : 0.248359
[21:56:04.256] iteration 2462 : model1 loss : 0.317306 model2 loss : 0.312216
[21:56:04.583] iteration 2463 : model1 loss : 0.403104 model2 loss : 0.352304
[21:56:04.911] iteration 2464 : model1 loss : 0.370706 model2 loss : 0.351846
[21:56:05.238] iteration 2465 : model1 loss : 0.406561 model2 loss : 0.273031
[21:56:05.566] iteration 2466 : model1 loss : 0.356792 model2 loss : 0.273097
[21:56:05.893] iteration 2467 : model1 loss : 0.327573 model2 loss : 0.306174
[21:56:06.222] iteration 2468 : model1 loss : 0.343679 model2 loss : 0.274883
[21:56:06.547] iteration 2469 : model1 loss : 0.328367 model2 loss : 0.274641
[21:56:06.873] iteration 2470 : model1 loss : 0.284070 model2 loss : 0.279094
[21:56:07.198] iteration 2471 : model1 loss : 0.296046 model2 loss : 0.265200
[21:56:07.526] iteration 2472 : model1 loss : 0.392385 model2 loss : 0.246166
[21:56:07.853] iteration 2473 : model1 loss : 0.406909 model2 loss : 0.428493
[21:56:08.178] iteration 2474 : model1 loss : 0.398102 model2 loss : 0.308854
[21:56:08.504] iteration 2475 : model1 loss : 0.332022 model2 loss : 0.289773
[21:56:08.835] iteration 2476 : model1 loss : 0.323108 model2 loss : 0.293701
[21:56:09.162] iteration 2477 : model1 loss : 0.356951 model2 loss : 0.325314
[21:56:09.489] iteration 2478 : model1 loss : 0.285974 model2 loss : 0.298117
[21:56:09.818] iteration 2479 : model1 loss : 0.320148 model2 loss : 0.277192
[21:56:10.151] iteration 2480 : model1 loss : 0.442218 model2 loss : 0.408364
[21:56:10.489] iteration 2481 : model1 loss : 0.320505 model2 loss : 0.265161
[21:56:10.844] iteration 2482 : model1 loss : 0.304111 model2 loss : 0.255578
[21:56:11.184] iteration 2483 : model1 loss : 0.413696 model2 loss : 0.354189
[21:56:11.525] iteration 2484 : model1 loss : 0.306282 model2 loss : 0.254806
[21:56:11.862] iteration 2485 : model1 loss : 0.358105 model2 loss : 0.315197
[21:56:12.204] iteration 2486 : model1 loss : 0.289281 model2 loss : 0.222392
[21:56:12.541] iteration 2487 : model1 loss : 0.328011 model2 loss : 0.324119
[21:56:12.881] iteration 2488 : model1 loss : 0.328653 model2 loss : 0.321015
[21:56:13.220] iteration 2489 : model1 loss : 0.295146 model2 loss : 0.250659
[21:56:13.558] iteration 2490 : model1 loss : 0.356900 model2 loss : 0.349784
[21:56:13.896] iteration 2491 : model1 loss : 0.323699 model2 loss : 0.253896
[21:56:14.233] iteration 2492 : model1 loss : 0.386044 model2 loss : 0.313567
[21:56:14.570] iteration 2493 : model1 loss : 0.358090 model2 loss : 0.353535
[21:56:14.909] iteration 2494 : model1 loss : 0.371951 model2 loss : 0.318098
[21:56:15.247] iteration 2495 : model1 loss : 0.257666 model2 loss : 0.224656
[21:56:15.586] iteration 2496 : model1 loss : 0.361586 model2 loss : 0.339224
[21:56:15.924] iteration 2497 : model1 loss : 0.410784 model2 loss : 0.371881
[21:56:16.262] iteration 2498 : model1 loss : 0.349435 model2 loss : 0.240413
[21:56:16.598] iteration 2499 : model1 loss : 0.338241 model2 loss : 0.304699
[21:56:16.934] iteration 2500 : model1 loss : 0.297665 model2 loss : 0.275410
[21:56:17.529] iteration 2501 : model1 loss : 0.323137 model2 loss : 0.235478
[21:56:17.867] iteration 2502 : model1 loss : 0.333105 model2 loss : 0.322368
[21:56:18.209] iteration 2503 : model1 loss : 0.329231 model2 loss : 0.260925
[21:56:18.550] iteration 2504 : model1 loss : 0.331893 model2 loss : 0.271888
[21:56:18.889] iteration 2505 : model1 loss : 0.269672 model2 loss : 0.251241
[21:56:19.228] iteration 2506 : model1 loss : 0.350866 model2 loss : 0.320884
[21:56:19.563] iteration 2507 : model1 loss : 0.297160 model2 loss : 0.290413
[21:56:19.898] iteration 2508 : model1 loss : 0.274714 model2 loss : 0.294714
[21:56:20.237] iteration 2509 : model1 loss : 0.382602 model2 loss : 0.365979
[21:56:20.574] iteration 2510 : model1 loss : 0.290168 model2 loss : 0.244165
[21:56:20.915] iteration 2511 : model1 loss : 0.359484 model2 loss : 0.251234
[21:56:21.251] iteration 2512 : model1 loss : 0.339655 model2 loss : 0.380131
[21:56:21.588] iteration 2513 : model1 loss : 0.350044 model2 loss : 0.333759
[21:56:21.927] iteration 2514 : model1 loss : 0.352149 model2 loss : 0.353040
[21:56:22.263] iteration 2515 : model1 loss : 0.306978 model2 loss : 0.287620
[21:56:22.599] iteration 2516 : model1 loss : 0.274630 model2 loss : 0.294989
[21:56:22.936] iteration 2517 : model1 loss : 0.343524 model2 loss : 0.306507
[21:56:23.276] iteration 2518 : model1 loss : 0.364287 model2 loss : 0.323927
[21:56:23.616] iteration 2519 : model1 loss : 0.367577 model2 loss : 0.322524
[21:56:23.955] iteration 2520 : model1 loss : 0.312296 model2 loss : 0.253753
[21:56:24.294] iteration 2521 : model1 loss : 0.332076 model2 loss : 0.316597
[21:56:24.630] iteration 2522 : model1 loss : 0.363079 model2 loss : 0.305092
[21:56:24.969] iteration 2523 : model1 loss : 0.273956 model2 loss : 0.254725
[21:56:25.306] iteration 2524 : model1 loss : 0.361724 model2 loss : 0.317113
[21:56:25.642] iteration 2525 : model1 loss : 0.265761 model2 loss : 0.251792
[21:56:25.982] iteration 2526 : model1 loss : 0.387185 model2 loss : 0.388587
[21:56:26.322] iteration 2527 : model1 loss : 0.268798 model2 loss : 0.230348
[21:56:26.659] iteration 2528 : model1 loss : 0.312261 model2 loss : 0.297567
[21:56:26.997] iteration 2529 : model1 loss : 0.314417 model2 loss : 0.279232
[21:56:27.334] iteration 2530 : model1 loss : 0.338757 model2 loss : 0.303693
[21:56:27.672] iteration 2531 : model1 loss : 0.294504 model2 loss : 0.271792
[21:56:28.008] iteration 2532 : model1 loss : 0.257731 model2 loss : 0.264490
[21:56:28.348] iteration 2533 : model1 loss : 0.290765 model2 loss : 0.258650
[21:56:28.685] iteration 2534 : model1 loss : 0.319819 model2 loss : 0.304020
[21:56:29.022] iteration 2535 : model1 loss : 0.334427 model2 loss : 0.294103
[21:56:29.361] iteration 2536 : model1 loss : 0.333544 model2 loss : 0.285622
[21:56:29.697] iteration 2537 : model1 loss : 0.250275 model2 loss : 0.199701
[21:56:30.034] iteration 2538 : model1 loss : 0.350535 model2 loss : 0.315320
[21:56:30.374] iteration 2539 : model1 loss : 0.295644 model2 loss : 0.196155
[21:56:30.711] iteration 2540 : model1 loss : 0.324994 model2 loss : 0.312181
[21:56:31.050] iteration 2541 : model1 loss : 0.371747 model2 loss : 0.309161
[21:56:31.386] iteration 2542 : model1 loss : 0.306314 model2 loss : 0.314874
[21:56:31.722] iteration 2543 : model1 loss : 0.315067 model2 loss : 0.283941
[21:56:32.058] iteration 2544 : model1 loss : 0.285634 model2 loss : 0.287694
[21:56:32.395] iteration 2545 : model1 loss : 0.300569 model2 loss : 0.243635
[21:56:32.733] iteration 2546 : model1 loss : 0.299946 model2 loss : 0.323350
[21:56:33.081] iteration 2547 : model1 loss : 0.256416 model2 loss : 0.218523
[21:56:33.424] iteration 2548 : model1 loss : 0.376270 model2 loss : 0.338130
[21:56:33.762] iteration 2549 : model1 loss : 0.293686 model2 loss : 0.268938
[21:56:34.100] iteration 2550 : model1 loss : 0.420461 model2 loss : 0.418922
[21:56:34.764] iteration 2551 : model1 loss : 0.313621 model2 loss : 0.299725
[21:56:35.101] iteration 2552 : model1 loss : 0.404899 model2 loss : 0.311574
[21:56:35.441] iteration 2553 : model1 loss : 0.277937 model2 loss : 0.262729
[21:56:35.793] iteration 2554 : model1 loss : 0.373711 model2 loss : 0.309427
[21:56:36.130] iteration 2555 : model1 loss : 0.364132 model2 loss : 0.456023
[21:56:36.470] iteration 2556 : model1 loss : 0.262731 model2 loss : 0.239283
[21:56:36.811] iteration 2557 : model1 loss : 0.268449 model2 loss : 0.258329
[21:56:37.149] iteration 2558 : model1 loss : 0.338689 model2 loss : 0.264201
[21:56:37.497] iteration 2559 : model1 loss : 0.316812 model2 loss : 0.275118
[21:56:37.834] iteration 2560 : model1 loss : 0.371653 model2 loss : 0.355922
[21:56:38.171] iteration 2561 : model1 loss : 0.340820 model2 loss : 0.333000
[21:56:38.514] iteration 2562 : model1 loss : 0.297626 model2 loss : 0.286996
[21:56:38.850] iteration 2563 : model1 loss : 0.381886 model2 loss : 0.333696
[21:56:39.186] iteration 2564 : model1 loss : 0.332473 model2 loss : 0.314810
[21:56:39.522] iteration 2565 : model1 loss : 0.373971 model2 loss : 0.358935
[21:56:39.858] iteration 2566 : model1 loss : 0.358707 model2 loss : 0.327925
[21:56:40.194] iteration 2567 : model1 loss : 0.306203 model2 loss : 0.278014
[21:56:40.531] iteration 2568 : model1 loss : 0.316645 model2 loss : 0.242480
[21:56:40.867] iteration 2569 : model1 loss : 0.355544 model2 loss : 0.273496
[21:56:41.204] iteration 2570 : model1 loss : 0.335009 model2 loss : 0.337523
[21:56:41.554] iteration 2571 : model1 loss : 0.268618 model2 loss : 0.221226
[21:56:41.898] iteration 2572 : model1 loss : 0.264545 model2 loss : 0.222774
[21:56:42.235] iteration 2573 : model1 loss : 0.337941 model2 loss : 0.253431
[21:56:42.572] iteration 2574 : model1 loss : 0.228700 model2 loss : 0.214514
[21:56:42.907] iteration 2575 : model1 loss : 0.387356 model2 loss : 0.336347
[21:56:43.242] iteration 2576 : model1 loss : 0.352017 model2 loss : 0.353639
[21:56:43.579] iteration 2577 : model1 loss : 0.329834 model2 loss : 0.334726
[21:56:43.915] iteration 2578 : model1 loss : 0.389302 model2 loss : 0.398045
[21:56:44.254] iteration 2579 : model1 loss : 0.334415 model2 loss : 0.285218
[21:56:44.592] iteration 2580 : model1 loss : 0.346046 model2 loss : 0.358018
[21:56:44.929] iteration 2581 : model1 loss : 0.384745 model2 loss : 0.404132
[21:56:45.268] iteration 2582 : model1 loss : 0.331094 model2 loss : 0.305851
[21:56:45.610] iteration 2583 : model1 loss : 0.306190 model2 loss : 0.307041
[21:56:45.947] iteration 2584 : model1 loss : 0.240989 model2 loss : 0.232978
[21:56:46.286] iteration 2585 : model1 loss : 0.269033 model2 loss : 0.242095
[21:56:46.628] iteration 2586 : model1 loss : 0.321151 model2 loss : 0.270302
[21:56:46.965] iteration 2587 : model1 loss : 0.371052 model2 loss : 0.338492
[21:56:47.313] iteration 2588 : model1 loss : 0.266772 model2 loss : 0.253800
[21:56:47.656] iteration 2589 : model1 loss : 0.303058 model2 loss : 0.283628
[21:56:47.993] iteration 2590 : model1 loss : 0.288430 model2 loss : 0.230774
[21:56:48.332] iteration 2591 : model1 loss : 0.358624 model2 loss : 0.333074
[21:56:48.670] iteration 2592 : model1 loss : 0.286973 model2 loss : 0.322510
[21:56:49.007] iteration 2593 : model1 loss : 0.267217 model2 loss : 0.229845
[21:56:49.344] iteration 2594 : model1 loss : 0.336414 model2 loss : 0.278038
[21:56:49.682] iteration 2595 : model1 loss : 0.284967 model2 loss : 0.239430
[21:56:50.019] iteration 2596 : model1 loss : 0.292395 model2 loss : 0.373729
[21:56:50.357] iteration 2597 : model1 loss : 0.432499 model2 loss : 0.342725
[21:56:50.693] iteration 2598 : model1 loss : 0.320872 model2 loss : 0.279516
[21:56:51.031] iteration 2599 : model1 loss : 0.314671 model2 loss : 0.297864
[21:56:51.368] iteration 2600 : model1 loss : 0.354361 model2 loss : 0.289329
[21:56:52.015] iteration 2601 : model1 loss : 0.283002 model2 loss : 0.264768
[21:56:52.356] iteration 2602 : model1 loss : 0.264102 model2 loss : 0.247713
[21:56:52.693] iteration 2603 : model1 loss : 0.287222 model2 loss : 0.327577
[21:56:53.032] iteration 2604 : model1 loss : 0.311191 model2 loss : 0.244564
[21:56:53.371] iteration 2605 : model1 loss : 0.345579 model2 loss : 0.358339
[21:56:53.715] iteration 2606 : model1 loss : 0.349944 model2 loss : 0.408092
[21:56:54.055] iteration 2607 : model1 loss : 0.252335 model2 loss : 0.245163
[21:56:54.393] iteration 2608 : model1 loss : 0.273607 model2 loss : 0.307346
[21:56:54.732] iteration 2609 : model1 loss : 0.355493 model2 loss : 0.293488
[21:56:55.074] iteration 2610 : model1 loss : 0.337074 model2 loss : 0.319595
[21:56:55.413] iteration 2611 : model1 loss : 0.336508 model2 loss : 0.263304
[21:56:55.751] iteration 2612 : model1 loss : 0.301189 model2 loss : 0.263313
[21:56:56.091] iteration 2613 : model1 loss : 0.326923 model2 loss : 0.296384
[21:56:56.430] iteration 2614 : model1 loss : 0.267065 model2 loss : 0.360994
[21:56:56.767] iteration 2615 : model1 loss : 0.278583 model2 loss : 0.272807
[21:56:57.106] iteration 2616 : model1 loss : 0.334084 model2 loss : 0.290659
[21:56:57.443] iteration 2617 : model1 loss : 0.349669 model2 loss : 0.293841
[21:56:57.783] iteration 2618 : model1 loss : 0.276631 model2 loss : 0.272847
[21:56:58.121] iteration 2619 : model1 loss : 0.374205 model2 loss : 0.337884
[21:56:58.462] iteration 2620 : model1 loss : 0.359861 model2 loss : 0.350732
[21:56:58.798] iteration 2621 : model1 loss : 0.339593 model2 loss : 0.313498
[21:56:59.136] iteration 2622 : model1 loss : 0.257800 model2 loss : 0.247667
[21:56:59.477] iteration 2623 : model1 loss : 0.329164 model2 loss : 0.349246
[21:56:59.816] iteration 2624 : model1 loss : 0.418573 model2 loss : 0.339105
[21:57:00.153] iteration 2625 : model1 loss : 0.292963 model2 loss : 0.270387
[21:57:00.491] iteration 2626 : model1 loss : 0.332749 model2 loss : 0.300542
[21:57:00.818] iteration 2627 : model1 loss : 0.320257 model2 loss : 0.324547
[21:57:01.148] iteration 2628 : model1 loss : 0.315944 model2 loss : 0.277174
[21:57:01.475] iteration 2629 : model1 loss : 0.271293 model2 loss : 0.292345
[21:57:01.801] iteration 2630 : model1 loss : 0.403507 model2 loss : 0.431575
[21:57:02.129] iteration 2631 : model1 loss : 0.352318 model2 loss : 0.277296
[21:57:02.457] iteration 2632 : model1 loss : 0.270385 model2 loss : 0.236432
[21:57:02.786] iteration 2633 : model1 loss : 0.507218 model2 loss : 0.404018
[21:57:03.115] iteration 2634 : model1 loss : 0.483520 model2 loss : 0.460544
[21:57:03.444] iteration 2635 : model1 loss : 0.306822 model2 loss : 0.224673
[21:57:03.774] iteration 2636 : model1 loss : 0.227949 model2 loss : 0.238209
[21:57:04.103] iteration 2637 : model1 loss : 0.276950 model2 loss : 0.315622
[21:57:04.435] iteration 2638 : model1 loss : 0.319664 model2 loss : 0.276724
[21:57:04.765] iteration 2639 : model1 loss : 0.304333 model2 loss : 0.239061
[21:57:05.095] iteration 2640 : model1 loss : 0.479015 model2 loss : 0.345349
[21:57:05.427] iteration 2641 : model1 loss : 0.393990 model2 loss : 0.362312
[21:57:05.757] iteration 2642 : model1 loss : 0.253977 model2 loss : 0.265774
[21:57:06.087] iteration 2643 : model1 loss : 0.285812 model2 loss : 0.325416
[21:57:06.419] iteration 2644 : model1 loss : 0.432184 model2 loss : 0.422467
[21:57:06.747] iteration 2645 : model1 loss : 0.315276 model2 loss : 0.301916
[21:57:07.073] iteration 2646 : model1 loss : 0.310317 model2 loss : 0.304697
[21:57:07.401] iteration 2647 : model1 loss : 0.304509 model2 loss : 0.319627
[21:57:07.728] iteration 2648 : model1 loss : 0.340494 model2 loss : 0.254365
[21:57:08.055] iteration 2649 : model1 loss : 0.419443 model2 loss : 0.336838
[21:57:08.382] iteration 2650 : model1 loss : 0.411603 model2 loss : 0.382748
[21:57:08.949] iteration 2651 : model1 loss : 0.388349 model2 loss : 0.249848
[21:57:09.277] iteration 2652 : model1 loss : 0.242338 model2 loss : 0.180142
[21:57:09.605] iteration 2653 : model1 loss : 0.295577 model2 loss : 0.281250
[21:57:09.932] iteration 2654 : model1 loss : 0.317230 model2 loss : 0.323285
[21:57:10.260] iteration 2655 : model1 loss : 0.355752 model2 loss : 0.350049
[21:57:10.589] iteration 2656 : model1 loss : 0.389022 model2 loss : 0.303023
[21:57:10.918] iteration 2657 : model1 loss : 0.279117 model2 loss : 0.245767
[21:57:11.248] iteration 2658 : model1 loss : 0.263364 model2 loss : 0.279263
[21:57:11.578] iteration 2659 : model1 loss : 0.346529 model2 loss : 0.335811
[21:57:11.906] iteration 2660 : model1 loss : 0.372162 model2 loss : 0.353327
[21:57:12.233] iteration 2661 : model1 loss : 0.308650 model2 loss : 0.331256
[21:57:12.561] iteration 2662 : model1 loss : 0.319904 model2 loss : 0.265414
[21:57:12.889] iteration 2663 : model1 loss : 0.306169 model2 loss : 0.275219
[21:57:13.218] iteration 2664 : model1 loss : 0.309810 model2 loss : 0.308883
[21:57:13.547] iteration 2665 : model1 loss : 0.341187 model2 loss : 0.262444
[21:57:13.877] iteration 2666 : model1 loss : 0.310700 model2 loss : 0.300258
[21:57:14.206] iteration 2667 : model1 loss : 0.337358 model2 loss : 0.335722
[21:57:14.534] iteration 2668 : model1 loss : 0.361484 model2 loss : 0.381539
[21:57:14.862] iteration 2669 : model1 loss : 0.302556 model2 loss : 0.267113
[21:57:15.197] iteration 2670 : model1 loss : 0.366988 model2 loss : 0.351285
[21:57:15.526] iteration 2671 : model1 loss : 0.397266 model2 loss : 0.401952
[21:57:15.854] iteration 2672 : model1 loss : 0.419171 model2 loss : 0.355385
[21:57:16.182] iteration 2673 : model1 loss : 0.325346 model2 loss : 0.321655
[21:57:16.511] iteration 2674 : model1 loss : 0.290196 model2 loss : 0.256844
[21:57:16.842] iteration 2675 : model1 loss : 0.356098 model2 loss : 0.346701
[21:57:17.170] iteration 2676 : model1 loss : 0.312831 model2 loss : 0.298190
[21:57:17.499] iteration 2677 : model1 loss : 0.232084 model2 loss : 0.190708
[21:57:17.827] iteration 2678 : model1 loss : 0.284140 model2 loss : 0.232376
[21:57:18.156] iteration 2679 : model1 loss : 0.278024 model2 loss : 0.311408
[21:57:18.485] iteration 2680 : model1 loss : 0.348537 model2 loss : 0.347165
[21:57:18.814] iteration 2681 : model1 loss : 0.272367 model2 loss : 0.229199
[21:57:19.143] iteration 2682 : model1 loss : 0.388990 model2 loss : 0.392140
[21:57:19.472] iteration 2683 : model1 loss : 0.301595 model2 loss : 0.292350
[21:57:19.800] iteration 2684 : model1 loss : 0.331353 model2 loss : 0.299024
[21:57:20.130] iteration 2685 : model1 loss : 0.401587 model2 loss : 0.367209
[21:57:20.460] iteration 2686 : model1 loss : 0.355797 model2 loss : 0.341934
[21:57:20.789] iteration 2687 : model1 loss : 0.342387 model2 loss : 0.326317
[21:57:21.117] iteration 2688 : model1 loss : 0.263823 model2 loss : 0.260120
[21:57:21.445] iteration 2689 : model1 loss : 0.203630 model2 loss : 0.153687
[21:57:21.774] iteration 2690 : model1 loss : 0.336755 model2 loss : 0.305987
[21:57:22.107] iteration 2691 : model1 loss : 0.459649 model2 loss : 0.375401
[21:57:22.435] iteration 2692 : model1 loss : 0.343610 model2 loss : 0.320432
[21:57:22.774] iteration 2693 : model1 loss : 0.387520 model2 loss : 0.355782
[21:57:23.114] iteration 2694 : model1 loss : 0.332018 model2 loss : 0.326536
[21:57:23.456] iteration 2695 : model1 loss : 0.327986 model2 loss : 0.226014
[21:57:23.798] iteration 2696 : model1 loss : 0.364997 model2 loss : 0.317168
[21:57:24.140] iteration 2697 : model1 loss : 0.310560 model2 loss : 0.289480
[21:57:24.480] iteration 2698 : model1 loss : 0.324375 model2 loss : 0.340487
[21:57:24.819] iteration 2699 : model1 loss : 0.285269 model2 loss : 0.226818
[21:57:25.168] iteration 2700 : model1 loss : 0.394160 model2 loss : 0.391646
[21:57:25.816] iteration 2701 : model1 loss : 0.292248 model2 loss : 0.281205
[21:57:26.156] iteration 2702 : model1 loss : 0.335776 model2 loss : 0.269813
[21:57:26.498] iteration 2703 : model1 loss : 0.491736 model2 loss : 0.304261
[21:57:26.837] iteration 2704 : model1 loss : 0.400474 model2 loss : 0.344044
[21:57:27.174] iteration 2705 : model1 loss : 0.265420 model2 loss : 0.142090
[21:57:27.511] iteration 2706 : model1 loss : 0.316063 model2 loss : 0.197791
[21:57:27.848] iteration 2707 : model1 loss : 0.354112 model2 loss : 0.306128
[21:57:28.186] iteration 2708 : model1 loss : 0.367101 model2 loss : 0.365927
[21:57:28.522] iteration 2709 : model1 loss : 0.322898 model2 loss : 0.304935
[21:57:28.859] iteration 2710 : model1 loss : 0.275291 model2 loss : 0.268343
[21:57:29.196] iteration 2711 : model1 loss : 0.355496 model2 loss : 0.346348
[21:57:29.534] iteration 2712 : model1 loss : 0.363685 model2 loss : 0.321447
[21:57:29.871] iteration 2713 : model1 loss : 0.326914 model2 loss : 0.325763
[21:57:30.209] iteration 2714 : model1 loss : 0.302021 model2 loss : 0.282545
[21:57:30.546] iteration 2715 : model1 loss : 0.379348 model2 loss : 0.325488
[21:57:30.886] iteration 2716 : model1 loss : 0.351008 model2 loss : 0.250789
[21:57:31.222] iteration 2717 : model1 loss : 0.336222 model2 loss : 0.332307
[21:57:31.561] iteration 2718 : model1 loss : 0.377592 model2 loss : 0.424502
[21:57:31.896] iteration 2719 : model1 loss : 0.354906 model2 loss : 0.295345
[21:57:32.233] iteration 2720 : model1 loss : 0.311395 model2 loss : 0.273342
[21:57:32.568] iteration 2721 : model1 loss : 0.340502 model2 loss : 0.348497
[21:57:32.903] iteration 2722 : model1 loss : 0.331319 model2 loss : 0.329037
[21:57:33.238] iteration 2723 : model1 loss : 0.261047 model2 loss : 0.260938
[21:57:33.573] iteration 2724 : model1 loss : 0.289906 model2 loss : 0.292511
[21:57:33.908] iteration 2725 : model1 loss : 0.331921 model2 loss : 0.315351
[21:57:34.964] iteration 2726 : model1 loss : 0.354324 model2 loss : 0.288904
[21:57:35.302] iteration 2727 : model1 loss : 0.287897 model2 loss : 0.282613
[21:57:35.642] iteration 2728 : model1 loss : 0.336521 model2 loss : 0.311941
[21:57:35.979] iteration 2729 : model1 loss : 0.323101 model2 loss : 0.279317
[21:57:36.316] iteration 2730 : model1 loss : 0.287697 model2 loss : 0.259113
[21:57:36.657] iteration 2731 : model1 loss : 0.370064 model2 loss : 0.292765
[21:57:36.995] iteration 2732 : model1 loss : 0.216186 model2 loss : 0.184626
[21:57:37.333] iteration 2733 : model1 loss : 0.349723 model2 loss : 0.322122
[21:57:37.673] iteration 2734 : model1 loss : 0.375917 model2 loss : 0.372692
[21:57:38.013] iteration 2735 : model1 loss : 0.320069 model2 loss : 0.257347
[21:57:38.352] iteration 2736 : model1 loss : 0.375741 model2 loss : 0.279444
[21:57:38.691] iteration 2737 : model1 loss : 0.227966 model2 loss : 0.211233
[21:57:39.035] iteration 2738 : model1 loss : 0.270261 model2 loss : 0.260287
[21:57:39.380] iteration 2739 : model1 loss : 0.303087 model2 loss : 0.259354
[21:57:39.716] iteration 2740 : model1 loss : 0.343685 model2 loss : 0.258126
[21:57:40.051] iteration 2741 : model1 loss : 0.425514 model2 loss : 0.336471
[21:57:40.390] iteration 2742 : model1 loss : 0.323679 model2 loss : 0.298444
[21:57:40.731] iteration 2743 : model1 loss : 0.356777 model2 loss : 0.289980
[21:57:41.072] iteration 2744 : model1 loss : 0.278282 model2 loss : 0.234969
[21:57:41.412] iteration 2745 : model1 loss : 0.343064 model2 loss : 0.344509
[21:57:41.752] iteration 2746 : model1 loss : 0.291560 model2 loss : 0.216854
[21:57:42.090] iteration 2747 : model1 loss : 0.288725 model2 loss : 0.275994
[21:57:42.430] iteration 2748 : model1 loss : 0.320006 model2 loss : 0.348462
[21:57:42.768] iteration 2749 : model1 loss : 0.257180 model2 loss : 0.216337
[21:57:43.112] iteration 2750 : model1 loss : 0.272145 model2 loss : 0.250343
[21:57:43.747] iteration 2751 : model1 loss : 0.322825 model2 loss : 0.292545
[21:57:44.083] iteration 2752 : model1 loss : 0.389590 model2 loss : 0.379022
[21:57:44.414] iteration 2753 : model1 loss : 0.287964 model2 loss : 0.293963
[21:57:44.744] iteration 2754 : model1 loss : 0.268577 model2 loss : 0.253389
[21:57:45.073] iteration 2755 : model1 loss : 0.375699 model2 loss : 0.432813
[21:57:45.402] iteration 2756 : model1 loss : 0.367102 model2 loss : 0.361731
[21:57:45.732] iteration 2757 : model1 loss : 0.343459 model2 loss : 0.336835
[21:57:46.064] iteration 2758 : model1 loss : 0.315593 model2 loss : 0.261891
[21:57:46.393] iteration 2759 : model1 loss : 0.324489 model2 loss : 0.328834
[21:57:46.722] iteration 2760 : model1 loss : 0.452555 model2 loss : 0.406770
[21:57:47.051] iteration 2761 : model1 loss : 0.350399 model2 loss : 0.384995
[21:57:47.380] iteration 2762 : model1 loss : 0.383707 model2 loss : 0.377016
[21:57:47.709] iteration 2763 : model1 loss : 0.283932 model2 loss : 0.282893
[21:57:48.038] iteration 2764 : model1 loss : 0.303368 model2 loss : 0.264310
[21:57:48.370] iteration 2765 : model1 loss : 0.288374 model2 loss : 0.222946
[21:57:48.699] iteration 2766 : model1 loss : 0.219549 model2 loss : 0.254769
[21:57:49.028] iteration 2767 : model1 loss : 0.381261 model2 loss : 0.358707
[21:57:49.357] iteration 2768 : model1 loss : 0.250206 model2 loss : 0.241122
[21:57:49.691] iteration 2769 : model1 loss : 0.325042 model2 loss : 0.309756
[21:57:50.025] iteration 2770 : model1 loss : 0.238176 model2 loss : 0.219284
[21:57:50.354] iteration 2771 : model1 loss : 0.369115 model2 loss : 0.342172
[21:57:50.683] iteration 2772 : model1 loss : 0.236270 model2 loss : 0.240295
[21:57:51.012] iteration 2773 : model1 loss : 0.325459 model2 loss : 0.332896
[21:57:51.341] iteration 2774 : model1 loss : 0.327692 model2 loss : 0.309719
[21:57:51.670] iteration 2775 : model1 loss : 0.288914 model2 loss : 0.244128
[21:57:51.999] iteration 2776 : model1 loss : 0.395594 model2 loss : 0.395457
[21:57:52.349] iteration 2777 : model1 loss : 0.336002 model2 loss : 0.305695
[21:57:52.687] iteration 2778 : model1 loss : 0.289904 model2 loss : 0.287353
[21:57:53.025] iteration 2779 : model1 loss : 0.297819 model2 loss : 0.286342
[21:57:53.363] iteration 2780 : model1 loss : 0.370838 model2 loss : 0.217085
[21:57:53.700] iteration 2781 : model1 loss : 0.293762 model2 loss : 0.283500
[21:57:54.029] iteration 2782 : model1 loss : 0.321732 model2 loss : 0.286601
[21:57:54.364] iteration 2783 : model1 loss : 0.245145 model2 loss : 0.188710
[21:57:54.693] iteration 2784 : model1 loss : 0.270946 model2 loss : 0.195721
[21:57:55.022] iteration 2785 : model1 loss : 0.422275 model2 loss : 0.350773
[21:57:55.350] iteration 2786 : model1 loss : 0.297282 model2 loss : 0.269906
[21:57:55.680] iteration 2787 : model1 loss : 0.317584 model2 loss : 0.337448
[21:57:56.008] iteration 2788 : model1 loss : 0.322556 model2 loss : 0.334360
[21:57:56.337] iteration 2789 : model1 loss : 0.365794 model2 loss : 0.381157
[21:57:56.676] iteration 2790 : model1 loss : 0.251167 model2 loss : 0.200281
[21:57:57.015] iteration 2791 : model1 loss : 0.286142 model2 loss : 0.205948
[21:57:57.354] iteration 2792 : model1 loss : 0.302640 model2 loss : 0.319348
[21:57:57.693] iteration 2793 : model1 loss : 0.237245 model2 loss : 0.229751
[21:57:58.031] iteration 2794 : model1 loss : 0.459927 model2 loss : 0.395198
[21:57:58.369] iteration 2795 : model1 loss : 0.319203 model2 loss : 0.265568
[21:57:58.707] iteration 2796 : model1 loss : 0.341521 model2 loss : 0.339758
[21:57:59.048] iteration 2797 : model1 loss : 0.348448 model2 loss : 0.287578
[21:57:59.390] iteration 2798 : model1 loss : 0.364324 model2 loss : 0.355733
[21:57:59.731] iteration 2799 : model1 loss : 0.294754 model2 loss : 0.193916
[21:58:00.070] iteration 2800 : model1 loss : 0.310598 model2 loss : 0.358300
[21:58:00.731] iteration 2801 : model1 loss : 0.276776 model2 loss : 0.280392
[21:58:01.069] iteration 2802 : model1 loss : 0.362572 model2 loss : 0.334914
[21:58:01.409] iteration 2803 : model1 loss : 0.318087 model2 loss : 0.280094
[21:58:01.748] iteration 2804 : model1 loss : 0.352568 model2 loss : 0.318512
[21:58:02.086] iteration 2805 : model1 loss : 0.292413 model2 loss : 0.227113
[21:58:02.427] iteration 2806 : model1 loss : 0.278591 model2 loss : 0.210910
[21:58:02.766] iteration 2807 : model1 loss : 0.312913 model2 loss : 0.324325
[21:58:03.107] iteration 2808 : model1 loss : 0.303813 model2 loss : 0.278367
[21:58:03.445] iteration 2809 : model1 loss : 0.307375 model2 loss : 0.281449
[21:58:03.785] iteration 2810 : model1 loss : 0.354606 model2 loss : 0.297379
[21:58:04.125] iteration 2811 : model1 loss : 0.303720 model2 loss : 0.274067
[21:58:04.466] iteration 2812 : model1 loss : 0.337162 model2 loss : 0.297971
[21:58:04.809] iteration 2813 : model1 loss : 0.326077 model2 loss : 0.322753
[21:58:05.147] iteration 2814 : model1 loss : 0.224696 model2 loss : 0.199636
[21:58:05.484] iteration 2815 : model1 loss : 0.305775 model2 loss : 0.273350
[21:58:05.822] iteration 2816 : model1 loss : 0.282090 model2 loss : 0.270417
[21:58:06.159] iteration 2817 : model1 loss : 0.322301 model2 loss : 0.285224
[21:58:06.508] iteration 2818 : model1 loss : 0.209947 model2 loss : 0.206610
[21:58:06.837] iteration 2819 : model1 loss : 0.367749 model2 loss : 0.323789
[21:58:07.168] iteration 2820 : model1 loss : 0.392977 model2 loss : 0.350897
[21:58:07.497] iteration 2821 : model1 loss : 0.277999 model2 loss : 0.295890
[21:58:07.825] iteration 2822 : model1 loss : 0.297999 model2 loss : 0.299928
[21:58:08.153] iteration 2823 : model1 loss : 0.274730 model2 loss : 0.296240
[21:58:08.482] iteration 2824 : model1 loss : 0.338441 model2 loss : 0.318973
[21:58:08.814] iteration 2825 : model1 loss : 0.332835 model2 loss : 0.275322
[21:58:09.148] iteration 2826 : model1 loss : 0.329219 model2 loss : 0.293958
[21:58:09.478] iteration 2827 : model1 loss : 0.347662 model2 loss : 0.344510
[21:58:09.810] iteration 2828 : model1 loss : 0.330287 model2 loss : 0.245057
[21:58:10.139] iteration 2829 : model1 loss : 0.344952 model2 loss : 0.283886
[21:58:10.469] iteration 2830 : model1 loss : 0.266424 model2 loss : 0.220922
[21:58:10.797] iteration 2831 : model1 loss : 0.261280 model2 loss : 0.236461
[21:58:11.126] iteration 2832 : model1 loss : 0.325876 model2 loss : 0.291173
[21:58:11.461] iteration 2833 : model1 loss : 0.305197 model2 loss : 0.284168
[21:58:11.795] iteration 2834 : model1 loss : 0.333032 model2 loss : 0.306070
[21:58:12.123] iteration 2835 : model1 loss : 0.392236 model2 loss : 0.369577
[21:58:12.458] iteration 2836 : model1 loss : 0.249004 model2 loss : 0.212664
[21:58:12.786] iteration 2837 : model1 loss : 0.384427 model2 loss : 0.315184
[21:58:13.114] iteration 2838 : model1 loss : 0.293028 model2 loss : 0.255993
[21:58:13.442] iteration 2839 : model1 loss : 0.286456 model2 loss : 0.248945
[21:58:13.770] iteration 2840 : model1 loss : 0.247610 model2 loss : 0.212559
[21:58:14.099] iteration 2841 : model1 loss : 0.334685 model2 loss : 0.325377
[21:58:14.434] iteration 2842 : model1 loss : 0.362645 model2 loss : 0.324862
[21:58:14.763] iteration 2843 : model1 loss : 0.321716 model2 loss : 0.287541
[21:58:15.091] iteration 2844 : model1 loss : 0.314292 model2 loss : 0.282976
[21:58:15.420] iteration 2845 : model1 loss : 0.438866 model2 loss : 0.420736
[21:58:15.748] iteration 2846 : model1 loss : 0.382486 model2 loss : 0.317449
[21:58:16.076] iteration 2847 : model1 loss : 0.266146 model2 loss : 0.256110
[21:58:16.405] iteration 2848 : model1 loss : 0.348906 model2 loss : 0.347743
[21:58:16.733] iteration 2849 : model1 loss : 0.360439 model2 loss : 0.362540
[21:58:17.061] iteration 2850 : model1 loss : 0.295741 model2 loss : 0.290745
[21:58:17.616] iteration 2851 : model1 loss : 0.381253 model2 loss : 0.342887
[21:58:17.945] iteration 2852 : model1 loss : 0.291249 model2 loss : 0.334774
[21:58:18.273] iteration 2853 : model1 loss : 0.307448 model2 loss : 0.259043
[21:58:18.600] iteration 2854 : model1 loss : 0.325986 model2 loss : 0.271145
[21:58:18.929] iteration 2855 : model1 loss : 0.349168 model2 loss : 0.355075
[21:58:19.257] iteration 2856 : model1 loss : 0.399541 model2 loss : 0.403261
[21:58:19.585] iteration 2857 : model1 loss : 0.359840 model2 loss : 0.333835
[21:58:19.914] iteration 2858 : model1 loss : 0.360487 model2 loss : 0.366807
[21:58:20.241] iteration 2859 : model1 loss : 0.273451 model2 loss : 0.275876
[21:58:20.570] iteration 2860 : model1 loss : 0.296226 model2 loss : 0.355222
[21:58:20.898] iteration 2861 : model1 loss : 0.308434 model2 loss : 0.274237
[21:58:21.227] iteration 2862 : model1 loss : 0.325788 model2 loss : 0.405966
[21:58:21.555] iteration 2863 : model1 loss : 0.386239 model2 loss : 0.365564
[21:58:21.885] iteration 2864 : model1 loss : 0.298258 model2 loss : 0.290528
[21:58:22.212] iteration 2865 : model1 loss : 0.431137 model2 loss : 0.328967
[21:58:22.540] iteration 2866 : model1 loss : 0.297272 model2 loss : 0.311584
[21:58:22.868] iteration 2867 : model1 loss : 0.317827 model2 loss : 0.333782
[21:58:23.197] iteration 2868 : model1 loss : 0.347837 model2 loss : 0.318141
[21:58:23.525] iteration 2869 : model1 loss : 0.296027 model2 loss : 0.283340
[21:58:23.853] iteration 2870 : model1 loss : 0.345785 model2 loss : 0.315926
[21:58:24.182] iteration 2871 : model1 loss : 0.281627 model2 loss : 0.220208
[21:58:24.510] iteration 2872 : model1 loss : 0.317235 model2 loss : 0.309662
[21:58:24.839] iteration 2873 : model1 loss : 0.301223 model2 loss : 0.312154
[21:58:25.167] iteration 2874 : model1 loss : 0.305613 model2 loss : 0.280591
[21:58:25.496] iteration 2875 : model1 loss : 0.377894 model2 loss : 0.275838
[21:58:25.826] iteration 2876 : model1 loss : 0.302459 model2 loss : 0.257947
[21:58:26.165] iteration 2877 : model1 loss : 0.391877 model2 loss : 0.382029
[21:58:26.503] iteration 2878 : model1 loss : 0.373357 model2 loss : 0.345351
[21:58:26.840] iteration 2879 : model1 loss : 0.267599 model2 loss : 0.220581
[21:58:27.177] iteration 2880 : model1 loss : 0.298882 model2 loss : 0.272158
[21:58:27.515] iteration 2881 : model1 loss : 0.318720 model2 loss : 0.309303
[21:58:27.853] iteration 2882 : model1 loss : 0.290871 model2 loss : 0.299759
[21:58:28.191] iteration 2883 : model1 loss : 0.327257 model2 loss : 0.280360
[21:58:28.528] iteration 2884 : model1 loss : 0.333238 model2 loss : 0.348414
[21:58:28.866] iteration 2885 : model1 loss : 0.334436 model2 loss : 0.316567
[21:58:29.203] iteration 2886 : model1 loss : 0.277946 model2 loss : 0.285032
[21:58:29.541] iteration 2887 : model1 loss : 0.305053 model2 loss : 0.267713
[21:58:29.880] iteration 2888 : model1 loss : 0.325882 model2 loss : 0.325271
[21:58:30.219] iteration 2889 : model1 loss : 0.350357 model2 loss : 0.375333
[21:58:30.557] iteration 2890 : model1 loss : 0.336998 model2 loss : 0.312856
[21:58:30.894] iteration 2891 : model1 loss : 0.348946 model2 loss : 0.340004
[21:58:31.232] iteration 2892 : model1 loss : 0.330049 model2 loss : 0.305427
[21:58:31.570] iteration 2893 : model1 loss : 0.340451 model2 loss : 0.325815
[21:58:31.907] iteration 2894 : model1 loss : 0.249744 model2 loss : 0.261977
[21:58:32.245] iteration 2895 : model1 loss : 0.344208 model2 loss : 0.320856
[21:58:32.625] iteration 2896 : model1 loss : 0.316573 model2 loss : 0.334912
[21:58:32.966] iteration 2897 : model1 loss : 0.317346 model2 loss : 0.278079
[21:58:33.304] iteration 2898 : model1 loss : 0.288356 model2 loss : 0.228712
[21:58:33.641] iteration 2899 : model1 loss : 0.264277 model2 loss : 0.220773
[21:58:34.002] iteration 2900 : model1 loss : 0.328990 model2 loss : 0.292727
[21:58:34.654] iteration 2901 : model1 loss : 0.327021 model2 loss : 0.293865
[21:58:34.993] iteration 2902 : model1 loss : 0.332395 model2 loss : 0.308998
[21:58:35.332] iteration 2903 : model1 loss : 0.275952 model2 loss : 0.246402
[21:58:35.669] iteration 2904 : model1 loss : 0.464320 model2 loss : 0.416485
[21:58:36.007] iteration 2905 : model1 loss : 0.294182 model2 loss : 0.282436
[21:58:36.345] iteration 2906 : model1 loss : 0.306156 model2 loss : 0.255467
[21:58:36.686] iteration 2907 : model1 loss : 0.366900 model2 loss : 0.300942
[21:58:37.024] iteration 2908 : model1 loss : 0.422297 model2 loss : 0.375388
[21:58:37.362] iteration 2909 : model1 loss : 0.331868 model2 loss : 0.296512
[21:58:37.700] iteration 2910 : model1 loss : 0.292799 model2 loss : 0.285671
[21:58:38.038] iteration 2911 : model1 loss : 0.311113 model2 loss : 0.258449
[21:58:38.378] iteration 2912 : model1 loss : 0.250190 model2 loss : 0.270531
[21:58:38.717] iteration 2913 : model1 loss : 0.371591 model2 loss : 0.348297
[21:58:39.054] iteration 2914 : model1 loss : 0.263509 model2 loss : 0.243874
[21:58:39.391] iteration 2915 : model1 loss : 0.276189 model2 loss : 0.242136
[21:58:39.729] iteration 2916 : model1 loss : 0.439267 model2 loss : 0.286698
[21:58:40.065] iteration 2917 : model1 loss : 0.398311 model2 loss : 0.305834
[21:58:40.403] iteration 2918 : model1 loss : 0.321264 model2 loss : 0.258878
[21:58:40.742] iteration 2919 : model1 loss : 0.339847 model2 loss : 0.326207
[21:58:41.079] iteration 2920 : model1 loss : 0.292797 model2 loss : 0.265752
[21:58:41.416] iteration 2921 : model1 loss : 0.252229 model2 loss : 0.246820
[21:58:41.754] iteration 2922 : model1 loss : 0.317704 model2 loss : 0.301197
[21:58:42.091] iteration 2923 : model1 loss : 0.366936 model2 loss : 0.275490
[21:58:42.430] iteration 2924 : model1 loss : 0.243731 model2 loss : 0.202134
[21:58:42.768] iteration 2925 : model1 loss : 0.358937 model2 loss : 0.257208
[21:58:43.104] iteration 2926 : model1 loss : 0.403443 model2 loss : 0.326889
[21:58:43.442] iteration 2927 : model1 loss : 0.392503 model2 loss : 0.313158
[21:58:43.778] iteration 2928 : model1 loss : 0.356360 model2 loss : 0.305971
[21:58:44.118] iteration 2929 : model1 loss : 0.332055 model2 loss : 0.212877
[21:58:44.455] iteration 2930 : model1 loss : 0.350769 model2 loss : 0.268248
[21:58:44.792] iteration 2931 : model1 loss : 0.326143 model2 loss : 0.255053
[21:58:45.129] iteration 2932 : model1 loss : 0.314754 model2 loss : 0.263582
[21:58:45.470] iteration 2933 : model1 loss : 0.367523 model2 loss : 0.344934
[21:58:45.807] iteration 2934 : model1 loss : 0.365116 model2 loss : 0.310073
[21:58:46.144] iteration 2935 : model1 loss : 0.300141 model2 loss : 0.230705
[21:58:46.481] iteration 2936 : model1 loss : 0.322596 model2 loss : 0.284795
[21:58:46.827] iteration 2937 : model1 loss : 0.358479 model2 loss : 0.281801
[21:58:47.166] iteration 2938 : model1 loss : 0.367401 model2 loss : 0.373345
[21:58:47.503] iteration 2939 : model1 loss : 0.318851 model2 loss : 0.325481
[21:58:47.841] iteration 2940 : model1 loss : 0.308619 model2 loss : 0.222179
[21:58:48.178] iteration 2941 : model1 loss : 0.341261 model2 loss : 0.333652
[21:58:48.518] iteration 2942 : model1 loss : 0.264303 model2 loss : 0.244494
[21:58:48.855] iteration 2943 : model1 loss : 0.284440 model2 loss : 0.246758
[21:58:49.191] iteration 2944 : model1 loss : 0.307071 model2 loss : 0.323935
[21:58:49.528] iteration 2945 : model1 loss : 0.310261 model2 loss : 0.346361
[21:58:49.866] iteration 2946 : model1 loss : 0.245381 model2 loss : 0.238908
[21:58:50.206] iteration 2947 : model1 loss : 0.421554 model2 loss : 0.345049
[21:58:50.548] iteration 2948 : model1 loss : 0.269674 model2 loss : 0.224404
[21:58:50.885] iteration 2949 : model1 loss : 0.480166 model2 loss : 0.384954
[21:58:51.223] iteration 2950 : model1 loss : 0.311246 model2 loss : 0.269370
[21:58:51.862] iteration 2951 : model1 loss : 0.296707 model2 loss : 0.237571
[21:58:52.199] iteration 2952 : model1 loss : 0.379632 model2 loss : 0.383575
[21:58:52.538] iteration 2953 : model1 loss : 0.381140 model2 loss : 0.380363
[21:58:52.875] iteration 2954 : model1 loss : 0.322405 model2 loss : 0.286144
[21:58:53.213] iteration 2955 : model1 loss : 0.368551 model2 loss : 0.251102
[21:58:53.550] iteration 2956 : model1 loss : 0.319949 model2 loss : 0.344618
[21:58:53.888] iteration 2957 : model1 loss : 0.300563 model2 loss : 0.307062
[21:58:54.226] iteration 2958 : model1 loss : 0.312795 model2 loss : 0.295484
[21:58:54.562] iteration 2959 : model1 loss : 0.357121 model2 loss : 0.327772
[21:58:54.900] iteration 2960 : model1 loss : 0.298920 model2 loss : 0.305931
[21:58:55.236] iteration 2961 : model1 loss : 0.324830 model2 loss : 0.287118
[21:58:55.574] iteration 2962 : model1 loss : 0.300480 model2 loss : 0.292196
[21:58:55.914] iteration 2963 : model1 loss : 0.312569 model2 loss : 0.278705
[21:58:56.250] iteration 2964 : model1 loss : 0.393148 model2 loss : 0.372352
[21:58:56.588] iteration 2965 : model1 loss : 0.322931 model2 loss : 0.255763
[21:58:56.925] iteration 2966 : model1 loss : 0.316272 model2 loss : 0.312354
[21:58:57.264] iteration 2967 : model1 loss : 0.339259 model2 loss : 0.322320
[21:58:57.603] iteration 2968 : model1 loss : 0.290998 model2 loss : 0.327550
[21:58:57.948] iteration 2969 : model1 loss : 0.357503 model2 loss : 0.325858
[21:58:58.287] iteration 2970 : model1 loss : 0.286573 model2 loss : 0.231141
[21:58:58.625] iteration 2971 : model1 loss : 0.272032 model2 loss : 0.234860
[21:58:58.968] iteration 2972 : model1 loss : 0.383205 model2 loss : 0.372665
[21:58:59.305] iteration 2973 : model1 loss : 0.301042 model2 loss : 0.295389
[21:58:59.642] iteration 2974 : model1 loss : 0.352820 model2 loss : 0.327593
[21:58:59.979] iteration 2975 : model1 loss : 0.310530 model2 loss : 0.325480
[21:59:00.317] iteration 2976 : model1 loss : 0.356958 model2 loss : 0.360781
[21:59:00.653] iteration 2977 : model1 loss : 0.294749 model2 loss : 0.327564
[21:59:00.990] iteration 2978 : model1 loss : 0.312497 model2 loss : 0.288641
[21:59:01.347] iteration 2979 : model1 loss : 0.363649 model2 loss : 0.349141
[21:59:01.694] iteration 2980 : model1 loss : 0.410928 model2 loss : 0.419321
[21:59:02.034] iteration 2981 : model1 loss : 0.354896 model2 loss : 0.262375
[21:59:02.373] iteration 2982 : model1 loss : 0.363621 model2 loss : 0.385911
[21:59:02.711] iteration 2983 : model1 loss : 0.340066 model2 loss : 0.287988
[21:59:03.048] iteration 2984 : model1 loss : 0.290569 model2 loss : 0.297851
[21:59:03.385] iteration 2985 : model1 loss : 0.416133 model2 loss : 0.392054
[21:59:03.725] iteration 2986 : model1 loss : 0.340209 model2 loss : 0.346416
[21:59:04.065] iteration 2987 : model1 loss : 0.382217 model2 loss : 0.358547
[21:59:04.403] iteration 2988 : model1 loss : 0.377440 model2 loss : 0.315123
[21:59:04.740] iteration 2989 : model1 loss : 0.312093 model2 loss : 0.220138
[21:59:05.081] iteration 2990 : model1 loss : 0.359579 model2 loss : 0.339928
[21:59:05.423] iteration 2991 : model1 loss : 0.372847 model2 loss : 0.257491
[21:59:05.757] iteration 2992 : model1 loss : 0.349543 model2 loss : 0.264995
[21:59:06.098] iteration 2993 : model1 loss : 0.331273 model2 loss : 0.288762
[21:59:06.439] iteration 2994 : model1 loss : 0.381304 model2 loss : 0.224687
[21:59:06.777] iteration 2995 : model1 loss : 0.337265 model2 loss : 0.274073
[21:59:07.115] iteration 2996 : model1 loss : 0.308209 model2 loss : 0.293515
[21:59:07.451] iteration 2997 : model1 loss : 0.363372 model2 loss : 0.302642
[21:59:07.788] iteration 2998 : model1 loss : 0.416228 model2 loss : 0.320041
[21:59:08.125] iteration 2999 : model1 loss : 0.407474 model2 loss : 0.372454
[21:59:08.461] iteration 3000 : model1 loss : 0.296429 model2 loss : 0.285303
[22:00:13.801] iteration 3000 : model1_mean_dice : 0.474839 model1_mean_hd95 : 18.654464
[22:00:54.656] iteration 3000 : model2_mean_dice : 0.404592 model2_mean_hd95 : 18.630340
[22:00:54.875] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_3000.pth
[22:00:54.896] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_3000.pth
[22:00:55.229] iteration 3001 : model1 loss : 0.401237 model2 loss : 0.371772
[22:00:55.565] iteration 3002 : model1 loss : 0.377237 model2 loss : 0.330596
[22:00:55.904] iteration 3003 : model1 loss : 0.346552 model2 loss : 0.259892
[22:00:56.241] iteration 3004 : model1 loss : 0.317184 model2 loss : 0.294803
[22:00:56.577] iteration 3005 : model1 loss : 0.388490 model2 loss : 0.365813
[22:00:56.913] iteration 3006 : model1 loss : 0.285083 model2 loss : 0.220395
[22:00:57.250] iteration 3007 : model1 loss : 0.352080 model2 loss : 0.277476
[22:00:57.587] iteration 3008 : model1 loss : 0.368124 model2 loss : 0.303967
[22:00:57.924] iteration 3009 : model1 loss : 0.313273 model2 loss : 0.284980
[22:00:58.260] iteration 3010 : model1 loss : 0.334930 model2 loss : 0.333339
[22:00:58.596] iteration 3011 : model1 loss : 0.349743 model2 loss : 0.317464
[22:00:58.933] iteration 3012 : model1 loss : 0.322275 model2 loss : 0.341796
[22:00:59.268] iteration 3013 : model1 loss : 0.313607 model2 loss : 0.280711
[22:00:59.605] iteration 3014 : model1 loss : 0.376164 model2 loss : 0.354475
[22:00:59.942] iteration 3015 : model1 loss : 0.379567 model2 loss : 0.354801
[22:01:00.278] iteration 3016 : model1 loss : 0.311869 model2 loss : 0.274103
[22:01:00.614] iteration 3017 : model1 loss : 0.337321 model2 loss : 0.291278
[22:01:00.951] iteration 3018 : model1 loss : 0.307956 model2 loss : 0.256607
[22:01:01.290] iteration 3019 : model1 loss : 0.231886 model2 loss : 0.169136
[22:01:01.630] iteration 3020 : model1 loss : 0.293062 model2 loss : 0.229416
[22:01:01.967] iteration 3021 : model1 loss : 0.286798 model2 loss : 0.259798
[22:01:02.306] iteration 3022 : model1 loss : 0.266161 model2 loss : 0.276388
[22:01:02.645] iteration 3023 : model1 loss : 0.455325 model2 loss : 0.288688
[22:01:02.983] iteration 3024 : model1 loss : 0.441444 model2 loss : 0.353607
[22:01:03.321] iteration 3025 : model1 loss : 0.374459 model2 loss : 0.354563
[22:01:03.658] iteration 3026 : model1 loss : 0.341176 model2 loss : 0.345281
[22:01:03.995] iteration 3027 : model1 loss : 0.341905 model2 loss : 0.334179
[22:01:04.330] iteration 3028 : model1 loss : 0.334637 model2 loss : 0.244608
[22:01:04.666] iteration 3029 : model1 loss : 0.407766 model2 loss : 0.366852
[22:01:05.003] iteration 3030 : model1 loss : 0.398678 model2 loss : 0.268886
[22:01:05.340] iteration 3031 : model1 loss : 0.376679 model2 loss : 0.343586
[22:01:05.678] iteration 3032 : model1 loss : 0.352921 model2 loss : 0.291380
[22:01:06.019] iteration 3033 : model1 loss : 0.322139 model2 loss : 0.328436
[22:01:06.355] iteration 3034 : model1 loss : 0.333010 model2 loss : 0.377882
[22:01:06.695] iteration 3035 : model1 loss : 0.351318 model2 loss : 0.286075
[22:01:07.032] iteration 3036 : model1 loss : 0.379442 model2 loss : 0.342996
[22:01:07.369] iteration 3037 : model1 loss : 0.283547 model2 loss : 0.208200
[22:01:07.705] iteration 3038 : model1 loss : 0.344142 model2 loss : 0.308214
[22:01:08.043] iteration 3039 : model1 loss : 0.347730 model2 loss : 0.321335
[22:01:08.379] iteration 3040 : model1 loss : 0.288464 model2 loss : 0.239790
[22:01:08.715] iteration 3041 : model1 loss : 0.285554 model2 loss : 0.231724
[22:01:09.052] iteration 3042 : model1 loss : 0.402015 model2 loss : 0.421566
[22:01:09.392] iteration 3043 : model1 loss : 0.249172 model2 loss : 0.239529
[22:01:09.729] iteration 3044 : model1 loss : 0.260858 model2 loss : 0.191349
[22:01:10.068] iteration 3045 : model1 loss : 0.278235 model2 loss : 0.257597
[22:01:10.405] iteration 3046 : model1 loss : 0.308880 model2 loss : 0.250871
[22:01:10.742] iteration 3047 : model1 loss : 0.365143 model2 loss : 0.271475
[22:01:11.083] iteration 3048 : model1 loss : 0.291973 model2 loss : 0.278408
[22:01:11.425] iteration 3049 : model1 loss : 0.321427 model2 loss : 0.260610
[22:01:11.762] iteration 3050 : model1 loss : 0.344434 model2 loss : 0.307168
[22:01:12.397] iteration 3051 : model1 loss : 0.331896 model2 loss : 0.297994
[22:01:12.737] iteration 3052 : model1 loss : 0.270084 model2 loss : 0.229607
[22:01:13.074] iteration 3053 : model1 loss : 0.331496 model2 loss : 0.297605
[22:01:13.411] iteration 3054 : model1 loss : 0.337361 model2 loss : 0.277835
[22:01:13.749] iteration 3055 : model1 loss : 0.292477 model2 loss : 0.312960
[22:01:14.092] iteration 3056 : model1 loss : 0.393323 model2 loss : 0.349601
[22:01:14.432] iteration 3057 : model1 loss : 0.348582 model2 loss : 0.305793
[22:01:14.769] iteration 3058 : model1 loss : 0.391143 model2 loss : 0.332533
[22:01:15.115] iteration 3059 : model1 loss : 0.285218 model2 loss : 0.209791
[22:01:15.455] iteration 3060 : model1 loss : 0.378778 model2 loss : 0.330634
[22:01:15.793] iteration 3061 : model1 loss : 0.340171 model2 loss : 0.391932
[22:01:16.134] iteration 3062 : model1 loss : 0.388961 model2 loss : 0.380123
[22:01:16.480] iteration 3063 : model1 loss : 0.244709 model2 loss : 0.253248
[22:01:16.818] iteration 3064 : model1 loss : 0.278613 model2 loss : 0.245135
[22:01:17.156] iteration 3065 : model1 loss : 0.295499 model2 loss : 0.259413
[22:01:17.494] iteration 3066 : model1 loss : 0.272219 model2 loss : 0.231969
[22:01:17.834] iteration 3067 : model1 loss : 0.320036 model2 loss : 0.287926
[22:01:18.172] iteration 3068 : model1 loss : 0.288479 model2 loss : 0.257962
[22:01:18.510] iteration 3069 : model1 loss : 0.415205 model2 loss : 0.392323
[22:01:18.852] iteration 3070 : model1 loss : 0.424810 model2 loss : 0.363784
[22:01:19.192] iteration 3071 : model1 loss : 0.333679 model2 loss : 0.288925
[22:01:19.530] iteration 3072 : model1 loss : 0.265712 model2 loss : 0.221124
[22:01:19.875] iteration 3073 : model1 loss : 0.276905 model2 loss : 0.232580
[22:01:20.212] iteration 3074 : model1 loss : 0.354437 model2 loss : 0.314607
[22:01:20.552] iteration 3075 : model1 loss : 0.392205 model2 loss : 0.421633
[22:01:20.890] iteration 3076 : model1 loss : 0.350266 model2 loss : 0.303563
[22:01:21.230] iteration 3077 : model1 loss : 0.402781 model2 loss : 0.385767
[22:01:21.577] iteration 3078 : model1 loss : 0.338848 model2 loss : 0.287477
[22:01:21.916] iteration 3079 : model1 loss : 0.316367 model2 loss : 0.244272
[22:01:22.257] iteration 3080 : model1 loss : 0.291151 model2 loss : 0.261961
[22:01:22.596] iteration 3081 : model1 loss : 0.302133 model2 loss : 0.187374
[22:01:22.937] iteration 3082 : model1 loss : 0.290692 model2 loss : 0.322130
[22:01:23.278] iteration 3083 : model1 loss : 0.403078 model2 loss : 0.318683
[22:01:23.618] iteration 3084 : model1 loss : 0.255702 model2 loss : 0.274274
[22:01:23.956] iteration 3085 : model1 loss : 0.337119 model2 loss : 0.312596
[22:01:24.295] iteration 3086 : model1 loss : 0.272428 model2 loss : 0.259180
[22:01:24.639] iteration 3087 : model1 loss : 0.327972 model2 loss : 0.357992
[22:01:24.980] iteration 3088 : model1 loss : 0.339820 model2 loss : 0.307279
[22:01:25.320] iteration 3089 : model1 loss : 0.271304 model2 loss : 0.266607
[22:01:25.658] iteration 3090 : model1 loss : 0.285462 model2 loss : 0.226808
[22:01:25.996] iteration 3091 : model1 loss : 0.255332 model2 loss : 0.209938
[22:01:26.335] iteration 3092 : model1 loss : 0.324486 model2 loss : 0.314675
[22:01:26.673] iteration 3093 : model1 loss : 0.376532 model2 loss : 0.352386
[22:01:27.011] iteration 3094 : model1 loss : 0.260823 model2 loss : 0.255590
[22:01:27.349] iteration 3095 : model1 loss : 0.271634 model2 loss : 0.241442
[22:01:27.687] iteration 3096 : model1 loss : 0.314852 model2 loss : 0.328205
[22:01:28.026] iteration 3097 : model1 loss : 0.253168 model2 loss : 0.219007
[22:01:28.364] iteration 3098 : model1 loss : 0.273915 model2 loss : 0.256302
[22:01:28.701] iteration 3099 : model1 loss : 0.315241 model2 loss : 0.265917
[22:01:29.039] iteration 3100 : model1 loss : 0.313514 model2 loss : 0.269126
[22:01:29.689] iteration 3101 : model1 loss : 0.372295 model2 loss : 0.265638
[22:01:30.019] iteration 3102 : model1 loss : 0.318846 model2 loss : 0.320207
[22:01:30.348] iteration 3103 : model1 loss : 0.396680 model2 loss : 0.345811
[22:01:30.676] iteration 3104 : model1 loss : 0.237029 model2 loss : 0.190749
[22:01:31.004] iteration 3105 : model1 loss : 0.335616 model2 loss : 0.274041
[22:01:31.332] iteration 3106 : model1 loss : 0.306916 model2 loss : 0.290142
[22:01:31.659] iteration 3107 : model1 loss : 0.341812 model2 loss : 0.305468
[22:01:31.987] iteration 3108 : model1 loss : 0.332363 model2 loss : 0.279043
[22:01:32.316] iteration 3109 : model1 loss : 0.317684 model2 loss : 0.320613
[22:01:32.644] iteration 3110 : model1 loss : 0.386418 model2 loss : 0.371387
[22:01:32.972] iteration 3111 : model1 loss : 0.243126 model2 loss : 0.261320
[22:01:33.301] iteration 3112 : model1 loss : 0.250524 model2 loss : 0.215062
[22:01:33.630] iteration 3113 : model1 loss : 0.301215 model2 loss : 0.329484
[22:01:33.957] iteration 3114 : model1 loss : 0.328901 model2 loss : 0.278640
[22:01:34.285] iteration 3115 : model1 loss : 0.379082 model2 loss : 0.402207
[22:01:34.612] iteration 3116 : model1 loss : 0.282123 model2 loss : 0.227482
[22:01:34.940] iteration 3117 : model1 loss : 0.254922 model2 loss : 0.263969
[22:01:35.267] iteration 3118 : model1 loss : 0.369676 model2 loss : 0.278507
[22:01:35.595] iteration 3119 : model1 loss : 0.356281 model2 loss : 0.280007
[22:01:35.922] iteration 3120 : model1 loss : 0.387826 model2 loss : 0.395266
[22:01:36.249] iteration 3121 : model1 loss : 0.261127 model2 loss : 0.262594
[22:01:36.576] iteration 3122 : model1 loss : 0.364274 model2 loss : 0.395369
[22:01:36.904] iteration 3123 : model1 loss : 0.295804 model2 loss : 0.299767
[22:01:37.232] iteration 3124 : model1 loss : 0.267734 model2 loss : 0.271942
[22:01:37.558] iteration 3125 : model1 loss : 0.301344 model2 loss : 0.189631
[22:01:37.885] iteration 3126 : model1 loss : 0.345393 model2 loss : 0.313159
[22:01:38.212] iteration 3127 : model1 loss : 0.352357 model2 loss : 0.409123
[22:01:38.539] iteration 3128 : model1 loss : 0.282947 model2 loss : 0.280369
[22:01:38.865] iteration 3129 : model1 loss : 0.319050 model2 loss : 0.301287
[22:01:39.192] iteration 3130 : model1 loss : 0.267548 model2 loss : 0.277934
[22:01:39.520] iteration 3131 : model1 loss : 0.247332 model2 loss : 0.275335
[22:01:39.847] iteration 3132 : model1 loss : 0.264532 model2 loss : 0.247024
[22:01:40.174] iteration 3133 : model1 loss : 0.331190 model2 loss : 0.287013
[22:01:40.500] iteration 3134 : model1 loss : 0.325694 model2 loss : 0.332576
[22:01:40.827] iteration 3135 : model1 loss : 0.252266 model2 loss : 0.220670
[22:01:41.153] iteration 3136 : model1 loss : 0.290769 model2 loss : 0.299567
[22:01:41.480] iteration 3137 : model1 loss : 0.267916 model2 loss : 0.229124
[22:01:41.807] iteration 3138 : model1 loss : 0.244232 model2 loss : 0.270511
[22:01:42.133] iteration 3139 : model1 loss : 0.326998 model2 loss : 0.320936
[22:01:42.460] iteration 3140 : model1 loss : 0.331571 model2 loss : 0.349902
[22:01:42.791] iteration 3141 : model1 loss : 0.355670 model2 loss : 0.271458
[22:01:43.118] iteration 3142 : model1 loss : 0.317119 model2 loss : 0.304295
[22:01:43.444] iteration 3143 : model1 loss : 0.289487 model2 loss : 0.287603
[22:01:43.770] iteration 3144 : model1 loss : 0.329486 model2 loss : 0.284709
[22:01:44.096] iteration 3145 : model1 loss : 0.404791 model2 loss : 0.405309
[22:01:44.423] iteration 3146 : model1 loss : 0.263871 model2 loss : 0.205255
[22:01:44.750] iteration 3147 : model1 loss : 0.312469 model2 loss : 0.264807
[22:01:45.076] iteration 3148 : model1 loss : 0.319355 model2 loss : 0.271547
[22:01:45.401] iteration 3149 : model1 loss : 0.270795 model2 loss : 0.304231
[22:01:45.728] iteration 3150 : model1 loss : 0.376406 model2 loss : 0.362420
[22:01:46.261] iteration 3151 : model1 loss : 0.352358 model2 loss : 0.313265
[22:01:46.587] iteration 3152 : model1 loss : 0.358561 model2 loss : 0.343011
[22:01:46.915] iteration 3153 : model1 loss : 0.281995 model2 loss : 0.274249
[22:01:47.242] iteration 3154 : model1 loss : 0.340181 model2 loss : 0.378487
[22:01:47.569] iteration 3155 : model1 loss : 0.311558 model2 loss : 0.224826
[22:01:47.896] iteration 3156 : model1 loss : 0.322106 model2 loss : 0.301605
[22:01:48.229] iteration 3157 : model1 loss : 0.296344 model2 loss : 0.312154
[22:01:48.555] iteration 3158 : model1 loss : 0.325084 model2 loss : 0.314819
[22:01:48.882] iteration 3159 : model1 loss : 0.296135 model2 loss : 0.313912
[22:01:49.209] iteration 3160 : model1 loss : 0.228056 model2 loss : 0.178035
[22:01:49.535] iteration 3161 : model1 loss : 0.348635 model2 loss : 0.283521
[22:01:49.861] iteration 3162 : model1 loss : 0.404105 model2 loss : 0.290067
[22:01:50.188] iteration 3163 : model1 loss : 0.412316 model2 loss : 0.337268
[22:01:50.514] iteration 3164 : model1 loss : 0.260639 model2 loss : 0.264372
[22:01:50.841] iteration 3165 : model1 loss : 0.365092 model2 loss : 0.361664
[22:01:51.168] iteration 3166 : model1 loss : 0.248091 model2 loss : 0.222122
[22:01:51.494] iteration 3167 : model1 loss : 0.415596 model2 loss : 0.374840
[22:01:51.821] iteration 3168 : model1 loss : 0.254133 model2 loss : 0.249439
[22:01:52.148] iteration 3169 : model1 loss : 0.249942 model2 loss : 0.255848
[22:01:52.474] iteration 3170 : model1 loss : 0.247827 model2 loss : 0.189481
[22:01:52.801] iteration 3171 : model1 loss : 0.371968 model2 loss : 0.424386
[22:01:53.128] iteration 3172 : model1 loss : 0.303479 model2 loss : 0.271520
[22:01:53.455] iteration 3173 : model1 loss : 0.354538 model2 loss : 0.349602
[22:01:53.782] iteration 3174 : model1 loss : 0.428890 model2 loss : 0.444535
[22:01:54.109] iteration 3175 : model1 loss : 0.240895 model2 loss : 0.215794
[22:01:54.436] iteration 3176 : model1 loss : 0.265426 model2 loss : 0.280979
[22:01:54.762] iteration 3177 : model1 loss : 0.262732 model2 loss : 0.275653
[22:01:55.089] iteration 3178 : model1 loss : 0.325306 model2 loss : 0.293618
[22:01:55.415] iteration 3179 : model1 loss : 0.270243 model2 loss : 0.269513
[22:01:55.743] iteration 3180 : model1 loss : 0.328357 model2 loss : 0.312711
[22:01:56.070] iteration 3181 : model1 loss : 0.226907 model2 loss : 0.203516
[22:01:56.401] iteration 3182 : model1 loss : 0.208267 model2 loss : 0.238808
[22:01:56.726] iteration 3183 : model1 loss : 0.342695 model2 loss : 0.310977
[22:01:57.053] iteration 3184 : model1 loss : 0.296063 model2 loss : 0.268145
[22:01:57.379] iteration 3185 : model1 loss : 0.246054 model2 loss : 0.242294
[22:01:57.706] iteration 3186 : model1 loss : 0.372381 model2 loss : 0.371508
[22:01:58.031] iteration 3187 : model1 loss : 0.309539 model2 loss : 0.199651
[22:01:58.358] iteration 3188 : model1 loss : 0.354347 model2 loss : 0.346330
[22:01:58.685] iteration 3189 : model1 loss : 0.312309 model2 loss : 0.315928
[22:01:59.010] iteration 3190 : model1 loss : 0.339656 model2 loss : 0.305450
[22:01:59.336] iteration 3191 : model1 loss : 0.304489 model2 loss : 0.300501
[22:01:59.661] iteration 3192 : model1 loss : 0.265439 model2 loss : 0.244340
[22:01:59.988] iteration 3193 : model1 loss : 0.225671 model2 loss : 0.250318
[22:02:00.318] iteration 3194 : model1 loss : 0.399353 model2 loss : 0.434888
[22:02:00.644] iteration 3195 : model1 loss : 0.307678 model2 loss : 0.301530
[22:02:00.971] iteration 3196 : model1 loss : 0.394383 model2 loss : 0.330889
[22:02:01.298] iteration 3197 : model1 loss : 0.342515 model2 loss : 0.314678
[22:02:01.624] iteration 3198 : model1 loss : 0.331905 model2 loss : 0.319185
[22:02:01.951] iteration 3199 : model1 loss : 0.353156 model2 loss : 0.337102
[22:02:02.278] iteration 3200 : model1 loss : 0.312260 model2 loss : 0.204615
[22:02:02.809] iteration 3201 : model1 loss : 0.384026 model2 loss : 0.348946
[22:02:03.136] iteration 3202 : model1 loss : 0.339613 model2 loss : 0.357741
[22:02:03.461] iteration 3203 : model1 loss : 0.285272 model2 loss : 0.220333
[22:02:03.788] iteration 3204 : model1 loss : 0.330306 model2 loss : 0.289887
[22:02:04.115] iteration 3205 : model1 loss : 0.340851 model2 loss : 0.359851
[22:02:04.442] iteration 3206 : model1 loss : 0.327358 model2 loss : 0.325066
[22:02:04.768] iteration 3207 : model1 loss : 0.258357 model2 loss : 0.269859
[22:02:05.094] iteration 3208 : model1 loss : 0.352393 model2 loss : 0.347003
[22:02:05.421] iteration 3209 : model1 loss : 0.372461 model2 loss : 0.345299
[22:02:05.746] iteration 3210 : model1 loss : 0.325855 model2 loss : 0.294658
[22:02:06.074] iteration 3211 : model1 loss : 0.325023 model2 loss : 0.342062
[22:02:06.400] iteration 3212 : model1 loss : 0.337627 model2 loss : 0.334221
[22:02:06.728] iteration 3213 : model1 loss : 0.358701 model2 loss : 0.329068
[22:02:07.061] iteration 3214 : model1 loss : 0.311462 model2 loss : 0.313847
[22:02:07.399] iteration 3215 : model1 loss : 0.268358 model2 loss : 0.225478
[22:02:07.741] iteration 3216 : model1 loss : 0.329841 model2 loss : 0.357180
[22:02:08.071] iteration 3217 : model1 loss : 0.409137 model2 loss : 0.378334
[22:02:08.399] iteration 3218 : model1 loss : 0.283377 model2 loss : 0.311228
[22:02:08.727] iteration 3219 : model1 loss : 0.388660 model2 loss : 0.307321
[22:02:09.056] iteration 3220 : model1 loss : 0.375927 model2 loss : 0.343656
[22:02:09.384] iteration 3221 : model1 loss : 0.468640 model2 loss : 0.319872
[22:02:09.711] iteration 3222 : model1 loss : 0.369550 model2 loss : 0.245066
[22:02:10.039] iteration 3223 : model1 loss : 0.322900 model2 loss : 0.230993
[22:02:10.368] iteration 3224 : model1 loss : 0.342062 model2 loss : 0.280237
[22:02:10.696] iteration 3225 : model1 loss : 0.375202 model2 loss : 0.391296
[22:02:11.024] iteration 3226 : model1 loss : 0.314211 model2 loss : 0.271548
[22:02:11.351] iteration 3227 : model1 loss : 0.366836 model2 loss : 0.264072
[22:02:11.680] iteration 3228 : model1 loss : 0.394763 model2 loss : 0.358548
[22:02:12.007] iteration 3229 : model1 loss : 0.315590 model2 loss : 0.285994
[22:02:12.335] iteration 3230 : model1 loss : 0.339043 model2 loss : 0.301024
[22:02:12.662] iteration 3231 : model1 loss : 0.313430 model2 loss : 0.245468
[22:02:12.989] iteration 3232 : model1 loss : 0.313549 model2 loss : 0.235482
[22:02:13.316] iteration 3233 : model1 loss : 0.368531 model2 loss : 0.328609
[22:02:13.643] iteration 3234 : model1 loss : 0.316653 model2 loss : 0.268785
[22:02:13.971] iteration 3235 : model1 loss : 0.399179 model2 loss : 0.386189
[22:02:14.299] iteration 3236 : model1 loss : 0.369518 model2 loss : 0.313265
[22:02:14.627] iteration 3237 : model1 loss : 0.358164 model2 loss : 0.314306
[22:02:14.954] iteration 3238 : model1 loss : 0.352104 model2 loss : 0.284352
[22:02:15.291] iteration 3239 : model1 loss : 0.310100 model2 loss : 0.238721
[22:02:15.627] iteration 3240 : model1 loss : 0.313710 model2 loss : 0.334837
[22:02:15.964] iteration 3241 : model1 loss : 0.257190 model2 loss : 0.245360
[22:02:16.301] iteration 3242 : model1 loss : 0.301704 model2 loss : 0.239600
[22:02:16.637] iteration 3243 : model1 loss : 0.360897 model2 loss : 0.316500
[22:02:16.974] iteration 3244 : model1 loss : 0.333699 model2 loss : 0.273284
[22:02:17.314] iteration 3245 : model1 loss : 0.260582 model2 loss : 0.226337
[22:02:17.651] iteration 3246 : model1 loss : 0.412162 model2 loss : 0.370058
[22:02:17.988] iteration 3247 : model1 loss : 0.229974 model2 loss : 0.146053
[22:02:18.327] iteration 3248 : model1 loss : 0.369845 model2 loss : 0.361101
[22:02:18.673] iteration 3249 : model1 loss : 0.270673 model2 loss : 0.239679
[22:02:19.009] iteration 3250 : model1 loss : 0.288074 model2 loss : 0.272100
[22:02:19.695] iteration 3251 : model1 loss : 0.222746 model2 loss : 0.223452
[22:02:20.033] iteration 3252 : model1 loss : 0.314386 model2 loss : 0.303037
[22:02:20.369] iteration 3253 : model1 loss : 0.275266 model2 loss : 0.251239
[22:02:20.707] iteration 3254 : model1 loss : 0.324601 model2 loss : 0.282093
[22:02:21.044] iteration 3255 : model1 loss : 0.311750 model2 loss : 0.274494
[22:02:21.383] iteration 3256 : model1 loss : 0.268496 model2 loss : 0.218524
[22:02:21.720] iteration 3257 : model1 loss : 0.332934 model2 loss : 0.312126
[22:02:22.058] iteration 3258 : model1 loss : 0.335364 model2 loss : 0.334031
[22:02:22.404] iteration 3259 : model1 loss : 0.251076 model2 loss : 0.219399
[22:02:22.741] iteration 3260 : model1 loss : 0.311269 model2 loss : 0.224692
[22:02:23.081] iteration 3261 : model1 loss : 0.281691 model2 loss : 0.254535
[22:02:23.419] iteration 3262 : model1 loss : 0.374435 model2 loss : 0.331215
[22:02:23.756] iteration 3263 : model1 loss : 0.383739 model2 loss : 0.383841
[22:02:24.093] iteration 3264 : model1 loss : 0.339655 model2 loss : 0.269557
[22:02:24.430] iteration 3265 : model1 loss : 0.275355 model2 loss : 0.247365
[22:02:24.768] iteration 3266 : model1 loss : 0.335396 model2 loss : 0.299749
[22:02:25.106] iteration 3267 : model1 loss : 0.333595 model2 loss : 0.364032
[22:02:25.443] iteration 3268 : model1 loss : 0.323810 model2 loss : 0.361394
[22:02:25.780] iteration 3269 : model1 loss : 0.297167 model2 loss : 0.204815
[22:02:26.119] iteration 3270 : model1 loss : 0.305719 model2 loss : 0.303633
[22:02:27.182] iteration 3271 : model1 loss : 0.362294 model2 loss : 0.306130
[22:02:27.522] iteration 3272 : model1 loss : 0.466928 model2 loss : 0.292344
[22:02:27.859] iteration 3273 : model1 loss : 0.440593 model2 loss : 0.354437
[22:02:28.196] iteration 3274 : model1 loss : 0.416876 model2 loss : 0.347594
[22:02:28.534] iteration 3275 : model1 loss : 0.394812 model2 loss : 0.369166
[22:02:28.873] iteration 3276 : model1 loss : 0.378790 model2 loss : 0.328644
[22:02:29.210] iteration 3277 : model1 loss : 0.217808 model2 loss : 0.212916
[22:02:29.549] iteration 3278 : model1 loss : 0.327299 model2 loss : 0.236446
[22:02:29.888] iteration 3279 : model1 loss : 0.305629 model2 loss : 0.277462
[22:02:30.229] iteration 3280 : model1 loss : 0.356482 model2 loss : 0.296621
[22:02:30.566] iteration 3281 : model1 loss : 0.383832 model2 loss : 0.375208
[22:02:30.904] iteration 3282 : model1 loss : 0.415039 model2 loss : 0.362515
[22:02:31.242] iteration 3283 : model1 loss : 0.404586 model2 loss : 0.388198
[22:02:31.580] iteration 3284 : model1 loss : 0.294668 model2 loss : 0.209404
[22:02:31.921] iteration 3285 : model1 loss : 0.379575 model2 loss : 0.307822
[22:02:32.259] iteration 3286 : model1 loss : 0.343188 model2 loss : 0.323749
[22:02:32.596] iteration 3287 : model1 loss : 0.383476 model2 loss : 0.368399
[22:02:32.939] iteration 3288 : model1 loss : 0.321711 model2 loss : 0.276709
[22:02:33.277] iteration 3289 : model1 loss : 0.341976 model2 loss : 0.350316
[22:02:33.614] iteration 3290 : model1 loss : 0.316889 model2 loss : 0.251167
[22:02:33.952] iteration 3291 : model1 loss : 0.302332 model2 loss : 0.338782
[22:02:34.290] iteration 3292 : model1 loss : 0.302773 model2 loss : 0.303441
[22:02:34.628] iteration 3293 : model1 loss : 0.300123 model2 loss : 0.241438
[22:02:34.967] iteration 3294 : model1 loss : 0.332476 model2 loss : 0.225967
[22:02:35.307] iteration 3295 : model1 loss : 0.402365 model2 loss : 0.349717
[22:02:35.644] iteration 3296 : model1 loss : 0.327447 model2 loss : 0.287046
[22:02:35.984] iteration 3297 : model1 loss : 0.371201 model2 loss : 0.339312
[22:02:36.321] iteration 3298 : model1 loss : 0.369730 model2 loss : 0.310537
[22:02:36.655] iteration 3299 : model1 loss : 0.298181 model2 loss : 0.274417
[22:02:36.993] iteration 3300 : model1 loss : 0.358315 model2 loss : 0.278823
[22:02:37.642] iteration 3301 : model1 loss : 0.346889 model2 loss : 0.236338
[22:02:37.980] iteration 3302 : model1 loss : 0.270302 model2 loss : 0.223478
[22:02:38.317] iteration 3303 : model1 loss : 0.348114 model2 loss : 0.338588
[22:02:38.659] iteration 3304 : model1 loss : 0.397585 model2 loss : 0.411930
[22:02:38.996] iteration 3305 : model1 loss : 0.328339 model2 loss : 0.288640
[22:02:39.334] iteration 3306 : model1 loss : 0.270301 model2 loss : 0.282066
[22:02:39.671] iteration 3307 : model1 loss : 0.316550 model2 loss : 0.288546
[22:02:40.009] iteration 3308 : model1 loss : 0.364303 model2 loss : 0.350042
[22:02:40.347] iteration 3309 : model1 loss : 0.312129 model2 loss : 0.241380
[22:02:40.685] iteration 3310 : model1 loss : 0.327463 model2 loss : 0.231732
[22:02:41.021] iteration 3311 : model1 loss : 0.358357 model2 loss : 0.315429
[22:02:41.357] iteration 3312 : model1 loss : 0.307909 model2 loss : 0.204404
[22:02:41.685] iteration 3313 : model1 loss : 0.293387 model2 loss : 0.289850
[22:02:42.013] iteration 3314 : model1 loss : 0.379265 model2 loss : 0.232681
[22:02:42.340] iteration 3315 : model1 loss : 0.400199 model2 loss : 0.342844
[22:02:42.668] iteration 3316 : model1 loss : 0.272638 model2 loss : 0.209783
[22:02:43.000] iteration 3317 : model1 loss : 0.348122 model2 loss : 0.313151
[22:02:43.327] iteration 3318 : model1 loss : 0.300881 model2 loss : 0.249343
[22:02:43.655] iteration 3319 : model1 loss : 0.296764 model2 loss : 0.216358
[22:02:43.984] iteration 3320 : model1 loss : 0.399196 model2 loss : 0.381262
[22:02:44.313] iteration 3321 : model1 loss : 0.331853 model2 loss : 0.305254
[22:02:44.641] iteration 3322 : model1 loss : 0.406859 model2 loss : 0.381493
[22:02:44.972] iteration 3323 : model1 loss : 0.352980 model2 loss : 0.302794
[22:02:45.301] iteration 3324 : model1 loss : 0.255906 model2 loss : 0.225585
[22:02:45.629] iteration 3325 : model1 loss : 0.329236 model2 loss : 0.252167
[22:02:45.957] iteration 3326 : model1 loss : 0.245351 model2 loss : 0.267335
[22:02:46.287] iteration 3327 : model1 loss : 0.317802 model2 loss : 0.356757
[22:02:46.617] iteration 3328 : model1 loss : 0.324202 model2 loss : 0.287818
[22:02:46.944] iteration 3329 : model1 loss : 0.337384 model2 loss : 0.308306
[22:02:47.272] iteration 3330 : model1 loss : 0.311758 model2 loss : 0.253446
[22:02:47.602] iteration 3331 : model1 loss : 0.314094 model2 loss : 0.299913
[22:02:47.931] iteration 3332 : model1 loss : 0.364307 model2 loss : 0.358204
[22:02:48.261] iteration 3333 : model1 loss : 0.332542 model2 loss : 0.299256
[22:02:48.590] iteration 3334 : model1 loss : 0.309494 model2 loss : 0.247851
[22:02:48.918] iteration 3335 : model1 loss : 0.366117 model2 loss : 0.324659
[22:02:49.246] iteration 3336 : model1 loss : 0.391017 model2 loss : 0.298954
[22:02:49.574] iteration 3337 : model1 loss : 0.432601 model2 loss : 0.338390
[22:02:49.903] iteration 3338 : model1 loss : 0.356748 model2 loss : 0.356520
[22:02:50.231] iteration 3339 : model1 loss : 0.347401 model2 loss : 0.353879
[22:02:50.559] iteration 3340 : model1 loss : 0.260255 model2 loss : 0.216243
[22:02:50.885] iteration 3341 : model1 loss : 0.270309 model2 loss : 0.229464
[22:02:51.213] iteration 3342 : model1 loss : 0.279996 model2 loss : 0.280437
[22:02:51.542] iteration 3343 : model1 loss : 0.329013 model2 loss : 0.244274
[22:02:51.870] iteration 3344 : model1 loss : 0.361689 model2 loss : 0.355215
[22:02:52.200] iteration 3345 : model1 loss : 0.231595 model2 loss : 0.257556
[22:02:52.528] iteration 3346 : model1 loss : 0.316427 model2 loss : 0.349501
[22:02:52.860] iteration 3347 : model1 loss : 0.318412 model2 loss : 0.290380
[22:02:53.189] iteration 3348 : model1 loss : 0.365541 model2 loss : 0.372803
[22:02:53.518] iteration 3349 : model1 loss : 0.352783 model2 loss : 0.333542
[22:02:53.846] iteration 3350 : model1 loss : 0.288517 model2 loss : 0.293107
[22:02:54.410] iteration 3351 : model1 loss : 0.303444 model2 loss : 0.208565
[22:02:54.738] iteration 3352 : model1 loss : 0.320936 model2 loss : 0.320935
[22:02:55.066] iteration 3353 : model1 loss : 0.271700 model2 loss : 0.202332
[22:02:55.394] iteration 3354 : model1 loss : 0.368219 model2 loss : 0.403213
[22:02:55.723] iteration 3355 : model1 loss : 0.326283 model2 loss : 0.302484
[22:02:56.051] iteration 3356 : model1 loss : 0.338603 model2 loss : 0.331833
[22:02:56.379] iteration 3357 : model1 loss : 0.312259 model2 loss : 0.405133
[22:02:56.707] iteration 3358 : model1 loss : 0.289211 model2 loss : 0.296756
[22:02:57.036] iteration 3359 : model1 loss : 0.334206 model2 loss : 0.311824
[22:02:57.364] iteration 3360 : model1 loss : 0.352339 model2 loss : 0.368278
[22:02:57.692] iteration 3361 : model1 loss : 0.228842 model2 loss : 0.242780
[22:02:58.022] iteration 3362 : model1 loss : 0.291146 model2 loss : 0.196998
[22:02:58.350] iteration 3363 : model1 loss : 0.356767 model2 loss : 0.328779
[22:02:58.678] iteration 3364 : model1 loss : 0.285871 model2 loss : 0.293269
[22:02:59.006] iteration 3365 : model1 loss : 0.350730 model2 loss : 0.346243
[22:02:59.334] iteration 3366 : model1 loss : 0.372317 model2 loss : 0.303406
[22:02:59.662] iteration 3367 : model1 loss : 0.299137 model2 loss : 0.285967
[22:02:59.991] iteration 3368 : model1 loss : 0.259447 model2 loss : 0.216664
[22:03:00.320] iteration 3369 : model1 loss : 0.242488 model2 loss : 0.262091
[22:03:00.647] iteration 3370 : model1 loss : 0.301544 model2 loss : 0.263077
[22:03:00.975] iteration 3371 : model1 loss : 0.218493 model2 loss : 0.235449
[22:03:01.305] iteration 3372 : model1 loss : 0.315136 model2 loss : 0.313059
[22:03:01.643] iteration 3373 : model1 loss : 0.332949 model2 loss : 0.335993
[22:03:01.981] iteration 3374 : model1 loss : 0.323959 model2 loss : 0.283588
[22:03:02.317] iteration 3375 : model1 loss : 0.364818 model2 loss : 0.348024
[22:03:02.658] iteration 3376 : model1 loss : 0.216120 model2 loss : 0.187968
[22:03:03.000] iteration 3377 : model1 loss : 0.338959 model2 loss : 0.346995
[22:03:03.338] iteration 3378 : model1 loss : 0.248384 model2 loss : 0.218278
[22:03:03.675] iteration 3379 : model1 loss : 0.244921 model2 loss : 0.252642
[22:03:04.013] iteration 3380 : model1 loss : 0.360392 model2 loss : 0.306404
[22:03:04.350] iteration 3381 : model1 loss : 0.379274 model2 loss : 0.399455
[22:03:04.687] iteration 3382 : model1 loss : 0.306177 model2 loss : 0.299005
[22:03:05.025] iteration 3383 : model1 loss : 0.287201 model2 loss : 0.296979
[22:03:05.366] iteration 3384 : model1 loss : 0.263259 model2 loss : 0.269533
[22:03:05.704] iteration 3385 : model1 loss : 0.358202 model2 loss : 0.324805
[22:03:06.041] iteration 3386 : model1 loss : 0.247729 model2 loss : 0.244207
[22:03:06.379] iteration 3387 : model1 loss : 0.247117 model2 loss : 0.336590
[22:03:06.716] iteration 3388 : model1 loss : 0.314862 model2 loss : 0.271172
[22:03:07.056] iteration 3389 : model1 loss : 0.268466 model2 loss : 0.256053
[22:03:07.395] iteration 3390 : model1 loss : 0.314436 model2 loss : 0.303524
[22:03:07.732] iteration 3391 : model1 loss : 0.167090 model2 loss : 0.140240
[22:03:08.071] iteration 3392 : model1 loss : 0.272863 model2 loss : 0.247858
[22:03:08.408] iteration 3393 : model1 loss : 0.290984 model2 loss : 0.246095
[22:03:08.746] iteration 3394 : model1 loss : 0.361849 model2 loss : 0.348754
[22:03:09.082] iteration 3395 : model1 loss : 0.330931 model2 loss : 0.359841
[22:03:09.420] iteration 3396 : model1 loss : 0.338417 model2 loss : 0.347198
[22:03:09.758] iteration 3397 : model1 loss : 0.287715 model2 loss : 0.253107
[22:03:10.100] iteration 3398 : model1 loss : 0.333409 model2 loss : 0.330398
[22:03:10.437] iteration 3399 : model1 loss : 0.273466 model2 loss : 0.257910
[22:03:10.774] iteration 3400 : model1 loss : 0.310889 model2 loss : 0.277914
[22:03:11.381] iteration 3401 : model1 loss : 0.319668 model2 loss : 0.253925
[22:03:11.719] iteration 3402 : model1 loss : 0.325767 model2 loss : 0.311608
[22:03:12.055] iteration 3403 : model1 loss : 0.302413 model2 loss : 0.307498
[22:03:12.393] iteration 3404 : model1 loss : 0.385579 model2 loss : 0.381360
[22:03:12.731] iteration 3405 : model1 loss : 0.343410 model2 loss : 0.273273
[22:03:13.074] iteration 3406 : model1 loss : 0.294174 model2 loss : 0.225788
[22:03:13.412] iteration 3407 : model1 loss : 0.304036 model2 loss : 0.313884
[22:03:13.753] iteration 3408 : model1 loss : 0.298334 model2 loss : 0.248409
[22:03:14.091] iteration 3409 : model1 loss : 0.281153 model2 loss : 0.281680
[22:03:14.434] iteration 3410 : model1 loss : 0.300501 model2 loss : 0.305156
[22:03:14.772] iteration 3411 : model1 loss : 0.269190 model2 loss : 0.195993
[22:03:15.110] iteration 3412 : model1 loss : 0.332996 model2 loss : 0.393479
[22:03:15.449] iteration 3413 : model1 loss : 0.326528 model2 loss : 0.246395
[22:03:15.803] iteration 3414 : model1 loss : 0.359665 model2 loss : 0.406433
[22:03:16.141] iteration 3415 : model1 loss : 0.378816 model2 loss : 0.276743
[22:03:16.483] iteration 3416 : model1 loss : 0.279358 model2 loss : 0.295951
[22:03:16.820] iteration 3417 : model1 loss : 0.377577 model2 loss : 0.358228
[22:03:17.164] iteration 3418 : model1 loss : 0.346294 model2 loss : 0.389970
[22:03:17.503] iteration 3419 : model1 loss : 0.229008 model2 loss : 0.277920
[22:03:17.841] iteration 3420 : model1 loss : 0.356182 model2 loss : 0.362979
[22:03:18.177] iteration 3421 : model1 loss : 0.318241 model2 loss : 0.337745
[22:03:18.514] iteration 3422 : model1 loss : 0.320769 model2 loss : 0.312300
[22:03:18.852] iteration 3423 : model1 loss : 0.268582 model2 loss : 0.208378
[22:03:19.194] iteration 3424 : model1 loss : 0.324516 model2 loss : 0.304849
[22:03:19.531] iteration 3425 : model1 loss : 0.279523 model2 loss : 0.225778
[22:03:19.871] iteration 3426 : model1 loss : 0.279594 model2 loss : 0.275072
[22:03:20.207] iteration 3427 : model1 loss : 0.387327 model2 loss : 0.347561
[22:03:20.545] iteration 3428 : model1 loss : 0.297001 model2 loss : 0.282370
[22:03:20.886] iteration 3429 : model1 loss : 0.308670 model2 loss : 0.366400
[22:03:21.224] iteration 3430 : model1 loss : 0.408385 model2 loss : 0.406359
[22:03:21.564] iteration 3431 : model1 loss : 0.264005 model2 loss : 0.225555
[22:03:21.902] iteration 3432 : model1 loss : 0.212518 model2 loss : 0.251206
[22:03:22.239] iteration 3433 : model1 loss : 0.295589 model2 loss : 0.224935
[22:03:22.578] iteration 3434 : model1 loss : 0.309114 model2 loss : 0.292987
[22:03:22.916] iteration 3435 : model1 loss : 0.221333 model2 loss : 0.208064
[22:03:23.254] iteration 3436 : model1 loss : 0.281768 model2 loss : 0.265735
[22:03:23.592] iteration 3437 : model1 loss : 0.277221 model2 loss : 0.312131
[22:03:23.930] iteration 3438 : model1 loss : 0.393254 model2 loss : 0.429296
[22:03:24.267] iteration 3439 : model1 loss : 0.218267 model2 loss : 0.243598
[22:03:24.606] iteration 3440 : model1 loss : 0.302615 model2 loss : 0.317501
[22:03:24.943] iteration 3441 : model1 loss : 0.339906 model2 loss : 0.225809
[22:03:25.281] iteration 3442 : model1 loss : 0.337027 model2 loss : 0.280743
[22:03:25.618] iteration 3443 : model1 loss : 0.301220 model2 loss : 0.323671
[22:03:25.956] iteration 3444 : model1 loss : 0.295288 model2 loss : 0.227095
[22:03:26.295] iteration 3445 : model1 loss : 0.358215 model2 loss : 0.357163
[22:03:26.633] iteration 3446 : model1 loss : 0.203919 model2 loss : 0.225354
[22:03:26.972] iteration 3447 : model1 loss : 0.283061 model2 loss : 0.259010
[22:03:27.310] iteration 3448 : model1 loss : 0.289548 model2 loss : 0.267533
[22:03:27.646] iteration 3449 : model1 loss : 0.282460 model2 loss : 0.282619
[22:03:27.984] iteration 3450 : model1 loss : 0.259911 model2 loss : 0.281412
[22:03:28.628] iteration 3451 : model1 loss : 0.369557 model2 loss : 0.333851
[22:03:28.967] iteration 3452 : model1 loss : 0.364382 model2 loss : 0.314679
[22:03:29.304] iteration 3453 : model1 loss : 0.288689 model2 loss : 0.274806
[22:03:29.641] iteration 3454 : model1 loss : 0.296769 model2 loss : 0.265076
[22:03:29.978] iteration 3455 : model1 loss : 0.310685 model2 loss : 0.249243
[22:03:30.315] iteration 3456 : model1 loss : 0.255299 model2 loss : 0.280875
[22:03:30.653] iteration 3457 : model1 loss : 0.307720 model2 loss : 0.323864
[22:03:30.990] iteration 3458 : model1 loss : 0.237245 model2 loss : 0.181846
[22:03:31.327] iteration 3459 : model1 loss : 0.297700 model2 loss : 0.246345
[22:03:31.664] iteration 3460 : model1 loss : 0.236829 model2 loss : 0.228979
[22:03:31.992] iteration 3461 : model1 loss : 0.380475 model2 loss : 0.380422
[22:03:32.322] iteration 3462 : model1 loss : 0.243961 model2 loss : 0.221833
[22:03:32.659] iteration 3463 : model1 loss : 0.283838 model2 loss : 0.292024
[22:03:32.998] iteration 3464 : model1 loss : 0.282972 model2 loss : 0.252685
[22:03:33.338] iteration 3465 : model1 loss : 0.295456 model2 loss : 0.260769
[22:03:33.678] iteration 3466 : model1 loss : 0.346776 model2 loss : 0.303905
[22:03:34.015] iteration 3467 : model1 loss : 0.297069 model2 loss : 0.303947
[22:03:34.351] iteration 3468 : model1 loss : 0.353838 model2 loss : 0.313673
[22:03:34.688] iteration 3469 : model1 loss : 0.273049 model2 loss : 0.226107
[22:03:35.026] iteration 3470 : model1 loss : 0.262204 model2 loss : 0.232023
[22:03:35.363] iteration 3471 : model1 loss : 0.290806 model2 loss : 0.225978
[22:03:35.699] iteration 3472 : model1 loss : 0.298060 model2 loss : 0.333740
[22:03:36.036] iteration 3473 : model1 loss : 0.287633 model2 loss : 0.312489
[22:03:36.372] iteration 3474 : model1 loss : 0.260647 model2 loss : 0.223757
[22:03:36.712] iteration 3475 : model1 loss : 0.295219 model2 loss : 0.266296
[22:03:37.050] iteration 3476 : model1 loss : 0.277755 model2 loss : 0.254481
[22:03:37.388] iteration 3477 : model1 loss : 0.343826 model2 loss : 0.348594
[22:03:37.727] iteration 3478 : model1 loss : 0.303262 model2 loss : 0.298781
[22:03:38.065] iteration 3479 : model1 loss : 0.217130 model2 loss : 0.252011
[22:03:38.665] iteration 3480 : model1 loss : 0.363513 model2 loss : 0.350595
[22:03:39.005] iteration 3481 : model1 loss : 0.233314 model2 loss : 0.229580
[22:03:39.343] iteration 3482 : model1 loss : 0.335227 model2 loss : 0.310805
[22:03:39.680] iteration 3483 : model1 loss : 0.282718 model2 loss : 0.318295
[22:03:40.020] iteration 3484 : model1 loss : 0.347293 model2 loss : 0.313047
[22:03:40.358] iteration 3485 : model1 loss : 0.341989 model2 loss : 0.340838
[22:03:40.700] iteration 3486 : model1 loss : 0.313303 model2 loss : 0.313567
[22:03:41.037] iteration 3487 : model1 loss : 0.275529 model2 loss : 0.301540
[22:03:41.375] iteration 3488 : model1 loss : 0.312368 model2 loss : 0.299652
[22:03:41.714] iteration 3489 : model1 loss : 0.230928 model2 loss : 0.188904
[22:03:42.052] iteration 3490 : model1 loss : 0.441584 model2 loss : 0.420757
[22:03:42.390] iteration 3491 : model1 loss : 0.324272 model2 loss : 0.271295
[22:03:42.726] iteration 3492 : model1 loss : 0.332083 model2 loss : 0.241556
[22:03:43.065] iteration 3493 : model1 loss : 0.318885 model2 loss : 0.233274
[22:03:43.402] iteration 3494 : model1 loss : 0.283464 model2 loss : 0.249938
[22:03:43.739] iteration 3495 : model1 loss : 0.394518 model2 loss : 0.382521
[22:03:44.079] iteration 3496 : model1 loss : 0.273833 model2 loss : 0.271375
[22:03:44.414] iteration 3497 : model1 loss : 0.364080 model2 loss : 0.325361
[22:03:44.751] iteration 3498 : model1 loss : 0.365246 model2 loss : 0.380680
[22:03:45.087] iteration 3499 : model1 loss : 0.301451 model2 loss : 0.299460
[22:03:45.423] iteration 3500 : model1 loss : 0.339794 model2 loss : 0.355577
[22:03:46.067] iteration 3501 : model1 loss : 0.242576 model2 loss : 0.185356
[22:03:46.405] iteration 3502 : model1 loss : 0.312910 model2 loss : 0.300253
[22:03:46.743] iteration 3503 : model1 loss : 0.327442 model2 loss : 0.312468
[22:03:47.082] iteration 3504 : model1 loss : 0.224091 model2 loss : 0.226421
[22:03:47.418] iteration 3505 : model1 loss : 0.345263 model2 loss : 0.346997
[22:03:47.755] iteration 3506 : model1 loss : 0.386082 model2 loss : 0.336314
[22:03:48.091] iteration 3507 : model1 loss : 0.304210 model2 loss : 0.325120
[22:03:48.429] iteration 3508 : model1 loss : 0.296000 model2 loss : 0.282893
[22:03:48.766] iteration 3509 : model1 loss : 0.375121 model2 loss : 0.320924
[22:03:49.103] iteration 3510 : model1 loss : 0.261401 model2 loss : 0.205155
[22:03:49.441] iteration 3511 : model1 loss : 0.292583 model2 loss : 0.265598
[22:03:49.779] iteration 3512 : model1 loss : 0.248690 model2 loss : 0.280008
[22:03:50.118] iteration 3513 : model1 loss : 0.234786 model2 loss : 0.184247
[22:03:50.454] iteration 3514 : model1 loss : 0.280501 model2 loss : 0.259306
[22:03:50.790] iteration 3515 : model1 loss : 0.430054 model2 loss : 0.424437
[22:03:51.126] iteration 3516 : model1 loss : 0.402565 model2 loss : 0.367521
[22:03:51.469] iteration 3517 : model1 loss : 0.322855 model2 loss : 0.311871
[22:03:51.802] iteration 3518 : model1 loss : 0.284889 model2 loss : 0.248538
[22:03:52.139] iteration 3519 : model1 loss : 0.357021 model2 loss : 0.299518
[22:03:52.475] iteration 3520 : model1 loss : 0.261843 model2 loss : 0.267382
[22:03:52.815] iteration 3521 : model1 loss : 0.290217 model2 loss : 0.306530
[22:03:53.152] iteration 3522 : model1 loss : 0.319371 model2 loss : 0.228417
[22:03:53.489] iteration 3523 : model1 loss : 0.221672 model2 loss : 0.274985
[22:03:53.822] iteration 3524 : model1 loss : 0.408555 model2 loss : 0.384980
[22:03:54.162] iteration 3525 : model1 loss : 0.373970 model2 loss : 0.349701
[22:03:54.506] iteration 3526 : model1 loss : 0.380102 model2 loss : 0.377343
[22:03:54.842] iteration 3527 : model1 loss : 0.299819 model2 loss : 0.230852
[22:03:55.174] iteration 3528 : model1 loss : 0.316459 model2 loss : 0.300545
[22:03:55.511] iteration 3529 : model1 loss : 0.305573 model2 loss : 0.281710
[22:03:55.845] iteration 3530 : model1 loss : 0.277900 model2 loss : 0.287802
[22:03:56.177] iteration 3531 : model1 loss : 0.283114 model2 loss : 0.249822
[22:03:56.520] iteration 3532 : model1 loss : 0.214564 model2 loss : 0.184301
[22:03:56.856] iteration 3533 : model1 loss : 0.289866 model2 loss : 0.313301
[22:03:57.194] iteration 3534 : model1 loss : 0.334135 model2 loss : 0.322749
[22:03:57.531] iteration 3535 : model1 loss : 0.331974 model2 loss : 0.361429
[22:03:57.866] iteration 3536 : model1 loss : 0.373965 model2 loss : 0.220719
[22:03:58.205] iteration 3537 : model1 loss : 0.309388 model2 loss : 0.288504
[22:03:58.536] iteration 3538 : model1 loss : 0.216258 model2 loss : 0.155760
[22:03:58.869] iteration 3539 : model1 loss : 0.287104 model2 loss : 0.313322
[22:03:59.205] iteration 3540 : model1 loss : 0.260439 model2 loss : 0.217848
[22:03:59.548] iteration 3541 : model1 loss : 0.241397 model2 loss : 0.205418
[22:03:59.887] iteration 3542 : model1 loss : 0.390253 model2 loss : 0.305696
[22:04:00.224] iteration 3543 : model1 loss : 0.271814 model2 loss : 0.260161
[22:04:00.562] iteration 3544 : model1 loss : 0.308968 model2 loss : 0.279794
[22:04:00.899] iteration 3545 : model1 loss : 0.399551 model2 loss : 0.388401
[22:04:01.235] iteration 3546 : model1 loss : 0.355843 model2 loss : 0.337590
[22:04:01.571] iteration 3547 : model1 loss : 0.323342 model2 loss : 0.369263
[22:04:01.914] iteration 3548 : model1 loss : 0.384092 model2 loss : 0.394152
[22:04:02.252] iteration 3549 : model1 loss : 0.346871 model2 loss : 0.340856
[22:04:02.590] iteration 3550 : model1 loss : 0.340824 model2 loss : 0.308838
[22:04:03.206] iteration 3551 : model1 loss : 0.356735 model2 loss : 0.313475
[22:04:03.548] iteration 3552 : model1 loss : 0.349479 model2 loss : 0.266047
[22:04:03.896] iteration 3553 : model1 loss : 0.360809 model2 loss : 0.350489
[22:04:04.226] iteration 3554 : model1 loss : 0.300129 model2 loss : 0.272539
[22:04:04.555] iteration 3555 : model1 loss : 0.300420 model2 loss : 0.282988
[22:04:04.885] iteration 3556 : model1 loss : 0.362040 model2 loss : 0.288564
[22:04:05.211] iteration 3557 : model1 loss : 0.300921 model2 loss : 0.301589
[22:04:05.538] iteration 3558 : model1 loss : 0.308804 model2 loss : 0.326856
[22:04:05.867] iteration 3559 : model1 loss : 0.258881 model2 loss : 0.244619
[22:04:06.196] iteration 3560 : model1 loss : 0.259600 model2 loss : 0.239571
[22:04:06.525] iteration 3561 : model1 loss : 0.253697 model2 loss : 0.218674
[22:04:06.854] iteration 3562 : model1 loss : 0.212610 model2 loss : 0.208291
[22:04:07.183] iteration 3563 : model1 loss : 0.321521 model2 loss : 0.335496
[22:04:07.516] iteration 3564 : model1 loss : 0.255068 model2 loss : 0.262206
[22:04:07.845] iteration 3565 : model1 loss : 0.378796 model2 loss : 0.373676
[22:04:08.174] iteration 3566 : model1 loss : 0.274328 model2 loss : 0.238716
[22:04:08.507] iteration 3567 : model1 loss : 0.315099 model2 loss : 0.358170
[22:04:08.837] iteration 3568 : model1 loss : 0.262734 model2 loss : 0.272423
[22:04:09.175] iteration 3569 : model1 loss : 0.309940 model2 loss : 0.317407
[22:04:09.514] iteration 3570 : model1 loss : 0.381979 model2 loss : 0.347879
[22:04:09.851] iteration 3571 : model1 loss : 0.312888 model2 loss : 0.316274
[22:04:10.188] iteration 3572 : model1 loss : 0.264764 model2 loss : 0.246458
[22:04:10.525] iteration 3573 : model1 loss : 0.297446 model2 loss : 0.236183
[22:04:10.862] iteration 3574 : model1 loss : 0.284320 model2 loss : 0.259816
[22:04:11.198] iteration 3575 : model1 loss : 0.359783 model2 loss : 0.377184
[22:04:11.537] iteration 3576 : model1 loss : 0.264165 model2 loss : 0.289801
[22:04:11.875] iteration 3577 : model1 loss : 0.301985 model2 loss : 0.258941
[22:04:12.212] iteration 3578 : model1 loss : 0.311537 model2 loss : 0.326925
[22:04:12.550] iteration 3579 : model1 loss : 0.243223 model2 loss : 0.226743
[22:04:12.889] iteration 3580 : model1 loss : 0.309712 model2 loss : 0.261355
[22:04:13.227] iteration 3581 : model1 loss : 0.345007 model2 loss : 0.265698
[22:04:13.564] iteration 3582 : model1 loss : 0.307921 model2 loss : 0.278106
[22:04:13.902] iteration 3583 : model1 loss : 0.342855 model2 loss : 0.328249
[22:04:14.239] iteration 3584 : model1 loss : 0.267054 model2 loss : 0.240926
[22:04:14.587] iteration 3585 : model1 loss : 0.291945 model2 loss : 0.259964
[22:04:14.916] iteration 3586 : model1 loss : 0.278831 model2 loss : 0.246301
[22:04:15.244] iteration 3587 : model1 loss : 0.310359 model2 loss : 0.294509
[22:04:15.573] iteration 3588 : model1 loss : 0.275214 model2 loss : 0.253366
[22:04:15.902] iteration 3589 : model1 loss : 0.312881 model2 loss : 0.259291
[22:04:16.232] iteration 3590 : model1 loss : 0.223389 model2 loss : 0.249322
[22:04:16.560] iteration 3591 : model1 loss : 0.312731 model2 loss : 0.287887
[22:04:16.891] iteration 3592 : model1 loss : 0.211804 model2 loss : 0.190441
[22:04:17.219] iteration 3593 : model1 loss : 0.253344 model2 loss : 0.216450
[22:04:17.548] iteration 3594 : model1 loss : 0.317755 model2 loss : 0.224690
[22:04:17.880] iteration 3595 : model1 loss : 0.321391 model2 loss : 0.324643
[22:04:18.208] iteration 3596 : model1 loss : 0.292690 model2 loss : 0.316608
[22:04:18.536] iteration 3597 : model1 loss : 0.266728 model2 loss : 0.243571
[22:04:18.865] iteration 3598 : model1 loss : 0.326293 model2 loss : 0.296899
[22:04:19.193] iteration 3599 : model1 loss : 0.275423 model2 loss : 0.255027
[22:04:19.528] iteration 3600 : model1 loss : 0.352113 model2 loss : 0.306729
[22:04:20.085] iteration 3601 : model1 loss : 0.319469 model2 loss : 0.294593
[22:04:20.426] iteration 3602 : model1 loss : 0.307798 model2 loss : 0.259050
[22:04:20.768] iteration 3603 : model1 loss : 0.318535 model2 loss : 0.259479
[22:04:21.107] iteration 3604 : model1 loss : 0.253761 model2 loss : 0.305346
[22:04:21.447] iteration 3605 : model1 loss : 0.400916 model2 loss : 0.406404
[22:04:21.791] iteration 3606 : model1 loss : 0.336397 model2 loss : 0.357067
[22:04:22.131] iteration 3607 : model1 loss : 0.346709 model2 loss : 0.301287
[22:04:22.470] iteration 3608 : model1 loss : 0.330508 model2 loss : 0.298996
[22:04:22.808] iteration 3609 : model1 loss : 0.238619 model2 loss : 0.237337
[22:04:23.146] iteration 3610 : model1 loss : 0.351769 model2 loss : 0.340978
[22:04:23.484] iteration 3611 : model1 loss : 0.305767 model2 loss : 0.318087
[22:04:23.826] iteration 3612 : model1 loss : 0.236454 model2 loss : 0.204095
[22:04:24.154] iteration 3613 : model1 loss : 0.239231 model2 loss : 0.213942
[22:04:24.487] iteration 3614 : model1 loss : 0.358206 model2 loss : 0.377378
[22:04:24.815] iteration 3615 : model1 loss : 0.286141 model2 loss : 0.277243
[22:04:25.144] iteration 3616 : model1 loss : 0.268190 model2 loss : 0.320300
[22:04:25.473] iteration 3617 : model1 loss : 0.380766 model2 loss : 0.354315
[22:04:25.802] iteration 3618 : model1 loss : 0.310187 model2 loss : 0.274434
[22:04:26.130] iteration 3619 : model1 loss : 0.277725 model2 loss : 0.264875
[22:04:26.460] iteration 3620 : model1 loss : 0.301195 model2 loss : 0.352721
[22:04:26.788] iteration 3621 : model1 loss : 0.268882 model2 loss : 0.317167
[22:04:27.121] iteration 3622 : model1 loss : 0.260917 model2 loss : 0.206860
[22:04:27.450] iteration 3623 : model1 loss : 0.254135 model2 loss : 0.203695
[22:04:27.779] iteration 3624 : model1 loss : 0.275691 model2 loss : 0.225421
[22:04:28.106] iteration 3625 : model1 loss : 0.300895 model2 loss : 0.234809
[22:04:28.436] iteration 3626 : model1 loss : 0.260869 model2 loss : 0.272597
[22:04:28.765] iteration 3627 : model1 loss : 0.385107 model2 loss : 0.377326
[22:04:29.093] iteration 3628 : model1 loss : 0.255257 model2 loss : 0.298439
[22:04:29.423] iteration 3629 : model1 loss : 0.255725 model2 loss : 0.205150
[22:04:29.752] iteration 3630 : model1 loss : 0.322809 model2 loss : 0.325791
[22:04:30.079] iteration 3631 : model1 loss : 0.269737 model2 loss : 0.293986
[22:04:30.407] iteration 3632 : model1 loss : 0.303653 model2 loss : 0.281135
[22:04:30.735] iteration 3633 : model1 loss : 0.393618 model2 loss : 0.391345
[22:04:31.063] iteration 3634 : model1 loss : 0.387382 model2 loss : 0.392349
[22:04:31.391] iteration 3635 : model1 loss : 0.248197 model2 loss : 0.250780
[22:04:31.719] iteration 3636 : model1 loss : 0.287197 model2 loss : 0.227635
[22:04:32.048] iteration 3637 : model1 loss : 0.269160 model2 loss : 0.280641
[22:04:32.376] iteration 3638 : model1 loss : 0.270242 model2 loss : 0.263368
[22:04:32.704] iteration 3639 : model1 loss : 0.226057 model2 loss : 0.307148
[22:04:33.031] iteration 3640 : model1 loss : 0.266409 model2 loss : 0.293570
[22:04:33.358] iteration 3641 : model1 loss : 0.317794 model2 loss : 0.338840
[22:04:33.684] iteration 3642 : model1 loss : 0.240608 model2 loss : 0.253121
[22:04:34.011] iteration 3643 : model1 loss : 0.289577 model2 loss : 0.286815
[22:04:34.339] iteration 3644 : model1 loss : 0.315727 model2 loss : 0.334825
[22:04:34.665] iteration 3645 : model1 loss : 0.289580 model2 loss : 0.252223
[22:04:34.992] iteration 3646 : model1 loss : 0.316437 model2 loss : 0.298939
[22:04:35.319] iteration 3647 : model1 loss : 0.349417 model2 loss : 0.304389
[22:04:35.647] iteration 3648 : model1 loss : 0.208901 model2 loss : 0.214893
[22:04:35.975] iteration 3649 : model1 loss : 0.362138 model2 loss : 0.358204
[22:04:36.302] iteration 3650 : model1 loss : 0.221399 model2 loss : 0.235465
[22:04:36.843] iteration 3651 : model1 loss : 0.337306 model2 loss : 0.263168
[22:04:37.170] iteration 3652 : model1 loss : 0.431624 model2 loss : 0.402732
[22:04:37.497] iteration 3653 : model1 loss : 0.321227 model2 loss : 0.344737
[22:04:37.832] iteration 3654 : model1 loss : 0.278119 model2 loss : 0.303314
[22:04:38.159] iteration 3655 : model1 loss : 0.280546 model2 loss : 0.291943
[22:04:38.485] iteration 3656 : model1 loss : 0.346739 model2 loss : 0.342144
[22:04:38.811] iteration 3657 : model1 loss : 0.301816 model2 loss : 0.273881
[22:04:39.138] iteration 3658 : model1 loss : 0.359391 model2 loss : 0.315781
[22:04:39.466] iteration 3659 : model1 loss : 0.231769 model2 loss : 0.213345
[22:04:39.792] iteration 3660 : model1 loss : 0.268751 model2 loss : 0.260943
[22:04:40.120] iteration 3661 : model1 loss : 0.244225 model2 loss : 0.222346
[22:04:40.448] iteration 3662 : model1 loss : 0.411747 model2 loss : 0.297794
[22:04:40.775] iteration 3663 : model1 loss : 0.343172 model2 loss : 0.336234
[22:04:41.102] iteration 3664 : model1 loss : 0.297946 model2 loss : 0.274128
[22:04:41.429] iteration 3665 : model1 loss : 0.292036 model2 loss : 0.278064
[22:04:41.757] iteration 3666 : model1 loss : 0.266900 model2 loss : 0.249385
[22:04:42.084] iteration 3667 : model1 loss : 0.291138 model2 loss : 0.275163
[22:04:42.413] iteration 3668 : model1 loss : 0.337135 model2 loss : 0.292216
[22:04:42.740] iteration 3669 : model1 loss : 0.334935 model2 loss : 0.330917
[22:04:43.069] iteration 3670 : model1 loss : 0.309210 model2 loss : 0.287459
[22:04:43.398] iteration 3671 : model1 loss : 0.225324 model2 loss : 0.189248
[22:04:43.725] iteration 3672 : model1 loss : 0.263187 model2 loss : 0.258390
[22:04:44.052] iteration 3673 : model1 loss : 0.251808 model2 loss : 0.233010
[22:04:44.379] iteration 3674 : model1 loss : 0.292642 model2 loss : 0.286521
[22:04:44.706] iteration 3675 : model1 loss : 0.401044 model2 loss : 0.379771
[22:04:45.033] iteration 3676 : model1 loss : 0.303150 model2 loss : 0.294978
[22:04:45.360] iteration 3677 : model1 loss : 0.353897 model2 loss : 0.336344
[22:04:45.688] iteration 3678 : model1 loss : 0.362918 model2 loss : 0.342176
[22:04:46.018] iteration 3679 : model1 loss : 0.277763 model2 loss : 0.285757
[22:04:46.345] iteration 3680 : model1 loss : 0.262056 model2 loss : 0.215025
[22:04:46.676] iteration 3681 : model1 loss : 0.248509 model2 loss : 0.359422
[22:04:47.002] iteration 3682 : model1 loss : 0.259715 model2 loss : 0.249783
[22:04:47.329] iteration 3683 : model1 loss : 0.212229 model2 loss : 0.194931
[22:04:47.656] iteration 3684 : model1 loss : 0.231962 model2 loss : 0.274739
[22:04:47.983] iteration 3685 : model1 loss : 0.342629 model2 loss : 0.260575
[22:04:48.310] iteration 3686 : model1 loss : 0.261199 model2 loss : 0.221432
[22:04:48.639] iteration 3687 : model1 loss : 0.341892 model2 loss : 0.305873
[22:04:48.970] iteration 3688 : model1 loss : 0.248168 model2 loss : 0.206178
[22:04:49.298] iteration 3689 : model1 loss : 0.313519 model2 loss : 0.303437
[22:04:49.625] iteration 3690 : model1 loss : 0.361678 model2 loss : 0.299440
[22:04:49.953] iteration 3691 : model1 loss : 0.209700 model2 loss : 0.233273
[22:04:50.285] iteration 3692 : model1 loss : 0.264719 model2 loss : 0.175405
[22:04:50.613] iteration 3693 : model1 loss : 0.350869 model2 loss : 0.309977
[22:04:50.944] iteration 3694 : model1 loss : 0.363107 model2 loss : 0.333123
[22:04:51.272] iteration 3695 : model1 loss : 0.340568 model2 loss : 0.301582
[22:04:51.604] iteration 3696 : model1 loss : 0.333223 model2 loss : 0.238358
[22:04:51.931] iteration 3697 : model1 loss : 0.272087 model2 loss : 0.280446
[22:04:52.257] iteration 3698 : model1 loss : 0.337050 model2 loss : 0.367954
[22:04:52.585] iteration 3699 : model1 loss : 0.289123 model2 loss : 0.297470
[22:04:52.908] iteration 3700 : model1 loss : 0.295941 model2 loss : 0.355607
[22:04:53.401] iteration 3701 : model1 loss : 0.358050 model2 loss : 0.317097
[22:04:53.728] iteration 3702 : model1 loss : 0.281140 model2 loss : 0.266986
[22:04:54.055] iteration 3703 : model1 loss : 0.333358 model2 loss : 0.270355
[22:04:54.379] iteration 3704 : model1 loss : 0.384248 model2 loss : 0.394169
[22:04:54.706] iteration 3705 : model1 loss : 0.322570 model2 loss : 0.307698
[22:04:55.034] iteration 3706 : model1 loss : 0.307800 model2 loss : 0.343109
[22:04:55.362] iteration 3707 : model1 loss : 0.337518 model2 loss : 0.315845
[22:04:55.693] iteration 3708 : model1 loss : 0.311948 model2 loss : 0.323211
[22:04:56.021] iteration 3709 : model1 loss : 0.263103 model2 loss : 0.249797
[22:04:56.350] iteration 3710 : model1 loss : 0.231249 model2 loss : 0.139057
[22:04:56.678] iteration 3711 : model1 loss : 0.312987 model2 loss : 0.326300
[22:04:57.009] iteration 3712 : model1 loss : 0.420626 model2 loss : 0.407611
[22:04:57.337] iteration 3713 : model1 loss : 0.240725 model2 loss : 0.212116
[22:04:57.663] iteration 3714 : model1 loss : 0.257016 model2 loss : 0.225370
[22:04:57.991] iteration 3715 : model1 loss : 0.349364 model2 loss : 0.329606
[22:04:58.318] iteration 3716 : model1 loss : 0.442769 model2 loss : 0.300877
[22:04:58.646] iteration 3717 : model1 loss : 0.292977 model2 loss : 0.285432
[22:04:58.979] iteration 3718 : model1 loss : 0.301872 model2 loss : 0.297048
[22:04:59.306] iteration 3719 : model1 loss : 0.262878 model2 loss : 0.285968
[22:04:59.632] iteration 3720 : model1 loss : 0.270256 model2 loss : 0.188231
[22:04:59.959] iteration 3721 : model1 loss : 0.294350 model2 loss : 0.272559
[22:05:00.287] iteration 3722 : model1 loss : 0.404462 model2 loss : 0.429487
[22:05:00.615] iteration 3723 : model1 loss : 0.479181 model2 loss : 0.486146
[22:05:00.942] iteration 3724 : model1 loss : 0.345299 model2 loss : 0.334200
[22:05:01.270] iteration 3725 : model1 loss : 0.295209 model2 loss : 0.289118
[22:05:01.600] iteration 3726 : model1 loss : 0.308257 model2 loss : 0.261653
[22:05:01.927] iteration 3727 : model1 loss : 0.257776 model2 loss : 0.244050
[22:05:02.254] iteration 3728 : model1 loss : 0.274800 model2 loss : 0.259355
[22:05:02.582] iteration 3729 : model1 loss : 0.374457 model2 loss : 0.411380
[22:05:02.909] iteration 3730 : model1 loss : 0.260973 model2 loss : 0.252731
[22:05:03.237] iteration 3731 : model1 loss : 0.314579 model2 loss : 0.276174
[22:05:03.564] iteration 3732 : model1 loss : 0.396359 model2 loss : 0.332040
[22:05:03.892] iteration 3733 : model1 loss : 0.285907 model2 loss : 0.296592
[22:05:04.216] iteration 3734 : model1 loss : 0.257249 model2 loss : 0.235594
[22:05:04.541] iteration 3735 : model1 loss : 0.283655 model2 loss : 0.305678
[22:05:04.868] iteration 3736 : model1 loss : 0.232847 model2 loss : 0.271179
[22:05:05.195] iteration 3737 : model1 loss : 0.314702 model2 loss : 0.341909
[22:05:05.519] iteration 3738 : model1 loss : 0.200942 model2 loss : 0.178146
[22:05:05.847] iteration 3739 : model1 loss : 0.195332 model2 loss : 0.184075
[22:05:06.176] iteration 3740 : model1 loss : 0.197569 model2 loss : 0.196657
[22:05:06.504] iteration 3741 : model1 loss : 0.351403 model2 loss : 0.343545
[22:05:06.830] iteration 3742 : model1 loss : 0.196598 model2 loss : 0.230320
[22:05:07.157] iteration 3743 : model1 loss : 0.338746 model2 loss : 0.306815
[22:05:07.485] iteration 3744 : model1 loss : 0.340311 model2 loss : 0.328649
[22:05:07.812] iteration 3745 : model1 loss : 0.333184 model2 loss : 0.298783
[22:05:08.140] iteration 3746 : model1 loss : 0.324851 model2 loss : 0.335637
[22:05:08.468] iteration 3747 : model1 loss : 0.332281 model2 loss : 0.337642
[22:05:08.799] iteration 3748 : model1 loss : 0.267997 model2 loss : 0.273825
[22:05:09.127] iteration 3749 : model1 loss : 0.317653 model2 loss : 0.246684
[22:05:09.459] iteration 3750 : model1 loss : 0.354422 model2 loss : 0.359723
[22:05:09.994] iteration 3751 : model1 loss : 0.324672 model2 loss : 0.343590
[22:05:10.319] iteration 3752 : model1 loss : 0.224102 model2 loss : 0.239291
[22:05:10.643] iteration 3753 : model1 loss : 0.248881 model2 loss : 0.235099
[22:05:10.968] iteration 3754 : model1 loss : 0.264132 model2 loss : 0.226730
[22:05:11.293] iteration 3755 : model1 loss : 0.305758 model2 loss : 0.300641
[22:05:11.626] iteration 3756 : model1 loss : 0.268133 model2 loss : 0.274120
[22:05:11.952] iteration 3757 : model1 loss : 0.332859 model2 loss : 0.370488
[22:05:12.277] iteration 3758 : model1 loss : 0.269055 model2 loss : 0.311802
[22:05:12.601] iteration 3759 : model1 loss : 0.214044 model2 loss : 0.200913
[22:05:12.927] iteration 3760 : model1 loss : 0.221722 model2 loss : 0.271955
[22:05:13.254] iteration 3761 : model1 loss : 0.305469 model2 loss : 0.270165
[22:05:13.577] iteration 3762 : model1 loss : 0.357032 model2 loss : 0.335638
[22:05:13.913] iteration 3763 : model1 loss : 0.358225 model2 loss : 0.304266
[22:05:14.239] iteration 3764 : model1 loss : 0.361664 model2 loss : 0.240996
[22:05:14.565] iteration 3765 : model1 loss : 0.363683 model2 loss : 0.297875
[22:05:14.892] iteration 3766 : model1 loss : 0.234826 model2 loss : 0.198808
[22:05:15.219] iteration 3767 : model1 loss : 0.337135 model2 loss : 0.303832
[22:05:15.546] iteration 3768 : model1 loss : 0.198064 model2 loss : 0.148021
[22:05:15.873] iteration 3769 : model1 loss : 0.217839 model2 loss : 0.211359
[22:05:16.201] iteration 3770 : model1 loss : 0.324161 model2 loss : 0.318273
[22:05:16.528] iteration 3771 : model1 loss : 0.354822 model2 loss : 0.364531
[22:05:16.856] iteration 3772 : model1 loss : 0.385195 model2 loss : 0.329148
[22:05:17.186] iteration 3773 : model1 loss : 0.292750 model2 loss : 0.303433
[22:05:17.515] iteration 3774 : model1 loss : 0.343557 model2 loss : 0.315653
[22:05:17.843] iteration 3775 : model1 loss : 0.300198 model2 loss : 0.276244
[22:05:18.173] iteration 3776 : model1 loss : 0.301970 model2 loss : 0.299024
[22:05:18.508] iteration 3777 : model1 loss : 0.217527 model2 loss : 0.307138
[22:05:18.848] iteration 3778 : model1 loss : 0.374284 model2 loss : 0.280208
[22:05:19.186] iteration 3779 : model1 loss : 0.289583 model2 loss : 0.261820
[22:05:19.522] iteration 3780 : model1 loss : 0.295028 model2 loss : 0.289333
[22:05:19.859] iteration 3781 : model1 loss : 0.316695 model2 loss : 0.268297
[22:05:20.196] iteration 3782 : model1 loss : 0.284412 model2 loss : 0.308425
[22:05:20.533] iteration 3783 : model1 loss : 0.234744 model2 loss : 0.215107
[22:05:20.869] iteration 3784 : model1 loss : 0.316426 model2 loss : 0.311779
[22:05:21.206] iteration 3785 : model1 loss : 0.269620 model2 loss : 0.301081
[22:05:21.547] iteration 3786 : model1 loss : 0.333316 model2 loss : 0.319275
[22:05:21.884] iteration 3787 : model1 loss : 0.278695 model2 loss : 0.305026
[22:05:22.221] iteration 3788 : model1 loss : 0.295892 model2 loss : 0.243725
[22:05:22.558] iteration 3789 : model1 loss : 0.325886 model2 loss : 0.330256
[22:05:22.898] iteration 3790 : model1 loss : 0.321447 model2 loss : 0.272767
[22:05:23.235] iteration 3791 : model1 loss : 0.262626 model2 loss : 0.244975
[22:05:23.572] iteration 3792 : model1 loss : 0.333376 model2 loss : 0.280551
[22:05:23.912] iteration 3793 : model1 loss : 0.307397 model2 loss : 0.259135
[22:05:24.248] iteration 3794 : model1 loss : 0.321342 model2 loss : 0.335550
[22:05:24.585] iteration 3795 : model1 loss : 0.185572 model2 loss : 0.162677
[22:05:24.922] iteration 3796 : model1 loss : 0.201982 model2 loss : 0.143591
[22:05:25.260] iteration 3797 : model1 loss : 0.376672 model2 loss : 0.392232
[22:05:25.595] iteration 3798 : model1 loss : 0.295016 model2 loss : 0.342152
[22:05:25.933] iteration 3799 : model1 loss : 0.259370 model2 loss : 0.222605
[22:05:26.271] iteration 3800 : model1 loss : 0.179440 model2 loss : 0.121455
[22:05:26.894] iteration 3801 : model1 loss : 0.224404 model2 loss : 0.220995
[22:05:27.230] iteration 3802 : model1 loss : 0.272884 model2 loss : 0.236749
[22:05:27.568] iteration 3803 : model1 loss : 0.250519 model2 loss : 0.178240
[22:05:27.905] iteration 3804 : model1 loss : 0.227748 model2 loss : 0.253640
[22:05:28.242] iteration 3805 : model1 loss : 0.310207 model2 loss : 0.272317
[22:05:28.581] iteration 3806 : model1 loss : 0.287071 model2 loss : 0.305560
[22:05:28.919] iteration 3807 : model1 loss : 0.237527 model2 loss : 0.240074
[22:05:29.256] iteration 3808 : model1 loss : 0.331978 model2 loss : 0.376374
[22:05:29.584] iteration 3809 : model1 loss : 0.190260 model2 loss : 0.158684
[22:05:29.912] iteration 3810 : model1 loss : 0.584137 model2 loss : 0.548879
[22:05:30.240] iteration 3811 : model1 loss : 0.291486 model2 loss : 0.286958
[22:05:30.568] iteration 3812 : model1 loss : 0.308375 model2 loss : 0.288610
[22:05:30.897] iteration 3813 : model1 loss : 0.295164 model2 loss : 0.286355
[22:05:31.225] iteration 3814 : model1 loss : 0.287480 model2 loss : 0.328906
[22:05:31.555] iteration 3815 : model1 loss : 0.219225 model2 loss : 0.198815
[22:05:32.575] iteration 3816 : model1 loss : 0.222392 model2 loss : 0.218481
[22:05:32.904] iteration 3817 : model1 loss : 0.394228 model2 loss : 0.438478
[22:05:33.233] iteration 3818 : model1 loss : 0.289503 model2 loss : 0.331468
[22:05:33.566] iteration 3819 : model1 loss : 0.296494 model2 loss : 0.246545
[22:05:33.897] iteration 3820 : model1 loss : 0.233436 model2 loss : 0.183436
[22:05:34.229] iteration 3821 : model1 loss : 0.316975 model2 loss : 0.326882
[22:05:34.568] iteration 3822 : model1 loss : 0.284756 model2 loss : 0.284357
[22:05:34.911] iteration 3823 : model1 loss : 0.308549 model2 loss : 0.286988
[22:05:35.270] iteration 3824 : model1 loss : 0.293715 model2 loss : 0.271049
[22:05:35.611] iteration 3825 : model1 loss : 0.344413 model2 loss : 0.313878
[22:05:35.950] iteration 3826 : model1 loss : 0.317975 model2 loss : 0.270712
[22:05:36.289] iteration 3827 : model1 loss : 0.299709 model2 loss : 0.255184
[22:05:36.624] iteration 3828 : model1 loss : 0.260055 model2 loss : 0.286344
[22:05:36.963] iteration 3829 : model1 loss : 0.320061 model2 loss : 0.342736
[22:05:37.301] iteration 3830 : model1 loss : 0.275220 model2 loss : 0.217547
[22:05:37.639] iteration 3831 : model1 loss : 0.295035 model2 loss : 0.355968
[22:05:37.977] iteration 3832 : model1 loss : 0.242618 model2 loss : 0.302114
[22:05:38.313] iteration 3833 : model1 loss : 0.294919 model2 loss : 0.292761
[22:05:38.650] iteration 3834 : model1 loss : 0.332836 model2 loss : 0.340335
[22:05:38.978] iteration 3835 : model1 loss : 0.191568 model2 loss : 0.181520
[22:05:39.306] iteration 3836 : model1 loss : 0.249163 model2 loss : 0.314031
[22:05:39.634] iteration 3837 : model1 loss : 0.334463 model2 loss : 0.333267
[22:05:39.962] iteration 3838 : model1 loss : 0.372627 model2 loss : 0.314015
[22:05:40.291] iteration 3839 : model1 loss : 0.349729 model2 loss : 0.303631
[22:05:40.621] iteration 3840 : model1 loss : 0.232747 model2 loss : 0.244132
[22:05:40.950] iteration 3841 : model1 loss : 0.218112 model2 loss : 0.167106
[22:05:41.279] iteration 3842 : model1 loss : 0.302771 model2 loss : 0.208442
[22:05:41.606] iteration 3843 : model1 loss : 0.411214 model2 loss : 0.375848
[22:05:41.932] iteration 3844 : model1 loss : 0.335827 model2 loss : 0.363159
[22:05:42.262] iteration 3845 : model1 loss : 0.273769 model2 loss : 0.282264
[22:05:42.598] iteration 3846 : model1 loss : 0.224470 model2 loss : 0.245502
[22:05:42.931] iteration 3847 : model1 loss : 0.353050 model2 loss : 0.341903
[22:05:43.269] iteration 3848 : model1 loss : 0.410519 model2 loss : 0.373323
[22:05:43.610] iteration 3849 : model1 loss : 0.274159 model2 loss : 0.281814
[22:05:43.944] iteration 3850 : model1 loss : 0.311093 model2 loss : 0.296278
[22:05:44.574] iteration 3851 : model1 loss : 0.269606 model2 loss : 0.299293
[22:05:44.910] iteration 3852 : model1 loss : 0.280572 model2 loss : 0.299583
[22:05:45.245] iteration 3853 : model1 loss : 0.316727 model2 loss : 0.325933
[22:05:45.582] iteration 3854 : model1 loss : 0.305413 model2 loss : 0.277514
[22:05:45.915] iteration 3855 : model1 loss : 0.359614 model2 loss : 0.335479
[22:05:46.250] iteration 3856 : model1 loss : 0.388016 model2 loss : 0.312848
[22:05:46.587] iteration 3857 : model1 loss : 0.283336 model2 loss : 0.217992
[22:05:46.924] iteration 3858 : model1 loss : 0.343559 model2 loss : 0.323346
[22:05:47.261] iteration 3859 : model1 loss : 0.249866 model2 loss : 0.312764
[22:05:47.597] iteration 3860 : model1 loss : 0.278452 model2 loss : 0.295747
[22:05:47.932] iteration 3861 : model1 loss : 0.279156 model2 loss : 0.268858
[22:05:48.272] iteration 3862 : model1 loss : 0.238366 model2 loss : 0.253483
[22:05:48.610] iteration 3863 : model1 loss : 0.332817 model2 loss : 0.313696
[22:05:48.947] iteration 3864 : model1 loss : 0.219772 model2 loss : 0.178330
[22:05:49.286] iteration 3865 : model1 loss : 0.437692 model2 loss : 0.420696
[22:05:49.624] iteration 3866 : model1 loss : 0.248566 model2 loss : 0.239400
[22:05:49.963] iteration 3867 : model1 loss : 0.249434 model2 loss : 0.232568
[22:05:50.300] iteration 3868 : model1 loss : 0.265990 model2 loss : 0.248849
[22:05:50.636] iteration 3869 : model1 loss : 0.328671 model2 loss : 0.329734
[22:05:50.971] iteration 3870 : model1 loss : 0.398321 model2 loss : 0.407274
[22:05:51.304] iteration 3871 : model1 loss : 0.300144 model2 loss : 0.258031
[22:05:51.639] iteration 3872 : model1 loss : 0.312281 model2 loss : 0.286937
[22:05:51.976] iteration 3873 : model1 loss : 0.287772 model2 loss : 0.266548
[22:05:52.317] iteration 3874 : model1 loss : 0.328029 model2 loss : 0.314726
[22:05:52.659] iteration 3875 : model1 loss : 0.206904 model2 loss : 0.200056
[22:05:52.997] iteration 3876 : model1 loss : 0.294748 model2 loss : 0.309210
[22:05:53.334] iteration 3877 : model1 loss : 0.297915 model2 loss : 0.305333
[22:05:53.669] iteration 3878 : model1 loss : 0.368430 model2 loss : 0.345951
[22:05:54.009] iteration 3879 : model1 loss : 0.311704 model2 loss : 0.245875
[22:05:54.350] iteration 3880 : model1 loss : 0.334283 model2 loss : 0.302781
[22:05:54.686] iteration 3881 : model1 loss : 0.333435 model2 loss : 0.295490
[22:05:55.023] iteration 3882 : model1 loss : 0.263376 model2 loss : 0.286826
[22:05:55.365] iteration 3883 : model1 loss : 0.335505 model2 loss : 0.275336
[22:05:55.701] iteration 3884 : model1 loss : 0.339572 model2 loss : 0.340786
[22:05:56.038] iteration 3885 : model1 loss : 0.330739 model2 loss : 0.332678
[22:05:56.376] iteration 3886 : model1 loss : 0.245180 model2 loss : 0.232859
[22:05:56.713] iteration 3887 : model1 loss : 0.253026 model2 loss : 0.225971
[22:05:57.053] iteration 3888 : model1 loss : 0.246149 model2 loss : 0.230365
[22:05:57.390] iteration 3889 : model1 loss : 0.286720 model2 loss : 0.296913
[22:05:57.726] iteration 3890 : model1 loss : 0.331775 model2 loss : 0.251376
[22:05:58.063] iteration 3891 : model1 loss : 0.362097 model2 loss : 0.290275
[22:05:58.403] iteration 3892 : model1 loss : 0.281542 model2 loss : 0.231673
[22:05:58.744] iteration 3893 : model1 loss : 0.317850 model2 loss : 0.312715
[22:05:59.084] iteration 3894 : model1 loss : 0.280308 model2 loss : 0.239448
[22:05:59.422] iteration 3895 : model1 loss : 0.293195 model2 loss : 0.259938
[22:05:59.758] iteration 3896 : model1 loss : 0.293747 model2 loss : 0.277554
[22:06:00.095] iteration 3897 : model1 loss : 0.246310 model2 loss : 0.270377
[22:06:00.432] iteration 3898 : model1 loss : 0.283273 model2 loss : 0.228893
[22:06:00.769] iteration 3899 : model1 loss : 0.286755 model2 loss : 0.342663
[22:06:01.106] iteration 3900 : model1 loss : 0.249099 model2 loss : 0.233212
[22:06:01.758] iteration 3901 : model1 loss : 0.345214 model2 loss : 0.337345
[22:06:02.096] iteration 3902 : model1 loss : 0.294132 model2 loss : 0.321223
[22:06:02.430] iteration 3903 : model1 loss : 0.281083 model2 loss : 0.238192
[22:06:02.768] iteration 3904 : model1 loss : 0.370544 model2 loss : 0.287439
[22:06:03.107] iteration 3905 : model1 loss : 0.274981 model2 loss : 0.200274
[22:06:03.443] iteration 3906 : model1 loss : 0.392530 model2 loss : 0.345938
[22:06:03.781] iteration 3907 : model1 loss : 0.412152 model2 loss : 0.433803
[22:06:04.118] iteration 3908 : model1 loss : 0.369277 model2 loss : 0.302726
[22:06:04.454] iteration 3909 : model1 loss : 0.322944 model2 loss : 0.380371
[22:06:04.791] iteration 3910 : model1 loss : 0.315323 model2 loss : 0.299239
[22:06:05.126] iteration 3911 : model1 loss : 0.326144 model2 loss : 0.282262
[22:06:05.461] iteration 3912 : model1 loss : 0.257222 model2 loss : 0.265576
[22:06:05.798] iteration 3913 : model1 loss : 0.330722 model2 loss : 0.343111
[22:06:06.134] iteration 3914 : model1 loss : 0.336711 model2 loss : 0.278742
[22:06:06.471] iteration 3915 : model1 loss : 0.357772 model2 loss : 0.350679
[22:06:06.806] iteration 3916 : model1 loss : 0.300436 model2 loss : 0.335883
[22:06:07.139] iteration 3917 : model1 loss : 0.424943 model2 loss : 0.374045
[22:06:07.478] iteration 3918 : model1 loss : 0.287092 model2 loss : 0.279947
[22:06:07.814] iteration 3919 : model1 loss : 0.257873 model2 loss : 0.232100
[22:06:08.152] iteration 3920 : model1 loss : 0.216768 model2 loss : 0.207663
[22:06:08.490] iteration 3921 : model1 loss : 0.286375 model2 loss : 0.286176
[22:06:08.830] iteration 3922 : model1 loss : 0.344013 model2 loss : 0.316782
[22:06:09.166] iteration 3923 : model1 loss : 0.284424 model2 loss : 0.278499
[22:06:09.503] iteration 3924 : model1 loss : 0.265168 model2 loss : 0.272309
[22:06:09.838] iteration 3925 : model1 loss : 0.457271 model2 loss : 0.482343
[22:06:10.173] iteration 3926 : model1 loss : 0.319486 model2 loss : 0.288448
[22:06:10.507] iteration 3927 : model1 loss : 0.326895 model2 loss : 0.258912
[22:06:10.846] iteration 3928 : model1 loss : 0.259428 model2 loss : 0.258441
[22:06:11.186] iteration 3929 : model1 loss : 0.305337 model2 loss : 0.248066
[22:06:11.524] iteration 3930 : model1 loss : 0.299244 model2 loss : 0.313291
[22:06:11.860] iteration 3931 : model1 loss : 0.231013 model2 loss : 0.218820
[22:06:12.197] iteration 3932 : model1 loss : 0.293305 model2 loss : 0.237388
[22:06:12.536] iteration 3933 : model1 loss : 0.294601 model2 loss : 0.305418
[22:06:12.874] iteration 3934 : model1 loss : 0.270724 model2 loss : 0.266862
[22:06:13.212] iteration 3935 : model1 loss : 0.271399 model2 loss : 0.224302
[22:06:13.550] iteration 3936 : model1 loss : 0.315457 model2 loss : 0.328597
[22:06:13.890] iteration 3937 : model1 loss : 0.300653 model2 loss : 0.268215
[22:06:14.228] iteration 3938 : model1 loss : 0.253615 model2 loss : 0.273065
[22:06:14.565] iteration 3939 : model1 loss : 0.342478 model2 loss : 0.352395
[22:06:14.901] iteration 3940 : model1 loss : 0.196402 model2 loss : 0.210654
[22:06:15.239] iteration 3941 : model1 loss : 0.268797 model2 loss : 0.327800
[22:06:15.576] iteration 3942 : model1 loss : 0.379127 model2 loss : 0.317077
[22:06:15.915] iteration 3943 : model1 loss : 0.243683 model2 loss : 0.223234
[22:06:16.254] iteration 3944 : model1 loss : 0.288073 model2 loss : 0.211835
[22:06:16.591] iteration 3945 : model1 loss : 0.302434 model2 loss : 0.302424
[22:06:16.929] iteration 3946 : model1 loss : 0.301395 model2 loss : 0.299414
[22:06:17.268] iteration 3947 : model1 loss : 0.337004 model2 loss : 0.315196
[22:06:17.607] iteration 3948 : model1 loss : 0.254182 model2 loss : 0.327753
[22:06:17.945] iteration 3949 : model1 loss : 0.289039 model2 loss : 0.281301
[22:06:18.281] iteration 3950 : model1 loss : 0.320874 model2 loss : 0.232344
[22:06:18.910] iteration 3951 : model1 loss : 0.379041 model2 loss : 0.256675
[22:06:19.274] iteration 3952 : model1 loss : 0.294953 model2 loss : 0.241719
[22:06:19.610] iteration 3953 : model1 loss : 0.245628 model2 loss : 0.211134
[22:06:19.944] iteration 3954 : model1 loss : 0.321075 model2 loss : 0.284407
[22:06:20.277] iteration 3955 : model1 loss : 0.416639 model2 loss : 0.450202
[22:06:20.615] iteration 3956 : model1 loss : 0.299105 model2 loss : 0.244611
[22:06:20.952] iteration 3957 : model1 loss : 0.342256 model2 loss : 0.339523
[22:06:21.288] iteration 3958 : model1 loss : 0.394566 model2 loss : 0.355547
[22:06:21.626] iteration 3959 : model1 loss : 0.249851 model2 loss : 0.174709
[22:06:21.974] iteration 3960 : model1 loss : 0.339842 model2 loss : 0.364265
[22:06:22.312] iteration 3961 : model1 loss : 0.347544 model2 loss : 0.375952
[22:06:22.646] iteration 3962 : model1 loss : 0.323160 model2 loss : 0.288093
[22:06:22.982] iteration 3963 : model1 loss : 0.264546 model2 loss : 0.205594
[22:06:23.318] iteration 3964 : model1 loss : 0.272543 model2 loss : 0.235660
[22:06:23.656] iteration 3965 : model1 loss : 0.313256 model2 loss : 0.323094
[22:06:23.992] iteration 3966 : model1 loss : 0.308117 model2 loss : 0.281191
[22:06:24.328] iteration 3967 : model1 loss : 0.338938 model2 loss : 0.351094
[22:06:24.664] iteration 3968 : model1 loss : 0.371755 model2 loss : 0.275655
[22:06:24.998] iteration 3969 : model1 loss : 0.381054 model2 loss : 0.288761
[22:06:25.333] iteration 3970 : model1 loss : 0.238085 model2 loss : 0.229721
[22:06:25.670] iteration 3971 : model1 loss : 0.286037 model2 loss : 0.362963
[22:06:26.006] iteration 3972 : model1 loss : 0.353233 model2 loss : 0.263646
[22:06:26.345] iteration 3973 : model1 loss : 0.303962 model2 loss : 0.280463
[22:06:26.680] iteration 3974 : model1 loss : 0.321645 model2 loss : 0.300170
[22:06:27.017] iteration 3975 : model1 loss : 0.190746 model2 loss : 0.188544
[22:06:27.355] iteration 3976 : model1 loss : 0.330782 model2 loss : 0.206700
[22:06:27.695] iteration 3977 : model1 loss : 0.474093 model2 loss : 0.353072
[22:06:28.033] iteration 3978 : model1 loss : 0.321350 model2 loss : 0.248251
[22:06:28.372] iteration 3979 : model1 loss : 0.272526 model2 loss : 0.264325
[22:06:28.709] iteration 3980 : model1 loss : 0.287061 model2 loss : 0.275945
[22:06:29.046] iteration 3981 : model1 loss : 0.227208 model2 loss : 0.297817
[22:06:29.381] iteration 3982 : model1 loss : 0.264925 model2 loss : 0.261123
[22:06:29.718] iteration 3983 : model1 loss : 0.236996 model2 loss : 0.259923
[22:06:30.055] iteration 3984 : model1 loss : 0.266928 model2 loss : 0.237328
[22:06:30.392] iteration 3985 : model1 loss : 0.224852 model2 loss : 0.238380
[22:06:30.728] iteration 3986 : model1 loss : 0.285809 model2 loss : 0.261867
[22:06:31.065] iteration 3987 : model1 loss : 0.265800 model2 loss : 0.241225
[22:06:31.402] iteration 3988 : model1 loss : 0.214262 model2 loss : 0.206989
[22:06:31.738] iteration 3989 : model1 loss : 0.245849 model2 loss : 0.271949
[22:06:32.076] iteration 3990 : model1 loss : 0.341333 model2 loss : 0.258048
[22:06:32.412] iteration 3991 : model1 loss : 0.200942 model2 loss : 0.245308
[22:06:32.751] iteration 3992 : model1 loss : 0.426645 model2 loss : 0.451052
[22:06:33.087] iteration 3993 : model1 loss : 0.313912 model2 loss : 0.314309
[22:06:33.423] iteration 3994 : model1 loss : 0.269373 model2 loss : 0.224585
[22:06:33.760] iteration 3995 : model1 loss : 0.320922 model2 loss : 0.306534
[22:06:34.097] iteration 3996 : model1 loss : 0.308247 model2 loss : 0.236010
[22:06:34.434] iteration 3997 : model1 loss : 0.356928 model2 loss : 0.332005
[22:06:34.769] iteration 3998 : model1 loss : 0.259359 model2 loss : 0.270745
[22:06:35.107] iteration 3999 : model1 loss : 0.313675 model2 loss : 0.288699
[22:06:35.444] iteration 4000 : model1 loss : 0.391087 model2 loss : 0.279653
[22:06:36.091] iteration 4001 : model1 loss : 0.268518 model2 loss : 0.189606
[22:06:36.431] iteration 4002 : model1 loss : 0.337605 model2 loss : 0.321784
[22:06:36.769] iteration 4003 : model1 loss : 0.332105 model2 loss : 0.296518
[22:06:37.108] iteration 4004 : model1 loss : 0.261240 model2 loss : 0.266542
[22:06:37.445] iteration 4005 : model1 loss : 0.371874 model2 loss : 0.330211
[22:06:37.781] iteration 4006 : model1 loss : 0.332560 model2 loss : 0.302582
[22:06:38.124] iteration 4007 : model1 loss : 0.372045 model2 loss : 0.313125
[22:06:38.461] iteration 4008 : model1 loss : 0.270886 model2 loss : 0.271281
[22:06:38.799] iteration 4009 : model1 loss : 0.262224 model2 loss : 0.221338
[22:06:39.139] iteration 4010 : model1 loss : 0.338276 model2 loss : 0.367747
[22:06:39.478] iteration 4011 : model1 loss : 0.334834 model2 loss : 0.273653
[22:06:39.815] iteration 4012 : model1 loss : 0.186689 model2 loss : 0.160255
[22:06:40.154] iteration 4013 : model1 loss : 0.275641 model2 loss : 0.296862
[22:06:40.491] iteration 4014 : model1 loss : 0.275222 model2 loss : 0.294480
[22:06:40.828] iteration 4015 : model1 loss : 0.317747 model2 loss : 0.261856
[22:06:41.169] iteration 4016 : model1 loss : 0.318349 model2 loss : 0.321540
[22:06:41.510] iteration 4017 : model1 loss : 0.349866 model2 loss : 0.363980
[22:06:41.848] iteration 4018 : model1 loss : 0.270869 model2 loss : 0.274472
[22:06:42.185] iteration 4019 : model1 loss : 0.357005 model2 loss : 0.340185
[22:06:42.525] iteration 4020 : model1 loss : 0.324684 model2 loss : 0.285374
[22:06:42.863] iteration 4021 : model1 loss : 0.339540 model2 loss : 0.288504
[22:06:43.200] iteration 4022 : model1 loss : 0.312291 model2 loss : 0.352227
[22:06:43.537] iteration 4023 : model1 loss : 0.308853 model2 loss : 0.286513
[22:06:43.875] iteration 4024 : model1 loss : 0.262424 model2 loss : 0.206051
[22:06:44.211] iteration 4025 : model1 loss : 0.281459 model2 loss : 0.231069
[22:06:44.548] iteration 4026 : model1 loss : 0.295072 model2 loss : 0.333989
[22:06:44.885] iteration 4027 : model1 loss : 0.402635 model2 loss : 0.367206
[22:06:45.223] iteration 4028 : model1 loss : 0.300896 model2 loss : 0.246080
[22:06:45.562] iteration 4029 : model1 loss : 0.247322 model2 loss : 0.250814
[22:06:45.899] iteration 4030 : model1 loss : 0.257088 model2 loss : 0.236316
[22:06:46.236] iteration 4031 : model1 loss : 0.350173 model2 loss : 0.337442
[22:06:46.573] iteration 4032 : model1 loss : 0.293960 model2 loss : 0.278461
[22:06:46.911] iteration 4033 : model1 loss : 0.457544 model2 loss : 0.340340
[22:06:47.248] iteration 4034 : model1 loss : 0.436966 model2 loss : 0.359354
[22:06:47.585] iteration 4035 : model1 loss : 0.199649 model2 loss : 0.177268
[22:06:47.922] iteration 4036 : model1 loss : 0.259924 model2 loss : 0.170926
[22:06:48.257] iteration 4037 : model1 loss : 0.305006 model2 loss : 0.350008
[22:06:48.594] iteration 4038 : model1 loss : 0.396170 model2 loss : 0.395066
[22:06:48.930] iteration 4039 : model1 loss : 0.304695 model2 loss : 0.295406
[22:06:49.265] iteration 4040 : model1 loss : 0.337562 model2 loss : 0.319870
[22:06:49.602] iteration 4041 : model1 loss : 0.286599 model2 loss : 0.219063
[22:06:49.936] iteration 4042 : model1 loss : 0.248833 model2 loss : 0.245032
[22:06:50.271] iteration 4043 : model1 loss : 0.217598 model2 loss : 0.213900
[22:06:50.609] iteration 4044 : model1 loss : 0.296394 model2 loss : 0.260152
[22:06:50.946] iteration 4045 : model1 loss : 0.254708 model2 loss : 0.256714
[22:06:51.282] iteration 4046 : model1 loss : 0.237543 model2 loss : 0.233136
[22:06:51.618] iteration 4047 : model1 loss : 0.316867 model2 loss : 0.306562
[22:06:51.957] iteration 4048 : model1 loss : 0.376898 model2 loss : 0.343820
[22:06:52.294] iteration 4049 : model1 loss : 0.336250 model2 loss : 0.283339
[22:06:52.627] iteration 4050 : model1 loss : 0.343764 model2 loss : 0.342177
[22:06:53.258] iteration 4051 : model1 loss : 0.333765 model2 loss : 0.345941
[22:06:53.598] iteration 4052 : model1 loss : 0.255542 model2 loss : 0.230650
[22:06:53.936] iteration 4053 : model1 loss : 0.260637 model2 loss : 0.227409
[22:06:54.275] iteration 4054 : model1 loss : 0.218662 model2 loss : 0.205456
[22:06:54.613] iteration 4055 : model1 loss : 0.311914 model2 loss : 0.277590
[22:06:54.949] iteration 4056 : model1 loss : 0.311123 model2 loss : 0.252595
[22:06:55.288] iteration 4057 : model1 loss : 0.347933 model2 loss : 0.317409
[22:06:55.625] iteration 4058 : model1 loss : 0.345568 model2 loss : 0.337952
[22:06:55.962] iteration 4059 : model1 loss : 0.247540 model2 loss : 0.230785
[22:06:56.300] iteration 4060 : model1 loss : 0.294840 model2 loss : 0.251131
[22:06:56.637] iteration 4061 : model1 loss : 0.265041 model2 loss : 0.221162
[22:06:56.974] iteration 4062 : model1 loss : 0.303071 model2 loss : 0.284894
[22:06:57.310] iteration 4063 : model1 loss : 0.275155 model2 loss : 0.187953
[22:06:57.646] iteration 4064 : model1 loss : 0.331861 model2 loss : 0.390700
[22:06:57.981] iteration 4065 : model1 loss : 0.278641 model2 loss : 0.271482
[22:06:58.316] iteration 4066 : model1 loss : 0.299231 model2 loss : 0.288229
[22:06:58.655] iteration 4067 : model1 loss : 0.305837 model2 loss : 0.289425
[22:06:58.993] iteration 4068 : model1 loss : 0.257929 model2 loss : 0.259847
[22:06:59.331] iteration 4069 : model1 loss : 0.311671 model2 loss : 0.285365
[22:06:59.667] iteration 4070 : model1 loss : 0.401239 model2 loss : 0.432221
[22:07:00.007] iteration 4071 : model1 loss : 0.333319 model2 loss : 0.296919
[22:07:00.345] iteration 4072 : model1 loss : 0.356220 model2 loss : 0.353273
[22:07:00.682] iteration 4073 : model1 loss : 0.345797 model2 loss : 0.203425
[22:07:01.022] iteration 4074 : model1 loss : 0.338281 model2 loss : 0.285858
[22:07:01.362] iteration 4075 : model1 loss : 0.390031 model2 loss : 0.365420
[22:07:01.700] iteration 4076 : model1 loss : 0.302193 model2 loss : 0.256525
[22:07:02.040] iteration 4077 : model1 loss : 0.242902 model2 loss : 0.232857
[22:07:02.377] iteration 4078 : model1 loss : 0.266940 model2 loss : 0.222368
[22:07:02.715] iteration 4079 : model1 loss : 0.410745 model2 loss : 0.425851
[22:07:03.058] iteration 4080 : model1 loss : 0.307140 model2 loss : 0.242671
[22:07:03.394] iteration 4081 : model1 loss : 0.249584 model2 loss : 0.171222
[22:07:03.733] iteration 4082 : model1 loss : 0.251285 model2 loss : 0.239073
[22:07:04.073] iteration 4083 : model1 loss : 0.208905 model2 loss : 0.187227
[22:07:04.414] iteration 4084 : model1 loss : 0.335726 model2 loss : 0.268940
[22:07:04.752] iteration 4085 : model1 loss : 0.350139 model2 loss : 0.323952
[22:07:05.089] iteration 4086 : model1 loss : 0.351042 model2 loss : 0.380551
[22:07:05.427] iteration 4087 : model1 loss : 0.257594 model2 loss : 0.234889
[22:07:05.764] iteration 4088 : model1 loss : 0.303326 model2 loss : 0.259880
[22:07:06.102] iteration 4089 : model1 loss : 0.329414 model2 loss : 0.307633
[22:07:06.441] iteration 4090 : model1 loss : 0.331072 model2 loss : 0.310993
[22:07:06.806] iteration 4091 : model1 loss : 0.364051 model2 loss : 0.326753
[22:07:07.144] iteration 4092 : model1 loss : 0.469455 model2 loss : 0.314755
[22:07:07.485] iteration 4093 : model1 loss : 0.250718 model2 loss : 0.247480
[22:07:07.823] iteration 4094 : model1 loss : 0.443560 model2 loss : 0.442575
[22:07:08.159] iteration 4095 : model1 loss : 0.357558 model2 loss : 0.395195
[22:07:08.494] iteration 4096 : model1 loss : 0.355073 model2 loss : 0.361404
[22:07:08.830] iteration 4097 : model1 loss : 0.284326 model2 loss : 0.218366
[22:07:09.165] iteration 4098 : model1 loss : 0.299996 model2 loss : 0.140667
[22:07:09.502] iteration 4099 : model1 loss : 0.418943 model2 loss : 0.331533
[22:07:09.838] iteration 4100 : model1 loss : 0.388696 model2 loss : 0.335462
[22:07:10.504] iteration 4101 : model1 loss : 0.338400 model2 loss : 0.254291
[22:07:10.842] iteration 4102 : model1 loss : 0.337713 model2 loss : 0.312778
[22:07:11.178] iteration 4103 : model1 loss : 0.388602 model2 loss : 0.314399
[22:07:11.514] iteration 4104 : model1 loss : 0.362211 model2 loss : 0.329441
[22:07:11.850] iteration 4105 : model1 loss : 0.247173 model2 loss : 0.172928
[22:07:12.185] iteration 4106 : model1 loss : 0.330048 model2 loss : 0.330280
[22:07:12.518] iteration 4107 : model1 loss : 0.403600 model2 loss : 0.373646
[22:07:12.853] iteration 4108 : model1 loss : 0.362632 model2 loss : 0.316189
[22:07:13.191] iteration 4109 : model1 loss : 0.322208 model2 loss : 0.206107
[22:07:13.531] iteration 4110 : model1 loss : 0.320490 model2 loss : 0.250036
[22:07:13.868] iteration 4111 : model1 loss : 0.296396 model2 loss : 0.271041
[22:07:14.207] iteration 4112 : model1 loss : 0.360266 model2 loss : 0.323294
[22:07:14.544] iteration 4113 : model1 loss : 0.347337 model2 loss : 0.395420
[22:07:14.888] iteration 4114 : model1 loss : 0.295022 model2 loss : 0.244449
[22:07:15.226] iteration 4115 : model1 loss : 0.308652 model2 loss : 0.335953
[22:07:15.564] iteration 4116 : model1 loss : 0.230710 model2 loss : 0.244204
[22:07:15.901] iteration 4117 : model1 loss : 0.246916 model2 loss : 0.213951
[22:07:16.239] iteration 4118 : model1 loss : 0.323301 model2 loss : 0.313358
[22:07:16.576] iteration 4119 : model1 loss : 0.301756 model2 loss : 0.325291
[22:07:16.914] iteration 4120 : model1 loss : 0.335019 model2 loss : 0.246528
[22:07:17.251] iteration 4121 : model1 loss : 0.405865 model2 loss : 0.285410
[22:07:17.589] iteration 4122 : model1 loss : 0.314487 model2 loss : 0.292772
[22:07:17.926] iteration 4123 : model1 loss : 0.214338 model2 loss : 0.227259
[22:07:18.264] iteration 4124 : model1 loss : 0.318381 model2 loss : 0.379445
[22:07:18.601] iteration 4125 : model1 loss : 0.314268 model2 loss : 0.245098
[22:07:18.939] iteration 4126 : model1 loss : 0.370424 model2 loss : 0.353505
[22:07:19.277] iteration 4127 : model1 loss : 0.307578 model2 loss : 0.293527
[22:07:19.613] iteration 4128 : model1 loss : 0.382216 model2 loss : 0.375797
[22:07:19.950] iteration 4129 : model1 loss : 0.321417 model2 loss : 0.293530
[22:07:20.288] iteration 4130 : model1 loss : 0.224183 model2 loss : 0.211593
[22:07:20.626] iteration 4131 : model1 loss : 0.370253 model2 loss : 0.380411
[22:07:20.963] iteration 4132 : model1 loss : 0.372370 model2 loss : 0.383075
[22:07:21.301] iteration 4133 : model1 loss : 0.221238 model2 loss : 0.292439
[22:07:21.639] iteration 4134 : model1 loss : 0.264311 model2 loss : 0.211655
[22:07:21.976] iteration 4135 : model1 loss : 0.356371 model2 loss : 0.352551
[22:07:22.312] iteration 4136 : model1 loss : 0.326944 model2 loss : 0.287885
[22:07:22.649] iteration 4137 : model1 loss : 0.291007 model2 loss : 0.281768
[22:07:22.990] iteration 4138 : model1 loss : 0.313258 model2 loss : 0.293677
[22:07:23.327] iteration 4139 : model1 loss : 0.325075 model2 loss : 0.171912
[22:07:23.665] iteration 4140 : model1 loss : 0.231678 model2 loss : 0.163109
[22:07:24.003] iteration 4141 : model1 loss : 0.440612 model2 loss : 0.387683
[22:07:24.342] iteration 4142 : model1 loss : 0.414849 model2 loss : 0.420063
[22:07:24.682] iteration 4143 : model1 loss : 0.386312 model2 loss : 0.311347
[22:07:25.020] iteration 4144 : model1 loss : 0.291635 model2 loss : 0.278322
[22:07:25.357] iteration 4145 : model1 loss : 0.218668 model2 loss : 0.210554
[22:07:25.696] iteration 4146 : model1 loss : 0.264063 model2 loss : 0.264108
[22:07:26.033] iteration 4147 : model1 loss : 0.349734 model2 loss : 0.339182
[22:07:26.370] iteration 4148 : model1 loss : 0.301104 model2 loss : 0.278864
[22:07:26.712] iteration 4149 : model1 loss : 0.317135 model2 loss : 0.232381
[22:07:27.050] iteration 4150 : model1 loss : 0.374600 model2 loss : 0.363625
[22:07:27.684] iteration 4151 : model1 loss : 0.265228 model2 loss : 0.215329
[22:07:28.021] iteration 4152 : model1 loss : 0.279915 model2 loss : 0.277947
[22:07:28.360] iteration 4153 : model1 loss : 0.267761 model2 loss : 0.276256
[22:07:28.698] iteration 4154 : model1 loss : 0.341695 model2 loss : 0.279548
[22:07:29.038] iteration 4155 : model1 loss : 0.326579 model2 loss : 0.380954
[22:07:29.380] iteration 4156 : model1 loss : 0.308225 model2 loss : 0.321333
[22:07:29.717] iteration 4157 : model1 loss : 0.306231 model2 loss : 0.237756
[22:07:30.059] iteration 4158 : model1 loss : 0.306242 model2 loss : 0.284002
[22:07:30.392] iteration 4159 : model1 loss : 0.360993 model2 loss : 0.291272
[22:07:30.728] iteration 4160 : model1 loss : 0.266402 model2 loss : 0.228431
[22:07:31.059] iteration 4161 : model1 loss : 0.280624 model2 loss : 0.261387
[22:07:31.398] iteration 4162 : model1 loss : 0.293022 model2 loss : 0.280043
[22:07:31.737] iteration 4163 : model1 loss : 0.265448 model2 loss : 0.228488
[22:07:32.076] iteration 4164 : model1 loss : 0.242991 model2 loss : 0.200377
[22:07:32.415] iteration 4165 : model1 loss : 0.361895 model2 loss : 0.262438
[22:07:32.753] iteration 4166 : model1 loss : 0.333132 model2 loss : 0.304212
[22:07:33.090] iteration 4167 : model1 loss : 0.379349 model2 loss : 0.298302
[22:07:33.429] iteration 4168 : model1 loss : 0.243175 model2 loss : 0.209858
[22:07:33.768] iteration 4169 : model1 loss : 0.239897 model2 loss : 0.231510
[22:07:34.109] iteration 4170 : model1 loss : 0.305557 model2 loss : 0.307861
[22:07:34.447] iteration 4171 : model1 loss : 0.439578 model2 loss : 0.368742
[22:07:34.785] iteration 4172 : model1 loss : 0.305315 model2 loss : 0.307498
[22:07:35.123] iteration 4173 : model1 loss : 0.372299 model2 loss : 0.390038
[22:07:35.461] iteration 4174 : model1 loss : 0.379665 model2 loss : 0.366333
[22:07:35.799] iteration 4175 : model1 loss : 0.228532 model2 loss : 0.278584
[22:07:36.136] iteration 4176 : model1 loss : 0.258980 model2 loss : 0.251516
[22:07:36.479] iteration 4177 : model1 loss : 0.342504 model2 loss : 0.333895
[22:07:36.816] iteration 4178 : model1 loss : 0.277629 model2 loss : 0.247997
[22:07:37.154] iteration 4179 : model1 loss : 0.281416 model2 loss : 0.257431
[22:07:37.492] iteration 4180 : model1 loss : 0.328563 model2 loss : 0.318490
[22:07:37.830] iteration 4181 : model1 loss : 0.245846 model2 loss : 0.250687
[22:07:38.170] iteration 4182 : model1 loss : 0.398593 model2 loss : 0.424663
[22:07:38.510] iteration 4183 : model1 loss : 0.312686 model2 loss : 0.268713
[22:07:38.849] iteration 4184 : model1 loss : 0.309855 model2 loss : 0.242331
[22:07:39.188] iteration 4185 : model1 loss : 0.282283 model2 loss : 0.302530
[22:07:39.525] iteration 4186 : model1 loss : 0.326134 model2 loss : 0.350698
[22:07:39.864] iteration 4187 : model1 loss : 0.289657 model2 loss : 0.253112
[22:07:40.204] iteration 4188 : model1 loss : 0.302491 model2 loss : 0.250285
[22:07:40.542] iteration 4189 : model1 loss : 0.310012 model2 loss : 0.274554
[22:07:40.879] iteration 4190 : model1 loss : 0.301489 model2 loss : 0.249114
[22:07:41.218] iteration 4191 : model1 loss : 0.379610 model2 loss : 0.381467
[22:07:41.561] iteration 4192 : model1 loss : 0.165937 model2 loss : 0.202568
[22:07:41.900] iteration 4193 : model1 loss : 0.319006 model2 loss : 0.297018
[22:07:42.244] iteration 4194 : model1 loss : 0.314992 model2 loss : 0.314279
[22:07:42.587] iteration 4195 : model1 loss : 0.342324 model2 loss : 0.350219
[22:07:42.926] iteration 4196 : model1 loss : 0.296149 model2 loss : 0.279377
[22:07:43.264] iteration 4197 : model1 loss : 0.226948 model2 loss : 0.254448
[22:07:43.603] iteration 4198 : model1 loss : 0.320686 model2 loss : 0.331364
[22:07:43.945] iteration 4199 : model1 loss : 0.305209 model2 loss : 0.276420
[22:07:44.284] iteration 4200 : model1 loss : 0.295275 model2 loss : 0.331469
[22:07:44.954] iteration 4201 : model1 loss : 0.234661 model2 loss : 0.246786
[22:07:45.292] iteration 4202 : model1 loss : 0.288373 model2 loss : 0.216742
[22:07:45.630] iteration 4203 : model1 loss : 0.270949 model2 loss : 0.247706
[22:07:45.968] iteration 4204 : model1 loss : 0.247745 model2 loss : 0.281922
[22:07:46.307] iteration 4205 : model1 loss : 0.252922 model2 loss : 0.250971
[22:07:46.646] iteration 4206 : model1 loss : 0.245022 model2 loss : 0.216753
[22:07:46.987] iteration 4207 : model1 loss : 0.217556 model2 loss : 0.218514
[22:07:47.326] iteration 4208 : model1 loss : 0.283072 model2 loss : 0.282789
[22:07:47.663] iteration 4209 : model1 loss : 0.319074 model2 loss : 0.387885
[22:07:48.001] iteration 4210 : model1 loss : 0.349945 model2 loss : 0.311071
[22:07:48.339] iteration 4211 : model1 loss : 0.272208 model2 loss : 0.245037
[22:07:48.680] iteration 4212 : model1 loss : 0.218275 model2 loss : 0.246706
[22:07:49.020] iteration 4213 : model1 loss : 0.252824 model2 loss : 0.226617
[22:07:49.358] iteration 4214 : model1 loss : 0.303860 model2 loss : 0.340396
[22:07:49.696] iteration 4215 : model1 loss : 0.315755 model2 loss : 0.341818
[22:07:50.037] iteration 4216 : model1 loss : 0.292908 model2 loss : 0.298320
[22:07:50.378] iteration 4217 : model1 loss : 0.366273 model2 loss : 0.260571
[22:07:50.719] iteration 4218 : model1 loss : 0.271881 model2 loss : 0.280761
[22:07:51.056] iteration 4219 : model1 loss : 0.333471 model2 loss : 0.311759
[22:07:51.393] iteration 4220 : model1 loss : 0.232187 model2 loss : 0.314236
[22:07:51.731] iteration 4221 : model1 loss : 0.282069 model2 loss : 0.287955
[22:07:52.068] iteration 4222 : model1 loss : 0.365442 model2 loss : 0.319612
[22:07:52.404] iteration 4223 : model1 loss : 0.389389 model2 loss : 0.386377
[22:07:52.744] iteration 4224 : model1 loss : 0.301508 model2 loss : 0.283052
[22:07:53.080] iteration 4225 : model1 loss : 0.243810 model2 loss : 0.266236
[22:07:53.418] iteration 4226 : model1 loss : 0.289774 model2 loss : 0.308839
[22:07:53.756] iteration 4227 : model1 loss : 0.331297 model2 loss : 0.375398
[22:07:54.093] iteration 4228 : model1 loss : 0.210404 model2 loss : 0.208447
[22:07:54.431] iteration 4229 : model1 loss : 0.272655 model2 loss : 0.290329
[22:07:54.768] iteration 4230 : model1 loss : 0.357363 model2 loss : 0.346666
[22:07:55.107] iteration 4231 : model1 loss : 0.225111 model2 loss : 0.236148
[22:07:55.447] iteration 4232 : model1 loss : 0.236258 model2 loss : 0.220496
[22:07:55.785] iteration 4233 : model1 loss : 0.161444 model2 loss : 0.156197
[22:07:56.124] iteration 4234 : model1 loss : 0.204648 model2 loss : 0.182314
[22:07:56.463] iteration 4235 : model1 loss : 0.316686 model2 loss : 0.302224
[22:07:56.801] iteration 4236 : model1 loss : 0.317770 model2 loss : 0.294891
[22:07:57.139] iteration 4237 : model1 loss : 0.196446 model2 loss : 0.202159
[22:07:57.477] iteration 4238 : model1 loss : 0.349724 model2 loss : 0.341576
[22:07:57.815] iteration 4239 : model1 loss : 0.323588 model2 loss : 0.298988
[22:07:58.152] iteration 4240 : model1 loss : 0.289904 model2 loss : 0.316245
[22:07:58.490] iteration 4241 : model1 loss : 0.372884 model2 loss : 0.325093
[22:07:58.828] iteration 4242 : model1 loss : 0.308715 model2 loss : 0.304382
[22:07:59.168] iteration 4243 : model1 loss : 0.290351 model2 loss : 0.278921
[22:07:59.506] iteration 4244 : model1 loss : 0.269582 model2 loss : 0.212980
[22:07:59.844] iteration 4245 : model1 loss : 0.302108 model2 loss : 0.308910
[22:08:00.181] iteration 4246 : model1 loss : 0.288705 model2 loss : 0.341371
[22:08:00.521] iteration 4247 : model1 loss : 0.240491 model2 loss : 0.296845
[22:08:00.859] iteration 4248 : model1 loss : 0.376631 model2 loss : 0.285604
[22:08:01.196] iteration 4249 : model1 loss : 0.181272 model2 loss : 0.160212
[22:08:01.535] iteration 4250 : model1 loss : 0.316626 model2 loss : 0.213475
[22:08:02.212] iteration 4251 : model1 loss : 0.169098 model2 loss : 0.197730
[22:08:02.551] iteration 4252 : model1 loss : 0.222674 model2 loss : 0.157760
[22:08:02.889] iteration 4253 : model1 loss : 0.276792 model2 loss : 0.277545
[22:08:03.227] iteration 4254 : model1 loss : 0.310469 model2 loss : 0.294289
[22:08:03.566] iteration 4255 : model1 loss : 0.295020 model2 loss : 0.295855
[22:08:03.904] iteration 4256 : model1 loss : 0.305758 model2 loss : 0.357181
[22:08:04.242] iteration 4257 : model1 loss : 0.336303 model2 loss : 0.304361
[22:08:04.582] iteration 4258 : model1 loss : 0.440560 model2 loss : 0.356927
[22:08:04.920] iteration 4259 : model1 loss : 0.242354 model2 loss : 0.228597
[22:08:05.259] iteration 4260 : model1 loss : 0.232155 model2 loss : 0.310649
[22:08:05.598] iteration 4261 : model1 loss : 0.279188 model2 loss : 0.348679
[22:08:05.936] iteration 4262 : model1 loss : 0.280961 model2 loss : 0.321699
[22:08:06.275] iteration 4263 : model1 loss : 0.253489 model2 loss : 0.324754
[22:08:06.613] iteration 4264 : model1 loss : 0.318549 model2 loss : 0.233989
[22:08:06.951] iteration 4265 : model1 loss : 0.387738 model2 loss : 0.387350
[22:08:07.289] iteration 4266 : model1 loss : 0.268075 model2 loss : 0.234833
[22:08:07.626] iteration 4267 : model1 loss : 0.270998 model2 loss : 0.328675
[22:08:07.964] iteration 4268 : model1 loss : 0.230994 model2 loss : 0.216123
[22:08:08.302] iteration 4269 : model1 loss : 0.391265 model2 loss : 0.333387
[22:08:08.641] iteration 4270 : model1 loss : 0.244814 model2 loss : 0.306345
[22:08:08.979] iteration 4271 : model1 loss : 0.345348 model2 loss : 0.299368
[22:08:09.319] iteration 4272 : model1 loss : 0.497228 model2 loss : 0.472450
[22:08:09.657] iteration 4273 : model1 loss : 0.273248 model2 loss : 0.225506
[22:08:09.996] iteration 4274 : model1 loss : 0.290583 model2 loss : 0.256034
[22:08:10.336] iteration 4275 : model1 loss : 0.434680 model2 loss : 0.345672
[22:08:10.674] iteration 4276 : model1 loss : 0.299874 model2 loss : 0.247651
[22:08:11.012] iteration 4277 : model1 loss : 0.195491 model2 loss : 0.285481
[22:08:11.358] iteration 4278 : model1 loss : 0.299327 model2 loss : 0.233329
[22:08:11.696] iteration 4279 : model1 loss : 0.228943 model2 loss : 0.228051
[22:08:12.035] iteration 4280 : model1 loss : 0.326233 model2 loss : 0.301852
[22:08:12.373] iteration 4281 : model1 loss : 0.305552 model2 loss : 0.324543
[22:08:12.714] iteration 4282 : model1 loss : 0.303254 model2 loss : 0.328283
[22:08:13.053] iteration 4283 : model1 loss : 0.386750 model2 loss : 0.421632
[22:08:13.391] iteration 4284 : model1 loss : 0.294396 model2 loss : 0.265365
[22:08:13.730] iteration 4285 : model1 loss : 0.381213 model2 loss : 0.272847
[22:08:14.069] iteration 4286 : model1 loss : 0.372296 model2 loss : 0.275851
[22:08:14.406] iteration 4287 : model1 loss : 0.274976 model2 loss : 0.273975
[22:08:14.744] iteration 4288 : model1 loss : 0.328958 model2 loss : 0.341296
[22:08:15.082] iteration 4289 : model1 loss : 0.393125 model2 loss : 0.383256
[22:08:15.420] iteration 4290 : model1 loss : 0.308709 model2 loss : 0.283061
[22:08:15.758] iteration 4291 : model1 loss : 0.372444 model2 loss : 0.313003
[22:08:16.096] iteration 4292 : model1 loss : 0.328034 model2 loss : 0.229546
[22:08:16.434] iteration 4293 : model1 loss : 0.269450 model2 loss : 0.178203
[22:08:16.772] iteration 4294 : model1 loss : 0.341677 model2 loss : 0.295278
[22:08:17.110] iteration 4295 : model1 loss : 0.344182 model2 loss : 0.320959
[22:08:17.448] iteration 4296 : model1 loss : 0.224662 model2 loss : 0.210908
[22:08:17.785] iteration 4297 : model1 loss : 0.345760 model2 loss : 0.323717
[22:08:18.122] iteration 4298 : model1 loss : 0.373981 model2 loss : 0.334829
[22:08:18.459] iteration 4299 : model1 loss : 0.324681 model2 loss : 0.308564
[22:08:18.798] iteration 4300 : model1 loss : 0.385279 model2 loss : 0.339779
[22:08:19.433] iteration 4301 : model1 loss : 0.297315 model2 loss : 0.263493
[22:08:19.774] iteration 4302 : model1 loss : 0.383701 model2 loss : 0.399847
[22:08:20.112] iteration 4303 : model1 loss : 0.321942 model2 loss : 0.315430
[22:08:20.450] iteration 4304 : model1 loss : 0.284519 model2 loss : 0.312490
[22:08:20.787] iteration 4305 : model1 loss : 0.344462 model2 loss : 0.323914
[22:08:21.124] iteration 4306 : model1 loss : 0.429974 model2 loss : 0.373128
[22:08:21.463] iteration 4307 : model1 loss : 0.345116 model2 loss : 0.334169
[22:08:21.800] iteration 4308 : model1 loss : 0.285622 model2 loss : 0.252290
[22:08:22.137] iteration 4309 : model1 loss : 0.341640 model2 loss : 0.286779
[22:08:22.475] iteration 4310 : model1 loss : 0.214695 model2 loss : 0.228600
[22:08:22.813] iteration 4311 : model1 loss : 0.242319 model2 loss : 0.257323
[22:08:23.149] iteration 4312 : model1 loss : 0.229579 model2 loss : 0.217340
[22:08:23.487] iteration 4313 : model1 loss : 0.272059 model2 loss : 0.316034
[22:08:23.824] iteration 4314 : model1 loss : 0.311490 model2 loss : 0.248067
[22:08:24.161] iteration 4315 : model1 loss : 0.312266 model2 loss : 0.321567
[22:08:24.499] iteration 4316 : model1 loss : 0.359628 model2 loss : 0.388811
[22:08:24.836] iteration 4317 : model1 loss : 0.324595 model2 loss : 0.321249
[22:08:25.174] iteration 4318 : model1 loss : 0.304926 model2 loss : 0.277892
[22:08:25.512] iteration 4319 : model1 loss : 0.297707 model2 loss : 0.270826
[22:08:25.851] iteration 4320 : model1 loss : 0.220869 model2 loss : 0.188495
[22:08:26.190] iteration 4321 : model1 loss : 0.202509 model2 loss : 0.207619
[22:08:26.528] iteration 4322 : model1 loss : 0.234513 model2 loss : 0.282078
[22:08:26.867] iteration 4323 : model1 loss : 0.172740 model2 loss : 0.180270
[22:08:27.205] iteration 4324 : model1 loss : 0.259527 model2 loss : 0.202169
[22:08:27.544] iteration 4325 : model1 loss : 0.252903 model2 loss : 0.275591
[22:08:27.883] iteration 4326 : model1 loss : 0.306252 model2 loss : 0.304856
[22:08:28.220] iteration 4327 : model1 loss : 0.325426 model2 loss : 0.330988
[22:08:28.557] iteration 4328 : model1 loss : 0.154318 model2 loss : 0.143872
[22:08:28.893] iteration 4329 : model1 loss : 0.343971 model2 loss : 0.334782
[22:08:29.229] iteration 4330 : model1 loss : 0.310386 model2 loss : 0.254550
[22:08:29.565] iteration 4331 : model1 loss : 0.331772 model2 loss : 0.292567
[22:08:29.904] iteration 4332 : model1 loss : 0.308312 model2 loss : 0.339043
[22:08:30.242] iteration 4333 : model1 loss : 0.304284 model2 loss : 0.255308
[22:08:30.578] iteration 4334 : model1 loss : 0.290196 model2 loss : 0.307433
[22:08:30.915] iteration 4335 : model1 loss : 0.197452 model2 loss : 0.161871
[22:08:31.257] iteration 4336 : model1 loss : 0.231150 model2 loss : 0.228923
[22:08:31.594] iteration 4337 : model1 loss : 0.355707 model2 loss : 0.336467
[22:08:31.932] iteration 4338 : model1 loss : 0.286884 model2 loss : 0.261869
[22:08:32.269] iteration 4339 : model1 loss : 0.173533 model2 loss : 0.145659
[22:08:32.605] iteration 4340 : model1 loss : 0.292374 model2 loss : 0.170076
[22:08:32.947] iteration 4341 : model1 loss : 0.333829 model2 loss : 0.326024
[22:08:33.284] iteration 4342 : model1 loss : 0.253164 model2 loss : 0.224738
[22:08:33.622] iteration 4343 : model1 loss : 0.331885 model2 loss : 0.319620
[22:08:33.959] iteration 4344 : model1 loss : 0.321498 model2 loss : 0.334436
[22:08:34.297] iteration 4345 : model1 loss : 0.269387 model2 loss : 0.218644
[22:08:34.637] iteration 4346 : model1 loss : 0.352383 model2 loss : 0.328152
[22:08:34.975] iteration 4347 : model1 loss : 0.295474 model2 loss : 0.234447
[22:08:35.313] iteration 4348 : model1 loss : 0.226959 model2 loss : 0.204854
[22:08:35.650] iteration 4349 : model1 loss : 0.340586 model2 loss : 0.317628
[22:08:35.990] iteration 4350 : model1 loss : 0.310787 model2 loss : 0.292812
[22:08:36.637] iteration 4351 : model1 loss : 0.295979 model2 loss : 0.256764
[22:08:36.975] iteration 4352 : model1 loss : 0.308746 model2 loss : 0.323561
[22:08:37.314] iteration 4353 : model1 loss : 0.216196 model2 loss : 0.193524
[22:08:37.645] iteration 4354 : model1 loss : 0.341929 model2 loss : 0.305081
[22:08:37.971] iteration 4355 : model1 loss : 0.348683 model2 loss : 0.303882
[22:08:38.298] iteration 4356 : model1 loss : 0.272870 model2 loss : 0.302843
[22:08:38.624] iteration 4357 : model1 loss : 0.319207 model2 loss : 0.302890
[22:08:38.951] iteration 4358 : model1 loss : 0.265643 model2 loss : 0.238979
[22:08:39.275] iteration 4359 : model1 loss : 0.315047 model2 loss : 0.323024
[22:08:39.602] iteration 4360 : model1 loss : 0.280918 model2 loss : 0.222130
[22:08:40.654] iteration 4361 : model1 loss : 0.392374 model2 loss : 0.415527
[22:08:40.994] iteration 4362 : model1 loss : 0.202265 model2 loss : 0.251941
[22:08:41.337] iteration 4363 : model1 loss : 0.208641 model2 loss : 0.210301
[22:08:41.674] iteration 4364 : model1 loss : 0.401934 model2 loss : 0.341141
[22:08:42.013] iteration 4365 : model1 loss : 0.122697 model2 loss : 0.178110
[22:08:42.349] iteration 4366 : model1 loss : 0.285596 model2 loss : 0.265673
[22:08:42.684] iteration 4367 : model1 loss : 0.338814 model2 loss : 0.352895
[22:08:43.018] iteration 4368 : model1 loss : 0.324235 model2 loss : 0.378198
[22:08:43.356] iteration 4369 : model1 loss : 0.327755 model2 loss : 0.344731
[22:08:43.692] iteration 4370 : model1 loss : 0.236447 model2 loss : 0.276202
[22:08:44.029] iteration 4371 : model1 loss : 0.319596 model2 loss : 0.332398
[22:08:44.358] iteration 4372 : model1 loss : 0.311945 model2 loss : 0.338637
[22:08:44.686] iteration 4373 : model1 loss : 0.322784 model2 loss : 0.288788
[22:08:45.014] iteration 4374 : model1 loss : 0.363791 model2 loss : 0.401950
[22:08:45.342] iteration 4375 : model1 loss : 0.301851 model2 loss : 0.291384
[22:08:45.670] iteration 4376 : model1 loss : 0.276417 model2 loss : 0.230370
[22:08:45.998] iteration 4377 : model1 loss : 0.248074 model2 loss : 0.240291
[22:08:46.326] iteration 4378 : model1 loss : 0.254856 model2 loss : 0.326148
[22:08:46.653] iteration 4379 : model1 loss : 0.270940 model2 loss : 0.227329
[22:08:46.980] iteration 4380 : model1 loss : 0.264934 model2 loss : 0.294406
[22:08:47.308] iteration 4381 : model1 loss : 0.241629 model2 loss : 0.199177
[22:08:47.636] iteration 4382 : model1 loss : 0.222422 model2 loss : 0.207924
[22:08:47.964] iteration 4383 : model1 loss : 0.295109 model2 loss : 0.293626
[22:08:48.293] iteration 4384 : model1 loss : 0.317474 model2 loss : 0.248048
[22:08:48.621] iteration 4385 : model1 loss : 0.202496 model2 loss : 0.164667
[22:08:48.948] iteration 4386 : model1 loss : 0.323688 model2 loss : 0.376201
[22:08:49.276] iteration 4387 : model1 loss : 0.258087 model2 loss : 0.166934
[22:08:49.604] iteration 4388 : model1 loss : 0.233685 model2 loss : 0.218689
[22:08:49.932] iteration 4389 : model1 loss : 0.234557 model2 loss : 0.322119
[22:08:50.259] iteration 4390 : model1 loss : 0.312890 model2 loss : 0.290655
[22:08:50.586] iteration 4391 : model1 loss : 0.258498 model2 loss : 0.219080
[22:08:50.913] iteration 4392 : model1 loss : 0.206162 model2 loss : 0.226323
[22:08:51.240] iteration 4393 : model1 loss : 0.333389 model2 loss : 0.297362
[22:08:51.569] iteration 4394 : model1 loss : 0.285631 model2 loss : 0.274059
[22:08:51.897] iteration 4395 : model1 loss : 0.242547 model2 loss : 0.230158
[22:08:52.224] iteration 4396 : model1 loss : 0.331052 model2 loss : 0.297360
[22:08:52.551] iteration 4397 : model1 loss : 0.307255 model2 loss : 0.304466
[22:08:52.878] iteration 4398 : model1 loss : 0.345321 model2 loss : 0.303164
[22:08:53.206] iteration 4399 : model1 loss : 0.376204 model2 loss : 0.356005
[22:08:53.533] iteration 4400 : model1 loss : 0.243011 model2 loss : 0.289212
[22:08:54.082] iteration 4401 : model1 loss : 0.251938 model2 loss : 0.221541
[22:08:54.409] iteration 4402 : model1 loss : 0.334544 model2 loss : 0.264781
[22:08:54.737] iteration 4403 : model1 loss : 0.220689 model2 loss : 0.219262
[22:08:55.065] iteration 4404 : model1 loss : 0.305652 model2 loss : 0.268688
[22:08:55.392] iteration 4405 : model1 loss : 0.399601 model2 loss : 0.324384
[22:08:55.722] iteration 4406 : model1 loss : 0.278891 model2 loss : 0.265618
[22:08:56.050] iteration 4407 : model1 loss : 0.290087 model2 loss : 0.269214
[22:08:56.378] iteration 4408 : model1 loss : 0.273827 model2 loss : 0.314408
[22:08:56.706] iteration 4409 : model1 loss : 0.289642 model2 loss : 0.246504
[22:08:57.033] iteration 4410 : model1 loss : 0.377791 model2 loss : 0.297295
[22:08:57.361] iteration 4411 : model1 loss : 0.381586 model2 loss : 0.289636
[22:08:57.691] iteration 4412 : model1 loss : 0.279133 model2 loss : 0.217755
[22:08:58.018] iteration 4413 : model1 loss : 0.271006 model2 loss : 0.254685
[22:08:58.342] iteration 4414 : model1 loss : 0.240526 model2 loss : 0.204961
[22:08:58.669] iteration 4415 : model1 loss : 0.266584 model2 loss : 0.264372
[22:08:58.996] iteration 4416 : model1 loss : 0.239175 model2 loss : 0.241884
[22:08:59.326] iteration 4417 : model1 loss : 0.332636 model2 loss : 0.320558
[22:08:59.654] iteration 4418 : model1 loss : 0.251388 model2 loss : 0.213912
[22:08:59.979] iteration 4419 : model1 loss : 0.288334 model2 loss : 0.280111
[22:09:00.306] iteration 4420 : model1 loss : 0.305436 model2 loss : 0.306337
[22:09:00.633] iteration 4421 : model1 loss : 0.404880 model2 loss : 0.339523
[22:09:00.957] iteration 4422 : model1 loss : 0.343017 model2 loss : 0.360065
[22:09:01.285] iteration 4423 : model1 loss : 0.312780 model2 loss : 0.326091
[22:09:01.612] iteration 4424 : model1 loss : 0.345841 model2 loss : 0.325836
[22:09:01.940] iteration 4425 : model1 loss : 0.359513 model2 loss : 0.341049
[22:09:02.267] iteration 4426 : model1 loss : 0.391586 model2 loss : 0.282075
[22:09:02.595] iteration 4427 : model1 loss : 0.323974 model2 loss : 0.283127
[22:09:02.922] iteration 4428 : model1 loss : 0.151978 model2 loss : 0.176084
[22:09:03.249] iteration 4429 : model1 loss : 0.245138 model2 loss : 0.236861
[22:09:03.577] iteration 4430 : model1 loss : 0.261182 model2 loss : 0.296014
[22:09:03.906] iteration 4431 : model1 loss : 0.238107 model2 loss : 0.276632
[22:09:04.234] iteration 4432 : model1 loss : 0.330100 model2 loss : 0.350735
[22:09:04.557] iteration 4433 : model1 loss : 0.203198 model2 loss : 0.220910
[22:09:04.895] iteration 4434 : model1 loss : 0.301844 model2 loss : 0.269422
[22:09:05.231] iteration 4435 : model1 loss : 0.283052 model2 loss : 0.269652
[22:09:05.568] iteration 4436 : model1 loss : 0.230137 model2 loss : 0.337275
[22:09:05.906] iteration 4437 : model1 loss : 0.318421 model2 loss : 0.320427
[22:09:06.239] iteration 4438 : model1 loss : 0.436252 model2 loss : 0.431226
[22:09:06.573] iteration 4439 : model1 loss : 0.329111 model2 loss : 0.249226
[22:09:06.907] iteration 4440 : model1 loss : 0.354835 model2 loss : 0.372167
[22:09:07.237] iteration 4441 : model1 loss : 0.318078 model2 loss : 0.284137
[22:09:07.570] iteration 4442 : model1 loss : 0.351973 model2 loss : 0.353028
[22:09:07.903] iteration 4443 : model1 loss : 0.338898 model2 loss : 0.336151
[22:09:08.236] iteration 4444 : model1 loss : 0.274044 model2 loss : 0.253479
[22:09:08.573] iteration 4445 : model1 loss : 0.238347 model2 loss : 0.199933
[22:09:08.910] iteration 4446 : model1 loss : 0.308908 model2 loss : 0.337165
[22:09:09.246] iteration 4447 : model1 loss : 0.331153 model2 loss : 0.238363
[22:09:09.581] iteration 4448 : model1 loss : 0.347056 model2 loss : 0.340396
[22:09:09.920] iteration 4449 : model1 loss : 0.218007 model2 loss : 0.268138
[22:09:10.254] iteration 4450 : model1 loss : 0.321558 model2 loss : 0.322300
[22:09:10.922] iteration 4451 : model1 loss : 0.307820 model2 loss : 0.299320
[22:09:11.259] iteration 4452 : model1 loss : 0.338220 model2 loss : 0.341761
[22:09:11.598] iteration 4453 : model1 loss : 0.168597 model2 loss : 0.141811
[22:09:11.934] iteration 4454 : model1 loss : 0.228518 model2 loss : 0.216152
[22:09:12.267] iteration 4455 : model1 loss : 0.331275 model2 loss : 0.291660
[22:09:12.600] iteration 4456 : model1 loss : 0.323417 model2 loss : 0.306570
[22:09:12.938] iteration 4457 : model1 loss : 0.277273 model2 loss : 0.285151
[22:09:13.279] iteration 4458 : model1 loss : 0.232570 model2 loss : 0.270279
[22:09:13.617] iteration 4459 : model1 loss : 0.325536 model2 loss : 0.336685
[22:09:13.955] iteration 4460 : model1 loss : 0.285259 model2 loss : 0.295387
[22:09:14.294] iteration 4461 : model1 loss : 0.277993 model2 loss : 0.266554
[22:09:14.630] iteration 4462 : model1 loss : 0.359520 model2 loss : 0.331798
[22:09:14.963] iteration 4463 : model1 loss : 0.337630 model2 loss : 0.369539
[22:09:15.301] iteration 4464 : model1 loss : 0.388962 model2 loss : 0.359112
[22:09:15.638] iteration 4465 : model1 loss : 0.316741 model2 loss : 0.279670
[22:09:15.981] iteration 4466 : model1 loss : 0.301318 model2 loss : 0.226697
[22:09:16.324] iteration 4467 : model1 loss : 0.326891 model2 loss : 0.325090
[22:09:16.661] iteration 4468 : model1 loss : 0.325367 model2 loss : 0.293503
[22:09:16.994] iteration 4469 : model1 loss : 0.260399 model2 loss : 0.230529
[22:09:17.332] iteration 4470 : model1 loss : 0.258689 model2 loss : 0.255210
[22:09:17.669] iteration 4471 : model1 loss : 0.193725 model2 loss : 0.216872
[22:09:18.007] iteration 4472 : model1 loss : 0.264889 model2 loss : 0.261636
[22:09:18.345] iteration 4473 : model1 loss : 0.280638 model2 loss : 0.253069
[22:09:18.680] iteration 4474 : model1 loss : 0.290189 model2 loss : 0.277148
[22:09:19.016] iteration 4475 : model1 loss : 0.250978 model2 loss : 0.265063
[22:09:19.354] iteration 4476 : model1 loss : 0.239686 model2 loss : 0.287921
[22:09:19.691] iteration 4477 : model1 loss : 0.270725 model2 loss : 0.270952
[22:09:20.025] iteration 4478 : model1 loss : 0.243644 model2 loss : 0.216669
[22:09:20.363] iteration 4479 : model1 loss : 0.299030 model2 loss : 0.294184
[22:09:20.700] iteration 4480 : model1 loss : 0.315362 model2 loss : 0.330213
[22:09:21.035] iteration 4481 : model1 loss : 0.283741 model2 loss : 0.295391
[22:09:21.374] iteration 4482 : model1 loss : 0.348283 model2 loss : 0.273595
[22:09:21.713] iteration 4483 : model1 loss : 0.396555 model2 loss : 0.305326
[22:09:22.053] iteration 4484 : model1 loss : 0.243941 model2 loss : 0.265514
[22:09:22.386] iteration 4485 : model1 loss : 0.260623 model2 loss : 0.333760
[22:09:22.719] iteration 4486 : model1 loss : 0.222071 model2 loss : 0.219781
[22:09:23.050] iteration 4487 : model1 loss : 0.262278 model2 loss : 0.238404
[22:09:23.380] iteration 4488 : model1 loss : 0.198052 model2 loss : 0.163751
[22:09:23.709] iteration 4489 : model1 loss : 0.328259 model2 loss : 0.320274
[22:09:24.037] iteration 4490 : model1 loss : 0.237189 model2 loss : 0.225189
[22:09:24.374] iteration 4491 : model1 loss : 0.180634 model2 loss : 0.229875
[22:09:24.712] iteration 4492 : model1 loss : 0.373906 model2 loss : 0.365582
[22:09:25.071] iteration 4493 : model1 loss : 0.259855 model2 loss : 0.227121
[22:09:25.410] iteration 4494 : model1 loss : 0.323238 model2 loss : 0.295602
[22:09:25.748] iteration 4495 : model1 loss : 0.248556 model2 loss : 0.314462
[22:09:26.086] iteration 4496 : model1 loss : 0.365110 model2 loss : 0.367691
[22:09:26.424] iteration 4497 : model1 loss : 0.328436 model2 loss : 0.337185
[22:09:26.762] iteration 4498 : model1 loss : 0.329265 model2 loss : 0.357319
[22:09:27.098] iteration 4499 : model1 loss : 0.314132 model2 loss : 0.313737
[22:09:27.435] iteration 4500 : model1 loss : 0.277193 model2 loss : 0.287392
[22:09:28.121] iteration 4501 : model1 loss : 0.341150 model2 loss : 0.330404
[22:09:28.459] iteration 4502 : model1 loss : 0.241386 model2 loss : 0.192205
[22:09:28.796] iteration 4503 : model1 loss : 0.294080 model2 loss : 0.256082
[22:09:29.134] iteration 4504 : model1 loss : 0.301642 model2 loss : 0.323516
[22:09:29.470] iteration 4505 : model1 loss : 0.252752 model2 loss : 0.249829
[22:09:29.804] iteration 4506 : model1 loss : 0.243737 model2 loss : 0.306748
[22:09:30.138] iteration 4507 : model1 loss : 0.331560 model2 loss : 0.359781
[22:09:30.472] iteration 4508 : model1 loss : 0.212642 model2 loss : 0.276430
[22:09:30.808] iteration 4509 : model1 loss : 0.271094 model2 loss : 0.290343
[22:09:31.148] iteration 4510 : model1 loss : 0.315137 model2 loss : 0.240538
[22:09:31.476] iteration 4511 : model1 loss : 0.228104 model2 loss : 0.183725
[22:09:31.806] iteration 4512 : model1 loss : 0.206572 model2 loss : 0.229774
[22:09:32.136] iteration 4513 : model1 loss : 0.262333 model2 loss : 0.251618
[22:09:32.475] iteration 4514 : model1 loss : 0.298506 model2 loss : 0.288561
[22:09:32.804] iteration 4515 : model1 loss : 0.299731 model2 loss : 0.372572
[22:09:33.135] iteration 4516 : model1 loss : 0.307007 model2 loss : 0.261048
[22:09:33.468] iteration 4517 : model1 loss : 0.223104 model2 loss : 0.271002
[22:09:33.812] iteration 4518 : model1 loss : 0.217684 model2 loss : 0.247914
[22:09:34.151] iteration 4519 : model1 loss : 0.346565 model2 loss : 0.284028
[22:09:34.489] iteration 4520 : model1 loss : 0.254078 model2 loss : 0.265286
[22:09:34.826] iteration 4521 : model1 loss : 0.318997 model2 loss : 0.319175
[22:09:35.163] iteration 4522 : model1 loss : 0.212222 model2 loss : 0.260646
[22:09:35.500] iteration 4523 : model1 loss : 0.351664 model2 loss : 0.346544
[22:09:35.839] iteration 4524 : model1 loss : 0.341101 model2 loss : 0.332124
[22:09:36.176] iteration 4525 : model1 loss : 0.298696 model2 loss : 0.304650
[22:09:36.514] iteration 4526 : model1 loss : 0.245686 model2 loss : 0.315470
[22:09:36.852] iteration 4527 : model1 loss : 0.278158 model2 loss : 0.278413
[22:09:37.187] iteration 4528 : model1 loss : 0.285230 model2 loss : 0.286991
[22:09:37.523] iteration 4529 : model1 loss : 0.316066 model2 loss : 0.342761
[22:09:37.861] iteration 4530 : model1 loss : 0.337364 model2 loss : 0.319595
[22:09:38.198] iteration 4531 : model1 loss : 0.250030 model2 loss : 0.252663
[22:09:38.542] iteration 4532 : model1 loss : 0.257714 model2 loss : 0.263617
[22:09:38.882] iteration 4533 : model1 loss : 0.298862 model2 loss : 0.343615
[22:09:39.218] iteration 4534 : model1 loss : 0.283706 model2 loss : 0.306748
[22:09:39.555] iteration 4535 : model1 loss : 0.263074 model2 loss : 0.245478
[22:09:39.893] iteration 4536 : model1 loss : 0.348541 model2 loss : 0.349566
[22:09:40.228] iteration 4537 : model1 loss : 0.227744 model2 loss : 0.272926
[22:09:40.563] iteration 4538 : model1 loss : 0.198455 model2 loss : 0.266034
[22:09:40.892] iteration 4539 : model1 loss : 0.221934 model2 loss : 0.222795
[22:09:41.225] iteration 4540 : model1 loss : 0.343102 model2 loss : 0.330679
[22:09:41.554] iteration 4541 : model1 loss : 0.273263 model2 loss : 0.283701
[22:09:41.882] iteration 4542 : model1 loss : 0.250740 model2 loss : 0.226930
[22:09:42.213] iteration 4543 : model1 loss : 0.359042 model2 loss : 0.332643
[22:09:42.543] iteration 4544 : model1 loss : 0.203738 model2 loss : 0.216261
[22:09:42.875] iteration 4545 : model1 loss : 0.324699 model2 loss : 0.291003
[22:09:43.205] iteration 4546 : model1 loss : 0.311467 model2 loss : 0.293831
[22:09:43.533] iteration 4547 : model1 loss : 0.309120 model2 loss : 0.347328
[22:09:43.862] iteration 4548 : model1 loss : 0.210565 model2 loss : 0.260716
[22:09:44.191] iteration 4549 : model1 loss : 0.288894 model2 loss : 0.237513
[22:09:44.519] iteration 4550 : model1 loss : 0.272128 model2 loss : 0.310520
[22:09:45.046] iteration 4551 : model1 loss : 0.366802 model2 loss : 0.281643
[22:09:45.376] iteration 4552 : model1 loss : 0.232543 model2 loss : 0.210490
[22:09:45.705] iteration 4553 : model1 loss : 0.335920 model2 loss : 0.299586
[22:09:46.035] iteration 4554 : model1 loss : 0.212867 model2 loss : 0.195671
[22:09:46.375] iteration 4555 : model1 loss : 0.249652 model2 loss : 0.238780
[22:09:46.712] iteration 4556 : model1 loss : 0.434843 model2 loss : 0.415545
[22:09:47.051] iteration 4557 : model1 loss : 0.384448 model2 loss : 0.371317
[22:09:47.392] iteration 4558 : model1 loss : 0.422220 model2 loss : 0.335638
[22:09:47.729] iteration 4559 : model1 loss : 0.376467 model2 loss : 0.368022
[22:09:48.067] iteration 4560 : model1 loss : 0.398270 model2 loss : 0.448776
[22:09:48.411] iteration 4561 : model1 loss : 0.199038 model2 loss : 0.182411
[22:09:48.748] iteration 4562 : model1 loss : 0.223652 model2 loss : 0.211588
[22:09:49.087] iteration 4563 : model1 loss : 0.206300 model2 loss : 0.199523
[22:09:49.425] iteration 4564 : model1 loss : 0.317695 model2 loss : 0.349150
[22:09:49.764] iteration 4565 : model1 loss : 0.265538 model2 loss : 0.218211
[22:09:50.101] iteration 4566 : model1 loss : 0.274719 model2 loss : 0.320534
[22:09:50.431] iteration 4567 : model1 loss : 0.358255 model2 loss : 0.366196
[22:09:50.760] iteration 4568 : model1 loss : 0.309838 model2 loss : 0.341820
[22:09:51.089] iteration 4569 : model1 loss : 0.294776 model2 loss : 0.234280
[22:09:51.418] iteration 4570 : model1 loss : 0.311144 model2 loss : 0.237471
[22:09:51.748] iteration 4571 : model1 loss : 0.269175 model2 loss : 0.248455
[22:09:52.077] iteration 4572 : model1 loss : 0.272428 model2 loss : 0.209101
[22:09:52.406] iteration 4573 : model1 loss : 0.335112 model2 loss : 0.348898
[22:09:52.735] iteration 4574 : model1 loss : 0.265188 model2 loss : 0.281940
[22:09:53.064] iteration 4575 : model1 loss : 0.319568 model2 loss : 0.353944
[22:09:53.392] iteration 4576 : model1 loss : 0.287416 model2 loss : 0.263244
[22:09:53.720] iteration 4577 : model1 loss : 0.334154 model2 loss : 0.285949
[22:09:54.046] iteration 4578 : model1 loss : 0.251215 model2 loss : 0.227547
[22:09:54.373] iteration 4579 : model1 loss : 0.262932 model2 loss : 0.251871
[22:09:54.700] iteration 4580 : model1 loss : 0.198043 model2 loss : 0.224032
[22:09:55.027] iteration 4581 : model1 loss : 0.308896 model2 loss : 0.277287
[22:09:55.354] iteration 4582 : model1 loss : 0.257169 model2 loss : 0.252012
[22:09:55.682] iteration 4583 : model1 loss : 0.206423 model2 loss : 0.214945
[22:09:56.009] iteration 4584 : model1 loss : 0.262185 model2 loss : 0.231037
[22:09:56.337] iteration 4585 : model1 loss : 0.208315 model2 loss : 0.217507
[22:09:56.665] iteration 4586 : model1 loss : 0.334306 model2 loss : 0.369449
[22:09:56.992] iteration 4587 : model1 loss : 0.168306 model2 loss : 0.223797
[22:09:57.321] iteration 4588 : model1 loss : 0.222862 model2 loss : 0.217944
[22:09:57.648] iteration 4589 : model1 loss : 0.170440 model2 loss : 0.229672
[22:09:57.975] iteration 4590 : model1 loss : 0.295499 model2 loss : 0.279174
[22:09:58.304] iteration 4591 : model1 loss : 0.357295 model2 loss : 0.377268
[22:09:58.632] iteration 4592 : model1 loss : 0.264618 model2 loss : 0.254455
[22:09:58.960] iteration 4593 : model1 loss : 0.367472 model2 loss : 0.325671
[22:09:59.290] iteration 4594 : model1 loss : 0.334557 model2 loss : 0.338270
[22:09:59.629] iteration 4595 : model1 loss : 0.275370 model2 loss : 0.260411
[22:09:59.961] iteration 4596 : model1 loss : 0.294889 model2 loss : 0.333079
[22:10:00.299] iteration 4597 : model1 loss : 0.294417 model2 loss : 0.272702
[22:10:00.629] iteration 4598 : model1 loss : 0.282931 model2 loss : 0.263900
[22:10:00.963] iteration 4599 : model1 loss : 0.278836 model2 loss : 0.287928
[22:10:01.294] iteration 4600 : model1 loss : 0.386749 model2 loss : 0.307253
[22:10:01.911] iteration 4601 : model1 loss : 0.345982 model2 loss : 0.324061
[22:10:02.240] iteration 4602 : model1 loss : 0.222549 model2 loss : 0.272543
[22:10:02.569] iteration 4603 : model1 loss : 0.255583 model2 loss : 0.278115
[22:10:02.899] iteration 4604 : model1 loss : 0.257773 model2 loss : 0.283646
[22:10:03.240] iteration 4605 : model1 loss : 0.225214 model2 loss : 0.205240
[22:10:03.579] iteration 4606 : model1 loss : 0.343966 model2 loss : 0.377070
[22:10:03.917] iteration 4607 : model1 loss : 0.310122 model2 loss : 0.287305
[22:10:04.260] iteration 4608 : model1 loss : 0.288019 model2 loss : 0.267869
[22:10:04.599] iteration 4609 : model1 loss : 0.162156 model2 loss : 0.176027
[22:10:04.937] iteration 4610 : model1 loss : 0.215772 model2 loss : 0.229147
[22:10:05.280] iteration 4611 : model1 loss : 0.246834 model2 loss : 0.300617
[22:10:05.620] iteration 4612 : model1 loss : 0.295913 model2 loss : 0.296552
[22:10:05.958] iteration 4613 : model1 loss : 0.266120 model2 loss : 0.235830
[22:10:06.296] iteration 4614 : model1 loss : 0.340576 model2 loss : 0.335405
[22:10:06.634] iteration 4615 : model1 loss : 0.306553 model2 loss : 0.316372
[22:10:06.974] iteration 4616 : model1 loss : 0.261646 model2 loss : 0.270070
[22:10:07.313] iteration 4617 : model1 loss : 0.349688 model2 loss : 0.368963
[22:10:07.651] iteration 4618 : model1 loss : 0.409410 model2 loss : 0.384272
[22:10:07.994] iteration 4619 : model1 loss : 0.342601 model2 loss : 0.335042
[22:10:08.338] iteration 4620 : model1 loss : 0.277673 model2 loss : 0.272289
[22:10:08.678] iteration 4621 : model1 loss : 0.191312 model2 loss : 0.162341
[22:10:09.021] iteration 4622 : model1 loss : 0.261798 model2 loss : 0.288398
[22:10:09.360] iteration 4623 : model1 loss : 0.258002 model2 loss : 0.206995
[22:10:09.698] iteration 4624 : model1 loss : 0.290892 model2 loss : 0.252732
[22:10:10.038] iteration 4625 : model1 loss : 0.312273 model2 loss : 0.307468
[22:10:10.381] iteration 4626 : model1 loss : 0.294637 model2 loss : 0.276385
[22:10:10.725] iteration 4627 : model1 loss : 0.370671 model2 loss : 0.357183
[22:10:11.065] iteration 4628 : model1 loss : 0.318849 model2 loss : 0.234616
[22:10:11.403] iteration 4629 : model1 loss : 0.189568 model2 loss : 0.133347
[22:10:11.747] iteration 4630 : model1 loss : 0.271023 model2 loss : 0.260326
[22:10:12.087] iteration 4631 : model1 loss : 0.283000 model2 loss : 0.282956
[22:10:12.427] iteration 4632 : model1 loss : 0.279936 model2 loss : 0.258800
[22:10:12.765] iteration 4633 : model1 loss : 0.254837 model2 loss : 0.291353
[22:10:13.107] iteration 4634 : model1 loss : 0.320205 model2 loss : 0.298823
[22:10:13.443] iteration 4635 : model1 loss : 0.198599 model2 loss : 0.268379
[22:10:13.781] iteration 4636 : model1 loss : 0.317932 model2 loss : 0.271345
[22:10:14.118] iteration 4637 : model1 loss : 0.286737 model2 loss : 0.201066
[22:10:14.457] iteration 4638 : model1 loss : 0.246382 model2 loss : 0.258704
[22:10:14.796] iteration 4639 : model1 loss : 0.236408 model2 loss : 0.232994
[22:10:15.134] iteration 4640 : model1 loss : 0.243940 model2 loss : 0.217967
[22:10:15.476] iteration 4641 : model1 loss : 0.185532 model2 loss : 0.266437
[22:10:15.816] iteration 4642 : model1 loss : 0.267330 model2 loss : 0.196782
[22:10:16.154] iteration 4643 : model1 loss : 0.230768 model2 loss : 0.259516
[22:10:16.494] iteration 4644 : model1 loss : 0.258848 model2 loss : 0.322248
[22:10:16.830] iteration 4645 : model1 loss : 0.284765 model2 loss : 0.324782
[22:10:17.168] iteration 4646 : model1 loss : 0.242253 model2 loss : 0.292171
[22:10:17.506] iteration 4647 : model1 loss : 0.336714 model2 loss : 0.307617
[22:10:17.846] iteration 4648 : model1 loss : 0.255441 model2 loss : 0.268572
[22:10:18.181] iteration 4649 : model1 loss : 0.371935 model2 loss : 0.382382
[22:10:18.519] iteration 4650 : model1 loss : 0.202872 model2 loss : 0.197327
[22:10:19.169] iteration 4651 : model1 loss : 0.350439 model2 loss : 0.350470
[22:10:19.508] iteration 4652 : model1 loss : 0.291720 model2 loss : 0.306659
[22:10:19.846] iteration 4653 : model1 loss : 0.351360 model2 loss : 0.346891
[22:10:20.183] iteration 4654 : model1 loss : 0.307126 model2 loss : 0.316654
[22:10:20.525] iteration 4655 : model1 loss : 0.289030 model2 loss : 0.266900
[22:10:20.864] iteration 4656 : model1 loss : 0.182893 model2 loss : 0.200774
[22:10:21.200] iteration 4657 : model1 loss : 0.290474 model2 loss : 0.303517
[22:10:21.541] iteration 4658 : model1 loss : 0.245618 model2 loss : 0.258110
[22:10:21.879] iteration 4659 : model1 loss : 0.345285 model2 loss : 0.332161
[22:10:22.216] iteration 4660 : model1 loss : 0.329032 model2 loss : 0.327619
[22:10:22.553] iteration 4661 : model1 loss : 0.291650 model2 loss : 0.284788
[22:10:22.890] iteration 4662 : model1 loss : 0.330187 model2 loss : 0.318047
[22:10:23.228] iteration 4663 : model1 loss : 0.319377 model2 loss : 0.304302
[22:10:23.565] iteration 4664 : model1 loss : 0.176304 model2 loss : 0.212945
[22:10:23.902] iteration 4665 : model1 loss : 0.416631 model2 loss : 0.377804
[22:10:24.239] iteration 4666 : model1 loss : 0.216566 model2 loss : 0.213069
[22:10:24.576] iteration 4667 : model1 loss : 0.207045 model2 loss : 0.235647
[22:10:24.913] iteration 4668 : model1 loss : 0.222010 model2 loss : 0.233803
[22:10:25.251] iteration 4669 : model1 loss : 0.312676 model2 loss : 0.236621
[22:10:25.589] iteration 4670 : model1 loss : 0.270828 model2 loss : 0.240912
[22:10:25.926] iteration 4671 : model1 loss : 0.341921 model2 loss : 0.317996
[22:10:26.265] iteration 4672 : model1 loss : 0.204718 model2 loss : 0.229703
[22:10:26.605] iteration 4673 : model1 loss : 0.309924 model2 loss : 0.312645
[22:10:26.943] iteration 4674 : model1 loss : 0.299222 model2 loss : 0.283774
[22:10:27.281] iteration 4675 : model1 loss : 0.150653 model2 loss : 0.153189
[22:10:27.619] iteration 4676 : model1 loss : 0.266768 model2 loss : 0.224542
[22:10:27.956] iteration 4677 : model1 loss : 0.296192 model2 loss : 0.254537
[22:10:28.293] iteration 4678 : model1 loss : 0.251590 model2 loss : 0.259062
[22:10:28.629] iteration 4679 : model1 loss : 0.261447 model2 loss : 0.237301
[22:10:28.966] iteration 4680 : model1 loss : 0.299282 model2 loss : 0.290908
[22:10:29.303] iteration 4681 : model1 loss : 0.207638 model2 loss : 0.253770
[22:10:29.640] iteration 4682 : model1 loss : 0.281813 model2 loss : 0.244794
[22:10:29.979] iteration 4683 : model1 loss : 0.305048 model2 loss : 0.321212
[22:10:30.317] iteration 4684 : model1 loss : 0.250028 model2 loss : 0.182243
[22:10:30.655] iteration 4685 : model1 loss : 0.252786 model2 loss : 0.265250
[22:10:30.994] iteration 4686 : model1 loss : 0.339936 model2 loss : 0.371514
[22:10:31.330] iteration 4687 : model1 loss : 0.245378 model2 loss : 0.245814
[22:10:31.669] iteration 4688 : model1 loss : 0.388691 model2 loss : 0.404705
[22:10:32.008] iteration 4689 : model1 loss : 0.312526 model2 loss : 0.358699
[22:10:32.347] iteration 4690 : model1 loss : 0.318844 model2 loss : 0.299446
[22:10:32.685] iteration 4691 : model1 loss : 0.353214 model2 loss : 0.323867
[22:10:33.022] iteration 4692 : model1 loss : 0.247612 model2 loss : 0.219403
[22:10:33.362] iteration 4693 : model1 loss : 0.304373 model2 loss : 0.358906
[22:10:33.702] iteration 4694 : model1 loss : 0.254765 model2 loss : 0.201693
[22:10:34.039] iteration 4695 : model1 loss : 0.267273 model2 loss : 0.266405
[22:10:34.377] iteration 4696 : model1 loss : 0.305599 model2 loss : 0.318681
[22:10:34.714] iteration 4697 : model1 loss : 0.260470 model2 loss : 0.249607
[22:10:35.047] iteration 4698 : model1 loss : 0.167190 model2 loss : 0.193151
[22:10:35.385] iteration 4699 : model1 loss : 0.227527 model2 loss : 0.302085
[22:10:35.722] iteration 4700 : model1 loss : 0.246770 model2 loss : 0.211710
[22:10:36.401] iteration 4701 : model1 loss : 0.292933 model2 loss : 0.278162
[22:10:36.738] iteration 4702 : model1 loss : 0.338778 model2 loss : 0.320148
[22:10:37.074] iteration 4703 : model1 loss : 0.257418 model2 loss : 0.253202
[22:10:37.411] iteration 4704 : model1 loss : 0.217750 model2 loss : 0.208595
[22:10:37.750] iteration 4705 : model1 loss : 0.218493 model2 loss : 0.202501
[22:10:38.084] iteration 4706 : model1 loss : 0.313383 model2 loss : 0.337558
[22:10:38.422] iteration 4707 : model1 loss : 0.251991 model2 loss : 0.240317
[22:10:38.759] iteration 4708 : model1 loss : 0.419538 model2 loss : 0.389457
[22:10:39.097] iteration 4709 : model1 loss : 0.301795 model2 loss : 0.202774
[22:10:39.434] iteration 4710 : model1 loss : 0.308656 model2 loss : 0.325113
[22:10:39.771] iteration 4711 : model1 loss : 0.278925 model2 loss : 0.228670
[22:10:40.105] iteration 4712 : model1 loss : 0.412934 model2 loss : 0.357238
[22:10:40.446] iteration 4713 : model1 loss : 0.258205 model2 loss : 0.210903
[22:10:40.781] iteration 4714 : model1 loss : 0.300567 model2 loss : 0.344121
[22:10:41.116] iteration 4715 : model1 loss : 0.271950 model2 loss : 0.308214
[22:10:41.454] iteration 4716 : model1 loss : 0.162372 model2 loss : 0.206745
[22:10:41.792] iteration 4717 : model1 loss : 0.329842 model2 loss : 0.300625
[22:10:42.127] iteration 4718 : model1 loss : 0.211645 model2 loss : 0.237785
[22:10:42.465] iteration 4719 : model1 loss : 0.329376 model2 loss : 0.353821
[22:10:42.804] iteration 4720 : model1 loss : 0.293293 model2 loss : 0.241479
[22:10:43.139] iteration 4721 : model1 loss : 0.392030 model2 loss : 0.282403
[22:10:43.477] iteration 4722 : model1 loss : 0.195688 model2 loss : 0.227244
[22:10:43.816] iteration 4723 : model1 loss : 0.340134 model2 loss : 0.331213
[22:10:44.158] iteration 4724 : model1 loss : 0.261387 model2 loss : 0.279118
[22:10:44.497] iteration 4725 : model1 loss : 0.212800 model2 loss : 0.211138
[22:10:44.836] iteration 4726 : model1 loss : 0.338617 model2 loss : 0.357329
[22:10:45.171] iteration 4727 : model1 loss : 0.425611 model2 loss : 0.381598
[22:10:45.510] iteration 4728 : model1 loss : 0.265482 model2 loss : 0.183376
[22:10:45.847] iteration 4729 : model1 loss : 0.360410 model2 loss : 0.269273
[22:10:46.182] iteration 4730 : model1 loss : 0.296755 model2 loss : 0.370889
[22:10:46.521] iteration 4731 : model1 loss : 0.379063 model2 loss : 0.374617
[22:10:46.858] iteration 4732 : model1 loss : 0.265348 model2 loss : 0.232224
[22:10:47.193] iteration 4733 : model1 loss : 0.297297 model2 loss : 0.301566
[22:10:47.532] iteration 4734 : model1 loss : 0.364623 model2 loss : 0.452233
[22:10:47.870] iteration 4735 : model1 loss : 0.337010 model2 loss : 0.199134
[22:10:48.515] iteration 4736 : model1 loss : 0.411642 model2 loss : 0.381513
[22:10:48.855] iteration 4737 : model1 loss : 0.270620 model2 loss : 0.287878
[22:10:49.190] iteration 4738 : model1 loss : 0.313966 model2 loss : 0.270163
[22:10:49.532] iteration 4739 : model1 loss : 0.222601 model2 loss : 0.232308
[22:10:49.869] iteration 4740 : model1 loss : 0.280598 model2 loss : 0.272212
[22:10:50.204] iteration 4741 : model1 loss : 0.292171 model2 loss : 0.245476
[22:10:50.543] iteration 4742 : model1 loss : 0.208804 model2 loss : 0.239006
[22:10:50.882] iteration 4743 : model1 loss : 0.350387 model2 loss : 0.353390
[22:10:51.220] iteration 4744 : model1 loss : 0.388910 model2 loss : 0.348884
[22:10:51.560] iteration 4745 : model1 loss : 0.260913 model2 loss : 0.195549
[22:10:51.901] iteration 4746 : model1 loss : 0.302686 model2 loss : 0.287179
[22:10:52.238] iteration 4747 : model1 loss : 0.390996 model2 loss : 0.425016
[22:10:52.575] iteration 4748 : model1 loss : 0.215410 model2 loss : 0.170341
[22:10:52.912] iteration 4749 : model1 loss : 0.299764 model2 loss : 0.299133
[22:10:53.250] iteration 4750 : model1 loss : 0.281481 model2 loss : 0.267880
[22:10:53.904] iteration 4751 : model1 loss : 0.247656 model2 loss : 0.209525
[22:10:54.242] iteration 4752 : model1 loss : 0.282734 model2 loss : 0.282184
[22:10:54.580] iteration 4753 : model1 loss : 0.283077 model2 loss : 0.271889
[22:10:54.920] iteration 4754 : model1 loss : 0.402293 model2 loss : 0.407282
[22:10:55.262] iteration 4755 : model1 loss : 0.323625 model2 loss : 0.330026
[22:10:55.601] iteration 4756 : model1 loss : 0.304643 model2 loss : 0.312001
[22:10:55.938] iteration 4757 : model1 loss : 0.292250 model2 loss : 0.241838
[22:10:56.277] iteration 4758 : model1 loss : 0.418079 model2 loss : 0.285446
[22:10:56.612] iteration 4759 : model1 loss : 0.285846 model2 loss : 0.230294
[22:10:56.949] iteration 4760 : model1 loss : 0.364540 model2 loss : 0.305941
[22:10:57.288] iteration 4761 : model1 loss : 0.364052 model2 loss : 0.337867
[22:10:57.624] iteration 4762 : model1 loss : 0.323519 model2 loss : 0.300293
[22:10:57.964] iteration 4763 : model1 loss : 0.273808 model2 loss : 0.310616
[22:10:58.304] iteration 4764 : model1 loss : 0.333436 model2 loss : 0.351102
[22:10:58.642] iteration 4765 : model1 loss : 0.302920 model2 loss : 0.241166
[22:10:58.979] iteration 4766 : model1 loss : 0.314667 model2 loss : 0.261165
[22:10:59.320] iteration 4767 : model1 loss : 0.236777 model2 loss : 0.248259
[22:10:59.658] iteration 4768 : model1 loss : 0.235565 model2 loss : 0.156677
[22:10:59.995] iteration 4769 : model1 loss : 0.317202 model2 loss : 0.310659
[22:11:00.335] iteration 4770 : model1 loss : 0.282179 model2 loss : 0.259527
[22:11:00.673] iteration 4771 : model1 loss : 0.229882 model2 loss : 0.258645
[22:11:01.012] iteration 4772 : model1 loss : 0.352924 model2 loss : 0.314478
[22:11:01.354] iteration 4773 : model1 loss : 0.294763 model2 loss : 0.276602
[22:11:01.696] iteration 4774 : model1 loss : 0.284861 model2 loss : 0.297896
[22:11:02.034] iteration 4775 : model1 loss : 0.210028 model2 loss : 0.180653
[22:11:02.377] iteration 4776 : model1 loss : 0.327405 model2 loss : 0.286812
[22:11:02.716] iteration 4777 : model1 loss : 0.279904 model2 loss : 0.251029
[22:11:03.058] iteration 4778 : model1 loss : 0.246134 model2 loss : 0.237500
[22:11:03.394] iteration 4779 : model1 loss : 0.319467 model2 loss : 0.368008
[22:11:03.740] iteration 4780 : model1 loss : 0.312024 model2 loss : 0.265982
[22:11:04.080] iteration 4781 : model1 loss : 0.236938 model2 loss : 0.292756
[22:11:04.427] iteration 4782 : model1 loss : 0.378947 model2 loss : 0.390054
[22:11:04.772] iteration 4783 : model1 loss : 0.291139 model2 loss : 0.240591
[22:11:05.112] iteration 4784 : model1 loss : 0.294688 model2 loss : 0.315583
[22:11:05.454] iteration 4785 : model1 loss : 0.301166 model2 loss : 0.285230
[22:11:05.793] iteration 4786 : model1 loss : 0.358931 model2 loss : 0.249665
[22:11:06.130] iteration 4787 : model1 loss : 0.255936 model2 loss : 0.291710
[22:11:06.477] iteration 4788 : model1 loss : 0.240657 model2 loss : 0.216601
[22:11:06.816] iteration 4789 : model1 loss : 0.257719 model2 loss : 0.214428
[22:11:07.153] iteration 4790 : model1 loss : 0.198029 model2 loss : 0.258862
[22:11:07.490] iteration 4791 : model1 loss : 0.295222 model2 loss : 0.275663
[22:11:07.830] iteration 4792 : model1 loss : 0.244606 model2 loss : 0.229573
[22:11:08.168] iteration 4793 : model1 loss : 0.291076 model2 loss : 0.234002
[22:11:08.508] iteration 4794 : model1 loss : 0.262748 model2 loss : 0.265347
[22:11:08.845] iteration 4795 : model1 loss : 0.364188 model2 loss : 0.327925
[22:11:09.182] iteration 4796 : model1 loss : 0.288260 model2 loss : 0.284399
[22:11:09.519] iteration 4797 : model1 loss : 0.360786 model2 loss : 0.372187
[22:11:09.857] iteration 4798 : model1 loss : 0.313629 model2 loss : 0.267545
[22:11:10.196] iteration 4799 : model1 loss : 0.326081 model2 loss : 0.294208
[22:11:10.538] iteration 4800 : model1 loss : 0.359523 model2 loss : 0.354831
[22:11:11.204] iteration 4801 : model1 loss : 0.244590 model2 loss : 0.200328
[22:11:11.544] iteration 4802 : model1 loss : 0.285153 model2 loss : 0.297539
[22:11:11.883] iteration 4803 : model1 loss : 0.285154 model2 loss : 0.264390
[22:11:12.222] iteration 4804 : model1 loss : 0.298342 model2 loss : 0.331003
[22:11:12.560] iteration 4805 : model1 loss : 0.305971 model2 loss : 0.294749
[22:11:12.914] iteration 4806 : model1 loss : 0.336867 model2 loss : 0.348033
[22:11:13.253] iteration 4807 : model1 loss : 0.390824 model2 loss : 0.386983
[22:11:13.590] iteration 4808 : model1 loss : 0.259540 model2 loss : 0.311397
[22:11:13.928] iteration 4809 : model1 loss : 0.262410 model2 loss : 0.203943
[22:11:14.266] iteration 4810 : model1 loss : 0.256046 model2 loss : 0.277782
[22:11:14.602] iteration 4811 : model1 loss : 0.315353 model2 loss : 0.298421
[22:11:14.940] iteration 4812 : model1 loss : 0.264019 model2 loss : 0.264712
[22:11:15.281] iteration 4813 : model1 loss : 0.236583 model2 loss : 0.206262
[22:11:15.622] iteration 4814 : model1 loss : 0.354498 model2 loss : 0.366094
[22:11:15.961] iteration 4815 : model1 loss : 0.249297 model2 loss : 0.224106
[22:11:16.298] iteration 4816 : model1 loss : 0.279680 model2 loss : 0.239872
[22:11:16.637] iteration 4817 : model1 loss : 0.290412 model2 loss : 0.265937
[22:11:16.976] iteration 4818 : model1 loss : 0.201317 model2 loss : 0.264350
[22:11:17.312] iteration 4819 : model1 loss : 0.366426 model2 loss : 0.300838
[22:11:17.654] iteration 4820 : model1 loss : 0.229741 model2 loss : 0.219257
[22:11:17.995] iteration 4821 : model1 loss : 0.243863 model2 loss : 0.272043
[22:11:18.332] iteration 4822 : model1 loss : 0.300178 model2 loss : 0.306783
[22:11:18.668] iteration 4823 : model1 loss : 0.244164 model2 loss : 0.241127
[22:11:19.004] iteration 4824 : model1 loss : 0.277800 model2 loss : 0.306157
[22:11:19.342] iteration 4825 : model1 loss : 0.307259 model2 loss : 0.261666
[22:11:19.679] iteration 4826 : model1 loss : 0.330073 model2 loss : 0.303497
[22:11:20.018] iteration 4827 : model1 loss : 0.288164 model2 loss : 0.299159
[22:11:20.359] iteration 4828 : model1 loss : 0.311873 model2 loss : 0.330554
[22:11:20.696] iteration 4829 : model1 loss : 0.281431 model2 loss : 0.244487
[22:11:21.038] iteration 4830 : model1 loss : 0.271641 model2 loss : 0.271700
[22:11:21.376] iteration 4831 : model1 loss : 0.396506 model2 loss : 0.369713
[22:11:21.714] iteration 4832 : model1 loss : 0.253728 model2 loss : 0.300692
[22:11:22.051] iteration 4833 : model1 loss : 0.194743 model2 loss : 0.194391
[22:11:22.390] iteration 4834 : model1 loss : 0.205440 model2 loss : 0.185931
[22:11:22.727] iteration 4835 : model1 loss : 0.275670 model2 loss : 0.272446
[22:11:23.068] iteration 4836 : model1 loss : 0.256702 model2 loss : 0.253023
[22:11:23.404] iteration 4837 : model1 loss : 0.302883 model2 loss : 0.334749
[22:11:23.742] iteration 4838 : model1 loss : 0.300202 model2 loss : 0.268927
[22:11:24.079] iteration 4839 : model1 loss : 0.358009 model2 loss : 0.365293
[22:11:24.419] iteration 4840 : model1 loss : 0.249663 model2 loss : 0.276022
[22:11:24.762] iteration 4841 : model1 loss : 0.341015 model2 loss : 0.345703
[22:11:25.103] iteration 4842 : model1 loss : 0.285260 model2 loss : 0.233472
[22:11:25.440] iteration 4843 : model1 loss : 0.225597 model2 loss : 0.195910
[22:11:25.776] iteration 4844 : model1 loss : 0.292618 model2 loss : 0.267056
[22:11:26.114] iteration 4845 : model1 loss : 0.278837 model2 loss : 0.283854
[22:11:26.451] iteration 4846 : model1 loss : 0.284897 model2 loss : 0.251577
[22:11:26.789] iteration 4847 : model1 loss : 0.311834 model2 loss : 0.238528
[22:11:27.125] iteration 4848 : model1 loss : 0.283022 model2 loss : 0.180977
[22:11:27.462] iteration 4849 : model1 loss : 0.293963 model2 loss : 0.286514
[22:11:27.799] iteration 4850 : model1 loss : 0.269159 model2 loss : 0.218930
[22:11:28.449] iteration 4851 : model1 loss : 0.220742 model2 loss : 0.194660
[22:11:28.787] iteration 4852 : model1 loss : 0.274779 model2 loss : 0.250693
[22:11:29.125] iteration 4853 : model1 loss : 0.297847 model2 loss : 0.289448
[22:11:29.462] iteration 4854 : model1 loss : 0.212811 model2 loss : 0.193424
[22:11:29.800] iteration 4855 : model1 loss : 0.256760 model2 loss : 0.223358
[22:11:30.139] iteration 4856 : model1 loss : 0.297592 model2 loss : 0.313610
[22:11:30.476] iteration 4857 : model1 loss : 0.228820 model2 loss : 0.280957
[22:11:30.812] iteration 4858 : model1 loss : 0.284050 model2 loss : 0.305098
[22:11:31.150] iteration 4859 : model1 loss : 0.273341 model2 loss : 0.220555
[22:11:31.489] iteration 4860 : model1 loss : 0.337412 model2 loss : 0.343544
[22:11:31.825] iteration 4861 : model1 loss : 0.247794 model2 loss : 0.239265
[22:11:32.162] iteration 4862 : model1 loss : 0.301059 model2 loss : 0.294180
[22:11:32.508] iteration 4863 : model1 loss : 0.338707 model2 loss : 0.346798
[22:11:32.853] iteration 4864 : model1 loss : 0.322954 model2 loss : 0.218760
[22:11:33.196] iteration 4865 : model1 loss : 0.308037 model2 loss : 0.289146
[22:11:33.537] iteration 4866 : model1 loss : 0.167073 model2 loss : 0.223625
[22:11:33.883] iteration 4867 : model1 loss : 0.267823 model2 loss : 0.318142
[22:11:34.221] iteration 4868 : model1 loss : 0.289720 model2 loss : 0.310229
[22:11:34.559] iteration 4869 : model1 loss : 0.284529 model2 loss : 0.308718
[22:11:34.904] iteration 4870 : model1 loss : 0.269324 model2 loss : 0.262561
[22:11:35.243] iteration 4871 : model1 loss : 0.302631 model2 loss : 0.221885
[22:11:35.581] iteration 4872 : model1 loss : 0.217657 model2 loss : 0.234643
[22:11:35.919] iteration 4873 : model1 loss : 0.272526 model2 loss : 0.265594
[22:11:36.256] iteration 4874 : model1 loss : 0.269616 model2 loss : 0.244608
[22:11:36.595] iteration 4875 : model1 loss : 0.363518 model2 loss : 0.291315
[22:11:36.938] iteration 4876 : model1 loss : 0.320229 model2 loss : 0.363680
[22:11:37.275] iteration 4877 : model1 loss : 0.315048 model2 loss : 0.324673
[22:11:37.629] iteration 4878 : model1 loss : 0.197958 model2 loss : 0.233099
[22:11:37.965] iteration 4879 : model1 loss : 0.292660 model2 loss : 0.228953
[22:11:38.308] iteration 4880 : model1 loss : 0.303342 model2 loss : 0.314813
[22:11:38.648] iteration 4881 : model1 loss : 0.308693 model2 loss : 0.265465
[22:11:38.987] iteration 4882 : model1 loss : 0.262391 model2 loss : 0.310136
[22:11:39.327] iteration 4883 : model1 loss : 0.270846 model2 loss : 0.196528
[22:11:39.656] iteration 4884 : model1 loss : 0.318949 model2 loss : 0.339511
[22:11:39.996] iteration 4885 : model1 loss : 0.422029 model2 loss : 0.355792
[22:11:40.340] iteration 4886 : model1 loss : 0.311389 model2 loss : 0.350452
[22:11:40.687] iteration 4887 : model1 loss : 0.304266 model2 loss : 0.370228
[22:11:41.017] iteration 4888 : model1 loss : 0.178861 model2 loss : 0.216964
[22:11:41.364] iteration 4889 : model1 loss : 0.264306 model2 loss : 0.278599
[22:11:41.714] iteration 4890 : model1 loss : 0.342503 model2 loss : 0.359672
[22:11:42.053] iteration 4891 : model1 loss : 0.302949 model2 loss : 0.337400
[22:11:42.398] iteration 4892 : model1 loss : 0.282175 model2 loss : 0.142268
[22:11:42.739] iteration 4893 : model1 loss : 0.301187 model2 loss : 0.322755
[22:11:43.077] iteration 4894 : model1 loss : 0.348637 model2 loss : 0.286502
[22:11:43.419] iteration 4895 : model1 loss : 0.360223 model2 loss : 0.320656
[22:11:43.759] iteration 4896 : model1 loss : 0.210464 model2 loss : 0.233865
[22:11:44.097] iteration 4897 : model1 loss : 0.253736 model2 loss : 0.302868
[22:11:44.436] iteration 4898 : model1 loss : 0.326441 model2 loss : 0.286413
[22:11:44.781] iteration 4899 : model1 loss : 0.316131 model2 loss : 0.321325
[22:11:45.123] iteration 4900 : model1 loss : 0.331352 model2 loss : 0.357074
[22:11:45.771] iteration 4901 : model1 loss : 0.314015 model2 loss : 0.297129
[22:11:46.109] iteration 4902 : model1 loss : 0.264841 model2 loss : 0.296761
[22:11:46.447] iteration 4903 : model1 loss : 0.255710 model2 loss : 0.196505
[22:11:46.787] iteration 4904 : model1 loss : 0.377629 model2 loss : 0.328463
[22:11:47.129] iteration 4905 : model1 loss : 0.297368 model2 loss : 0.271543
[22:11:48.013] iteration 4906 : model1 loss : 0.289747 model2 loss : 0.381553
[22:11:48.342] iteration 4907 : model1 loss : 0.278419 model2 loss : 0.271636
[22:11:48.673] iteration 4908 : model1 loss : 0.239700 model2 loss : 0.263723
[22:11:49.005] iteration 4909 : model1 loss : 0.347725 model2 loss : 0.308061
[22:11:49.337] iteration 4910 : model1 loss : 0.231403 model2 loss : 0.240171
[22:11:49.669] iteration 4911 : model1 loss : 0.400618 model2 loss : 0.337250
[22:11:49.998] iteration 4912 : model1 loss : 0.296015 model2 loss : 0.272239
[22:11:50.328] iteration 4913 : model1 loss : 0.340290 model2 loss : 0.309672
[22:11:50.658] iteration 4914 : model1 loss : 0.352471 model2 loss : 0.310739
[22:11:50.987] iteration 4915 : model1 loss : 0.270409 model2 loss : 0.240168
[22:11:51.318] iteration 4916 : model1 loss : 0.277847 model2 loss : 0.271140
[22:11:51.646] iteration 4917 : model1 loss : 0.307755 model2 loss : 0.315014
[22:11:51.978] iteration 4918 : model1 loss : 0.315252 model2 loss : 0.326317
[22:11:52.308] iteration 4919 : model1 loss : 0.225417 model2 loss : 0.236046
[22:11:52.637] iteration 4920 : model1 loss : 0.297993 model2 loss : 0.272303
[22:11:52.968] iteration 4921 : model1 loss : 0.291729 model2 loss : 0.323460
[22:11:53.298] iteration 4922 : model1 loss : 0.301774 model2 loss : 0.299725
[22:11:53.628] iteration 4923 : model1 loss : 0.337171 model2 loss : 0.316743
[22:11:53.956] iteration 4924 : model1 loss : 0.358337 model2 loss : 0.368147
[22:11:54.286] iteration 4925 : model1 loss : 0.153455 model2 loss : 0.189683
[22:11:54.617] iteration 4926 : model1 loss : 0.279532 model2 loss : 0.255872
[22:11:54.947] iteration 4927 : model1 loss : 0.337246 model2 loss : 0.317926
[22:11:55.278] iteration 4928 : model1 loss : 0.273537 model2 loss : 0.217151
[22:11:55.606] iteration 4929 : model1 loss : 0.230094 model2 loss : 0.233115
[22:11:55.934] iteration 4930 : model1 loss : 0.270665 model2 loss : 0.274159
[22:11:56.265] iteration 4931 : model1 loss : 0.198252 model2 loss : 0.223781
[22:11:56.595] iteration 4932 : model1 loss : 0.248084 model2 loss : 0.246587
[22:11:56.924] iteration 4933 : model1 loss : 0.233397 model2 loss : 0.155525
[22:11:57.257] iteration 4934 : model1 loss : 0.243403 model2 loss : 0.252004
[22:11:57.585] iteration 4935 : model1 loss : 0.331305 model2 loss : 0.372223
[22:11:57.915] iteration 4936 : model1 loss : 0.232250 model2 loss : 0.328450
[22:11:58.245] iteration 4937 : model1 loss : 0.304343 model2 loss : 0.306405
[22:11:58.575] iteration 4938 : model1 loss : 0.202099 model2 loss : 0.218543
[22:11:58.905] iteration 4939 : model1 loss : 0.308874 model2 loss : 0.301380
[22:11:59.235] iteration 4940 : model1 loss : 0.237298 model2 loss : 0.240544
[22:11:59.563] iteration 4941 : model1 loss : 0.297138 model2 loss : 0.333878
[22:11:59.888] iteration 4942 : model1 loss : 0.269157 model2 loss : 0.281539
[22:12:00.213] iteration 4943 : model1 loss : 0.259948 model2 loss : 0.225645
[22:12:00.544] iteration 4944 : model1 loss : 0.227852 model2 loss : 0.181602
[22:12:00.873] iteration 4945 : model1 loss : 0.252098 model2 loss : 0.229069
[22:12:01.202] iteration 4946 : model1 loss : 0.193687 model2 loss : 0.224234
[22:12:01.532] iteration 4947 : model1 loss : 0.305894 model2 loss : 0.222386
[22:12:01.861] iteration 4948 : model1 loss : 0.167497 model2 loss : 0.233294
[22:12:02.189] iteration 4949 : model1 loss : 0.302704 model2 loss : 0.268341
[22:12:02.518] iteration 4950 : model1 loss : 0.298629 model2 loss : 0.234084
[22:12:03.088] iteration 4951 : model1 loss : 0.342705 model2 loss : 0.296043
[22:12:03.422] iteration 4952 : model1 loss : 0.359883 model2 loss : 0.344328
[22:12:03.754] iteration 4953 : model1 loss : 0.278146 model2 loss : 0.263119
[22:12:04.085] iteration 4954 : model1 loss : 0.383743 model2 loss : 0.339719
[22:12:04.416] iteration 4955 : model1 loss : 0.326970 model2 loss : 0.333624
[22:12:04.747] iteration 4956 : model1 loss : 0.312913 model2 loss : 0.336889
[22:12:05.076] iteration 4957 : model1 loss : 0.222031 model2 loss : 0.224105
[22:12:05.407] iteration 4958 : model1 loss : 0.408420 model2 loss : 0.376195
[22:12:05.736] iteration 4959 : model1 loss : 0.319904 model2 loss : 0.278898
[22:12:06.066] iteration 4960 : model1 loss : 0.306245 model2 loss : 0.316187
[22:12:06.394] iteration 4961 : model1 loss : 0.304792 model2 loss : 0.227874
[22:12:06.726] iteration 4962 : model1 loss : 0.287037 model2 loss : 0.219589
[22:12:07.056] iteration 4963 : model1 loss : 0.287681 model2 loss : 0.263159
[22:12:07.385] iteration 4964 : model1 loss : 0.239408 model2 loss : 0.277050
[22:12:07.716] iteration 4965 : model1 loss : 0.233512 model2 loss : 0.196629
[22:12:08.048] iteration 4966 : model1 loss : 0.356894 model2 loss : 0.337294
[22:12:08.378] iteration 4967 : model1 loss : 0.246431 model2 loss : 0.236883
[22:12:08.708] iteration 4968 : model1 loss : 0.294555 model2 loss : 0.247009
[22:12:09.038] iteration 4969 : model1 loss : 0.317555 model2 loss : 0.328609
[22:12:09.367] iteration 4970 : model1 loss : 0.218182 model2 loss : 0.242401
[22:12:09.697] iteration 4971 : model1 loss : 0.294853 model2 loss : 0.298790
[22:12:10.027] iteration 4972 : model1 loss : 0.345406 model2 loss : 0.356878
[22:12:10.356] iteration 4973 : model1 loss : 0.399955 model2 loss : 0.373729
[22:12:10.686] iteration 4974 : model1 loss : 0.275287 model2 loss : 0.293651
[22:12:11.015] iteration 4975 : model1 loss : 0.344291 model2 loss : 0.347049
[22:12:11.345] iteration 4976 : model1 loss : 0.323437 model2 loss : 0.257462
[22:12:11.674] iteration 4977 : model1 loss : 0.211546 model2 loss : 0.217911
[22:12:12.005] iteration 4978 : model1 loss : 0.247502 model2 loss : 0.250035
[22:12:12.342] iteration 4979 : model1 loss : 0.323777 model2 loss : 0.361590
[22:12:12.671] iteration 4980 : model1 loss : 0.453705 model2 loss : 0.334220
[22:12:13.001] iteration 4981 : model1 loss : 0.253062 model2 loss : 0.164010
[22:12:13.331] iteration 4982 : model1 loss : 0.279232 model2 loss : 0.251387
[22:12:13.662] iteration 4983 : model1 loss : 0.372419 model2 loss : 0.345176
[22:12:13.995] iteration 4984 : model1 loss : 0.262273 model2 loss : 0.223563
[22:12:14.326] iteration 4985 : model1 loss : 0.331761 model2 loss : 0.254969
[22:12:14.656] iteration 4986 : model1 loss : 0.236583 model2 loss : 0.250178
[22:12:14.990] iteration 4987 : model1 loss : 0.243407 model2 loss : 0.283137
[22:12:15.322] iteration 4988 : model1 loss : 0.361768 model2 loss : 0.297676
[22:12:15.653] iteration 4989 : model1 loss : 0.170243 model2 loss : 0.182874
[22:12:15.985] iteration 4990 : model1 loss : 0.220182 model2 loss : 0.127163
[22:12:16.314] iteration 4991 : model1 loss : 0.339709 model2 loss : 0.294979
[22:12:16.644] iteration 4992 : model1 loss : 0.288769 model2 loss : 0.282045
[22:12:16.975] iteration 4993 : model1 loss : 0.267564 model2 loss : 0.304969
[22:12:17.307] iteration 4994 : model1 loss : 0.257592 model2 loss : 0.305947
[22:12:17.637] iteration 4995 : model1 loss : 0.334850 model2 loss : 0.351037
[22:12:17.966] iteration 4996 : model1 loss : 0.229304 model2 loss : 0.165025
[22:12:18.292] iteration 4997 : model1 loss : 0.284872 model2 loss : 0.379768
[22:12:18.624] iteration 4998 : model1 loss : 0.228451 model2 loss : 0.200924
[22:12:18.953] iteration 4999 : model1 loss : 0.197162 model2 loss : 0.201019
[22:12:19.283] iteration 5000 : model1 loss : 0.239866 model2 loss : 0.212957
[22:12:19.842] iteration 5001 : model1 loss : 0.225146 model2 loss : 0.264509
[22:12:20.172] iteration 5002 : model1 loss : 0.253119 model2 loss : 0.245699
[22:12:20.501] iteration 5003 : model1 loss : 0.401457 model2 loss : 0.410014
[22:12:20.826] iteration 5004 : model1 loss : 0.381224 model2 loss : 0.300824
[22:12:21.157] iteration 5005 : model1 loss : 0.386352 model2 loss : 0.431435
[22:12:21.488] iteration 5006 : model1 loss : 0.333929 model2 loss : 0.334596
[22:12:21.817] iteration 5007 : model1 loss : 0.314810 model2 loss : 0.266147
[22:12:22.148] iteration 5008 : model1 loss : 0.309333 model2 loss : 0.334167
[22:12:22.478] iteration 5009 : model1 loss : 0.272823 model2 loss : 0.211172
[22:12:22.809] iteration 5010 : model1 loss : 0.166795 model2 loss : 0.176307
[22:12:23.139] iteration 5011 : model1 loss : 0.349336 model2 loss : 0.365121
[22:12:23.469] iteration 5012 : model1 loss : 0.293195 model2 loss : 0.259314
[22:12:23.799] iteration 5013 : model1 loss : 0.186263 model2 loss : 0.183005
[22:12:24.128] iteration 5014 : model1 loss : 0.312361 model2 loss : 0.292761
[22:12:24.458] iteration 5015 : model1 loss : 0.335685 model2 loss : 0.323417
[22:12:24.788] iteration 5016 : model1 loss : 0.220099 model2 loss : 0.190404
[22:12:25.117] iteration 5017 : model1 loss : 0.163676 model2 loss : 0.190430
[22:12:25.446] iteration 5018 : model1 loss : 0.363036 model2 loss : 0.345546
[22:12:25.775] iteration 5019 : model1 loss : 0.374943 model2 loss : 0.318269
[22:12:26.105] iteration 5020 : model1 loss : 0.284442 model2 loss : 0.297877
[22:12:26.434] iteration 5021 : model1 loss : 0.297437 model2 loss : 0.291970
[22:12:26.765] iteration 5022 : model1 loss : 0.193739 model2 loss : 0.250942
[22:12:27.096] iteration 5023 : model1 loss : 0.238132 model2 loss : 0.243500
[22:12:27.430] iteration 5024 : model1 loss : 0.256273 model2 loss : 0.209055
[22:12:27.758] iteration 5025 : model1 loss : 0.321639 model2 loss : 0.342924
[22:12:28.088] iteration 5026 : model1 loss : 0.213379 model2 loss : 0.240486
[22:12:28.416] iteration 5027 : model1 loss : 0.137531 model2 loss : 0.137321
[22:12:28.746] iteration 5028 : model1 loss : 0.311848 model2 loss : 0.341823
[22:12:29.075] iteration 5029 : model1 loss : 0.310714 model2 loss : 0.280492
[22:12:29.404] iteration 5030 : model1 loss : 0.274267 model2 loss : 0.324976
[22:12:29.733] iteration 5031 : model1 loss : 0.150454 model2 loss : 0.206484
[22:12:30.062] iteration 5032 : model1 loss : 0.297648 model2 loss : 0.283927
[22:12:30.392] iteration 5033 : model1 loss : 0.316514 model2 loss : 0.263266
[22:12:30.722] iteration 5034 : model1 loss : 0.267866 model2 loss : 0.231411
[22:12:31.050] iteration 5035 : model1 loss : 0.349202 model2 loss : 0.288223
[22:12:31.376] iteration 5036 : model1 loss : 0.493470 model2 loss : 0.369715
[22:12:31.701] iteration 5037 : model1 loss : 0.208695 model2 loss : 0.219794
[22:12:32.030] iteration 5038 : model1 loss : 0.336617 model2 loss : 0.341321
[22:12:32.360] iteration 5039 : model1 loss : 0.267565 model2 loss : 0.283353
[22:12:32.688] iteration 5040 : model1 loss : 0.296966 model2 loss : 0.274510
[22:12:33.017] iteration 5041 : model1 loss : 0.337594 model2 loss : 0.191618
[22:12:33.346] iteration 5042 : model1 loss : 0.218717 model2 loss : 0.190451
[22:12:33.675] iteration 5043 : model1 loss : 0.384692 model2 loss : 0.346303
[22:12:34.004] iteration 5044 : model1 loss : 0.279901 model2 loss : 0.257159
[22:12:34.334] iteration 5045 : model1 loss : 0.271346 model2 loss : 0.305450
[22:12:34.662] iteration 5046 : model1 loss : 0.290800 model2 loss : 0.311662
[22:12:34.991] iteration 5047 : model1 loss : 0.274562 model2 loss : 0.246629
[22:12:35.322] iteration 5048 : model1 loss : 0.278012 model2 loss : 0.205298
[22:12:35.651] iteration 5049 : model1 loss : 0.306308 model2 loss : 0.324316
[22:12:35.979] iteration 5050 : model1 loss : 0.342260 model2 loss : 0.278524
[22:12:36.538] iteration 5051 : model1 loss : 0.376195 model2 loss : 0.317244
[22:12:36.867] iteration 5052 : model1 loss : 0.262439 model2 loss : 0.265446
[22:12:37.196] iteration 5053 : model1 loss : 0.225406 model2 loss : 0.175916
[22:12:37.525] iteration 5054 : model1 loss : 0.297203 model2 loss : 0.265534
[22:12:37.855] iteration 5055 : model1 loss : 0.326619 model2 loss : 0.308541
[22:12:38.184] iteration 5056 : model1 loss : 0.248800 model2 loss : 0.240703
[22:12:38.525] iteration 5057 : model1 loss : 0.197410 model2 loss : 0.147608
[22:12:38.854] iteration 5058 : model1 loss : 0.290833 model2 loss : 0.281530
[22:12:39.184] iteration 5059 : model1 loss : 0.249112 model2 loss : 0.224530
[22:12:39.513] iteration 5060 : model1 loss : 0.292882 model2 loss : 0.293466
[22:12:39.844] iteration 5061 : model1 loss : 0.290174 model2 loss : 0.288598
[22:12:40.173] iteration 5062 : model1 loss : 0.352746 model2 loss : 0.308294
[22:12:40.502] iteration 5063 : model1 loss : 0.264707 model2 loss : 0.254426
[22:12:40.831] iteration 5064 : model1 loss : 0.282550 model2 loss : 0.267891
[22:12:41.159] iteration 5065 : model1 loss : 0.255913 model2 loss : 0.267781
[22:12:41.488] iteration 5066 : model1 loss : 0.305346 model2 loss : 0.289351
[22:12:41.817] iteration 5067 : model1 loss : 0.271798 model2 loss : 0.281444
[22:12:42.147] iteration 5068 : model1 loss : 0.294161 model2 loss : 0.305136
[22:12:42.476] iteration 5069 : model1 loss : 0.322281 model2 loss : 0.364545
[22:12:42.805] iteration 5070 : model1 loss : 0.252451 model2 loss : 0.265249
[22:12:43.134] iteration 5071 : model1 loss : 0.264547 model2 loss : 0.283230
[22:12:43.463] iteration 5072 : model1 loss : 0.304320 model2 loss : 0.315772
[22:12:43.798] iteration 5073 : model1 loss : 0.215880 model2 loss : 0.242084
[22:12:44.126] iteration 5074 : model1 loss : 0.162915 model2 loss : 0.171034
[22:12:44.456] iteration 5075 : model1 loss : 0.260017 model2 loss : 0.275482
[22:12:44.785] iteration 5076 : model1 loss : 0.327178 model2 loss : 0.352144
[22:12:45.114] iteration 5077 : model1 loss : 0.297037 model2 loss : 0.323729
[22:12:45.444] iteration 5078 : model1 loss : 0.270468 model2 loss : 0.290662
[22:12:45.773] iteration 5079 : model1 loss : 0.219837 model2 loss : 0.197104
[22:12:46.109] iteration 5080 : model1 loss : 0.370672 model2 loss : 0.323731
[22:12:46.447] iteration 5081 : model1 loss : 0.273842 model2 loss : 0.224795
[22:12:46.778] iteration 5082 : model1 loss : 0.198513 model2 loss : 0.197209
[22:12:47.108] iteration 5083 : model1 loss : 0.353545 model2 loss : 0.330501
[22:12:47.437] iteration 5084 : model1 loss : 0.322239 model2 loss : 0.327919
[22:12:47.766] iteration 5085 : model1 loss : 0.214268 model2 loss : 0.174500
[22:12:48.095] iteration 5086 : model1 loss : 0.230416 model2 loss : 0.213626
[22:12:48.425] iteration 5087 : model1 loss : 0.411087 model2 loss : 0.330324
[22:12:48.753] iteration 5088 : model1 loss : 0.294519 model2 loss : 0.310626
[22:12:49.083] iteration 5089 : model1 loss : 0.193850 model2 loss : 0.206286
[22:12:49.412] iteration 5090 : model1 loss : 0.274136 model2 loss : 0.322199
[22:12:49.741] iteration 5091 : model1 loss : 0.246802 model2 loss : 0.204858
[22:12:50.070] iteration 5092 : model1 loss : 0.334003 model2 loss : 0.237054
[22:12:50.399] iteration 5093 : model1 loss : 0.321359 model2 loss : 0.259246
[22:12:50.729] iteration 5094 : model1 loss : 0.225671 model2 loss : 0.209178
[22:12:51.059] iteration 5095 : model1 loss : 0.349746 model2 loss : 0.403444
[22:12:51.388] iteration 5096 : model1 loss : 0.235261 model2 loss : 0.264218
[22:12:51.718] iteration 5097 : model1 loss : 0.240727 model2 loss : 0.224682
[22:12:52.047] iteration 5098 : model1 loss : 0.233345 model2 loss : 0.258899
[22:12:52.382] iteration 5099 : model1 loss : 0.337958 model2 loss : 0.329183
[22:12:52.711] iteration 5100 : model1 loss : 0.253692 model2 loss : 0.186023
[22:12:53.291] iteration 5101 : model1 loss : 0.258640 model2 loss : 0.273745
[22:12:53.629] iteration 5102 : model1 loss : 0.294274 model2 loss : 0.372566
[22:12:53.970] iteration 5103 : model1 loss : 0.284749 model2 loss : 0.293871
[22:12:54.308] iteration 5104 : model1 loss : 0.312731 model2 loss : 0.308340
[22:12:54.648] iteration 5105 : model1 loss : 0.305353 model2 loss : 0.324490
[22:12:54.980] iteration 5106 : model1 loss : 0.269308 model2 loss : 0.266640
[22:12:55.318] iteration 5107 : model1 loss : 0.333116 model2 loss : 0.308161
[22:12:55.655] iteration 5108 : model1 loss : 0.294581 model2 loss : 0.311932
[22:12:55.991] iteration 5109 : model1 loss : 0.398707 model2 loss : 0.398570
[22:12:56.326] iteration 5110 : model1 loss : 0.299711 model2 loss : 0.270983
[22:12:56.664] iteration 5111 : model1 loss : 0.327191 model2 loss : 0.331919
[22:12:57.003] iteration 5112 : model1 loss : 0.274789 model2 loss : 0.259805
[22:12:57.344] iteration 5113 : model1 loss : 0.211567 model2 loss : 0.236671
[22:12:57.700] iteration 5114 : model1 loss : 0.271048 model2 loss : 0.292406
[22:12:58.039] iteration 5115 : model1 loss : 0.340931 model2 loss : 0.341673
[22:12:58.376] iteration 5116 : model1 loss : 0.254873 model2 loss : 0.247800
[22:12:58.714] iteration 5117 : model1 loss : 0.271617 model2 loss : 0.373278
[22:12:59.048] iteration 5118 : model1 loss : 0.354378 model2 loss : 0.405060
[22:12:59.388] iteration 5119 : model1 loss : 0.203960 model2 loss : 0.219947
[22:12:59.730] iteration 5120 : model1 loss : 0.317870 model2 loss : 0.341051
[22:13:00.067] iteration 5121 : model1 loss : 0.299043 model2 loss : 0.365624
[22:13:00.424] iteration 5122 : model1 loss : 0.132791 model2 loss : 0.139998
[22:13:00.762] iteration 5123 : model1 loss : 0.219690 model2 loss : 0.227465
[22:13:01.100] iteration 5124 : model1 loss : 0.219980 model2 loss : 0.189689
[22:13:01.438] iteration 5125 : model1 loss : 0.325083 model2 loss : 0.302901
[22:13:01.773] iteration 5126 : model1 loss : 0.281196 model2 loss : 0.249784
[22:13:02.111] iteration 5127 : model1 loss : 0.232374 model2 loss : 0.215432
[22:13:02.448] iteration 5128 : model1 loss : 0.403725 model2 loss : 0.331449
[22:13:02.786] iteration 5129 : model1 loss : 0.288179 model2 loss : 0.241644
[22:13:03.124] iteration 5130 : model1 loss : 0.315350 model2 loss : 0.283139
[22:13:03.463] iteration 5131 : model1 loss : 0.280416 model2 loss : 0.229625
[22:13:03.796] iteration 5132 : model1 loss : 0.203722 model2 loss : 0.226809
[22:13:04.131] iteration 5133 : model1 loss : 0.325181 model2 loss : 0.340852
[22:13:04.465] iteration 5134 : model1 loss : 0.280089 model2 loss : 0.235122
[22:13:04.800] iteration 5135 : model1 loss : 0.211748 model2 loss : 0.209761
[22:13:05.137] iteration 5136 : model1 loss : 0.231419 model2 loss : 0.289375
[22:13:05.474] iteration 5137 : model1 loss : 0.318956 model2 loss : 0.280068
[22:13:05.809] iteration 5138 : model1 loss : 0.279930 model2 loss : 0.261257
[22:13:06.148] iteration 5139 : model1 loss : 0.205323 model2 loss : 0.179382
[22:13:06.483] iteration 5140 : model1 loss : 0.225415 model2 loss : 0.201796
[22:13:06.819] iteration 5141 : model1 loss : 0.233355 model2 loss : 0.247713
[22:13:07.157] iteration 5142 : model1 loss : 0.259250 model2 loss : 0.273631
[22:13:07.491] iteration 5143 : model1 loss : 0.185095 model2 loss : 0.242132
[22:13:07.829] iteration 5144 : model1 loss : 0.233969 model2 loss : 0.282968
[22:13:08.167] iteration 5145 : model1 loss : 0.141671 model2 loss : 0.171826
[22:13:08.503] iteration 5146 : model1 loss : 0.341636 model2 loss : 0.305042
[22:13:08.837] iteration 5147 : model1 loss : 0.253137 model2 loss : 0.243284
[22:13:09.176] iteration 5148 : model1 loss : 0.275963 model2 loss : 0.222387
[22:13:09.521] iteration 5149 : model1 loss : 0.271389 model2 loss : 0.276323
[22:13:09.860] iteration 5150 : model1 loss : 0.203175 model2 loss : 0.257226
[22:13:10.539] iteration 5151 : model1 loss : 0.379744 model2 loss : 0.377220
[22:13:10.877] iteration 5152 : model1 loss : 0.329033 model2 loss : 0.323776
[22:13:11.216] iteration 5153 : model1 loss : 0.197261 model2 loss : 0.317719
[22:13:11.554] iteration 5154 : model1 loss : 0.276987 model2 loss : 0.266940
[22:13:11.893] iteration 5155 : model1 loss : 0.259288 model2 loss : 0.285220
[22:13:12.232] iteration 5156 : model1 loss : 0.187996 model2 loss : 0.205729
[22:13:12.573] iteration 5157 : model1 loss : 0.159075 model2 loss : 0.203498
[22:13:12.909] iteration 5158 : model1 loss : 0.256844 model2 loss : 0.241452
[22:13:13.250] iteration 5159 : model1 loss : 0.283584 model2 loss : 0.290487
[22:13:13.588] iteration 5160 : model1 loss : 0.125327 model2 loss : 0.135047
[22:13:13.928] iteration 5161 : model1 loss : 0.269052 model2 loss : 0.287079
[22:13:14.266] iteration 5162 : model1 loss : 0.285950 model2 loss : 0.313280
[22:13:14.606] iteration 5163 : model1 loss : 0.277642 model2 loss : 0.279700
[22:13:14.943] iteration 5164 : model1 loss : 0.269076 model2 loss : 0.285004
[22:13:15.283] iteration 5165 : model1 loss : 0.327291 model2 loss : 0.376482
[22:13:15.621] iteration 5166 : model1 loss : 0.123660 model2 loss : 0.159839
[22:13:15.965] iteration 5167 : model1 loss : 0.351585 model2 loss : 0.377003
[22:13:16.311] iteration 5168 : model1 loss : 0.286749 model2 loss : 0.271863
[22:13:16.651] iteration 5169 : model1 loss : 0.333182 model2 loss : 0.326705
[22:13:16.984] iteration 5170 : model1 loss : 0.267695 model2 loss : 0.290030
[22:13:17.318] iteration 5171 : model1 loss : 0.342726 model2 loss : 0.355755
[22:13:17.656] iteration 5172 : model1 loss : 0.209515 model2 loss : 0.243704
[22:13:17.995] iteration 5173 : model1 loss : 0.208401 model2 loss : 0.181589
[22:13:18.333] iteration 5174 : model1 loss : 0.310794 model2 loss : 0.242996
[22:13:18.673] iteration 5175 : model1 loss : 0.349582 model2 loss : 0.372436
[22:13:19.011] iteration 5176 : model1 loss : 0.208882 model2 loss : 0.269917
[22:13:19.349] iteration 5177 : model1 loss : 0.298186 model2 loss : 0.221329
[22:13:19.687] iteration 5178 : model1 loss : 0.181906 model2 loss : 0.208614
[22:13:20.025] iteration 5179 : model1 loss : 0.186703 model2 loss : 0.149826
[22:13:20.367] iteration 5180 : model1 loss : 0.316525 model2 loss : 0.274681
[22:13:20.706] iteration 5181 : model1 loss : 0.258230 model2 loss : 0.239972
[22:13:21.044] iteration 5182 : model1 loss : 0.245721 model2 loss : 0.281291
[22:13:21.385] iteration 5183 : model1 loss : 0.196137 model2 loss : 0.207431
[22:13:21.728] iteration 5184 : model1 loss : 0.271998 model2 loss : 0.230281
[22:13:22.065] iteration 5185 : model1 loss : 0.288579 model2 loss : 0.223945
[22:13:22.404] iteration 5186 : model1 loss : 0.522730 model2 loss : 0.427872
[22:13:22.744] iteration 5187 : model1 loss : 0.308951 model2 loss : 0.260155
[22:13:23.084] iteration 5188 : model1 loss : 0.424871 model2 loss : 0.361558
[22:13:23.424] iteration 5189 : model1 loss : 0.314385 model2 loss : 0.318546
[22:13:23.766] iteration 5190 : model1 loss : 0.203815 model2 loss : 0.212577
[22:13:24.104] iteration 5191 : model1 loss : 0.304711 model2 loss : 0.278830
[22:13:24.445] iteration 5192 : model1 loss : 0.246083 model2 loss : 0.339180
[22:13:24.781] iteration 5193 : model1 loss : 0.278486 model2 loss : 0.234410
[22:13:25.116] iteration 5194 : model1 loss : 0.213377 model2 loss : 0.275689
[22:13:25.454] iteration 5195 : model1 loss : 0.305534 model2 loss : 0.312271
[22:13:25.789] iteration 5196 : model1 loss : 0.243014 model2 loss : 0.241090
[22:13:26.124] iteration 5197 : model1 loss : 0.248390 model2 loss : 0.272401
[22:13:26.461] iteration 5198 : model1 loss : 0.286870 model2 loss : 0.240161
[22:13:26.800] iteration 5199 : model1 loss : 0.328449 model2 loss : 0.296160
[22:13:27.134] iteration 5200 : model1 loss : 0.232325 model2 loss : 0.222653
[22:13:27.808] iteration 5201 : model1 loss : 0.242855 model2 loss : 0.222632
[22:13:28.146] iteration 5202 : model1 loss : 0.308155 model2 loss : 0.309155
[22:13:28.484] iteration 5203 : model1 loss : 0.285376 model2 loss : 0.297599
[22:13:28.822] iteration 5204 : model1 loss : 0.250461 model2 loss : 0.215696
[22:13:29.157] iteration 5205 : model1 loss : 0.244305 model2 loss : 0.308682
[22:13:29.490] iteration 5206 : model1 loss : 0.245572 model2 loss : 0.231611
[22:13:29.824] iteration 5207 : model1 loss : 0.295700 model2 loss : 0.295075
[22:13:30.158] iteration 5208 : model1 loss : 0.325787 model2 loss : 0.253924
[22:13:30.495] iteration 5209 : model1 loss : 0.372893 model2 loss : 0.325722
[22:13:30.830] iteration 5210 : model1 loss : 0.282929 model2 loss : 0.285184
[22:13:31.166] iteration 5211 : model1 loss : 0.224125 model2 loss : 0.234475
[22:13:31.507] iteration 5212 : model1 loss : 0.294969 model2 loss : 0.297091
[22:13:31.846] iteration 5213 : model1 loss : 0.447876 model2 loss : 0.466507
[22:13:32.182] iteration 5214 : model1 loss : 0.301760 model2 loss : 0.252405
[22:13:32.521] iteration 5215 : model1 loss : 0.268834 model2 loss : 0.286770
[22:13:32.857] iteration 5216 : model1 loss : 0.336591 model2 loss : 0.292419
[22:13:33.191] iteration 5217 : model1 loss : 0.276921 model2 loss : 0.268801
[22:13:33.525] iteration 5218 : model1 loss : 0.313436 model2 loss : 0.294028
[22:13:33.863] iteration 5219 : model1 loss : 0.298947 model2 loss : 0.307934
[22:13:34.201] iteration 5220 : model1 loss : 0.446707 model2 loss : 0.343285
[22:13:34.535] iteration 5221 : model1 loss : 0.223458 model2 loss : 0.231333
[22:13:34.869] iteration 5222 : model1 loss : 0.398642 model2 loss : 0.311734
[22:13:35.203] iteration 5223 : model1 loss : 0.164665 model2 loss : 0.217793
[22:13:35.539] iteration 5224 : model1 loss : 0.302588 model2 loss : 0.308929
[22:13:35.873] iteration 5225 : model1 loss : 0.265156 model2 loss : 0.235009
[22:13:36.211] iteration 5226 : model1 loss : 0.295677 model2 loss : 0.323997
[22:13:36.551] iteration 5227 : model1 loss : 0.312667 model2 loss : 0.300340
[22:13:36.889] iteration 5228 : model1 loss : 0.311856 model2 loss : 0.305196
[22:13:37.223] iteration 5229 : model1 loss : 0.329020 model2 loss : 0.307883
[22:13:37.557] iteration 5230 : model1 loss : 0.345734 model2 loss : 0.262089
[22:13:37.891] iteration 5231 : model1 loss : 0.227125 model2 loss : 0.214237
[22:13:38.224] iteration 5232 : model1 loss : 0.277598 model2 loss : 0.242577
[22:13:38.562] iteration 5233 : model1 loss : 0.322989 model2 loss : 0.332802
[22:13:38.899] iteration 5234 : model1 loss : 0.234134 model2 loss : 0.244221
[22:13:39.237] iteration 5235 : model1 loss : 0.232256 model2 loss : 0.274515
[22:13:39.578] iteration 5236 : model1 loss : 0.267970 model2 loss : 0.263909
[22:13:39.915] iteration 5237 : model1 loss : 0.237045 model2 loss : 0.224885
[22:13:40.247] iteration 5238 : model1 loss : 0.391460 model2 loss : 0.347405
[22:13:40.587] iteration 5239 : model1 loss : 0.278190 model2 loss : 0.190991
[22:13:40.924] iteration 5240 : model1 loss : 0.326150 model2 loss : 0.336761
[22:13:41.264] iteration 5241 : model1 loss : 0.298943 model2 loss : 0.310216
[22:13:41.603] iteration 5242 : model1 loss : 0.327013 model2 loss : 0.303103
[22:13:41.942] iteration 5243 : model1 loss : 0.323026 model2 loss : 0.332392
[22:13:42.278] iteration 5244 : model1 loss : 0.203489 model2 loss : 0.202697
[22:13:42.613] iteration 5245 : model1 loss : 0.168780 model2 loss : 0.191062
[22:13:42.947] iteration 5246 : model1 loss : 0.363762 model2 loss : 0.335939
[22:13:43.281] iteration 5247 : model1 loss : 0.188237 model2 loss : 0.139628
[22:13:43.615] iteration 5248 : model1 loss : 0.314124 model2 loss : 0.323924
[22:13:43.948] iteration 5249 : model1 loss : 0.494519 model2 loss : 0.506965
[22:13:44.295] iteration 5250 : model1 loss : 0.253747 model2 loss : 0.266164
[22:13:44.916] iteration 5251 : model1 loss : 0.262186 model2 loss : 0.312661
[22:13:45.251] iteration 5252 : model1 loss : 0.216440 model2 loss : 0.224221
[22:13:45.585] iteration 5253 : model1 loss : 0.261119 model2 loss : 0.282390
[22:13:45.920] iteration 5254 : model1 loss : 0.277892 model2 loss : 0.276608
[22:13:46.255] iteration 5255 : model1 loss : 0.187236 model2 loss : 0.152898
[22:13:46.590] iteration 5256 : model1 loss : 0.308001 model2 loss : 0.255309
[22:13:46.924] iteration 5257 : model1 loss : 0.245694 model2 loss : 0.259025
[22:13:47.258] iteration 5258 : model1 loss : 0.358119 model2 loss : 0.315169
[22:13:47.593] iteration 5259 : model1 loss : 0.260407 model2 loss : 0.244378
[22:13:47.926] iteration 5260 : model1 loss : 0.309054 model2 loss : 0.338519
[22:13:48.261] iteration 5261 : model1 loss : 0.247673 model2 loss : 0.227488
[22:13:48.596] iteration 5262 : model1 loss : 0.289072 model2 loss : 0.225737
[22:13:48.934] iteration 5263 : model1 loss : 0.362469 model2 loss : 0.395581
[22:13:49.268] iteration 5264 : model1 loss : 0.304892 model2 loss : 0.335944
[22:13:49.605] iteration 5265 : model1 loss : 0.179834 model2 loss : 0.156031
[22:13:49.938] iteration 5266 : model1 loss : 0.279653 model2 loss : 0.296056
[22:13:50.275] iteration 5267 : model1 loss : 0.295709 model2 loss : 0.282918
[22:13:50.610] iteration 5268 : model1 loss : 0.303438 model2 loss : 0.274332
[22:13:50.945] iteration 5269 : model1 loss : 0.177385 model2 loss : 0.147363
[22:13:51.280] iteration 5270 : model1 loss : 0.356357 model2 loss : 0.307815
[22:13:51.617] iteration 5271 : model1 loss : 0.229771 model2 loss : 0.248798
[22:13:51.955] iteration 5272 : model1 loss : 0.295177 model2 loss : 0.307213
[22:13:52.288] iteration 5273 : model1 loss : 0.360116 model2 loss : 0.317569
[22:13:52.626] iteration 5274 : model1 loss : 0.342415 model2 loss : 0.250235
[22:13:52.962] iteration 5275 : model1 loss : 0.368813 model2 loss : 0.319291
[22:13:53.295] iteration 5276 : model1 loss : 0.264002 model2 loss : 0.266807
[22:13:53.630] iteration 5277 : model1 loss : 0.321331 model2 loss : 0.274657
[22:13:53.967] iteration 5278 : model1 loss : 0.358489 model2 loss : 0.340468
[22:13:54.300] iteration 5279 : model1 loss : 0.317061 model2 loss : 0.306667
[22:13:54.635] iteration 5280 : model1 loss : 0.206068 model2 loss : 0.218687
[22:13:54.973] iteration 5281 : model1 loss : 0.174094 model2 loss : 0.230253
[22:13:55.314] iteration 5282 : model1 loss : 0.301141 model2 loss : 0.307795
[22:13:55.646] iteration 5283 : model1 loss : 0.333117 model2 loss : 0.312087
[22:13:55.980] iteration 5284 : model1 loss : 0.290565 model2 loss : 0.301983
[22:13:56.317] iteration 5285 : model1 loss : 0.236276 model2 loss : 0.258143
[22:13:56.652] iteration 5286 : model1 loss : 0.431302 model2 loss : 0.440283
[22:13:56.990] iteration 5287 : model1 loss : 0.270815 model2 loss : 0.252290
[22:13:57.325] iteration 5288 : model1 loss : 0.311537 model2 loss : 0.302077
[22:13:57.663] iteration 5289 : model1 loss : 0.153996 model2 loss : 0.151734
[22:13:58.000] iteration 5290 : model1 loss : 0.302513 model2 loss : 0.318433
[22:13:58.345] iteration 5291 : model1 loss : 0.266895 model2 loss : 0.165715
[22:13:58.679] iteration 5292 : model1 loss : 0.237617 model2 loss : 0.201653
[22:13:59.014] iteration 5293 : model1 loss : 0.356328 model2 loss : 0.292226
[22:13:59.357] iteration 5294 : model1 loss : 0.420650 model2 loss : 0.470057
[22:13:59.695] iteration 5295 : model1 loss : 0.285688 model2 loss : 0.255888
[22:14:00.034] iteration 5296 : model1 loss : 0.322354 model2 loss : 0.288965
[22:14:00.369] iteration 5297 : model1 loss : 0.221747 model2 loss : 0.240296
[22:14:00.705] iteration 5298 : model1 loss : 0.216741 model2 loss : 0.207567
[22:14:01.038] iteration 5299 : model1 loss : 0.259120 model2 loss : 0.283969
[22:14:01.377] iteration 5300 : model1 loss : 0.365978 model2 loss : 0.328120
[22:14:02.015] iteration 5301 : model1 loss : 0.375306 model2 loss : 0.344058
[22:14:02.351] iteration 5302 : model1 loss : 0.275904 model2 loss : 0.342715
[22:14:02.694] iteration 5303 : model1 loss : 0.356085 model2 loss : 0.292100
[22:14:03.035] iteration 5304 : model1 loss : 0.267733 model2 loss : 0.311269
[22:14:03.368] iteration 5305 : model1 loss : 0.268460 model2 loss : 0.307391
[22:14:03.706] iteration 5306 : model1 loss : 0.374150 model2 loss : 0.380677
[22:14:04.042] iteration 5307 : model1 loss : 0.254850 model2 loss : 0.214006
[22:14:04.376] iteration 5308 : model1 loss : 0.278648 model2 loss : 0.253184
[22:14:04.713] iteration 5309 : model1 loss : 0.268052 model2 loss : 0.194697
[22:14:05.045] iteration 5310 : model1 loss : 0.265653 model2 loss : 0.285172
[22:14:05.383] iteration 5311 : model1 loss : 0.312783 model2 loss : 0.324160
[22:14:05.719] iteration 5312 : model1 loss : 0.314986 model2 loss : 0.351234
[22:14:06.056] iteration 5313 : model1 loss : 0.255623 model2 loss : 0.233578
[22:14:06.393] iteration 5314 : model1 loss : 0.289267 model2 loss : 0.305997
[22:14:06.730] iteration 5315 : model1 loss : 0.303946 model2 loss : 0.273450
[22:14:07.063] iteration 5316 : model1 loss : 0.272883 model2 loss : 0.212041
[22:14:07.400] iteration 5317 : model1 loss : 0.237213 model2 loss : 0.293251
[22:14:07.734] iteration 5318 : model1 loss : 0.286324 model2 loss : 0.220047
[22:14:08.073] iteration 5319 : model1 loss : 0.302973 model2 loss : 0.295756
[22:14:08.408] iteration 5320 : model1 loss : 0.237874 model2 loss : 0.243078
[22:14:08.745] iteration 5321 : model1 loss : 0.284097 model2 loss : 0.218240
[22:14:09.082] iteration 5322 : model1 loss : 0.321780 model2 loss : 0.322305
[22:14:09.415] iteration 5323 : model1 loss : 0.292631 model2 loss : 0.265980
[22:14:09.749] iteration 5324 : model1 loss : 0.313534 model2 loss : 0.305239
[22:14:10.083] iteration 5325 : model1 loss : 0.169462 model2 loss : 0.190802
[22:14:10.419] iteration 5326 : model1 loss : 0.263882 model2 loss : 0.286319
[22:14:10.752] iteration 5327 : model1 loss : 0.291061 model2 loss : 0.234530
[22:14:11.085] iteration 5328 : model1 loss : 0.234303 model2 loss : 0.245558
[22:14:11.419] iteration 5329 : model1 loss : 0.206745 model2 loss : 0.218090
[22:14:11.757] iteration 5330 : model1 loss : 0.215335 model2 loss : 0.220899
[22:14:12.093] iteration 5331 : model1 loss : 0.336685 model2 loss : 0.301973
[22:14:12.430] iteration 5332 : model1 loss : 0.301857 model2 loss : 0.273958
[22:14:12.767] iteration 5333 : model1 loss : 0.366989 model2 loss : 0.403162
[22:14:13.099] iteration 5334 : model1 loss : 0.285794 model2 loss : 0.284563
[22:14:13.432] iteration 5335 : model1 loss : 0.344715 model2 loss : 0.279436
[22:14:13.766] iteration 5336 : model1 loss : 0.419385 model2 loss : 0.432229
[22:14:14.095] iteration 5337 : model1 loss : 0.294578 model2 loss : 0.339685
[22:14:14.424] iteration 5338 : model1 loss : 0.348553 model2 loss : 0.358027
[22:14:14.753] iteration 5339 : model1 loss : 0.293415 model2 loss : 0.281297
[22:14:15.082] iteration 5340 : model1 loss : 0.329514 model2 loss : 0.357183
[22:14:15.413] iteration 5341 : model1 loss : 0.261193 model2 loss : 0.267006
[22:14:15.741] iteration 5342 : model1 loss : 0.203372 model2 loss : 0.169456
[22:14:16.070] iteration 5343 : model1 loss : 0.302942 model2 loss : 0.264609
[22:14:16.399] iteration 5344 : model1 loss : 0.306130 model2 loss : 0.271707
[22:14:16.728] iteration 5345 : model1 loss : 0.317222 model2 loss : 0.304651
[22:14:17.057] iteration 5346 : model1 loss : 0.305462 model2 loss : 0.276205
[22:14:17.386] iteration 5347 : model1 loss : 0.294559 model2 loss : 0.309881
[22:14:17.716] iteration 5348 : model1 loss : 0.257145 model2 loss : 0.234520
[22:14:18.045] iteration 5349 : model1 loss : 0.347006 model2 loss : 0.321970
[22:14:18.374] iteration 5350 : model1 loss : 0.380873 model2 loss : 0.289948
[22:14:18.919] iteration 5351 : model1 loss : 0.260501 model2 loss : 0.223588
[22:14:19.250] iteration 5352 : model1 loss : 0.313239 model2 loss : 0.293405
[22:14:19.579] iteration 5353 : model1 loss : 0.186062 model2 loss : 0.203168
[22:14:19.907] iteration 5354 : model1 loss : 0.234287 model2 loss : 0.240703
[22:14:20.236] iteration 5355 : model1 loss : 0.182618 model2 loss : 0.218589
[22:14:20.564] iteration 5356 : model1 loss : 0.299061 model2 loss : 0.294515
[22:14:20.893] iteration 5357 : model1 loss : 0.314977 model2 loss : 0.282733
[22:14:21.226] iteration 5358 : model1 loss : 0.275789 model2 loss : 0.296882
[22:14:21.555] iteration 5359 : model1 loss : 0.305218 model2 loss : 0.377646
[22:14:21.883] iteration 5360 : model1 loss : 0.276499 model2 loss : 0.340211
[22:14:22.212] iteration 5361 : model1 loss : 0.289027 model2 loss : 0.281584
[22:14:22.541] iteration 5362 : model1 loss : 0.312574 model2 loss : 0.350955
[22:14:22.874] iteration 5363 : model1 loss : 0.296555 model2 loss : 0.351955
[22:14:23.202] iteration 5364 : model1 loss : 0.323623 model2 loss : 0.321203
[22:14:23.535] iteration 5365 : model1 loss : 0.426392 model2 loss : 0.432238
[22:14:23.864] iteration 5366 : model1 loss : 0.225274 model2 loss : 0.209378
[22:14:24.193] iteration 5367 : model1 loss : 0.336057 model2 loss : 0.288510
[22:14:24.522] iteration 5368 : model1 loss : 0.325658 model2 loss : 0.235848
[22:14:24.851] iteration 5369 : model1 loss : 0.198122 model2 loss : 0.154041
[22:14:25.180] iteration 5370 : model1 loss : 0.225048 model2 loss : 0.228053
[22:14:25.513] iteration 5371 : model1 loss : 0.287690 model2 loss : 0.282557
[22:14:25.842] iteration 5372 : model1 loss : 0.251986 model2 loss : 0.291352
[22:14:26.172] iteration 5373 : model1 loss : 0.294603 model2 loss : 0.314014
[22:14:26.501] iteration 5374 : model1 loss : 0.272742 model2 loss : 0.317731
[22:14:26.832] iteration 5375 : model1 loss : 0.210693 model2 loss : 0.213292
[22:14:27.162] iteration 5376 : model1 loss : 0.289998 model2 loss : 0.392089
[22:14:27.490] iteration 5377 : model1 loss : 0.327220 model2 loss : 0.297791
[22:14:27.819] iteration 5378 : model1 loss : 0.276563 model2 loss : 0.296330
[22:14:28.148] iteration 5379 : model1 loss : 0.261806 model2 loss : 0.218947
[22:14:28.478] iteration 5380 : model1 loss : 0.256370 model2 loss : 0.283875
[22:14:28.806] iteration 5381 : model1 loss : 0.273393 model2 loss : 0.259776
[22:14:29.135] iteration 5382 : model1 loss : 0.240492 model2 loss : 0.233110
[22:14:29.462] iteration 5383 : model1 loss : 0.208754 model2 loss : 0.194215
[22:14:29.787] iteration 5384 : model1 loss : 0.233788 model2 loss : 0.222246
[22:14:30.115] iteration 5385 : model1 loss : 0.240384 model2 loss : 0.240009
[22:14:30.443] iteration 5386 : model1 loss : 0.256826 model2 loss : 0.228363
[22:14:30.771] iteration 5387 : model1 loss : 0.392242 model2 loss : 0.361022
[22:14:31.098] iteration 5388 : model1 loss : 0.295957 model2 loss : 0.216299
[22:14:31.424] iteration 5389 : model1 loss : 0.250388 model2 loss : 0.333329
[22:14:31.748] iteration 5390 : model1 loss : 0.212137 model2 loss : 0.169138
[22:14:32.075] iteration 5391 : model1 loss : 0.168699 model2 loss : 0.157543
[22:14:32.403] iteration 5392 : model1 loss : 0.242762 model2 loss : 0.257490
[22:14:32.727] iteration 5393 : model1 loss : 0.326327 model2 loss : 0.330941
[22:14:33.054] iteration 5394 : model1 loss : 0.346096 model2 loss : 0.305116
[22:14:33.382] iteration 5395 : model1 loss : 0.400419 model2 loss : 0.401152
[22:14:33.710] iteration 5396 : model1 loss : 0.291370 model2 loss : 0.269739
[22:14:34.035] iteration 5397 : model1 loss : 0.299077 model2 loss : 0.294080
[22:14:34.359] iteration 5398 : model1 loss : 0.237206 model2 loss : 0.241806
[22:14:34.684] iteration 5399 : model1 loss : 0.269755 model2 loss : 0.210040
[22:14:35.012] iteration 5400 : model1 loss : 0.214671 model2 loss : 0.232307
[22:14:35.654] iteration 5401 : model1 loss : 0.340339 model2 loss : 0.311799
[22:14:35.995] iteration 5402 : model1 loss : 0.227830 model2 loss : 0.254607
[22:14:36.334] iteration 5403 : model1 loss : 0.290386 model2 loss : 0.253714
[22:14:36.673] iteration 5404 : model1 loss : 0.264352 model2 loss : 0.286420
[22:14:37.009] iteration 5405 : model1 loss : 0.302200 model2 loss : 0.281638
[22:14:37.343] iteration 5406 : model1 loss : 0.338703 model2 loss : 0.233496
[22:14:37.677] iteration 5407 : model1 loss : 0.256304 model2 loss : 0.233161
[22:14:38.010] iteration 5408 : model1 loss : 0.315109 model2 loss : 0.212114
[22:14:38.351] iteration 5409 : model1 loss : 0.324306 model2 loss : 0.309605
[22:14:38.689] iteration 5410 : model1 loss : 0.227408 model2 loss : 0.201645
[22:14:39.023] iteration 5411 : model1 loss : 0.183838 model2 loss : 0.198034
[22:14:39.356] iteration 5412 : model1 loss : 0.271632 model2 loss : 0.271241
[22:14:39.693] iteration 5413 : model1 loss : 0.262779 model2 loss : 0.236499
[22:14:40.027] iteration 5414 : model1 loss : 0.318988 model2 loss : 0.318056
[22:14:40.360] iteration 5415 : model1 loss : 0.410038 model2 loss : 0.255503
[22:14:40.698] iteration 5416 : model1 loss : 0.400983 model2 loss : 0.364143
[22:14:41.033] iteration 5417 : model1 loss : 0.205909 model2 loss : 0.207333
[22:14:41.367] iteration 5418 : model1 loss : 0.274363 model2 loss : 0.285886
[22:14:41.695] iteration 5419 : model1 loss : 0.220924 model2 loss : 0.237563
[22:14:42.021] iteration 5420 : model1 loss : 0.217953 model2 loss : 0.267922
[22:14:42.346] iteration 5421 : model1 loss : 0.277503 model2 loss : 0.302967
[22:14:42.672] iteration 5422 : model1 loss : 0.322944 model2 loss : 0.319191
[22:14:42.997] iteration 5423 : model1 loss : 0.312375 model2 loss : 0.316907
[22:14:43.326] iteration 5424 : model1 loss : 0.226262 model2 loss : 0.220067
[22:14:43.656] iteration 5425 : model1 loss : 0.284974 model2 loss : 0.274389
[22:14:43.983] iteration 5426 : model1 loss : 0.306941 model2 loss : 0.274854
[22:14:44.312] iteration 5427 : model1 loss : 0.329047 model2 loss : 0.338083
[22:14:44.636] iteration 5428 : model1 loss : 0.284983 model2 loss : 0.227835
[22:14:44.967] iteration 5429 : model1 loss : 0.327427 model2 loss : 0.232711
[22:14:45.296] iteration 5430 : model1 loss : 0.351723 model2 loss : 0.336599
[22:14:45.625] iteration 5431 : model1 loss : 0.219392 model2 loss : 0.269389
[22:14:45.954] iteration 5432 : model1 loss : 0.404586 model2 loss : 0.360206
[22:14:46.293] iteration 5433 : model1 loss : 0.313292 model2 loss : 0.264032
[22:14:46.627] iteration 5434 : model1 loss : 0.260187 model2 loss : 0.243472
[22:14:46.961] iteration 5435 : model1 loss : 0.366429 model2 loss : 0.353909
[22:14:47.296] iteration 5436 : model1 loss : 0.281650 model2 loss : 0.231623
[22:14:47.640] iteration 5437 : model1 loss : 0.242565 model2 loss : 0.222013
[22:14:47.988] iteration 5438 : model1 loss : 0.300288 model2 loss : 0.254590
[22:14:48.326] iteration 5439 : model1 loss : 0.337374 model2 loss : 0.314298
[22:14:48.662] iteration 5440 : model1 loss : 0.203661 model2 loss : 0.234368
[22:14:48.995] iteration 5441 : model1 loss : 0.295159 model2 loss : 0.295075
[22:14:49.328] iteration 5442 : model1 loss : 0.278782 model2 loss : 0.234298
[22:14:49.666] iteration 5443 : model1 loss : 0.353121 model2 loss : 0.350583
[22:14:50.004] iteration 5444 : model1 loss : 0.321044 model2 loss : 0.300559
[22:14:50.336] iteration 5445 : model1 loss : 0.415494 model2 loss : 0.418021
[22:14:50.674] iteration 5446 : model1 loss : 0.325807 model2 loss : 0.333159
[22:14:51.011] iteration 5447 : model1 loss : 0.218753 model2 loss : 0.195654
[22:14:51.345] iteration 5448 : model1 loss : 0.316285 model2 loss : 0.329485
[22:14:51.679] iteration 5449 : model1 loss : 0.285466 model2 loss : 0.326933
[22:14:52.012] iteration 5450 : model1 loss : 0.249640 model2 loss : 0.278634
[22:14:53.374] iteration 5451 : model1 loss : 0.327049 model2 loss : 0.393753
[22:14:53.708] iteration 5452 : model1 loss : 0.294378 model2 loss : 0.303677
[22:14:54.042] iteration 5453 : model1 loss : 0.134558 model2 loss : 0.203855
[22:14:54.380] iteration 5454 : model1 loss : 0.363426 model2 loss : 0.356575
[22:14:54.715] iteration 5455 : model1 loss : 0.332342 model2 loss : 0.314102
[22:14:55.049] iteration 5456 : model1 loss : 0.146171 model2 loss : 0.169133
[22:14:55.386] iteration 5457 : model1 loss : 0.267688 model2 loss : 0.280846
[22:14:55.724] iteration 5458 : model1 loss : 0.256785 model2 loss : 0.238467
[22:14:56.060] iteration 5459 : model1 loss : 0.310365 model2 loss : 0.321082
[22:14:56.387] iteration 5460 : model1 loss : 0.248369 model2 loss : 0.269139
[22:14:56.715] iteration 5461 : model1 loss : 0.289953 model2 loss : 0.294399
[22:14:57.040] iteration 5462 : model1 loss : 0.246832 model2 loss : 0.249211
[22:14:57.366] iteration 5463 : model1 loss : 0.249668 model2 loss : 0.275505
[22:14:57.691] iteration 5464 : model1 loss : 0.142288 model2 loss : 0.174550
[22:14:58.017] iteration 5465 : model1 loss : 0.304105 model2 loss : 0.287581
[22:14:58.353] iteration 5466 : model1 loss : 0.289879 model2 loss : 0.308799
[22:14:58.688] iteration 5467 : model1 loss : 0.209996 model2 loss : 0.234018
[22:14:59.025] iteration 5468 : model1 loss : 0.277920 model2 loss : 0.280017
[22:14:59.359] iteration 5469 : model1 loss : 0.289630 model2 loss : 0.343289
[22:14:59.694] iteration 5470 : model1 loss : 0.285386 model2 loss : 0.274211
[22:15:00.030] iteration 5471 : model1 loss : 0.322897 model2 loss : 0.342235
[22:15:00.367] iteration 5472 : model1 loss : 0.301436 model2 loss : 0.254758
[22:15:00.706] iteration 5473 : model1 loss : 0.298452 model2 loss : 0.336263
[22:15:01.040] iteration 5474 : model1 loss : 0.310468 model2 loss : 0.274612
[22:15:01.372] iteration 5475 : model1 loss : 0.321219 model2 loss : 0.296008
[22:15:01.693] iteration 5476 : model1 loss : 0.347783 model2 loss : 0.310258
[22:15:02.016] iteration 5477 : model1 loss : 0.179197 model2 loss : 0.206972
[22:15:02.344] iteration 5478 : model1 loss : 0.121913 model2 loss : 0.247914
[22:15:02.669] iteration 5479 : model1 loss : 0.209964 model2 loss : 0.225739
[22:15:02.993] iteration 5480 : model1 loss : 0.199720 model2 loss : 0.278626
[22:15:03.320] iteration 5481 : model1 loss : 0.222236 model2 loss : 0.250578
[22:15:03.643] iteration 5482 : model1 loss : 0.378339 model2 loss : 0.414485
[22:15:03.971] iteration 5483 : model1 loss : 0.298932 model2 loss : 0.296753
[22:15:04.300] iteration 5484 : model1 loss : 0.272826 model2 loss : 0.281565
[22:15:04.627] iteration 5485 : model1 loss : 0.198638 model2 loss : 0.237655
[22:15:04.960] iteration 5486 : model1 loss : 0.216693 model2 loss : 0.222679
[22:15:05.290] iteration 5487 : model1 loss : 0.272660 model2 loss : 0.266929
[22:15:05.619] iteration 5488 : model1 loss : 0.205764 model2 loss : 0.191138
[22:15:05.948] iteration 5489 : model1 loss : 0.372728 model2 loss : 0.349822
[22:15:06.279] iteration 5490 : model1 loss : 0.149950 model2 loss : 0.205956
[22:15:06.609] iteration 5491 : model1 loss : 0.216462 model2 loss : 0.297671
[22:15:06.939] iteration 5492 : model1 loss : 0.328932 model2 loss : 0.266557
[22:15:07.268] iteration 5493 : model1 loss : 0.425014 model2 loss : 0.368159
[22:15:07.597] iteration 5494 : model1 loss : 0.257928 model2 loss : 0.244658
[22:15:07.927] iteration 5495 : model1 loss : 0.279951 model2 loss : 0.300174
[22:15:08.256] iteration 5496 : model1 loss : 0.411831 model2 loss : 0.391869
[22:15:08.585] iteration 5497 : model1 loss : 0.282077 model2 loss : 0.298798
[22:15:08.914] iteration 5498 : model1 loss : 0.265049 model2 loss : 0.280982
[22:15:09.244] iteration 5499 : model1 loss : 0.308707 model2 loss : 0.311509
[22:15:09.573] iteration 5500 : model1 loss : 0.158166 model2 loss : 0.207849
[22:15:10.125] iteration 5501 : model1 loss : 0.257749 model2 loss : 0.259470
[22:15:10.454] iteration 5502 : model1 loss : 0.248400 model2 loss : 0.257597
[22:15:10.783] iteration 5503 : model1 loss : 0.280030 model2 loss : 0.268205
[22:15:11.112] iteration 5504 : model1 loss : 0.140526 model2 loss : 0.181114
[22:15:11.441] iteration 5505 : model1 loss : 0.204734 model2 loss : 0.216519
[22:15:11.770] iteration 5506 : model1 loss : 0.321500 model2 loss : 0.324143
[22:15:12.100] iteration 5507 : model1 loss : 0.387624 model2 loss : 0.376138
[22:15:12.429] iteration 5508 : model1 loss : 0.193910 model2 loss : 0.203451
[22:15:12.758] iteration 5509 : model1 loss : 0.296234 model2 loss : 0.306431
[22:15:13.087] iteration 5510 : model1 loss : 0.266329 model2 loss : 0.300415
[22:15:13.416] iteration 5511 : model1 loss : 0.304953 model2 loss : 0.329566
[22:15:13.745] iteration 5512 : model1 loss : 0.358468 model2 loss : 0.326227
[22:15:14.074] iteration 5513 : model1 loss : 0.259492 model2 loss : 0.238748
[22:15:14.403] iteration 5514 : model1 loss : 0.226175 model2 loss : 0.273652
[22:15:14.732] iteration 5515 : model1 loss : 0.278044 model2 loss : 0.303955
[22:15:15.061] iteration 5516 : model1 loss : 0.351504 model2 loss : 0.403842
[22:15:15.390] iteration 5517 : model1 loss : 0.287319 model2 loss : 0.296643
[22:15:15.719] iteration 5518 : model1 loss : 0.260217 model2 loss : 0.308590
[22:15:16.050] iteration 5519 : model1 loss : 0.204422 model2 loss : 0.244581
[22:15:16.378] iteration 5520 : model1 loss : 0.329924 model2 loss : 0.327802
[22:15:16.707] iteration 5521 : model1 loss : 0.188037 model2 loss : 0.204764
[22:15:17.036] iteration 5522 : model1 loss : 0.373935 model2 loss : 0.306480
[22:15:17.365] iteration 5523 : model1 loss : 0.387580 model2 loss : 0.413172
[22:15:17.695] iteration 5524 : model1 loss : 0.177588 model2 loss : 0.205914
[22:15:18.023] iteration 5525 : model1 loss : 0.166141 model2 loss : 0.175264
[22:15:18.353] iteration 5526 : model1 loss : 0.274464 model2 loss : 0.259644
[22:15:18.684] iteration 5527 : model1 loss : 0.284876 model2 loss : 0.238024
[22:15:19.012] iteration 5528 : model1 loss : 0.291844 model2 loss : 0.329040
[22:15:19.342] iteration 5529 : model1 loss : 0.364341 model2 loss : 0.366281
[22:15:19.671] iteration 5530 : model1 loss : 0.295050 model2 loss : 0.388625
[22:15:20.000] iteration 5531 : model1 loss : 0.334784 model2 loss : 0.294946
[22:15:20.330] iteration 5532 : model1 loss : 0.227049 model2 loss : 0.237155
[22:15:20.660] iteration 5533 : model1 loss : 0.282607 model2 loss : 0.317965
[22:15:20.989] iteration 5534 : model1 loss : 0.145542 model2 loss : 0.230368
[22:15:21.318] iteration 5535 : model1 loss : 0.287177 model2 loss : 0.308725
[22:15:21.647] iteration 5536 : model1 loss : 0.219993 model2 loss : 0.206482
[22:15:21.976] iteration 5537 : model1 loss : 0.343600 model2 loss : 0.326926
[22:15:22.306] iteration 5538 : model1 loss : 0.196227 model2 loss : 0.231626
[22:15:22.635] iteration 5539 : model1 loss : 0.284371 model2 loss : 0.232449
[22:15:22.964] iteration 5540 : model1 loss : 0.312092 model2 loss : 0.324745
[22:15:23.291] iteration 5541 : model1 loss : 0.271518 model2 loss : 0.250222
[22:15:23.618] iteration 5542 : model1 loss : 0.255387 model2 loss : 0.293466
[22:15:23.946] iteration 5543 : model1 loss : 0.362472 model2 loss : 0.329239
[22:15:24.274] iteration 5544 : model1 loss : 0.225693 model2 loss : 0.229571
[22:15:24.602] iteration 5545 : model1 loss : 0.349873 model2 loss : 0.377159
[22:15:24.933] iteration 5546 : model1 loss : 0.286860 model2 loss : 0.276135
[22:15:25.261] iteration 5547 : model1 loss : 0.338552 model2 loss : 0.370092
[22:15:25.592] iteration 5548 : model1 loss : 0.300025 model2 loss : 0.291812
[22:15:25.920] iteration 5549 : model1 loss : 0.288079 model2 loss : 0.345636
[22:15:26.248] iteration 5550 : model1 loss : 0.210839 model2 loss : 0.218999
[22:15:26.755] iteration 5551 : model1 loss : 0.296666 model2 loss : 0.228996
[22:15:27.083] iteration 5552 : model1 loss : 0.291593 model2 loss : 0.260831
[22:15:27.411] iteration 5553 : model1 loss : 0.170180 model2 loss : 0.269371
[22:15:27.737] iteration 5554 : model1 loss : 0.305037 model2 loss : 0.240027
[22:15:28.067] iteration 5555 : model1 loss : 0.284619 model2 loss : 0.246198
[22:15:28.395] iteration 5556 : model1 loss : 0.266419 model2 loss : 0.209038
[22:15:28.728] iteration 5557 : model1 loss : 0.194128 model2 loss : 0.207478
[22:15:29.057] iteration 5558 : model1 loss : 0.285898 model2 loss : 0.293705
[22:15:29.387] iteration 5559 : model1 loss : 0.366821 model2 loss : 0.285167
[22:15:29.716] iteration 5560 : model1 loss : 0.128959 model2 loss : 0.217164
[22:15:30.049] iteration 5561 : model1 loss : 0.223807 model2 loss : 0.275080
[22:15:30.377] iteration 5562 : model1 loss : 0.335709 model2 loss : 0.413641
[22:15:30.707] iteration 5563 : model1 loss : 0.212453 model2 loss : 0.298219
[22:15:31.038] iteration 5564 : model1 loss : 0.266479 model2 loss : 0.223138
[22:15:31.371] iteration 5565 : model1 loss : 0.238312 model2 loss : 0.227564
[22:15:31.700] iteration 5566 : model1 loss : 0.279324 model2 loss : 0.300242
[22:15:32.034] iteration 5567 : model1 loss : 0.299410 model2 loss : 0.280467
[22:15:32.364] iteration 5568 : model1 loss : 0.279302 model2 loss : 0.318489
[22:15:32.694] iteration 5569 : model1 loss : 0.262130 model2 loss : 0.249786
[22:15:33.023] iteration 5570 : model1 loss : 0.177393 model2 loss : 0.241829
[22:15:33.352] iteration 5571 : model1 loss : 0.260838 model2 loss : 0.200163
[22:15:33.682] iteration 5572 : model1 loss : 0.252756 model2 loss : 0.258987
[22:15:34.011] iteration 5573 : model1 loss : 0.291230 model2 loss : 0.268387
[22:15:34.340] iteration 5574 : model1 loss : 0.290634 model2 loss : 0.278490
[22:15:34.669] iteration 5575 : model1 loss : 0.243488 model2 loss : 0.286781
[22:15:34.999] iteration 5576 : model1 loss : 0.382029 model2 loss : 0.334230
[22:15:35.327] iteration 5577 : model1 loss : 0.332989 model2 loss : 0.289980
[22:15:35.656] iteration 5578 : model1 loss : 0.400677 model2 loss : 0.421617
[22:15:35.986] iteration 5579 : model1 loss : 0.318144 model2 loss : 0.342427
[22:15:36.315] iteration 5580 : model1 loss : 0.211136 model2 loss : 0.178179
[22:15:36.643] iteration 5581 : model1 loss : 0.296644 model2 loss : 0.303407
[22:15:36.972] iteration 5582 : model1 loss : 0.286414 model2 loss : 0.300199
[22:15:37.303] iteration 5583 : model1 loss : 0.348737 model2 loss : 0.357534
[22:15:37.630] iteration 5584 : model1 loss : 0.215123 model2 loss : 0.215479
[22:15:37.958] iteration 5585 : model1 loss : 0.273448 model2 loss : 0.319571
[22:15:38.286] iteration 5586 : model1 loss : 0.279184 model2 loss : 0.273511
[22:15:38.613] iteration 5587 : model1 loss : 0.275468 model2 loss : 0.318242
[22:15:38.940] iteration 5588 : model1 loss : 0.190007 model2 loss : 0.284770
[22:15:39.267] iteration 5589 : model1 loss : 0.321752 model2 loss : 0.327985
[22:15:39.594] iteration 5590 : model1 loss : 0.273571 model2 loss : 0.299918
[22:15:39.922] iteration 5591 : model1 loss : 0.250862 model2 loss : 0.283331
[22:15:40.250] iteration 5592 : model1 loss : 0.314533 model2 loss : 0.414876
[22:15:40.577] iteration 5593 : model1 loss : 0.291461 model2 loss : 0.248580
[22:15:40.904] iteration 5594 : model1 loss : 0.275178 model2 loss : 0.203952
[22:15:41.232] iteration 5595 : model1 loss : 0.338718 model2 loss : 0.302016
[22:15:41.559] iteration 5596 : model1 loss : 0.270629 model2 loss : 0.309994
[22:15:41.887] iteration 5597 : model1 loss : 0.250917 model2 loss : 0.258885
[22:15:42.214] iteration 5598 : model1 loss : 0.309717 model2 loss : 0.292651
[22:15:42.542] iteration 5599 : model1 loss : 0.276355 model2 loss : 0.337589
[22:15:42.870] iteration 5600 : model1 loss : 0.150784 model2 loss : 0.170633
[22:15:43.423] iteration 5601 : model1 loss : 0.281019 model2 loss : 0.261926
[22:15:43.751] iteration 5602 : model1 loss : 0.288726 model2 loss : 0.295117
[22:15:44.078] iteration 5603 : model1 loss : 0.244428 model2 loss : 0.287123
[22:15:44.405] iteration 5604 : model1 loss : 0.301786 model2 loss : 0.305557
[22:15:44.733] iteration 5605 : model1 loss : 0.250733 model2 loss : 0.243002
[22:15:45.062] iteration 5606 : model1 loss : 0.237921 model2 loss : 0.256476
[22:15:45.390] iteration 5607 : model1 loss : 0.172576 model2 loss : 0.193047
[22:15:45.718] iteration 5608 : model1 loss : 0.280747 model2 loss : 0.253750
[22:15:46.046] iteration 5609 : model1 loss : 0.297985 model2 loss : 0.365313
[22:15:46.375] iteration 5610 : model1 loss : 0.297393 model2 loss : 0.372304
[22:15:46.703] iteration 5611 : model1 loss : 0.298445 model2 loss : 0.310374
[22:15:47.030] iteration 5612 : model1 loss : 0.341279 model2 loss : 0.240600
[22:15:47.359] iteration 5613 : model1 loss : 0.290193 model2 loss : 0.218836
[22:15:47.687] iteration 5614 : model1 loss : 0.234484 model2 loss : 0.261030
[22:15:48.014] iteration 5615 : model1 loss : 0.255070 model2 loss : 0.273384
[22:15:48.340] iteration 5616 : model1 loss : 0.344910 model2 loss : 0.397228
[22:15:48.669] iteration 5617 : model1 loss : 0.466848 model2 loss : 0.324415
[22:15:48.998] iteration 5618 : model1 loss : 0.243805 model2 loss : 0.276050
[22:15:49.324] iteration 5619 : model1 loss : 0.305756 model2 loss : 0.324249
[22:15:49.651] iteration 5620 : model1 loss : 0.230841 model2 loss : 0.269388
[22:15:49.979] iteration 5621 : model1 loss : 0.310850 model2 loss : 0.284356
[22:15:50.308] iteration 5622 : model1 loss : 0.281767 model2 loss : 0.282841
[22:15:50.635] iteration 5623 : model1 loss : 0.315449 model2 loss : 0.324534
[22:15:50.963] iteration 5624 : model1 loss : 0.291741 model2 loss : 0.296028
[22:15:51.290] iteration 5625 : model1 loss : 0.292238 model2 loss : 0.331348
[22:15:51.618] iteration 5626 : model1 loss : 0.199288 model2 loss : 0.268456
[22:15:51.948] iteration 5627 : model1 loss : 0.207853 model2 loss : 0.260396
[22:15:52.276] iteration 5628 : model1 loss : 0.239428 model2 loss : 0.220616
[22:15:52.604] iteration 5629 : model1 loss : 0.304867 model2 loss : 0.341292
[22:15:52.932] iteration 5630 : model1 loss : 0.286628 model2 loss : 0.247044
[22:15:53.260] iteration 5631 : model1 loss : 0.258739 model2 loss : 0.273418
[22:15:53.587] iteration 5632 : model1 loss : 0.209957 model2 loss : 0.243685
[22:15:53.914] iteration 5633 : model1 loss : 0.176899 model2 loss : 0.208277
[22:15:54.242] iteration 5634 : model1 loss : 0.392915 model2 loss : 0.392635
[22:15:54.569] iteration 5635 : model1 loss : 0.204957 model2 loss : 0.218622
[22:15:54.903] iteration 5636 : model1 loss : 0.212700 model2 loss : 0.216680
[22:15:55.232] iteration 5637 : model1 loss : 0.254767 model2 loss : 0.210349
[22:15:55.560] iteration 5638 : model1 loss : 0.365892 model2 loss : 0.367199
[22:15:55.890] iteration 5639 : model1 loss : 0.205856 model2 loss : 0.188781
[22:15:56.219] iteration 5640 : model1 loss : 0.207736 model2 loss : 0.171973
[22:15:56.548] iteration 5641 : model1 loss : 0.220387 model2 loss : 0.259588
[22:15:56.878] iteration 5642 : model1 loss : 0.175289 model2 loss : 0.232987
[22:15:57.206] iteration 5643 : model1 loss : 0.281352 model2 loss : 0.248084
[22:15:57.538] iteration 5644 : model1 loss : 0.374204 model2 loss : 0.286928
[22:15:57.868] iteration 5645 : model1 loss : 0.306806 model2 loss : 0.301896
[22:15:58.197] iteration 5646 : model1 loss : 0.352867 model2 loss : 0.275281
[22:15:58.527] iteration 5647 : model1 loss : 0.271980 model2 loss : 0.237320
[22:15:58.856] iteration 5648 : model1 loss : 0.187413 model2 loss : 0.214897
[22:15:59.189] iteration 5649 : model1 loss : 0.340644 model2 loss : 0.300028
[22:15:59.518] iteration 5650 : model1 loss : 0.176975 model2 loss : 0.173928
[22:16:00.086] iteration 5651 : model1 loss : 0.228719 model2 loss : 0.227338
[22:16:00.415] iteration 5652 : model1 loss : 0.187808 model2 loss : 0.188887
[22:16:00.745] iteration 5653 : model1 loss : 0.253781 model2 loss : 0.303756
[22:16:01.074] iteration 5654 : model1 loss : 0.238080 model2 loss : 0.230927
[22:16:01.403] iteration 5655 : model1 loss : 0.249233 model2 loss : 0.275410
[22:16:01.732] iteration 5656 : model1 loss : 0.344582 model2 loss : 0.325610
[22:16:02.062] iteration 5657 : model1 loss : 0.202373 model2 loss : 0.265276
[22:16:02.392] iteration 5658 : model1 loss : 0.175337 model2 loss : 0.191251
[22:16:02.721] iteration 5659 : model1 loss : 0.286279 model2 loss : 0.330949
[22:16:03.050] iteration 5660 : model1 loss : 0.297279 model2 loss : 0.349993
[22:16:03.379] iteration 5661 : model1 loss : 0.178159 model2 loss : 0.195784
[22:16:03.708] iteration 5662 : model1 loss : 0.257610 model2 loss : 0.248326
[22:16:04.037] iteration 5663 : model1 loss : 0.304875 model2 loss : 0.255843
[22:16:04.368] iteration 5664 : model1 loss : 0.189618 model2 loss : 0.159765
[22:16:04.699] iteration 5665 : model1 loss : 0.348164 model2 loss : 0.320837
[22:16:05.028] iteration 5666 : model1 loss : 0.273352 model2 loss : 0.243131
[22:16:05.357] iteration 5667 : model1 loss : 0.236120 model2 loss : 0.247132
[22:16:05.685] iteration 5668 : model1 loss : 0.206799 model2 loss : 0.260841
[22:16:06.014] iteration 5669 : model1 loss : 0.234647 model2 loss : 0.170203
[22:16:06.343] iteration 5670 : model1 loss : 0.421564 model2 loss : 0.345705
[22:16:06.672] iteration 5671 : model1 loss : 0.277249 model2 loss : 0.268196
[22:16:07.000] iteration 5672 : model1 loss : 0.307525 model2 loss : 0.290715
[22:16:07.330] iteration 5673 : model1 loss : 0.221164 model2 loss : 0.228956
[22:16:07.658] iteration 5674 : model1 loss : 0.209634 model2 loss : 0.287495
[22:16:07.987] iteration 5675 : model1 loss : 0.150526 model2 loss : 0.169608
[22:16:08.316] iteration 5676 : model1 loss : 0.345232 model2 loss : 0.332924
[22:16:08.645] iteration 5677 : model1 loss : 0.246808 model2 loss : 0.231356
[22:16:08.974] iteration 5678 : model1 loss : 0.137405 model2 loss : 0.143265
[22:16:09.301] iteration 5679 : model1 loss : 0.329247 model2 loss : 0.371872
[22:16:09.631] iteration 5680 : model1 loss : 0.244817 model2 loss : 0.237378
[22:16:09.959] iteration 5681 : model1 loss : 0.319973 model2 loss : 0.347712
[22:16:10.287] iteration 5682 : model1 loss : 0.323903 model2 loss : 0.348941
[22:16:10.614] iteration 5683 : model1 loss : 0.144218 model2 loss : 0.150916
[22:16:10.942] iteration 5684 : model1 loss : 0.357822 model2 loss : 0.336375
[22:16:11.269] iteration 5685 : model1 loss : 0.320403 model2 loss : 0.307299
[22:16:11.596] iteration 5686 : model1 loss : 0.377552 model2 loss : 0.394237
[22:16:11.923] iteration 5687 : model1 loss : 0.248952 model2 loss : 0.255684
[22:16:12.256] iteration 5688 : model1 loss : 0.273113 model2 loss : 0.303093
[22:16:12.586] iteration 5689 : model1 loss : 0.204938 model2 loss : 0.218574
[22:16:12.913] iteration 5690 : model1 loss : 0.218438 model2 loss : 0.334359
[22:16:13.241] iteration 5691 : model1 loss : 0.263003 model2 loss : 0.238027
[22:16:13.569] iteration 5692 : model1 loss : 0.204840 model2 loss : 0.236247
[22:16:13.895] iteration 5693 : model1 loss : 0.405733 model2 loss : 0.365992
[22:16:14.222] iteration 5694 : model1 loss : 0.217812 model2 loss : 0.163118
[22:16:14.553] iteration 5695 : model1 loss : 0.242159 model2 loss : 0.238123
[22:16:14.881] iteration 5696 : model1 loss : 0.269480 model2 loss : 0.293763
[22:16:15.210] iteration 5697 : model1 loss : 0.219894 model2 loss : 0.238927
[22:16:15.536] iteration 5698 : model1 loss : 0.148868 model2 loss : 0.238880
[22:16:15.865] iteration 5699 : model1 loss : 0.251962 model2 loss : 0.267837
[22:16:16.193] iteration 5700 : model1 loss : 0.380191 model2 loss : 0.268986
[22:16:16.761] iteration 5701 : model1 loss : 0.365220 model2 loss : 0.358108
[22:16:17.088] iteration 5702 : model1 loss : 0.253906 model2 loss : 0.327906
[22:16:17.416] iteration 5703 : model1 loss : 0.286671 model2 loss : 0.239358
[22:16:17.744] iteration 5704 : model1 loss : 0.239242 model2 loss : 0.223226
[22:16:18.072] iteration 5705 : model1 loss : 0.148701 model2 loss : 0.147893
[22:16:18.400] iteration 5706 : model1 loss : 0.371046 model2 loss : 0.287413
[22:16:18.727] iteration 5707 : model1 loss : 0.385142 model2 loss : 0.378724
[22:16:19.055] iteration 5708 : model1 loss : 0.297852 model2 loss : 0.233106
[22:16:19.384] iteration 5709 : model1 loss : 0.401293 model2 loss : 0.348274
[22:16:19.716] iteration 5710 : model1 loss : 0.241145 model2 loss : 0.208612
[22:16:20.044] iteration 5711 : model1 loss : 0.230968 model2 loss : 0.264016
[22:16:20.374] iteration 5712 : model1 loss : 0.229903 model2 loss : 0.246051
[22:16:20.702] iteration 5713 : model1 loss : 0.282391 model2 loss : 0.311717
[22:16:21.029] iteration 5714 : model1 loss : 0.177865 model2 loss : 0.200383
[22:16:21.357] iteration 5715 : model1 loss : 0.290667 model2 loss : 0.322597
[22:16:21.685] iteration 5716 : model1 loss : 0.354116 model2 loss : 0.298237
[22:16:22.013] iteration 5717 : model1 loss : 0.275885 model2 loss : 0.314452
[22:16:22.357] iteration 5718 : model1 loss : 0.247596 model2 loss : 0.212876
[22:16:22.696] iteration 5719 : model1 loss : 0.205256 model2 loss : 0.181683
[22:16:23.036] iteration 5720 : model1 loss : 0.250184 model2 loss : 0.248606
[22:16:23.375] iteration 5721 : model1 loss : 0.336147 model2 loss : 0.330379
[22:16:23.713] iteration 5722 : model1 loss : 0.367804 model2 loss : 0.313604
[22:16:24.052] iteration 5723 : model1 loss : 0.247699 model2 loss : 0.294399
[22:16:24.392] iteration 5724 : model1 loss : 0.264664 model2 loss : 0.241568
[22:16:24.734] iteration 5725 : model1 loss : 0.222464 model2 loss : 0.237505
[22:16:25.073] iteration 5726 : model1 loss : 0.272161 model2 loss : 0.286110
[22:16:25.412] iteration 5727 : model1 loss : 0.262119 model2 loss : 0.246396
[22:16:25.750] iteration 5728 : model1 loss : 0.310191 model2 loss : 0.282607
[22:16:26.089] iteration 5729 : model1 loss : 0.308689 model2 loss : 0.265356
[22:16:26.427] iteration 5730 : model1 loss : 0.225391 model2 loss : 0.258029
[22:16:26.766] iteration 5731 : model1 loss : 0.309562 model2 loss : 0.283137
[22:16:27.106] iteration 5732 : model1 loss : 0.374868 model2 loss : 0.374121
[22:16:27.445] iteration 5733 : model1 loss : 0.211269 model2 loss : 0.248608
[22:16:27.783] iteration 5734 : model1 loss : 0.210882 model2 loss : 0.192975
[22:16:28.122] iteration 5735 : model1 loss : 0.301775 model2 loss : 0.338114
[22:16:28.459] iteration 5736 : model1 loss : 0.277052 model2 loss : 0.284929
[22:16:28.797] iteration 5737 : model1 loss : 0.391934 model2 loss : 0.294880
[22:16:29.137] iteration 5738 : model1 loss : 0.191824 model2 loss : 0.248866
[22:16:29.474] iteration 5739 : model1 loss : 0.300151 model2 loss : 0.316797
[22:16:29.812] iteration 5740 : model1 loss : 0.367674 model2 loss : 0.265534
[22:16:30.152] iteration 5741 : model1 loss : 0.249368 model2 loss : 0.207160
[22:16:30.491] iteration 5742 : model1 loss : 0.181054 model2 loss : 0.205516
[22:16:30.829] iteration 5743 : model1 loss : 0.260951 model2 loss : 0.248314
[22:16:31.167] iteration 5744 : model1 loss : 0.300657 model2 loss : 0.298140
[22:16:31.511] iteration 5745 : model1 loss : 0.322240 model2 loss : 0.262468
[22:16:31.850] iteration 5746 : model1 loss : 0.290355 model2 loss : 0.291641
[22:16:32.190] iteration 5747 : model1 loss : 0.150783 model2 loss : 0.213681
[22:16:32.530] iteration 5748 : model1 loss : 0.274642 model2 loss : 0.300989
[22:16:32.870] iteration 5749 : model1 loss : 0.259035 model2 loss : 0.265110
[22:16:33.209] iteration 5750 : model1 loss : 0.307110 model2 loss : 0.252166
[22:16:33.857] iteration 5751 : model1 loss : 0.336462 model2 loss : 0.321072
[22:16:34.186] iteration 5752 : model1 loss : 0.291708 model2 loss : 0.234014
[22:16:34.512] iteration 5753 : model1 loss : 0.275510 model2 loss : 0.292515
[22:16:34.839] iteration 5754 : model1 loss : 0.288149 model2 loss : 0.265600
[22:16:35.166] iteration 5755 : model1 loss : 0.237987 model2 loss : 0.210318
[22:16:35.494] iteration 5756 : model1 loss : 0.297488 model2 loss : 0.270338
[22:16:35.818] iteration 5757 : model1 loss : 0.270133 model2 loss : 0.226925
[22:16:36.146] iteration 5758 : model1 loss : 0.233263 model2 loss : 0.181726
[22:16:36.474] iteration 5759 : model1 loss : 0.306673 model2 loss : 0.256641
[22:16:36.802] iteration 5760 : model1 loss : 0.340462 model2 loss : 0.354298
[22:16:37.131] iteration 5761 : model1 loss : 0.203721 model2 loss : 0.209791
[22:16:37.458] iteration 5762 : model1 loss : 0.387254 model2 loss : 0.342727
[22:16:37.785] iteration 5763 : model1 loss : 0.257164 model2 loss : 0.233052
[22:16:38.113] iteration 5764 : model1 loss : 0.168286 model2 loss : 0.159157
[22:16:38.441] iteration 5765 : model1 loss : 0.220684 model2 loss : 0.180717
[22:16:38.768] iteration 5766 : model1 loss : 0.297403 model2 loss : 0.217578
[22:16:39.098] iteration 5767 : model1 loss : 0.135912 model2 loss : 0.146516
[22:16:39.427] iteration 5768 : model1 loss : 0.224239 model2 loss : 0.296323
[22:16:39.751] iteration 5769 : model1 loss : 0.197540 model2 loss : 0.205821
[22:16:40.078] iteration 5770 : model1 loss : 0.310455 model2 loss : 0.289614
[22:16:40.406] iteration 5771 : model1 loss : 0.224701 model2 loss : 0.285205
[22:16:40.733] iteration 5772 : model1 loss : 0.273323 model2 loss : 0.227790
[22:16:41.056] iteration 5773 : model1 loss : 0.246386 model2 loss : 0.217303
[22:16:41.384] iteration 5774 : model1 loss : 0.186086 model2 loss : 0.239901
[22:16:41.711] iteration 5775 : model1 loss : 0.288019 model2 loss : 0.287311
[22:16:42.035] iteration 5776 : model1 loss : 0.342463 model2 loss : 0.297296
[22:16:42.362] iteration 5777 : model1 loss : 0.243023 model2 loss : 0.237698
[22:16:42.690] iteration 5778 : model1 loss : 0.329643 model2 loss : 0.336336
[22:16:43.017] iteration 5779 : model1 loss : 0.306242 model2 loss : 0.277975
[22:16:43.343] iteration 5780 : model1 loss : 0.337217 model2 loss : 0.262005
[22:16:43.670] iteration 5781 : model1 loss : 0.325145 model2 loss : 0.266310
[22:16:43.997] iteration 5782 : model1 loss : 0.344646 model2 loss : 0.311011
[22:16:44.324] iteration 5783 : model1 loss : 0.241050 model2 loss : 0.268660
[22:16:44.648] iteration 5784 : model1 loss : 0.228664 model2 loss : 0.248049
[22:16:44.975] iteration 5785 : model1 loss : 0.312262 model2 loss : 0.328376
[22:16:45.302] iteration 5786 : model1 loss : 0.294131 model2 loss : 0.279122
[22:16:45.630] iteration 5787 : model1 loss : 0.272228 model2 loss : 0.270609
[22:16:45.958] iteration 5788 : model1 loss : 0.234769 model2 loss : 0.243258
[22:16:46.285] iteration 5789 : model1 loss : 0.288391 model2 loss : 0.255056
[22:16:46.612] iteration 5790 : model1 loss : 0.305533 model2 loss : 0.201148
[22:16:46.936] iteration 5791 : model1 loss : 0.207188 model2 loss : 0.219299
[22:16:47.263] iteration 5792 : model1 loss : 0.157219 model2 loss : 0.162676
[22:16:47.590] iteration 5793 : model1 loss : 0.206116 model2 loss : 0.182766
[22:16:47.917] iteration 5794 : model1 loss : 0.232714 model2 loss : 0.207574
[22:16:48.240] iteration 5795 : model1 loss : 0.288564 model2 loss : 0.256735
[22:16:48.566] iteration 5796 : model1 loss : 0.255037 model2 loss : 0.245172
[22:16:48.889] iteration 5797 : model1 loss : 0.324243 model2 loss : 0.378756
[22:16:49.217] iteration 5798 : model1 loss : 0.199223 model2 loss : 0.296696
[22:16:49.547] iteration 5799 : model1 loss : 0.265314 model2 loss : 0.260596
[22:16:49.874] iteration 5800 : model1 loss : 0.229228 model2 loss : 0.217968
[22:16:50.435] iteration 5801 : model1 loss : 0.276790 model2 loss : 0.355363
[22:16:50.762] iteration 5802 : model1 loss : 0.276176 model2 loss : 0.252542
[22:16:51.089] iteration 5803 : model1 loss : 0.318372 model2 loss : 0.292053
[22:16:51.416] iteration 5804 : model1 loss : 0.259020 model2 loss : 0.270219
[22:16:51.743] iteration 5805 : model1 loss : 0.295873 model2 loss : 0.313900
[22:16:52.071] iteration 5806 : model1 loss : 0.385165 model2 loss : 0.372480
[22:16:52.397] iteration 5807 : model1 loss : 0.240239 model2 loss : 0.237474
[22:16:52.724] iteration 5808 : model1 loss : 0.197412 model2 loss : 0.217902
[22:16:53.046] iteration 5809 : model1 loss : 0.279062 model2 loss : 0.325853
[22:16:53.373] iteration 5810 : model1 loss : 0.338350 model2 loss : 0.335895
[22:16:53.696] iteration 5811 : model1 loss : 0.203738 model2 loss : 0.250255
[22:16:54.023] iteration 5812 : model1 loss : 0.258453 model2 loss : 0.332247
[22:16:54.353] iteration 5813 : model1 loss : 0.274622 model2 loss : 0.262495
[22:16:54.679] iteration 5814 : model1 loss : 0.361009 model2 loss : 0.394198
[22:16:55.006] iteration 5815 : model1 loss : 0.200507 model2 loss : 0.198000
[22:16:55.334] iteration 5816 : model1 loss : 0.213249 model2 loss : 0.216888
[22:16:55.657] iteration 5817 : model1 loss : 0.266680 model2 loss : 0.307318
[22:16:55.984] iteration 5818 : model1 loss : 0.235594 model2 loss : 0.252623
[22:16:56.310] iteration 5819 : model1 loss : 0.255668 model2 loss : 0.219242
[22:16:56.637] iteration 5820 : model1 loss : 0.294557 model2 loss : 0.290557
[22:16:56.964] iteration 5821 : model1 loss : 0.229699 model2 loss : 0.272931
[22:16:57.300] iteration 5822 : model1 loss : 0.339789 model2 loss : 0.336225
[22:16:57.628] iteration 5823 : model1 loss : 0.141989 model2 loss : 0.146436
[22:16:57.955] iteration 5824 : model1 loss : 0.205791 model2 loss : 0.233359
[22:16:58.282] iteration 5825 : model1 loss : 0.241536 model2 loss : 0.235145
[22:16:58.608] iteration 5826 : model1 loss : 0.307760 model2 loss : 0.259944
[22:16:58.938] iteration 5827 : model1 loss : 0.222838 model2 loss : 0.262505
[22:16:59.264] iteration 5828 : model1 loss : 0.284946 model2 loss : 0.312189
[22:16:59.592] iteration 5829 : model1 loss : 0.308936 model2 loss : 0.313620
[22:16:59.919] iteration 5830 : model1 loss : 0.309915 model2 loss : 0.278776
[22:17:00.246] iteration 5831 : model1 loss : 0.254713 model2 loss : 0.220830
[22:17:00.572] iteration 5832 : model1 loss : 0.187656 model2 loss : 0.216804
[22:17:00.905] iteration 5833 : model1 loss : 0.284014 model2 loss : 0.274364
[22:17:01.232] iteration 5834 : model1 loss : 0.266372 model2 loss : 0.249926
[22:17:01.559] iteration 5835 : model1 loss : 0.385525 model2 loss : 0.363110
[22:17:01.886] iteration 5836 : model1 loss : 0.268647 model2 loss : 0.243740
[22:17:02.213] iteration 5837 : model1 loss : 0.330143 model2 loss : 0.344651
[22:17:02.545] iteration 5838 : model1 loss : 0.286841 model2 loss : 0.272584
[22:17:02.871] iteration 5839 : model1 loss : 0.338435 model2 loss : 0.314697
[22:17:03.195] iteration 5840 : model1 loss : 0.181914 model2 loss : 0.211427
[22:17:03.519] iteration 5841 : model1 loss : 0.262767 model2 loss : 0.289088
[22:17:03.848] iteration 5842 : model1 loss : 0.322807 model2 loss : 0.329156
[22:17:04.175] iteration 5843 : model1 loss : 0.345976 model2 loss : 0.287189
[22:17:04.500] iteration 5844 : model1 loss : 0.265063 model2 loss : 0.319365
[22:17:04.828] iteration 5845 : model1 loss : 0.197665 model2 loss : 0.222553
[22:17:05.156] iteration 5846 : model1 loss : 0.123678 model2 loss : 0.165875
[22:17:05.483] iteration 5847 : model1 loss : 0.280801 model2 loss : 0.288413
[22:17:05.810] iteration 5848 : model1 loss : 0.272851 model2 loss : 0.326401
[22:17:06.138] iteration 5849 : model1 loss : 0.215672 model2 loss : 0.281101
[22:17:06.465] iteration 5850 : model1 loss : 0.328801 model2 loss : 0.333100
[22:17:07.031] iteration 5851 : model1 loss : 0.302240 model2 loss : 0.254298
[22:17:07.359] iteration 5852 : model1 loss : 0.208619 model2 loss : 0.308640
[22:17:07.686] iteration 5853 : model1 loss : 0.317142 model2 loss : 0.414472
[22:17:08.014] iteration 5854 : model1 loss : 0.436140 model2 loss : 0.252884
[22:17:08.343] iteration 5855 : model1 loss : 0.319613 model2 loss : 0.342757
[22:17:08.671] iteration 5856 : model1 loss : 0.251259 model2 loss : 0.287810
[22:17:08.998] iteration 5857 : model1 loss : 0.271205 model2 loss : 0.232878
[22:17:09.325] iteration 5858 : model1 loss : 0.220837 model2 loss : 0.193129
[22:17:09.652] iteration 5859 : model1 loss : 0.175810 model2 loss : 0.227360
[22:17:09.979] iteration 5860 : model1 loss : 0.167117 model2 loss : 0.226157
[22:17:10.307] iteration 5861 : model1 loss : 0.247915 model2 loss : 0.268369
[22:17:10.634] iteration 5862 : model1 loss : 0.274360 model2 loss : 0.362308
[22:17:10.961] iteration 5863 : model1 loss : 0.258987 model2 loss : 0.232697
[22:17:11.288] iteration 5864 : model1 loss : 0.264240 model2 loss : 0.277679
[22:17:11.615] iteration 5865 : model1 loss : 0.357104 model2 loss : 0.353684
[22:17:11.941] iteration 5866 : model1 loss : 0.260571 model2 loss : 0.270698
[22:17:12.268] iteration 5867 : model1 loss : 0.369343 model2 loss : 0.261071
[22:17:12.593] iteration 5868 : model1 loss : 0.355243 model2 loss : 0.282871
[22:17:12.917] iteration 5869 : model1 loss : 0.297945 model2 loss : 0.312116
[22:17:13.243] iteration 5870 : model1 loss : 0.244568 model2 loss : 0.241625
[22:17:13.570] iteration 5871 : model1 loss : 0.308291 model2 loss : 0.291183
[22:17:13.892] iteration 5872 : model1 loss : 0.280091 model2 loss : 0.284452
[22:17:14.219] iteration 5873 : model1 loss : 0.273174 model2 loss : 0.242553
[22:17:14.546] iteration 5874 : model1 loss : 0.270151 model2 loss : 0.237272
[22:17:14.873] iteration 5875 : model1 loss : 0.309942 model2 loss : 0.337739
[22:17:15.196] iteration 5876 : model1 loss : 0.239782 model2 loss : 0.266241
[22:17:15.519] iteration 5877 : model1 loss : 0.401900 model2 loss : 0.323076
[22:17:15.846] iteration 5878 : model1 loss : 0.245721 model2 loss : 0.246451
[22:17:16.175] iteration 5879 : model1 loss : 0.275042 model2 loss : 0.227698
[22:17:16.497] iteration 5880 : model1 loss : 0.223682 model2 loss : 0.232597
[22:17:16.824] iteration 5881 : model1 loss : 0.161299 model2 loss : 0.208866
[22:17:17.150] iteration 5882 : model1 loss : 0.279859 model2 loss : 0.295368
[22:17:17.477] iteration 5883 : model1 loss : 0.315843 model2 loss : 0.318647
[22:17:17.803] iteration 5884 : model1 loss : 0.206542 model2 loss : 0.200882
[22:17:18.139] iteration 5885 : model1 loss : 0.275880 model2 loss : 0.286789
[22:17:18.465] iteration 5886 : model1 loss : 0.250011 model2 loss : 0.208744
[22:17:18.797] iteration 5887 : model1 loss : 0.198893 model2 loss : 0.249063
[22:17:19.124] iteration 5888 : model1 loss : 0.291398 model2 loss : 0.284879
[22:17:19.451] iteration 5889 : model1 loss : 0.363097 model2 loss : 0.358148
[22:17:19.778] iteration 5890 : model1 loss : 0.296946 model2 loss : 0.316440
[22:17:20.107] iteration 5891 : model1 loss : 0.210636 model2 loss : 0.278790
[22:17:20.434] iteration 5892 : model1 loss : 0.220835 model2 loss : 0.233535
[22:17:20.761] iteration 5893 : model1 loss : 0.349513 model2 loss : 0.353283
[22:17:21.088] iteration 5894 : model1 loss : 0.351112 model2 loss : 0.368632
[22:17:21.415] iteration 5895 : model1 loss : 0.323577 model2 loss : 0.269756
[22:17:21.742] iteration 5896 : model1 loss : 0.294369 model2 loss : 0.218460
[22:17:22.066] iteration 5897 : model1 loss : 0.288265 model2 loss : 0.286468
[22:17:22.394] iteration 5898 : model1 loss : 0.365458 model2 loss : 0.332722
[22:17:22.721] iteration 5899 : model1 loss : 0.326791 model2 loss : 0.317238
[22:17:23.050] iteration 5900 : model1 loss : 0.301373 model2 loss : 0.285471
[22:17:23.614] iteration 5901 : model1 loss : 0.256044 model2 loss : 0.209236
[22:17:23.941] iteration 5902 : model1 loss : 0.254427 model2 loss : 0.301916
[22:17:24.266] iteration 5903 : model1 loss : 0.302849 model2 loss : 0.301073
[22:17:24.593] iteration 5904 : model1 loss : 0.328450 model2 loss : 0.391065
[22:17:24.916] iteration 5905 : model1 loss : 0.269317 model2 loss : 0.240110
[22:17:25.243] iteration 5906 : model1 loss : 0.303019 model2 loss : 0.304411
[22:17:25.571] iteration 5907 : model1 loss : 0.273099 model2 loss : 0.294341
[22:17:25.898] iteration 5908 : model1 loss : 0.295055 model2 loss : 0.278664
[22:17:26.225] iteration 5909 : model1 loss : 0.285341 model2 loss : 0.224064
[22:17:26.552] iteration 5910 : model1 loss : 0.361961 model2 loss : 0.335873
[22:17:26.880] iteration 5911 : model1 loss : 0.270032 model2 loss : 0.261758
[22:17:27.208] iteration 5912 : model1 loss : 0.378189 model2 loss : 0.369970
[22:17:27.536] iteration 5913 : model1 loss : 0.358083 model2 loss : 0.318581
[22:17:27.864] iteration 5914 : model1 loss : 0.314907 model2 loss : 0.349844
[22:17:28.192] iteration 5915 : model1 loss : 0.259692 model2 loss : 0.229158
[22:17:28.519] iteration 5916 : model1 loss : 0.278403 model2 loss : 0.284854
[22:17:28.848] iteration 5917 : model1 loss : 0.331047 model2 loss : 0.315308
[22:17:29.176] iteration 5918 : model1 loss : 0.287873 model2 loss : 0.274959
[22:17:29.504] iteration 5919 : model1 loss : 0.318172 model2 loss : 0.323477
[22:17:29.831] iteration 5920 : model1 loss : 0.260212 model2 loss : 0.267886
[22:17:30.161] iteration 5921 : model1 loss : 0.311910 model2 loss : 0.320629
[22:17:30.499] iteration 5922 : model1 loss : 0.226184 model2 loss : 0.278824
[22:17:30.841] iteration 5923 : model1 loss : 0.268434 model2 loss : 0.246454
[22:17:31.181] iteration 5924 : model1 loss : 0.264920 model2 loss : 0.291816
[22:17:31.521] iteration 5925 : model1 loss : 0.300271 model2 loss : 0.304336
[22:17:31.860] iteration 5926 : model1 loss : 0.412164 model2 loss : 0.302531
[22:17:32.203] iteration 5927 : model1 loss : 0.323177 model2 loss : 0.314661
[22:17:32.542] iteration 5928 : model1 loss : 0.421556 model2 loss : 0.343818
[22:17:32.884] iteration 5929 : model1 loss : 0.268756 model2 loss : 0.277623
[22:17:33.221] iteration 5930 : model1 loss : 0.403955 model2 loss : 0.310568
[22:17:33.558] iteration 5931 : model1 loss : 0.317840 model2 loss : 0.215177
[22:17:33.899] iteration 5932 : model1 loss : 0.280558 model2 loss : 0.231735
[22:17:34.235] iteration 5933 : model1 loss : 0.177807 model2 loss : 0.170579
[22:17:34.574] iteration 5934 : model1 loss : 0.343359 model2 loss : 0.306525
[22:17:34.923] iteration 5935 : model1 loss : 0.279986 model2 loss : 0.330192
[22:17:35.266] iteration 5936 : model1 loss : 0.214626 model2 loss : 0.261832
[22:17:35.610] iteration 5937 : model1 loss : 0.337163 model2 loss : 0.338449
[22:17:35.947] iteration 5938 : model1 loss : 0.324770 model2 loss : 0.325659
[22:17:36.285] iteration 5939 : model1 loss : 0.247718 model2 loss : 0.220360
[22:17:36.625] iteration 5940 : model1 loss : 0.301250 model2 loss : 0.309919
[22:17:36.967] iteration 5941 : model1 loss : 0.358567 model2 loss : 0.337261
[22:17:37.309] iteration 5942 : model1 loss : 0.292674 model2 loss : 0.329166
[22:17:37.648] iteration 5943 : model1 loss : 0.334966 model2 loss : 0.302454
[22:17:37.991] iteration 5944 : model1 loss : 0.279489 model2 loss : 0.256672
[22:17:38.332] iteration 5945 : model1 loss : 0.294261 model2 loss : 0.321002
[22:17:38.669] iteration 5946 : model1 loss : 0.239210 model2 loss : 0.238306
[22:17:39.006] iteration 5947 : model1 loss : 0.297585 model2 loss : 0.297272
[22:17:39.343] iteration 5948 : model1 loss : 0.238438 model2 loss : 0.233146
[22:17:39.684] iteration 5949 : model1 loss : 0.230391 model2 loss : 0.167257
[22:17:40.027] iteration 5950 : model1 loss : 0.298837 model2 loss : 0.265343
[22:17:40.679] iteration 5951 : model1 loss : 0.179227 model2 loss : 0.209122
[22:17:41.018] iteration 5952 : model1 loss : 0.248733 model2 loss : 0.258363
[22:17:41.356] iteration 5953 : model1 loss : 0.364906 model2 loss : 0.366731
[22:17:41.695] iteration 5954 : model1 loss : 0.220649 model2 loss : 0.262487
[22:17:42.032] iteration 5955 : model1 loss : 0.279270 model2 loss : 0.272116
[22:17:42.369] iteration 5956 : model1 loss : 0.307684 model2 loss : 0.305045
[22:17:42.711] iteration 5957 : model1 loss : 0.242149 model2 loss : 0.278570
[22:17:43.050] iteration 5958 : model1 loss : 0.247708 model2 loss : 0.241797
[22:17:43.389] iteration 5959 : model1 loss : 0.313686 model2 loss : 0.322206
[22:17:43.728] iteration 5960 : model1 loss : 0.186074 model2 loss : 0.169834
[22:17:44.070] iteration 5961 : model1 loss : 0.392607 model2 loss : 0.421000
[22:17:44.411] iteration 5962 : model1 loss : 0.373986 model2 loss : 0.405980
[22:17:44.749] iteration 5963 : model1 loss : 0.305607 model2 loss : 0.309089
[22:17:45.096] iteration 5964 : model1 loss : 0.121027 model2 loss : 0.225273
[22:17:45.436] iteration 5965 : model1 loss : 0.197918 model2 loss : 0.196391
[22:17:45.788] iteration 5966 : model1 loss : 0.354988 model2 loss : 0.353350
[22:17:46.126] iteration 5967 : model1 loss : 0.275671 model2 loss : 0.273861
[22:17:46.470] iteration 5968 : model1 loss : 0.209687 model2 loss : 0.259664
[22:17:46.824] iteration 5969 : model1 loss : 0.246796 model2 loss : 0.282264
[22:17:47.166] iteration 5970 : model1 loss : 0.250486 model2 loss : 0.287850
[22:17:47.504] iteration 5971 : model1 loss : 0.193877 model2 loss : 0.178968
[22:17:47.845] iteration 5972 : model1 loss : 0.340931 model2 loss : 0.352053
[22:17:48.187] iteration 5973 : model1 loss : 0.144864 model2 loss : 0.214075
[22:17:48.524] iteration 5974 : model1 loss : 0.275260 model2 loss : 0.286716
[22:17:48.862] iteration 5975 : model1 loss : 0.331022 model2 loss : 0.293720
[22:17:49.204] iteration 5976 : model1 loss : 0.207373 model2 loss : 0.289867
[22:17:49.542] iteration 5977 : model1 loss : 0.259801 model2 loss : 0.250727
[22:17:49.880] iteration 5978 : model1 loss : 0.216889 model2 loss : 0.241038
[22:17:50.218] iteration 5979 : model1 loss : 0.363254 model2 loss : 0.361929
[22:17:50.555] iteration 5980 : model1 loss : 0.292500 model2 loss : 0.318835
[22:17:50.892] iteration 5981 : model1 loss : 0.291802 model2 loss : 0.321682
[22:17:51.229] iteration 5982 : model1 loss : 0.285593 model2 loss : 0.269102
[22:17:51.567] iteration 5983 : model1 loss : 0.136702 model2 loss : 0.226908
[22:17:51.903] iteration 5984 : model1 loss : 0.234854 model2 loss : 0.215723
[22:17:52.241] iteration 5985 : model1 loss : 0.302257 model2 loss : 0.306170
[22:17:52.580] iteration 5986 : model1 loss : 0.187590 model2 loss : 0.220030
[22:17:53.335] iteration 5987 : model1 loss : 0.281099 model2 loss : 0.213590
[22:17:53.671] iteration 5988 : model1 loss : 0.285879 model2 loss : 0.311402
[22:17:54.007] iteration 5989 : model1 loss : 0.244688 model2 loss : 0.298605
[22:17:54.343] iteration 5990 : model1 loss : 0.222928 model2 loss : 0.208537
[22:17:54.681] iteration 5991 : model1 loss : 0.228291 model2 loss : 0.225075
[22:17:55.017] iteration 5992 : model1 loss : 0.246180 model2 loss : 0.302993
[22:17:55.355] iteration 5993 : model1 loss : 0.296713 model2 loss : 0.269755
[22:17:55.691] iteration 5994 : model1 loss : 0.251079 model2 loss : 0.220139
[22:17:56.026] iteration 5995 : model1 loss : 0.227411 model2 loss : 0.281064
[22:17:56.969] iteration 5996 : model1 loss : 0.287718 model2 loss : 0.303276
[22:17:57.306] iteration 5997 : model1 loss : 0.232578 model2 loss : 0.251313
[22:17:57.646] iteration 5998 : model1 loss : 0.272310 model2 loss : 0.276136
[22:17:57.985] iteration 5999 : model1 loss : 0.338793 model2 loss : 0.342474
[22:17:58.326] iteration 6000 : model1 loss : 0.258746 model2 loss : 0.219793
[22:19:04.438] iteration 6000 : model1_mean_dice : 0.672220 model1_mean_hd95 : 14.602791
[22:19:37.592] iteration 6000 : model2_mean_dice : 0.510722 model2_mean_hd95 : 16.516191
[22:19:37.698] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_6000.pth
[22:19:37.717] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_6000.pth
[22:19:38.052] iteration 6001 : model1 loss : 0.327747 model2 loss : 0.285982
[22:19:38.378] iteration 6002 : model1 loss : 0.257561 model2 loss : 0.259062
[22:19:38.705] iteration 6003 : model1 loss : 0.271398 model2 loss : 0.238200
[22:19:39.031] iteration 6004 : model1 loss : 0.320582 model2 loss : 0.325898
[22:19:39.358] iteration 6005 : model1 loss : 0.344678 model2 loss : 0.320860
[22:19:39.685] iteration 6006 : model1 loss : 0.307764 model2 loss : 0.360901
[22:19:40.011] iteration 6007 : model1 loss : 0.241834 model2 loss : 0.227510
[22:19:40.338] iteration 6008 : model1 loss : 0.300952 model2 loss : 0.293903
[22:19:40.664] iteration 6009 : model1 loss : 0.238806 model2 loss : 0.245111
[22:19:40.991] iteration 6010 : model1 loss : 0.232553 model2 loss : 0.201107
[22:19:41.319] iteration 6011 : model1 loss : 0.296236 model2 loss : 0.247870
[22:19:41.646] iteration 6012 : model1 loss : 0.223663 model2 loss : 0.239923
[22:19:41.974] iteration 6013 : model1 loss : 0.198163 model2 loss : 0.199234
[22:19:42.301] iteration 6014 : model1 loss : 0.220679 model2 loss : 0.357945
[22:19:42.627] iteration 6015 : model1 loss : 0.274865 model2 loss : 0.261868
[22:19:42.954] iteration 6016 : model1 loss : 0.335739 model2 loss : 0.331436
[22:19:43.280] iteration 6017 : model1 loss : 0.400143 model2 loss : 0.403071
[22:19:43.607] iteration 6018 : model1 loss : 0.252117 model2 loss : 0.208946
[22:19:43.934] iteration 6019 : model1 loss : 0.252307 model2 loss : 0.209188
[22:19:44.261] iteration 6020 : model1 loss : 0.367869 model2 loss : 0.374617
[22:19:44.589] iteration 6021 : model1 loss : 0.314110 model2 loss : 0.254178
[22:19:44.916] iteration 6022 : model1 loss : 0.233064 model2 loss : 0.253967
[22:19:45.245] iteration 6023 : model1 loss : 0.281054 model2 loss : 0.293906
[22:19:45.571] iteration 6024 : model1 loss : 0.214741 model2 loss : 0.229820
[22:19:45.899] iteration 6025 : model1 loss : 0.314675 model2 loss : 0.362333
[22:19:46.226] iteration 6026 : model1 loss : 0.313050 model2 loss : 0.271691
[22:19:46.558] iteration 6027 : model1 loss : 0.191224 model2 loss : 0.205193
[22:19:46.882] iteration 6028 : model1 loss : 0.308606 model2 loss : 0.359014
[22:19:47.208] iteration 6029 : model1 loss : 0.307879 model2 loss : 0.284591
[22:19:47.541] iteration 6030 : model1 loss : 0.220058 model2 loss : 0.223867
[22:19:47.868] iteration 6031 : model1 loss : 0.354080 model2 loss : 0.392129
[22:19:48.195] iteration 6032 : model1 loss : 0.271020 model2 loss : 0.352570
[22:19:48.523] iteration 6033 : model1 loss : 0.361345 model2 loss : 0.410553
[22:19:48.850] iteration 6034 : model1 loss : 0.216620 model2 loss : 0.227254
[22:19:49.177] iteration 6035 : model1 loss : 0.215425 model2 loss : 0.308234
[22:19:49.505] iteration 6036 : model1 loss : 0.269275 model2 loss : 0.336235
[22:19:49.833] iteration 6037 : model1 loss : 0.374713 model2 loss : 0.321207
[22:19:50.159] iteration 6038 : model1 loss : 0.392179 model2 loss : 0.351211
[22:19:50.486] iteration 6039 : model1 loss : 0.266826 model2 loss : 0.281138
[22:19:50.813] iteration 6040 : model1 loss : 0.339860 model2 loss : 0.321890
[22:19:51.140] iteration 6041 : model1 loss : 0.338571 model2 loss : 0.306544
[22:19:51.466] iteration 6042 : model1 loss : 0.232885 model2 loss : 0.220404
[22:19:51.793] iteration 6043 : model1 loss : 0.218325 model2 loss : 0.193008
[22:19:52.121] iteration 6044 : model1 loss : 0.146182 model2 loss : 0.228783
[22:19:52.449] iteration 6045 : model1 loss : 0.234395 model2 loss : 0.279776
[22:19:52.776] iteration 6046 : model1 loss : 0.320336 model2 loss : 0.314899
[22:19:53.103] iteration 6047 : model1 loss : 0.198960 model2 loss : 0.244329
[22:19:53.429] iteration 6048 : model1 loss : 0.190069 model2 loss : 0.216711
[22:19:53.757] iteration 6049 : model1 loss : 0.232356 model2 loss : 0.265370
[22:19:54.084] iteration 6050 : model1 loss : 0.379259 model2 loss : 0.304126
[22:19:54.636] iteration 6051 : model1 loss : 0.339330 model2 loss : 0.294803
[22:19:54.965] iteration 6052 : model1 loss : 0.250131 model2 loss : 0.264925
[22:19:55.292] iteration 6053 : model1 loss : 0.369624 model2 loss : 0.408381
[22:19:55.620] iteration 6054 : model1 loss : 0.274621 model2 loss : 0.255977
[22:19:55.946] iteration 6055 : model1 loss : 0.252158 model2 loss : 0.283694
[22:19:56.274] iteration 6056 : model1 loss : 0.301970 model2 loss : 0.289946
[22:19:56.602] iteration 6057 : model1 loss : 0.215277 model2 loss : 0.210439
[22:19:56.929] iteration 6058 : model1 loss : 0.233065 model2 loss : 0.257784
[22:19:57.256] iteration 6059 : model1 loss : 0.218145 model2 loss : 0.289682
[22:19:57.582] iteration 6060 : model1 loss : 0.285368 model2 loss : 0.241166
[22:19:57.909] iteration 6061 : model1 loss : 0.345799 model2 loss : 0.359698
[22:19:58.236] iteration 6062 : model1 loss : 0.345131 model2 loss : 0.373843
[22:19:58.563] iteration 6063 : model1 loss : 0.327844 model2 loss : 0.339331
[22:19:58.890] iteration 6064 : model1 loss : 0.167622 model2 loss : 0.116738
[22:19:59.217] iteration 6065 : model1 loss : 0.337753 model2 loss : 0.272177
[22:19:59.544] iteration 6066 : model1 loss : 0.364210 model2 loss : 0.381589
[22:19:59.871] iteration 6067 : model1 loss : 0.350033 model2 loss : 0.329060
[22:20:00.197] iteration 6068 : model1 loss : 0.295099 model2 loss : 0.315427
[22:20:00.526] iteration 6069 : model1 loss : 0.262927 model2 loss : 0.248780
[22:20:00.852] iteration 6070 : model1 loss : 0.301917 model2 loss : 0.311576
[22:20:01.182] iteration 6071 : model1 loss : 0.306096 model2 loss : 0.257234
[22:20:01.510] iteration 6072 : model1 loss : 0.247018 model2 loss : 0.294537
[22:20:01.837] iteration 6073 : model1 loss : 0.296148 model2 loss : 0.287818
[22:20:02.164] iteration 6074 : model1 loss : 0.300156 model2 loss : 0.294110
[22:20:02.492] iteration 6075 : model1 loss : 0.335507 model2 loss : 0.362362
[22:20:02.818] iteration 6076 : model1 loss : 0.251420 model2 loss : 0.264297
[22:20:03.144] iteration 6077 : model1 loss : 0.228305 model2 loss : 0.254767
[22:20:03.470] iteration 6078 : model1 loss : 0.222394 model2 loss : 0.219900
[22:20:03.797] iteration 6079 : model1 loss : 0.298069 model2 loss : 0.262161
[22:20:04.124] iteration 6080 : model1 loss : 0.350263 model2 loss : 0.312845
[22:20:04.456] iteration 6081 : model1 loss : 0.314021 model2 loss : 0.348045
[22:20:04.784] iteration 6082 : model1 loss : 0.329221 model2 loss : 0.335400
[22:20:05.114] iteration 6083 : model1 loss : 0.214140 model2 loss : 0.245295
[22:20:05.442] iteration 6084 : model1 loss : 0.250136 model2 loss : 0.239013
[22:20:05.772] iteration 6085 : model1 loss : 0.206519 model2 loss : 0.190218
[22:20:06.099] iteration 6086 : model1 loss : 0.363588 model2 loss : 0.389701
[22:20:06.427] iteration 6087 : model1 loss : 0.319672 model2 loss : 0.300795
[22:20:06.754] iteration 6088 : model1 loss : 0.239157 model2 loss : 0.234958
[22:20:07.081] iteration 6089 : model1 loss : 0.288940 model2 loss : 0.349868
[22:20:07.410] iteration 6090 : model1 loss : 0.363539 model2 loss : 0.368023
[22:20:07.737] iteration 6091 : model1 loss : 0.239221 model2 loss : 0.235304
[22:20:08.064] iteration 6092 : model1 loss : 0.266768 model2 loss : 0.269787
[22:20:08.395] iteration 6093 : model1 loss : 0.228931 model2 loss : 0.275615
[22:20:08.723] iteration 6094 : model1 loss : 0.273576 model2 loss : 0.331014
[22:20:09.050] iteration 6095 : model1 loss : 0.218193 model2 loss : 0.255271
[22:20:09.378] iteration 6096 : model1 loss : 0.353110 model2 loss : 0.386375
[22:20:09.705] iteration 6097 : model1 loss : 0.249492 model2 loss : 0.332310
[22:20:10.032] iteration 6098 : model1 loss : 0.302578 model2 loss : 0.261434
[22:20:10.360] iteration 6099 : model1 loss : 0.283484 model2 loss : 0.239655
[22:20:10.687] iteration 6100 : model1 loss : 0.308369 model2 loss : 0.310860
[22:20:11.211] iteration 6101 : model1 loss : 0.234094 model2 loss : 0.274215
[22:20:11.541] iteration 6102 : model1 loss : 0.288035 model2 loss : 0.366260
[22:20:11.869] iteration 6103 : model1 loss : 0.296586 model2 loss : 0.374273
[22:20:12.199] iteration 6104 : model1 loss : 0.330533 model2 loss : 0.367198
[22:20:12.527] iteration 6105 : model1 loss : 0.366211 model2 loss : 0.359024
[22:20:12.854] iteration 6106 : model1 loss : 0.315949 model2 loss : 0.329041
[22:20:13.181] iteration 6107 : model1 loss : 0.264730 model2 loss : 0.253703
[22:20:13.509] iteration 6108 : model1 loss : 0.239035 model2 loss : 0.242949
[22:20:13.844] iteration 6109 : model1 loss : 0.384402 model2 loss : 0.387647
[22:20:14.172] iteration 6110 : model1 loss : 0.212971 model2 loss : 0.235330
[22:20:14.499] iteration 6111 : model1 loss : 0.304847 model2 loss : 0.293871
[22:20:14.826] iteration 6112 : model1 loss : 0.274066 model2 loss : 0.247236
[22:20:15.154] iteration 6113 : model1 loss : 0.291664 model2 loss : 0.300101
[22:20:15.481] iteration 6114 : model1 loss : 0.289673 model2 loss : 0.288127
[22:20:15.809] iteration 6115 : model1 loss : 0.251134 model2 loss : 0.282621
[22:20:16.136] iteration 6116 : model1 loss : 0.295975 model2 loss : 0.239209
[22:20:16.463] iteration 6117 : model1 loss : 0.310017 model2 loss : 0.279383
[22:20:16.790] iteration 6118 : model1 loss : 0.246849 model2 loss : 0.222760
[22:20:17.117] iteration 6119 : model1 loss : 0.125561 model2 loss : 0.180085
[22:20:17.446] iteration 6120 : model1 loss : 0.191812 model2 loss : 0.213277
[22:20:17.774] iteration 6121 : model1 loss : 0.311743 model2 loss : 0.312751
[22:20:18.101] iteration 6122 : model1 loss : 0.252342 model2 loss : 0.290260
[22:20:18.428] iteration 6123 : model1 loss : 0.315317 model2 loss : 0.300287
[22:20:18.755] iteration 6124 : model1 loss : 0.194476 model2 loss : 0.197890
[22:20:19.081] iteration 6125 : model1 loss : 0.324393 model2 loss : 0.297152
[22:20:19.408] iteration 6126 : model1 loss : 0.277014 model2 loss : 0.281568
[22:20:19.738] iteration 6127 : model1 loss : 0.318978 model2 loss : 0.278937
[22:20:20.066] iteration 6128 : model1 loss : 0.294854 model2 loss : 0.306946
[22:20:20.393] iteration 6129 : model1 loss : 0.204212 model2 loss : 0.142983
[22:20:20.720] iteration 6130 : model1 loss : 0.239873 model2 loss : 0.240623
[22:20:21.047] iteration 6131 : model1 loss : 0.211007 model2 loss : 0.244242
[22:20:21.374] iteration 6132 : model1 loss : 0.373599 model2 loss : 0.330782
[22:20:21.702] iteration 6133 : model1 loss : 0.311671 model2 loss : 0.424025
[22:20:22.030] iteration 6134 : model1 loss : 0.294528 model2 loss : 0.310558
[22:20:22.357] iteration 6135 : model1 loss : 0.216067 model2 loss : 0.221059
[22:20:22.684] iteration 6136 : model1 loss : 0.249394 model2 loss : 0.205240
[22:20:23.013] iteration 6137 : model1 loss : 0.344817 model2 loss : 0.333517
[22:20:23.340] iteration 6138 : model1 loss : 0.282330 model2 loss : 0.298902
[22:20:23.667] iteration 6139 : model1 loss : 0.272600 model2 loss : 0.295467
[22:20:23.995] iteration 6140 : model1 loss : 0.269279 model2 loss : 0.246608
[22:20:24.322] iteration 6141 : model1 loss : 0.235993 model2 loss : 0.308592
[22:20:24.649] iteration 6142 : model1 loss : 0.416506 model2 loss : 0.434836
[22:20:24.977] iteration 6143 : model1 loss : 0.313905 model2 loss : 0.347719
[22:20:25.306] iteration 6144 : model1 loss : 0.242470 model2 loss : 0.241628
[22:20:25.634] iteration 6145 : model1 loss : 0.188992 model2 loss : 0.232514
[22:20:25.962] iteration 6146 : model1 loss : 0.341101 model2 loss : 0.366922
[22:20:26.288] iteration 6147 : model1 loss : 0.333493 model2 loss : 0.331619
[22:20:26.617] iteration 6148 : model1 loss : 0.271850 model2 loss : 0.267715
[22:20:26.946] iteration 6149 : model1 loss : 0.257812 model2 loss : 0.248065
[22:20:27.274] iteration 6150 : model1 loss : 0.252367 model2 loss : 0.251325
[22:20:27.812] iteration 6151 : model1 loss : 0.254325 model2 loss : 0.254870
[22:20:28.141] iteration 6152 : model1 loss : 0.231788 model2 loss : 0.246656
[22:20:28.468] iteration 6153 : model1 loss : 0.350209 model2 loss : 0.330441
[22:20:28.795] iteration 6154 : model1 loss : 0.260295 model2 loss : 0.256609
[22:20:29.124] iteration 6155 : model1 loss : 0.217804 model2 loss : 0.196318
[22:20:29.452] iteration 6156 : model1 loss : 0.312977 model2 loss : 0.323829
[22:20:29.779] iteration 6157 : model1 loss : 0.274484 model2 loss : 0.291305
[22:20:30.114] iteration 6158 : model1 loss : 0.319900 model2 loss : 0.268215
[22:20:30.442] iteration 6159 : model1 loss : 0.286822 model2 loss : 0.258886
[22:20:30.770] iteration 6160 : model1 loss : 0.245551 model2 loss : 0.175339
[22:20:31.099] iteration 6161 : model1 loss : 0.335795 model2 loss : 0.296927
[22:20:31.427] iteration 6162 : model1 loss : 0.282533 model2 loss : 0.310162
[22:20:31.755] iteration 6163 : model1 loss : 0.303187 model2 loss : 0.351211
[22:20:32.082] iteration 6164 : model1 loss : 0.249943 model2 loss : 0.241408
[22:20:32.410] iteration 6165 : model1 loss : 0.299964 model2 loss : 0.225762
[22:20:32.740] iteration 6166 : model1 loss : 0.298241 model2 loss : 0.249856
[22:20:33.067] iteration 6167 : model1 loss : 0.291247 model2 loss : 0.286007
[22:20:33.395] iteration 6168 : model1 loss : 0.250667 model2 loss : 0.217572
[22:20:33.723] iteration 6169 : model1 loss : 0.201348 model2 loss : 0.235148
[22:20:34.052] iteration 6170 : model1 loss : 0.243546 model2 loss : 0.235416
[22:20:34.380] iteration 6171 : model1 loss : 0.273575 model2 loss : 0.206899
[22:20:34.711] iteration 6172 : model1 loss : 0.331576 model2 loss : 0.294176
[22:20:35.038] iteration 6173 : model1 loss : 0.287260 model2 loss : 0.266990
[22:20:35.370] iteration 6174 : model1 loss : 0.309636 model2 loss : 0.291583
[22:20:35.697] iteration 6175 : model1 loss : 0.195825 model2 loss : 0.242467
[22:20:36.025] iteration 6176 : model1 loss : 0.291144 model2 loss : 0.288833
[22:20:36.354] iteration 6177 : model1 loss : 0.250910 model2 loss : 0.291976
[22:20:36.681] iteration 6178 : model1 loss : 0.314660 model2 loss : 0.335995
[22:20:37.010] iteration 6179 : model1 loss : 0.183104 model2 loss : 0.233971
[22:20:37.338] iteration 6180 : model1 loss : 0.187353 model2 loss : 0.198437
[22:20:37.665] iteration 6181 : model1 loss : 0.339234 model2 loss : 0.323732
[22:20:37.994] iteration 6182 : model1 loss : 0.169668 model2 loss : 0.203491
[22:20:38.323] iteration 6183 : model1 loss : 0.213398 model2 loss : 0.257179
[22:20:38.650] iteration 6184 : model1 loss : 0.180696 model2 loss : 0.167486
[22:20:38.977] iteration 6185 : model1 loss : 0.300508 model2 loss : 0.337900
[22:20:39.305] iteration 6186 : model1 loss : 0.330621 model2 loss : 0.342740
[22:20:39.633] iteration 6187 : model1 loss : 0.367427 model2 loss : 0.247544
[22:20:39.960] iteration 6188 : model1 loss : 0.162247 model2 loss : 0.215001
[22:20:40.289] iteration 6189 : model1 loss : 0.282658 model2 loss : 0.289588
[22:20:40.617] iteration 6190 : model1 loss : 0.342606 model2 loss : 0.371866
[22:20:40.944] iteration 6191 : model1 loss : 0.351878 model2 loss : 0.351292
[22:20:41.272] iteration 6192 : model1 loss : 0.182885 model2 loss : 0.268586
[22:20:41.599] iteration 6193 : model1 loss : 0.261362 model2 loss : 0.284452
[22:20:41.928] iteration 6194 : model1 loss : 0.296487 model2 loss : 0.301734
[22:20:42.256] iteration 6195 : model1 loss : 0.210399 model2 loss : 0.237655
[22:20:42.583] iteration 6196 : model1 loss : 0.377643 model2 loss : 0.372575
[22:20:42.911] iteration 6197 : model1 loss : 0.248481 model2 loss : 0.260740
[22:20:43.239] iteration 6198 : model1 loss : 0.343380 model2 loss : 0.346824
[22:20:43.568] iteration 6199 : model1 loss : 0.177091 model2 loss : 0.164169
[22:20:43.903] iteration 6200 : model1 loss : 0.360664 model2 loss : 0.337811
[22:20:44.548] iteration 6201 : model1 loss : 0.288570 model2 loss : 0.253402
[22:20:44.884] iteration 6202 : model1 loss : 0.389346 model2 loss : 0.374702
[22:20:45.223] iteration 6203 : model1 loss : 0.238772 model2 loss : 0.242823
[22:20:45.559] iteration 6204 : model1 loss : 0.300586 model2 loss : 0.323689
[22:20:45.896] iteration 6205 : model1 loss : 0.307248 model2 loss : 0.327552
[22:20:46.234] iteration 6206 : model1 loss : 0.271267 model2 loss : 0.367188
[22:20:46.574] iteration 6207 : model1 loss : 0.281014 model2 loss : 0.302146
[22:20:46.909] iteration 6208 : model1 loss : 0.346798 model2 loss : 0.300524
[22:20:47.247] iteration 6209 : model1 loss : 0.241088 model2 loss : 0.260102
[22:20:47.585] iteration 6210 : model1 loss : 0.211964 model2 loss : 0.271490
[22:20:47.922] iteration 6211 : model1 loss : 0.221298 model2 loss : 0.264767
[22:20:48.259] iteration 6212 : model1 loss : 0.279867 model2 loss : 0.271341
[22:20:48.598] iteration 6213 : model1 loss : 0.158933 model2 loss : 0.230300
[22:20:48.938] iteration 6214 : model1 loss : 0.287382 model2 loss : 0.328584
[22:20:49.273] iteration 6215 : model1 loss : 0.320639 model2 loss : 0.344320
[22:20:49.612] iteration 6216 : model1 loss : 0.169687 model2 loss : 0.221817
[22:20:49.951] iteration 6217 : model1 loss : 0.267537 model2 loss : 0.308876
[22:20:50.288] iteration 6218 : model1 loss : 0.409350 model2 loss : 0.272116
[22:20:50.625] iteration 6219 : model1 loss : 0.269537 model2 loss : 0.226687
[22:20:50.962] iteration 6220 : model1 loss : 0.264603 model2 loss : 0.286663
[22:20:51.303] iteration 6221 : model1 loss : 0.256400 model2 loss : 0.256063
[22:20:51.639] iteration 6222 : model1 loss : 0.320083 model2 loss : 0.305625
[22:20:51.975] iteration 6223 : model1 loss : 0.245992 model2 loss : 0.208738
[22:20:52.320] iteration 6224 : model1 loss : 0.276706 model2 loss : 0.247606
[22:20:52.656] iteration 6225 : model1 loss : 0.211171 model2 loss : 0.241252
[22:20:52.995] iteration 6226 : model1 loss : 0.308688 model2 loss : 0.297876
[22:20:53.331] iteration 6227 : model1 loss : 0.309889 model2 loss : 0.330450
[22:20:53.666] iteration 6228 : model1 loss : 0.281887 model2 loss : 0.309741
[22:20:54.002] iteration 6229 : model1 loss : 0.260657 model2 loss : 0.258432
[22:20:54.339] iteration 6230 : model1 loss : 0.271884 model2 loss : 0.277124
[22:20:54.677] iteration 6231 : model1 loss : 0.220723 model2 loss : 0.246116
[22:20:55.017] iteration 6232 : model1 loss : 0.277498 model2 loss : 0.337072
[22:20:55.358] iteration 6233 : model1 loss : 0.292786 model2 loss : 0.322115
[22:20:55.687] iteration 6234 : model1 loss : 0.235909 model2 loss : 0.255190
[22:20:56.014] iteration 6235 : model1 loss : 0.241454 model2 loss : 0.324755
[22:20:56.342] iteration 6236 : model1 loss : 0.288992 model2 loss : 0.296867
[22:20:56.670] iteration 6237 : model1 loss : 0.186417 model2 loss : 0.260664
[22:20:56.998] iteration 6238 : model1 loss : 0.167860 model2 loss : 0.197619
[22:20:57.325] iteration 6239 : model1 loss : 0.290122 model2 loss : 0.230817
[22:20:57.654] iteration 6240 : model1 loss : 0.220568 model2 loss : 0.250643
[22:20:57.981] iteration 6241 : model1 loss : 0.303017 model2 loss : 0.370950
[22:20:58.308] iteration 6242 : model1 loss : 0.240840 model2 loss : 0.306705
[22:20:58.637] iteration 6243 : model1 loss : 0.260396 model2 loss : 0.296233
[22:20:58.965] iteration 6244 : model1 loss : 0.244296 model2 loss : 0.283622
[22:20:59.293] iteration 6245 : model1 loss : 0.320538 model2 loss : 0.255079
[22:20:59.624] iteration 6246 : model1 loss : 0.352427 model2 loss : 0.328288
[22:20:59.952] iteration 6247 : model1 loss : 0.332677 model2 loss : 0.304303
[22:21:00.280] iteration 6248 : model1 loss : 0.261601 model2 loss : 0.226055
[22:21:00.608] iteration 6249 : model1 loss : 0.304011 model2 loss : 0.386910
[22:21:00.935] iteration 6250 : model1 loss : 0.296775 model2 loss : 0.308261
[22:21:01.501] iteration 6251 : model1 loss : 0.337361 model2 loss : 0.407352
[22:21:01.828] iteration 6252 : model1 loss : 0.228642 model2 loss : 0.228912
[22:21:02.156] iteration 6253 : model1 loss : 0.320446 model2 loss : 0.304681
[22:21:02.485] iteration 6254 : model1 loss : 0.300646 model2 loss : 0.270416
[22:21:02.813] iteration 6255 : model1 loss : 0.316574 model2 loss : 0.234228
[22:21:03.140] iteration 6256 : model1 loss : 0.282596 model2 loss : 0.315662
[22:21:03.469] iteration 6257 : model1 loss : 0.228990 model2 loss : 0.257232
[22:21:03.796] iteration 6258 : model1 loss : 0.139882 model2 loss : 0.171963
[22:21:04.123] iteration 6259 : model1 loss : 0.284215 model2 loss : 0.304848
[22:21:04.450] iteration 6260 : model1 loss : 0.389751 model2 loss : 0.357704
[22:21:04.777] iteration 6261 : model1 loss : 0.156459 model2 loss : 0.198377
[22:21:05.105] iteration 6262 : model1 loss : 0.321122 model2 loss : 0.261357
[22:21:05.433] iteration 6263 : model1 loss : 0.208868 model2 loss : 0.246141
[22:21:05.760] iteration 6264 : model1 loss : 0.301659 model2 loss : 0.255244
[22:21:06.089] iteration 6265 : model1 loss : 0.173202 model2 loss : 0.177980
[22:21:06.416] iteration 6266 : model1 loss : 0.199416 model2 loss : 0.171877
[22:21:06.742] iteration 6267 : model1 loss : 0.283134 model2 loss : 0.257540
[22:21:07.068] iteration 6268 : model1 loss : 0.203258 model2 loss : 0.183124
[22:21:07.395] iteration 6269 : model1 loss : 0.193533 model2 loss : 0.191134
[22:21:07.723] iteration 6270 : model1 loss : 0.192507 model2 loss : 0.205143
[22:21:08.049] iteration 6271 : model1 loss : 0.247648 model2 loss : 0.204895
[22:21:08.375] iteration 6272 : model1 loss : 0.337875 model2 loss : 0.360610
[22:21:08.703] iteration 6273 : model1 loss : 0.222606 model2 loss : 0.199420
[22:21:09.029] iteration 6274 : model1 loss : 0.297875 model2 loss : 0.301165
[22:21:09.355] iteration 6275 : model1 loss : 0.209391 model2 loss : 0.246269
[22:21:09.682] iteration 6276 : model1 loss : 0.321014 model2 loss : 0.256918
[22:21:10.008] iteration 6277 : model1 loss : 0.188534 model2 loss : 0.154060
[22:21:10.338] iteration 6278 : model1 loss : 0.237458 model2 loss : 0.218974
[22:21:10.674] iteration 6279 : model1 loss : 0.266834 model2 loss : 0.259481
[22:21:10.999] iteration 6280 : model1 loss : 0.253921 model2 loss : 0.218029
[22:21:11.326] iteration 6281 : model1 loss : 0.345938 model2 loss : 0.273880
[22:21:11.652] iteration 6282 : model1 loss : 0.228064 model2 loss : 0.239283
[22:21:11.979] iteration 6283 : model1 loss : 0.264825 model2 loss : 0.235809
[22:21:12.304] iteration 6284 : model1 loss : 0.364123 model2 loss : 0.322520
[22:21:12.631] iteration 6285 : model1 loss : 0.277292 model2 loss : 0.247628
[22:21:12.968] iteration 6286 : model1 loss : 0.359345 model2 loss : 0.304000
[22:21:13.305] iteration 6287 : model1 loss : 0.345319 model2 loss : 0.303425
[22:21:13.642] iteration 6288 : model1 loss : 0.315116 model2 loss : 0.326377
[22:21:13.980] iteration 6289 : model1 loss : 0.140384 model2 loss : 0.112858
[22:21:14.317] iteration 6290 : model1 loss : 0.373911 model2 loss : 0.334611
[22:21:14.654] iteration 6291 : model1 loss : 0.261026 model2 loss : 0.208188
[22:21:14.992] iteration 6292 : model1 loss : 0.363253 model2 loss : 0.292916
[22:21:15.331] iteration 6293 : model1 loss : 0.260378 model2 loss : 0.283926
[22:21:15.668] iteration 6294 : model1 loss : 0.322828 model2 loss : 0.358426
[22:21:16.006] iteration 6295 : model1 loss : 0.257983 model2 loss : 0.222432
[22:21:16.342] iteration 6296 : model1 loss : 0.290464 model2 loss : 0.276052
[22:21:16.678] iteration 6297 : model1 loss : 0.282825 model2 loss : 0.237280
[22:21:17.019] iteration 6298 : model1 loss : 0.194629 model2 loss : 0.232489
[22:21:17.360] iteration 6299 : model1 loss : 0.206561 model2 loss : 0.287327
[22:21:17.697] iteration 6300 : model1 loss : 0.262090 model2 loss : 0.279238
[22:21:18.333] iteration 6301 : model1 loss : 0.229877 model2 loss : 0.199957
[22:21:18.669] iteration 6302 : model1 loss : 0.215262 model2 loss : 0.240301
[22:21:19.005] iteration 6303 : model1 loss : 0.316023 model2 loss : 0.327321
[22:21:19.341] iteration 6304 : model1 loss : 0.232632 model2 loss : 0.209304
[22:21:19.679] iteration 6305 : model1 loss : 0.349011 model2 loss : 0.344984
[22:21:20.015] iteration 6306 : model1 loss : 0.213793 model2 loss : 0.194796
[22:21:20.352] iteration 6307 : model1 loss : 0.333016 model2 loss : 0.289752
[22:21:20.689] iteration 6308 : model1 loss : 0.345749 model2 loss : 0.374543
[22:21:21.025] iteration 6309 : model1 loss : 0.305052 model2 loss : 0.336788
[22:21:21.362] iteration 6310 : model1 loss : 0.219656 model2 loss : 0.193112
[22:21:21.698] iteration 6311 : model1 loss : 0.284361 model2 loss : 0.321009
[22:21:22.034] iteration 6312 : model1 loss : 0.305055 model2 loss : 0.261156
[22:21:22.371] iteration 6313 : model1 loss : 0.262535 model2 loss : 0.262190
[22:21:22.707] iteration 6314 : model1 loss : 0.285734 model2 loss : 0.289324
[22:21:23.044] iteration 6315 : model1 loss : 0.300141 model2 loss : 0.258458
[22:21:23.380] iteration 6316 : model1 loss : 0.200979 model2 loss : 0.200089
[22:21:23.716] iteration 6317 : model1 loss : 0.115614 model2 loss : 0.135839
[22:21:24.052] iteration 6318 : model1 loss : 0.301647 model2 loss : 0.237921
[22:21:24.388] iteration 6319 : model1 loss : 0.265727 model2 loss : 0.275468
[22:21:24.726] iteration 6320 : model1 loss : 0.341707 model2 loss : 0.284100
[22:21:25.064] iteration 6321 : model1 loss : 0.412584 model2 loss : 0.346008
[22:21:25.401] iteration 6322 : model1 loss : 0.205911 model2 loss : 0.240027
[22:21:25.739] iteration 6323 : model1 loss : 0.386323 model2 loss : 0.182522
[22:21:26.075] iteration 6324 : model1 loss : 0.294983 model2 loss : 0.238604
[22:21:26.412] iteration 6325 : model1 loss : 0.289882 model2 loss : 0.190006
[22:21:26.751] iteration 6326 : model1 loss : 0.301400 model2 loss : 0.319171
[22:21:27.087] iteration 6327 : model1 loss : 0.217017 model2 loss : 0.258451
[22:21:27.423] iteration 6328 : model1 loss : 0.243367 model2 loss : 0.221880
[22:21:27.761] iteration 6329 : model1 loss : 0.287107 model2 loss : 0.256578
[22:21:28.097] iteration 6330 : model1 loss : 0.186175 model2 loss : 0.209107
[22:21:28.434] iteration 6331 : model1 loss : 0.287647 model2 loss : 0.276489
[22:21:28.775] iteration 6332 : model1 loss : 0.266057 model2 loss : 0.282571
[22:21:29.111] iteration 6333 : model1 loss : 0.280828 model2 loss : 0.256766
[22:21:29.447] iteration 6334 : model1 loss : 0.185771 model2 loss : 0.202636
[22:21:29.782] iteration 6335 : model1 loss : 0.294859 model2 loss : 0.297012
[22:21:30.120] iteration 6336 : model1 loss : 0.252907 model2 loss : 0.182284
[22:21:30.457] iteration 6337 : model1 loss : 0.308482 model2 loss : 0.309652
[22:21:30.794] iteration 6338 : model1 loss : 0.312876 model2 loss : 0.275796
[22:21:31.130] iteration 6339 : model1 loss : 0.330526 model2 loss : 0.310380
[22:21:31.468] iteration 6340 : model1 loss : 0.271825 model2 loss : 0.188524
[22:21:31.806] iteration 6341 : model1 loss : 0.256160 model2 loss : 0.274991
[22:21:32.141] iteration 6342 : model1 loss : 0.207149 model2 loss : 0.229058
[22:21:32.478] iteration 6343 : model1 loss : 0.335830 model2 loss : 0.255548
[22:21:32.815] iteration 6344 : model1 loss : 0.290149 model2 loss : 0.279664
[22:21:33.152] iteration 6345 : model1 loss : 0.248965 model2 loss : 0.259610
[22:21:33.490] iteration 6346 : model1 loss : 0.285083 model2 loss : 0.284056
[22:21:33.827] iteration 6347 : model1 loss : 0.278367 model2 loss : 0.237917
[22:21:34.164] iteration 6348 : model1 loss : 0.321537 model2 loss : 0.215527
[22:21:34.500] iteration 6349 : model1 loss : 0.268811 model2 loss : 0.270213
[22:21:34.837] iteration 6350 : model1 loss : 0.238679 model2 loss : 0.197746
[22:21:35.483] iteration 6351 : model1 loss : 0.269822 model2 loss : 0.268530
[22:21:35.819] iteration 6352 : model1 loss : 0.185486 model2 loss : 0.206259
[22:21:36.155] iteration 6353 : model1 loss : 0.122707 model2 loss : 0.148951
[22:21:36.491] iteration 6354 : model1 loss : 0.275853 model2 loss : 0.233111
[22:21:36.827] iteration 6355 : model1 loss : 0.297957 model2 loss : 0.292145
[22:21:37.164] iteration 6356 : model1 loss : 0.182300 model2 loss : 0.190494
[22:21:37.501] iteration 6357 : model1 loss : 0.287953 model2 loss : 0.286123
[22:21:37.838] iteration 6358 : model1 loss : 0.172445 model2 loss : 0.209987
[22:21:38.175] iteration 6359 : model1 loss : 0.257230 model2 loss : 0.192339
[22:21:38.512] iteration 6360 : model1 loss : 0.204987 model2 loss : 0.212958
[22:21:38.848] iteration 6361 : model1 loss : 0.274635 model2 loss : 0.181702
[22:21:39.185] iteration 6362 : model1 loss : 0.256611 model2 loss : 0.288784
[22:21:39.521] iteration 6363 : model1 loss : 0.258497 model2 loss : 0.304411
[22:21:39.857] iteration 6364 : model1 loss : 0.200648 model2 loss : 0.187751
[22:21:40.195] iteration 6365 : model1 loss : 0.407218 model2 loss : 0.281871
[22:21:40.534] iteration 6366 : model1 loss : 0.293826 model2 loss : 0.301101
[22:21:40.872] iteration 6367 : model1 loss : 0.328765 model2 loss : 0.308960
[22:21:41.211] iteration 6368 : model1 loss : 0.359391 model2 loss : 0.368316
[22:21:41.549] iteration 6369 : model1 loss : 0.267000 model2 loss : 0.232300
[22:21:41.886] iteration 6370 : model1 loss : 0.244940 model2 loss : 0.196680
[22:21:42.222] iteration 6371 : model1 loss : 0.247386 model2 loss : 0.270171
[22:21:42.558] iteration 6372 : model1 loss : 0.392311 model2 loss : 0.320707
[22:21:42.894] iteration 6373 : model1 loss : 0.317452 model2 loss : 0.270249
[22:21:43.231] iteration 6374 : model1 loss : 0.336356 model2 loss : 0.241052
[22:21:43.568] iteration 6375 : model1 loss : 0.253116 model2 loss : 0.271200
[22:21:43.906] iteration 6376 : model1 loss : 0.301456 model2 loss : 0.307520
[22:21:44.243] iteration 6377 : model1 loss : 0.238961 model2 loss : 0.199991
[22:21:44.580] iteration 6378 : model1 loss : 0.307996 model2 loss : 0.293224
[22:21:44.921] iteration 6379 : model1 loss : 0.217382 model2 loss : 0.215169
[22:21:45.262] iteration 6380 : model1 loss : 0.292351 model2 loss : 0.331889
[22:21:45.601] iteration 6381 : model1 loss : 0.255662 model2 loss : 0.281203
[22:21:45.937] iteration 6382 : model1 loss : 0.262184 model2 loss : 0.288861
[22:21:46.274] iteration 6383 : model1 loss : 0.327248 model2 loss : 0.296461
[22:21:46.609] iteration 6384 : model1 loss : 0.271040 model2 loss : 0.251259
[22:21:46.945] iteration 6385 : model1 loss : 0.331450 model2 loss : 0.338986
[22:21:47.281] iteration 6386 : model1 loss : 0.390247 model2 loss : 0.380741
[22:21:47.618] iteration 6387 : model1 loss : 0.155371 model2 loss : 0.199426
[22:21:47.955] iteration 6388 : model1 loss : 0.235275 model2 loss : 0.330151
[22:21:48.291] iteration 6389 : model1 loss : 0.309075 model2 loss : 0.329242
[22:21:48.627] iteration 6390 : model1 loss : 0.267579 model2 loss : 0.307031
[22:21:48.963] iteration 6391 : model1 loss : 0.225016 model2 loss : 0.254808
[22:21:49.299] iteration 6392 : model1 loss : 0.258978 model2 loss : 0.247194
[22:21:49.635] iteration 6393 : model1 loss : 0.241627 model2 loss : 0.227558
[22:21:49.973] iteration 6394 : model1 loss : 0.244480 model2 loss : 0.180553
[22:21:50.313] iteration 6395 : model1 loss : 0.163252 model2 loss : 0.217381
[22:21:50.649] iteration 6396 : model1 loss : 0.250864 model2 loss : 0.246123
[22:21:50.987] iteration 6397 : model1 loss : 0.308941 model2 loss : 0.308716
[22:21:51.325] iteration 6398 : model1 loss : 0.197057 model2 loss : 0.221239
[22:21:51.661] iteration 6399 : model1 loss : 0.165811 model2 loss : 0.158100
[22:21:51.998] iteration 6400 : model1 loss : 0.292870 model2 loss : 0.278107
[22:21:52.651] iteration 6401 : model1 loss : 0.197009 model2 loss : 0.245142
[22:21:52.988] iteration 6402 : model1 loss : 0.201978 model2 loss : 0.198946
[22:21:53.325] iteration 6403 : model1 loss : 0.320053 model2 loss : 0.278640
[22:21:53.662] iteration 6404 : model1 loss : 0.324845 model2 loss : 0.281370
[22:21:53.998] iteration 6405 : model1 loss : 0.211828 model2 loss : 0.198929
[22:21:54.334] iteration 6406 : model1 loss : 0.358991 model2 loss : 0.355473
[22:21:54.669] iteration 6407 : model1 loss : 0.301390 model2 loss : 0.237523
[22:21:55.007] iteration 6408 : model1 loss : 0.353133 model2 loss : 0.380180
[22:21:55.347] iteration 6409 : model1 loss : 0.223735 model2 loss : 0.227260
[22:21:55.683] iteration 6410 : model1 loss : 0.211820 model2 loss : 0.207655
[22:21:56.019] iteration 6411 : model1 loss : 0.358756 model2 loss : 0.340777
[22:21:56.358] iteration 6412 : model1 loss : 0.262044 model2 loss : 0.205555
[22:21:56.693] iteration 6413 : model1 loss : 0.220967 model2 loss : 0.264415
[22:21:57.030] iteration 6414 : model1 loss : 0.222981 model2 loss : 0.211628
[22:21:57.366] iteration 6415 : model1 loss : 0.277385 model2 loss : 0.271089
[22:21:57.704] iteration 6416 : model1 loss : 0.370789 model2 loss : 0.417265
[22:21:58.041] iteration 6417 : model1 loss : 0.371083 model2 loss : 0.344390
[22:21:58.376] iteration 6418 : model1 loss : 0.462180 model2 loss : 0.408624
[22:21:58.712] iteration 6419 : model1 loss : 0.259827 model2 loss : 0.265409
[22:21:59.048] iteration 6420 : model1 loss : 0.265169 model2 loss : 0.223135
[22:21:59.385] iteration 6421 : model1 loss : 0.131369 model2 loss : 0.149429
[22:21:59.721] iteration 6422 : model1 loss : 0.326986 model2 loss : 0.367553
[22:22:00.058] iteration 6423 : model1 loss : 0.323288 model2 loss : 0.397397
[22:22:00.396] iteration 6424 : model1 loss : 0.339798 model2 loss : 0.304450
[22:22:00.734] iteration 6425 : model1 loss : 0.214500 model2 loss : 0.210954
[22:22:01.075] iteration 6426 : model1 loss : 0.233881 model2 loss : 0.236692
[22:22:01.412] iteration 6427 : model1 loss : 0.294549 model2 loss : 0.228367
[22:22:01.749] iteration 6428 : model1 loss : 0.150277 model2 loss : 0.203307
[22:22:02.086] iteration 6429 : model1 loss : 0.260920 model2 loss : 0.281349
[22:22:02.421] iteration 6430 : model1 loss : 0.221216 model2 loss : 0.287267
[22:22:02.757] iteration 6431 : model1 loss : 0.257772 model2 loss : 0.251898
[22:22:03.093] iteration 6432 : model1 loss : 0.180990 model2 loss : 0.188295
[22:22:03.430] iteration 6433 : model1 loss : 0.240715 model2 loss : 0.238217
[22:22:03.767] iteration 6434 : model1 loss : 0.238469 model2 loss : 0.250385
[22:22:04.103] iteration 6435 : model1 loss : 0.216617 model2 loss : 0.249947
[22:22:04.441] iteration 6436 : model1 loss : 0.204799 model2 loss : 0.252740
[22:22:04.778] iteration 6437 : model1 loss : 0.228517 model2 loss : 0.219497
[22:22:05.114] iteration 6438 : model1 loss : 0.257298 model2 loss : 0.218987
[22:22:05.452] iteration 6439 : model1 loss : 0.178898 model2 loss : 0.256606
[22:22:05.788] iteration 6440 : model1 loss : 0.261989 model2 loss : 0.276306
[22:22:06.125] iteration 6441 : model1 loss : 0.255097 model2 loss : 0.309266
[22:22:06.462] iteration 6442 : model1 loss : 0.217028 model2 loss : 0.223252
[22:22:06.799] iteration 6443 : model1 loss : 0.242784 model2 loss : 0.258851
[22:22:07.137] iteration 6444 : model1 loss : 0.300076 model2 loss : 0.307033
[22:22:07.477] iteration 6445 : model1 loss : 0.245595 model2 loss : 0.271439
[22:22:07.815] iteration 6446 : model1 loss : 0.327582 model2 loss : 0.310328
[22:22:08.152] iteration 6447 : model1 loss : 0.270155 model2 loss : 0.255520
[22:22:08.490] iteration 6448 : model1 loss : 0.269626 model2 loss : 0.322265
[22:22:08.829] iteration 6449 : model1 loss : 0.195213 model2 loss : 0.187730
[22:22:09.168] iteration 6450 : model1 loss : 0.204041 model2 loss : 0.277008
[22:22:09.819] iteration 6451 : model1 loss : 0.380221 model2 loss : 0.417885
[22:22:10.156] iteration 6452 : model1 loss : 0.227351 model2 loss : 0.263447
[22:22:10.493] iteration 6453 : model1 loss : 0.112443 model2 loss : 0.194719
[22:22:10.830] iteration 6454 : model1 loss : 0.283706 model2 loss : 0.254417
[22:22:11.166] iteration 6455 : model1 loss : 0.251620 model2 loss : 0.185088
[22:22:11.503] iteration 6456 : model1 loss : 0.232929 model2 loss : 0.216004
[22:22:11.840] iteration 6457 : model1 loss : 0.312015 model2 loss : 0.347235
[22:22:12.177] iteration 6458 : model1 loss : 0.309249 model2 loss : 0.263599
[22:22:12.520] iteration 6459 : model1 loss : 0.307942 model2 loss : 0.293383
[22:22:12.857] iteration 6460 : model1 loss : 0.201339 model2 loss : 0.231708
[22:22:13.193] iteration 6461 : model1 loss : 0.237309 model2 loss : 0.239638
[22:22:13.530] iteration 6462 : model1 loss : 0.249891 model2 loss : 0.243675
[22:22:13.866] iteration 6463 : model1 loss : 0.320344 model2 loss : 0.310114
[22:22:14.201] iteration 6464 : model1 loss : 0.352570 model2 loss : 0.359133
[22:22:14.538] iteration 6465 : model1 loss : 0.280213 model2 loss : 0.305207
[22:22:14.874] iteration 6466 : model1 loss : 0.375582 model2 loss : 0.341883
[22:22:15.210] iteration 6467 : model1 loss : 0.214018 model2 loss : 0.309270
[22:22:15.548] iteration 6468 : model1 loss : 0.281117 model2 loss : 0.308898
[22:22:15.890] iteration 6469 : model1 loss : 0.226095 model2 loss : 0.242004
[22:22:16.226] iteration 6470 : model1 loss : 0.183200 model2 loss : 0.179591
[22:22:16.562] iteration 6471 : model1 loss : 0.244818 model2 loss : 0.191645
[22:22:16.898] iteration 6472 : model1 loss : 0.249289 model2 loss : 0.238839
[22:22:17.237] iteration 6473 : model1 loss : 0.229346 model2 loss : 0.244976
[22:22:17.578] iteration 6474 : model1 loss : 0.298457 model2 loss : 0.286850
[22:22:17.915] iteration 6475 : model1 loss : 0.277316 model2 loss : 0.255344
[22:22:18.251] iteration 6476 : model1 loss : 0.199350 model2 loss : 0.223583
[22:22:18.589] iteration 6477 : model1 loss : 0.177295 model2 loss : 0.182090
[22:22:18.926] iteration 6478 : model1 loss : 0.244771 model2 loss : 0.270450
[22:22:19.262] iteration 6479 : model1 loss : 0.313571 model2 loss : 0.304750
[22:22:19.599] iteration 6480 : model1 loss : 0.332394 model2 loss : 0.309276
[22:22:19.939] iteration 6481 : model1 loss : 0.322225 model2 loss : 0.354283
[22:22:20.276] iteration 6482 : model1 loss : 0.201553 model2 loss : 0.221956
[22:22:20.612] iteration 6483 : model1 loss : 0.275380 model2 loss : 0.294516
[22:22:20.948] iteration 6484 : model1 loss : 0.284186 model2 loss : 0.279763
[22:22:21.284] iteration 6485 : model1 loss : 0.315162 model2 loss : 0.282021
[22:22:21.621] iteration 6486 : model1 loss : 0.230486 model2 loss : 0.279664
[22:22:21.958] iteration 6487 : model1 loss : 0.247137 model2 loss : 0.214344
[22:22:22.296] iteration 6488 : model1 loss : 0.206392 model2 loss : 0.245409
[22:22:22.634] iteration 6489 : model1 loss : 0.219181 model2 loss : 0.239348
[22:22:22.972] iteration 6490 : model1 loss : 0.291956 model2 loss : 0.281872
[22:22:23.309] iteration 6491 : model1 loss : 0.255122 model2 loss : 0.306565
[22:22:23.645] iteration 6492 : model1 loss : 0.389679 model2 loss : 0.388730
[22:22:23.982] iteration 6493 : model1 loss : 0.272631 model2 loss : 0.292717
[22:22:24.318] iteration 6494 : model1 loss : 0.259153 model2 loss : 0.309110
[22:22:24.655] iteration 6495 : model1 loss : 0.282682 model2 loss : 0.291878
[22:22:24.992] iteration 6496 : model1 loss : 0.187037 model2 loss : 0.142103
[22:22:25.334] iteration 6497 : model1 loss : 0.365205 model2 loss : 0.382982
[22:22:25.672] iteration 6498 : model1 loss : 0.218630 model2 loss : 0.243448
[22:22:26.010] iteration 6499 : model1 loss : 0.211045 model2 loss : 0.214090
[22:22:26.350] iteration 6500 : model1 loss : 0.266920 model2 loss : 0.205368
[22:22:27.011] iteration 6501 : model1 loss : 0.317036 model2 loss : 0.349320
[22:22:27.348] iteration 6502 : model1 loss : 0.263350 model2 loss : 0.280893
[22:22:27.688] iteration 6503 : model1 loss : 0.210692 model2 loss : 0.280659
[22:22:28.025] iteration 6504 : model1 loss : 0.143181 model2 loss : 0.204430
[22:22:28.363] iteration 6505 : model1 loss : 0.316474 model2 loss : 0.307405
[22:22:28.702] iteration 6506 : model1 loss : 0.209893 model2 loss : 0.217578
[22:22:29.039] iteration 6507 : model1 loss : 0.219182 model2 loss : 0.209442
[22:22:29.378] iteration 6508 : model1 loss : 0.154022 model2 loss : 0.189992
[22:22:29.724] iteration 6509 : model1 loss : 0.239003 model2 loss : 0.260831
[22:22:30.061] iteration 6510 : model1 loss : 0.210065 model2 loss : 0.206676
[22:22:30.401] iteration 6511 : model1 loss : 0.342950 model2 loss : 0.316585
[22:22:30.742] iteration 6512 : model1 loss : 0.211914 model2 loss : 0.258055
[22:22:31.079] iteration 6513 : model1 loss : 0.308327 model2 loss : 0.196307
[22:22:31.417] iteration 6514 : model1 loss : 0.239181 model2 loss : 0.242091
[22:22:31.754] iteration 6515 : model1 loss : 0.328776 model2 loss : 0.316615
[22:22:32.090] iteration 6516 : model1 loss : 0.217353 model2 loss : 0.257993
[22:22:32.428] iteration 6517 : model1 loss : 0.253621 model2 loss : 0.250330
[22:22:32.764] iteration 6518 : model1 loss : 0.317247 model2 loss : 0.305043
[22:22:33.100] iteration 6519 : model1 loss : 0.272089 model2 loss : 0.273077
[22:22:33.437] iteration 6520 : model1 loss : 0.303273 model2 loss : 0.338919
[22:22:33.775] iteration 6521 : model1 loss : 0.309662 model2 loss : 0.255341
[22:22:34.112] iteration 6522 : model1 loss : 0.273358 model2 loss : 0.228310
[22:22:34.440] iteration 6523 : model1 loss : 0.151866 model2 loss : 0.187568
[22:22:34.768] iteration 6524 : model1 loss : 0.203413 model2 loss : 0.234570
[22:22:35.097] iteration 6525 : model1 loss : 0.343002 model2 loss : 0.316493
[22:22:35.426] iteration 6526 : model1 loss : 0.140321 model2 loss : 0.191928
[22:22:35.756] iteration 6527 : model1 loss : 0.266288 model2 loss : 0.218196
[22:22:36.087] iteration 6528 : model1 loss : 0.239579 model2 loss : 0.250479
[22:22:36.415] iteration 6529 : model1 loss : 0.272276 model2 loss : 0.259039
[22:22:36.742] iteration 6530 : model1 loss : 0.203399 model2 loss : 0.206770
[22:22:37.070] iteration 6531 : model1 loss : 0.317108 model2 loss : 0.318219
[22:22:37.398] iteration 6532 : model1 loss : 0.482051 model2 loss : 0.387832
[22:22:37.725] iteration 6533 : model1 loss : 0.170503 model2 loss : 0.176430
[22:22:38.052] iteration 6534 : model1 loss : 0.309228 model2 loss : 0.301817
[22:22:38.378] iteration 6535 : model1 loss : 0.249572 model2 loss : 0.246357
[22:22:38.705] iteration 6536 : model1 loss : 0.289889 model2 loss : 0.303994
[22:22:39.031] iteration 6537 : model1 loss : 0.204531 model2 loss : 0.308497
[22:22:39.358] iteration 6538 : model1 loss : 0.280626 model2 loss : 0.304871
[22:22:39.684] iteration 6539 : model1 loss : 0.298016 model2 loss : 0.297348
[22:22:40.012] iteration 6540 : model1 loss : 0.274360 model2 loss : 0.307009
[22:22:40.911] iteration 6541 : model1 loss : 0.267390 model2 loss : 0.286773
[22:22:41.239] iteration 6542 : model1 loss : 0.242239 model2 loss : 0.261116
[22:22:41.563] iteration 6543 : model1 loss : 0.213484 model2 loss : 0.283977
[22:22:41.891] iteration 6544 : model1 loss : 0.201790 model2 loss : 0.264944
[22:22:42.220] iteration 6545 : model1 loss : 0.334426 model2 loss : 0.336364
[22:22:42.549] iteration 6546 : model1 loss : 0.268767 model2 loss : 0.297805
[22:22:42.873] iteration 6547 : model1 loss : 0.333402 model2 loss : 0.341060
[22:22:43.201] iteration 6548 : model1 loss : 0.282597 model2 loss : 0.262944
[22:22:43.529] iteration 6549 : model1 loss : 0.268076 model2 loss : 0.295293
[22:22:43.858] iteration 6550 : model1 loss : 0.271686 model2 loss : 0.269893
[22:22:44.432] iteration 6551 : model1 loss : 0.269351 model2 loss : 0.320262
[22:22:44.764] iteration 6552 : model1 loss : 0.208906 model2 loss : 0.189035
[22:22:45.097] iteration 6553 : model1 loss : 0.123547 model2 loss : 0.170319
[22:22:45.426] iteration 6554 : model1 loss : 0.217962 model2 loss : 0.223722
[22:22:45.754] iteration 6555 : model1 loss : 0.338611 model2 loss : 0.375320
[22:22:46.082] iteration 6556 : model1 loss : 0.312670 model2 loss : 0.336907
[22:22:46.410] iteration 6557 : model1 loss : 0.256370 model2 loss : 0.296170
[22:22:46.739] iteration 6558 : model1 loss : 0.186427 model2 loss : 0.184340
[22:22:47.068] iteration 6559 : model1 loss : 0.171509 model2 loss : 0.244422
[22:22:47.397] iteration 6560 : model1 loss : 0.318011 model2 loss : 0.313307
[22:22:47.726] iteration 6561 : model1 loss : 0.271282 model2 loss : 0.368222
[22:22:48.055] iteration 6562 : model1 loss : 0.166113 model2 loss : 0.167317
[22:22:48.384] iteration 6563 : model1 loss : 0.316781 model2 loss : 0.349075
[22:22:48.711] iteration 6564 : model1 loss : 0.154458 model2 loss : 0.154883
[22:22:49.039] iteration 6565 : model1 loss : 0.247051 model2 loss : 0.339750
[22:22:49.367] iteration 6566 : model1 loss : 0.243824 model2 loss : 0.272777
[22:22:49.695] iteration 6567 : model1 loss : 0.259708 model2 loss : 0.136267
[22:22:50.023] iteration 6568 : model1 loss : 0.292415 model2 loss : 0.320708
[22:22:50.352] iteration 6569 : model1 loss : 0.322965 model2 loss : 0.320207
[22:22:50.683] iteration 6570 : model1 loss : 0.307059 model2 loss : 0.328573
[22:22:51.010] iteration 6571 : model1 loss : 0.298017 model2 loss : 0.340497
[22:22:51.339] iteration 6572 : model1 loss : 0.219784 model2 loss : 0.165153
[22:22:51.668] iteration 6573 : model1 loss : 0.280018 model2 loss : 0.267085
[22:22:51.997] iteration 6574 : model1 loss : 0.253409 model2 loss : 0.198303
[22:22:52.328] iteration 6575 : model1 loss : 0.275785 model2 loss : 0.318853
[22:22:52.655] iteration 6576 : model1 loss : 0.259233 model2 loss : 0.305384
[22:22:52.983] iteration 6577 : model1 loss : 0.197123 model2 loss : 0.180927
[22:22:53.312] iteration 6578 : model1 loss : 0.213045 model2 loss : 0.223652
[22:22:53.636] iteration 6579 : model1 loss : 0.328907 model2 loss : 0.302432
[22:22:53.965] iteration 6580 : model1 loss : 0.257028 model2 loss : 0.238363
[22:22:54.293] iteration 6581 : model1 loss : 0.250363 model2 loss : 0.234774
[22:22:54.630] iteration 6582 : model1 loss : 0.219804 model2 loss : 0.181659
[22:22:54.958] iteration 6583 : model1 loss : 0.323446 model2 loss : 0.300464
[22:22:55.287] iteration 6584 : model1 loss : 0.273779 model2 loss : 0.305556
[22:22:55.615] iteration 6585 : model1 loss : 0.354106 model2 loss : 0.349357
[22:22:55.942] iteration 6586 : model1 loss : 0.339231 model2 loss : 0.264739
[22:22:56.271] iteration 6587 : model1 loss : 0.215181 model2 loss : 0.200924
[22:22:56.598] iteration 6588 : model1 loss : 0.318549 model2 loss : 0.320828
[22:22:56.926] iteration 6589 : model1 loss : 0.162764 model2 loss : 0.174115
[22:22:57.254] iteration 6590 : model1 loss : 0.270375 model2 loss : 0.256576
[22:22:57.582] iteration 6591 : model1 loss : 0.267113 model2 loss : 0.341299
[22:22:57.909] iteration 6592 : model1 loss : 0.393541 model2 loss : 0.378443
[22:22:58.237] iteration 6593 : model1 loss : 0.268047 model2 loss : 0.252188
[22:22:58.565] iteration 6594 : model1 loss : 0.326500 model2 loss : 0.332985
[22:22:58.892] iteration 6595 : model1 loss : 0.261137 model2 loss : 0.211772
[22:22:59.220] iteration 6596 : model1 loss : 0.320974 model2 loss : 0.327937
[22:22:59.554] iteration 6597 : model1 loss : 0.247149 model2 loss : 0.250851
[22:22:59.880] iteration 6598 : model1 loss : 0.358007 model2 loss : 0.332190
[22:23:00.206] iteration 6599 : model1 loss : 0.335415 model2 loss : 0.295995
[22:23:00.532] iteration 6600 : model1 loss : 0.183148 model2 loss : 0.258994
[22:23:01.035] iteration 6601 : model1 loss : 0.375632 model2 loss : 0.200127
[22:23:01.362] iteration 6602 : model1 loss : 0.327579 model2 loss : 0.340757
[22:23:01.689] iteration 6603 : model1 loss : 0.291149 model2 loss : 0.339410
[22:23:02.021] iteration 6604 : model1 loss : 0.232915 model2 loss : 0.271237
[22:23:02.352] iteration 6605 : model1 loss : 0.230075 model2 loss : 0.284435
[22:23:02.678] iteration 6606 : model1 loss : 0.306487 model2 loss : 0.334492
[22:23:03.005] iteration 6607 : model1 loss : 0.283165 model2 loss : 0.275585
[22:23:03.332] iteration 6608 : model1 loss : 0.222342 model2 loss : 0.224952
[22:23:03.658] iteration 6609 : model1 loss : 0.238401 model2 loss : 0.257217
[22:23:03.985] iteration 6610 : model1 loss : 0.234634 model2 loss : 0.265424
[22:23:04.311] iteration 6611 : model1 loss : 0.225874 model2 loss : 0.266193
[22:23:04.642] iteration 6612 : model1 loss : 0.254802 model2 loss : 0.256133
[22:23:04.968] iteration 6613 : model1 loss : 0.330620 model2 loss : 0.202804
[22:23:05.295] iteration 6614 : model1 loss : 0.318291 model2 loss : 0.278416
[22:23:05.621] iteration 6615 : model1 loss : 0.328867 model2 loss : 0.253405
[22:23:05.947] iteration 6616 : model1 loss : 0.414489 model2 loss : 0.356928
[22:23:06.275] iteration 6617 : model1 loss : 0.268247 model2 loss : 0.225764
[22:23:06.601] iteration 6618 : model1 loss : 0.361315 model2 loss : 0.323855
[22:23:06.928] iteration 6619 : model1 loss : 0.335191 model2 loss : 0.328594
[22:23:07.254] iteration 6620 : model1 loss : 0.279329 model2 loss : 0.193587
[22:23:07.579] iteration 6621 : model1 loss : 0.302140 model2 loss : 0.227747
[22:23:07.906] iteration 6622 : model1 loss : 0.320310 model2 loss : 0.297635
[22:23:08.232] iteration 6623 : model1 loss : 0.306750 model2 loss : 0.305713
[22:23:08.557] iteration 6624 : model1 loss : 0.321435 model2 loss : 0.307635
[22:23:08.883] iteration 6625 : model1 loss : 0.280118 model2 loss : 0.301666
[22:23:09.209] iteration 6626 : model1 loss : 0.268130 model2 loss : 0.272877
[22:23:09.536] iteration 6627 : model1 loss : 0.214171 model2 loss : 0.220074
[22:23:09.862] iteration 6628 : model1 loss : 0.228955 model2 loss : 0.255346
[22:23:10.189] iteration 6629 : model1 loss : 0.389136 model2 loss : 0.353797
[22:23:10.515] iteration 6630 : model1 loss : 0.385135 model2 loss : 0.317115
[22:23:10.841] iteration 6631 : model1 loss : 0.304161 model2 loss : 0.295790
[22:23:11.168] iteration 6632 : model1 loss : 0.372008 model2 loss : 0.338119
[22:23:11.493] iteration 6633 : model1 loss : 0.235434 model2 loss : 0.228436
[22:23:11.821] iteration 6634 : model1 loss : 0.280841 model2 loss : 0.205268
[22:23:12.148] iteration 6635 : model1 loss : 0.255532 model2 loss : 0.259408
[22:23:12.474] iteration 6636 : model1 loss : 0.265979 model2 loss : 0.265566
[22:23:12.802] iteration 6637 : model1 loss : 0.333040 model2 loss : 0.255029
[22:23:13.128] iteration 6638 : model1 loss : 0.205514 model2 loss : 0.232342
[22:23:13.455] iteration 6639 : model1 loss : 0.302734 model2 loss : 0.274900
[22:23:13.781] iteration 6640 : model1 loss : 0.269499 model2 loss : 0.305216
[22:23:14.107] iteration 6641 : model1 loss : 0.303318 model2 loss : 0.255096
[22:23:14.437] iteration 6642 : model1 loss : 0.216659 model2 loss : 0.213671
[22:23:14.764] iteration 6643 : model1 loss : 0.244192 model2 loss : 0.267958
[22:23:15.091] iteration 6644 : model1 loss : 0.254118 model2 loss : 0.244185
[22:23:15.418] iteration 6645 : model1 loss : 0.192836 model2 loss : 0.184510
[22:23:15.746] iteration 6646 : model1 loss : 0.249502 model2 loss : 0.267124
[22:23:16.076] iteration 6647 : model1 loss : 0.271685 model2 loss : 0.228847
[22:23:16.403] iteration 6648 : model1 loss : 0.247647 model2 loss : 0.242202
[22:23:16.730] iteration 6649 : model1 loss : 0.160070 model2 loss : 0.189118
[22:23:17.057] iteration 6650 : model1 loss : 0.283129 model2 loss : 0.225659
[22:23:17.592] iteration 6651 : model1 loss : 0.153247 model2 loss : 0.173867
[22:23:17.918] iteration 6652 : model1 loss : 0.199068 model2 loss : 0.220222
[22:23:18.244] iteration 6653 : model1 loss : 0.226518 model2 loss : 0.255099
[22:23:18.570] iteration 6654 : model1 loss : 0.288337 model2 loss : 0.278331
[22:23:18.897] iteration 6655 : model1 loss : 0.315726 model2 loss : 0.307368
[22:23:19.224] iteration 6656 : model1 loss : 0.277552 model2 loss : 0.303444
[22:23:19.550] iteration 6657 : model1 loss : 0.252370 model2 loss : 0.245285
[22:23:19.877] iteration 6658 : model1 loss : 0.200181 model2 loss : 0.191697
[22:23:20.203] iteration 6659 : model1 loss : 0.263570 model2 loss : 0.228613
[22:23:20.529] iteration 6660 : model1 loss : 0.290190 model2 loss : 0.282951
[22:23:20.854] iteration 6661 : model1 loss : 0.201688 model2 loss : 0.210002
[22:23:21.180] iteration 6662 : model1 loss : 0.313530 model2 loss : 0.233596
[22:23:21.508] iteration 6663 : model1 loss : 0.249028 model2 loss : 0.249842
[22:23:21.838] iteration 6664 : model1 loss : 0.266427 model2 loss : 0.248737
[22:23:22.165] iteration 6665 : model1 loss : 0.400920 model2 loss : 0.413561
[22:23:22.494] iteration 6666 : model1 loss : 0.251346 model2 loss : 0.265417
[22:23:22.821] iteration 6667 : model1 loss : 0.268817 model2 loss : 0.357162
[22:23:23.149] iteration 6668 : model1 loss : 0.313726 model2 loss : 0.254784
[22:23:23.477] iteration 6669 : model1 loss : 0.247997 model2 loss : 0.268820
[22:23:23.804] iteration 6670 : model1 loss : 0.346525 model2 loss : 0.347561
[22:23:24.132] iteration 6671 : model1 loss : 0.178340 model2 loss : 0.251483
[22:23:24.460] iteration 6672 : model1 loss : 0.256526 model2 loss : 0.328186
[22:23:24.788] iteration 6673 : model1 loss : 0.150209 model2 loss : 0.215776
[22:23:25.116] iteration 6674 : model1 loss : 0.277887 model2 loss : 0.292013
[22:23:25.444] iteration 6675 : model1 loss : 0.283785 model2 loss : 0.300158
[22:23:25.771] iteration 6676 : model1 loss : 0.270632 model2 loss : 0.292121
[22:23:26.099] iteration 6677 : model1 loss : 0.287763 model2 loss : 0.304901
[22:23:26.427] iteration 6678 : model1 loss : 0.260262 model2 loss : 0.276057
[22:23:26.755] iteration 6679 : model1 loss : 0.319274 model2 loss : 0.276124
[22:23:27.083] iteration 6680 : model1 loss : 0.330153 model2 loss : 0.294844
[22:23:27.410] iteration 6681 : model1 loss : 0.389206 model2 loss : 0.325150
[22:23:27.739] iteration 6682 : model1 loss : 0.300032 model2 loss : 0.329417
[22:23:28.066] iteration 6683 : model1 loss : 0.124910 model2 loss : 0.125131
[22:23:28.394] iteration 6684 : model1 loss : 0.296293 model2 loss : 0.345564
[22:23:28.723] iteration 6685 : model1 loss : 0.243353 model2 loss : 0.294374
[22:23:29.051] iteration 6686 : model1 loss : 0.214416 model2 loss : 0.200696
[22:23:29.378] iteration 6687 : model1 loss : 0.307877 model2 loss : 0.328203
[22:23:29.706] iteration 6688 : model1 loss : 0.200321 model2 loss : 0.249218
[22:23:30.034] iteration 6689 : model1 loss : 0.378577 model2 loss : 0.291575
[22:23:30.363] iteration 6690 : model1 loss : 0.259095 model2 loss : 0.265229
[22:23:30.690] iteration 6691 : model1 loss : 0.220645 model2 loss : 0.225363
[22:23:31.019] iteration 6692 : model1 loss : 0.202864 model2 loss : 0.231021
[22:23:31.348] iteration 6693 : model1 loss : 0.216944 model2 loss : 0.211973
[22:23:31.676] iteration 6694 : model1 loss : 0.206468 model2 loss : 0.220923
[22:23:32.004] iteration 6695 : model1 loss : 0.270041 model2 loss : 0.210228
[22:23:32.331] iteration 6696 : model1 loss : 0.288838 model2 loss : 0.269208
[22:23:32.658] iteration 6697 : model1 loss : 0.260040 model2 loss : 0.289205
[22:23:32.986] iteration 6698 : model1 loss : 0.273346 model2 loss : 0.262320
[22:23:33.314] iteration 6699 : model1 loss : 0.290002 model2 loss : 0.316992
[22:23:33.642] iteration 6700 : model1 loss : 0.345473 model2 loss : 0.307467
[22:23:34.157] iteration 6701 : model1 loss : 0.249579 model2 loss : 0.218822
[22:23:34.485] iteration 6702 : model1 loss : 0.317548 model2 loss : 0.271339
[22:23:34.813] iteration 6703 : model1 loss : 0.309238 model2 loss : 0.330176
[22:23:35.140] iteration 6704 : model1 loss : 0.304605 model2 loss : 0.292928
[22:23:35.469] iteration 6705 : model1 loss : 0.373713 model2 loss : 0.391726
[22:23:35.797] iteration 6706 : model1 loss : 0.137532 model2 loss : 0.126612
[22:23:36.126] iteration 6707 : model1 loss : 0.236081 model2 loss : 0.258379
[22:23:36.454] iteration 6708 : model1 loss : 0.204647 model2 loss : 0.246660
[22:23:36.782] iteration 6709 : model1 loss : 0.329916 model2 loss : 0.341008
[22:23:37.110] iteration 6710 : model1 loss : 0.230113 model2 loss : 0.162808
[22:23:37.440] iteration 6711 : model1 loss : 0.241396 model2 loss : 0.296456
[22:23:37.769] iteration 6712 : model1 loss : 0.292792 model2 loss : 0.349622
[22:23:38.099] iteration 6713 : model1 loss : 0.358047 model2 loss : 0.389523
[22:23:38.428] iteration 6714 : model1 loss : 0.215197 model2 loss : 0.196889
[22:23:38.756] iteration 6715 : model1 loss : 0.175086 model2 loss : 0.144096
[22:23:39.085] iteration 6716 : model1 loss : 0.292866 model2 loss : 0.255504
[22:23:39.416] iteration 6717 : model1 loss : 0.299182 model2 loss : 0.183930
[22:23:39.746] iteration 6718 : model1 loss : 0.263127 model2 loss : 0.312096
[22:23:40.074] iteration 6719 : model1 loss : 0.364869 model2 loss : 0.396050
[22:23:40.403] iteration 6720 : model1 loss : 0.177160 model2 loss : 0.247442
[22:23:40.732] iteration 6721 : model1 loss : 0.320820 model2 loss : 0.382564
[22:23:41.061] iteration 6722 : model1 loss : 0.116419 model2 loss : 0.102304
[22:23:41.389] iteration 6723 : model1 loss : 0.316386 model2 loss : 0.314511
[22:23:41.716] iteration 6724 : model1 loss : 0.360746 model2 loss : 0.379384
[22:23:42.043] iteration 6725 : model1 loss : 0.358068 model2 loss : 0.325260
[22:23:42.370] iteration 6726 : model1 loss : 0.231609 model2 loss : 0.313099
[22:23:42.697] iteration 6727 : model1 loss : 0.231118 model2 loss : 0.278777
[22:23:43.024] iteration 6728 : model1 loss : 0.260399 model2 loss : 0.325412
[22:23:43.350] iteration 6729 : model1 loss : 0.325384 model2 loss : 0.312491
[22:23:43.677] iteration 6730 : model1 loss : 0.130689 model2 loss : 0.159044
[22:23:44.004] iteration 6731 : model1 loss : 0.217231 model2 loss : 0.198539
[22:23:44.330] iteration 6732 : model1 loss : 0.343120 model2 loss : 0.328871
[22:23:44.657] iteration 6733 : model1 loss : 0.324314 model2 loss : 0.309577
[22:23:44.983] iteration 6734 : model1 loss : 0.301455 model2 loss : 0.275161
[22:23:45.311] iteration 6735 : model1 loss : 0.243136 model2 loss : 0.223590
[22:23:45.637] iteration 6736 : model1 loss : 0.225565 model2 loss : 0.183073
[22:23:45.964] iteration 6737 : model1 loss : 0.313948 model2 loss : 0.310471
[22:23:46.291] iteration 6738 : model1 loss : 0.241401 model2 loss : 0.281392
[22:23:46.618] iteration 6739 : model1 loss : 0.284113 model2 loss : 0.310039
[22:23:46.944] iteration 6740 : model1 loss : 0.246123 model2 loss : 0.197591
[22:23:47.271] iteration 6741 : model1 loss : 0.176181 model2 loss : 0.247799
[22:23:47.597] iteration 6742 : model1 loss : 0.213101 model2 loss : 0.256126
[22:23:47.924] iteration 6743 : model1 loss : 0.341606 model2 loss : 0.407281
[22:23:48.251] iteration 6744 : model1 loss : 0.160655 model2 loss : 0.175417
[22:23:48.577] iteration 6745 : model1 loss : 0.213122 model2 loss : 0.236294
[22:23:48.906] iteration 6746 : model1 loss : 0.287931 model2 loss : 0.355183
[22:23:49.232] iteration 6747 : model1 loss : 0.203802 model2 loss : 0.250517
[22:23:49.559] iteration 6748 : model1 loss : 0.359637 model2 loss : 0.372333
[22:23:49.886] iteration 6749 : model1 loss : 0.214430 model2 loss : 0.252999
[22:23:50.213] iteration 6750 : model1 loss : 0.209933 model2 loss : 0.219654
[22:23:50.669] iteration 6751 : model1 loss : 0.201148 model2 loss : 0.248209
[22:23:50.996] iteration 6752 : model1 loss : 0.352284 model2 loss : 0.323613
[22:23:51.323] iteration 6753 : model1 loss : 0.293679 model2 loss : 0.229262
[22:23:51.650] iteration 6754 : model1 loss : 0.129954 model2 loss : 0.158597
[22:23:51.977] iteration 6755 : model1 loss : 0.195620 model2 loss : 0.199872
[22:23:52.304] iteration 6756 : model1 loss : 0.298395 model2 loss : 0.242449
[22:23:52.630] iteration 6757 : model1 loss : 0.289806 model2 loss : 0.312013
[22:23:52.958] iteration 6758 : model1 loss : 0.219551 model2 loss : 0.136500
[22:23:53.286] iteration 6759 : model1 loss : 0.200204 model2 loss : 0.223113
[22:23:53.613] iteration 6760 : model1 loss : 0.404856 model2 loss : 0.323705
[22:23:53.939] iteration 6761 : model1 loss : 0.218075 model2 loss : 0.260538
[22:23:54.266] iteration 6762 : model1 loss : 0.321619 model2 loss : 0.269440
[22:23:54.593] iteration 6763 : model1 loss : 0.172540 model2 loss : 0.171226
[22:23:54.919] iteration 6764 : model1 loss : 0.183169 model2 loss : 0.250708
[22:23:55.246] iteration 6765 : model1 loss : 0.257325 model2 loss : 0.260124
[22:23:55.573] iteration 6766 : model1 loss : 0.196040 model2 loss : 0.193790
[22:23:55.900] iteration 6767 : model1 loss : 0.148394 model2 loss : 0.166732
[22:23:56.226] iteration 6768 : model1 loss : 0.177235 model2 loss : 0.170154
[22:23:56.553] iteration 6769 : model1 loss : 0.240139 model2 loss : 0.208303
[22:23:56.879] iteration 6770 : model1 loss : 0.271311 model2 loss : 0.355552
[22:23:57.206] iteration 6771 : model1 loss : 0.361888 model2 loss : 0.376310
[22:23:57.532] iteration 6772 : model1 loss : 0.299880 model2 loss : 0.281778
[22:23:57.858] iteration 6773 : model1 loss : 0.186671 model2 loss : 0.221024
[22:23:58.185] iteration 6774 : model1 loss : 0.282877 model2 loss : 0.320117
[22:23:58.512] iteration 6775 : model1 loss : 0.180282 model2 loss : 0.206091
[22:23:58.839] iteration 6776 : model1 loss : 0.250236 model2 loss : 0.347794
[22:23:59.166] iteration 6777 : model1 loss : 0.310881 model2 loss : 0.250910
[22:23:59.493] iteration 6778 : model1 loss : 0.290037 model2 loss : 0.243556
[22:23:59.822] iteration 6779 : model1 loss : 0.223302 model2 loss : 0.242868
[22:24:00.149] iteration 6780 : model1 loss : 0.344268 model2 loss : 0.296914
[22:24:00.475] iteration 6781 : model1 loss : 0.278857 model2 loss : 0.238707
[22:24:00.803] iteration 6782 : model1 loss : 0.156750 model2 loss : 0.226046
[22:24:01.134] iteration 6783 : model1 loss : 0.166547 model2 loss : 0.177610
[22:24:01.462] iteration 6784 : model1 loss : 0.286468 model2 loss : 0.326784
[22:24:01.789] iteration 6785 : model1 loss : 0.283757 model2 loss : 0.290632
[22:24:02.116] iteration 6786 : model1 loss : 0.197628 model2 loss : 0.197115
[22:24:02.449] iteration 6787 : model1 loss : 0.300732 model2 loss : 0.302169
[22:24:02.775] iteration 6788 : model1 loss : 0.272874 model2 loss : 0.268661
[22:24:03.102] iteration 6789 : model1 loss : 0.310133 model2 loss : 0.386554
[22:24:03.431] iteration 6790 : model1 loss : 0.256593 model2 loss : 0.314258
[22:24:03.758] iteration 6791 : model1 loss : 0.208040 model2 loss : 0.216891
[22:24:04.085] iteration 6792 : model1 loss : 0.155665 model2 loss : 0.216652
[22:24:04.412] iteration 6793 : model1 loss : 0.147301 model2 loss : 0.140664
[22:24:04.739] iteration 6794 : model1 loss : 0.132213 model2 loss : 0.169531
[22:24:05.066] iteration 6795 : model1 loss : 0.216022 model2 loss : 0.226767
[22:24:05.392] iteration 6796 : model1 loss : 0.176526 model2 loss : 0.165085
[22:24:05.719] iteration 6797 : model1 loss : 0.273249 model2 loss : 0.311086
[22:24:06.046] iteration 6798 : model1 loss : 0.237959 model2 loss : 0.302663
[22:24:06.373] iteration 6799 : model1 loss : 0.275843 model2 loss : 0.277059
[22:24:06.700] iteration 6800 : model1 loss : 0.260499 model2 loss : 0.292827
[22:24:07.173] iteration 6801 : model1 loss : 0.353960 model2 loss : 0.337978
[22:24:07.502] iteration 6802 : model1 loss : 0.240450 model2 loss : 0.252075
[22:24:07.828] iteration 6803 : model1 loss : 0.301734 model2 loss : 0.257593
[22:24:08.156] iteration 6804 : model1 loss : 0.233514 model2 loss : 0.322766
[22:24:08.483] iteration 6805 : model1 loss : 0.161142 model2 loss : 0.199939
[22:24:08.811] iteration 6806 : model1 loss : 0.252729 model2 loss : 0.298857
[22:24:09.138] iteration 6807 : model1 loss : 0.200209 model2 loss : 0.280778
[22:24:09.466] iteration 6808 : model1 loss : 0.270840 model2 loss : 0.217463
[22:24:09.792] iteration 6809 : model1 loss : 0.182892 model2 loss : 0.203420
[22:24:10.121] iteration 6810 : model1 loss : 0.359919 model2 loss : 0.324456
[22:24:10.448] iteration 6811 : model1 loss : 0.239245 model2 loss : 0.364151
[22:24:10.775] iteration 6812 : model1 loss : 0.315083 model2 loss : 0.274302
[22:24:11.102] iteration 6813 : model1 loss : 0.248335 model2 loss : 0.286499
[22:24:11.429] iteration 6814 : model1 loss : 0.354097 model2 loss : 0.343186
[22:24:11.756] iteration 6815 : model1 loss : 0.282548 model2 loss : 0.281123
[22:24:12.083] iteration 6816 : model1 loss : 0.129474 model2 loss : 0.182430
[22:24:12.411] iteration 6817 : model1 loss : 0.319919 model2 loss : 0.352311
[22:24:12.739] iteration 6818 : model1 loss : 0.302522 model2 loss : 0.282131
[22:24:13.065] iteration 6819 : model1 loss : 0.276971 model2 loss : 0.253217
[22:24:13.393] iteration 6820 : model1 loss : 0.188489 model2 loss : 0.219331
[22:24:13.720] iteration 6821 : model1 loss : 0.287342 model2 loss : 0.300962
[22:24:14.048] iteration 6822 : model1 loss : 0.256568 model2 loss : 0.274360
[22:24:14.375] iteration 6823 : model1 loss : 0.238395 model2 loss : 0.301644
[22:24:14.703] iteration 6824 : model1 loss : 0.273439 model2 loss : 0.286643
[22:24:15.029] iteration 6825 : model1 loss : 0.193013 model2 loss : 0.211737
[22:24:15.357] iteration 6826 : model1 loss : 0.219297 model2 loss : 0.280522
[22:24:15.684] iteration 6827 : model1 loss : 0.220384 model2 loss : 0.226602
[22:24:16.011] iteration 6828 : model1 loss : 0.144616 model2 loss : 0.222575
[22:24:16.338] iteration 6829 : model1 loss : 0.176723 model2 loss : 0.227970
[22:24:16.665] iteration 6830 : model1 loss : 0.221103 model2 loss : 0.218837
[22:24:16.991] iteration 6831 : model1 loss : 0.239108 model2 loss : 0.245455
[22:24:17.317] iteration 6832 : model1 loss : 0.217053 model2 loss : 0.265726
[22:24:17.644] iteration 6833 : model1 loss : 0.282412 model2 loss : 0.254755
[22:24:17.970] iteration 6834 : model1 loss : 0.267831 model2 loss : 0.301334
[22:24:18.296] iteration 6835 : model1 loss : 0.312456 model2 loss : 0.343786
[22:24:18.623] iteration 6836 : model1 loss : 0.345439 model2 loss : 0.361380
[22:24:18.948] iteration 6837 : model1 loss : 0.171508 model2 loss : 0.168116
[22:24:19.275] iteration 6838 : model1 loss : 0.261616 model2 loss : 0.310061
[22:24:19.603] iteration 6839 : model1 loss : 0.320780 model2 loss : 0.306770
[22:24:19.929] iteration 6840 : model1 loss : 0.272749 model2 loss : 0.245274
[22:24:20.256] iteration 6841 : model1 loss : 0.173681 model2 loss : 0.118822
[22:24:20.583] iteration 6842 : model1 loss : 0.202711 model2 loss : 0.223908
[22:24:20.910] iteration 6843 : model1 loss : 0.215824 model2 loss : 0.237628
[22:24:21.236] iteration 6844 : model1 loss : 0.208580 model2 loss : 0.229778
[22:24:21.563] iteration 6845 : model1 loss : 0.343936 model2 loss : 0.333006
[22:24:21.890] iteration 6846 : model1 loss : 0.348202 model2 loss : 0.296751
[22:24:22.216] iteration 6847 : model1 loss : 0.201544 model2 loss : 0.210446
[22:24:22.544] iteration 6848 : model1 loss : 0.263894 model2 loss : 0.232558
[22:24:22.870] iteration 6849 : model1 loss : 0.341199 model2 loss : 0.349314
[22:24:23.197] iteration 6850 : model1 loss : 0.208636 model2 loss : 0.239877
[22:24:23.653] iteration 6851 : model1 loss : 0.239801 model2 loss : 0.199843
[22:24:23.980] iteration 6852 : model1 loss : 0.246017 model2 loss : 0.301402
[22:24:24.307] iteration 6853 : model1 loss : 0.247769 model2 loss : 0.290946
[22:24:24.634] iteration 6854 : model1 loss : 0.220870 model2 loss : 0.220273
[22:24:24.962] iteration 6855 : model1 loss : 0.178097 model2 loss : 0.223255
[22:24:25.291] iteration 6856 : model1 loss : 0.209878 model2 loss : 0.194885
[22:24:25.620] iteration 6857 : model1 loss : 0.246205 model2 loss : 0.268836
[22:24:25.949] iteration 6858 : model1 loss : 0.283636 model2 loss : 0.278767
[22:24:26.278] iteration 6859 : model1 loss : 0.353123 model2 loss : 0.294063
[22:24:26.607] iteration 6860 : model1 loss : 0.301011 model2 loss : 0.211407
[22:24:26.935] iteration 6861 : model1 loss : 0.200712 model2 loss : 0.225646
[22:24:27.264] iteration 6862 : model1 loss : 0.243063 model2 loss : 0.268234
[22:24:27.593] iteration 6863 : model1 loss : 0.219828 model2 loss : 0.222573
[22:24:27.921] iteration 6864 : model1 loss : 0.306070 model2 loss : 0.323251
[22:24:28.250] iteration 6865 : model1 loss : 0.308694 model2 loss : 0.396395
[22:24:28.578] iteration 6866 : model1 loss : 0.358709 model2 loss : 0.319396
[22:24:28.907] iteration 6867 : model1 loss : 0.230180 model2 loss : 0.236529
[22:24:29.235] iteration 6868 : model1 loss : 0.236243 model2 loss : 0.243075
[22:24:29.562] iteration 6869 : model1 loss : 0.283343 model2 loss : 0.339633
[22:24:29.890] iteration 6870 : model1 loss : 0.278221 model2 loss : 0.280148
[22:24:30.220] iteration 6871 : model1 loss : 0.283836 model2 loss : 0.291441
[22:24:30.549] iteration 6872 : model1 loss : 0.287460 model2 loss : 0.302401
[22:24:30.877] iteration 6873 : model1 loss : 0.211547 model2 loss : 0.221107
[22:24:31.206] iteration 6874 : model1 loss : 0.288108 model2 loss : 0.214960
[22:24:31.533] iteration 6875 : model1 loss : 0.315807 model2 loss : 0.238155
[22:24:31.860] iteration 6876 : model1 loss : 0.258040 model2 loss : 0.255971
[22:24:32.187] iteration 6877 : model1 loss : 0.290530 model2 loss : 0.264575
[22:24:32.514] iteration 6878 : model1 loss : 0.196588 model2 loss : 0.169959
[22:24:32.842] iteration 6879 : model1 loss : 0.273563 model2 loss : 0.306907
[22:24:33.169] iteration 6880 : model1 loss : 0.348524 model2 loss : 0.280491
[22:24:33.496] iteration 6881 : model1 loss : 0.249197 model2 loss : 0.197100
[22:24:33.824] iteration 6882 : model1 loss : 0.388320 model2 loss : 0.351610
[22:24:34.151] iteration 6883 : model1 loss : 0.293374 model2 loss : 0.286561
[22:24:34.479] iteration 6884 : model1 loss : 0.195226 model2 loss : 0.223605
[22:24:34.805] iteration 6885 : model1 loss : 0.250274 model2 loss : 0.204431
[22:24:35.133] iteration 6886 : model1 loss : 0.253920 model2 loss : 0.290197
[22:24:35.460] iteration 6887 : model1 loss : 0.378341 model2 loss : 0.352737
[22:24:35.787] iteration 6888 : model1 loss : 0.184239 model2 loss : 0.223586
[22:24:36.114] iteration 6889 : model1 loss : 0.248123 model2 loss : 0.270691
[22:24:36.440] iteration 6890 : model1 loss : 0.119385 model2 loss : 0.125298
[22:24:36.767] iteration 6891 : model1 loss : 0.217420 model2 loss : 0.272716
[22:24:37.097] iteration 6892 : model1 loss : 0.265279 model2 loss : 0.250322
[22:24:37.424] iteration 6893 : model1 loss : 0.307259 model2 loss : 0.348396
[22:24:37.751] iteration 6894 : model1 loss : 0.216440 model2 loss : 0.311360
[22:24:38.078] iteration 6895 : model1 loss : 0.267518 model2 loss : 0.286806
[22:24:38.405] iteration 6896 : model1 loss : 0.306093 model2 loss : 0.281486
[22:24:38.733] iteration 6897 : model1 loss : 0.196900 model2 loss : 0.194417
[22:24:39.060] iteration 6898 : model1 loss : 0.243793 model2 loss : 0.315344
[22:24:39.390] iteration 6899 : model1 loss : 0.251253 model2 loss : 0.199064
[22:24:39.718] iteration 6900 : model1 loss : 0.338788 model2 loss : 0.370630
[22:24:40.201] iteration 6901 : model1 loss : 0.178790 model2 loss : 0.178514
[22:24:40.530] iteration 6902 : model1 loss : 0.268053 model2 loss : 0.343767
[22:24:40.860] iteration 6903 : model1 loss : 0.297309 model2 loss : 0.322812
[22:24:41.195] iteration 6904 : model1 loss : 0.173183 model2 loss : 0.188695
[22:24:41.532] iteration 6905 : model1 loss : 0.248634 model2 loss : 0.242920
[22:24:41.870] iteration 6906 : model1 loss : 0.331499 model2 loss : 0.327695
[22:24:42.208] iteration 6907 : model1 loss : 0.266994 model2 loss : 0.325812
[22:24:42.546] iteration 6908 : model1 loss : 0.217087 model2 loss : 0.221526
[22:24:42.884] iteration 6909 : model1 loss : 0.266313 model2 loss : 0.216393
[22:24:43.223] iteration 6910 : model1 loss : 0.179811 model2 loss : 0.193692
[22:24:43.560] iteration 6911 : model1 loss : 0.222013 model2 loss : 0.225360
[22:24:43.898] iteration 6912 : model1 loss : 0.334315 model2 loss : 0.292594
[22:24:44.237] iteration 6913 : model1 loss : 0.207063 model2 loss : 0.215083
[22:24:44.576] iteration 6914 : model1 loss : 0.173290 model2 loss : 0.260983
[22:24:44.914] iteration 6915 : model1 loss : 0.223130 model2 loss : 0.266962
[22:24:45.252] iteration 6916 : model1 loss : 0.355082 model2 loss : 0.317370
[22:24:45.592] iteration 6917 : model1 loss : 0.368329 model2 loss : 0.411689
[22:24:45.931] iteration 6918 : model1 loss : 0.203349 model2 loss : 0.179868
[22:24:46.273] iteration 6919 : model1 loss : 0.347777 model2 loss : 0.329357
[22:24:46.610] iteration 6920 : model1 loss : 0.311927 model2 loss : 0.292944
[22:24:46.949] iteration 6921 : model1 loss : 0.240928 model2 loss : 0.293032
[22:24:47.285] iteration 6922 : model1 loss : 0.295966 model2 loss : 0.301399
[22:24:47.622] iteration 6923 : model1 loss : 0.271946 model2 loss : 0.301819
[22:24:47.958] iteration 6924 : model1 loss : 0.170756 model2 loss : 0.140837
[22:24:48.295] iteration 6925 : model1 loss : 0.213477 model2 loss : 0.198286
[22:24:48.632] iteration 6926 : model1 loss : 0.261577 model2 loss : 0.224203
[22:24:48.968] iteration 6927 : model1 loss : 0.188610 model2 loss : 0.224515
[22:24:49.308] iteration 6928 : model1 loss : 0.268456 model2 loss : 0.320396
[22:24:49.647] iteration 6929 : model1 loss : 0.208259 model2 loss : 0.225873
[22:24:49.982] iteration 6930 : model1 loss : 0.330754 model2 loss : 0.281522
[22:24:50.322] iteration 6931 : model1 loss : 0.198742 model2 loss : 0.234605
[22:24:50.660] iteration 6932 : model1 loss : 0.264666 model2 loss : 0.246603
[22:24:50.996] iteration 6933 : model1 loss : 0.216599 model2 loss : 0.282661
[22:24:51.333] iteration 6934 : model1 loss : 0.210359 model2 loss : 0.182934
[22:24:51.669] iteration 6935 : model1 loss : 0.301333 model2 loss : 0.304498
[22:24:52.005] iteration 6936 : model1 loss : 0.286679 model2 loss : 0.289112
[22:24:52.342] iteration 6937 : model1 loss : 0.293954 model2 loss : 0.288093
[22:24:52.678] iteration 6938 : model1 loss : 0.306361 model2 loss : 0.283912
[22:24:53.019] iteration 6939 : model1 loss : 0.204127 model2 loss : 0.265839
[22:24:53.356] iteration 6940 : model1 loss : 0.284113 model2 loss : 0.372904
[22:24:53.692] iteration 6941 : model1 loss : 0.198907 model2 loss : 0.221809
[22:24:54.028] iteration 6942 : model1 loss : 0.164291 model2 loss : 0.160664
[22:24:54.364] iteration 6943 : model1 loss : 0.322911 model2 loss : 0.327711
[22:24:54.700] iteration 6944 : model1 loss : 0.205880 model2 loss : 0.192546
[22:24:55.036] iteration 6945 : model1 loss : 0.268408 model2 loss : 0.242099
[22:24:55.372] iteration 6946 : model1 loss : 0.272262 model2 loss : 0.228515
[22:24:55.710] iteration 6947 : model1 loss : 0.324569 model2 loss : 0.367357
[22:24:56.045] iteration 6948 : model1 loss : 0.167364 model2 loss : 0.248481
[22:24:56.382] iteration 6949 : model1 loss : 0.216764 model2 loss : 0.198446
[22:24:56.718] iteration 6950 : model1 loss : 0.209296 model2 loss : 0.241952
[22:24:57.365] iteration 6951 : model1 loss : 0.332171 model2 loss : 0.331502
[22:24:57.701] iteration 6952 : model1 loss : 0.212444 model2 loss : 0.260709
[22:24:58.038] iteration 6953 : model1 loss : 0.210776 model2 loss : 0.246825
[22:24:58.374] iteration 6954 : model1 loss : 0.270044 model2 loss : 0.295781
[22:24:58.710] iteration 6955 : model1 loss : 0.264527 model2 loss : 0.264554
[22:24:59.046] iteration 6956 : model1 loss : 0.205478 model2 loss : 0.250723
[22:24:59.384] iteration 6957 : model1 loss : 0.198552 model2 loss : 0.269170
[22:24:59.720] iteration 6958 : model1 loss : 0.220851 model2 loss : 0.201233
[22:25:00.056] iteration 6959 : model1 loss : 0.406139 model2 loss : 0.363951
[22:25:00.394] iteration 6960 : model1 loss : 0.211769 model2 loss : 0.226444
[22:25:00.736] iteration 6961 : model1 loss : 0.262732 model2 loss : 0.266582
[22:25:01.072] iteration 6962 : model1 loss : 0.187206 model2 loss : 0.165114
[22:25:01.409] iteration 6963 : model1 loss : 0.294830 model2 loss : 0.270229
[22:25:01.745] iteration 6964 : model1 loss : 0.328330 model2 loss : 0.377592
[22:25:02.086] iteration 6965 : model1 loss : 0.273370 model2 loss : 0.301001
[22:25:02.422] iteration 6966 : model1 loss : 0.257441 model2 loss : 0.275886
[22:25:02.759] iteration 6967 : model1 loss : 0.167788 model2 loss : 0.186253
[22:25:03.100] iteration 6968 : model1 loss : 0.209619 model2 loss : 0.271165
[22:25:03.437] iteration 6969 : model1 loss : 0.309207 model2 loss : 0.261462
[22:25:03.774] iteration 6970 : model1 loss : 0.302832 model2 loss : 0.282738
[22:25:04.111] iteration 6971 : model1 loss : 0.330013 model2 loss : 0.334971
[22:25:04.447] iteration 6972 : model1 loss : 0.289441 model2 loss : 0.296985
[22:25:04.784] iteration 6973 : model1 loss : 0.224635 model2 loss : 0.194941
[22:25:05.121] iteration 6974 : model1 loss : 0.260277 model2 loss : 0.252794
[22:25:05.463] iteration 6975 : model1 loss : 0.203442 model2 loss : 0.259290
[22:25:05.800] iteration 6976 : model1 loss : 0.286074 model2 loss : 0.322897
[22:25:06.136] iteration 6977 : model1 loss : 0.401984 model2 loss : 0.405253
[22:25:06.473] iteration 6978 : model1 loss : 0.296774 model2 loss : 0.243726
[22:25:06.809] iteration 6979 : model1 loss : 0.395094 model2 loss : 0.402114
[22:25:07.146] iteration 6980 : model1 loss : 0.297513 model2 loss : 0.317004
[22:25:07.484] iteration 6981 : model1 loss : 0.263629 model2 loss : 0.339885
[22:25:07.827] iteration 6982 : model1 loss : 0.186740 model2 loss : 0.275301
[22:25:08.164] iteration 6983 : model1 loss : 0.200136 model2 loss : 0.207888
[22:25:08.502] iteration 6984 : model1 loss : 0.317813 model2 loss : 0.303882
[22:25:08.838] iteration 6985 : model1 loss : 0.283601 model2 loss : 0.295753
[22:25:09.175] iteration 6986 : model1 loss : 0.234728 model2 loss : 0.113693
[22:25:09.514] iteration 6987 : model1 loss : 0.361984 model2 loss : 0.260583
[22:25:09.850] iteration 6988 : model1 loss : 0.249817 model2 loss : 0.271654
[22:25:10.187] iteration 6989 : model1 loss : 0.265252 model2 loss : 0.261440
[22:25:10.524] iteration 6990 : model1 loss : 0.201875 model2 loss : 0.224599
[22:25:10.860] iteration 6991 : model1 loss : 0.332073 model2 loss : 0.296565
[22:25:11.196] iteration 6992 : model1 loss : 0.243104 model2 loss : 0.285350
[22:25:11.532] iteration 6993 : model1 loss : 0.299086 model2 loss : 0.297148
[22:25:11.869] iteration 6994 : model1 loss : 0.317465 model2 loss : 0.292957
[22:25:12.206] iteration 6995 : model1 loss : 0.241255 model2 loss : 0.211811
[22:25:12.544] iteration 6996 : model1 loss : 0.221752 model2 loss : 0.203936
[22:25:12.883] iteration 6997 : model1 loss : 0.336144 model2 loss : 0.328985
[22:25:13.220] iteration 6998 : model1 loss : 0.341401 model2 loss : 0.331935
[22:25:13.557] iteration 6999 : model1 loss : 0.293711 model2 loss : 0.324395
[22:25:13.894] iteration 7000 : model1 loss : 0.282335 model2 loss : 0.373322
[22:25:14.533] iteration 7001 : model1 loss : 0.255585 model2 loss : 0.310884
[22:25:14.873] iteration 7002 : model1 loss : 0.216379 model2 loss : 0.284736
[22:25:15.210] iteration 7003 : model1 loss : 0.236749 model2 loss : 0.285581
[22:25:15.547] iteration 7004 : model1 loss : 0.273093 model2 loss : 0.276798
[22:25:15.884] iteration 7005 : model1 loss : 0.236816 model2 loss : 0.261566
[22:25:16.222] iteration 7006 : model1 loss : 0.280675 model2 loss : 0.308558
[22:25:16.559] iteration 7007 : model1 loss : 0.212357 model2 loss : 0.227565
[22:25:16.896] iteration 7008 : model1 loss : 0.232238 model2 loss : 0.271830
[22:25:17.232] iteration 7009 : model1 loss : 0.200473 model2 loss : 0.212571
[22:25:17.569] iteration 7010 : model1 loss : 0.335991 model2 loss : 0.358702
[22:25:17.906] iteration 7011 : model1 loss : 0.215448 model2 loss : 0.221321
[22:25:18.245] iteration 7012 : model1 loss : 0.248417 model2 loss : 0.195742
[22:25:18.583] iteration 7013 : model1 loss : 0.179855 model2 loss : 0.263196
[22:25:18.919] iteration 7014 : model1 loss : 0.283154 model2 loss : 0.316544
[22:25:19.255] iteration 7015 : model1 loss : 0.189181 model2 loss : 0.209977
[22:25:19.590] iteration 7016 : model1 loss : 0.288624 model2 loss : 0.291672
[22:25:19.927] iteration 7017 : model1 loss : 0.353943 model2 loss : 0.362725
[22:25:20.262] iteration 7018 : model1 loss : 0.202861 model2 loss : 0.163509
[22:25:20.597] iteration 7019 : model1 loss : 0.383191 model2 loss : 0.321623
[22:25:20.934] iteration 7020 : model1 loss : 0.221109 model2 loss : 0.240050
[22:25:21.270] iteration 7021 : model1 loss : 0.394516 model2 loss : 0.376217
[22:25:21.608] iteration 7022 : model1 loss : 0.197715 model2 loss : 0.214450
[22:25:21.944] iteration 7023 : model1 loss : 0.299995 model2 loss : 0.351479
[22:25:22.280] iteration 7024 : model1 loss : 0.130986 model2 loss : 0.180791
[22:25:22.616] iteration 7025 : model1 loss : 0.271125 model2 loss : 0.340117
[22:25:22.954] iteration 7026 : model1 loss : 0.200787 model2 loss : 0.248624
[22:25:23.297] iteration 7027 : model1 loss : 0.163011 model2 loss : 0.197930
[22:25:23.633] iteration 7028 : model1 loss : 0.350110 model2 loss : 0.388122
[22:25:23.969] iteration 7029 : model1 loss : 0.338590 model2 loss : 0.303960
[22:25:24.306] iteration 7030 : model1 loss : 0.239554 model2 loss : 0.213365
[22:25:24.642] iteration 7031 : model1 loss : 0.312613 model2 loss : 0.360287
[22:25:24.978] iteration 7032 : model1 loss : 0.307409 model2 loss : 0.314979
[22:25:25.315] iteration 7033 : model1 loss : 0.297205 model2 loss : 0.280127
[22:25:25.652] iteration 7034 : model1 loss : 0.308865 model2 loss : 0.301013
[22:25:25.990] iteration 7035 : model1 loss : 0.291903 model2 loss : 0.329579
[22:25:26.327] iteration 7036 : model1 loss : 0.354113 model2 loss : 0.324320
[22:25:26.664] iteration 7037 : model1 loss : 0.285026 model2 loss : 0.250824
[22:25:27.001] iteration 7038 : model1 loss : 0.272399 model2 loss : 0.297129
[22:25:27.339] iteration 7039 : model1 loss : 0.200494 model2 loss : 0.222131
[22:25:27.677] iteration 7040 : model1 loss : 0.226308 model2 loss : 0.295890
[22:25:28.014] iteration 7041 : model1 loss : 0.239418 model2 loss : 0.229862
[22:25:28.341] iteration 7042 : model1 loss : 0.200782 model2 loss : 0.196530
[22:25:28.669] iteration 7043 : model1 loss : 0.274710 model2 loss : 0.317749
[22:25:28.997] iteration 7044 : model1 loss : 0.273593 model2 loss : 0.272738
[22:25:29.327] iteration 7045 : model1 loss : 0.227982 model2 loss : 0.308451
[22:25:29.663] iteration 7046 : model1 loss : 0.230615 model2 loss : 0.266590
[22:25:30.000] iteration 7047 : model1 loss : 0.318504 model2 loss : 0.256960
[22:25:30.333] iteration 7048 : model1 loss : 0.333947 model2 loss : 0.346452
[22:25:30.661] iteration 7049 : model1 loss : 0.317816 model2 loss : 0.344360
[22:25:30.997] iteration 7050 : model1 loss : 0.239903 model2 loss : 0.215937
[22:25:31.672] iteration 7051 : model1 loss : 0.417331 model2 loss : 0.433091
[22:25:32.008] iteration 7052 : model1 loss : 0.391395 model2 loss : 0.371137
[22:25:32.344] iteration 7053 : model1 loss : 0.303531 model2 loss : 0.308951
[22:25:32.682] iteration 7054 : model1 loss : 0.142087 model2 loss : 0.204398
[22:25:33.017] iteration 7055 : model1 loss : 0.302770 model2 loss : 0.294415
[22:25:33.355] iteration 7056 : model1 loss : 0.322316 model2 loss : 0.344799
[22:25:33.691] iteration 7057 : model1 loss : 0.336686 model2 loss : 0.286894
[22:25:34.028] iteration 7058 : model1 loss : 0.229601 model2 loss : 0.244145
[22:25:34.365] iteration 7059 : model1 loss : 0.232706 model2 loss : 0.180110
[22:25:34.704] iteration 7060 : model1 loss : 0.268195 model2 loss : 0.278964
[22:25:35.041] iteration 7061 : model1 loss : 0.266172 model2 loss : 0.265959
[22:25:35.378] iteration 7062 : model1 loss : 0.266128 model2 loss : 0.330093
[22:25:35.716] iteration 7063 : model1 loss : 0.203536 model2 loss : 0.214449
[22:25:36.052] iteration 7064 : model1 loss : 0.262849 model2 loss : 0.300202
[22:25:36.389] iteration 7065 : model1 loss : 0.301753 model2 loss : 0.302980
[22:25:36.725] iteration 7066 : model1 loss : 0.300211 model2 loss : 0.313931
[22:25:37.061] iteration 7067 : model1 loss : 0.239709 model2 loss : 0.182319
[22:25:37.396] iteration 7068 : model1 loss : 0.240163 model2 loss : 0.274078
[22:25:37.733] iteration 7069 : model1 loss : 0.218609 model2 loss : 0.318617
[22:25:38.069] iteration 7070 : model1 loss : 0.295205 model2 loss : 0.288879
[22:25:38.406] iteration 7071 : model1 loss : 0.180478 model2 loss : 0.221347
[22:25:38.743] iteration 7072 : model1 loss : 0.297275 model2 loss : 0.246571
[22:25:39.079] iteration 7073 : model1 loss : 0.300652 model2 loss : 0.267843
[22:25:39.415] iteration 7074 : model1 loss : 0.277084 model2 loss : 0.214208
[22:25:39.750] iteration 7075 : model1 loss : 0.285493 model2 loss : 0.297242
[22:25:40.086] iteration 7076 : model1 loss : 0.288686 model2 loss : 0.344662
[22:25:40.423] iteration 7077 : model1 loss : 0.240969 model2 loss : 0.263561
[22:25:40.760] iteration 7078 : model1 loss : 0.255503 model2 loss : 0.239917
[22:25:41.096] iteration 7079 : model1 loss : 0.332799 model2 loss : 0.264554
[22:25:41.431] iteration 7080 : model1 loss : 0.231744 model2 loss : 0.277685
[22:25:41.766] iteration 7081 : model1 loss : 0.243339 model2 loss : 0.211655
[22:25:42.101] iteration 7082 : model1 loss : 0.295711 model2 loss : 0.243725
[22:25:42.435] iteration 7083 : model1 loss : 0.331733 model2 loss : 0.332496
[22:25:42.770] iteration 7084 : model1 loss : 0.120782 model2 loss : 0.141824
[22:25:43.106] iteration 7085 : model1 loss : 0.414667 model2 loss : 0.451704
[22:25:44.103] iteration 7086 : model1 loss : 0.224289 model2 loss : 0.269354
[22:25:44.440] iteration 7087 : model1 loss : 0.127816 model2 loss : 0.176154
[22:25:44.776] iteration 7088 : model1 loss : 0.294586 model2 loss : 0.299344
[22:25:45.114] iteration 7089 : model1 loss : 0.197569 model2 loss : 0.189786
[22:25:45.454] iteration 7090 : model1 loss : 0.151245 model2 loss : 0.150139
[22:25:45.789] iteration 7091 : model1 loss : 0.263269 model2 loss : 0.297557
[22:25:46.126] iteration 7092 : model1 loss : 0.311778 model2 loss : 0.305500
[22:25:46.462] iteration 7093 : model1 loss : 0.299044 model2 loss : 0.289451
[22:25:46.798] iteration 7094 : model1 loss : 0.207870 model2 loss : 0.283549
[22:25:47.134] iteration 7095 : model1 loss : 0.148763 model2 loss : 0.150102
[22:25:47.472] iteration 7096 : model1 loss : 0.248103 model2 loss : 0.223246
[22:25:47.810] iteration 7097 : model1 loss : 0.212539 model2 loss : 0.219015
[22:25:48.146] iteration 7098 : model1 loss : 0.318588 model2 loss : 0.351776
[22:25:48.482] iteration 7099 : model1 loss : 0.252118 model2 loss : 0.211076
[22:25:48.819] iteration 7100 : model1 loss : 0.203394 model2 loss : 0.206872
[22:25:49.465] iteration 7101 : model1 loss : 0.365812 model2 loss : 0.348160
[22:25:49.805] iteration 7102 : model1 loss : 0.265362 model2 loss : 0.207167
[22:25:50.142] iteration 7103 : model1 loss : 0.312936 model2 loss : 0.326537
[22:25:50.480] iteration 7104 : model1 loss : 0.261371 model2 loss : 0.283615
[22:25:50.816] iteration 7105 : model1 loss : 0.247583 model2 loss : 0.312607
[22:25:51.153] iteration 7106 : model1 loss : 0.291548 model2 loss : 0.274599
[22:25:51.489] iteration 7107 : model1 loss : 0.184159 model2 loss : 0.209372
[22:25:51.830] iteration 7108 : model1 loss : 0.179884 model2 loss : 0.235090
[22:25:52.166] iteration 7109 : model1 loss : 0.321618 model2 loss : 0.340861
[22:25:52.502] iteration 7110 : model1 loss : 0.231073 model2 loss : 0.205049
[22:25:52.839] iteration 7111 : model1 loss : 0.197566 model2 loss : 0.240072
[22:25:53.176] iteration 7112 : model1 loss : 0.296731 model2 loss : 0.369751
[22:25:53.512] iteration 7113 : model1 loss : 0.182481 model2 loss : 0.260265
[22:25:53.848] iteration 7114 : model1 loss : 0.249428 model2 loss : 0.309254
[22:25:54.184] iteration 7115 : model1 loss : 0.285997 model2 loss : 0.350424
[22:25:54.521] iteration 7116 : model1 loss : 0.275856 model2 loss : 0.279602
[22:25:54.858] iteration 7117 : model1 loss : 0.318401 model2 loss : 0.316901
[22:25:55.195] iteration 7118 : model1 loss : 0.267718 model2 loss : 0.273114
[22:25:55.533] iteration 7119 : model1 loss : 0.176679 model2 loss : 0.210143
[22:25:55.870] iteration 7120 : model1 loss : 0.212730 model2 loss : 0.240094
[22:25:56.205] iteration 7121 : model1 loss : 0.333432 model2 loss : 0.282945
[22:25:56.541] iteration 7122 : model1 loss : 0.340723 model2 loss : 0.360067
[22:25:56.878] iteration 7123 : model1 loss : 0.295309 model2 loss : 0.363075
[22:25:57.215] iteration 7124 : model1 loss : 0.301509 model2 loss : 0.338984
[22:25:57.551] iteration 7125 : model1 loss : 0.294995 model2 loss : 0.347889
[22:25:57.887] iteration 7126 : model1 loss : 0.187550 model2 loss : 0.267791
[22:25:58.228] iteration 7127 : model1 loss : 0.279187 model2 loss : 0.275183
[22:25:58.564] iteration 7128 : model1 loss : 0.235059 model2 loss : 0.280746
[22:25:58.901] iteration 7129 : model1 loss : 0.292036 model2 loss : 0.300385
[22:25:59.239] iteration 7130 : model1 loss : 0.300429 model2 loss : 0.284154
[22:25:59.575] iteration 7131 : model1 loss : 0.260829 model2 loss : 0.257651
[22:25:59.911] iteration 7132 : model1 loss : 0.321302 model2 loss : 0.314545
[22:26:00.247] iteration 7133 : model1 loss : 0.259086 model2 loss : 0.260106
[22:26:00.584] iteration 7134 : model1 loss : 0.311389 model2 loss : 0.313081
[22:26:00.923] iteration 7135 : model1 loss : 0.285678 model2 loss : 0.324872
[22:26:01.260] iteration 7136 : model1 loss : 0.326272 model2 loss : 0.343835
[22:26:01.595] iteration 7137 : model1 loss : 0.232310 model2 loss : 0.262082
[22:26:01.931] iteration 7138 : model1 loss : 0.297251 model2 loss : 0.286712
[22:26:02.269] iteration 7139 : model1 loss : 0.196691 model2 loss : 0.200934
[22:26:02.610] iteration 7140 : model1 loss : 0.221918 model2 loss : 0.253437
[22:26:02.947] iteration 7141 : model1 loss : 0.250705 model2 loss : 0.382009
[22:26:03.292] iteration 7142 : model1 loss : 0.231530 model2 loss : 0.273557
[22:26:03.628] iteration 7143 : model1 loss : 0.261684 model2 loss : 0.281473
[22:26:03.966] iteration 7144 : model1 loss : 0.174906 model2 loss : 0.183423
[22:26:04.302] iteration 7145 : model1 loss : 0.306210 model2 loss : 0.273701
[22:26:04.638] iteration 7146 : model1 loss : 0.198104 model2 loss : 0.211006
[22:26:04.978] iteration 7147 : model1 loss : 0.287016 model2 loss : 0.208490
[22:26:05.314] iteration 7148 : model1 loss : 0.259232 model2 loss : 0.303309
[22:26:05.651] iteration 7149 : model1 loss : 0.273998 model2 loss : 0.234433
[22:26:05.994] iteration 7150 : model1 loss : 0.241254 model2 loss : 0.191644
[22:26:06.648] iteration 7151 : model1 loss : 0.294902 model2 loss : 0.313026
[22:26:06.990] iteration 7152 : model1 loss : 0.259325 model2 loss : 0.303401
[22:26:07.328] iteration 7153 : model1 loss : 0.268949 model2 loss : 0.308585
[22:26:07.665] iteration 7154 : model1 loss : 0.159972 model2 loss : 0.255255
[22:26:08.003] iteration 7155 : model1 loss : 0.153897 model2 loss : 0.165171
[22:26:08.346] iteration 7156 : model1 loss : 0.203487 model2 loss : 0.187503
[22:26:08.684] iteration 7157 : model1 loss : 0.297939 model2 loss : 0.306523
[22:26:09.027] iteration 7158 : model1 loss : 0.148215 model2 loss : 0.153893
[22:26:09.370] iteration 7159 : model1 loss : 0.271747 model2 loss : 0.271055
[22:26:09.712] iteration 7160 : model1 loss : 0.304393 model2 loss : 0.286423
[22:26:10.049] iteration 7161 : model1 loss : 0.160354 model2 loss : 0.157629
[22:26:10.393] iteration 7162 : model1 loss : 0.330775 model2 loss : 0.356670
[22:26:10.735] iteration 7163 : model1 loss : 0.173828 model2 loss : 0.186196
[22:26:11.077] iteration 7164 : model1 loss : 0.244461 model2 loss : 0.245225
[22:26:11.415] iteration 7165 : model1 loss : 0.202992 model2 loss : 0.233529
[22:26:11.756] iteration 7166 : model1 loss : 0.228614 model2 loss : 0.273296
[22:26:12.097] iteration 7167 : model1 loss : 0.155821 model2 loss : 0.235046
[22:26:12.433] iteration 7168 : model1 loss : 0.185626 model2 loss : 0.122138
[22:26:12.775] iteration 7169 : model1 loss : 0.279186 model2 loss : 0.295730
[22:26:13.117] iteration 7170 : model1 loss : 0.280268 model2 loss : 0.286033
[22:26:13.460] iteration 7171 : model1 loss : 0.139808 model2 loss : 0.143501
[22:26:13.797] iteration 7172 : model1 loss : 0.249694 model2 loss : 0.306266
[22:26:14.136] iteration 7173 : model1 loss : 0.284839 model2 loss : 0.317595
[22:26:14.481] iteration 7174 : model1 loss : 0.343495 model2 loss : 0.336367
[22:26:14.819] iteration 7175 : model1 loss : 0.251366 model2 loss : 0.288385
[22:26:15.163] iteration 7176 : model1 loss : 0.213906 model2 loss : 0.208116
[22:26:15.504] iteration 7177 : model1 loss : 0.338612 model2 loss : 0.347021
[22:26:15.849] iteration 7178 : model1 loss : 0.293384 model2 loss : 0.292154
[22:26:16.190] iteration 7179 : model1 loss : 0.307902 model2 loss : 0.234464
[22:26:16.531] iteration 7180 : model1 loss : 0.221373 model2 loss : 0.217918
[22:26:16.871] iteration 7181 : model1 loss : 0.320717 model2 loss : 0.310992
[22:26:17.209] iteration 7182 : model1 loss : 0.273074 model2 loss : 0.301657
[22:26:17.548] iteration 7183 : model1 loss : 0.247330 model2 loss : 0.254684
[22:26:17.892] iteration 7184 : model1 loss : 0.205662 model2 loss : 0.249034
[22:26:18.231] iteration 7185 : model1 loss : 0.222333 model2 loss : 0.279030
[22:26:18.574] iteration 7186 : model1 loss : 0.189247 model2 loss : 0.229821
[22:26:18.917] iteration 7187 : model1 loss : 0.239108 model2 loss : 0.218536
[22:26:19.257] iteration 7188 : model1 loss : 0.229228 model2 loss : 0.224152
[22:26:19.600] iteration 7189 : model1 loss : 0.297140 model2 loss : 0.291974
[22:26:19.942] iteration 7190 : model1 loss : 0.234829 model2 loss : 0.289493
[22:26:20.283] iteration 7191 : model1 loss : 0.201800 model2 loss : 0.289929
[22:26:20.627] iteration 7192 : model1 loss : 0.341809 model2 loss : 0.348290
[22:26:20.969] iteration 7193 : model1 loss : 0.286684 model2 loss : 0.339998
[22:26:21.311] iteration 7194 : model1 loss : 0.232978 model2 loss : 0.278181
[22:26:21.653] iteration 7195 : model1 loss : 0.242101 model2 loss : 0.248859
[22:26:21.995] iteration 7196 : model1 loss : 0.328712 model2 loss : 0.321271
[22:26:22.333] iteration 7197 : model1 loss : 0.213018 model2 loss : 0.241553
[22:26:22.675] iteration 7198 : model1 loss : 0.266678 model2 loss : 0.266618
[22:26:23.017] iteration 7199 : model1 loss : 0.291088 model2 loss : 0.279178
[22:26:23.355] iteration 7200 : model1 loss : 0.314446 model2 loss : 0.283691
[22:26:24.008] iteration 7201 : model1 loss : 0.281895 model2 loss : 0.283964
[22:26:24.348] iteration 7202 : model1 loss : 0.289980 model2 loss : 0.333460
[22:26:24.690] iteration 7203 : model1 loss : 0.213640 model2 loss : 0.250840
[22:26:25.027] iteration 7204 : model1 loss : 0.312039 model2 loss : 0.324848
[22:26:25.368] iteration 7205 : model1 loss : 0.239205 model2 loss : 0.243335
[22:26:25.706] iteration 7206 : model1 loss : 0.286137 model2 loss : 0.316575
[22:26:26.045] iteration 7207 : model1 loss : 0.275742 model2 loss : 0.369325
[22:26:26.385] iteration 7208 : model1 loss : 0.152320 model2 loss : 0.235753
[22:26:26.724] iteration 7209 : model1 loss : 0.112404 model2 loss : 0.254575
[22:26:27.062] iteration 7210 : model1 loss : 0.293568 model2 loss : 0.310356
[22:26:27.404] iteration 7211 : model1 loss : 0.197405 model2 loss : 0.184965
[22:26:27.743] iteration 7212 : model1 loss : 0.117007 model2 loss : 0.160014
[22:26:28.086] iteration 7213 : model1 loss : 0.395310 model2 loss : 0.338546
[22:26:28.427] iteration 7214 : model1 loss : 0.224462 model2 loss : 0.250296
[22:26:28.769] iteration 7215 : model1 loss : 0.227551 model2 loss : 0.200055
[22:26:29.108] iteration 7216 : model1 loss : 0.241922 model2 loss : 0.275200
[22:26:29.450] iteration 7217 : model1 loss : 0.246845 model2 loss : 0.237440
[22:26:29.791] iteration 7218 : model1 loss : 0.205910 model2 loss : 0.244308
[22:26:30.130] iteration 7219 : model1 loss : 0.287772 model2 loss : 0.289838
[22:26:30.469] iteration 7220 : model1 loss : 0.276972 model2 loss : 0.306567
[22:26:30.811] iteration 7221 : model1 loss : 0.209993 model2 loss : 0.286937
[22:26:31.148] iteration 7222 : model1 loss : 0.223948 model2 loss : 0.340235
[22:26:31.495] iteration 7223 : model1 loss : 0.400682 model2 loss : 0.402658
[22:26:31.836] iteration 7224 : model1 loss : 0.359086 model2 loss : 0.376085
[22:26:32.178] iteration 7225 : model1 loss : 0.196385 model2 loss : 0.260288
[22:26:32.519] iteration 7226 : model1 loss : 0.379849 model2 loss : 0.407604
[22:26:32.859] iteration 7227 : model1 loss : 0.236468 model2 loss : 0.233885
[22:26:33.197] iteration 7228 : model1 loss : 0.253698 model2 loss : 0.189222
[22:26:33.540] iteration 7229 : model1 loss : 0.222512 model2 loss : 0.217102
[22:26:33.881] iteration 7230 : model1 loss : 0.288754 model2 loss : 0.343381
[22:26:34.224] iteration 7231 : model1 loss : 0.201499 model2 loss : 0.202544
[22:26:34.561] iteration 7232 : model1 loss : 0.335736 model2 loss : 0.305321
[22:26:34.899] iteration 7233 : model1 loss : 0.286068 model2 loss : 0.279570
[22:26:35.548] iteration 7234 : model1 loss : 0.326533 model2 loss : 0.322431
[22:26:35.885] iteration 7235 : model1 loss : 0.248451 model2 loss : 0.242513
[22:26:36.227] iteration 7236 : model1 loss : 0.330316 model2 loss : 0.322864
[22:26:36.569] iteration 7237 : model1 loss : 0.212405 model2 loss : 0.282471
[22:26:36.907] iteration 7238 : model1 loss : 0.194959 model2 loss : 0.261444
[22:26:37.246] iteration 7239 : model1 loss : 0.325665 model2 loss : 0.323405
[22:26:37.583] iteration 7240 : model1 loss : 0.271060 model2 loss : 0.346548
[22:26:37.927] iteration 7241 : model1 loss : 0.261513 model2 loss : 0.283283
[22:26:38.269] iteration 7242 : model1 loss : 0.317926 model2 loss : 0.304948
[22:26:38.608] iteration 7243 : model1 loss : 0.207377 model2 loss : 0.255832
[22:26:38.976] iteration 7244 : model1 loss : 0.220764 model2 loss : 0.235029
[22:26:39.319] iteration 7245 : model1 loss : 0.179730 model2 loss : 0.264209
[22:26:39.659] iteration 7246 : model1 loss : 0.167220 model2 loss : 0.200403
[22:26:39.997] iteration 7247 : model1 loss : 0.129258 model2 loss : 0.165229
[22:26:40.339] iteration 7248 : model1 loss : 0.364166 model2 loss : 0.325752
[22:26:40.677] iteration 7249 : model1 loss : 0.244353 model2 loss : 0.288907
[22:26:41.015] iteration 7250 : model1 loss : 0.241467 model2 loss : 0.183637
[22:26:41.672] iteration 7251 : model1 loss : 0.191173 model2 loss : 0.173222
[22:26:42.014] iteration 7252 : model1 loss : 0.339448 model2 loss : 0.319497
[22:26:42.355] iteration 7253 : model1 loss : 0.221597 model2 loss : 0.245520
[22:26:42.692] iteration 7254 : model1 loss : 0.229789 model2 loss : 0.257030
[22:26:43.030] iteration 7255 : model1 loss : 0.167421 model2 loss : 0.237299
[22:26:43.379] iteration 7256 : model1 loss : 0.173112 model2 loss : 0.208703
[22:26:43.724] iteration 7257 : model1 loss : 0.254609 model2 loss : 0.288010
[22:26:44.062] iteration 7258 : model1 loss : 0.198111 model2 loss : 0.188276
[22:26:44.405] iteration 7259 : model1 loss : 0.252607 model2 loss : 0.300405
[22:26:44.745] iteration 7260 : model1 loss : 0.238198 model2 loss : 0.274983
[22:26:45.083] iteration 7261 : model1 loss : 0.258159 model2 loss : 0.260553
[22:26:45.428] iteration 7262 : model1 loss : 0.420105 model2 loss : 0.439836
[22:26:45.773] iteration 7263 : model1 loss : 0.254237 model2 loss : 0.277851
[22:26:46.111] iteration 7264 : model1 loss : 0.305058 model2 loss : 0.310059
[22:26:46.452] iteration 7265 : model1 loss : 0.284204 model2 loss : 0.325484
[22:26:46.794] iteration 7266 : model1 loss : 0.268873 model2 loss : 0.290297
[22:26:47.143] iteration 7267 : model1 loss : 0.214448 model2 loss : 0.223329
[22:26:47.487] iteration 7268 : model1 loss : 0.242413 model2 loss : 0.246647
[22:26:47.825] iteration 7269 : model1 loss : 0.330950 model2 loss : 0.304356
[22:26:48.163] iteration 7270 : model1 loss : 0.190976 model2 loss : 0.190400
[22:26:48.500] iteration 7271 : model1 loss : 0.274090 model2 loss : 0.233191
[22:26:48.839] iteration 7272 : model1 loss : 0.282595 model2 loss : 0.320175
[22:26:49.176] iteration 7273 : model1 loss : 0.204003 model2 loss : 0.274957
[22:26:49.524] iteration 7274 : model1 loss : 0.262566 model2 loss : 0.335025
[22:26:49.869] iteration 7275 : model1 loss : 0.291173 model2 loss : 0.281672
[22:26:50.207] iteration 7276 : model1 loss : 0.261947 model2 loss : 0.288354
[22:26:50.549] iteration 7277 : model1 loss : 0.203523 model2 loss : 0.206702
[22:26:50.886] iteration 7278 : model1 loss : 0.311440 model2 loss : 0.394518
[22:26:51.224] iteration 7279 : model1 loss : 0.314883 model2 loss : 0.294787
[22:26:51.563] iteration 7280 : model1 loss : 0.264596 model2 loss : 0.337300
[22:26:51.891] iteration 7281 : model1 loss : 0.210261 model2 loss : 0.200889
[22:26:52.223] iteration 7282 : model1 loss : 0.336132 model2 loss : 0.292068
[22:26:52.552] iteration 7283 : model1 loss : 0.229611 model2 loss : 0.183391
[22:26:52.882] iteration 7284 : model1 loss : 0.204945 model2 loss : 0.276796
[22:26:53.212] iteration 7285 : model1 loss : 0.142651 model2 loss : 0.192171
[22:26:53.541] iteration 7286 : model1 loss : 0.294221 model2 loss : 0.280456
[22:26:53.870] iteration 7287 : model1 loss : 0.335497 model2 loss : 0.218915
[22:26:54.198] iteration 7288 : model1 loss : 0.349682 model2 loss : 0.318156
[22:26:54.528] iteration 7289 : model1 loss : 0.286580 model2 loss : 0.207597
[22:26:54.855] iteration 7290 : model1 loss : 0.255610 model2 loss : 0.215966
[22:26:55.184] iteration 7291 : model1 loss : 0.355168 model2 loss : 0.325583
[22:26:55.519] iteration 7292 : model1 loss : 0.190271 model2 loss : 0.205544
[22:26:55.849] iteration 7293 : model1 loss : 0.305261 model2 loss : 0.206539
[22:26:56.178] iteration 7294 : model1 loss : 0.307271 model2 loss : 0.249566
[22:26:56.505] iteration 7295 : model1 loss : 0.277165 model2 loss : 0.216740
[22:26:56.833] iteration 7296 : model1 loss : 0.266763 model2 loss : 0.311676
[22:26:57.161] iteration 7297 : model1 loss : 0.284061 model2 loss : 0.282992
[22:26:57.489] iteration 7298 : model1 loss : 0.287661 model2 loss : 0.299367
[22:26:57.817] iteration 7299 : model1 loss : 0.337201 model2 loss : 0.345110
[22:26:58.148] iteration 7300 : model1 loss : 0.222812 model2 loss : 0.198230
[22:26:58.663] iteration 7301 : model1 loss : 0.290006 model2 loss : 0.288277
[22:26:58.990] iteration 7302 : model1 loss : 0.213806 model2 loss : 0.252270
[22:26:59.318] iteration 7303 : model1 loss : 0.275115 model2 loss : 0.275695
[22:26:59.647] iteration 7304 : model1 loss : 0.343256 model2 loss : 0.306283
[22:26:59.974] iteration 7305 : model1 loss : 0.421091 model2 loss : 0.466232
[22:27:00.304] iteration 7306 : model1 loss : 0.283110 model2 loss : 0.300961
[22:27:00.632] iteration 7307 : model1 loss : 0.240501 model2 loss : 0.252698
[22:27:00.961] iteration 7308 : model1 loss : 0.219803 model2 loss : 0.234195
[22:27:01.290] iteration 7309 : model1 loss : 0.310652 model2 loss : 0.332627
[22:27:01.619] iteration 7310 : model1 loss : 0.161465 model2 loss : 0.230325
[22:27:01.949] iteration 7311 : model1 loss : 0.198426 model2 loss : 0.225038
[22:27:02.277] iteration 7312 : model1 loss : 0.299314 model2 loss : 0.281099
[22:27:02.605] iteration 7313 : model1 loss : 0.129747 model2 loss : 0.182720
[22:27:02.933] iteration 7314 : model1 loss : 0.231496 model2 loss : 0.207961
[22:27:03.261] iteration 7315 : model1 loss : 0.348880 model2 loss : 0.355306
[22:27:03.590] iteration 7316 : model1 loss : 0.289070 model2 loss : 0.332028
[22:27:03.917] iteration 7317 : model1 loss : 0.272161 model2 loss : 0.312776
[22:27:04.245] iteration 7318 : model1 loss : 0.304109 model2 loss : 0.314789
[22:27:04.573] iteration 7319 : model1 loss : 0.255977 model2 loss : 0.217109
[22:27:04.901] iteration 7320 : model1 loss : 0.152591 model2 loss : 0.128864
[22:27:05.228] iteration 7321 : model1 loss : 0.224879 model2 loss : 0.247468
[22:27:05.556] iteration 7322 : model1 loss : 0.296122 model2 loss : 0.331288
[22:27:05.884] iteration 7323 : model1 loss : 0.307966 model2 loss : 0.364310
[22:27:06.216] iteration 7324 : model1 loss : 0.296904 model2 loss : 0.309032
[22:27:06.544] iteration 7325 : model1 loss : 0.193753 model2 loss : 0.273524
[22:27:06.873] iteration 7326 : model1 loss : 0.256676 model2 loss : 0.289988
[22:27:07.202] iteration 7327 : model1 loss : 0.172840 model2 loss : 0.202646
[22:27:07.530] iteration 7328 : model1 loss : 0.277358 model2 loss : 0.334648
[22:27:07.857] iteration 7329 : model1 loss : 0.257755 model2 loss : 0.274332
[22:27:08.188] iteration 7330 : model1 loss : 0.254004 model2 loss : 0.294758
[22:27:08.515] iteration 7331 : model1 loss : 0.187947 model2 loss : 0.228144
[22:27:08.843] iteration 7332 : model1 loss : 0.296268 model2 loss : 0.289258
[22:27:09.170] iteration 7333 : model1 loss : 0.259985 model2 loss : 0.224272
[22:27:09.498] iteration 7334 : model1 loss : 0.427932 model2 loss : 0.433342
[22:27:09.826] iteration 7335 : model1 loss : 0.262878 model2 loss : 0.189329
[22:27:10.153] iteration 7336 : model1 loss : 0.352168 model2 loss : 0.353088
[22:27:10.482] iteration 7337 : model1 loss : 0.195113 model2 loss : 0.199169
[22:27:10.810] iteration 7338 : model1 loss : 0.262155 model2 loss : 0.261702
[22:27:11.136] iteration 7339 : model1 loss : 0.286831 model2 loss : 0.332434
[22:27:11.462] iteration 7340 : model1 loss : 0.244928 model2 loss : 0.271563
[22:27:11.788] iteration 7341 : model1 loss : 0.174478 model2 loss : 0.186400
[22:27:12.114] iteration 7342 : model1 loss : 0.161194 model2 loss : 0.202296
[22:27:12.441] iteration 7343 : model1 loss : 0.317050 model2 loss : 0.334931
[22:27:12.768] iteration 7344 : model1 loss : 0.335696 model2 loss : 0.326900
[22:27:13.094] iteration 7345 : model1 loss : 0.295889 model2 loss : 0.233056
[22:27:13.419] iteration 7346 : model1 loss : 0.305139 model2 loss : 0.346013
[22:27:13.747] iteration 7347 : model1 loss : 0.158496 model2 loss : 0.238780
[22:27:14.072] iteration 7348 : model1 loss : 0.251216 model2 loss : 0.229523
[22:27:14.403] iteration 7349 : model1 loss : 0.282977 model2 loss : 0.341518
[22:27:14.730] iteration 7350 : model1 loss : 0.217101 model2 loss : 0.251958
[22:27:15.228] iteration 7351 : model1 loss : 0.327913 model2 loss : 0.399953
[22:27:15.554] iteration 7352 : model1 loss : 0.266985 model2 loss : 0.318583
[22:27:15.883] iteration 7353 : model1 loss : 0.222390 model2 loss : 0.254489
[22:27:16.213] iteration 7354 : model1 loss : 0.352873 model2 loss : 0.358402
[22:27:16.544] iteration 7355 : model1 loss : 0.183674 model2 loss : 0.181123
[22:27:16.873] iteration 7356 : model1 loss : 0.307561 model2 loss : 0.280258
[22:27:17.201] iteration 7357 : model1 loss : 0.181108 model2 loss : 0.198533
[22:27:17.531] iteration 7358 : model1 loss : 0.229724 model2 loss : 0.260704
[22:27:17.862] iteration 7359 : model1 loss : 0.243437 model2 loss : 0.262291
[22:27:18.189] iteration 7360 : model1 loss : 0.196606 model2 loss : 0.271415
[22:27:18.514] iteration 7361 : model1 loss : 0.309808 model2 loss : 0.353264
[22:27:18.844] iteration 7362 : model1 loss : 0.307510 model2 loss : 0.339652
[22:27:19.170] iteration 7363 : model1 loss : 0.217810 model2 loss : 0.245435
[22:27:19.493] iteration 7364 : model1 loss : 0.226570 model2 loss : 0.255249
[22:27:19.820] iteration 7365 : model1 loss : 0.246421 model2 loss : 0.278382
[22:27:20.146] iteration 7366 : model1 loss : 0.207606 model2 loss : 0.270630
[22:27:20.473] iteration 7367 : model1 loss : 0.271292 model2 loss : 0.217404
[22:27:20.800] iteration 7368 : model1 loss : 0.216977 model2 loss : 0.252688
[22:27:21.126] iteration 7369 : model1 loss : 0.337865 model2 loss : 0.362686
[22:27:21.451] iteration 7370 : model1 loss : 0.282664 model2 loss : 0.242539
[22:27:21.777] iteration 7371 : model1 loss : 0.236731 model2 loss : 0.338304
[22:27:22.104] iteration 7372 : model1 loss : 0.400363 model2 loss : 0.415726
[22:27:22.430] iteration 7373 : model1 loss : 0.201512 model2 loss : 0.212375
[22:27:22.756] iteration 7374 : model1 loss : 0.200493 model2 loss : 0.205460
[22:27:23.082] iteration 7375 : model1 loss : 0.309712 model2 loss : 0.322478
[22:27:23.406] iteration 7376 : model1 loss : 0.360462 model2 loss : 0.333595
[22:27:23.732] iteration 7377 : model1 loss : 0.182635 model2 loss : 0.171818
[22:27:24.058] iteration 7378 : model1 loss : 0.241756 model2 loss : 0.231274
[22:27:24.384] iteration 7379 : model1 loss : 0.247435 model2 loss : 0.229417
[22:27:24.713] iteration 7380 : model1 loss : 0.195407 model2 loss : 0.197079
[22:27:25.040] iteration 7381 : model1 loss : 0.359455 model2 loss : 0.364620
[22:27:25.367] iteration 7382 : model1 loss : 0.144410 model2 loss : 0.150088
[22:27:25.692] iteration 7383 : model1 loss : 0.190719 model2 loss : 0.205764
[22:27:26.020] iteration 7384 : model1 loss : 0.265380 model2 loss : 0.256170
[22:27:26.352] iteration 7385 : model1 loss : 0.311118 model2 loss : 0.263024
[22:27:26.677] iteration 7386 : model1 loss : 0.282152 model2 loss : 0.305134
[22:27:27.004] iteration 7387 : model1 loss : 0.370920 model2 loss : 0.291821
[22:27:27.331] iteration 7388 : model1 loss : 0.203471 model2 loss : 0.216864
[22:27:27.659] iteration 7389 : model1 loss : 0.225740 model2 loss : 0.173560
[22:27:27.987] iteration 7390 : model1 loss : 0.305790 model2 loss : 0.338997
[22:27:28.314] iteration 7391 : model1 loss : 0.313084 model2 loss : 0.277930
[22:27:28.642] iteration 7392 : model1 loss : 0.244967 model2 loss : 0.195262
[22:27:28.970] iteration 7393 : model1 loss : 0.221077 model2 loss : 0.207304
[22:27:29.299] iteration 7394 : model1 loss : 0.275772 model2 loss : 0.291528
[22:27:29.649] iteration 7395 : model1 loss : 0.350607 model2 loss : 0.347758
[22:27:29.991] iteration 7396 : model1 loss : 0.253133 model2 loss : 0.171692
[22:27:30.325] iteration 7397 : model1 loss : 0.208632 model2 loss : 0.203703
[22:27:30.655] iteration 7398 : model1 loss : 0.351360 model2 loss : 0.309843
[22:27:30.988] iteration 7399 : model1 loss : 0.301646 model2 loss : 0.300813
[22:27:31.332] iteration 7400 : model1 loss : 0.198896 model2 loss : 0.215528
[22:27:31.958] iteration 7401 : model1 loss : 0.215062 model2 loss : 0.286949
[22:27:32.288] iteration 7402 : model1 loss : 0.266813 model2 loss : 0.272463
[22:27:32.622] iteration 7403 : model1 loss : 0.310493 model2 loss : 0.245327
[22:27:32.954] iteration 7404 : model1 loss : 0.253035 model2 loss : 0.222331
[22:27:33.284] iteration 7405 : model1 loss : 0.269435 model2 loss : 0.252930
[22:27:33.614] iteration 7406 : model1 loss : 0.218753 model2 loss : 0.284451
[22:27:33.942] iteration 7407 : model1 loss : 0.351711 model2 loss : 0.339555
[22:27:34.276] iteration 7408 : model1 loss : 0.196554 model2 loss : 0.204412
[22:27:34.613] iteration 7409 : model1 loss : 0.282909 model2 loss : 0.277237
[22:27:34.943] iteration 7410 : model1 loss : 0.319440 model2 loss : 0.337983
[22:27:35.275] iteration 7411 : model1 loss : 0.234262 model2 loss : 0.270437
[22:27:35.603] iteration 7412 : model1 loss : 0.314580 model2 loss : 0.202346
[22:27:35.933] iteration 7413 : model1 loss : 0.293537 model2 loss : 0.268904
[22:27:36.262] iteration 7414 : model1 loss : 0.280726 model2 loss : 0.272093
[22:27:36.594] iteration 7415 : model1 loss : 0.241079 model2 loss : 0.288446
[22:27:36.926] iteration 7416 : model1 loss : 0.215634 model2 loss : 0.297826
[22:27:37.256] iteration 7417 : model1 loss : 0.284698 model2 loss : 0.284686
[22:27:37.586] iteration 7418 : model1 loss : 0.307187 model2 loss : 0.311704
[22:27:37.926] iteration 7419 : model1 loss : 0.307755 model2 loss : 0.273491
[22:27:38.260] iteration 7420 : model1 loss : 0.280177 model2 loss : 0.274774
[22:27:38.590] iteration 7421 : model1 loss : 0.251124 model2 loss : 0.284371
[22:27:38.920] iteration 7422 : model1 loss : 0.207703 model2 loss : 0.280263
[22:27:39.248] iteration 7423 : model1 loss : 0.331425 model2 loss : 0.359777
[22:27:39.575] iteration 7424 : model1 loss : 0.269979 model2 loss : 0.271214
[22:27:39.903] iteration 7425 : model1 loss : 0.200770 model2 loss : 0.207106
[22:27:40.230] iteration 7426 : model1 loss : 0.331237 model2 loss : 0.400872
[22:27:40.558] iteration 7427 : model1 loss : 0.275964 model2 loss : 0.316269
[22:27:40.885] iteration 7428 : model1 loss : 0.236319 model2 loss : 0.263976
[22:27:41.214] iteration 7429 : model1 loss : 0.246069 model2 loss : 0.227545
[22:27:41.542] iteration 7430 : model1 loss : 0.297294 model2 loss : 0.316740
[22:27:41.869] iteration 7431 : model1 loss : 0.314362 model2 loss : 0.287001
[22:27:42.206] iteration 7432 : model1 loss : 0.176717 model2 loss : 0.221410
[22:27:42.534] iteration 7433 : model1 loss : 0.259863 model2 loss : 0.286567
[22:27:42.870] iteration 7434 : model1 loss : 0.222078 model2 loss : 0.189513
[22:27:43.199] iteration 7435 : model1 loss : 0.153643 model2 loss : 0.214398
[22:27:43.527] iteration 7436 : model1 loss : 0.250889 model2 loss : 0.304572
[22:27:43.854] iteration 7437 : model1 loss : 0.276499 model2 loss : 0.247634
[22:27:44.181] iteration 7438 : model1 loss : 0.322580 model2 loss : 0.237289
[22:27:44.509] iteration 7439 : model1 loss : 0.219303 model2 loss : 0.229015
[22:27:44.837] iteration 7440 : model1 loss : 0.233912 model2 loss : 0.214891
[22:27:45.168] iteration 7441 : model1 loss : 0.220985 model2 loss : 0.228362
[22:27:45.497] iteration 7442 : model1 loss : 0.259259 model2 loss : 0.304597
[22:27:45.825] iteration 7443 : model1 loss : 0.264295 model2 loss : 0.239505
[22:27:46.162] iteration 7444 : model1 loss : 0.311459 model2 loss : 0.410360
[22:27:46.490] iteration 7445 : model1 loss : 0.198679 model2 loss : 0.234592
[22:27:46.818] iteration 7446 : model1 loss : 0.265478 model2 loss : 0.284561
[22:27:47.147] iteration 7447 : model1 loss : 0.230928 model2 loss : 0.181032
[22:27:47.474] iteration 7448 : model1 loss : 0.215389 model2 loss : 0.215776
[22:27:47.802] iteration 7449 : model1 loss : 0.198966 model2 loss : 0.141729
[22:27:48.130] iteration 7450 : model1 loss : 0.307444 model2 loss : 0.268614
[22:27:48.686] iteration 7451 : model1 loss : 0.193551 model2 loss : 0.253627
[22:27:49.018] iteration 7452 : model1 loss : 0.244821 model2 loss : 0.243197
[22:27:49.346] iteration 7453 : model1 loss : 0.209243 model2 loss : 0.228899
[22:27:49.674] iteration 7454 : model1 loss : 0.251408 model2 loss : 0.238459
[22:27:50.002] iteration 7455 : model1 loss : 0.333039 model2 loss : 0.256274
[22:27:50.331] iteration 7456 : model1 loss : 0.295422 model2 loss : 0.289217
[22:27:50.658] iteration 7457 : model1 loss : 0.257102 model2 loss : 0.160844
[22:27:50.986] iteration 7458 : model1 loss : 0.239393 model2 loss : 0.262573
[22:27:51.314] iteration 7459 : model1 loss : 0.204457 model2 loss : 0.237925
[22:27:51.643] iteration 7460 : model1 loss : 0.350663 model2 loss : 0.341382
[22:27:51.970] iteration 7461 : model1 loss : 0.324061 model2 loss : 0.294823
[22:27:52.298] iteration 7462 : model1 loss : 0.329467 model2 loss : 0.281889
[22:27:52.627] iteration 7463 : model1 loss : 0.368631 model2 loss : 0.366528
[22:27:52.955] iteration 7464 : model1 loss : 0.149767 model2 loss : 0.192278
[22:27:53.284] iteration 7465 : model1 loss : 0.305289 model2 loss : 0.358616
[22:27:53.612] iteration 7466 : model1 loss : 0.291185 model2 loss : 0.343607
[22:27:53.949] iteration 7467 : model1 loss : 0.115388 model2 loss : 0.181779
[22:27:54.279] iteration 7468 : model1 loss : 0.238219 model2 loss : 0.264531
[22:27:54.605] iteration 7469 : model1 loss : 0.312764 model2 loss : 0.325659
[22:27:54.933] iteration 7470 : model1 loss : 0.255271 model2 loss : 0.252933
[22:27:55.261] iteration 7471 : model1 loss : 0.202823 model2 loss : 0.164481
[22:27:55.589] iteration 7472 : model1 loss : 0.233333 model2 loss : 0.232674
[22:27:55.916] iteration 7473 : model1 loss : 0.338726 model2 loss : 0.280875
[22:27:56.244] iteration 7474 : model1 loss : 0.370278 model2 loss : 0.387729
[22:27:56.571] iteration 7475 : model1 loss : 0.265072 model2 loss : 0.278452
[22:27:56.900] iteration 7476 : model1 loss : 0.254800 model2 loss : 0.288954
[22:27:57.227] iteration 7477 : model1 loss : 0.305910 model2 loss : 0.337798
[22:27:57.554] iteration 7478 : model1 loss : 0.232174 model2 loss : 0.306396
[22:27:57.882] iteration 7479 : model1 loss : 0.276011 model2 loss : 0.246698
[22:27:58.210] iteration 7480 : model1 loss : 0.172767 model2 loss : 0.203184
[22:27:58.537] iteration 7481 : model1 loss : 0.284768 model2 loss : 0.360532
[22:27:58.865] iteration 7482 : model1 loss : 0.193694 model2 loss : 0.246812
[22:27:59.193] iteration 7483 : model1 loss : 0.402438 model2 loss : 0.437441
[22:27:59.522] iteration 7484 : model1 loss : 0.233027 model2 loss : 0.239460
[22:27:59.849] iteration 7485 : model1 loss : 0.232538 model2 loss : 0.203186
[22:28:00.177] iteration 7486 : model1 loss : 0.270337 model2 loss : 0.257214
[22:28:00.506] iteration 7487 : model1 loss : 0.223185 model2 loss : 0.269115
[22:28:00.834] iteration 7488 : model1 loss : 0.291747 model2 loss : 0.267019
[22:28:01.161] iteration 7489 : model1 loss : 0.330996 model2 loss : 0.322977
[22:28:01.488] iteration 7490 : model1 loss : 0.232849 model2 loss : 0.282168
[22:28:01.822] iteration 7491 : model1 loss : 0.229922 model2 loss : 0.244030
[22:28:02.150] iteration 7492 : model1 loss : 0.320198 model2 loss : 0.312135
[22:28:02.476] iteration 7493 : model1 loss : 0.336850 model2 loss : 0.373540
[22:28:02.801] iteration 7494 : model1 loss : 0.197174 model2 loss : 0.192484
[22:28:03.127] iteration 7495 : model1 loss : 0.212047 model2 loss : 0.260824
[22:28:03.454] iteration 7496 : model1 loss : 0.237449 model2 loss : 0.214307
[22:28:03.779] iteration 7497 : model1 loss : 0.250436 model2 loss : 0.252563
[22:28:04.106] iteration 7498 : model1 loss : 0.160030 model2 loss : 0.173704
[22:28:04.432] iteration 7499 : model1 loss : 0.263932 model2 loss : 0.221454
[22:28:04.758] iteration 7500 : model1 loss : 0.273098 model2 loss : 0.272348
[22:28:05.322] iteration 7501 : model1 loss : 0.298471 model2 loss : 0.318431
[22:28:05.659] iteration 7502 : model1 loss : 0.337532 model2 loss : 0.350544
[22:28:05.986] iteration 7503 : model1 loss : 0.267928 model2 loss : 0.278026
[22:28:06.314] iteration 7504 : model1 loss : 0.189268 model2 loss : 0.185197
[22:28:06.641] iteration 7505 : model1 loss : 0.198816 model2 loss : 0.232470
[22:28:06.968] iteration 7506 : model1 loss : 0.318730 model2 loss : 0.333608
[22:28:07.296] iteration 7507 : model1 loss : 0.268066 model2 loss : 0.311801
[22:28:07.624] iteration 7508 : model1 loss : 0.167896 model2 loss : 0.168197
[22:28:07.951] iteration 7509 : model1 loss : 0.284926 model2 loss : 0.295909
[22:28:08.278] iteration 7510 : model1 loss : 0.236596 model2 loss : 0.211866
[22:28:08.606] iteration 7511 : model1 loss : 0.207448 model2 loss : 0.223621
[22:28:08.933] iteration 7512 : model1 loss : 0.219235 model2 loss : 0.235025
[22:28:09.260] iteration 7513 : model1 loss : 0.165872 model2 loss : 0.214951
[22:28:09.588] iteration 7514 : model1 loss : 0.405548 model2 loss : 0.425903
[22:28:09.916] iteration 7515 : model1 loss : 0.209232 model2 loss : 0.240203
[22:28:10.244] iteration 7516 : model1 loss : 0.241780 model2 loss : 0.232285
[22:28:10.573] iteration 7517 : model1 loss : 0.331775 model2 loss : 0.369082
[22:28:10.900] iteration 7518 : model1 loss : 0.181223 model2 loss : 0.175113
[22:28:11.228] iteration 7519 : model1 loss : 0.166992 model2 loss : 0.197383
[22:28:11.555] iteration 7520 : model1 loss : 0.184500 model2 loss : 0.275395
[22:28:11.882] iteration 7521 : model1 loss : 0.317909 model2 loss : 0.296669
[22:28:12.209] iteration 7522 : model1 loss : 0.205156 model2 loss : 0.250300
[22:28:12.537] iteration 7523 : model1 loss : 0.116548 model2 loss : 0.172133
[22:28:12.866] iteration 7524 : model1 loss : 0.250760 model2 loss : 0.260317
[22:28:13.197] iteration 7525 : model1 loss : 0.236702 model2 loss : 0.274487
[22:28:13.524] iteration 7526 : model1 loss : 0.166349 model2 loss : 0.157761
[22:28:13.853] iteration 7527 : model1 loss : 0.206769 model2 loss : 0.261267
[22:28:14.186] iteration 7528 : model1 loss : 0.198739 model2 loss : 0.303325
[22:28:14.515] iteration 7529 : model1 loss : 0.159177 model2 loss : 0.232521
[22:28:14.842] iteration 7530 : model1 loss : 0.202567 model2 loss : 0.207453
[22:28:15.174] iteration 7531 : model1 loss : 0.210879 model2 loss : 0.253230
[22:28:15.502] iteration 7532 : model1 loss : 0.298961 model2 loss : 0.377874
[22:28:15.830] iteration 7533 : model1 loss : 0.175663 model2 loss : 0.220549
[22:28:16.157] iteration 7534 : model1 loss : 0.248734 model2 loss : 0.233915
[22:28:16.484] iteration 7535 : model1 loss : 0.250140 model2 loss : 0.176939
[22:28:16.813] iteration 7536 : model1 loss : 0.297898 model2 loss : 0.277147
[22:28:17.141] iteration 7537 : model1 loss : 0.238630 model2 loss : 0.235241
[22:28:17.469] iteration 7538 : model1 loss : 0.358392 model2 loss : 0.387382
[22:28:17.796] iteration 7539 : model1 loss : 0.286400 model2 loss : 0.224194
[22:28:18.122] iteration 7540 : model1 loss : 0.274875 model2 loss : 0.347484
[22:28:18.449] iteration 7541 : model1 loss : 0.274587 model2 loss : 0.299557
[22:28:18.776] iteration 7542 : model1 loss : 0.348904 model2 loss : 0.229410
[22:28:19.103] iteration 7543 : model1 loss : 0.292402 model2 loss : 0.219687
[22:28:19.430] iteration 7544 : model1 loss : 0.293122 model2 loss : 0.309929
[22:28:19.757] iteration 7545 : model1 loss : 0.298486 model2 loss : 0.277236
[22:28:20.086] iteration 7546 : model1 loss : 0.363630 model2 loss : 0.319881
[22:28:20.413] iteration 7547 : model1 loss : 0.276486 model2 loss : 0.220031
[22:28:20.740] iteration 7548 : model1 loss : 0.262352 model2 loss : 0.218254
[22:28:21.067] iteration 7549 : model1 loss : 0.206047 model2 loss : 0.179472
[22:28:21.394] iteration 7550 : model1 loss : 0.308053 model2 loss : 0.325896
[22:28:21.958] iteration 7551 : model1 loss : 0.267116 model2 loss : 0.292873
[22:28:22.287] iteration 7552 : model1 loss : 0.238517 model2 loss : 0.223888
[22:28:22.614] iteration 7553 : model1 loss : 0.268177 model2 loss : 0.299423
[22:28:22.942] iteration 7554 : model1 loss : 0.241373 model2 loss : 0.232341
[22:28:23.269] iteration 7555 : model1 loss : 0.190836 model2 loss : 0.220368
[22:28:23.596] iteration 7556 : model1 loss : 0.228941 model2 loss : 0.197000
[22:28:23.923] iteration 7557 : model1 loss : 0.265374 model2 loss : 0.283991
[22:28:24.250] iteration 7558 : model1 loss : 0.212609 model2 loss : 0.254059
[22:28:24.577] iteration 7559 : model1 loss : 0.221223 model2 loss : 0.245300
[22:28:24.904] iteration 7560 : model1 loss : 0.218607 model2 loss : 0.228450
[22:28:25.232] iteration 7561 : model1 loss : 0.249117 model2 loss : 0.219203
[22:28:25.560] iteration 7562 : model1 loss : 0.304883 model2 loss : 0.314935
[22:28:25.888] iteration 7563 : model1 loss : 0.401995 model2 loss : 0.401248
[22:28:26.215] iteration 7564 : model1 loss : 0.199031 model2 loss : 0.212479
[22:28:26.543] iteration 7565 : model1 loss : 0.227671 model2 loss : 0.286323
[22:28:26.870] iteration 7566 : model1 loss : 0.305404 model2 loss : 0.302289
[22:28:27.197] iteration 7567 : model1 loss : 0.180592 model2 loss : 0.189958
[22:28:27.525] iteration 7568 : model1 loss : 0.222970 model2 loss : 0.230520
[22:28:27.852] iteration 7569 : model1 loss : 0.263021 model2 loss : 0.275969
[22:28:28.180] iteration 7570 : model1 loss : 0.246990 model2 loss : 0.276830
[22:28:28.507] iteration 7571 : model1 loss : 0.257257 model2 loss : 0.283500
[22:28:28.834] iteration 7572 : model1 loss : 0.361536 model2 loss : 0.284505
[22:28:29.162] iteration 7573 : model1 loss : 0.281582 model2 loss : 0.248300
[22:28:29.489] iteration 7574 : model1 loss : 0.228773 model2 loss : 0.220022
[22:28:29.816] iteration 7575 : model1 loss : 0.262195 model2 loss : 0.278222
[22:28:30.147] iteration 7576 : model1 loss : 0.247849 model2 loss : 0.240721
[22:28:30.474] iteration 7577 : model1 loss : 0.257506 model2 loss : 0.269464
[22:28:30.800] iteration 7578 : model1 loss : 0.312622 model2 loss : 0.250356
[22:28:31.125] iteration 7579 : model1 loss : 0.313184 model2 loss : 0.261932
[22:28:31.452] iteration 7580 : model1 loss : 0.253870 model2 loss : 0.233553
[22:28:31.780] iteration 7581 : model1 loss : 0.291433 model2 loss : 0.186977
[22:28:32.105] iteration 7582 : model1 loss : 0.167669 model2 loss : 0.117340
[22:28:32.430] iteration 7583 : model1 loss : 0.309713 model2 loss : 0.317833
[22:28:32.756] iteration 7584 : model1 loss : 0.258119 model2 loss : 0.296012
[22:28:33.082] iteration 7585 : model1 loss : 0.189344 model2 loss : 0.279481
[22:28:33.408] iteration 7586 : model1 loss : 0.304228 model2 loss : 0.310793
[22:28:33.733] iteration 7587 : model1 loss : 0.298289 model2 loss : 0.342058
[22:28:34.058] iteration 7588 : model1 loss : 0.319438 model2 loss : 0.321816
[22:28:34.383] iteration 7589 : model1 loss : 0.261319 model2 loss : 0.240910
[22:28:34.711] iteration 7590 : model1 loss : 0.257785 model2 loss : 0.263324
[22:28:35.043] iteration 7591 : model1 loss : 0.338623 model2 loss : 0.322306
[22:28:35.370] iteration 7592 : model1 loss : 0.323024 model2 loss : 0.280573
[22:28:35.698] iteration 7593 : model1 loss : 0.230676 model2 loss : 0.250888
[22:28:36.025] iteration 7594 : model1 loss : 0.109267 model2 loss : 0.136093
[22:28:36.352] iteration 7595 : model1 loss : 0.311309 model2 loss : 0.336670
[22:28:36.680] iteration 7596 : model1 loss : 0.121432 model2 loss : 0.157562
[22:28:37.007] iteration 7597 : model1 loss : 0.257159 model2 loss : 0.271652
[22:28:37.334] iteration 7598 : model1 loss : 0.262190 model2 loss : 0.257491
[22:28:37.663] iteration 7599 : model1 loss : 0.296196 model2 loss : 0.270764
[22:28:37.990] iteration 7600 : model1 loss : 0.199279 model2 loss : 0.275895
[22:28:38.522] iteration 7601 : model1 loss : 0.298046 model2 loss : 0.304305
[22:28:38.851] iteration 7602 : model1 loss : 0.230836 model2 loss : 0.226536
[22:28:39.179] iteration 7603 : model1 loss : 0.247675 model2 loss : 0.276724
[22:28:39.507] iteration 7604 : model1 loss : 0.214774 model2 loss : 0.170345
[22:28:39.838] iteration 7605 : model1 loss : 0.226855 model2 loss : 0.204478
[22:28:40.166] iteration 7606 : model1 loss : 0.333232 model2 loss : 0.317006
[22:28:40.494] iteration 7607 : model1 loss : 0.384847 model2 loss : 0.378554
[22:28:40.822] iteration 7608 : model1 loss : 0.344159 model2 loss : 0.392054
[22:28:41.149] iteration 7609 : model1 loss : 0.274478 model2 loss : 0.298175
[22:28:41.476] iteration 7610 : model1 loss : 0.345015 model2 loss : 0.356891
[22:28:41.805] iteration 7611 : model1 loss : 0.253875 model2 loss : 0.282408
[22:28:42.132] iteration 7612 : model1 loss : 0.233211 model2 loss : 0.304657
[22:28:42.459] iteration 7613 : model1 loss : 0.241127 model2 loss : 0.292233
[22:28:42.786] iteration 7614 : model1 loss : 0.200580 model2 loss : 0.220873
[22:28:43.114] iteration 7615 : model1 loss : 0.330563 model2 loss : 0.332037
[22:28:43.441] iteration 7616 : model1 loss : 0.315827 model2 loss : 0.336195
[22:28:43.769] iteration 7617 : model1 loss : 0.210730 model2 loss : 0.273735
[22:28:44.097] iteration 7618 : model1 loss : 0.199929 model2 loss : 0.267687
[22:28:44.424] iteration 7619 : model1 loss : 0.221609 model2 loss : 0.271761
[22:28:44.751] iteration 7620 : model1 loss : 0.195415 model2 loss : 0.244205
[22:28:45.079] iteration 7621 : model1 loss : 0.285607 model2 loss : 0.169656
[22:28:45.407] iteration 7622 : model1 loss : 0.337354 model2 loss : 0.354363
[22:28:45.735] iteration 7623 : model1 loss : 0.223693 model2 loss : 0.228684
[22:28:46.062] iteration 7624 : model1 loss : 0.212483 model2 loss : 0.271024
[22:28:46.388] iteration 7625 : model1 loss : 0.280876 model2 loss : 0.220600
[22:28:46.714] iteration 7626 : model1 loss : 0.231687 model2 loss : 0.299538
[22:28:47.041] iteration 7627 : model1 loss : 0.231791 model2 loss : 0.225394
[22:28:47.367] iteration 7628 : model1 loss : 0.251782 model2 loss : 0.247872
[22:28:47.695] iteration 7629 : model1 loss : 0.236719 model2 loss : 0.305115
[22:28:48.024] iteration 7630 : model1 loss : 0.233833 model2 loss : 0.291939
[22:28:48.850] iteration 7631 : model1 loss : 0.250710 model2 loss : 0.293624
[22:28:49.178] iteration 7632 : model1 loss : 0.213074 model2 loss : 0.215636
[22:28:49.506] iteration 7633 : model1 loss : 0.431847 model2 loss : 0.447829
[22:28:49.833] iteration 7634 : model1 loss : 0.301827 model2 loss : 0.286078
[22:28:50.163] iteration 7635 : model1 loss : 0.285595 model2 loss : 0.331696
[22:28:50.493] iteration 7636 : model1 loss : 0.233271 model2 loss : 0.311849
[22:28:50.821] iteration 7637 : model1 loss : 0.362717 model2 loss : 0.312484
[22:28:51.148] iteration 7638 : model1 loss : 0.115076 model2 loss : 0.121147
[22:28:51.476] iteration 7639 : model1 loss : 0.310509 model2 loss : 0.320392
[22:28:51.804] iteration 7640 : model1 loss : 0.264230 model2 loss : 0.299844
[22:28:52.133] iteration 7641 : model1 loss : 0.302861 model2 loss : 0.300766
[22:28:52.461] iteration 7642 : model1 loss : 0.206813 model2 loss : 0.262921
[22:28:52.790] iteration 7643 : model1 loss : 0.147660 model2 loss : 0.172185
[22:28:53.120] iteration 7644 : model1 loss : 0.350813 model2 loss : 0.379609
[22:28:53.451] iteration 7645 : model1 loss : 0.189937 model2 loss : 0.252895
[22:28:53.787] iteration 7646 : model1 loss : 0.201046 model2 loss : 0.219356
[22:28:54.126] iteration 7647 : model1 loss : 0.302198 model2 loss : 0.305414
[22:28:54.466] iteration 7648 : model1 loss : 0.292908 model2 loss : 0.360815
[22:28:54.803] iteration 7649 : model1 loss : 0.378503 model2 loss : 0.345739
[22:28:55.140] iteration 7650 : model1 loss : 0.134268 model2 loss : 0.136285
[22:28:55.790] iteration 7651 : model1 loss : 0.130703 model2 loss : 0.146336
[22:28:56.129] iteration 7652 : model1 loss : 0.252997 model2 loss : 0.270676
[22:28:56.472] iteration 7653 : model1 loss : 0.264990 model2 loss : 0.267267
[22:28:56.810] iteration 7654 : model1 loss : 0.316056 model2 loss : 0.306999
[22:28:57.141] iteration 7655 : model1 loss : 0.338321 model2 loss : 0.328404
[22:28:57.470] iteration 7656 : model1 loss : 0.313053 model2 loss : 0.335272
[22:28:57.806] iteration 7657 : model1 loss : 0.145919 model2 loss : 0.165841
[22:28:58.142] iteration 7658 : model1 loss : 0.274874 model2 loss : 0.291391
[22:28:58.472] iteration 7659 : model1 loss : 0.304627 model2 loss : 0.247845
[22:28:58.800] iteration 7660 : model1 loss : 0.281798 model2 loss : 0.305204
[22:28:59.137] iteration 7661 : model1 loss : 0.305504 model2 loss : 0.337300
[22:28:59.478] iteration 7662 : model1 loss : 0.223300 model2 loss : 0.246749
[22:28:59.807] iteration 7663 : model1 loss : 0.153357 model2 loss : 0.197223
[22:29:00.135] iteration 7664 : model1 loss : 0.183856 model2 loss : 0.221781
[22:29:00.474] iteration 7665 : model1 loss : 0.393195 model2 loss : 0.401841
[22:29:00.811] iteration 7666 : model1 loss : 0.230904 model2 loss : 0.192616
[22:29:01.141] iteration 7667 : model1 loss : 0.248087 model2 loss : 0.224711
[22:29:01.469] iteration 7668 : model1 loss : 0.298397 model2 loss : 0.279281
[22:29:01.806] iteration 7669 : model1 loss : 0.285793 model2 loss : 0.289046
[22:29:02.143] iteration 7670 : model1 loss : 0.240347 model2 loss : 0.256586
[22:29:02.479] iteration 7671 : model1 loss : 0.333938 model2 loss : 0.288051
[22:29:02.809] iteration 7672 : model1 loss : 0.214630 model2 loss : 0.241871
[22:29:03.139] iteration 7673 : model1 loss : 0.337612 model2 loss : 0.322875
[22:29:03.470] iteration 7674 : model1 loss : 0.227707 model2 loss : 0.228076
[22:29:03.799] iteration 7675 : model1 loss : 0.292251 model2 loss : 0.330449
[22:29:04.126] iteration 7676 : model1 loss : 0.191418 model2 loss : 0.202141
[22:29:04.456] iteration 7677 : model1 loss : 0.277737 model2 loss : 0.326501
[22:29:04.784] iteration 7678 : model1 loss : 0.302477 model2 loss : 0.308960
[22:29:05.114] iteration 7679 : model1 loss : 0.217573 model2 loss : 0.208120
[22:29:05.444] iteration 7680 : model1 loss : 0.167731 model2 loss : 0.141401
[22:29:05.773] iteration 7681 : model1 loss : 0.261433 model2 loss : 0.319969
[22:29:06.103] iteration 7682 : model1 loss : 0.240609 model2 loss : 0.289021
[22:29:06.431] iteration 7683 : model1 loss : 0.318656 model2 loss : 0.319788
[22:29:06.759] iteration 7684 : model1 loss : 0.239707 model2 loss : 0.273054
[22:29:07.092] iteration 7685 : model1 loss : 0.253222 model2 loss : 0.320087
[22:29:07.420] iteration 7686 : model1 loss : 0.366976 model2 loss : 0.331113
[22:29:07.751] iteration 7687 : model1 loss : 0.259042 model2 loss : 0.264810
[22:29:08.084] iteration 7688 : model1 loss : 0.334799 model2 loss : 0.292962
[22:29:08.413] iteration 7689 : model1 loss : 0.173755 model2 loss : 0.171361
[22:29:08.743] iteration 7690 : model1 loss : 0.202927 model2 loss : 0.165144
[22:29:09.078] iteration 7691 : model1 loss : 0.298890 model2 loss : 0.390495
[22:29:09.410] iteration 7692 : model1 loss : 0.211620 model2 loss : 0.205209
[22:29:09.739] iteration 7693 : model1 loss : 0.310072 model2 loss : 0.276782
[22:29:10.070] iteration 7694 : model1 loss : 0.156984 model2 loss : 0.189872
[22:29:10.406] iteration 7695 : model1 loss : 0.212737 model2 loss : 0.146055
[22:29:10.741] iteration 7696 : model1 loss : 0.180827 model2 loss : 0.195333
[22:29:11.071] iteration 7697 : model1 loss : 0.201850 model2 loss : 0.213778
[22:29:11.403] iteration 7698 : model1 loss : 0.328010 model2 loss : 0.253001
[22:29:11.735] iteration 7699 : model1 loss : 0.276269 model2 loss : 0.325146
[22:29:12.065] iteration 7700 : model1 loss : 0.310961 model2 loss : 0.302373
[22:29:12.636] iteration 7701 : model1 loss : 0.176333 model2 loss : 0.264708
[22:29:12.967] iteration 7702 : model1 loss : 0.255738 model2 loss : 0.279195
[22:29:13.297] iteration 7703 : model1 loss : 0.287886 model2 loss : 0.353293
[22:29:13.626] iteration 7704 : model1 loss : 0.142326 model2 loss : 0.267144
[22:29:13.956] iteration 7705 : model1 loss : 0.317420 model2 loss : 0.362333
[22:29:14.286] iteration 7706 : model1 loss : 0.318818 model2 loss : 0.287312
[22:29:14.617] iteration 7707 : model1 loss : 0.262709 model2 loss : 0.327896
[22:29:14.948] iteration 7708 : model1 loss : 0.193419 model2 loss : 0.178457
[22:29:15.279] iteration 7709 : model1 loss : 0.171364 model2 loss : 0.191150
[22:29:15.610] iteration 7710 : model1 loss : 0.184420 model2 loss : 0.148052
[22:29:15.938] iteration 7711 : model1 loss : 0.309868 model2 loss : 0.303264
[22:29:16.268] iteration 7712 : model1 loss : 0.258140 model2 loss : 0.227681
[22:29:16.599] iteration 7713 : model1 loss : 0.281919 model2 loss : 0.278549
[22:29:16.930] iteration 7714 : model1 loss : 0.118284 model2 loss : 0.233040
[22:29:17.260] iteration 7715 : model1 loss : 0.144173 model2 loss : 0.238943
[22:29:17.587] iteration 7716 : model1 loss : 0.203097 model2 loss : 0.250701
[22:29:17.914] iteration 7717 : model1 loss : 0.198110 model2 loss : 0.204658
[22:29:18.241] iteration 7718 : model1 loss : 0.289591 model2 loss : 0.353239
[22:29:18.576] iteration 7719 : model1 loss : 0.294196 model2 loss : 0.355732
[22:29:18.904] iteration 7720 : model1 loss : 0.191638 model2 loss : 0.303707
[22:29:19.233] iteration 7721 : model1 loss : 0.234106 model2 loss : 0.262598
[22:29:19.561] iteration 7722 : model1 loss : 0.285978 model2 loss : 0.298757
[22:29:19.888] iteration 7723 : model1 loss : 0.097720 model2 loss : 0.111443
[22:29:20.216] iteration 7724 : model1 loss : 0.241429 model2 loss : 0.228282
[22:29:20.544] iteration 7725 : model1 loss : 0.214003 model2 loss : 0.255072
[22:29:20.872] iteration 7726 : model1 loss : 0.283756 model2 loss : 0.224063
[22:29:21.202] iteration 7727 : model1 loss : 0.225874 model2 loss : 0.223863
[22:29:21.533] iteration 7728 : model1 loss : 0.193203 model2 loss : 0.190326
[22:29:21.863] iteration 7729 : model1 loss : 0.486333 model2 loss : 0.329381
[22:29:22.195] iteration 7730 : model1 loss : 0.259990 model2 loss : 0.295880
[22:29:22.526] iteration 7731 : model1 loss : 0.193807 model2 loss : 0.265674
[22:29:22.855] iteration 7732 : model1 loss : 0.159043 model2 loss : 0.205865
[22:29:23.186] iteration 7733 : model1 loss : 0.372099 model2 loss : 0.379468
[22:29:23.516] iteration 7734 : model1 loss : 0.198500 model2 loss : 0.204911
[22:29:23.848] iteration 7735 : model1 loss : 0.150635 model2 loss : 0.177889
[22:29:24.179] iteration 7736 : model1 loss : 0.284168 model2 loss : 0.293874
[22:29:24.511] iteration 7737 : model1 loss : 0.299162 model2 loss : 0.274218
[22:29:24.842] iteration 7738 : model1 loss : 0.251334 model2 loss : 0.218320
[22:29:25.175] iteration 7739 : model1 loss : 0.195308 model2 loss : 0.195890
[22:29:25.506] iteration 7740 : model1 loss : 0.156531 model2 loss : 0.161602
[22:29:25.834] iteration 7741 : model1 loss : 0.248794 model2 loss : 0.289378
[22:29:26.174] iteration 7742 : model1 loss : 0.298195 model2 loss : 0.301609
[22:29:26.508] iteration 7743 : model1 loss : 0.277851 model2 loss : 0.302727
[22:29:26.839] iteration 7744 : model1 loss : 0.262858 model2 loss : 0.299121
[22:29:27.169] iteration 7745 : model1 loss : 0.179662 model2 loss : 0.198646
[22:29:27.499] iteration 7746 : model1 loss : 0.284265 model2 loss : 0.355681
[22:29:27.827] iteration 7747 : model1 loss : 0.381202 model2 loss : 0.389107
[22:29:28.156] iteration 7748 : model1 loss : 0.287989 model2 loss : 0.285575
[22:29:28.485] iteration 7749 : model1 loss : 0.258856 model2 loss : 0.281696
[22:29:28.814] iteration 7750 : model1 loss : 0.211467 model2 loss : 0.300432
[22:29:29.375] iteration 7751 : model1 loss : 0.143800 model2 loss : 0.210208
[22:29:29.706] iteration 7752 : model1 loss : 0.289475 model2 loss : 0.339436
[22:29:30.033] iteration 7753 : model1 loss : 0.230556 model2 loss : 0.248569
[22:29:30.364] iteration 7754 : model1 loss : 0.363549 model2 loss : 0.382807
[22:29:30.692] iteration 7755 : model1 loss : 0.274790 model2 loss : 0.275883
[22:29:31.020] iteration 7756 : model1 loss : 0.344172 model2 loss : 0.347142
[22:29:31.348] iteration 7757 : model1 loss : 0.286337 model2 loss : 0.249508
[22:29:31.677] iteration 7758 : model1 loss : 0.272428 model2 loss : 0.229415
[22:29:32.007] iteration 7759 : model1 loss : 0.343428 model2 loss : 0.364416
[22:29:32.337] iteration 7760 : model1 loss : 0.178533 model2 loss : 0.276456
[22:29:32.667] iteration 7761 : model1 loss : 0.259282 model2 loss : 0.281950
[22:29:32.996] iteration 7762 : model1 loss : 0.228389 model2 loss : 0.251134
[22:29:33.326] iteration 7763 : model1 loss : 0.212412 model2 loss : 0.254444
[22:29:33.653] iteration 7764 : model1 loss : 0.147921 model2 loss : 0.167378
[22:29:33.993] iteration 7765 : model1 loss : 0.309796 model2 loss : 0.318204
[22:29:34.324] iteration 7766 : model1 loss : 0.183881 model2 loss : 0.273885
[22:29:34.655] iteration 7767 : model1 loss : 0.192062 model2 loss : 0.206668
[22:29:34.990] iteration 7768 : model1 loss : 0.272733 model2 loss : 0.255159
[22:29:35.321] iteration 7769 : model1 loss : 0.300285 model2 loss : 0.266320
[22:29:35.651] iteration 7770 : model1 loss : 0.136827 model2 loss : 0.193025
[22:29:35.979] iteration 7771 : model1 loss : 0.347617 model2 loss : 0.330110
[22:29:36.308] iteration 7772 : model1 loss : 0.247355 model2 loss : 0.180615
[22:29:36.638] iteration 7773 : model1 loss : 0.282243 model2 loss : 0.201569
[22:29:36.968] iteration 7774 : model1 loss : 0.224553 model2 loss : 0.211474
[22:29:37.297] iteration 7775 : model1 loss : 0.330972 model2 loss : 0.303589
[22:29:37.628] iteration 7776 : model1 loss : 0.238112 model2 loss : 0.205283
[22:29:37.959] iteration 7777 : model1 loss : 0.193490 model2 loss : 0.199558
[22:29:38.286] iteration 7778 : model1 loss : 0.241395 model2 loss : 0.245060
[22:29:38.619] iteration 7779 : model1 loss : 0.254289 model2 loss : 0.269936
[22:29:38.948] iteration 7780 : model1 loss : 0.290107 model2 loss : 0.313277
[22:29:39.279] iteration 7781 : model1 loss : 0.279832 model2 loss : 0.195966
[22:29:39.611] iteration 7782 : model1 loss : 0.302574 model2 loss : 0.349346
[22:29:39.940] iteration 7783 : model1 loss : 0.325802 model2 loss : 0.334338
[22:29:40.268] iteration 7784 : model1 loss : 0.224123 model2 loss : 0.274467
[22:29:40.595] iteration 7785 : model1 loss : 0.227570 model2 loss : 0.200241
[22:29:40.925] iteration 7786 : model1 loss : 0.189070 model2 loss : 0.240764
[22:29:41.255] iteration 7787 : model1 loss : 0.300026 model2 loss : 0.278440
[22:29:41.584] iteration 7788 : model1 loss : 0.230091 model2 loss : 0.251901
[22:29:41.914] iteration 7789 : model1 loss : 0.310102 model2 loss : 0.298567
[22:29:42.244] iteration 7790 : model1 loss : 0.274368 model2 loss : 0.271199
[22:29:42.574] iteration 7791 : model1 loss : 0.232636 model2 loss : 0.254335
[22:29:42.904] iteration 7792 : model1 loss : 0.234571 model2 loss : 0.237250
[22:29:43.234] iteration 7793 : model1 loss : 0.304883 model2 loss : 0.309738
[22:29:43.567] iteration 7794 : model1 loss : 0.278826 model2 loss : 0.273786
[22:29:43.897] iteration 7795 : model1 loss : 0.183012 model2 loss : 0.200307
[22:29:44.226] iteration 7796 : model1 loss : 0.155296 model2 loss : 0.155264
[22:29:44.556] iteration 7797 : model1 loss : 0.350416 model2 loss : 0.316581
[22:29:44.887] iteration 7798 : model1 loss : 0.241276 model2 loss : 0.234623
[22:29:45.217] iteration 7799 : model1 loss : 0.209751 model2 loss : 0.239739
[22:29:45.551] iteration 7800 : model1 loss : 0.202900 model2 loss : 0.273710
[22:29:46.138] iteration 7801 : model1 loss : 0.289876 model2 loss : 0.322929
[22:29:46.470] iteration 7802 : model1 loss : 0.227185 model2 loss : 0.209687
[22:29:46.798] iteration 7803 : model1 loss : 0.376461 model2 loss : 0.307922
[22:29:47.130] iteration 7804 : model1 loss : 0.197521 model2 loss : 0.219925
[22:29:47.463] iteration 7805 : model1 loss : 0.224307 model2 loss : 0.286706
[22:29:47.794] iteration 7806 : model1 loss : 0.218410 model2 loss : 0.243178
[22:29:48.127] iteration 7807 : model1 loss : 0.264814 model2 loss : 0.272974
[22:29:48.460] iteration 7808 : model1 loss : 0.200531 model2 loss : 0.212862
[22:29:48.789] iteration 7809 : model1 loss : 0.298472 model2 loss : 0.282296
[22:29:49.118] iteration 7810 : model1 loss : 0.229908 model2 loss : 0.244134
[22:29:49.441] iteration 7811 : model1 loss : 0.132931 model2 loss : 0.244677
[22:29:49.766] iteration 7812 : model1 loss : 0.180179 model2 loss : 0.225647
[22:29:50.099] iteration 7813 : model1 loss : 0.223136 model2 loss : 0.257207
[22:29:50.427] iteration 7814 : model1 loss : 0.294149 model2 loss : 0.369496
[22:29:50.757] iteration 7815 : model1 loss : 0.278569 model2 loss : 0.260195
[22:29:51.091] iteration 7816 : model1 loss : 0.224961 model2 loss : 0.259976
[22:29:51.422] iteration 7817 : model1 loss : 0.282877 model2 loss : 0.276747
[22:29:51.753] iteration 7818 : model1 loss : 0.273850 model2 loss : 0.327020
[22:29:52.081] iteration 7819 : model1 loss : 0.224561 model2 loss : 0.208287
[22:29:52.413] iteration 7820 : model1 loss : 0.113500 model2 loss : 0.141779
[22:29:52.741] iteration 7821 : model1 loss : 0.230379 model2 loss : 0.251611
[22:29:53.071] iteration 7822 : model1 loss : 0.247132 model2 loss : 0.257765
[22:29:53.401] iteration 7823 : model1 loss : 0.374138 model2 loss : 0.381998
[22:29:53.738] iteration 7824 : model1 loss : 0.251977 model2 loss : 0.215335
[22:29:54.072] iteration 7825 : model1 loss : 0.197034 model2 loss : 0.256738
[22:29:54.402] iteration 7826 : model1 loss : 0.226355 model2 loss : 0.229645
[22:29:54.732] iteration 7827 : model1 loss : 0.327357 model2 loss : 0.368997
[22:29:55.062] iteration 7828 : model1 loss : 0.183728 model2 loss : 0.171233
[22:29:55.393] iteration 7829 : model1 loss : 0.187176 model2 loss : 0.199033
[22:29:55.723] iteration 7830 : model1 loss : 0.202933 model2 loss : 0.229669
[22:29:56.050] iteration 7831 : model1 loss : 0.253893 model2 loss : 0.244293
[22:29:56.380] iteration 7832 : model1 loss : 0.166460 model2 loss : 0.207245
[22:29:56.707] iteration 7833 : model1 loss : 0.177305 model2 loss : 0.149135
[22:29:57.048] iteration 7834 : model1 loss : 0.168483 model2 loss : 0.138871
[22:29:57.387] iteration 7835 : model1 loss : 0.199730 model2 loss : 0.257549
[22:29:57.718] iteration 7836 : model1 loss : 0.334120 model2 loss : 0.249868
[22:29:58.046] iteration 7837 : model1 loss : 0.144605 model2 loss : 0.241437
[22:29:58.374] iteration 7838 : model1 loss : 0.222855 model2 loss : 0.257525
[22:29:58.709] iteration 7839 : model1 loss : 0.296044 model2 loss : 0.241547
[22:29:59.037] iteration 7840 : model1 loss : 0.192125 model2 loss : 0.239237
[22:29:59.364] iteration 7841 : model1 loss : 0.237947 model2 loss : 0.208593
[22:29:59.692] iteration 7842 : model1 loss : 0.184674 model2 loss : 0.242106
[22:30:00.024] iteration 7843 : model1 loss : 0.260118 model2 loss : 0.278019
[22:30:00.351] iteration 7844 : model1 loss : 0.293048 model2 loss : 0.329193
[22:30:00.680] iteration 7845 : model1 loss : 0.242700 model2 loss : 0.297268
[22:30:01.008] iteration 7846 : model1 loss : 0.161010 model2 loss : 0.165467
[22:30:01.336] iteration 7847 : model1 loss : 0.280401 model2 loss : 0.300303
[22:30:01.663] iteration 7848 : model1 loss : 0.291058 model2 loss : 0.272134
[22:30:01.992] iteration 7849 : model1 loss : 0.257419 model2 loss : 0.276742
[22:30:02.320] iteration 7850 : model1 loss : 0.363093 model2 loss : 0.308860
[22:30:02.875] iteration 7851 : model1 loss : 0.285926 model2 loss : 0.167219
[22:30:03.203] iteration 7852 : model1 loss : 0.227658 model2 loss : 0.298289
[22:30:03.531] iteration 7853 : model1 loss : 0.103222 model2 loss : 0.183456
[22:30:03.860] iteration 7854 : model1 loss : 0.418354 model2 loss : 0.453190
[22:30:04.189] iteration 7855 : model1 loss : 0.283514 model2 loss : 0.351128
[22:30:04.519] iteration 7856 : model1 loss : 0.183805 model2 loss : 0.161788
[22:30:04.847] iteration 7857 : model1 loss : 0.156104 model2 loss : 0.191436
[22:30:05.175] iteration 7858 : model1 loss : 0.199170 model2 loss : 0.183878
[22:30:05.504] iteration 7859 : model1 loss : 0.289054 model2 loss : 0.303898
[22:30:05.835] iteration 7860 : model1 loss : 0.267794 model2 loss : 0.294232
[22:30:06.176] iteration 7861 : model1 loss : 0.250520 model2 loss : 0.219896
[22:30:06.516] iteration 7862 : model1 loss : 0.214068 model2 loss : 0.207257
[22:30:06.856] iteration 7863 : model1 loss : 0.199207 model2 loss : 0.230476
[22:30:07.194] iteration 7864 : model1 loss : 0.234665 model2 loss : 0.237231
[22:30:07.534] iteration 7865 : model1 loss : 0.362805 model2 loss : 0.263129
[22:30:07.873] iteration 7866 : model1 loss : 0.285873 model2 loss : 0.289669
[22:30:08.218] iteration 7867 : model1 loss : 0.163499 model2 loss : 0.205102
[22:30:08.567] iteration 7868 : model1 loss : 0.272898 model2 loss : 0.293987
[22:30:08.910] iteration 7869 : model1 loss : 0.263192 model2 loss : 0.330937
[22:30:09.249] iteration 7870 : model1 loss : 0.316047 model2 loss : 0.338981
[22:30:09.592] iteration 7871 : model1 loss : 0.321565 model2 loss : 0.366024
[22:30:09.964] iteration 7872 : model1 loss : 0.328680 model2 loss : 0.272096
[22:30:10.308] iteration 7873 : model1 loss : 0.248328 model2 loss : 0.213885
[22:30:10.647] iteration 7874 : model1 loss : 0.245291 model2 loss : 0.243101
[22:30:10.985] iteration 7875 : model1 loss : 0.205194 model2 loss : 0.165977
[22:30:11.328] iteration 7876 : model1 loss : 0.397992 model2 loss : 0.365304
[22:30:11.670] iteration 7877 : model1 loss : 0.325134 model2 loss : 0.356728
[22:30:12.007] iteration 7878 : model1 loss : 0.307797 model2 loss : 0.246911
[22:30:12.351] iteration 7879 : model1 loss : 0.244771 model2 loss : 0.224788
[22:30:12.694] iteration 7880 : model1 loss : 0.340008 model2 loss : 0.326674
[22:30:13.037] iteration 7881 : model1 loss : 0.240646 model2 loss : 0.257072
[22:30:13.378] iteration 7882 : model1 loss : 0.291164 model2 loss : 0.312835
[22:30:13.719] iteration 7883 : model1 loss : 0.367951 model2 loss : 0.348005
[22:30:14.062] iteration 7884 : model1 loss : 0.204017 model2 loss : 0.172820
[22:30:14.399] iteration 7885 : model1 loss : 0.323407 model2 loss : 0.390855
[22:30:14.741] iteration 7886 : model1 loss : 0.339808 model2 loss : 0.222170
[22:30:15.079] iteration 7887 : model1 loss : 0.376254 model2 loss : 0.330928
[22:30:15.417] iteration 7888 : model1 loss : 0.285521 model2 loss : 0.268095
[22:30:15.756] iteration 7889 : model1 loss : 0.277005 model2 loss : 0.320815
[22:30:16.098] iteration 7890 : model1 loss : 0.306863 model2 loss : 0.314577
[22:30:16.434] iteration 7891 : model1 loss : 0.316168 model2 loss : 0.260218
[22:30:16.774] iteration 7892 : model1 loss : 0.345015 model2 loss : 0.341863
[22:30:17.114] iteration 7893 : model1 loss : 0.370668 model2 loss : 0.314889
[22:30:17.451] iteration 7894 : model1 loss : 0.290822 model2 loss : 0.291153
[22:30:17.788] iteration 7895 : model1 loss : 0.285691 model2 loss : 0.320872
[22:30:18.132] iteration 7896 : model1 loss : 0.385733 model2 loss : 0.401660
[22:30:18.473] iteration 7897 : model1 loss : 0.270658 model2 loss : 0.247969
[22:30:18.811] iteration 7898 : model1 loss : 0.315844 model2 loss : 0.250511
[22:30:19.148] iteration 7899 : model1 loss : 0.322570 model2 loss : 0.340106
[22:30:19.488] iteration 7900 : model1 loss : 0.247538 model2 loss : 0.183953
[22:30:20.140] iteration 7901 : model1 loss : 0.310786 model2 loss : 0.300797
[22:30:20.485] iteration 7902 : model1 loss : 0.307462 model2 loss : 0.176741
[22:30:20.822] iteration 7903 : model1 loss : 0.251556 model2 loss : 0.256205
[22:30:21.158] iteration 7904 : model1 loss : 0.373935 model2 loss : 0.358957
[22:30:21.498] iteration 7905 : model1 loss : 0.186680 model2 loss : 0.251632
[22:30:21.836] iteration 7906 : model1 loss : 0.308981 model2 loss : 0.337990
[22:30:22.178] iteration 7907 : model1 loss : 0.173255 model2 loss : 0.121096
[22:30:22.521] iteration 7908 : model1 loss : 0.336161 model2 loss : 0.357657
[22:30:22.859] iteration 7909 : model1 loss : 0.241179 model2 loss : 0.188409
[22:30:23.199] iteration 7910 : model1 loss : 0.319028 model2 loss : 0.312221
[22:30:23.536] iteration 7911 : model1 loss : 0.286815 model2 loss : 0.351420
[22:30:23.877] iteration 7912 : model1 loss : 0.238883 model2 loss : 0.218669
[22:30:24.215] iteration 7913 : model1 loss : 0.359749 model2 loss : 0.359607
[22:30:24.551] iteration 7914 : model1 loss : 0.284891 model2 loss : 0.327347
[22:30:24.888] iteration 7915 : model1 loss : 0.207652 model2 loss : 0.185499
[22:30:25.226] iteration 7916 : model1 loss : 0.161403 model2 loss : 0.152795
[22:30:25.566] iteration 7917 : model1 loss : 0.424022 model2 loss : 0.370329
[22:30:25.908] iteration 7918 : model1 loss : 0.221794 model2 loss : 0.178980
[22:30:26.250] iteration 7919 : model1 loss : 0.194094 model2 loss : 0.249356
[22:30:26.593] iteration 7920 : model1 loss : 0.365326 model2 loss : 0.283122
[22:30:26.934] iteration 7921 : model1 loss : 0.211043 model2 loss : 0.217725
[22:30:27.275] iteration 7922 : model1 loss : 0.308297 model2 loss : 0.362887
[22:30:27.614] iteration 7923 : model1 loss : 0.288821 model2 loss : 0.335837
[22:30:27.953] iteration 7924 : model1 loss : 0.336669 model2 loss : 0.428632
[22:30:28.296] iteration 7925 : model1 loss : 0.276211 model2 loss : 0.236109
[22:30:28.638] iteration 7926 : model1 loss : 0.191592 model2 loss : 0.201750
[22:30:28.979] iteration 7927 : model1 loss : 0.305453 model2 loss : 0.318521
[22:30:29.321] iteration 7928 : model1 loss : 0.199923 model2 loss : 0.358780
[22:30:29.660] iteration 7929 : model1 loss : 0.258619 model2 loss : 0.236990
[22:30:30.002] iteration 7930 : model1 loss : 0.309897 model2 loss : 0.382190
[22:30:30.346] iteration 7931 : model1 loss : 0.181748 model2 loss : 0.158638
[22:30:30.688] iteration 7932 : model1 loss : 0.295732 model2 loss : 0.293009
[22:30:31.027] iteration 7933 : model1 loss : 0.307531 model2 loss : 0.322539
[22:30:31.368] iteration 7934 : model1 loss : 0.154602 model2 loss : 0.166331
[22:30:31.710] iteration 7935 : model1 loss : 0.222772 model2 loss : 0.233314
[22:30:32.049] iteration 7936 : model1 loss : 0.149156 model2 loss : 0.136888
[22:30:32.386] iteration 7937 : model1 loss : 0.250629 model2 loss : 0.282312
[22:30:32.723] iteration 7938 : model1 loss : 0.098344 model2 loss : 0.200462
[22:30:33.065] iteration 7939 : model1 loss : 0.228443 model2 loss : 0.250262
[22:30:33.404] iteration 7940 : model1 loss : 0.275685 model2 loss : 0.287816
[22:30:33.741] iteration 7941 : model1 loss : 0.291957 model2 loss : 0.275310
[22:30:34.078] iteration 7942 : model1 loss : 0.174719 model2 loss : 0.173552
[22:30:34.421] iteration 7943 : model1 loss : 0.213544 model2 loss : 0.160810
[22:30:34.763] iteration 7944 : model1 loss : 0.148649 model2 loss : 0.178484
[22:30:35.106] iteration 7945 : model1 loss : 0.229723 model2 loss : 0.314608
[22:30:35.445] iteration 7946 : model1 loss : 0.214026 model2 loss : 0.211519
[22:30:35.787] iteration 7947 : model1 loss : 0.271325 model2 loss : 0.195694
[22:30:36.128] iteration 7948 : model1 loss : 0.140931 model2 loss : 0.171133
[22:30:36.471] iteration 7949 : model1 loss : 0.183084 model2 loss : 0.228011
[22:30:36.818] iteration 7950 : model1 loss : 0.295366 model2 loss : 0.306428
[22:30:37.488] iteration 7951 : model1 loss : 0.285096 model2 loss : 0.314758
[22:30:37.831] iteration 7952 : model1 loss : 0.277401 model2 loss : 0.281899
[22:30:38.170] iteration 7953 : model1 loss : 0.194972 model2 loss : 0.179328
[22:30:38.508] iteration 7954 : model1 loss : 0.322106 model2 loss : 0.309314
[22:30:38.847] iteration 7955 : model1 loss : 0.180283 model2 loss : 0.184562
[22:30:39.186] iteration 7956 : model1 loss : 0.200953 model2 loss : 0.218815
[22:30:39.526] iteration 7957 : model1 loss : 0.156797 model2 loss : 0.248417
[22:30:39.867] iteration 7958 : model1 loss : 0.245520 model2 loss : 0.267056
[22:30:40.205] iteration 7959 : model1 loss : 0.221245 model2 loss : 0.244833
[22:30:40.545] iteration 7960 : model1 loss : 0.321175 model2 loss : 0.281913
[22:30:40.892] iteration 7961 : model1 loss : 0.195068 model2 loss : 0.222465
[22:30:41.229] iteration 7962 : model1 loss : 0.233352 model2 loss : 0.210363
[22:30:41.571] iteration 7963 : model1 loss : 0.203520 model2 loss : 0.204388
[22:30:41.917] iteration 7964 : model1 loss : 0.189646 model2 loss : 0.203258
[22:30:42.257] iteration 7965 : model1 loss : 0.270786 model2 loss : 0.215719
[22:30:42.595] iteration 7966 : model1 loss : 0.200406 model2 loss : 0.245583
[22:30:42.937] iteration 7967 : model1 loss : 0.240079 model2 loss : 0.275636
[22:30:43.281] iteration 7968 : model1 loss : 0.253287 model2 loss : 0.251627
[22:30:43.619] iteration 7969 : model1 loss : 0.221551 model2 loss : 0.241693
[22:30:43.957] iteration 7970 : model1 loss : 0.323393 model2 loss : 0.331660
[22:30:44.300] iteration 7971 : model1 loss : 0.301560 model2 loss : 0.337452
[22:30:44.638] iteration 7972 : model1 loss : 0.253814 model2 loss : 0.291205
[22:30:44.976] iteration 7973 : model1 loss : 0.243093 model2 loss : 0.276003
[22:30:45.315] iteration 7974 : model1 loss : 0.302993 model2 loss : 0.367535
[22:30:45.659] iteration 7975 : model1 loss : 0.194801 model2 loss : 0.202747
[22:30:46.003] iteration 7976 : model1 loss : 0.197065 model2 loss : 0.251823
[22:30:46.345] iteration 7977 : model1 loss : 0.418608 model2 loss : 0.447286
[22:30:46.684] iteration 7978 : model1 loss : 0.258701 model2 loss : 0.322989
[22:30:47.025] iteration 7979 : model1 loss : 0.203521 model2 loss : 0.299062
[22:30:47.367] iteration 7980 : model1 loss : 0.302369 model2 loss : 0.303346
[22:30:47.708] iteration 7981 : model1 loss : 0.307864 model2 loss : 0.316336
[22:30:48.049] iteration 7982 : model1 loss : 0.111952 model2 loss : 0.129240
[22:30:48.388] iteration 7983 : model1 loss : 0.246350 model2 loss : 0.246014
[22:30:48.733] iteration 7984 : model1 loss : 0.220331 model2 loss : 0.280530
[22:30:49.076] iteration 7985 : model1 loss : 0.228208 model2 loss : 0.215888
[22:30:49.419] iteration 7986 : model1 loss : 0.227915 model2 loss : 0.261977
[22:30:49.762] iteration 7987 : model1 loss : 0.296265 model2 loss : 0.333724
[22:30:50.110] iteration 7988 : model1 loss : 0.275789 model2 loss : 0.265424
[22:30:50.450] iteration 7989 : model1 loss : 0.376872 model2 loss : 0.377160
[22:30:50.793] iteration 7990 : model1 loss : 0.288424 model2 loss : 0.324657
[22:30:51.138] iteration 7991 : model1 loss : 0.255469 model2 loss : 0.220437
[22:30:51.478] iteration 7992 : model1 loss : 0.247864 model2 loss : 0.246805
[22:30:51.821] iteration 7993 : model1 loss : 0.242937 model2 loss : 0.185115
[22:30:52.158] iteration 7994 : model1 loss : 0.267826 model2 loss : 0.255748
[22:30:52.497] iteration 7995 : model1 loss : 0.335668 model2 loss : 0.369617
[22:30:52.835] iteration 7996 : model1 loss : 0.360550 model2 loss : 0.309892
[22:30:53.182] iteration 7997 : model1 loss : 0.360186 model2 loss : 0.347075
[22:30:53.521] iteration 7998 : model1 loss : 0.296919 model2 loss : 0.304897
[22:30:53.864] iteration 7999 : model1 loss : 0.175448 model2 loss : 0.246982
[22:30:54.203] iteration 8000 : model1 loss : 0.201199 model2 loss : 0.224239
[22:30:54.882] iteration 8001 : model1 loss : 0.277886 model2 loss : 0.243708
[22:30:55.218] iteration 8002 : model1 loss : 0.292587 model2 loss : 0.304466
[22:30:55.557] iteration 8003 : model1 loss : 0.185343 model2 loss : 0.205346
[22:30:55.895] iteration 8004 : model1 loss : 0.206835 model2 loss : 0.225149
[22:30:56.233] iteration 8005 : model1 loss : 0.215214 model2 loss : 0.238953
[22:30:56.570] iteration 8006 : model1 loss : 0.272332 model2 loss : 0.310346
[22:30:56.908] iteration 8007 : model1 loss : 0.266533 model2 loss : 0.281198
[22:30:57.248] iteration 8008 : model1 loss : 0.272404 model2 loss : 0.293513
[22:30:57.587] iteration 8009 : model1 loss : 0.261798 model2 loss : 0.238006
[22:30:57.924] iteration 8010 : model1 loss : 0.214368 model2 loss : 0.227770
[22:30:58.261] iteration 8011 : model1 loss : 0.251956 model2 loss : 0.279881
[22:30:58.602] iteration 8012 : model1 loss : 0.270680 model2 loss : 0.292453
[22:30:58.940] iteration 8013 : model1 loss : 0.247921 model2 loss : 0.241326
[22:30:59.277] iteration 8014 : model1 loss : 0.276382 model2 loss : 0.232487
[22:30:59.616] iteration 8015 : model1 loss : 0.274719 model2 loss : 0.281967
[22:30:59.952] iteration 8016 : model1 loss : 0.205949 model2 loss : 0.299211
[22:31:00.290] iteration 8017 : model1 loss : 0.319483 model2 loss : 0.295629
[22:31:00.626] iteration 8018 : model1 loss : 0.175397 model2 loss : 0.182097
[22:31:00.962] iteration 8019 : model1 loss : 0.268600 model2 loss : 0.258076
[22:31:01.304] iteration 8020 : model1 loss : 0.223594 model2 loss : 0.243046
[22:31:01.644] iteration 8021 : model1 loss : 0.191074 model2 loss : 0.224577
[22:31:01.980] iteration 8022 : model1 loss : 0.214812 model2 loss : 0.231567
[22:31:02.317] iteration 8023 : model1 loss : 0.224108 model2 loss : 0.158694
[22:31:02.653] iteration 8024 : model1 loss : 0.281650 model2 loss : 0.286360
[22:31:02.990] iteration 8025 : model1 loss : 0.259291 model2 loss : 0.169594
[22:31:03.326] iteration 8026 : model1 loss : 0.283290 model2 loss : 0.303242
[22:31:03.662] iteration 8027 : model1 loss : 0.307398 model2 loss : 0.270586
[22:31:03.994] iteration 8028 : model1 loss : 0.310369 model2 loss : 0.276679
[22:31:04.322] iteration 8029 : model1 loss : 0.184336 model2 loss : 0.203705
[22:31:04.648] iteration 8030 : model1 loss : 0.205448 model2 loss : 0.226092
[22:31:04.977] iteration 8031 : model1 loss : 0.199580 model2 loss : 0.253706
[22:31:05.305] iteration 8032 : model1 loss : 0.360999 model2 loss : 0.323112
[22:31:05.631] iteration 8033 : model1 loss : 0.173992 model2 loss : 0.182497
[22:31:05.958] iteration 8034 : model1 loss : 0.253148 model2 loss : 0.264893
[22:31:06.286] iteration 8035 : model1 loss : 0.227330 model2 loss : 0.214617
[22:31:06.614] iteration 8036 : model1 loss : 0.401692 model2 loss : 0.420910
[22:31:06.941] iteration 8037 : model1 loss : 0.160920 model2 loss : 0.301498
[22:31:07.267] iteration 8038 : model1 loss : 0.249320 model2 loss : 0.203500
[22:31:07.594] iteration 8039 : model1 loss : 0.172632 model2 loss : 0.183195
[22:31:07.921] iteration 8040 : model1 loss : 0.204678 model2 loss : 0.274090
[22:31:08.248] iteration 8041 : model1 loss : 0.313648 model2 loss : 0.308843
[22:31:08.575] iteration 8042 : model1 loss : 0.152827 model2 loss : 0.200090
[22:31:08.903] iteration 8043 : model1 loss : 0.200061 model2 loss : 0.252619
[22:31:09.230] iteration 8044 : model1 loss : 0.311688 model2 loss : 0.338903
[22:31:09.557] iteration 8045 : model1 loss : 0.271203 model2 loss : 0.302914
[22:31:09.884] iteration 8046 : model1 loss : 0.338624 model2 loss : 0.381222
[22:31:10.212] iteration 8047 : model1 loss : 0.333313 model2 loss : 0.384660
[22:31:10.539] iteration 8048 : model1 loss : 0.293046 model2 loss : 0.305021
[22:31:10.866] iteration 8049 : model1 loss : 0.344076 model2 loss : 0.348012
[22:31:11.193] iteration 8050 : model1 loss : 0.299462 model2 loss : 0.403773
[22:31:11.745] iteration 8051 : model1 loss : 0.152615 model2 loss : 0.125036
[22:31:12.073] iteration 8052 : model1 loss : 0.345583 model2 loss : 0.411369
[22:31:12.400] iteration 8053 : model1 loss : 0.223429 model2 loss : 0.243323
[22:31:12.727] iteration 8054 : model1 loss : 0.306965 model2 loss : 0.359578
[22:31:13.054] iteration 8055 : model1 loss : 0.310688 model2 loss : 0.394057
[22:31:13.381] iteration 8056 : model1 loss : 0.292765 model2 loss : 0.271693
[22:31:13.715] iteration 8057 : model1 loss : 0.313390 model2 loss : 0.355459
[22:31:14.043] iteration 8058 : model1 loss : 0.286706 model2 loss : 0.291810
[22:31:14.371] iteration 8059 : model1 loss : 0.296678 model2 loss : 0.215782
[22:31:14.698] iteration 8060 : model1 loss : 0.295734 model2 loss : 0.330886
[22:31:15.026] iteration 8061 : model1 loss : 0.263333 model2 loss : 0.226703
[22:31:15.354] iteration 8062 : model1 loss : 0.279138 model2 loss : 0.238601
[22:31:15.682] iteration 8063 : model1 loss : 0.292106 model2 loss : 0.271182
[22:31:16.009] iteration 8064 : model1 loss : 0.255620 model2 loss : 0.272195
[22:31:16.341] iteration 8065 : model1 loss : 0.102936 model2 loss : 0.171719
[22:31:16.670] iteration 8066 : model1 loss : 0.169444 model2 loss : 0.190660
[22:31:16.998] iteration 8067 : model1 loss : 0.203582 model2 loss : 0.208159
[22:31:17.325] iteration 8068 : model1 loss : 0.208243 model2 loss : 0.249227
[22:31:17.653] iteration 8069 : model1 loss : 0.123149 model2 loss : 0.195008
[22:31:17.981] iteration 8070 : model1 loss : 0.248619 model2 loss : 0.247714
[22:31:18.309] iteration 8071 : model1 loss : 0.284802 model2 loss : 0.311494
[22:31:18.637] iteration 8072 : model1 loss : 0.232211 model2 loss : 0.287325
[22:31:18.965] iteration 8073 : model1 loss : 0.228269 model2 loss : 0.230858
[22:31:19.293] iteration 8074 : model1 loss : 0.274096 model2 loss : 0.273675
[22:31:19.620] iteration 8075 : model1 loss : 0.315501 model2 loss : 0.297672
[22:31:19.957] iteration 8076 : model1 loss : 0.255163 model2 loss : 0.247424
[22:31:20.286] iteration 8077 : model1 loss : 0.261738 model2 loss : 0.265283
[22:31:20.615] iteration 8078 : model1 loss : 0.301566 model2 loss : 0.348221
[22:31:20.942] iteration 8079 : model1 loss : 0.288932 model2 loss : 0.277998
[22:31:21.270] iteration 8080 : model1 loss : 0.094218 model2 loss : 0.132374
[22:31:21.598] iteration 8081 : model1 loss : 0.247191 model2 loss : 0.246673
[22:31:21.926] iteration 8082 : model1 loss : 0.329095 model2 loss : 0.258462
[22:31:22.253] iteration 8083 : model1 loss : 0.269221 model2 loss : 0.256068
[22:31:22.581] iteration 8084 : model1 loss : 0.291778 model2 loss : 0.310661
[22:31:22.909] iteration 8085 : model1 loss : 0.185525 model2 loss : 0.178157
[22:31:23.238] iteration 8086 : model1 loss : 0.186687 model2 loss : 0.219162
[22:31:23.576] iteration 8087 : model1 loss : 0.354365 model2 loss : 0.401167
[22:31:23.904] iteration 8088 : model1 loss : 0.252826 model2 loss : 0.250817
[22:31:24.232] iteration 8089 : model1 loss : 0.256206 model2 loss : 0.276174
[22:31:24.560] iteration 8090 : model1 loss : 0.242370 model2 loss : 0.224717
[22:31:24.888] iteration 8091 : model1 loss : 0.286311 model2 loss : 0.311081
[22:31:25.225] iteration 8092 : model1 loss : 0.271018 model2 loss : 0.279903
[22:31:25.553] iteration 8093 : model1 loss : 0.201833 model2 loss : 0.229600
[22:31:25.880] iteration 8094 : model1 loss : 0.190908 model2 loss : 0.253213
[22:31:26.208] iteration 8095 : model1 loss : 0.343320 model2 loss : 0.337027
[22:31:26.536] iteration 8096 : model1 loss : 0.257222 model2 loss : 0.253492
[22:31:26.863] iteration 8097 : model1 loss : 0.175047 model2 loss : 0.165443
[22:31:27.190] iteration 8098 : model1 loss : 0.230964 model2 loss : 0.253303
[22:31:27.517] iteration 8099 : model1 loss : 0.275573 model2 loss : 0.298922
[22:31:27.844] iteration 8100 : model1 loss : 0.251345 model2 loss : 0.305454
[22:31:28.406] iteration 8101 : model1 loss : 0.282132 model2 loss : 0.283390
[22:31:28.733] iteration 8102 : model1 loss : 0.214511 model2 loss : 0.280916
[22:31:29.061] iteration 8103 : model1 loss : 0.192319 model2 loss : 0.243172
[22:31:29.389] iteration 8104 : model1 loss : 0.302979 model2 loss : 0.312130
[22:31:29.716] iteration 8105 : model1 loss : 0.226726 model2 loss : 0.232632
[22:31:30.044] iteration 8106 : model1 loss : 0.346607 model2 loss : 0.306540
[22:31:30.372] iteration 8107 : model1 loss : 0.137329 model2 loss : 0.203307
[22:31:30.700] iteration 8108 : model1 loss : 0.232790 model2 loss : 0.268893
[22:31:31.027] iteration 8109 : model1 loss : 0.263161 model2 loss : 0.290119
[22:31:31.356] iteration 8110 : model1 loss : 0.216732 model2 loss : 0.231348
[22:31:31.683] iteration 8111 : model1 loss : 0.244720 model2 loss : 0.201796
[22:31:32.010] iteration 8112 : model1 loss : 0.303023 model2 loss : 0.304608
[22:31:32.337] iteration 8113 : model1 loss : 0.281069 model2 loss : 0.286111
[22:31:32.664] iteration 8114 : model1 loss : 0.183679 model2 loss : 0.189277
[22:31:32.992] iteration 8115 : model1 loss : 0.268035 model2 loss : 0.232259
[22:31:33.319] iteration 8116 : model1 loss : 0.189632 model2 loss : 0.183140
[22:31:33.646] iteration 8117 : model1 loss : 0.328395 model2 loss : 0.335877
[22:31:33.974] iteration 8118 : model1 loss : 0.279590 model2 loss : 0.274699
[22:31:34.301] iteration 8119 : model1 loss : 0.259970 model2 loss : 0.179858
[22:31:34.628] iteration 8120 : model1 loss : 0.153267 model2 loss : 0.124151
[22:31:34.955] iteration 8121 : model1 loss : 0.163830 model2 loss : 0.253936
[22:31:35.282] iteration 8122 : model1 loss : 0.255334 model2 loss : 0.246398
[22:31:35.609] iteration 8123 : model1 loss : 0.310019 model2 loss : 0.262674
[22:31:35.935] iteration 8124 : model1 loss : 0.209258 model2 loss : 0.192532
[22:31:36.262] iteration 8125 : model1 loss : 0.255235 model2 loss : 0.253362
[22:31:36.588] iteration 8126 : model1 loss : 0.220854 model2 loss : 0.220610
[22:31:36.914] iteration 8127 : model1 loss : 0.208274 model2 loss : 0.211894
[22:31:37.240] iteration 8128 : model1 loss : 0.235574 model2 loss : 0.217147
[22:31:37.565] iteration 8129 : model1 loss : 0.178168 model2 loss : 0.201778
[22:31:37.890] iteration 8130 : model1 loss : 0.313524 model2 loss : 0.291342
[22:31:38.217] iteration 8131 : model1 loss : 0.158587 model2 loss : 0.190079
[22:31:38.542] iteration 8132 : model1 loss : 0.209894 model2 loss : 0.244268
[22:31:38.868] iteration 8133 : model1 loss : 0.329450 model2 loss : 0.395375
[22:31:39.194] iteration 8134 : model1 loss : 0.432712 model2 loss : 0.441440
[22:31:39.520] iteration 8135 : model1 loss : 0.253894 model2 loss : 0.267307
[22:31:39.846] iteration 8136 : model1 loss : 0.117030 model2 loss : 0.186129
[22:31:40.172] iteration 8137 : model1 loss : 0.242140 model2 loss : 0.255024
[22:31:40.498] iteration 8138 : model1 loss : 0.103358 model2 loss : 0.139112
[22:31:40.824] iteration 8139 : model1 loss : 0.136733 model2 loss : 0.233379
[22:31:41.149] iteration 8140 : model1 loss : 0.284342 model2 loss : 0.337375
[22:31:41.475] iteration 8141 : model1 loss : 0.400239 model2 loss : 0.409449
[22:31:41.801] iteration 8142 : model1 loss : 0.365823 model2 loss : 0.395509
[22:31:42.127] iteration 8143 : model1 loss : 0.241700 model2 loss : 0.249540
[22:31:42.454] iteration 8144 : model1 loss : 0.330036 model2 loss : 0.271380
[22:31:42.780] iteration 8145 : model1 loss : 0.310898 model2 loss : 0.338722
[22:31:43.105] iteration 8146 : model1 loss : 0.189417 model2 loss : 0.221162
[22:31:43.432] iteration 8147 : model1 loss : 0.319679 model2 loss : 0.269398
[22:31:43.758] iteration 8148 : model1 loss : 0.351339 model2 loss : 0.347448
[22:31:44.083] iteration 8149 : model1 loss : 0.126709 model2 loss : 0.185020
[22:31:44.410] iteration 8150 : model1 loss : 0.125751 model2 loss : 0.183428
[22:31:44.967] iteration 8151 : model1 loss : 0.319493 model2 loss : 0.322899
[22:31:45.293] iteration 8152 : model1 loss : 0.289618 model2 loss : 0.321697
[22:31:45.619] iteration 8153 : model1 loss : 0.268022 model2 loss : 0.236233
[22:31:45.946] iteration 8154 : model1 loss : 0.359225 model2 loss : 0.297243
[22:31:46.276] iteration 8155 : model1 loss : 0.325994 model2 loss : 0.285715
[22:31:46.602] iteration 8156 : model1 loss : 0.208997 model2 loss : 0.250235
[22:31:46.928] iteration 8157 : model1 loss : 0.314634 model2 loss : 0.303380
[22:31:47.253] iteration 8158 : model1 loss : 0.203467 model2 loss : 0.280152
[22:31:47.578] iteration 8159 : model1 loss : 0.262565 model2 loss : 0.210439
[22:31:47.904] iteration 8160 : model1 loss : 0.231633 model2 loss : 0.208110
[22:31:48.229] iteration 8161 : model1 loss : 0.291824 model2 loss : 0.258782
[22:31:48.555] iteration 8162 : model1 loss : 0.288214 model2 loss : 0.277156
[22:31:48.882] iteration 8163 : model1 loss : 0.203127 model2 loss : 0.226547
[22:31:49.207] iteration 8164 : model1 loss : 0.283147 model2 loss : 0.277040
[22:31:49.533] iteration 8165 : model1 loss : 0.173454 model2 loss : 0.274342
[22:31:49.859] iteration 8166 : model1 loss : 0.163229 model2 loss : 0.182370
[22:31:50.185] iteration 8167 : model1 loss : 0.295871 model2 loss : 0.329464
[22:31:50.511] iteration 8168 : model1 loss : 0.238862 model2 loss : 0.244919
[22:31:50.836] iteration 8169 : model1 loss : 0.249435 model2 loss : 0.322050
[22:31:51.160] iteration 8170 : model1 loss : 0.205017 model2 loss : 0.215745
[22:31:51.489] iteration 8171 : model1 loss : 0.203253 model2 loss : 0.231595
[22:31:51.818] iteration 8172 : model1 loss : 0.298085 model2 loss : 0.271023
[22:31:52.143] iteration 8173 : model1 loss : 0.192377 model2 loss : 0.188191
[22:31:52.467] iteration 8174 : model1 loss : 0.225532 model2 loss : 0.147591
[22:31:52.792] iteration 8175 : model1 loss : 0.182708 model2 loss : 0.236522
[22:31:53.838] iteration 8176 : model1 loss : 0.225485 model2 loss : 0.185054
[22:31:54.165] iteration 8177 : model1 loss : 0.308617 model2 loss : 0.298862
[22:31:54.492] iteration 8178 : model1 loss : 0.238477 model2 loss : 0.252176
[22:31:54.820] iteration 8179 : model1 loss : 0.283626 model2 loss : 0.250253
[22:31:55.148] iteration 8180 : model1 loss : 0.324609 model2 loss : 0.337211
[22:31:55.477] iteration 8181 : model1 loss : 0.214586 model2 loss : 0.235864
[22:31:55.805] iteration 8182 : model1 loss : 0.275932 model2 loss : 0.284968
[22:31:56.133] iteration 8183 : model1 loss : 0.172638 model2 loss : 0.209678
[22:31:56.460] iteration 8184 : model1 loss : 0.385991 model2 loss : 0.266404
[22:31:56.789] iteration 8185 : model1 loss : 0.225201 model2 loss : 0.244599
[22:31:57.116] iteration 8186 : model1 loss : 0.222869 model2 loss : 0.260599
[22:31:57.446] iteration 8187 : model1 loss : 0.200370 model2 loss : 0.235856
[22:31:57.773] iteration 8188 : model1 loss : 0.186384 model2 loss : 0.275691
[22:31:58.100] iteration 8189 : model1 loss : 0.270766 model2 loss : 0.293715
[22:31:58.426] iteration 8190 : model1 loss : 0.204540 model2 loss : 0.238787
[22:31:58.754] iteration 8191 : model1 loss : 0.299167 model2 loss : 0.310679
[22:31:59.082] iteration 8192 : model1 loss : 0.233699 model2 loss : 0.217673
[22:31:59.410] iteration 8193 : model1 loss : 0.268604 model2 loss : 0.350308
[22:31:59.736] iteration 8194 : model1 loss : 0.290697 model2 loss : 0.222508
[22:32:00.064] iteration 8195 : model1 loss : 0.263864 model2 loss : 0.250098
[22:32:00.392] iteration 8196 : model1 loss : 0.335515 model2 loss : 0.331349
[22:32:00.719] iteration 8197 : model1 loss : 0.252692 model2 loss : 0.316603
[22:32:01.046] iteration 8198 : model1 loss : 0.211500 model2 loss : 0.248770
[22:32:01.374] iteration 8199 : model1 loss : 0.303899 model2 loss : 0.281883
[22:32:01.701] iteration 8200 : model1 loss : 0.124892 model2 loss : 0.127151
[22:32:02.261] iteration 8201 : model1 loss : 0.175489 model2 loss : 0.185111
[22:32:02.592] iteration 8202 : model1 loss : 0.348546 model2 loss : 0.309043
[22:32:02.923] iteration 8203 : model1 loss : 0.248123 model2 loss : 0.251548
[22:32:03.250] iteration 8204 : model1 loss : 0.235205 model2 loss : 0.251084
[22:32:03.580] iteration 8205 : model1 loss : 0.243989 model2 loss : 0.285890
[22:32:03.907] iteration 8206 : model1 loss : 0.296434 model2 loss : 0.285830
[22:32:04.235] iteration 8207 : model1 loss : 0.207730 model2 loss : 0.217570
[22:32:04.562] iteration 8208 : model1 loss : 0.224018 model2 loss : 0.330640
[22:32:04.889] iteration 8209 : model1 loss : 0.222247 model2 loss : 0.273518
[22:32:05.218] iteration 8210 : model1 loss : 0.275406 model2 loss : 0.275095
[22:32:05.546] iteration 8211 : model1 loss : 0.316913 model2 loss : 0.276908
[22:32:05.877] iteration 8212 : model1 loss : 0.203878 model2 loss : 0.253937
[22:32:06.205] iteration 8213 : model1 loss : 0.289211 model2 loss : 0.288679
[22:32:06.534] iteration 8214 : model1 loss : 0.305036 model2 loss : 0.307767
[22:32:06.862] iteration 8215 : model1 loss : 0.310183 model2 loss : 0.316234
[22:32:07.188] iteration 8216 : model1 loss : 0.262375 model2 loss : 0.259676
[22:32:07.521] iteration 8217 : model1 loss : 0.168044 model2 loss : 0.184682
[22:32:07.848] iteration 8218 : model1 loss : 0.312118 model2 loss : 0.364143
[22:32:08.177] iteration 8219 : model1 loss : 0.231541 model2 loss : 0.262228
[22:32:08.506] iteration 8220 : model1 loss : 0.249478 model2 loss : 0.272531
[22:32:08.832] iteration 8221 : model1 loss : 0.300813 model2 loss : 0.298726
[22:32:09.159] iteration 8222 : model1 loss : 0.156876 model2 loss : 0.216227
[22:32:09.485] iteration 8223 : model1 loss : 0.319858 model2 loss : 0.266004
[22:32:09.811] iteration 8224 : model1 loss : 0.222254 model2 loss : 0.234900
[22:32:10.139] iteration 8225 : model1 loss : 0.217849 model2 loss : 0.193624
[22:32:10.466] iteration 8226 : model1 loss : 0.361564 model2 loss : 0.382445
[22:32:10.792] iteration 8227 : model1 loss : 0.226407 model2 loss : 0.319282
[22:32:11.117] iteration 8228 : model1 loss : 0.163835 model2 loss : 0.162825
[22:32:11.444] iteration 8229 : model1 loss : 0.192950 model2 loss : 0.239920
[22:32:11.770] iteration 8230 : model1 loss : 0.283560 model2 loss : 0.293612
[22:32:12.095] iteration 8231 : model1 loss : 0.150482 model2 loss : 0.214375
[22:32:12.422] iteration 8232 : model1 loss : 0.285071 model2 loss : 0.317242
[22:32:12.747] iteration 8233 : model1 loss : 0.174116 model2 loss : 0.195794
[22:32:13.072] iteration 8234 : model1 loss : 0.238829 model2 loss : 0.218834
[22:32:13.398] iteration 8235 : model1 loss : 0.141839 model2 loss : 0.162202
[22:32:13.724] iteration 8236 : model1 loss : 0.215024 model2 loss : 0.194483
[22:32:14.050] iteration 8237 : model1 loss : 0.280905 model2 loss : 0.270727
[22:32:14.375] iteration 8238 : model1 loss : 0.190460 model2 loss : 0.215813
[22:32:14.700] iteration 8239 : model1 loss : 0.309088 model2 loss : 0.313653
[22:32:15.027] iteration 8240 : model1 loss : 0.187538 model2 loss : 0.228905
[22:32:15.353] iteration 8241 : model1 loss : 0.227725 model2 loss : 0.241768
[22:32:15.679] iteration 8242 : model1 loss : 0.113273 model2 loss : 0.178691
[22:32:16.004] iteration 8243 : model1 loss : 0.148817 model2 loss : 0.211486
[22:32:16.330] iteration 8244 : model1 loss : 0.222320 model2 loss : 0.269309
[22:32:16.656] iteration 8245 : model1 loss : 0.393841 model2 loss : 0.489569
[22:32:16.981] iteration 8246 : model1 loss : 0.260742 model2 loss : 0.255234
[22:32:17.307] iteration 8247 : model1 loss : 0.288550 model2 loss : 0.325500
[22:32:17.632] iteration 8248 : model1 loss : 0.305174 model2 loss : 0.275871
[22:32:17.958] iteration 8249 : model1 loss : 0.299262 model2 loss : 0.353922
[22:32:18.284] iteration 8250 : model1 loss : 0.128280 model2 loss : 0.118752
[22:32:18.800] iteration 8251 : model1 loss : 0.255157 model2 loss : 0.254329
[22:32:19.126] iteration 8252 : model1 loss : 0.139992 model2 loss : 0.144775
[22:32:19.452] iteration 8253 : model1 loss : 0.237217 model2 loss : 0.199327
[22:32:19.778] iteration 8254 : model1 loss : 0.262939 model2 loss : 0.213114
[22:32:20.104] iteration 8255 : model1 loss : 0.246386 model2 loss : 0.230012
[22:32:20.430] iteration 8256 : model1 loss : 0.165265 model2 loss : 0.175642
[22:32:20.759] iteration 8257 : model1 loss : 0.215507 model2 loss : 0.228806
[22:32:21.085] iteration 8258 : model1 loss : 0.151765 model2 loss : 0.154133
[22:32:21.411] iteration 8259 : model1 loss : 0.213420 model2 loss : 0.221119
[22:32:21.736] iteration 8260 : model1 loss : 0.171076 model2 loss : 0.235698
[22:32:22.063] iteration 8261 : model1 loss : 0.294769 model2 loss : 0.322187
[22:32:22.390] iteration 8262 : model1 loss : 0.222263 model2 loss : 0.247124
[22:32:22.716] iteration 8263 : model1 loss : 0.209492 model2 loss : 0.170005
[22:32:23.041] iteration 8264 : model1 loss : 0.245344 model2 loss : 0.218328
[22:32:23.367] iteration 8265 : model1 loss : 0.281853 model2 loss : 0.332702
[22:32:23.694] iteration 8266 : model1 loss : 0.285766 model2 loss : 0.330399
[22:32:24.019] iteration 8267 : model1 loss : 0.253579 model2 loss : 0.243033
[22:32:24.345] iteration 8268 : model1 loss : 0.349828 model2 loss : 0.309828
[22:32:24.671] iteration 8269 : model1 loss : 0.234710 model2 loss : 0.271427
[22:32:24.997] iteration 8270 : model1 loss : 0.231897 model2 loss : 0.192330
[22:32:25.324] iteration 8271 : model1 loss : 0.288144 model2 loss : 0.297675
[22:32:25.650] iteration 8272 : model1 loss : 0.267830 model2 loss : 0.252254
[22:32:25.976] iteration 8273 : model1 loss : 0.315919 model2 loss : 0.321143
[22:32:26.302] iteration 8274 : model1 loss : 0.253900 model2 loss : 0.366029
[22:32:26.628] iteration 8275 : model1 loss : 0.339693 model2 loss : 0.251498
[22:32:26.953] iteration 8276 : model1 loss : 0.278675 model2 loss : 0.279150
[22:32:27.278] iteration 8277 : model1 loss : 0.201777 model2 loss : 0.197076
[22:32:27.604] iteration 8278 : model1 loss : 0.321535 model2 loss : 0.313676
[22:32:27.934] iteration 8279 : model1 loss : 0.273342 model2 loss : 0.312628
[22:32:28.260] iteration 8280 : model1 loss : 0.190566 model2 loss : 0.258404
[22:32:28.587] iteration 8281 : model1 loss : 0.281421 model2 loss : 0.330670
[22:32:28.919] iteration 8282 : model1 loss : 0.174643 model2 loss : 0.187850
[22:32:29.245] iteration 8283 : model1 loss : 0.250131 model2 loss : 0.221767
[22:32:29.574] iteration 8284 : model1 loss : 0.205492 model2 loss : 0.205134
[22:32:29.900] iteration 8285 : model1 loss : 0.251823 model2 loss : 0.233127
[22:32:30.229] iteration 8286 : model1 loss : 0.210547 model2 loss : 0.296240
[22:32:30.557] iteration 8287 : model1 loss : 0.265413 model2 loss : 0.287130
[22:32:30.883] iteration 8288 : model1 loss : 0.304890 model2 loss : 0.282139
[22:32:31.209] iteration 8289 : model1 loss : 0.362371 model2 loss : 0.326274
[22:32:31.535] iteration 8290 : model1 loss : 0.143223 model2 loss : 0.169878
[22:32:31.865] iteration 8291 : model1 loss : 0.281005 model2 loss : 0.272660
[22:32:32.191] iteration 8292 : model1 loss : 0.268506 model2 loss : 0.263461
[22:32:32.519] iteration 8293 : model1 loss : 0.246114 model2 loss : 0.302686
[22:32:32.845] iteration 8294 : model1 loss : 0.319825 model2 loss : 0.338342
[22:32:33.171] iteration 8295 : model1 loss : 0.198185 model2 loss : 0.272549
[22:32:33.497] iteration 8296 : model1 loss : 0.209035 model2 loss : 0.339731
[22:32:33.824] iteration 8297 : model1 loss : 0.239279 model2 loss : 0.251830
[22:32:34.149] iteration 8298 : model1 loss : 0.185188 model2 loss : 0.244497
[22:32:34.474] iteration 8299 : model1 loss : 0.343835 model2 loss : 0.326835
[22:32:34.800] iteration 8300 : model1 loss : 0.268387 model2 loss : 0.251844
[22:32:35.368] iteration 8301 : model1 loss : 0.267077 model2 loss : 0.283940
[22:32:35.693] iteration 8302 : model1 loss : 0.301881 model2 loss : 0.209628
[22:32:36.021] iteration 8303 : model1 loss : 0.191520 model2 loss : 0.136977
[22:32:36.347] iteration 8304 : model1 loss : 0.189848 model2 loss : 0.215794
[22:32:36.672] iteration 8305 : model1 loss : 0.274565 model2 loss : 0.296145
[22:32:36.998] iteration 8306 : model1 loss : 0.279122 model2 loss : 0.273552
[22:32:37.324] iteration 8307 : model1 loss : 0.240956 model2 loss : 0.315209
[22:32:37.650] iteration 8308 : model1 loss : 0.202048 model2 loss : 0.203288
[22:32:37.975] iteration 8309 : model1 loss : 0.189663 model2 loss : 0.204524
[22:32:38.301] iteration 8310 : model1 loss : 0.246013 model2 loss : 0.236916
[22:32:38.627] iteration 8311 : model1 loss : 0.282859 model2 loss : 0.340278
[22:32:38.957] iteration 8312 : model1 loss : 0.228045 model2 loss : 0.223687
[22:32:39.283] iteration 8313 : model1 loss : 0.191832 model2 loss : 0.192630
[22:32:39.609] iteration 8314 : model1 loss : 0.247403 model2 loss : 0.229223
[22:32:39.934] iteration 8315 : model1 loss : 0.417993 model2 loss : 0.391709
[22:32:40.260] iteration 8316 : model1 loss : 0.321675 model2 loss : 0.349671
[22:32:40.586] iteration 8317 : model1 loss : 0.187020 model2 loss : 0.225237
[22:32:40.912] iteration 8318 : model1 loss : 0.268651 model2 loss : 0.276395
[22:32:41.238] iteration 8319 : model1 loss : 0.249992 model2 loss : 0.216419
[22:32:41.563] iteration 8320 : model1 loss : 0.260550 model2 loss : 0.162564
[22:32:41.889] iteration 8321 : model1 loss : 0.282297 model2 loss : 0.223561
[22:32:42.215] iteration 8322 : model1 loss : 0.205203 model2 loss : 0.205040
[22:32:42.541] iteration 8323 : model1 loss : 0.251347 model2 loss : 0.277624
[22:32:42.866] iteration 8324 : model1 loss : 0.112353 model2 loss : 0.090490
[22:32:43.191] iteration 8325 : model1 loss : 0.278539 model2 loss : 0.271346
[22:32:43.517] iteration 8326 : model1 loss : 0.202655 model2 loss : 0.255884
[22:32:43.843] iteration 8327 : model1 loss : 0.222299 model2 loss : 0.165631
[22:32:44.168] iteration 8328 : model1 loss : 0.144660 model2 loss : 0.160120
[22:32:44.494] iteration 8329 : model1 loss : 0.338761 model2 loss : 0.339394
[22:32:44.821] iteration 8330 : model1 loss : 0.259505 model2 loss : 0.278601
[22:32:45.147] iteration 8331 : model1 loss : 0.246219 model2 loss : 0.242465
[22:32:45.474] iteration 8332 : model1 loss : 0.288447 model2 loss : 0.271927
[22:32:45.799] iteration 8333 : model1 loss : 0.388886 model2 loss : 0.369452
[22:32:46.125] iteration 8334 : model1 loss : 0.329767 model2 loss : 0.343175
[22:32:46.450] iteration 8335 : model1 loss : 0.254495 model2 loss : 0.223453
[22:32:46.776] iteration 8336 : model1 loss : 0.296337 model2 loss : 0.296652
[22:32:47.101] iteration 8337 : model1 loss : 0.252818 model2 loss : 0.257784
[22:32:47.427] iteration 8338 : model1 loss : 0.189188 model2 loss : 0.232236
[22:32:47.753] iteration 8339 : model1 loss : 0.297857 model2 loss : 0.294874
[22:32:48.079] iteration 8340 : model1 loss : 0.249135 model2 loss : 0.263175
[22:32:48.407] iteration 8341 : model1 loss : 0.353071 model2 loss : 0.400310
[22:32:48.734] iteration 8342 : model1 loss : 0.206469 model2 loss : 0.183303
[22:32:49.063] iteration 8343 : model1 loss : 0.183040 model2 loss : 0.194376
[22:32:49.390] iteration 8344 : model1 loss : 0.403168 model2 loss : 0.416735
[22:32:49.716] iteration 8345 : model1 loss : 0.210490 model2 loss : 0.174180
[22:32:50.044] iteration 8346 : model1 loss : 0.269755 model2 loss : 0.209188
[22:32:50.371] iteration 8347 : model1 loss : 0.176629 model2 loss : 0.197178
[22:32:50.697] iteration 8348 : model1 loss : 0.226226 model2 loss : 0.297531
[22:32:51.023] iteration 8349 : model1 loss : 0.271393 model2 loss : 0.307572
[22:32:51.349] iteration 8350 : model1 loss : 0.249762 model2 loss : 0.224550
[22:32:51.883] iteration 8351 : model1 loss : 0.287490 model2 loss : 0.263123
[22:32:52.212] iteration 8352 : model1 loss : 0.326624 model2 loss : 0.259127
[22:32:52.537] iteration 8353 : model1 loss : 0.243088 model2 loss : 0.282353
[22:32:52.863] iteration 8354 : model1 loss : 0.191518 model2 loss : 0.199517
[22:32:53.189] iteration 8355 : model1 loss : 0.283394 model2 loss : 0.272217
[22:32:53.516] iteration 8356 : model1 loss : 0.366859 model2 loss : 0.327909
[22:32:53.842] iteration 8357 : model1 loss : 0.308925 model2 loss : 0.318647
[22:32:54.169] iteration 8358 : model1 loss : 0.183790 model2 loss : 0.192036
[22:32:54.495] iteration 8359 : model1 loss : 0.334017 model2 loss : 0.350534
[22:32:54.821] iteration 8360 : model1 loss : 0.303091 model2 loss : 0.309210
[22:32:55.148] iteration 8361 : model1 loss : 0.275341 model2 loss : 0.260817
[22:32:55.477] iteration 8362 : model1 loss : 0.151947 model2 loss : 0.226711
[22:32:55.812] iteration 8363 : model1 loss : 0.199901 model2 loss : 0.231236
[22:32:56.141] iteration 8364 : model1 loss : 0.245514 model2 loss : 0.274258
[22:32:56.477] iteration 8365 : model1 loss : 0.182215 model2 loss : 0.144709
[22:32:56.813] iteration 8366 : model1 loss : 0.280791 model2 loss : 0.276652
[22:32:57.150] iteration 8367 : model1 loss : 0.234602 model2 loss : 0.357918
[22:32:57.479] iteration 8368 : model1 loss : 0.325017 model2 loss : 0.398240
[22:32:57.818] iteration 8369 : model1 loss : 0.205114 model2 loss : 0.194421
[22:32:58.159] iteration 8370 : model1 loss : 0.191583 model2 loss : 0.269636
[22:32:58.496] iteration 8371 : model1 loss : 0.231432 model2 loss : 0.264301
[22:32:58.827] iteration 8372 : model1 loss : 0.219361 model2 loss : 0.274609
[22:32:59.163] iteration 8373 : model1 loss : 0.236658 model2 loss : 0.289494
[22:32:59.498] iteration 8374 : model1 loss : 0.316178 model2 loss : 0.317913
[22:32:59.834] iteration 8375 : model1 loss : 0.143811 model2 loss : 0.157212
[22:33:00.163] iteration 8376 : model1 loss : 0.279893 model2 loss : 0.304301
[22:33:00.501] iteration 8377 : model1 loss : 0.156852 model2 loss : 0.176502
[22:33:00.838] iteration 8378 : model1 loss : 0.220335 model2 loss : 0.200500
[22:33:01.176] iteration 8379 : model1 loss : 0.222223 model2 loss : 0.177775
[22:33:01.513] iteration 8380 : model1 loss : 0.133388 model2 loss : 0.148165
[22:33:01.849] iteration 8381 : model1 loss : 0.235149 model2 loss : 0.278784
[22:33:02.185] iteration 8382 : model1 loss : 0.237774 model2 loss : 0.266212
[22:33:02.523] iteration 8383 : model1 loss : 0.255514 model2 loss : 0.247551
[22:33:02.858] iteration 8384 : model1 loss : 0.171994 model2 loss : 0.164721
[22:33:03.194] iteration 8385 : model1 loss : 0.141562 model2 loss : 0.141764
[22:33:03.530] iteration 8386 : model1 loss : 0.292390 model2 loss : 0.284831
[22:33:03.866] iteration 8387 : model1 loss : 0.280100 model2 loss : 0.328832
[22:33:04.201] iteration 8388 : model1 loss : 0.207573 model2 loss : 0.214549
[22:33:04.536] iteration 8389 : model1 loss : 0.231092 model2 loss : 0.266473
[22:33:04.874] iteration 8390 : model1 loss : 0.220790 model2 loss : 0.199558
[22:33:05.210] iteration 8391 : model1 loss : 0.188694 model2 loss : 0.214936
[22:33:05.547] iteration 8392 : model1 loss : 0.203234 model2 loss : 0.156697
[22:33:05.883] iteration 8393 : model1 loss : 0.223224 model2 loss : 0.213401
[22:33:06.220] iteration 8394 : model1 loss : 0.230806 model2 loss : 0.242567
[22:33:06.556] iteration 8395 : model1 loss : 0.162733 model2 loss : 0.180028
[22:33:06.893] iteration 8396 : model1 loss : 0.209302 model2 loss : 0.159096
[22:33:07.230] iteration 8397 : model1 loss : 0.273981 model2 loss : 0.307550
[22:33:07.567] iteration 8398 : model1 loss : 0.242957 model2 loss : 0.197990
[22:33:07.903] iteration 8399 : model1 loss : 0.384254 model2 loss : 0.386645
[22:33:08.235] iteration 8400 : model1 loss : 0.235358 model2 loss : 0.197705
[22:33:08.880] iteration 8401 : model1 loss : 0.212221 model2 loss : 0.278150
[22:33:09.216] iteration 8402 : model1 loss : 0.204361 model2 loss : 0.260308
[22:33:09.553] iteration 8403 : model1 loss : 0.308737 model2 loss : 0.321788
[22:33:09.884] iteration 8404 : model1 loss : 0.246141 model2 loss : 0.421445
[22:33:10.220] iteration 8405 : model1 loss : 0.235567 model2 loss : 0.253642
[22:33:10.556] iteration 8406 : model1 loss : 0.312215 model2 loss : 0.281672
[22:33:10.894] iteration 8407 : model1 loss : 0.188963 model2 loss : 0.206705
[22:33:11.225] iteration 8408 : model1 loss : 0.256044 model2 loss : 0.368978
[22:33:11.562] iteration 8409 : model1 loss : 0.188533 model2 loss : 0.201853
[22:33:11.900] iteration 8410 : model1 loss : 0.318067 model2 loss : 0.301927
[22:33:12.229] iteration 8411 : model1 loss : 0.246581 model2 loss : 0.301670
[22:33:12.557] iteration 8412 : model1 loss : 0.249453 model2 loss : 0.314292
[22:33:12.885] iteration 8413 : model1 loss : 0.301579 model2 loss : 0.243080
[22:33:13.212] iteration 8414 : model1 loss : 0.149204 model2 loss : 0.199068
[22:33:13.540] iteration 8415 : model1 loss : 0.195574 model2 loss : 0.296531
[22:33:13.867] iteration 8416 : model1 loss : 0.193676 model2 loss : 0.210265
[22:33:14.194] iteration 8417 : model1 loss : 0.118216 model2 loss : 0.149752
[22:33:14.522] iteration 8418 : model1 loss : 0.342053 model2 loss : 0.368084
[22:33:14.849] iteration 8419 : model1 loss : 0.226866 model2 loss : 0.157865
[22:33:15.177] iteration 8420 : model1 loss : 0.330731 model2 loss : 0.309322
[22:33:15.505] iteration 8421 : model1 loss : 0.324262 model2 loss : 0.293563
[22:33:15.833] iteration 8422 : model1 loss : 0.295218 model2 loss : 0.297817
[22:33:16.169] iteration 8423 : model1 loss : 0.250405 model2 loss : 0.291444
[22:33:16.503] iteration 8424 : model1 loss : 0.281762 model2 loss : 0.296585
[22:33:16.839] iteration 8425 : model1 loss : 0.210957 model2 loss : 0.241166
[22:33:17.172] iteration 8426 : model1 loss : 0.279992 model2 loss : 0.292307
[22:33:17.509] iteration 8427 : model1 loss : 0.194329 model2 loss : 0.280500
[22:33:17.841] iteration 8428 : model1 loss : 0.190706 model2 loss : 0.237188
[22:33:18.178] iteration 8429 : model1 loss : 0.223346 model2 loss : 0.310233
[22:33:18.519] iteration 8430 : model1 loss : 0.273894 model2 loss : 0.320667
[22:33:18.855] iteration 8431 : model1 loss : 0.250942 model2 loss : 0.292773
[22:33:19.186] iteration 8432 : model1 loss : 0.318407 model2 loss : 0.306078
[22:33:19.522] iteration 8433 : model1 loss : 0.232377 model2 loss : 0.225823
[22:33:19.860] iteration 8434 : model1 loss : 0.228610 model2 loss : 0.274431
[22:33:20.196] iteration 8435 : model1 loss : 0.162880 model2 loss : 0.174733
[22:33:20.529] iteration 8436 : model1 loss : 0.200336 model2 loss : 0.283101
[22:33:20.866] iteration 8437 : model1 loss : 0.285189 model2 loss : 0.303580
[22:33:21.202] iteration 8438 : model1 loss : 0.305521 model2 loss : 0.228558
[22:33:21.538] iteration 8439 : model1 loss : 0.336842 model2 loss : 0.408754
[22:33:21.869] iteration 8440 : model1 loss : 0.217940 model2 loss : 0.237556
[22:33:22.205] iteration 8441 : model1 loss : 0.304204 model2 loss : 0.311023
[22:33:22.541] iteration 8442 : model1 loss : 0.383633 model2 loss : 0.361160
[22:33:22.879] iteration 8443 : model1 loss : 0.121398 model2 loss : 0.170615
[22:33:23.209] iteration 8444 : model1 loss : 0.266887 model2 loss : 0.224632
[22:33:23.542] iteration 8445 : model1 loss : 0.131083 model2 loss : 0.202485
[22:33:23.879] iteration 8446 : model1 loss : 0.229398 model2 loss : 0.293317
[22:33:24.215] iteration 8447 : model1 loss : 0.311450 model2 loss : 0.293243
[22:33:24.547] iteration 8448 : model1 loss : 0.254565 model2 loss : 0.232062
[22:33:24.883] iteration 8449 : model1 loss : 0.144543 model2 loss : 0.206985
[22:33:25.222] iteration 8450 : model1 loss : 0.267234 model2 loss : 0.253874
[22:33:25.853] iteration 8451 : model1 loss : 0.167248 model2 loss : 0.218390
[22:33:26.187] iteration 8452 : model1 loss : 0.275967 model2 loss : 0.271805
[22:33:26.527] iteration 8453 : model1 loss : 0.130114 model2 loss : 0.182435
[22:33:26.864] iteration 8454 : model1 loss : 0.204100 model2 loss : 0.194966
[22:33:27.201] iteration 8455 : model1 loss : 0.214573 model2 loss : 0.236803
[22:33:27.532] iteration 8456 : model1 loss : 0.162119 model2 loss : 0.204269
[22:33:27.867] iteration 8457 : model1 loss : 0.289006 model2 loss : 0.344555
[22:33:28.204] iteration 8458 : model1 loss : 0.320738 model2 loss : 0.330706
[22:33:28.542] iteration 8459 : model1 loss : 0.335240 model2 loss : 0.346387
[22:33:28.872] iteration 8460 : model1 loss : 0.248702 model2 loss : 0.180906
[22:33:29.208] iteration 8461 : model1 loss : 0.252460 model2 loss : 0.271080
[22:33:29.544] iteration 8462 : model1 loss : 0.289849 model2 loss : 0.300361
[22:33:29.880] iteration 8463 : model1 loss : 0.239694 model2 loss : 0.241914
[22:33:30.212] iteration 8464 : model1 loss : 0.219976 model2 loss : 0.200949
[22:33:30.548] iteration 8465 : model1 loss : 0.298999 model2 loss : 0.309012
[22:33:30.885] iteration 8466 : model1 loss : 0.341841 model2 loss : 0.275376
[22:33:31.222] iteration 8467 : model1 loss : 0.318795 model2 loss : 0.288876
[22:33:31.555] iteration 8468 : model1 loss : 0.173040 model2 loss : 0.170970
[22:33:31.890] iteration 8469 : model1 loss : 0.279864 model2 loss : 0.306541
[22:33:32.227] iteration 8470 : model1 loss : 0.198738 model2 loss : 0.250407
[22:33:32.563] iteration 8471 : model1 loss : 0.136061 model2 loss : 0.158874
[22:33:32.893] iteration 8472 : model1 loss : 0.204036 model2 loss : 0.203186
[22:33:33.229] iteration 8473 : model1 loss : 0.191233 model2 loss : 0.201458
[22:33:33.565] iteration 8474 : model1 loss : 0.204778 model2 loss : 0.273245
[22:33:33.902] iteration 8475 : model1 loss : 0.305647 model2 loss : 0.298585
[22:33:34.233] iteration 8476 : model1 loss : 0.178550 model2 loss : 0.206954
[22:33:34.570] iteration 8477 : model1 loss : 0.304234 model2 loss : 0.282212
[22:33:34.908] iteration 8478 : model1 loss : 0.295331 model2 loss : 0.279883
[22:33:35.245] iteration 8479 : model1 loss : 0.265061 model2 loss : 0.263990
[22:33:35.578] iteration 8480 : model1 loss : 0.287130 model2 loss : 0.221245
[22:33:36.229] iteration 8481 : model1 loss : 0.164119 model2 loss : 0.130276
[22:33:36.568] iteration 8482 : model1 loss : 0.228754 model2 loss : 0.241083
[22:33:36.904] iteration 8483 : model1 loss : 0.261570 model2 loss : 0.303601
[22:33:37.236] iteration 8484 : model1 loss : 0.174060 model2 loss : 0.251354
[22:33:37.572] iteration 8485 : model1 loss : 0.262434 model2 loss : 0.256588
[22:33:37.907] iteration 8486 : model1 loss : 0.220248 model2 loss : 0.213798
[22:33:38.243] iteration 8487 : model1 loss : 0.309500 model2 loss : 0.326971
[22:33:38.575] iteration 8488 : model1 loss : 0.298419 model2 loss : 0.340813
[22:33:38.911] iteration 8489 : model1 loss : 0.238423 model2 loss : 0.266560
[22:33:39.247] iteration 8490 : model1 loss : 0.205455 model2 loss : 0.286939
[22:33:39.583] iteration 8491 : model1 loss : 0.260578 model2 loss : 0.239329
[22:33:39.916] iteration 8492 : model1 loss : 0.280956 model2 loss : 0.291458
[22:33:40.253] iteration 8493 : model1 loss : 0.240299 model2 loss : 0.252935
[22:33:40.581] iteration 8494 : model1 loss : 0.306063 model2 loss : 0.279525
[22:33:40.909] iteration 8495 : model1 loss : 0.248079 model2 loss : 0.261412
[22:33:41.237] iteration 8496 : model1 loss : 0.129904 model2 loss : 0.136379
[22:33:41.565] iteration 8497 : model1 loss : 0.293683 model2 loss : 0.195667
[22:33:41.893] iteration 8498 : model1 loss : 0.192932 model2 loss : 0.211182
[22:33:42.221] iteration 8499 : model1 loss : 0.225282 model2 loss : 0.293532
[22:33:42.549] iteration 8500 : model1 loss : 0.246693 model2 loss : 0.228350
[22:33:43.128] iteration 8501 : model1 loss : 0.308798 model2 loss : 0.311070
[22:33:43.455] iteration 8502 : model1 loss : 0.263702 model2 loss : 0.264950
[22:33:43.783] iteration 8503 : model1 loss : 0.316096 model2 loss : 0.310440
[22:33:44.109] iteration 8504 : model1 loss : 0.247426 model2 loss : 0.232160
[22:33:44.436] iteration 8505 : model1 loss : 0.286245 model2 loss : 0.282816
[22:33:44.765] iteration 8506 : model1 loss : 0.222973 model2 loss : 0.207358
[22:33:45.091] iteration 8507 : model1 loss : 0.359042 model2 loss : 0.387541
[22:33:45.420] iteration 8508 : model1 loss : 0.350898 model2 loss : 0.279278
[22:33:45.748] iteration 8509 : model1 loss : 0.362218 model2 loss : 0.319203
[22:33:46.075] iteration 8510 : model1 loss : 0.305698 model2 loss : 0.325071
[22:33:46.402] iteration 8511 : model1 loss : 0.224194 model2 loss : 0.244580
[22:33:46.729] iteration 8512 : model1 loss : 0.249889 model2 loss : 0.198723
[22:33:47.056] iteration 8513 : model1 loss : 0.158330 model2 loss : 0.193051
[22:33:47.383] iteration 8514 : model1 loss : 0.298083 model2 loss : 0.292283
[22:33:47.709] iteration 8515 : model1 loss : 0.168350 model2 loss : 0.247430
[22:33:48.036] iteration 8516 : model1 loss : 0.183998 model2 loss : 0.255909
[22:33:48.363] iteration 8517 : model1 loss : 0.176871 model2 loss : 0.184834
[22:33:48.690] iteration 8518 : model1 loss : 0.344468 model2 loss : 0.331268
[22:33:49.017] iteration 8519 : model1 loss : 0.319038 model2 loss : 0.288244
[22:33:49.346] iteration 8520 : model1 loss : 0.180984 model2 loss : 0.228177
[22:33:49.676] iteration 8521 : model1 loss : 0.251837 model2 loss : 0.252250
[22:33:50.006] iteration 8522 : model1 loss : 0.168641 model2 loss : 0.162258
[22:33:50.336] iteration 8523 : model1 loss : 0.310053 model2 loss : 0.304043
[22:33:50.663] iteration 8524 : model1 loss : 0.220188 model2 loss : 0.240120
[22:33:50.990] iteration 8525 : model1 loss : 0.214600 model2 loss : 0.281021
[22:33:51.319] iteration 8526 : model1 loss : 0.180496 model2 loss : 0.262749
[22:33:51.645] iteration 8527 : model1 loss : 0.312412 model2 loss : 0.332915
[22:33:51.973] iteration 8528 : model1 loss : 0.207698 model2 loss : 0.136343
[22:33:52.300] iteration 8529 : model1 loss : 0.293174 model2 loss : 0.278514
[22:33:52.626] iteration 8530 : model1 loss : 0.250015 model2 loss : 0.269812
[22:33:52.953] iteration 8531 : model1 loss : 0.211509 model2 loss : 0.323594
[22:33:53.280] iteration 8532 : model1 loss : 0.319862 model2 loss : 0.311840
[22:33:53.607] iteration 8533 : model1 loss : 0.254382 model2 loss : 0.246185
[22:33:53.935] iteration 8534 : model1 loss : 0.162063 model2 loss : 0.224760
[22:33:54.261] iteration 8535 : model1 loss : 0.235567 model2 loss : 0.230096
[22:33:54.590] iteration 8536 : model1 loss : 0.135498 model2 loss : 0.152328
[22:33:54.917] iteration 8537 : model1 loss : 0.252740 model2 loss : 0.268617
[22:33:55.244] iteration 8538 : model1 loss : 0.321756 model2 loss : 0.328316
[22:33:55.571] iteration 8539 : model1 loss : 0.227190 model2 loss : 0.305367
[22:33:55.898] iteration 8540 : model1 loss : 0.241422 model2 loss : 0.214901
[22:33:56.225] iteration 8541 : model1 loss : 0.300657 model2 loss : 0.365569
[22:33:56.564] iteration 8542 : model1 loss : 0.216662 model2 loss : 0.270583
[22:33:56.901] iteration 8543 : model1 loss : 0.207689 model2 loss : 0.364818
[22:33:57.238] iteration 8544 : model1 loss : 0.214339 model2 loss : 0.221036
[22:33:57.574] iteration 8545 : model1 loss : 0.261439 model2 loss : 0.264327
[22:33:57.910] iteration 8546 : model1 loss : 0.450771 model2 loss : 0.419312
[22:33:58.248] iteration 8547 : model1 loss : 0.205668 model2 loss : 0.222394
[22:33:58.586] iteration 8548 : model1 loss : 0.230868 model2 loss : 0.233584
[22:33:58.924] iteration 8549 : model1 loss : 0.287598 model2 loss : 0.279185
[22:33:59.259] iteration 8550 : model1 loss : 0.326681 model2 loss : 0.332539
[22:33:59.891] iteration 8551 : model1 loss : 0.251802 model2 loss : 0.219986
[22:34:00.232] iteration 8552 : model1 loss : 0.253148 model2 loss : 0.297785
[22:34:00.569] iteration 8553 : model1 loss : 0.191391 model2 loss : 0.193814
[22:34:00.910] iteration 8554 : model1 loss : 0.201397 model2 loss : 0.209313
[22:34:01.246] iteration 8555 : model1 loss : 0.297986 model2 loss : 0.352837
[22:34:01.604] iteration 8556 : model1 loss : 0.278807 model2 loss : 0.220831
[22:34:01.939] iteration 8557 : model1 loss : 0.220752 model2 loss : 0.199759
[22:34:02.276] iteration 8558 : model1 loss : 0.245948 model2 loss : 0.272099
[22:34:02.614] iteration 8559 : model1 loss : 0.192696 model2 loss : 0.264571
[22:34:02.946] iteration 8560 : model1 loss : 0.216144 model2 loss : 0.243904
[22:34:03.282] iteration 8561 : model1 loss : 0.216301 model2 loss : 0.203962
[22:34:03.619] iteration 8562 : model1 loss : 0.295370 model2 loss : 0.256700
[22:34:03.955] iteration 8563 : model1 loss : 0.206213 model2 loss : 0.227803
[22:34:04.287] iteration 8564 : model1 loss : 0.147416 model2 loss : 0.213122
[22:34:04.624] iteration 8565 : model1 loss : 0.316792 model2 loss : 0.365783
[22:34:04.964] iteration 8566 : model1 loss : 0.224568 model2 loss : 0.301046
[22:34:05.303] iteration 8567 : model1 loss : 0.394809 model2 loss : 0.405808
[22:34:05.633] iteration 8568 : model1 loss : 0.204677 model2 loss : 0.230976
[22:34:05.969] iteration 8569 : model1 loss : 0.215242 model2 loss : 0.173211
[22:34:06.299] iteration 8570 : model1 loss : 0.205558 model2 loss : 0.303417
[22:34:06.627] iteration 8571 : model1 loss : 0.274282 model2 loss : 0.304575
[22:34:06.955] iteration 8572 : model1 loss : 0.195450 model2 loss : 0.228723
[22:34:07.282] iteration 8573 : model1 loss : 0.335911 model2 loss : 0.357387
[22:34:07.610] iteration 8574 : model1 loss : 0.241348 model2 loss : 0.257614
[22:34:07.936] iteration 8575 : model1 loss : 0.302480 model2 loss : 0.286777
[22:34:08.266] iteration 8576 : model1 loss : 0.365811 model2 loss : 0.443708
[22:34:08.594] iteration 8577 : model1 loss : 0.174705 model2 loss : 0.184318
[22:34:08.921] iteration 8578 : model1 loss : 0.257470 model2 loss : 0.318120
[22:34:09.248] iteration 8579 : model1 loss : 0.241425 model2 loss : 0.260169
[22:34:09.575] iteration 8580 : model1 loss : 0.268971 model2 loss : 0.211463
[22:34:09.902] iteration 8581 : model1 loss : 0.237234 model2 loss : 0.286965
[22:34:10.229] iteration 8582 : model1 loss : 0.287351 model2 loss : 0.268066
[22:34:10.556] iteration 8583 : model1 loss : 0.206951 model2 loss : 0.210086
[22:34:10.886] iteration 8584 : model1 loss : 0.269008 model2 loss : 0.325436
[22:34:11.213] iteration 8585 : model1 loss : 0.232651 model2 loss : 0.305165
[22:34:11.540] iteration 8586 : model1 loss : 0.140232 model2 loss : 0.223112
[22:34:11.867] iteration 8587 : model1 loss : 0.337587 model2 loss : 0.350805
[22:34:12.194] iteration 8588 : model1 loss : 0.236738 model2 loss : 0.246794
[22:34:12.521] iteration 8589 : model1 loss : 0.339932 model2 loss : 0.363767
[22:34:12.850] iteration 8590 : model1 loss : 0.399485 model2 loss : 0.405064
[22:34:13.179] iteration 8591 : model1 loss : 0.189875 model2 loss : 0.234117
[22:34:13.506] iteration 8592 : model1 loss : 0.262167 model2 loss : 0.230029
[22:34:13.833] iteration 8593 : model1 loss : 0.258127 model2 loss : 0.260452
[22:34:14.166] iteration 8594 : model1 loss : 0.316694 model2 loss : 0.299812
[22:34:14.493] iteration 8595 : model1 loss : 0.256957 model2 loss : 0.311555
[22:34:14.820] iteration 8596 : model1 loss : 0.164756 model2 loss : 0.209614
[22:34:15.147] iteration 8597 : model1 loss : 0.249578 model2 loss : 0.232161
[22:34:15.474] iteration 8598 : model1 loss : 0.236356 model2 loss : 0.234542
[22:34:15.801] iteration 8599 : model1 loss : 0.261063 model2 loss : 0.186761
[22:34:16.130] iteration 8600 : model1 loss : 0.170288 model2 loss : 0.208010
[22:34:16.699] iteration 8601 : model1 loss : 0.324110 model2 loss : 0.400617
[22:34:17.028] iteration 8602 : model1 loss : 0.292775 model2 loss : 0.317680
[22:34:17.356] iteration 8603 : model1 loss : 0.153954 model2 loss : 0.194032
[22:34:17.684] iteration 8604 : model1 loss : 0.342165 model2 loss : 0.332773
[22:34:18.010] iteration 8605 : model1 loss : 0.220255 model2 loss : 0.281542
[22:34:18.338] iteration 8606 : model1 loss : 0.234172 model2 loss : 0.186720
[22:34:18.666] iteration 8607 : model1 loss : 0.279282 model2 loss : 0.341549
[22:34:18.994] iteration 8608 : model1 loss : 0.217519 model2 loss : 0.228270
[22:34:19.322] iteration 8609 : model1 loss : 0.210662 model2 loss : 0.196467
[22:34:19.658] iteration 8610 : model1 loss : 0.201546 model2 loss : 0.217551
[22:34:19.986] iteration 8611 : model1 loss : 0.360630 model2 loss : 0.291339
[22:34:20.315] iteration 8612 : model1 loss : 0.295797 model2 loss : 0.222290
[22:34:20.643] iteration 8613 : model1 loss : 0.269551 model2 loss : 0.167201
[22:34:20.971] iteration 8614 : model1 loss : 0.247784 model2 loss : 0.260437
[22:34:21.299] iteration 8615 : model1 loss : 0.200626 model2 loss : 0.267554
[22:34:21.627] iteration 8616 : model1 loss : 0.279004 model2 loss : 0.320416
[22:34:21.954] iteration 8617 : model1 loss : 0.313288 model2 loss : 0.231981
[22:34:22.282] iteration 8618 : model1 loss : 0.301165 model2 loss : 0.368159
[22:34:22.610] iteration 8619 : model1 loss : 0.196857 model2 loss : 0.227438
[22:34:22.940] iteration 8620 : model1 loss : 0.250103 model2 loss : 0.295218
[22:34:23.268] iteration 8621 : model1 loss : 0.295554 model2 loss : 0.371451
[22:34:23.597] iteration 8622 : model1 loss : 0.266738 model2 loss : 0.267705
[22:34:23.925] iteration 8623 : model1 loss : 0.289984 model2 loss : 0.341739
[22:34:24.253] iteration 8624 : model1 loss : 0.182055 model2 loss : 0.244593
[22:34:24.580] iteration 8625 : model1 loss : 0.192720 model2 loss : 0.231941
[22:34:24.908] iteration 8626 : model1 loss : 0.187077 model2 loss : 0.231253
[22:34:25.237] iteration 8627 : model1 loss : 0.178595 model2 loss : 0.157842
[22:34:25.565] iteration 8628 : model1 loss : 0.325079 model2 loss : 0.272060
[22:34:25.893] iteration 8629 : model1 loss : 0.276453 model2 loss : 0.326338
[22:34:26.221] iteration 8630 : model1 loss : 0.292099 model2 loss : 0.275900
[22:34:26.549] iteration 8631 : model1 loss : 0.230871 model2 loss : 0.284492
[22:34:26.876] iteration 8632 : model1 loss : 0.294685 model2 loss : 0.273243
[22:34:27.202] iteration 8633 : model1 loss : 0.220096 model2 loss : 0.237794
[22:34:27.528] iteration 8634 : model1 loss : 0.217601 model2 loss : 0.176207
[22:34:27.857] iteration 8635 : model1 loss : 0.256078 model2 loss : 0.323773
[22:34:28.185] iteration 8636 : model1 loss : 0.135950 model2 loss : 0.175493
[22:34:28.513] iteration 8637 : model1 loss : 0.280422 model2 loss : 0.236746
[22:34:28.840] iteration 8638 : model1 loss : 0.113796 model2 loss : 0.205393
[22:34:29.167] iteration 8639 : model1 loss : 0.207807 model2 loss : 0.243865
[22:34:29.495] iteration 8640 : model1 loss : 0.133991 model2 loss : 0.143893
[22:34:29.823] iteration 8641 : model1 loss : 0.264142 model2 loss : 0.300786
[22:34:30.150] iteration 8642 : model1 loss : 0.245256 model2 loss : 0.281749
[22:34:30.478] iteration 8643 : model1 loss : 0.258565 model2 loss : 0.258466
[22:34:30.806] iteration 8644 : model1 loss : 0.297230 model2 loss : 0.289977
[22:34:31.134] iteration 8645 : model1 loss : 0.191081 model2 loss : 0.222724
[22:34:31.460] iteration 8646 : model1 loss : 0.208305 model2 loss : 0.264002
[22:34:31.785] iteration 8647 : model1 loss : 0.293953 model2 loss : 0.285299
[22:34:32.111] iteration 8648 : model1 loss : 0.223029 model2 loss : 0.320958
[22:34:32.437] iteration 8649 : model1 loss : 0.224481 model2 loss : 0.274218
[22:34:32.761] iteration 8650 : model1 loss : 0.355486 model2 loss : 0.273540
[22:34:33.292] iteration 8651 : model1 loss : 0.174967 model2 loss : 0.212805
[22:34:33.618] iteration 8652 : model1 loss : 0.199009 model2 loss : 0.217719
[22:34:33.944] iteration 8653 : model1 loss : 0.211269 model2 loss : 0.205506
[22:34:34.269] iteration 8654 : model1 loss : 0.250546 model2 loss : 0.286954
[22:34:34.595] iteration 8655 : model1 loss : 0.343145 model2 loss : 0.311931
[22:34:34.921] iteration 8656 : model1 loss : 0.435751 model2 loss : 0.480500
[22:34:35.247] iteration 8657 : model1 loss : 0.169179 model2 loss : 0.169267
[22:34:35.574] iteration 8658 : model1 loss : 0.205780 model2 loss : 0.257678
[22:34:35.903] iteration 8659 : model1 loss : 0.227793 model2 loss : 0.197911
[22:34:36.229] iteration 8660 : model1 loss : 0.286221 model2 loss : 0.298647
[22:34:36.556] iteration 8661 : model1 loss : 0.270026 model2 loss : 0.263904
[22:34:36.881] iteration 8662 : model1 loss : 0.320741 model2 loss : 0.436264
[22:34:37.206] iteration 8663 : model1 loss : 0.204231 model2 loss : 0.201598
[22:34:37.532] iteration 8664 : model1 loss : 0.245998 model2 loss : 0.276691
[22:34:37.857] iteration 8665 : model1 loss : 0.194817 model2 loss : 0.186782
[22:34:38.183] iteration 8666 : model1 loss : 0.287873 model2 loss : 0.275489
[22:34:38.508] iteration 8667 : model1 loss : 0.204253 model2 loss : 0.259580
[22:34:38.835] iteration 8668 : model1 loss : 0.239766 model2 loss : 0.190151
[22:34:39.161] iteration 8669 : model1 loss : 0.259276 model2 loss : 0.265342
[22:34:39.488] iteration 8670 : model1 loss : 0.149822 model2 loss : 0.148049
[22:34:39.814] iteration 8671 : model1 loss : 0.242022 model2 loss : 0.246055
[22:34:40.140] iteration 8672 : model1 loss : 0.204116 model2 loss : 0.235710
[22:34:40.467] iteration 8673 : model1 loss : 0.316764 model2 loss : 0.336868
[22:34:40.796] iteration 8674 : model1 loss : 0.240483 model2 loss : 0.290231
[22:34:41.123] iteration 8675 : model1 loss : 0.389230 model2 loss : 0.330554
[22:34:41.451] iteration 8676 : model1 loss : 0.376737 model2 loss : 0.361017
[22:34:41.779] iteration 8677 : model1 loss : 0.234649 model2 loss : 0.272543
[22:34:42.106] iteration 8678 : model1 loss : 0.275962 model2 loss : 0.292968
[22:34:42.434] iteration 8679 : model1 loss : 0.116267 model2 loss : 0.182711
[22:34:42.762] iteration 8680 : model1 loss : 0.305418 model2 loss : 0.337441
[22:34:43.089] iteration 8681 : model1 loss : 0.204864 model2 loss : 0.273357
[22:34:43.418] iteration 8682 : model1 loss : 0.271493 model2 loss : 0.297671
[22:34:43.745] iteration 8683 : model1 loss : 0.338617 model2 loss : 0.380463
[22:34:44.072] iteration 8684 : model1 loss : 0.207098 model2 loss : 0.204810
[22:34:44.397] iteration 8685 : model1 loss : 0.326567 model2 loss : 0.386064
[22:34:44.725] iteration 8686 : model1 loss : 0.226574 model2 loss : 0.250288
[22:34:45.052] iteration 8687 : model1 loss : 0.269196 model2 loss : 0.244283
[22:34:45.382] iteration 8688 : model1 loss : 0.194225 model2 loss : 0.166927
[22:34:45.717] iteration 8689 : model1 loss : 0.205548 model2 loss : 0.228654
[22:34:46.044] iteration 8690 : model1 loss : 0.238884 model2 loss : 0.260615
[22:34:46.372] iteration 8691 : model1 loss : 0.213326 model2 loss : 0.267680
[22:34:46.700] iteration 8692 : model1 loss : 0.290127 model2 loss : 0.278308
[22:34:47.024] iteration 8693 : model1 loss : 0.183123 model2 loss : 0.212888
[22:34:47.351] iteration 8694 : model1 loss : 0.290348 model2 loss : 0.267577
[22:34:47.680] iteration 8695 : model1 loss : 0.220488 model2 loss : 0.261098
[22:34:48.007] iteration 8696 : model1 loss : 0.185443 model2 loss : 0.206226
[22:34:48.331] iteration 8697 : model1 loss : 0.168609 model2 loss : 0.165688
[22:34:48.660] iteration 8698 : model1 loss : 0.221352 model2 loss : 0.271400
[22:34:48.988] iteration 8699 : model1 loss : 0.273473 model2 loss : 0.306305
[22:34:49.316] iteration 8700 : model1 loss : 0.296047 model2 loss : 0.345989
[22:34:49.907] iteration 8701 : model1 loss : 0.158855 model2 loss : 0.230509
[22:34:50.236] iteration 8702 : model1 loss : 0.223351 model2 loss : 0.241111
[22:34:50.564] iteration 8703 : model1 loss : 0.195254 model2 loss : 0.160141
[22:34:50.891] iteration 8704 : model1 loss : 0.277816 model2 loss : 0.335281
[22:34:51.217] iteration 8705 : model1 loss : 0.311506 model2 loss : 0.354648
[22:34:51.544] iteration 8706 : model1 loss : 0.260278 model2 loss : 0.304634
[22:34:51.871] iteration 8707 : model1 loss : 0.255336 model2 loss : 0.256626
[22:34:52.198] iteration 8708 : model1 loss : 0.203349 model2 loss : 0.216939
[22:34:52.524] iteration 8709 : model1 loss : 0.179736 model2 loss : 0.216119
[22:34:52.850] iteration 8710 : model1 loss : 0.190481 model2 loss : 0.289093
[22:34:53.178] iteration 8711 : model1 loss : 0.295988 model2 loss : 0.306006
[22:34:53.508] iteration 8712 : model1 loss : 0.219022 model2 loss : 0.287205
[22:34:53.835] iteration 8713 : model1 loss : 0.223885 model2 loss : 0.294279
[22:34:54.161] iteration 8714 : model1 loss : 0.290595 model2 loss : 0.341435
[22:34:54.487] iteration 8715 : model1 loss : 0.247166 model2 loss : 0.260686
[22:34:54.813] iteration 8716 : model1 loss : 0.273758 model2 loss : 0.329385
[22:34:55.140] iteration 8717 : model1 loss : 0.321456 model2 loss : 0.328169
[22:34:55.468] iteration 8718 : model1 loss : 0.337884 model2 loss : 0.369827
[22:34:55.794] iteration 8719 : model1 loss : 0.226380 model2 loss : 0.193248
[22:34:56.122] iteration 8720 : model1 loss : 0.183543 model2 loss : 0.182930
[22:34:57.048] iteration 8721 : model1 loss : 0.198913 model2 loss : 0.256227
[22:34:57.375] iteration 8722 : model1 loss : 0.241720 model2 loss : 0.257739
[22:34:57.702] iteration 8723 : model1 loss : 0.085299 model2 loss : 0.243696
[22:34:58.030] iteration 8724 : model1 loss : 0.270023 model2 loss : 0.259398
[22:34:58.361] iteration 8725 : model1 loss : 0.227143 model2 loss : 0.224275
[22:34:58.688] iteration 8726 : model1 loss : 0.243228 model2 loss : 0.204212
[22:34:59.015] iteration 8727 : model1 loss : 0.255797 model2 loss : 0.260642
[22:34:59.344] iteration 8728 : model1 loss : 0.182380 model2 loss : 0.221835
[22:34:59.671] iteration 8729 : model1 loss : 0.239750 model2 loss : 0.278586
[22:34:59.998] iteration 8730 : model1 loss : 0.213991 model2 loss : 0.269905
[22:35:00.326] iteration 8731 : model1 loss : 0.114530 model2 loss : 0.189944
[22:35:00.654] iteration 8732 : model1 loss : 0.277187 model2 loss : 0.271588
[22:35:00.981] iteration 8733 : model1 loss : 0.237743 model2 loss : 0.264013
[22:35:01.308] iteration 8734 : model1 loss : 0.265213 model2 loss : 0.312034
[22:35:01.636] iteration 8735 : model1 loss : 0.226868 model2 loss : 0.190803
[22:35:01.964] iteration 8736 : model1 loss : 0.281877 model2 loss : 0.316305
[22:35:02.291] iteration 8737 : model1 loss : 0.300149 model2 loss : 0.340453
[22:35:02.620] iteration 8738 : model1 loss : 0.224836 model2 loss : 0.270609
[22:35:02.946] iteration 8739 : model1 loss : 0.290253 model2 loss : 0.285344
[22:35:03.273] iteration 8740 : model1 loss : 0.255856 model2 loss : 0.292496
[22:35:03.600] iteration 8741 : model1 loss : 0.239067 model2 loss : 0.279342
[22:35:03.928] iteration 8742 : model1 loss : 0.135058 model2 loss : 0.160738
[22:35:04.256] iteration 8743 : model1 loss : 0.273701 model2 loss : 0.292237
[22:35:04.584] iteration 8744 : model1 loss : 0.351427 model2 loss : 0.322499
[22:35:04.912] iteration 8745 : model1 loss : 0.251832 model2 loss : 0.252594
[22:35:05.239] iteration 8746 : model1 loss : 0.141540 model2 loss : 0.216073
[22:35:05.567] iteration 8747 : model1 loss : 0.272465 model2 loss : 0.275181
[22:35:05.894] iteration 8748 : model1 loss : 0.248485 model2 loss : 0.225063
[22:35:06.223] iteration 8749 : model1 loss : 0.329102 model2 loss : 0.324421
[22:35:06.550] iteration 8750 : model1 loss : 0.282140 model2 loss : 0.332761
[22:35:07.119] iteration 8751 : model1 loss : 0.198993 model2 loss : 0.235962
[22:35:07.447] iteration 8752 : model1 loss : 0.200125 model2 loss : 0.252289
[22:35:07.775] iteration 8753 : model1 loss : 0.192638 model2 loss : 0.217769
[22:35:08.102] iteration 8754 : model1 loss : 0.253245 model2 loss : 0.342431
[22:35:08.430] iteration 8755 : model1 loss : 0.224580 model2 loss : 0.241220
[22:35:08.758] iteration 8756 : model1 loss : 0.174694 model2 loss : 0.203138
[22:35:09.086] iteration 8757 : model1 loss : 0.273139 model2 loss : 0.292092
[22:35:09.414] iteration 8758 : model1 loss : 0.230083 model2 loss : 0.225555
[22:35:09.742] iteration 8759 : model1 loss : 0.280274 model2 loss : 0.276903
[22:35:10.069] iteration 8760 : model1 loss : 0.147751 model2 loss : 0.172423
[22:35:10.398] iteration 8761 : model1 loss : 0.282935 model2 loss : 0.250763
[22:35:10.725] iteration 8762 : model1 loss : 0.279226 model2 loss : 0.307551
[22:35:11.052] iteration 8763 : model1 loss : 0.284772 model2 loss : 0.256304
[22:35:11.380] iteration 8764 : model1 loss : 0.291249 model2 loss : 0.398759
[22:35:11.709] iteration 8765 : model1 loss : 0.202437 model2 loss : 0.197857
[22:35:12.039] iteration 8766 : model1 loss : 0.268781 model2 loss : 0.357362
[22:35:12.367] iteration 8767 : model1 loss : 0.268132 model2 loss : 0.326018
[22:35:12.695] iteration 8768 : model1 loss : 0.256345 model2 loss : 0.293273
[22:35:13.023] iteration 8769 : model1 loss : 0.129155 model2 loss : 0.232515
[22:35:13.352] iteration 8770 : model1 loss : 0.145945 model2 loss : 0.206070
[22:35:13.678] iteration 8771 : model1 loss : 0.252709 model2 loss : 0.191257
[22:35:14.009] iteration 8772 : model1 loss : 0.331250 model2 loss : 0.380468
[22:35:14.337] iteration 8773 : model1 loss : 0.192861 model2 loss : 0.263833
[22:35:14.666] iteration 8774 : model1 loss : 0.279460 model2 loss : 0.327341
[22:35:14.994] iteration 8775 : model1 loss : 0.186012 model2 loss : 0.185210
[22:35:15.323] iteration 8776 : model1 loss : 0.144177 model2 loss : 0.146700
[22:35:15.652] iteration 8777 : model1 loss : 0.370887 model2 loss : 0.374350
[22:35:15.979] iteration 8778 : model1 loss : 0.179219 model2 loss : 0.201996
[22:35:16.307] iteration 8779 : model1 loss : 0.235073 model2 loss : 0.255526
[22:35:16.635] iteration 8780 : model1 loss : 0.201238 model2 loss : 0.217726
[22:35:16.963] iteration 8781 : model1 loss : 0.315831 model2 loss : 0.309419
[22:35:17.291] iteration 8782 : model1 loss : 0.264188 model2 loss : 0.242392
[22:35:17.618] iteration 8783 : model1 loss : 0.254694 model2 loss : 0.293494
[22:35:17.946] iteration 8784 : model1 loss : 0.228994 model2 loss : 0.248908
[22:35:18.273] iteration 8785 : model1 loss : 0.189969 model2 loss : 0.262793
[22:35:18.603] iteration 8786 : model1 loss : 0.296897 model2 loss : 0.386946
[22:35:18.931] iteration 8787 : model1 loss : 0.269648 model2 loss : 0.304490
[22:35:19.258] iteration 8788 : model1 loss : 0.263119 model2 loss : 0.303404
[22:35:19.586] iteration 8789 : model1 loss : 0.272866 model2 loss : 0.261119
[22:35:19.913] iteration 8790 : model1 loss : 0.284941 model2 loss : 0.270357
[22:35:20.240] iteration 8791 : model1 loss : 0.175785 model2 loss : 0.176805
[22:35:20.569] iteration 8792 : model1 loss : 0.348614 model2 loss : 0.308505
[22:35:20.897] iteration 8793 : model1 loss : 0.295955 model2 loss : 0.265744
[22:35:21.225] iteration 8794 : model1 loss : 0.265338 model2 loss : 0.255547
[22:35:21.554] iteration 8795 : model1 loss : 0.138912 model2 loss : 0.198878
[22:35:21.882] iteration 8796 : model1 loss : 0.263553 model2 loss : 0.285325
[22:35:22.213] iteration 8797 : model1 loss : 0.230526 model2 loss : 0.289197
[22:35:22.540] iteration 8798 : model1 loss : 0.302539 model2 loss : 0.340625
[22:35:22.868] iteration 8799 : model1 loss : 0.232390 model2 loss : 0.225486
[22:35:23.196] iteration 8800 : model1 loss : 0.252574 model2 loss : 0.258922
[22:35:23.768] iteration 8801 : model1 loss : 0.287656 model2 loss : 0.303100
[22:35:24.098] iteration 8802 : model1 loss : 0.282177 model2 loss : 0.362220
[22:35:24.427] iteration 8803 : model1 loss : 0.206363 model2 loss : 0.234056
[22:35:24.756] iteration 8804 : model1 loss : 0.229911 model2 loss : 0.238071
[22:35:25.085] iteration 8805 : model1 loss : 0.210535 model2 loss : 0.225181
[22:35:25.415] iteration 8806 : model1 loss : 0.228443 model2 loss : 0.246610
[22:35:25.742] iteration 8807 : model1 loss : 0.261724 model2 loss : 0.263110
[22:35:26.072] iteration 8808 : model1 loss : 0.220418 model2 loss : 0.256388
[22:35:26.401] iteration 8809 : model1 loss : 0.273131 model2 loss : 0.289007
[22:35:26.728] iteration 8810 : model1 loss : 0.201952 model2 loss : 0.238071
[22:35:27.055] iteration 8811 : model1 loss : 0.206000 model2 loss : 0.277906
[22:35:27.385] iteration 8812 : model1 loss : 0.217439 model2 loss : 0.241470
[22:35:27.714] iteration 8813 : model1 loss : 0.308224 model2 loss : 0.305976
[22:35:28.042] iteration 8814 : model1 loss : 0.113784 model2 loss : 0.129717
[22:35:28.372] iteration 8815 : model1 loss : 0.148119 model2 loss : 0.244201
[22:35:28.701] iteration 8816 : model1 loss : 0.212750 model2 loss : 0.186599
[22:35:29.029] iteration 8817 : model1 loss : 0.331714 model2 loss : 0.349063
[22:35:29.357] iteration 8818 : model1 loss : 0.240984 model2 loss : 0.287771
[22:35:29.686] iteration 8819 : model1 loss : 0.304039 model2 loss : 0.241483
[22:35:30.015] iteration 8820 : model1 loss : 0.146294 model2 loss : 0.165923
[22:35:30.345] iteration 8821 : model1 loss : 0.220019 model2 loss : 0.248292
[22:35:30.675] iteration 8822 : model1 loss : 0.278994 model2 loss : 0.284459
[22:35:31.005] iteration 8823 : model1 loss : 0.260836 model2 loss : 0.268490
[22:35:31.341] iteration 8824 : model1 loss : 0.104113 model2 loss : 0.098050
[22:35:31.672] iteration 8825 : model1 loss : 0.250394 model2 loss : 0.121376
[22:35:32.002] iteration 8826 : model1 loss : 0.187810 model2 loss : 0.192131
[22:35:32.334] iteration 8827 : model1 loss : 0.176362 model2 loss : 0.224777
[22:35:32.665] iteration 8828 : model1 loss : 0.259801 model2 loss : 0.342607
[22:35:32.995] iteration 8829 : model1 loss : 0.342792 model2 loss : 0.365691
[22:35:33.323] iteration 8830 : model1 loss : 0.193524 model2 loss : 0.173157
[22:35:33.651] iteration 8831 : model1 loss : 0.307632 model2 loss : 0.375537
[22:35:33.981] iteration 8832 : model1 loss : 0.153785 model2 loss : 0.127405
[22:35:34.310] iteration 8833 : model1 loss : 0.166427 model2 loss : 0.148679
[22:35:34.638] iteration 8834 : model1 loss : 0.265530 model2 loss : 0.257008
[22:35:34.966] iteration 8835 : model1 loss : 0.381007 model2 loss : 0.405991
[22:35:35.295] iteration 8836 : model1 loss : 0.200124 model2 loss : 0.209704
[22:35:35.623] iteration 8837 : model1 loss : 0.217697 model2 loss : 0.311713
[22:35:35.953] iteration 8838 : model1 loss : 0.225642 model2 loss : 0.337300
[22:35:36.281] iteration 8839 : model1 loss : 0.189021 model2 loss : 0.245259
[22:35:36.610] iteration 8840 : model1 loss : 0.225263 model2 loss : 0.259567
[22:35:36.940] iteration 8841 : model1 loss : 0.291451 model2 loss : 0.339192
[22:35:37.269] iteration 8842 : model1 loss : 0.201324 model2 loss : 0.261891
[22:35:37.598] iteration 8843 : model1 loss : 0.154849 model2 loss : 0.174502
[22:35:37.927] iteration 8844 : model1 loss : 0.172613 model2 loss : 0.234970
[22:35:38.255] iteration 8845 : model1 loss : 0.144899 model2 loss : 0.154562
[22:35:38.584] iteration 8846 : model1 loss : 0.226755 model2 loss : 0.204016
[22:35:38.912] iteration 8847 : model1 loss : 0.214331 model2 loss : 0.188423
[22:35:39.238] iteration 8848 : model1 loss : 0.210618 model2 loss : 0.204486
[22:35:39.563] iteration 8849 : model1 loss : 0.390792 model2 loss : 0.334264
[22:35:39.889] iteration 8850 : model1 loss : 0.318309 model2 loss : 0.339942
[22:35:40.418] iteration 8851 : model1 loss : 0.298609 model2 loss : 0.315431
[22:35:40.743] iteration 8852 : model1 loss : 0.223200 model2 loss : 0.223116
[22:35:41.069] iteration 8853 : model1 loss : 0.180743 model2 loss : 0.254119
[22:35:41.396] iteration 8854 : model1 loss : 0.253360 model2 loss : 0.298542
[22:35:41.723] iteration 8855 : model1 loss : 0.310533 model2 loss : 0.302507
[22:35:42.050] iteration 8856 : model1 loss : 0.230747 model2 loss : 0.212581
[22:35:42.376] iteration 8857 : model1 loss : 0.254009 model2 loss : 0.269575
[22:35:42.703] iteration 8858 : model1 loss : 0.207553 model2 loss : 0.269504
[22:35:43.031] iteration 8859 : model1 loss : 0.300285 model2 loss : 0.307960
[22:35:43.358] iteration 8860 : model1 loss : 0.262808 model2 loss : 0.313465
[22:35:43.684] iteration 8861 : model1 loss : 0.251266 model2 loss : 0.290441
[22:35:44.010] iteration 8862 : model1 loss : 0.209965 model2 loss : 0.311365
[22:35:44.337] iteration 8863 : model1 loss : 0.255621 model2 loss : 0.272047
[22:35:44.663] iteration 8864 : model1 loss : 0.205061 model2 loss : 0.224361
[22:35:44.989] iteration 8865 : model1 loss : 0.143563 model2 loss : 0.159644
[22:35:45.317] iteration 8866 : model1 loss : 0.240275 model2 loss : 0.244497
[22:35:45.643] iteration 8867 : model1 loss : 0.280992 model2 loss : 0.263091
[22:35:45.969] iteration 8868 : model1 loss : 0.195929 model2 loss : 0.244438
[22:35:46.296] iteration 8869 : model1 loss : 0.280677 model2 loss : 0.231482
[22:35:46.623] iteration 8870 : model1 loss : 0.324727 model2 loss : 0.292599
[22:35:46.948] iteration 8871 : model1 loss : 0.290748 model2 loss : 0.304196
[22:35:47.278] iteration 8872 : model1 loss : 0.206397 model2 loss : 0.201137
[22:35:47.608] iteration 8873 : model1 loss : 0.235307 model2 loss : 0.192071
[22:35:47.935] iteration 8874 : model1 loss : 0.113592 model2 loss : 0.153924
[22:35:48.263] iteration 8875 : model1 loss : 0.270098 model2 loss : 0.241174
[22:35:48.591] iteration 8876 : model1 loss : 0.297797 model2 loss : 0.292029
[22:35:48.919] iteration 8877 : model1 loss : 0.181622 model2 loss : 0.179518
[22:35:49.251] iteration 8878 : model1 loss : 0.162831 model2 loss : 0.235426
[22:35:49.581] iteration 8879 : model1 loss : 0.151585 model2 loss : 0.218768
[22:35:49.911] iteration 8880 : model1 loss : 0.317708 model2 loss : 0.334030
[22:35:50.239] iteration 8881 : model1 loss : 0.200723 model2 loss : 0.257263
[22:35:50.567] iteration 8882 : model1 loss : 0.242057 model2 loss : 0.254533
[22:35:50.895] iteration 8883 : model1 loss : 0.201152 model2 loss : 0.212547
[22:35:51.223] iteration 8884 : model1 loss : 0.222695 model2 loss : 0.232799
[22:35:51.551] iteration 8885 : model1 loss : 0.237366 model2 loss : 0.226025
[22:35:51.878] iteration 8886 : model1 loss : 0.237296 model2 loss : 0.257640
[22:35:52.208] iteration 8887 : model1 loss : 0.183685 model2 loss : 0.277604
[22:35:52.536] iteration 8888 : model1 loss : 0.188876 model2 loss : 0.183239
[22:35:52.867] iteration 8889 : model1 loss : 0.238212 model2 loss : 0.276223
[22:35:53.196] iteration 8890 : model1 loss : 0.126428 model2 loss : 0.161242
[22:35:53.526] iteration 8891 : model1 loss : 0.237045 model2 loss : 0.244984
[22:35:53.857] iteration 8892 : model1 loss : 0.294000 model2 loss : 0.310897
[22:35:54.186] iteration 8893 : model1 loss : 0.191282 model2 loss : 0.204473
[22:35:54.517] iteration 8894 : model1 loss : 0.204696 model2 loss : 0.255428
[22:35:54.846] iteration 8895 : model1 loss : 0.255030 model2 loss : 0.390322
[22:35:55.178] iteration 8896 : model1 loss : 0.203639 model2 loss : 0.303289
[22:35:55.511] iteration 8897 : model1 loss : 0.283001 model2 loss : 0.308781
[22:35:55.841] iteration 8898 : model1 loss : 0.241499 model2 loss : 0.222651
[22:35:56.171] iteration 8899 : model1 loss : 0.277607 model2 loss : 0.314220
[22:35:56.502] iteration 8900 : model1 loss : 0.309251 model2 loss : 0.331646
[22:35:57.068] iteration 8901 : model1 loss : 0.190063 model2 loss : 0.228466
[22:35:57.409] iteration 8902 : model1 loss : 0.219690 model2 loss : 0.158881
[22:35:57.740] iteration 8903 : model1 loss : 0.266625 model2 loss : 0.288773
[22:35:58.068] iteration 8904 : model1 loss : 0.273048 model2 loss : 0.372075
[22:35:58.397] iteration 8905 : model1 loss : 0.274020 model2 loss : 0.321000
[22:35:58.728] iteration 8906 : model1 loss : 0.278799 model2 loss : 0.306679
[22:35:59.058] iteration 8907 : model1 loss : 0.382589 model2 loss : 0.277483
[22:35:59.390] iteration 8908 : model1 loss : 0.188353 model2 loss : 0.163648
[22:35:59.722] iteration 8909 : model1 loss : 0.197752 model2 loss : 0.194465
[22:36:00.054] iteration 8910 : model1 loss : 0.208674 model2 loss : 0.231805
[22:36:00.384] iteration 8911 : model1 loss : 0.263571 model2 loss : 0.334421
[22:36:00.714] iteration 8912 : model1 loss : 0.233873 model2 loss : 0.188791
[22:36:01.054] iteration 8913 : model1 loss : 0.271914 model2 loss : 0.346517
[22:36:01.392] iteration 8914 : model1 loss : 0.199813 model2 loss : 0.242310
[22:36:01.730] iteration 8915 : model1 loss : 0.221546 model2 loss : 0.165457
[22:36:02.074] iteration 8916 : model1 loss : 0.227925 model2 loss : 0.273332
[22:36:02.417] iteration 8917 : model1 loss : 0.189740 model2 loss : 0.181316
[22:36:02.758] iteration 8918 : model1 loss : 0.271531 model2 loss : 0.254609
[22:36:03.101] iteration 8919 : model1 loss : 0.307173 model2 loss : 0.343500
[22:36:03.440] iteration 8920 : model1 loss : 0.344134 model2 loss : 0.293284
[22:36:03.769] iteration 8921 : model1 loss : 0.223763 model2 loss : 0.213174
[22:36:04.097] iteration 8922 : model1 loss : 0.102458 model2 loss : 0.123867
[22:36:04.435] iteration 8923 : model1 loss : 0.284178 model2 loss : 0.299383
[22:36:04.768] iteration 8924 : model1 loss : 0.243171 model2 loss : 0.204598
[22:36:05.098] iteration 8925 : model1 loss : 0.274616 model2 loss : 0.349497
[22:36:05.429] iteration 8926 : model1 loss : 0.266468 model2 loss : 0.234050
[22:36:05.760] iteration 8927 : model1 loss : 0.176292 model2 loss : 0.182124
[22:36:06.088] iteration 8928 : model1 loss : 0.111297 model2 loss : 0.148946
[22:36:06.423] iteration 8929 : model1 loss : 0.223013 model2 loss : 0.257368
[22:36:06.761] iteration 8930 : model1 loss : 0.334217 model2 loss : 0.341390
[22:36:07.092] iteration 8931 : model1 loss : 0.148141 model2 loss : 0.161403
[22:36:07.425] iteration 8932 : model1 loss : 0.250493 model2 loss : 0.264785
[22:36:07.755] iteration 8933 : model1 loss : 0.305758 model2 loss : 0.344949
[22:36:08.085] iteration 8934 : model1 loss : 0.209751 model2 loss : 0.210504
[22:36:08.415] iteration 8935 : model1 loss : 0.168219 model2 loss : 0.231398
[22:36:08.742] iteration 8936 : model1 loss : 0.335087 model2 loss : 0.332618
[22:36:09.072] iteration 8937 : model1 loss : 0.240133 model2 loss : 0.278051
[22:36:09.407] iteration 8938 : model1 loss : 0.263094 model2 loss : 0.163970
[22:36:09.736] iteration 8939 : model1 loss : 0.253679 model2 loss : 0.274783
[22:36:10.064] iteration 8940 : model1 loss : 0.220987 model2 loss : 0.213826
[22:36:10.393] iteration 8941 : model1 loss : 0.202699 model2 loss : 0.285870
[22:36:10.721] iteration 8942 : model1 loss : 0.343319 model2 loss : 0.289122
[22:36:11.053] iteration 8943 : model1 loss : 0.277405 model2 loss : 0.298344
[22:36:11.391] iteration 8944 : model1 loss : 0.292209 model2 loss : 0.251159
[22:36:11.721] iteration 8945 : model1 loss : 0.261871 model2 loss : 0.238187
[22:36:12.052] iteration 8946 : model1 loss : 0.290757 model2 loss : 0.265453
[22:36:12.381] iteration 8947 : model1 loss : 0.259065 model2 loss : 0.412698
[22:36:12.712] iteration 8948 : model1 loss : 0.312375 model2 loss : 0.253100
[22:36:13.044] iteration 8949 : model1 loss : 0.362062 model2 loss : 0.361274
[22:36:13.373] iteration 8950 : model1 loss : 0.215573 model2 loss : 0.230543
[22:36:13.929] iteration 8951 : model1 loss : 0.253937 model2 loss : 0.301461
[22:36:14.259] iteration 8952 : model1 loss : 0.271246 model2 loss : 0.308122
[22:36:14.590] iteration 8953 : model1 loss : 0.257251 model2 loss : 0.206827
[22:36:14.920] iteration 8954 : model1 loss : 0.169517 model2 loss : 0.168457
[22:36:15.249] iteration 8955 : model1 loss : 0.213135 model2 loss : 0.251597
[22:36:15.580] iteration 8956 : model1 loss : 0.239136 model2 loss : 0.268686
[22:36:15.910] iteration 8957 : model1 loss : 0.193567 model2 loss : 0.273355
[22:36:16.241] iteration 8958 : model1 loss : 0.210192 model2 loss : 0.250639
[22:36:16.572] iteration 8959 : model1 loss : 0.199931 model2 loss : 0.196469
[22:36:16.902] iteration 8960 : model1 loss : 0.320414 model2 loss : 0.338237
[22:36:17.232] iteration 8961 : model1 loss : 0.334494 model2 loss : 0.347039
[22:36:17.566] iteration 8962 : model1 loss : 0.191515 model2 loss : 0.185702
[22:36:17.895] iteration 8963 : model1 loss : 0.277884 model2 loss : 0.268226
[22:36:18.227] iteration 8964 : model1 loss : 0.310023 model2 loss : 0.327754
[22:36:18.557] iteration 8965 : model1 loss : 0.178025 model2 loss : 0.193018
[22:36:18.888] iteration 8966 : model1 loss : 0.226696 model2 loss : 0.235000
[22:36:19.225] iteration 8967 : model1 loss : 0.237265 model2 loss : 0.242937
[22:36:19.564] iteration 8968 : model1 loss : 0.323363 model2 loss : 0.373981
[22:36:19.905] iteration 8969 : model1 loss : 0.221000 model2 loss : 0.230398
[22:36:20.253] iteration 8970 : model1 loss : 0.301382 model2 loss : 0.328752
[22:36:20.591] iteration 8971 : model1 loss : 0.248983 model2 loss : 0.262453
[22:36:20.938] iteration 8972 : model1 loss : 0.106119 model2 loss : 0.118212
[22:36:21.281] iteration 8973 : model1 loss : 0.282533 model2 loss : 0.282871
[22:36:21.625] iteration 8974 : model1 loss : 0.185862 model2 loss : 0.186476
[22:36:21.964] iteration 8975 : model1 loss : 0.241016 model2 loss : 0.245600
[22:36:22.310] iteration 8976 : model1 loss : 0.168500 model2 loss : 0.192364
[22:36:22.656] iteration 8977 : model1 loss : 0.280621 model2 loss : 0.331770
[22:36:23.000] iteration 8978 : model1 loss : 0.308185 model2 loss : 0.218438
[22:36:23.350] iteration 8979 : model1 loss : 0.314546 model2 loss : 0.276731
[22:36:23.698] iteration 8980 : model1 loss : 0.127245 model2 loss : 0.197709
[22:36:24.048] iteration 8981 : model1 loss : 0.304447 model2 loss : 0.250257
[22:36:24.391] iteration 8982 : model1 loss : 0.244546 model2 loss : 0.233806
[22:36:24.735] iteration 8983 : model1 loss : 0.247421 model2 loss : 0.257540
[22:36:25.080] iteration 8984 : model1 loss : 0.274637 model2 loss : 0.248161
[22:36:25.426] iteration 8985 : model1 loss : 0.247421 model2 loss : 0.285499
[22:36:25.768] iteration 8986 : model1 loss : 0.322179 model2 loss : 0.363592
[22:36:26.113] iteration 8987 : model1 loss : 0.262084 model2 loss : 0.331722
[22:36:26.460] iteration 8988 : model1 loss : 0.209040 model2 loss : 0.244840
[22:36:26.800] iteration 8989 : model1 loss : 0.186054 model2 loss : 0.221908
[22:36:27.146] iteration 8990 : model1 loss : 0.278426 model2 loss : 0.295895
[22:36:27.492] iteration 8991 : model1 loss : 0.150947 model2 loss : 0.152971
[22:36:27.838] iteration 8992 : model1 loss : 0.282624 model2 loss : 0.234075
[22:36:28.184] iteration 8993 : model1 loss : 0.336657 model2 loss : 0.284038
[22:36:28.525] iteration 8994 : model1 loss : 0.221271 model2 loss : 0.195345
[22:36:28.866] iteration 8995 : model1 loss : 0.296697 model2 loss : 0.337798
[22:36:29.206] iteration 8996 : model1 loss : 0.188584 model2 loss : 0.175032
[22:36:29.549] iteration 8997 : model1 loss : 0.335845 model2 loss : 0.400487
[22:36:29.893] iteration 8998 : model1 loss : 0.283718 model2 loss : 0.287864
[22:36:30.239] iteration 8999 : model1 loss : 0.317934 model2 loss : 0.298682
[22:36:30.585] iteration 9000 : model1 loss : 0.185295 model2 loss : 0.190765
[22:37:17.136] iteration 9000 : model1_mean_dice : 0.649814 model1_mean_hd95 : 14.439026
[22:37:51.805] iteration 9000 : model2_mean_dice : 0.474081 model2_mean_hd95 : 15.389108
[22:37:52.050] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_9000.pth
[22:37:52.093] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_9000.pth
[22:37:52.434] iteration 9001 : model1 loss : 0.313943 model2 loss : 0.290449
[22:37:52.761] iteration 9002 : model1 loss : 0.330090 model2 loss : 0.270928
[22:37:53.089] iteration 9003 : model1 loss : 0.268406 model2 loss : 0.239508
[22:37:53.421] iteration 9004 : model1 loss : 0.281880 model2 loss : 0.316449
[22:37:53.763] iteration 9005 : model1 loss : 0.280297 model2 loss : 0.325620
[22:37:54.100] iteration 9006 : model1 loss : 0.325718 model2 loss : 0.337904
[22:37:54.437] iteration 9007 : model1 loss : 0.201553 model2 loss : 0.275888
[22:37:54.774] iteration 9008 : model1 loss : 0.302666 model2 loss : 0.391100
[22:37:55.111] iteration 9009 : model1 loss : 0.105995 model2 loss : 0.196178
[22:37:55.448] iteration 9010 : model1 loss : 0.247504 model2 loss : 0.302632
[22:37:55.786] iteration 9011 : model1 loss : 0.248095 model2 loss : 0.234607
[22:37:56.123] iteration 9012 : model1 loss : 0.199872 model2 loss : 0.233725
[22:37:56.460] iteration 9013 : model1 loss : 0.152243 model2 loss : 0.177869
[22:37:56.796] iteration 9014 : model1 loss : 0.240125 model2 loss : 0.259215
[22:37:57.134] iteration 9015 : model1 loss : 0.233333 model2 loss : 0.314950
[22:37:57.469] iteration 9016 : model1 loss : 0.263768 model2 loss : 0.277362
[22:37:57.807] iteration 9017 : model1 loss : 0.279019 model2 loss : 0.292730
[22:37:58.144] iteration 9018 : model1 loss : 0.156954 model2 loss : 0.147361
[22:37:58.483] iteration 9019 : model1 loss : 0.119686 model2 loss : 0.113341
[22:37:58.819] iteration 9020 : model1 loss : 0.234202 model2 loss : 0.232684
[22:37:59.156] iteration 9021 : model1 loss : 0.258764 model2 loss : 0.278262
[22:37:59.492] iteration 9022 : model1 loss : 0.399711 model2 loss : 0.415989
[22:37:59.830] iteration 9023 : model1 loss : 0.244663 model2 loss : 0.238481
[22:38:00.166] iteration 9024 : model1 loss : 0.307392 model2 loss : 0.291656
[22:38:00.503] iteration 9025 : model1 loss : 0.230617 model2 loss : 0.338135
[22:38:00.839] iteration 9026 : model1 loss : 0.285488 model2 loss : 0.352403
[22:38:01.176] iteration 9027 : model1 loss : 0.285018 model2 loss : 0.341603
[22:38:01.513] iteration 9028 : model1 loss : 0.229878 model2 loss : 0.268634
[22:38:01.851] iteration 9029 : model1 loss : 0.288303 model2 loss : 0.303374
[22:38:02.191] iteration 9030 : model1 loss : 0.252113 model2 loss : 0.329711
[22:38:02.528] iteration 9031 : model1 loss : 0.304985 model2 loss : 0.265373
[22:38:02.866] iteration 9032 : model1 loss : 0.301341 model2 loss : 0.302068
[22:38:03.203] iteration 9033 : model1 loss : 0.143513 model2 loss : 0.161688
[22:38:03.541] iteration 9034 : model1 loss : 0.166181 model2 loss : 0.219366
[22:38:03.881] iteration 9035 : model1 loss : 0.183824 model2 loss : 0.245709
[22:38:04.222] iteration 9036 : model1 loss : 0.245316 model2 loss : 0.268525
[22:38:04.558] iteration 9037 : model1 loss : 0.249428 model2 loss : 0.249346
[22:38:04.895] iteration 9038 : model1 loss : 0.242452 model2 loss : 0.231374
[22:38:05.232] iteration 9039 : model1 loss : 0.290302 model2 loss : 0.258798
[22:38:05.573] iteration 9040 : model1 loss : 0.133967 model2 loss : 0.185900
[22:38:05.911] iteration 9041 : model1 loss : 0.254450 model2 loss : 0.243749
[22:38:06.248] iteration 9042 : model1 loss : 0.302198 model2 loss : 0.340960
[22:38:06.585] iteration 9043 : model1 loss : 0.254898 model2 loss : 0.313766
[22:38:06.921] iteration 9044 : model1 loss : 0.291924 model2 loss : 0.287370
[22:38:07.258] iteration 9045 : model1 loss : 0.206516 model2 loss : 0.252991
[22:38:07.596] iteration 9046 : model1 loss : 0.221854 model2 loss : 0.212976
[22:38:07.934] iteration 9047 : model1 loss : 0.082005 model2 loss : 0.187844
[22:38:08.276] iteration 9048 : model1 loss : 0.115092 model2 loss : 0.146818
[22:38:08.614] iteration 9049 : model1 loss : 0.334977 model2 loss : 0.389043
[22:38:08.953] iteration 9050 : model1 loss : 0.195357 model2 loss : 0.236371
[22:38:09.640] iteration 9051 : model1 loss : 0.175344 model2 loss : 0.199383
[22:38:09.977] iteration 9052 : model1 loss : 0.265782 model2 loss : 0.322682
[22:38:10.316] iteration 9053 : model1 loss : 0.256152 model2 loss : 0.218346
[22:38:10.655] iteration 9054 : model1 loss : 0.230872 model2 loss : 0.224702
[22:38:10.993] iteration 9055 : model1 loss : 0.255783 model2 loss : 0.262837
[22:38:11.330] iteration 9056 : model1 loss : 0.194047 model2 loss : 0.252285
[22:38:11.668] iteration 9057 : model1 loss : 0.339633 model2 loss : 0.347644
[22:38:12.005] iteration 9058 : model1 loss : 0.235110 model2 loss : 0.201817
[22:38:12.342] iteration 9059 : model1 loss : 0.364706 model2 loss : 0.317051
[22:38:12.679] iteration 9060 : model1 loss : 0.260573 model2 loss : 0.320033
[22:38:13.017] iteration 9061 : model1 loss : 0.156684 model2 loss : 0.249471
[22:38:13.358] iteration 9062 : model1 loss : 0.124642 model2 loss : 0.133935
[22:38:13.696] iteration 9063 : model1 loss : 0.282170 model2 loss : 0.304120
[22:38:14.048] iteration 9064 : model1 loss : 0.333175 model2 loss : 0.383963
[22:38:14.386] iteration 9065 : model1 loss : 0.307840 model2 loss : 0.268847
[22:38:14.723] iteration 9066 : model1 loss : 0.212210 model2 loss : 0.213063
[22:38:15.062] iteration 9067 : model1 loss : 0.153985 model2 loss : 0.141608
[22:38:15.400] iteration 9068 : model1 loss : 0.227169 model2 loss : 0.208937
[22:38:15.736] iteration 9069 : model1 loss : 0.105724 model2 loss : 0.209081
[22:38:16.075] iteration 9070 : model1 loss : 0.180011 model2 loss : 0.203890
[22:38:16.412] iteration 9071 : model1 loss : 0.273155 model2 loss : 0.345201
[22:38:16.750] iteration 9072 : model1 loss : 0.206595 model2 loss : 0.223131
[22:38:17.087] iteration 9073 : model1 loss : 0.484062 model2 loss : 0.299811
[22:38:17.426] iteration 9074 : model1 loss : 0.353604 model2 loss : 0.321437
[22:38:17.764] iteration 9075 : model1 loss : 0.197243 model2 loss : 0.215338
[22:38:18.102] iteration 9076 : model1 loss : 0.314871 model2 loss : 0.342676
[22:38:18.439] iteration 9077 : model1 loss : 0.260510 model2 loss : 0.367013
[22:38:18.778] iteration 9078 : model1 loss : 0.227304 model2 loss : 0.219381
[22:38:19.116] iteration 9079 : model1 loss : 0.182092 model2 loss : 0.243647
[22:38:19.454] iteration 9080 : model1 loss : 0.242204 model2 loss : 0.255272
[22:38:19.792] iteration 9081 : model1 loss : 0.173376 model2 loss : 0.232166
[22:38:20.131] iteration 9082 : model1 loss : 0.373628 model2 loss : 0.397806
[22:38:20.468] iteration 9083 : model1 loss : 0.318598 model2 loss : 0.330623
[22:38:20.806] iteration 9084 : model1 loss : 0.193821 model2 loss : 0.228583
[22:38:21.144] iteration 9085 : model1 loss : 0.173084 model2 loss : 0.206703
[22:38:21.481] iteration 9086 : model1 loss : 0.304007 model2 loss : 0.338791
[22:38:21.819] iteration 9087 : model1 loss : 0.267808 model2 loss : 0.257773
[22:38:22.156] iteration 9088 : model1 loss : 0.185624 model2 loss : 0.178174
[22:38:22.495] iteration 9089 : model1 loss : 0.111942 model2 loss : 0.228084
[22:38:22.833] iteration 9090 : model1 loss : 0.264854 model2 loss : 0.280408
[22:38:23.171] iteration 9091 : model1 loss : 0.342273 model2 loss : 0.362534
[22:38:23.508] iteration 9092 : model1 loss : 0.322263 model2 loss : 0.353838
[22:38:23.846] iteration 9093 : model1 loss : 0.165448 model2 loss : 0.172397
[22:38:24.185] iteration 9094 : model1 loss : 0.199215 model2 loss : 0.220299
[22:38:24.523] iteration 9095 : model1 loss : 0.209553 model2 loss : 0.267679
[22:38:24.861] iteration 9096 : model1 loss : 0.221645 model2 loss : 0.266023
[22:38:25.199] iteration 9097 : model1 loss : 0.290864 model2 loss : 0.245929
[22:38:25.538] iteration 9098 : model1 loss : 0.403135 model2 loss : 0.440001
[22:38:25.880] iteration 9099 : model1 loss : 0.228836 model2 loss : 0.249051
[22:38:26.218] iteration 9100 : model1 loss : 0.297123 model2 loss : 0.265041
[22:38:26.818] iteration 9101 : model1 loss : 0.325954 model2 loss : 0.292093
[22:38:27.148] iteration 9102 : model1 loss : 0.257945 model2 loss : 0.307670
[22:38:27.477] iteration 9103 : model1 loss : 0.272200 model2 loss : 0.281034
[22:38:27.808] iteration 9104 : model1 loss : 0.353946 model2 loss : 0.351569
[22:38:28.138] iteration 9105 : model1 loss : 0.203121 model2 loss : 0.220004
[22:38:28.468] iteration 9106 : model1 loss : 0.265737 model2 loss : 0.308633
[22:38:28.800] iteration 9107 : model1 loss : 0.172111 model2 loss : 0.254162
[22:38:29.132] iteration 9108 : model1 loss : 0.258775 model2 loss : 0.286390
[22:38:29.463] iteration 9109 : model1 loss : 0.288814 model2 loss : 0.294663
[22:38:29.793] iteration 9110 : model1 loss : 0.300186 model2 loss : 0.356674
[22:38:30.122] iteration 9111 : model1 loss : 0.196854 model2 loss : 0.192990
[22:38:30.455] iteration 9112 : model1 loss : 0.260718 model2 loss : 0.282288
[22:38:30.785] iteration 9113 : model1 loss : 0.171108 model2 loss : 0.253294
[22:38:31.114] iteration 9114 : model1 loss : 0.347656 model2 loss : 0.210753
[22:38:31.441] iteration 9115 : model1 loss : 0.252163 model2 loss : 0.269505
[22:38:31.770] iteration 9116 : model1 loss : 0.336378 model2 loss : 0.308046
[22:38:32.101] iteration 9117 : model1 loss : 0.192702 model2 loss : 0.303567
[22:38:32.430] iteration 9118 : model1 loss : 0.234534 model2 loss : 0.263392
[22:38:32.759] iteration 9119 : model1 loss : 0.219905 model2 loss : 0.269846
[22:38:33.089] iteration 9120 : model1 loss : 0.279161 model2 loss : 0.278878
[22:38:33.419] iteration 9121 : model1 loss : 0.217802 model2 loss : 0.242539
[22:38:33.747] iteration 9122 : model1 loss : 0.290338 model2 loss : 0.330593
[22:38:34.080] iteration 9123 : model1 loss : 0.354559 model2 loss : 0.427143
[22:38:34.411] iteration 9124 : model1 loss : 0.256309 model2 loss : 0.291138
[22:38:34.743] iteration 9125 : model1 loss : 0.165367 model2 loss : 0.164525
[22:38:35.073] iteration 9126 : model1 loss : 0.212489 model2 loss : 0.303539
[22:38:35.404] iteration 9127 : model1 loss : 0.194534 model2 loss : 0.286751
[22:38:35.734] iteration 9128 : model1 loss : 0.291831 model2 loss : 0.203228
[22:38:36.063] iteration 9129 : model1 loss : 0.322852 model2 loss : 0.282677
[22:38:36.393] iteration 9130 : model1 loss : 0.241183 model2 loss : 0.257655
[22:38:36.724] iteration 9131 : model1 loss : 0.246561 model2 loss : 0.234829
[22:38:37.055] iteration 9132 : model1 loss : 0.293530 model2 loss : 0.357866
[22:38:37.387] iteration 9133 : model1 loss : 0.339256 model2 loss : 0.324588
[22:38:37.720] iteration 9134 : model1 loss : 0.204334 model2 loss : 0.182504
[22:38:38.055] iteration 9135 : model1 loss : 0.354727 model2 loss : 0.281809
[22:38:38.387] iteration 9136 : model1 loss : 0.244215 model2 loss : 0.248339
[22:38:38.718] iteration 9137 : model1 loss : 0.210326 model2 loss : 0.237457
[22:38:39.050] iteration 9138 : model1 loss : 0.319514 model2 loss : 0.318933
[22:38:39.384] iteration 9139 : model1 loss : 0.291090 model2 loss : 0.248868
[22:38:39.716] iteration 9140 : model1 loss : 0.221309 model2 loss : 0.277779
[22:38:40.047] iteration 9141 : model1 loss : 0.295484 model2 loss : 0.341771
[22:38:40.379] iteration 9142 : model1 loss : 0.214608 model2 loss : 0.220110
[22:38:40.710] iteration 9143 : model1 loss : 0.296947 model2 loss : 0.289836
[22:38:41.045] iteration 9144 : model1 loss : 0.294220 model2 loss : 0.315604
[22:38:41.378] iteration 9145 : model1 loss : 0.438758 model2 loss : 0.428340
[22:38:41.709] iteration 9146 : model1 loss : 0.169003 model2 loss : 0.194120
[22:38:42.041] iteration 9147 : model1 loss : 0.287464 model2 loss : 0.268523
[22:38:42.372] iteration 9148 : model1 loss : 0.277758 model2 loss : 0.252775
[22:38:42.705] iteration 9149 : model1 loss : 0.351844 model2 loss : 0.367411
[22:38:43.035] iteration 9150 : model1 loss : 0.136310 model2 loss : 0.178131
[22:38:43.604] iteration 9151 : model1 loss : 0.325972 model2 loss : 0.260527
[22:38:43.939] iteration 9152 : model1 loss : 0.352226 model2 loss : 0.329262
[22:38:44.272] iteration 9153 : model1 loss : 0.263430 model2 loss : 0.256907
[22:38:44.605] iteration 9154 : model1 loss : 0.306947 model2 loss : 0.342966
[22:38:44.940] iteration 9155 : model1 loss : 0.331989 model2 loss : 0.307695
[22:38:45.281] iteration 9156 : model1 loss : 0.384577 model2 loss : 0.402701
[22:38:45.612] iteration 9157 : model1 loss : 0.196812 model2 loss : 0.196756
[22:38:45.943] iteration 9158 : model1 loss : 0.306068 model2 loss : 0.339180
[22:38:46.272] iteration 9159 : model1 loss : 0.301506 model2 loss : 0.352239
[22:38:46.603] iteration 9160 : model1 loss : 0.276540 model2 loss : 0.252667
[22:38:46.937] iteration 9161 : model1 loss : 0.217061 model2 loss : 0.214258
[22:38:47.267] iteration 9162 : model1 loss : 0.182003 model2 loss : 0.180702
[22:38:47.598] iteration 9163 : model1 loss : 0.215056 model2 loss : 0.243379
[22:38:47.931] iteration 9164 : model1 loss : 0.120062 model2 loss : 0.197238
[22:38:48.261] iteration 9165 : model1 loss : 0.197823 model2 loss : 0.157094
[22:38:48.594] iteration 9166 : model1 loss : 0.212706 model2 loss : 0.211387
[22:38:48.927] iteration 9167 : model1 loss : 0.126097 model2 loss : 0.138420
[22:38:49.260] iteration 9168 : model1 loss : 0.264937 model2 loss : 0.275745
[22:38:49.594] iteration 9169 : model1 loss : 0.270784 model2 loss : 0.289639
[22:38:49.927] iteration 9170 : model1 loss : 0.109560 model2 loss : 0.125099
[22:38:50.260] iteration 9171 : model1 loss : 0.293479 model2 loss : 0.361568
[22:38:50.597] iteration 9172 : model1 loss : 0.218603 model2 loss : 0.233637
[22:38:50.931] iteration 9173 : model1 loss : 0.193830 model2 loss : 0.245467
[22:38:51.269] iteration 9174 : model1 loss : 0.309019 model2 loss : 0.286655
[22:38:51.601] iteration 9175 : model1 loss : 0.137330 model2 loss : 0.164225
[22:38:51.931] iteration 9176 : model1 loss : 0.164213 model2 loss : 0.172870
[22:38:52.261] iteration 9177 : model1 loss : 0.204949 model2 loss : 0.221994
[22:38:52.591] iteration 9178 : model1 loss : 0.281971 model2 loss : 0.292479
[22:38:52.921] iteration 9179 : model1 loss : 0.281899 model2 loss : 0.325289
[22:38:53.252] iteration 9180 : model1 loss : 0.252616 model2 loss : 0.265857
[22:38:53.582] iteration 9181 : model1 loss : 0.353232 model2 loss : 0.426652
[22:38:53.910] iteration 9182 : model1 loss : 0.273002 model2 loss : 0.352292
[22:38:54.239] iteration 9183 : model1 loss : 0.241527 model2 loss : 0.243723
[22:38:54.567] iteration 9184 : model1 loss : 0.326693 model2 loss : 0.302306
[22:38:54.896] iteration 9185 : model1 loss : 0.242864 model2 loss : 0.291813
[22:38:55.222] iteration 9186 : model1 loss : 0.248197 model2 loss : 0.272651
[22:38:55.548] iteration 9187 : model1 loss : 0.342531 model2 loss : 0.261939
[22:38:55.878] iteration 9188 : model1 loss : 0.401480 model2 loss : 0.401281
[22:38:56.207] iteration 9189 : model1 loss : 0.181369 model2 loss : 0.185361
[22:38:56.548] iteration 9190 : model1 loss : 0.205362 model2 loss : 0.259902
[22:38:56.890] iteration 9191 : model1 loss : 0.274915 model2 loss : 0.264063
[22:38:57.220] iteration 9192 : model1 loss : 0.252228 model2 loss : 0.289811
[22:38:57.551] iteration 9193 : model1 loss : 0.356613 model2 loss : 0.345139
[22:38:57.881] iteration 9194 : model1 loss : 0.258423 model2 loss : 0.255146
[22:38:58.214] iteration 9195 : model1 loss : 0.220903 model2 loss : 0.253883
[22:38:58.546] iteration 9196 : model1 loss : 0.202451 model2 loss : 0.273487
[22:38:58.875] iteration 9197 : model1 loss : 0.240861 model2 loss : 0.239553
[22:38:59.204] iteration 9198 : model1 loss : 0.259370 model2 loss : 0.273244
[22:38:59.542] iteration 9199 : model1 loss : 0.207219 model2 loss : 0.231958
[22:38:59.872] iteration 9200 : model1 loss : 0.306074 model2 loss : 0.330058
[22:39:00.451] iteration 9201 : model1 loss : 0.221337 model2 loss : 0.239868
[22:39:00.781] iteration 9202 : model1 loss : 0.218245 model2 loss : 0.251708
[22:39:01.111] iteration 9203 : model1 loss : 0.282892 model2 loss : 0.310684
[22:39:01.440] iteration 9204 : model1 loss : 0.260487 model2 loss : 0.262429
[22:39:01.771] iteration 9205 : model1 loss : 0.146161 model2 loss : 0.148654
[22:39:02.101] iteration 9206 : model1 loss : 0.268532 model2 loss : 0.242108
[22:39:02.429] iteration 9207 : model1 loss : 0.298636 model2 loss : 0.252654
[22:39:02.771] iteration 9208 : model1 loss : 0.251745 model2 loss : 0.207130
[22:39:03.102] iteration 9209 : model1 loss : 0.215019 model2 loss : 0.224319
[22:39:03.433] iteration 9210 : model1 loss : 0.205011 model2 loss : 0.198298
[22:39:03.771] iteration 9211 : model1 loss : 0.188754 model2 loss : 0.209665
[22:39:04.110] iteration 9212 : model1 loss : 0.216707 model2 loss : 0.212510
[22:39:04.448] iteration 9213 : model1 loss : 0.225080 model2 loss : 0.290333
[22:39:04.785] iteration 9214 : model1 loss : 0.212348 model2 loss : 0.242903
[22:39:05.134] iteration 9215 : model1 loss : 0.299214 model2 loss : 0.341434
[22:39:05.480] iteration 9216 : model1 loss : 0.257738 model2 loss : 0.306331
[22:39:05.822] iteration 9217 : model1 loss : 0.267082 model2 loss : 0.304473
[22:39:06.164] iteration 9218 : model1 loss : 0.217383 model2 loss : 0.196123
[22:39:06.504] iteration 9219 : model1 loss : 0.317337 model2 loss : 0.317730
[22:39:06.851] iteration 9220 : model1 loss : 0.161762 model2 loss : 0.153631
[22:39:07.195] iteration 9221 : model1 loss : 0.199999 model2 loss : 0.237648
[22:39:07.532] iteration 9222 : model1 loss : 0.212155 model2 loss : 0.211086
[22:39:07.870] iteration 9223 : model1 loss : 0.275333 model2 loss : 0.416658
[22:39:08.208] iteration 9224 : model1 loss : 0.122577 model2 loss : 0.148321
[22:39:08.551] iteration 9225 : model1 loss : 0.261340 model2 loss : 0.281458
[22:39:08.895] iteration 9226 : model1 loss : 0.213122 model2 loss : 0.256525
[22:39:09.226] iteration 9227 : model1 loss : 0.289024 model2 loss : 0.319988
[22:39:09.559] iteration 9228 : model1 loss : 0.182653 model2 loss : 0.179169
[22:39:09.891] iteration 9229 : model1 loss : 0.133145 model2 loss : 0.167801
[22:39:10.224] iteration 9230 : model1 loss : 0.231623 model2 loss : 0.195819
[22:39:10.556] iteration 9231 : model1 loss : 0.208905 model2 loss : 0.292742
[22:39:10.886] iteration 9232 : model1 loss : 0.186001 model2 loss : 0.217046
[22:39:11.218] iteration 9233 : model1 loss : 0.190086 model2 loss : 0.236960
[22:39:11.547] iteration 9234 : model1 loss : 0.230016 model2 loss : 0.244961
[22:39:11.877] iteration 9235 : model1 loss : 0.211287 model2 loss : 0.216893
[22:39:12.211] iteration 9236 : model1 loss : 0.212699 model2 loss : 0.214037
[22:39:12.542] iteration 9237 : model1 loss : 0.253427 model2 loss : 0.199853
[22:39:12.871] iteration 9238 : model1 loss : 0.133754 model2 loss : 0.273160
[22:39:13.200] iteration 9239 : model1 loss : 0.235282 model2 loss : 0.231651
[22:39:13.530] iteration 9240 : model1 loss : 0.185498 model2 loss : 0.184833
[22:39:13.863] iteration 9241 : model1 loss : 0.344051 model2 loss : 0.392522
[22:39:14.195] iteration 9242 : model1 loss : 0.188542 model2 loss : 0.235267
[22:39:14.527] iteration 9243 : model1 loss : 0.202259 model2 loss : 0.226222
[22:39:14.860] iteration 9244 : model1 loss : 0.287263 model2 loss : 0.270767
[22:39:15.192] iteration 9245 : model1 loss : 0.359496 model2 loss : 0.392059
[22:39:15.524] iteration 9246 : model1 loss : 0.237912 model2 loss : 0.247501
[22:39:15.855] iteration 9247 : model1 loss : 0.270316 model2 loss : 0.270050
[22:39:16.188] iteration 9248 : model1 loss : 0.274298 model2 loss : 0.325501
[22:39:16.519] iteration 9249 : model1 loss : 0.187559 model2 loss : 0.202464
[22:39:16.850] iteration 9250 : model1 loss : 0.277219 model2 loss : 0.306167
[22:39:17.451] iteration 9251 : model1 loss : 0.211279 model2 loss : 0.195868
[22:39:17.784] iteration 9252 : model1 loss : 0.223234 model2 loss : 0.251502
[22:39:18.129] iteration 9253 : model1 loss : 0.271952 model2 loss : 0.341946
[22:39:18.474] iteration 9254 : model1 loss : 0.279919 model2 loss : 0.261430
[22:39:18.819] iteration 9255 : model1 loss : 0.153480 model2 loss : 0.137440
[22:39:19.166] iteration 9256 : model1 loss : 0.329607 model2 loss : 0.356480
[22:39:19.512] iteration 9257 : model1 loss : 0.208858 model2 loss : 0.295423
[22:39:19.852] iteration 9258 : model1 loss : 0.270178 model2 loss : 0.271343
[22:39:20.194] iteration 9259 : model1 loss : 0.201828 model2 loss : 0.267186
[22:39:20.534] iteration 9260 : model1 loss : 0.268080 model2 loss : 0.277059
[22:39:20.873] iteration 9261 : model1 loss : 0.235600 model2 loss : 0.216442
[22:39:21.217] iteration 9262 : model1 loss : 0.343504 model2 loss : 0.332304
[22:39:21.557] iteration 9263 : model1 loss : 0.205962 model2 loss : 0.198938
[22:39:21.896] iteration 9264 : model1 loss : 0.226440 model2 loss : 0.276055
[22:39:22.235] iteration 9265 : model1 loss : 0.196643 model2 loss : 0.202845
[22:39:23.202] iteration 9266 : model1 loss : 0.120189 model2 loss : 0.135260
[22:39:23.541] iteration 9267 : model1 loss : 0.217352 model2 loss : 0.240218
[22:39:23.880] iteration 9268 : model1 loss : 0.237585 model2 loss : 0.302799
[22:39:24.225] iteration 9269 : model1 loss : 0.254705 model2 loss : 0.270733
[22:39:24.567] iteration 9270 : model1 loss : 0.153549 model2 loss : 0.189493
[22:39:24.911] iteration 9271 : model1 loss : 0.123498 model2 loss : 0.195860
[22:39:25.255] iteration 9272 : model1 loss : 0.239219 model2 loss : 0.241110
[22:39:25.595] iteration 9273 : model1 loss : 0.234639 model2 loss : 0.293013
[22:39:25.938] iteration 9274 : model1 loss : 0.160408 model2 loss : 0.227458
[22:39:26.282] iteration 9275 : model1 loss : 0.292782 model2 loss : 0.262315
[22:39:26.626] iteration 9276 : model1 loss : 0.278854 model2 loss : 0.337096
[22:39:26.971] iteration 9277 : model1 loss : 0.342198 model2 loss : 0.300805
[22:39:27.338] iteration 9278 : model1 loss : 0.331434 model2 loss : 0.326234
[22:39:27.679] iteration 9279 : model1 loss : 0.130733 model2 loss : 0.158076
[22:39:28.029] iteration 9280 : model1 loss : 0.250677 model2 loss : 0.358550
[22:39:28.375] iteration 9281 : model1 loss : 0.190587 model2 loss : 0.185991
[22:39:28.715] iteration 9282 : model1 loss : 0.266467 model2 loss : 0.304082
[22:39:29.065] iteration 9283 : model1 loss : 0.411477 model2 loss : 0.398026
[22:39:29.409] iteration 9284 : model1 loss : 0.345217 model2 loss : 0.345600
[22:39:29.756] iteration 9285 : model1 loss : 0.260681 model2 loss : 0.295464
[22:39:30.096] iteration 9286 : model1 loss : 0.266061 model2 loss : 0.274741
[22:39:30.442] iteration 9287 : model1 loss : 0.301435 model2 loss : 0.303902
[22:39:30.788] iteration 9288 : model1 loss : 0.203745 model2 loss : 0.271948
[22:39:31.127] iteration 9289 : model1 loss : 0.323542 model2 loss : 0.313296
[22:39:31.472] iteration 9290 : model1 loss : 0.229965 model2 loss : 0.202143
[22:39:31.811] iteration 9291 : model1 loss : 0.213965 model2 loss : 0.204014
[22:39:32.149] iteration 9292 : model1 loss : 0.256200 model2 loss : 0.272477
[22:39:32.490] iteration 9293 : model1 loss : 0.194120 model2 loss : 0.191130
[22:39:32.829] iteration 9294 : model1 loss : 0.274412 model2 loss : 0.292870
[22:39:33.173] iteration 9295 : model1 loss : 0.293819 model2 loss : 0.325683
[22:39:33.515] iteration 9296 : model1 loss : 0.207159 model2 loss : 0.222678
[22:39:33.856] iteration 9297 : model1 loss : 0.238965 model2 loss : 0.251852
[22:39:34.201] iteration 9298 : model1 loss : 0.198885 model2 loss : 0.282792
[22:39:34.541] iteration 9299 : model1 loss : 0.359510 model2 loss : 0.291560
[22:39:34.883] iteration 9300 : model1 loss : 0.291571 model2 loss : 0.283796
[22:39:35.558] iteration 9301 : model1 loss : 0.199673 model2 loss : 0.223711
[22:39:35.903] iteration 9302 : model1 loss : 0.252775 model2 loss : 0.267812
[22:39:36.243] iteration 9303 : model1 loss : 0.132594 model2 loss : 0.220366
[22:39:36.587] iteration 9304 : model1 loss : 0.197396 model2 loss : 0.191013
[22:39:36.928] iteration 9305 : model1 loss : 0.199628 model2 loss : 0.237474
[22:39:37.273] iteration 9306 : model1 loss : 0.233013 model2 loss : 0.285577
[22:39:37.613] iteration 9307 : model1 loss : 0.249138 model2 loss : 0.275310
[22:39:37.954] iteration 9308 : model1 loss : 0.260072 model2 loss : 0.235886
[22:39:38.297] iteration 9309 : model1 loss : 0.271995 model2 loss : 0.269547
[22:39:38.643] iteration 9310 : model1 loss : 0.221405 model2 loss : 0.169006
[22:39:38.985] iteration 9311 : model1 loss : 0.288878 model2 loss : 0.326842
[22:39:39.328] iteration 9312 : model1 loss : 0.175872 model2 loss : 0.178917
[22:39:39.670] iteration 9313 : model1 loss : 0.264744 model2 loss : 0.275106
[22:39:40.016] iteration 9314 : model1 loss : 0.225714 model2 loss : 0.248650
[22:39:40.372] iteration 9315 : model1 loss : 0.242955 model2 loss : 0.320287
[22:39:40.716] iteration 9316 : model1 loss : 0.208000 model2 loss : 0.232089
[22:39:41.056] iteration 9317 : model1 loss : 0.184155 model2 loss : 0.214821
[22:39:41.397] iteration 9318 : model1 loss : 0.117120 model2 loss : 0.236727
[22:39:41.737] iteration 9319 : model1 loss : 0.097856 model2 loss : 0.110770
[22:39:42.075] iteration 9320 : model1 loss : 0.214821 model2 loss : 0.289316
[22:39:42.415] iteration 9321 : model1 loss : 0.304727 model2 loss : 0.349534
[22:39:42.762] iteration 9322 : model1 loss : 0.122168 model2 loss : 0.149229
[22:39:43.106] iteration 9323 : model1 loss : 0.253024 model2 loss : 0.282407
[22:39:43.451] iteration 9324 : model1 loss : 0.284713 model2 loss : 0.316456
[22:39:43.791] iteration 9325 : model1 loss : 0.225514 model2 loss : 0.210159
[22:39:44.136] iteration 9326 : model1 loss : 0.251671 model2 loss : 0.220505
[22:39:44.477] iteration 9327 : model1 loss : 0.151335 model2 loss : 0.193065
[22:39:44.822] iteration 9328 : model1 loss : 0.198273 model2 loss : 0.161840
[22:39:45.162] iteration 9329 : model1 loss : 0.267606 model2 loss : 0.286867
[22:39:45.507] iteration 9330 : model1 loss : 0.271029 model2 loss : 0.323142
[22:39:45.851] iteration 9331 : model1 loss : 0.239406 model2 loss : 0.240688
[22:39:46.192] iteration 9332 : model1 loss : 0.197604 model2 loss : 0.200965
[22:39:46.537] iteration 9333 : model1 loss : 0.215773 model2 loss : 0.227487
[22:39:46.878] iteration 9334 : model1 loss : 0.226690 model2 loss : 0.244848
[22:39:47.223] iteration 9335 : model1 loss : 0.182387 model2 loss : 0.196034
[22:39:47.561] iteration 9336 : model1 loss : 0.227769 model2 loss : 0.266203
[22:39:47.908] iteration 9337 : model1 loss : 0.313933 model2 loss : 0.393758
[22:39:48.255] iteration 9338 : model1 loss : 0.193576 model2 loss : 0.200100
[22:39:48.595] iteration 9339 : model1 loss : 0.228243 model2 loss : 0.271724
[22:39:48.936] iteration 9340 : model1 loss : 0.257723 model2 loss : 0.290123
[22:39:49.282] iteration 9341 : model1 loss : 0.203709 model2 loss : 0.302854
[22:39:49.628] iteration 9342 : model1 loss : 0.346200 model2 loss : 0.348573
[22:39:49.972] iteration 9343 : model1 loss : 0.221944 model2 loss : 0.234061
[22:39:50.312] iteration 9344 : model1 loss : 0.225690 model2 loss : 0.199570
[22:39:50.654] iteration 9345 : model1 loss : 0.142394 model2 loss : 0.154697
[22:39:50.993] iteration 9346 : model1 loss : 0.106901 model2 loss : 0.106038
[22:39:51.336] iteration 9347 : model1 loss : 0.186518 model2 loss : 0.260742
[22:39:51.682] iteration 9348 : model1 loss : 0.226344 model2 loss : 0.208704
[22:39:52.022] iteration 9349 : model1 loss : 0.224695 model2 loss : 0.294875
[22:39:52.366] iteration 9350 : model1 loss : 0.307594 model2 loss : 0.339844
[22:39:53.001] iteration 9351 : model1 loss : 0.313674 model2 loss : 0.260412
[22:39:53.344] iteration 9352 : model1 loss : 0.197500 model2 loss : 0.189182
[22:39:53.685] iteration 9353 : model1 loss : 0.230237 model2 loss : 0.233966
[22:39:54.025] iteration 9354 : model1 loss : 0.231135 model2 loss : 0.188704
[22:39:54.364] iteration 9355 : model1 loss : 0.194673 model2 loss : 0.233794
[22:39:54.709] iteration 9356 : model1 loss : 0.390028 model2 loss : 0.347096
[22:39:55.049] iteration 9357 : model1 loss : 0.325898 model2 loss : 0.321830
[22:39:55.394] iteration 9358 : model1 loss : 0.240359 model2 loss : 0.283680
[22:39:55.739] iteration 9359 : model1 loss : 0.232244 model2 loss : 0.207089
[22:39:56.079] iteration 9360 : model1 loss : 0.176009 model2 loss : 0.192928
[22:39:56.423] iteration 9361 : model1 loss : 0.230897 model2 loss : 0.270312
[22:39:56.765] iteration 9362 : model1 loss : 0.233544 model2 loss : 0.283810
[22:39:57.110] iteration 9363 : model1 loss : 0.266395 model2 loss : 0.265565
[22:39:57.450] iteration 9364 : model1 loss : 0.184352 model2 loss : 0.249532
[22:39:57.795] iteration 9365 : model1 loss : 0.195325 model2 loss : 0.201545
[22:39:58.138] iteration 9366 : model1 loss : 0.277061 model2 loss : 0.314946
[22:39:58.483] iteration 9367 : model1 loss : 0.271111 model2 loss : 0.276093
[22:39:58.822] iteration 9368 : model1 loss : 0.266265 model2 loss : 0.209725
[22:39:59.167] iteration 9369 : model1 loss : 0.208405 model2 loss : 0.219619
[22:39:59.512] iteration 9370 : model1 loss : 0.248899 model2 loss : 0.224531
[22:39:59.851] iteration 9371 : model1 loss : 0.200731 model2 loss : 0.269820
[22:40:00.198] iteration 9372 : model1 loss : 0.301915 model2 loss : 0.305089
[22:40:00.543] iteration 9373 : model1 loss : 0.209373 model2 loss : 0.267852
[22:40:00.889] iteration 9374 : model1 loss : 0.163316 model2 loss : 0.254962
[22:40:01.233] iteration 9375 : model1 loss : 0.251499 model2 loss : 0.285395
[22:40:01.573] iteration 9376 : model1 loss : 0.307619 model2 loss : 0.345169
[22:40:01.917] iteration 9377 : model1 loss : 0.323345 model2 loss : 0.339377
[22:40:02.257] iteration 9378 : model1 loss : 0.187925 model2 loss : 0.197517
[22:40:02.601] iteration 9379 : model1 loss : 0.173527 model2 loss : 0.196147
[22:40:02.945] iteration 9380 : model1 loss : 0.217159 model2 loss : 0.254146
[22:40:03.285] iteration 9381 : model1 loss : 0.215333 model2 loss : 0.266337
[22:40:03.630] iteration 9382 : model1 loss : 0.248521 model2 loss : 0.237019
[22:40:03.975] iteration 9383 : model1 loss : 0.134957 model2 loss : 0.135635
[22:40:04.320] iteration 9384 : model1 loss : 0.219379 model2 loss : 0.242127
[22:40:04.666] iteration 9385 : model1 loss : 0.312825 model2 loss : 0.318800
[22:40:05.013] iteration 9386 : model1 loss : 0.250398 model2 loss : 0.246651
[22:40:05.357] iteration 9387 : model1 loss : 0.162643 model2 loss : 0.165687
[22:40:05.703] iteration 9388 : model1 loss : 0.349053 model2 loss : 0.377032
[22:40:06.049] iteration 9389 : model1 loss : 0.120008 model2 loss : 0.116176
[22:40:06.395] iteration 9390 : model1 loss : 0.309421 model2 loss : 0.379559
[22:40:06.736] iteration 9391 : model1 loss : 0.191997 model2 loss : 0.210145
[22:40:07.074] iteration 9392 : model1 loss : 0.281380 model2 loss : 0.208734
[22:40:07.411] iteration 9393 : model1 loss : 0.204896 model2 loss : 0.195533
[22:40:07.750] iteration 9394 : model1 loss : 0.223040 model2 loss : 0.272427
[22:40:08.088] iteration 9395 : model1 loss : 0.131623 model2 loss : 0.156831
[22:40:08.425] iteration 9396 : model1 loss : 0.255778 model2 loss : 0.279459
[22:40:08.763] iteration 9397 : model1 loss : 0.254346 model2 loss : 0.268204
[22:40:09.103] iteration 9398 : model1 loss : 0.354669 model2 loss : 0.341485
[22:40:09.441] iteration 9399 : model1 loss : 0.289458 model2 loss : 0.317178
[22:40:09.778] iteration 9400 : model1 loss : 0.186790 model2 loss : 0.195755
[22:40:10.422] iteration 9401 : model1 loss : 0.238197 model2 loss : 0.251141
[22:40:10.761] iteration 9402 : model1 loss : 0.333011 model2 loss : 0.306741
[22:40:11.098] iteration 9403 : model1 loss : 0.165127 model2 loss : 0.205762
[22:40:11.437] iteration 9404 : model1 loss : 0.111373 model2 loss : 0.166059
[22:40:11.774] iteration 9405 : model1 loss : 0.324348 model2 loss : 0.327991
[22:40:12.113] iteration 9406 : model1 loss : 0.242949 model2 loss : 0.282791
[22:40:12.450] iteration 9407 : model1 loss : 0.175815 model2 loss : 0.150849
[22:40:12.788] iteration 9408 : model1 loss : 0.207607 model2 loss : 0.205831
[22:40:13.129] iteration 9409 : model1 loss : 0.338810 model2 loss : 0.321935
[22:40:13.467] iteration 9410 : model1 loss : 0.307330 model2 loss : 0.329222
[22:40:13.804] iteration 9411 : model1 loss : 0.261443 model2 loss : 0.271022
[22:40:14.141] iteration 9412 : model1 loss : 0.172493 model2 loss : 0.225016
[22:40:14.481] iteration 9413 : model1 loss : 0.317434 model2 loss : 0.309926
[22:40:14.819] iteration 9414 : model1 loss : 0.274480 model2 loss : 0.248198
[22:40:15.156] iteration 9415 : model1 loss : 0.201456 model2 loss : 0.265412
[22:40:15.497] iteration 9416 : model1 loss : 0.201726 model2 loss : 0.227884
[22:40:15.834] iteration 9417 : model1 loss : 0.215758 model2 loss : 0.199768
[22:40:16.172] iteration 9418 : model1 loss : 0.214371 model2 loss : 0.187469
[22:40:16.507] iteration 9419 : model1 loss : 0.182225 model2 loss : 0.230234
[22:40:16.841] iteration 9420 : model1 loss : 0.302185 model2 loss : 0.303351
[22:40:17.180] iteration 9421 : model1 loss : 0.309781 model2 loss : 0.242651
[22:40:17.513] iteration 9422 : model1 loss : 0.234079 model2 loss : 0.223393
[22:40:17.850] iteration 9423 : model1 loss : 0.279493 model2 loss : 0.245241
[22:40:18.185] iteration 9424 : model1 loss : 0.207218 model2 loss : 0.242718
[22:40:18.523] iteration 9425 : model1 loss : 0.310223 model2 loss : 0.350832
[22:40:18.857] iteration 9426 : model1 loss : 0.225866 model2 loss : 0.222371
[22:40:19.190] iteration 9427 : model1 loss : 0.274414 model2 loss : 0.294171
[22:40:19.524] iteration 9428 : model1 loss : 0.248884 model2 loss : 0.340783
[22:40:19.860] iteration 9429 : model1 loss : 0.193684 model2 loss : 0.212820
[22:40:20.194] iteration 9430 : model1 loss : 0.164657 model2 loss : 0.227441
[22:40:20.528] iteration 9431 : model1 loss : 0.124170 model2 loss : 0.173339
[22:40:20.860] iteration 9432 : model1 loss : 0.223813 model2 loss : 0.218624
[22:40:21.194] iteration 9433 : model1 loss : 0.219817 model2 loss : 0.276772
[22:40:21.527] iteration 9434 : model1 loss : 0.307076 model2 loss : 0.301136
[22:40:21.860] iteration 9435 : model1 loss : 0.229313 model2 loss : 0.248460
[22:40:22.193] iteration 9436 : model1 loss : 0.304182 model2 loss : 0.226724
[22:40:22.529] iteration 9437 : model1 loss : 0.225867 model2 loss : 0.239774
[22:40:22.860] iteration 9438 : model1 loss : 0.263777 model2 loss : 0.285064
[22:40:23.193] iteration 9439 : model1 loss : 0.264175 model2 loss : 0.316528
[22:40:23.532] iteration 9440 : model1 loss : 0.148643 model2 loss : 0.124918
[22:40:23.870] iteration 9441 : model1 loss : 0.177713 model2 loss : 0.160022
[22:40:24.204] iteration 9442 : model1 loss : 0.288800 model2 loss : 0.352568
[22:40:24.537] iteration 9443 : model1 loss : 0.171510 model2 loss : 0.198096
[22:40:24.873] iteration 9444 : model1 loss : 0.223778 model2 loss : 0.232004
[22:40:25.208] iteration 9445 : model1 loss : 0.246947 model2 loss : 0.324804
[22:40:25.545] iteration 9446 : model1 loss : 0.204518 model2 loss : 0.186204
[22:40:25.878] iteration 9447 : model1 loss : 0.206876 model2 loss : 0.347038
[22:40:26.213] iteration 9448 : model1 loss : 0.193066 model2 loss : 0.201893
[22:40:26.548] iteration 9449 : model1 loss : 0.310831 model2 loss : 0.292223
[22:40:26.883] iteration 9450 : model1 loss : 0.174550 model2 loss : 0.163106
[22:40:27.487] iteration 9451 : model1 loss : 0.257788 model2 loss : 0.295498
[22:40:27.829] iteration 9452 : model1 loss : 0.319995 model2 loss : 0.325949
[22:40:28.165] iteration 9453 : model1 loss : 0.210834 model2 loss : 0.222025
[22:40:28.498] iteration 9454 : model1 loss : 0.163441 model2 loss : 0.186518
[22:40:28.833] iteration 9455 : model1 loss : 0.259780 model2 loss : 0.265968
[22:40:29.169] iteration 9456 : model1 loss : 0.197918 model2 loss : 0.202624
[22:40:29.503] iteration 9457 : model1 loss : 0.281076 model2 loss : 0.262936
[22:40:29.836] iteration 9458 : model1 loss : 0.240857 model2 loss : 0.243592
[22:40:30.170] iteration 9459 : model1 loss : 0.217289 model2 loss : 0.229539
[22:40:30.506] iteration 9460 : model1 loss : 0.172624 model2 loss : 0.207025
[22:40:30.839] iteration 9461 : model1 loss : 0.301818 model2 loss : 0.268681
[22:40:31.194] iteration 9462 : model1 loss : 0.277902 model2 loss : 0.370855
[22:40:31.531] iteration 9463 : model1 loss : 0.244795 model2 loss : 0.269409
[22:40:31.869] iteration 9464 : model1 loss : 0.262617 model2 loss : 0.252914
[22:40:32.207] iteration 9465 : model1 loss : 0.224729 model2 loss : 0.221602
[22:40:32.542] iteration 9466 : model1 loss : 0.278571 model2 loss : 0.282454
[22:40:32.879] iteration 9467 : model1 loss : 0.158255 model2 loss : 0.232740
[22:40:33.214] iteration 9468 : model1 loss : 0.294421 model2 loss : 0.333769
[22:40:33.547] iteration 9469 : model1 loss : 0.295583 model2 loss : 0.263119
[22:40:33.881] iteration 9470 : model1 loss : 0.281268 model2 loss : 0.261492
[22:40:34.215] iteration 9471 : model1 loss : 0.145671 model2 loss : 0.142342
[22:40:34.550] iteration 9472 : model1 loss : 0.135595 model2 loss : 0.212926
[22:40:34.885] iteration 9473 : model1 loss : 0.214065 model2 loss : 0.248709
[22:40:35.218] iteration 9474 : model1 loss : 0.283902 model2 loss : 0.275264
[22:40:35.553] iteration 9475 : model1 loss : 0.229475 model2 loss : 0.191627
[22:40:35.887] iteration 9476 : model1 loss : 0.272890 model2 loss : 0.281353
[22:40:36.227] iteration 9477 : model1 loss : 0.215964 model2 loss : 0.123497
[22:40:36.565] iteration 9478 : model1 loss : 0.230406 model2 loss : 0.253848
[22:40:36.896] iteration 9479 : model1 loss : 0.207532 model2 loss : 0.247795
[22:40:37.233] iteration 9480 : model1 loss : 0.265249 model2 loss : 0.270293
[22:40:37.570] iteration 9481 : model1 loss : 0.295125 model2 loss : 0.323267
[22:40:37.906] iteration 9482 : model1 loss : 0.251916 model2 loss : 0.285870
[22:40:38.243] iteration 9483 : model1 loss : 0.183199 model2 loss : 0.194322
[22:40:38.579] iteration 9484 : model1 loss : 0.176864 model2 loss : 0.154978
[22:40:38.913] iteration 9485 : model1 loss : 0.267129 model2 loss : 0.269893
[22:40:39.249] iteration 9486 : model1 loss : 0.313089 model2 loss : 0.355138
[22:40:39.583] iteration 9487 : model1 loss : 0.257454 model2 loss : 0.255349
[22:40:39.920] iteration 9488 : model1 loss : 0.202376 model2 loss : 0.194647
[22:40:40.255] iteration 9489 : model1 loss : 0.248623 model2 loss : 0.287424
[22:40:40.588] iteration 9490 : model1 loss : 0.226450 model2 loss : 0.205452
[22:40:40.924] iteration 9491 : model1 loss : 0.287817 model2 loss : 0.303299
[22:40:41.258] iteration 9492 : model1 loss : 0.157144 model2 loss : 0.154534
[22:40:41.592] iteration 9493 : model1 loss : 0.308526 model2 loss : 0.322584
[22:40:41.925] iteration 9494 : model1 loss : 0.232282 model2 loss : 0.208375
[22:40:42.257] iteration 9495 : model1 loss : 0.265604 model2 loss : 0.301621
[22:40:42.590] iteration 9496 : model1 loss : 0.145391 model2 loss : 0.150388
[22:40:42.923] iteration 9497 : model1 loss : 0.338064 model2 loss : 0.301695
[22:40:43.257] iteration 9498 : model1 loss : 0.271198 model2 loss : 0.222845
[22:40:43.591] iteration 9499 : model1 loss : 0.174266 model2 loss : 0.227433
[22:40:43.926] iteration 9500 : model1 loss : 0.247885 model2 loss : 0.281496
[22:40:44.569] iteration 9501 : model1 loss : 0.126579 model2 loss : 0.136304
[22:40:44.902] iteration 9502 : model1 loss : 0.169357 model2 loss : 0.262179
[22:40:45.234] iteration 9503 : model1 loss : 0.126417 model2 loss : 0.189844
[22:40:45.568] iteration 9504 : model1 loss : 0.193517 model2 loss : 0.229555
[22:40:45.900] iteration 9505 : model1 loss : 0.281186 model2 loss : 0.360498
[22:40:46.233] iteration 9506 : model1 loss : 0.170500 model2 loss : 0.188066
[22:40:46.567] iteration 9507 : model1 loss : 0.212769 model2 loss : 0.268915
[22:40:46.901] iteration 9508 : model1 loss : 0.231787 model2 loss : 0.217995
[22:40:47.234] iteration 9509 : model1 loss : 0.268843 model2 loss : 0.358068
[22:40:47.567] iteration 9510 : model1 loss : 0.289799 model2 loss : 0.225300
[22:40:47.899] iteration 9511 : model1 loss : 0.174795 model2 loss : 0.218381
[22:40:48.234] iteration 9512 : model1 loss : 0.220601 model2 loss : 0.245495
[22:40:48.566] iteration 9513 : model1 loss : 0.229639 model2 loss : 0.292303
[22:40:48.905] iteration 9514 : model1 loss : 0.322970 model2 loss : 0.385155
[22:40:49.237] iteration 9515 : model1 loss : 0.230392 model2 loss : 0.268950
[22:40:49.572] iteration 9516 : model1 loss : 0.135859 model2 loss : 0.201799
[22:40:49.909] iteration 9517 : model1 loss : 0.188163 model2 loss : 0.225998
[22:40:50.247] iteration 9518 : model1 loss : 0.112416 model2 loss : 0.145592
[22:40:50.580] iteration 9519 : model1 loss : 0.207313 model2 loss : 0.255987
[22:40:50.912] iteration 9520 : model1 loss : 0.295937 model2 loss : 0.289001
[22:40:51.247] iteration 9521 : model1 loss : 0.248118 model2 loss : 0.303873
[22:40:51.583] iteration 9522 : model1 loss : 0.178722 model2 loss : 0.174521
[22:40:51.921] iteration 9523 : model1 loss : 0.208785 model2 loss : 0.244414
[22:40:52.255] iteration 9524 : model1 loss : 0.270970 model2 loss : 0.320917
[22:40:52.587] iteration 9525 : model1 loss : 0.237007 model2 loss : 0.174288
[22:40:52.924] iteration 9526 : model1 loss : 0.273859 model2 loss : 0.313179
[22:40:53.263] iteration 9527 : model1 loss : 0.295988 model2 loss : 0.311960
[22:40:53.595] iteration 9528 : model1 loss : 0.314341 model2 loss : 0.389803
[22:40:53.927] iteration 9529 : model1 loss : 0.141391 model2 loss : 0.182112
[22:40:54.261] iteration 9530 : model1 loss : 0.205106 model2 loss : 0.243942
[22:40:54.597] iteration 9531 : model1 loss : 0.171645 model2 loss : 0.150933
[22:40:54.931] iteration 9532 : model1 loss : 0.239442 model2 loss : 0.215179
[22:40:55.265] iteration 9533 : model1 loss : 0.281911 model2 loss : 0.261927
[22:40:55.599] iteration 9534 : model1 loss : 0.276259 model2 loss : 0.298501
[22:40:55.936] iteration 9535 : model1 loss : 0.254586 model2 loss : 0.262307
[22:40:56.268] iteration 9536 : model1 loss : 0.283015 model2 loss : 0.305664
[22:40:56.603] iteration 9537 : model1 loss : 0.231625 model2 loss : 0.376720
[22:40:56.935] iteration 9538 : model1 loss : 0.163742 model2 loss : 0.179794
[22:40:57.268] iteration 9539 : model1 loss : 0.297899 model2 loss : 0.301145
[22:40:57.603] iteration 9540 : model1 loss : 0.183957 model2 loss : 0.222645
[22:40:57.935] iteration 9541 : model1 loss : 0.101049 model2 loss : 0.142277
[22:40:58.269] iteration 9542 : model1 loss : 0.204476 model2 loss : 0.246178
[22:40:58.601] iteration 9543 : model1 loss : 0.239762 model2 loss : 0.220368
[22:40:58.937] iteration 9544 : model1 loss : 0.209821 model2 loss : 0.333883
[22:40:59.272] iteration 9545 : model1 loss : 0.150610 model2 loss : 0.197777
[22:40:59.614] iteration 9546 : model1 loss : 0.185833 model2 loss : 0.230941
[22:40:59.954] iteration 9547 : model1 loss : 0.274613 model2 loss : 0.323972
[22:41:00.296] iteration 9548 : model1 loss : 0.239998 model2 loss : 0.299170
[22:41:00.632] iteration 9549 : model1 loss : 0.227175 model2 loss : 0.256920
[22:41:00.968] iteration 9550 : model1 loss : 0.214612 model2 loss : 0.202855
[22:41:01.624] iteration 9551 : model1 loss : 0.277830 model2 loss : 0.219273
[22:41:01.962] iteration 9552 : model1 loss : 0.235869 model2 loss : 0.236020
[22:41:02.295] iteration 9553 : model1 loss : 0.261246 model2 loss : 0.130365
[22:41:02.632] iteration 9554 : model1 loss : 0.261751 model2 loss : 0.278331
[22:41:02.968] iteration 9555 : model1 loss : 0.241329 model2 loss : 0.308343
[22:41:03.300] iteration 9556 : model1 loss : 0.308217 model2 loss : 0.323152
[22:41:03.634] iteration 9557 : model1 loss : 0.208095 model2 loss : 0.231977
[22:41:03.971] iteration 9558 : model1 loss : 0.169253 model2 loss : 0.203493
[22:41:04.307] iteration 9559 : model1 loss : 0.189988 model2 loss : 0.245767
[22:41:04.643] iteration 9560 : model1 loss : 0.259005 model2 loss : 0.314804
[22:41:04.980] iteration 9561 : model1 loss : 0.284437 model2 loss : 0.289855
[22:41:05.318] iteration 9562 : model1 loss : 0.251600 model2 loss : 0.286556
[22:41:05.655] iteration 9563 : model1 loss : 0.197671 model2 loss : 0.191525
[22:41:05.992] iteration 9564 : model1 loss : 0.252106 model2 loss : 0.301949
[22:41:06.329] iteration 9565 : model1 loss : 0.203741 model2 loss : 0.244762
[22:41:06.666] iteration 9566 : model1 loss : 0.212271 model2 loss : 0.290529
[22:41:07.002] iteration 9567 : model1 loss : 0.279743 model2 loss : 0.315680
[22:41:07.338] iteration 9568 : model1 loss : 0.189144 model2 loss : 0.231949
[22:41:07.675] iteration 9569 : model1 loss : 0.261444 model2 loss : 0.211966
[22:41:08.012] iteration 9570 : model1 loss : 0.240242 model2 loss : 0.268806
[22:41:08.348] iteration 9571 : model1 loss : 0.255686 model2 loss : 0.367095
[22:41:08.685] iteration 9572 : model1 loss : 0.181250 model2 loss : 0.171976
[22:41:09.017] iteration 9573 : model1 loss : 0.227602 model2 loss : 0.225136
[22:41:09.357] iteration 9574 : model1 loss : 0.203947 model2 loss : 0.239164
[22:41:09.694] iteration 9575 : model1 loss : 0.342842 model2 loss : 0.370222
[22:41:10.030] iteration 9576 : model1 loss : 0.182253 model2 loss : 0.269808
[22:41:10.368] iteration 9577 : model1 loss : 0.279553 model2 loss : 0.299264
[22:41:10.704] iteration 9578 : model1 loss : 0.375579 model2 loss : 0.425047
[22:41:11.040] iteration 9579 : model1 loss : 0.322315 model2 loss : 0.305615
[22:41:11.376] iteration 9580 : model1 loss : 0.260761 model2 loss : 0.301706
[22:41:11.713] iteration 9581 : model1 loss : 0.241138 model2 loss : 0.268190
[22:41:12.049] iteration 9582 : model1 loss : 0.202711 model2 loss : 0.233322
[22:41:12.386] iteration 9583 : model1 loss : 0.200126 model2 loss : 0.238061
[22:41:12.723] iteration 9584 : model1 loss : 0.162437 model2 loss : 0.188955
[22:41:13.061] iteration 9585 : model1 loss : 0.297894 model2 loss : 0.270083
[22:41:13.397] iteration 9586 : model1 loss : 0.207382 model2 loss : 0.261939
[22:41:13.730] iteration 9587 : model1 loss : 0.280052 model2 loss : 0.310044
[22:41:14.062] iteration 9588 : model1 loss : 0.224185 model2 loss : 0.208382
[22:41:14.394] iteration 9589 : model1 loss : 0.117429 model2 loss : 0.179907
[22:41:14.730] iteration 9590 : model1 loss : 0.201650 model2 loss : 0.212727
[22:41:15.062] iteration 9591 : model1 loss : 0.111204 model2 loss : 0.192360
[22:41:15.395] iteration 9592 : model1 loss : 0.159648 model2 loss : 0.201289
[22:41:15.724] iteration 9593 : model1 loss : 0.248533 model2 loss : 0.229313
[22:41:16.053] iteration 9594 : model1 loss : 0.270098 model2 loss : 0.268958
[22:41:16.381] iteration 9595 : model1 loss : 0.231290 model2 loss : 0.266790
[22:41:16.710] iteration 9596 : model1 loss : 0.171501 model2 loss : 0.248363
[22:41:17.041] iteration 9597 : model1 loss : 0.328155 model2 loss : 0.256839
[22:41:17.376] iteration 9598 : model1 loss : 0.332212 model2 loss : 0.341659
[22:41:17.709] iteration 9599 : model1 loss : 0.268094 model2 loss : 0.355454
[22:41:18.041] iteration 9600 : model1 loss : 0.333646 model2 loss : 0.322820
[22:41:18.654] iteration 9601 : model1 loss : 0.210928 model2 loss : 0.269602
[22:41:18.986] iteration 9602 : model1 loss : 0.193530 model2 loss : 0.265002
[22:41:19.318] iteration 9603 : model1 loss : 0.294744 model2 loss : 0.296062
[22:41:19.649] iteration 9604 : model1 loss : 0.203859 model2 loss : 0.192280
[22:41:19.979] iteration 9605 : model1 loss : 0.270341 model2 loss : 0.284538
[22:41:20.307] iteration 9606 : model1 loss : 0.261799 model2 loss : 0.259408
[22:41:20.636] iteration 9607 : model1 loss : 0.213937 model2 loss : 0.248976
[22:41:20.964] iteration 9608 : model1 loss : 0.202443 model2 loss : 0.249069
[22:41:21.293] iteration 9609 : model1 loss : 0.284042 model2 loss : 0.266340
[22:41:21.622] iteration 9610 : model1 loss : 0.116446 model2 loss : 0.133184
[22:41:21.951] iteration 9611 : model1 loss : 0.139480 model2 loss : 0.190145
[22:41:22.282] iteration 9612 : model1 loss : 0.176388 model2 loss : 0.194174
[22:41:22.612] iteration 9613 : model1 loss : 0.236301 model2 loss : 0.220636
[22:41:22.941] iteration 9614 : model1 loss : 0.097787 model2 loss : 0.117494
[22:41:23.273] iteration 9615 : model1 loss : 0.238674 model2 loss : 0.230401
[22:41:23.606] iteration 9616 : model1 loss : 0.092937 model2 loss : 0.135410
[22:41:23.937] iteration 9617 : model1 loss : 0.247841 model2 loss : 0.278007
[22:41:24.267] iteration 9618 : model1 loss : 0.225357 model2 loss : 0.232916
[22:41:24.597] iteration 9619 : model1 loss : 0.282835 model2 loss : 0.323315
[22:41:24.928] iteration 9620 : model1 loss : 0.328133 model2 loss : 0.314635
[22:41:25.260] iteration 9621 : model1 loss : 0.281322 model2 loss : 0.296446
[22:41:25.589] iteration 9622 : model1 loss : 0.327057 model2 loss : 0.361580
[22:41:25.919] iteration 9623 : model1 loss : 0.228053 model2 loss : 0.229383
[22:41:26.247] iteration 9624 : model1 loss : 0.226823 model2 loss : 0.302012
[22:41:26.576] iteration 9625 : model1 loss : 0.214232 model2 loss : 0.232049
[22:41:26.904] iteration 9626 : model1 loss : 0.198599 model2 loss : 0.247350
[22:41:27.235] iteration 9627 : model1 loss : 0.246189 model2 loss : 0.261594
[22:41:27.564] iteration 9628 : model1 loss : 0.403657 model2 loss : 0.401353
[22:41:27.896] iteration 9629 : model1 loss : 0.353939 model2 loss : 0.323531
[22:41:28.227] iteration 9630 : model1 loss : 0.191171 model2 loss : 0.227105
[22:41:28.558] iteration 9631 : model1 loss : 0.253610 model2 loss : 0.265029
[22:41:28.891] iteration 9632 : model1 loss : 0.203885 model2 loss : 0.222153
[22:41:29.221] iteration 9633 : model1 loss : 0.316203 model2 loss : 0.230029
[22:41:29.550] iteration 9634 : model1 loss : 0.175462 model2 loss : 0.209936
[22:41:29.878] iteration 9635 : model1 loss : 0.187678 model2 loss : 0.164572
[22:41:30.207] iteration 9636 : model1 loss : 0.298676 model2 loss : 0.284412
[22:41:30.540] iteration 9637 : model1 loss : 0.321923 model2 loss : 0.269983
[22:41:30.870] iteration 9638 : model1 loss : 0.268756 model2 loss : 0.303772
[22:41:31.199] iteration 9639 : model1 loss : 0.205265 model2 loss : 0.222270
[22:41:31.529] iteration 9640 : model1 loss : 0.252511 model2 loss : 0.197966
[22:41:31.865] iteration 9641 : model1 loss : 0.248823 model2 loss : 0.297471
[22:41:32.200] iteration 9642 : model1 loss : 0.227621 model2 loss : 0.271657
[22:41:32.532] iteration 9643 : model1 loss : 0.214912 model2 loss : 0.254787
[22:41:32.863] iteration 9644 : model1 loss : 0.315843 model2 loss : 0.324893
[22:41:33.193] iteration 9645 : model1 loss : 0.301111 model2 loss : 0.323894
[22:41:33.521] iteration 9646 : model1 loss : 0.280393 model2 loss : 0.205038
[22:41:33.849] iteration 9647 : model1 loss : 0.203353 model2 loss : 0.184072
[22:41:34.178] iteration 9648 : model1 loss : 0.275200 model2 loss : 0.318093
[22:41:34.517] iteration 9649 : model1 loss : 0.267597 model2 loss : 0.211628
[22:41:34.849] iteration 9650 : model1 loss : 0.224775 model2 loss : 0.322530
[22:41:35.406] iteration 9651 : model1 loss : 0.268072 model2 loss : 0.292620
[22:41:35.743] iteration 9652 : model1 loss : 0.186243 model2 loss : 0.177921
[22:41:36.079] iteration 9653 : model1 loss : 0.258605 model2 loss : 0.280780
[22:41:36.418] iteration 9654 : model1 loss : 0.346918 model2 loss : 0.369119
[22:41:36.754] iteration 9655 : model1 loss : 0.267328 model2 loss : 0.185828
[22:41:37.093] iteration 9656 : model1 loss : 0.257468 model2 loss : 0.353208
[22:41:37.431] iteration 9657 : model1 loss : 0.220553 model2 loss : 0.275584
[22:41:37.768] iteration 9658 : model1 loss : 0.264390 model2 loss : 0.247612
[22:41:38.105] iteration 9659 : model1 loss : 0.205640 model2 loss : 0.244494
[22:41:38.442] iteration 9660 : model1 loss : 0.334099 model2 loss : 0.335664
[22:41:38.780] iteration 9661 : model1 loss : 0.217835 model2 loss : 0.221615
[22:41:39.121] iteration 9662 : model1 loss : 0.265050 model2 loss : 0.283753
[22:41:39.474] iteration 9663 : model1 loss : 0.248159 model2 loss : 0.272147
[22:41:39.813] iteration 9664 : model1 loss : 0.362506 model2 loss : 0.387052
[22:41:40.150] iteration 9665 : model1 loss : 0.200204 model2 loss : 0.230093
[22:41:40.487] iteration 9666 : model1 loss : 0.202915 model2 loss : 0.227115
[22:41:40.829] iteration 9667 : model1 loss : 0.293720 model2 loss : 0.320700
[22:41:41.165] iteration 9668 : model1 loss : 0.200233 model2 loss : 0.225670
[22:41:41.503] iteration 9669 : model1 loss : 0.188736 model2 loss : 0.292894
[22:41:41.840] iteration 9670 : model1 loss : 0.104134 model2 loss : 0.112609
[22:41:42.176] iteration 9671 : model1 loss : 0.204719 model2 loss : 0.250162
[22:41:42.514] iteration 9672 : model1 loss : 0.319127 model2 loss : 0.309780
[22:41:42.852] iteration 9673 : model1 loss : 0.248624 model2 loss : 0.274275
[22:41:43.190] iteration 9674 : model1 loss : 0.286437 model2 loss : 0.302800
[22:41:43.527] iteration 9675 : model1 loss : 0.350740 model2 loss : 0.322859
[22:41:43.865] iteration 9676 : model1 loss : 0.267146 model2 loss : 0.291491
[22:41:44.207] iteration 9677 : model1 loss : 0.240129 model2 loss : 0.278021
[22:41:44.545] iteration 9678 : model1 loss : 0.296181 model2 loss : 0.328138
[22:41:44.883] iteration 9679 : model1 loss : 0.278322 model2 loss : 0.353117
[22:41:45.222] iteration 9680 : model1 loss : 0.152916 model2 loss : 0.270067
[22:41:45.559] iteration 9681 : model1 loss : 0.153154 model2 loss : 0.171910
[22:41:45.897] iteration 9682 : model1 loss : 0.291216 model2 loss : 0.296854
[22:41:46.234] iteration 9683 : model1 loss : 0.231977 model2 loss : 0.234081
[22:41:46.571] iteration 9684 : model1 loss : 0.366918 model2 loss : 0.363324
[22:41:46.918] iteration 9685 : model1 loss : 0.321507 model2 loss : 0.226787
[22:41:47.254] iteration 9686 : model1 loss : 0.199001 model2 loss : 0.260705
[22:41:47.592] iteration 9687 : model1 loss : 0.269011 model2 loss : 0.282492
[22:41:47.929] iteration 9688 : model1 loss : 0.248054 model2 loss : 0.283321
[22:41:48.266] iteration 9689 : model1 loss : 0.301986 model2 loss : 0.321637
[22:41:48.603] iteration 9690 : model1 loss : 0.332759 model2 loss : 0.370018
[22:41:48.940] iteration 9691 : model1 loss : 0.400301 model2 loss : 0.410453
[22:41:49.278] iteration 9692 : model1 loss : 0.311818 model2 loss : 0.359812
[22:41:49.616] iteration 9693 : model1 loss : 0.218615 model2 loss : 0.247669
[22:41:49.953] iteration 9694 : model1 loss : 0.264572 model2 loss : 0.300478
[22:41:50.291] iteration 9695 : model1 loss : 0.251728 model2 loss : 0.247934
[22:41:50.629] iteration 9696 : model1 loss : 0.231730 model2 loss : 0.239883
[22:41:50.966] iteration 9697 : model1 loss : 0.332701 model2 loss : 0.329151
[22:41:51.303] iteration 9698 : model1 loss : 0.307152 model2 loss : 0.248800
[22:41:51.641] iteration 9699 : model1 loss : 0.199347 model2 loss : 0.222797
[22:41:51.978] iteration 9700 : model1 loss : 0.213762 model2 loss : 0.236775
[22:41:52.620] iteration 9701 : model1 loss : 0.220360 model2 loss : 0.200978
[22:41:52.957] iteration 9702 : model1 loss : 0.224821 model2 loss : 0.226406
[22:41:53.294] iteration 9703 : model1 loss : 0.204614 model2 loss : 0.297387
[22:41:53.632] iteration 9704 : model1 loss : 0.253790 model2 loss : 0.278080
[22:41:53.969] iteration 9705 : model1 loss : 0.265179 model2 loss : 0.280028
[22:41:54.306] iteration 9706 : model1 loss : 0.270544 model2 loss : 0.339401
[22:41:54.644] iteration 9707 : model1 loss : 0.151161 model2 loss : 0.173033
[22:41:54.982] iteration 9708 : model1 loss : 0.283871 model2 loss : 0.306610
[22:41:55.322] iteration 9709 : model1 loss : 0.228272 model2 loss : 0.273306
[22:41:55.658] iteration 9710 : model1 loss : 0.241691 model2 loss : 0.258983
[22:41:55.995] iteration 9711 : model1 loss : 0.157062 model2 loss : 0.193926
[22:41:56.333] iteration 9712 : model1 loss : 0.247021 model2 loss : 0.247706
[22:41:56.670] iteration 9713 : model1 loss : 0.289882 model2 loss : 0.321980
[22:41:57.008] iteration 9714 : model1 loss : 0.171494 model2 loss : 0.219568
[22:41:57.342] iteration 9715 : model1 loss : 0.235275 model2 loss : 0.185053
[22:41:57.679] iteration 9716 : model1 loss : 0.297622 model2 loss : 0.314652
[22:41:58.017] iteration 9717 : model1 loss : 0.337664 model2 loss : 0.342861
[22:41:58.356] iteration 9718 : model1 loss : 0.266397 model2 loss : 0.265800
[22:41:58.692] iteration 9719 : model1 loss : 0.198346 model2 loss : 0.237477
[22:41:59.029] iteration 9720 : model1 loss : 0.279018 model2 loss : 0.318895
[22:41:59.367] iteration 9721 : model1 loss : 0.269733 model2 loss : 0.277025
[22:41:59.703] iteration 9722 : model1 loss : 0.281287 model2 loss : 0.283401
[22:42:00.042] iteration 9723 : model1 loss : 0.276986 model2 loss : 0.312426
[22:42:00.379] iteration 9724 : model1 loss : 0.226953 model2 loss : 0.275102
[22:42:00.716] iteration 9725 : model1 loss : 0.213567 model2 loss : 0.290675
[22:42:01.053] iteration 9726 : model1 loss : 0.369904 model2 loss : 0.336920
[22:42:01.390] iteration 9727 : model1 loss : 0.220510 model2 loss : 0.240628
[22:42:02.010] iteration 9728 : model1 loss : 0.192671 model2 loss : 0.204809
[22:42:02.346] iteration 9729 : model1 loss : 0.233408 model2 loss : 0.236809
[22:42:02.684] iteration 9730 : model1 loss : 0.219625 model2 loss : 0.233560
[22:42:03.021] iteration 9731 : model1 loss : 0.132931 model2 loss : 0.155381
[22:42:03.359] iteration 9732 : model1 loss : 0.256314 model2 loss : 0.270181
[22:42:03.702] iteration 9733 : model1 loss : 0.265709 model2 loss : 0.256567
[22:42:04.039] iteration 9734 : model1 loss : 0.190179 model2 loss : 0.206704
[22:42:04.378] iteration 9735 : model1 loss : 0.251161 model2 loss : 0.320442
[22:42:04.717] iteration 9736 : model1 loss : 0.309715 model2 loss : 0.324882
[22:42:05.054] iteration 9737 : model1 loss : 0.285429 model2 loss : 0.320025
[22:42:05.393] iteration 9738 : model1 loss : 0.209816 model2 loss : 0.228913
[22:42:05.730] iteration 9739 : model1 loss : 0.121993 model2 loss : 0.181223
[22:42:06.071] iteration 9740 : model1 loss : 0.306590 model2 loss : 0.331906
[22:42:06.409] iteration 9741 : model1 loss : 0.279314 model2 loss : 0.307968
[22:42:06.746] iteration 9742 : model1 loss : 0.284341 model2 loss : 0.258514
[22:42:07.084] iteration 9743 : model1 loss : 0.234709 model2 loss : 0.350163
[22:42:07.422] iteration 9744 : model1 loss : 0.218389 model2 loss : 0.224227
[22:42:07.759] iteration 9745 : model1 loss : 0.274649 model2 loss : 0.283600
[22:42:08.098] iteration 9746 : model1 loss : 0.252336 model2 loss : 0.340235
[22:42:08.436] iteration 9747 : model1 loss : 0.272882 model2 loss : 0.251628
[22:42:08.773] iteration 9748 : model1 loss : 0.238035 model2 loss : 0.233259
[22:42:09.112] iteration 9749 : model1 loss : 0.266978 model2 loss : 0.301761
[22:42:09.450] iteration 9750 : model1 loss : 0.094243 model2 loss : 0.087533
[22:42:10.078] iteration 9751 : model1 loss : 0.329897 model2 loss : 0.354058
[22:42:10.418] iteration 9752 : model1 loss : 0.165642 model2 loss : 0.199030
[22:42:10.750] iteration 9753 : model1 loss : 0.253820 model2 loss : 0.281823
[22:42:11.087] iteration 9754 : model1 loss : 0.186375 model2 loss : 0.202113
[22:42:11.424] iteration 9755 : model1 loss : 0.269296 model2 loss : 0.276992
[22:42:11.762] iteration 9756 : model1 loss : 0.218478 model2 loss : 0.247478
[22:42:12.099] iteration 9757 : model1 loss : 0.222381 model2 loss : 0.266165
[22:42:12.437] iteration 9758 : model1 loss : 0.177901 model2 loss : 0.209539
[22:42:12.775] iteration 9759 : model1 loss : 0.231169 model2 loss : 0.255930
[22:42:13.115] iteration 9760 : model1 loss : 0.213812 model2 loss : 0.228450
[22:42:13.452] iteration 9761 : model1 loss : 0.249216 model2 loss : 0.244246
[22:42:13.794] iteration 9762 : model1 loss : 0.190511 model2 loss : 0.216730
[22:42:14.124] iteration 9763 : model1 loss : 0.265670 model2 loss : 0.265513
[22:42:14.455] iteration 9764 : model1 loss : 0.345683 model2 loss : 0.302472
[22:42:14.785] iteration 9765 : model1 loss : 0.180191 model2 loss : 0.191982
[22:42:15.114] iteration 9766 : model1 loss : 0.129602 model2 loss : 0.149354
[22:42:15.443] iteration 9767 : model1 loss : 0.338703 model2 loss : 0.348631
[22:42:15.772] iteration 9768 : model1 loss : 0.197971 model2 loss : 0.241750
[22:42:16.102] iteration 9769 : model1 loss : 0.296398 model2 loss : 0.331542
[22:42:16.432] iteration 9770 : model1 loss : 0.273737 model2 loss : 0.325713
[22:42:16.762] iteration 9771 : model1 loss : 0.339962 model2 loss : 0.238394
[22:42:17.092] iteration 9772 : model1 loss : 0.182639 model2 loss : 0.238791
[22:42:17.421] iteration 9773 : model1 loss : 0.299851 model2 loss : 0.327435
[22:42:17.750] iteration 9774 : model1 loss : 0.193627 model2 loss : 0.158971
[22:42:18.078] iteration 9775 : model1 loss : 0.174077 model2 loss : 0.202921
[22:42:18.405] iteration 9776 : model1 loss : 0.240868 model2 loss : 0.290428
[22:42:18.734] iteration 9777 : model1 loss : 0.135026 model2 loss : 0.248320
[22:42:19.062] iteration 9778 : model1 loss : 0.258077 model2 loss : 0.271461
[22:42:19.387] iteration 9779 : model1 loss : 0.170150 model2 loss : 0.173609
[22:42:19.715] iteration 9780 : model1 loss : 0.284241 model2 loss : 0.298307
[22:42:20.042] iteration 9781 : model1 loss : 0.186255 model2 loss : 0.216067
[22:42:20.370] iteration 9782 : model1 loss : 0.338744 model2 loss : 0.362947
[22:42:20.698] iteration 9783 : model1 loss : 0.320841 model2 loss : 0.359292
[22:42:21.025] iteration 9784 : model1 loss : 0.205280 model2 loss : 0.185323
[22:42:21.354] iteration 9785 : model1 loss : 0.267158 model2 loss : 0.266467
[22:42:21.682] iteration 9786 : model1 loss : 0.143041 model2 loss : 0.210838
[22:42:22.009] iteration 9787 : model1 loss : 0.275845 model2 loss : 0.299338
[22:42:22.338] iteration 9788 : model1 loss : 0.276998 model2 loss : 0.291602
[22:42:22.666] iteration 9789 : model1 loss : 0.237246 model2 loss : 0.255028
[22:42:22.993] iteration 9790 : model1 loss : 0.290148 model2 loss : 0.280291
[22:42:23.322] iteration 9791 : model1 loss : 0.160769 model2 loss : 0.278507
[22:42:23.650] iteration 9792 : model1 loss : 0.218663 model2 loss : 0.271213
[22:42:23.979] iteration 9793 : model1 loss : 0.298588 model2 loss : 0.320684
[22:42:24.310] iteration 9794 : model1 loss : 0.236181 model2 loss : 0.243499
[22:42:24.637] iteration 9795 : model1 loss : 0.319507 model2 loss : 0.345769
[22:42:24.965] iteration 9796 : model1 loss : 0.089993 model2 loss : 0.133590
[22:42:25.294] iteration 9797 : model1 loss : 0.354589 model2 loss : 0.282266
[22:42:25.622] iteration 9798 : model1 loss : 0.332293 model2 loss : 0.335271
[22:42:25.951] iteration 9799 : model1 loss : 0.265977 model2 loss : 0.263710
[22:42:26.280] iteration 9800 : model1 loss : 0.293933 model2 loss : 0.236832
[22:42:26.815] iteration 9801 : model1 loss : 0.286505 model2 loss : 0.302344
[22:42:27.144] iteration 9802 : model1 loss : 0.388099 model2 loss : 0.414335
[22:42:27.471] iteration 9803 : model1 loss : 0.167453 model2 loss : 0.187119
[22:42:27.799] iteration 9804 : model1 loss : 0.271199 model2 loss : 0.253267
[22:42:28.126] iteration 9805 : model1 loss : 0.263570 model2 loss : 0.282408
[22:42:28.454] iteration 9806 : model1 loss : 0.276129 model2 loss : 0.250360
[22:42:28.784] iteration 9807 : model1 loss : 0.120619 model2 loss : 0.152320
[22:42:29.118] iteration 9808 : model1 loss : 0.246878 model2 loss : 0.361812
[22:42:29.457] iteration 9809 : model1 loss : 0.267198 model2 loss : 0.339325
[22:42:29.797] iteration 9810 : model1 loss : 0.136996 model2 loss : 0.176227
[22:42:30.790] iteration 9811 : model1 loss : 0.327032 model2 loss : 0.324417
[22:42:31.120] iteration 9812 : model1 loss : 0.137739 model2 loss : 0.161633
[22:42:31.450] iteration 9813 : model1 loss : 0.221650 model2 loss : 0.253743
[22:42:31.780] iteration 9814 : model1 loss : 0.183108 model2 loss : 0.193321
[22:42:32.107] iteration 9815 : model1 loss : 0.342147 model2 loss : 0.361480
[22:42:32.434] iteration 9816 : model1 loss : 0.278817 model2 loss : 0.331053
[22:42:32.762] iteration 9817 : model1 loss : 0.150521 model2 loss : 0.151359
[22:42:33.093] iteration 9818 : model1 loss : 0.246073 model2 loss : 0.295348
[22:42:33.422] iteration 9819 : model1 loss : 0.316816 model2 loss : 0.321582
[22:42:33.748] iteration 9820 : model1 loss : 0.195455 model2 loss : 0.247216
[22:42:34.075] iteration 9821 : model1 loss : 0.259682 model2 loss : 0.233900
[22:42:34.402] iteration 9822 : model1 loss : 0.239609 model2 loss : 0.263869
[22:42:34.727] iteration 9823 : model1 loss : 0.270151 model2 loss : 0.289347
[22:42:35.052] iteration 9824 : model1 loss : 0.166615 model2 loss : 0.210223
[22:42:35.376] iteration 9825 : model1 loss : 0.417992 model2 loss : 0.364176
[22:42:35.702] iteration 9826 : model1 loss : 0.235178 model2 loss : 0.270918
[22:42:36.028] iteration 9827 : model1 loss : 0.189420 model2 loss : 0.367872
[22:42:36.357] iteration 9828 : model1 loss : 0.191903 model2 loss : 0.237616
[22:42:36.684] iteration 9829 : model1 loss : 0.345782 model2 loss : 0.378525
[22:42:37.009] iteration 9830 : model1 loss : 0.209468 model2 loss : 0.265972
[22:42:37.335] iteration 9831 : model1 loss : 0.198728 model2 loss : 0.238045
[22:42:37.660] iteration 9832 : model1 loss : 0.186852 model2 loss : 0.300955
[22:42:37.988] iteration 9833 : model1 loss : 0.230030 model2 loss : 0.266733
[22:42:38.314] iteration 9834 : model1 loss : 0.205795 model2 loss : 0.259501
[22:42:38.639] iteration 9835 : model1 loss : 0.167541 model2 loss : 0.189527
[22:42:38.965] iteration 9836 : model1 loss : 0.192541 model2 loss : 0.208833
[22:42:39.290] iteration 9837 : model1 loss : 0.270374 model2 loss : 0.290717
[22:42:39.616] iteration 9838 : model1 loss : 0.253303 model2 loss : 0.354227
[22:42:39.942] iteration 9839 : model1 loss : 0.294140 model2 loss : 0.308503
[22:42:40.268] iteration 9840 : model1 loss : 0.296596 model2 loss : 0.348578
[22:42:40.592] iteration 9841 : model1 loss : 0.291504 model2 loss : 0.279755
[22:42:40.922] iteration 9842 : model1 loss : 0.301515 model2 loss : 0.299205
[22:42:41.251] iteration 9843 : model1 loss : 0.138731 model2 loss : 0.175467
[22:42:41.579] iteration 9844 : model1 loss : 0.247496 model2 loss : 0.266349
[22:42:41.905] iteration 9845 : model1 loss : 0.143143 model2 loss : 0.132825
[22:42:42.231] iteration 9846 : model1 loss : 0.251835 model2 loss : 0.270655
[22:42:42.556] iteration 9847 : model1 loss : 0.260288 model2 loss : 0.329753
[22:42:42.882] iteration 9848 : model1 loss : 0.174039 model2 loss : 0.173478
[22:42:43.207] iteration 9849 : model1 loss : 0.288573 model2 loss : 0.306818
[22:42:43.531] iteration 9850 : model1 loss : 0.272779 model2 loss : 0.247546
[22:42:44.092] iteration 9851 : model1 loss : 0.255014 model2 loss : 0.276606
[22:42:44.418] iteration 9852 : model1 loss : 0.177546 model2 loss : 0.201706
[22:42:44.742] iteration 9853 : model1 loss : 0.383283 model2 loss : 0.311896
[22:42:45.069] iteration 9854 : model1 loss : 0.274397 model2 loss : 0.293253
[22:42:45.394] iteration 9855 : model1 loss : 0.199527 model2 loss : 0.257881
[22:42:45.719] iteration 9856 : model1 loss : 0.271681 model2 loss : 0.402831
[22:42:46.044] iteration 9857 : model1 loss : 0.226419 model2 loss : 0.246525
[22:42:46.371] iteration 9858 : model1 loss : 0.213586 model2 loss : 0.234014
[22:42:46.696] iteration 9859 : model1 loss : 0.263792 model2 loss : 0.319236
[22:42:47.023] iteration 9860 : model1 loss : 0.140131 model2 loss : 0.205621
[22:42:47.349] iteration 9861 : model1 loss : 0.129306 model2 loss : 0.122118
[22:42:47.674] iteration 9862 : model1 loss : 0.271726 model2 loss : 0.270900
[22:42:47.999] iteration 9863 : model1 loss : 0.143938 model2 loss : 0.240871
[22:42:48.324] iteration 9864 : model1 loss : 0.168397 model2 loss : 0.178649
[22:42:48.650] iteration 9865 : model1 loss : 0.249507 model2 loss : 0.259224
[22:42:48.975] iteration 9866 : model1 loss : 0.197600 model2 loss : 0.247135
[22:42:49.304] iteration 9867 : model1 loss : 0.329719 model2 loss : 0.208059
[22:42:49.630] iteration 9868 : model1 loss : 0.201328 model2 loss : 0.236386
[22:42:49.955] iteration 9869 : model1 loss : 0.202191 model2 loss : 0.341612
[22:42:50.289] iteration 9870 : model1 loss : 0.217407 model2 loss : 0.262641
[22:42:50.617] iteration 9871 : model1 loss : 0.177830 model2 loss : 0.235808
[22:42:50.943] iteration 9872 : model1 loss : 0.363061 model2 loss : 0.338830
[22:42:51.267] iteration 9873 : model1 loss : 0.129025 model2 loss : 0.185073
[22:42:51.593] iteration 9874 : model1 loss : 0.246904 model2 loss : 0.291620
[22:42:51.922] iteration 9875 : model1 loss : 0.297707 model2 loss : 0.323965
[22:42:52.252] iteration 9876 : model1 loss : 0.226505 model2 loss : 0.268088
[22:42:52.580] iteration 9877 : model1 loss : 0.237772 model2 loss : 0.226273
[22:42:52.909] iteration 9878 : model1 loss : 0.272953 model2 loss : 0.283746
[22:42:53.234] iteration 9879 : model1 loss : 0.400162 model2 loss : 0.402004
[22:42:53.563] iteration 9880 : model1 loss : 0.181366 model2 loss : 0.195665
[22:42:53.893] iteration 9881 : model1 loss : 0.265432 model2 loss : 0.353298
[22:42:54.233] iteration 9882 : model1 loss : 0.208602 model2 loss : 0.206203
[22:42:54.571] iteration 9883 : model1 loss : 0.263241 model2 loss : 0.314450
[22:42:54.901] iteration 9884 : model1 loss : 0.298600 model2 loss : 0.340533
[22:42:55.230] iteration 9885 : model1 loss : 0.170747 model2 loss : 0.317327
[22:42:55.561] iteration 9886 : model1 loss : 0.244781 model2 loss : 0.264000
[22:42:55.890] iteration 9887 : model1 loss : 0.342255 model2 loss : 0.353853
[22:42:56.218] iteration 9888 : model1 loss : 0.178602 model2 loss : 0.184756
[22:42:56.547] iteration 9889 : model1 loss : 0.089851 model2 loss : 0.232232
[22:42:56.876] iteration 9890 : model1 loss : 0.117617 model2 loss : 0.170624
[22:42:57.204] iteration 9891 : model1 loss : 0.169741 model2 loss : 0.215186
[22:42:57.532] iteration 9892 : model1 loss : 0.273576 model2 loss : 0.303930
[22:42:57.859] iteration 9893 : model1 loss : 0.251841 model2 loss : 0.219936
[22:42:58.187] iteration 9894 : model1 loss : 0.107881 model2 loss : 0.117431
[22:42:58.516] iteration 9895 : model1 loss : 0.214594 model2 loss : 0.216541
[22:42:58.843] iteration 9896 : model1 loss : 0.147069 model2 loss : 0.257845
[22:42:59.171] iteration 9897 : model1 loss : 0.137237 model2 loss : 0.172513
[22:42:59.499] iteration 9898 : model1 loss : 0.269760 model2 loss : 0.258336
[22:42:59.826] iteration 9899 : model1 loss : 0.111337 model2 loss : 0.183801
[22:43:00.154] iteration 9900 : model1 loss : 0.184968 model2 loss : 0.252277
[22:43:00.700] iteration 9901 : model1 loss : 0.248707 model2 loss : 0.264239
[22:43:01.028] iteration 9902 : model1 loss : 0.305188 model2 loss : 0.304133
[22:43:01.357] iteration 9903 : model1 loss : 0.235775 model2 loss : 0.316828
[22:43:01.684] iteration 9904 : model1 loss : 0.189741 model2 loss : 0.190613
[22:43:02.012] iteration 9905 : model1 loss : 0.110076 model2 loss : 0.147367
[22:43:02.341] iteration 9906 : model1 loss : 0.279615 model2 loss : 0.298055
[22:43:02.669] iteration 9907 : model1 loss : 0.190753 model2 loss : 0.191623
[22:43:02.997] iteration 9908 : model1 loss : 0.338197 model2 loss : 0.343934
[22:43:03.323] iteration 9909 : model1 loss : 0.321747 model2 loss : 0.336172
[22:43:03.647] iteration 9910 : model1 loss : 0.194678 model2 loss : 0.236906
[22:43:03.974] iteration 9911 : model1 loss : 0.210681 model2 loss : 0.211382
[22:43:04.298] iteration 9912 : model1 loss : 0.238197 model2 loss : 0.225476
[22:43:04.621] iteration 9913 : model1 loss : 0.268112 model2 loss : 0.245818
[22:43:04.948] iteration 9914 : model1 loss : 0.271948 model2 loss : 0.315428
[22:43:05.276] iteration 9915 : model1 loss : 0.292068 model2 loss : 0.322338
[22:43:05.600] iteration 9916 : model1 loss : 0.243092 model2 loss : 0.314613
[22:43:05.925] iteration 9917 : model1 loss : 0.305225 model2 loss : 0.354495
[22:43:06.249] iteration 9918 : model1 loss : 0.289902 model2 loss : 0.365539
[22:43:06.571] iteration 9919 : model1 loss : 0.236579 model2 loss : 0.374456
[22:43:06.893] iteration 9920 : model1 loss : 0.145916 model2 loss : 0.184759
[22:43:07.216] iteration 9921 : model1 loss : 0.250772 model2 loss : 0.272965
[22:43:07.538] iteration 9922 : model1 loss : 0.262828 model2 loss : 0.259940
[22:43:07.860] iteration 9923 : model1 loss : 0.221309 model2 loss : 0.225801
[22:43:08.182] iteration 9924 : model1 loss : 0.120564 model2 loss : 0.217082
[22:43:08.504] iteration 9925 : model1 loss : 0.246855 model2 loss : 0.263890
[22:43:08.825] iteration 9926 : model1 loss : 0.132898 model2 loss : 0.157649
[22:43:09.151] iteration 9927 : model1 loss : 0.136628 model2 loss : 0.149027
[22:43:09.477] iteration 9928 : model1 loss : 0.252608 model2 loss : 0.270602
[22:43:09.803] iteration 9929 : model1 loss : 0.271758 model2 loss : 0.255750
[22:43:10.130] iteration 9930 : model1 loss : 0.266670 model2 loss : 0.325676
[22:43:10.456] iteration 9931 : model1 loss : 0.211855 model2 loss : 0.276945
[22:43:10.783] iteration 9932 : model1 loss : 0.297873 model2 loss : 0.327529
[22:43:11.108] iteration 9933 : model1 loss : 0.275727 model2 loss : 0.220945
[22:43:11.436] iteration 9934 : model1 loss : 0.216409 model2 loss : 0.226747
[22:43:11.762] iteration 9935 : model1 loss : 0.238802 model2 loss : 0.287875
[22:43:12.088] iteration 9936 : model1 loss : 0.145225 model2 loss : 0.210077
[22:43:12.415] iteration 9937 : model1 loss : 0.224706 model2 loss : 0.237541
[22:43:12.741] iteration 9938 : model1 loss : 0.271651 model2 loss : 0.256337
[22:43:13.068] iteration 9939 : model1 loss : 0.161970 model2 loss : 0.192778
[22:43:13.397] iteration 9940 : model1 loss : 0.166670 model2 loss : 0.195050
[22:43:13.723] iteration 9941 : model1 loss : 0.199294 model2 loss : 0.202538
[22:43:14.050] iteration 9942 : model1 loss : 0.159275 model2 loss : 0.218722
[22:43:14.377] iteration 9943 : model1 loss : 0.280266 model2 loss : 0.311634
[22:43:14.703] iteration 9944 : model1 loss : 0.331618 model2 loss : 0.307764
[22:43:15.030] iteration 9945 : model1 loss : 0.253339 model2 loss : 0.311975
[22:43:15.358] iteration 9946 : model1 loss : 0.157342 model2 loss : 0.132565
[22:43:15.684] iteration 9947 : model1 loss : 0.399123 model2 loss : 0.404741
[22:43:16.010] iteration 9948 : model1 loss : 0.142904 model2 loss : 0.153765
[22:43:16.338] iteration 9949 : model1 loss : 0.209588 model2 loss : 0.294949
[22:43:16.664] iteration 9950 : model1 loss : 0.208433 model2 loss : 0.210440
[22:43:17.193] iteration 9951 : model1 loss : 0.340226 model2 loss : 0.377403
[22:43:17.519] iteration 9952 : model1 loss : 0.263097 model2 loss : 0.211075
[22:43:17.845] iteration 9953 : model1 loss : 0.227432 model2 loss : 0.182141
[22:43:18.172] iteration 9954 : model1 loss : 0.212970 model2 loss : 0.242710
[22:43:18.498] iteration 9955 : model1 loss : 0.179864 model2 loss : 0.176662
[22:43:18.824] iteration 9956 : model1 loss : 0.262232 model2 loss : 0.283251
[22:43:19.151] iteration 9957 : model1 loss : 0.185052 model2 loss : 0.185277
[22:43:19.477] iteration 9958 : model1 loss : 0.217389 model2 loss : 0.221189
[22:43:19.802] iteration 9959 : model1 loss : 0.364486 model2 loss : 0.382548
[22:43:20.130] iteration 9960 : model1 loss : 0.328727 model2 loss : 0.360601
[22:43:20.459] iteration 9961 : model1 loss : 0.265892 model2 loss : 0.263134
[22:43:20.786] iteration 9962 : model1 loss : 0.150813 model2 loss : 0.122914
[22:43:21.114] iteration 9963 : model1 loss : 0.252344 model2 loss : 0.286105
[22:43:21.442] iteration 9964 : model1 loss : 0.247690 model2 loss : 0.254039
[22:43:21.770] iteration 9965 : model1 loss : 0.208723 model2 loss : 0.223606
[22:43:22.100] iteration 9966 : model1 loss : 0.273624 model2 loss : 0.308715
[22:43:22.428] iteration 9967 : model1 loss : 0.246729 model2 loss : 0.246702
[22:43:22.755] iteration 9968 : model1 loss : 0.134488 model2 loss : 0.196001
[22:43:23.083] iteration 9969 : model1 loss : 0.342581 model2 loss : 0.353255
[22:43:23.412] iteration 9970 : model1 loss : 0.235448 model2 loss : 0.235156
[22:43:23.739] iteration 9971 : model1 loss : 0.215334 model2 loss : 0.242759
[22:43:24.068] iteration 9972 : model1 loss : 0.223359 model2 loss : 0.213975
[22:43:24.395] iteration 9973 : model1 loss : 0.255774 model2 loss : 0.294890
[22:43:24.723] iteration 9974 : model1 loss : 0.253998 model2 loss : 0.223718
[22:43:25.051] iteration 9975 : model1 loss : 0.353952 model2 loss : 0.301201
[22:43:25.379] iteration 9976 : model1 loss : 0.259092 model2 loss : 0.241300
[22:43:25.705] iteration 9977 : model1 loss : 0.263718 model2 loss : 0.369155
[22:43:26.032] iteration 9978 : model1 loss : 0.189228 model2 loss : 0.170679
[22:43:26.357] iteration 9979 : model1 loss : 0.309687 model2 loss : 0.326017
[22:43:26.684] iteration 9980 : model1 loss : 0.212015 model2 loss : 0.233978
[22:43:27.011] iteration 9981 : model1 loss : 0.216459 model2 loss : 0.252057
[22:43:27.337] iteration 9982 : model1 loss : 0.252004 model2 loss : 0.257797
[22:43:27.664] iteration 9983 : model1 loss : 0.255931 model2 loss : 0.331449
[22:43:27.989] iteration 9984 : model1 loss : 0.343077 model2 loss : 0.324768
[22:43:28.316] iteration 9985 : model1 loss : 0.144727 model2 loss : 0.195807
[22:43:28.642] iteration 9986 : model1 loss : 0.319657 model2 loss : 0.272420
[22:43:28.969] iteration 9987 : model1 loss : 0.211933 model2 loss : 0.258246
[22:43:29.295] iteration 9988 : model1 loss : 0.210959 model2 loss : 0.279708
[22:43:29.622] iteration 9989 : model1 loss : 0.181917 model2 loss : 0.188919
[22:43:29.948] iteration 9990 : model1 loss : 0.347514 model2 loss : 0.299682
[22:43:30.274] iteration 9991 : model1 loss : 0.256826 model2 loss : 0.260159
[22:43:30.601] iteration 9992 : model1 loss : 0.173111 model2 loss : 0.284626
[22:43:30.927] iteration 9993 : model1 loss : 0.212789 model2 loss : 0.312823
[22:43:31.253] iteration 9994 : model1 loss : 0.346423 model2 loss : 0.351770
[22:43:31.579] iteration 9995 : model1 loss : 0.341014 model2 loss : 0.329350
[22:43:31.905] iteration 9996 : model1 loss : 0.182333 model2 loss : 0.213709
[22:43:32.232] iteration 9997 : model1 loss : 0.262598 model2 loss : 0.285250
[22:43:32.558] iteration 9998 : model1 loss : 0.166662 model2 loss : 0.200255
[22:43:32.884] iteration 9999 : model1 loss : 0.232025 model2 loss : 0.277280
[22:43:33.211] iteration 10000 : model1 loss : 0.317874 model2 loss : 0.341733
[22:43:33.725] iteration 10001 : model1 loss : 0.331645 model2 loss : 0.313626
[22:43:34.051] iteration 10002 : model1 loss : 0.180860 model2 loss : 0.204313
[22:43:34.377] iteration 10003 : model1 loss : 0.210756 model2 loss : 0.261857
[22:43:34.703] iteration 10004 : model1 loss : 0.283793 model2 loss : 0.302485
[22:43:35.030] iteration 10005 : model1 loss : 0.256104 model2 loss : 0.294402
[22:43:35.358] iteration 10006 : model1 loss : 0.172085 model2 loss : 0.231450
[22:43:35.683] iteration 10007 : model1 loss : 0.270845 model2 loss : 0.297124
[22:43:36.011] iteration 10008 : model1 loss : 0.218468 model2 loss : 0.327783
[22:43:36.338] iteration 10009 : model1 loss : 0.320080 model2 loss : 0.315826
[22:43:36.664] iteration 10010 : model1 loss : 0.224218 model2 loss : 0.207267
[22:43:36.990] iteration 10011 : model1 loss : 0.315116 model2 loss : 0.345070
[22:43:37.317] iteration 10012 : model1 loss : 0.244369 model2 loss : 0.272424
[22:43:37.643] iteration 10013 : model1 loss : 0.266922 model2 loss : 0.278112
[22:43:37.971] iteration 10014 : model1 loss : 0.178307 model2 loss : 0.224236
[22:43:38.297] iteration 10015 : model1 loss : 0.281832 model2 loss : 0.316588
[22:43:38.624] iteration 10016 : model1 loss : 0.208057 model2 loss : 0.273512
[22:43:38.950] iteration 10017 : model1 loss : 0.197912 model2 loss : 0.236457
[22:43:39.278] iteration 10018 : model1 loss : 0.274231 model2 loss : 0.298569
[22:43:39.603] iteration 10019 : model1 loss : 0.250405 model2 loss : 0.283569
[22:43:39.935] iteration 10020 : model1 loss : 0.159019 model2 loss : 0.232353
[22:43:40.258] iteration 10021 : model1 loss : 0.221381 model2 loss : 0.256922
[22:43:40.581] iteration 10022 : model1 loss : 0.240900 model2 loss : 0.289946
[22:43:40.909] iteration 10023 : model1 loss : 0.273361 model2 loss : 0.278833
[22:43:41.235] iteration 10024 : model1 loss : 0.262288 model2 loss : 0.279337
[22:43:41.562] iteration 10025 : model1 loss : 0.252309 model2 loss : 0.268019
[22:43:41.888] iteration 10026 : model1 loss : 0.304013 model2 loss : 0.338516
[22:43:42.215] iteration 10027 : model1 loss : 0.328350 model2 loss : 0.370866
[22:43:42.541] iteration 10028 : model1 loss : 0.115827 model2 loss : 0.158350
[22:43:42.866] iteration 10029 : model1 loss : 0.283729 model2 loss : 0.310726
[22:43:43.191] iteration 10030 : model1 loss : 0.121702 model2 loss : 0.124001
[22:43:43.516] iteration 10031 : model1 loss : 0.255386 model2 loss : 0.209705
[22:43:43.839] iteration 10032 : model1 loss : 0.165846 model2 loss : 0.185647
[22:43:44.161] iteration 10033 : model1 loss : 0.330628 model2 loss : 0.347496
[22:43:44.483] iteration 10034 : model1 loss : 0.260631 model2 loss : 0.254879
[22:43:44.806] iteration 10035 : model1 loss : 0.313232 model2 loss : 0.356543
[22:43:45.132] iteration 10036 : model1 loss : 0.178746 model2 loss : 0.147368
[22:43:45.454] iteration 10037 : model1 loss : 0.265652 model2 loss : 0.214823
[22:43:45.777] iteration 10038 : model1 loss : 0.197528 model2 loss : 0.348761
[22:43:46.100] iteration 10039 : model1 loss : 0.256865 model2 loss : 0.283988
[22:43:46.423] iteration 10040 : model1 loss : 0.235317 model2 loss : 0.236588
[22:43:46.745] iteration 10041 : model1 loss : 0.209044 model2 loss : 0.220048
[22:43:47.068] iteration 10042 : model1 loss : 0.227240 model2 loss : 0.229281
[22:43:47.390] iteration 10043 : model1 loss : 0.184441 model2 loss : 0.250572
[22:43:47.712] iteration 10044 : model1 loss : 0.342327 model2 loss : 0.330616
[22:43:48.036] iteration 10045 : model1 loss : 0.312701 model2 loss : 0.332874
[22:43:48.362] iteration 10046 : model1 loss : 0.143111 model2 loss : 0.204729
[22:43:48.684] iteration 10047 : model1 loss : 0.327787 model2 loss : 0.298567
[22:43:49.007] iteration 10048 : model1 loss : 0.181338 model2 loss : 0.154559
[22:43:49.334] iteration 10049 : model1 loss : 0.309020 model2 loss : 0.325561
[22:43:49.655] iteration 10050 : model1 loss : 0.205482 model2 loss : 0.192626
[22:43:50.175] iteration 10051 : model1 loss : 0.245897 model2 loss : 0.313988
[22:43:50.497] iteration 10052 : model1 loss : 0.261362 model2 loss : 0.281410
[22:43:50.820] iteration 10053 : model1 loss : 0.281848 model2 loss : 0.296036
[22:43:51.142] iteration 10054 : model1 loss : 0.225913 model2 loss : 0.278792
[22:43:51.466] iteration 10055 : model1 loss : 0.229469 model2 loss : 0.237313
[22:43:51.788] iteration 10056 : model1 loss : 0.239102 model2 loss : 0.301490
[22:43:52.110] iteration 10057 : model1 loss : 0.291284 model2 loss : 0.326831
[22:43:52.437] iteration 10058 : model1 loss : 0.321120 model2 loss : 0.352168
[22:43:52.760] iteration 10059 : model1 loss : 0.187472 model2 loss : 0.211451
[22:43:53.082] iteration 10060 : model1 loss : 0.197670 model2 loss : 0.212787
[22:43:53.410] iteration 10061 : model1 loss : 0.299147 model2 loss : 0.254700
[22:43:53.732] iteration 10062 : model1 loss : 0.243396 model2 loss : 0.255179
[22:43:54.054] iteration 10063 : model1 loss : 0.169450 model2 loss : 0.242562
[22:43:54.381] iteration 10064 : model1 loss : 0.356599 model2 loss : 0.349997
[22:43:54.705] iteration 10065 : model1 loss : 0.215098 model2 loss : 0.188197
[22:43:55.027] iteration 10066 : model1 loss : 0.315615 model2 loss : 0.364171
[22:43:55.356] iteration 10067 : model1 loss : 0.206874 model2 loss : 0.219030
[22:43:55.680] iteration 10068 : model1 loss : 0.283008 model2 loss : 0.296951
[22:43:56.014] iteration 10069 : model1 loss : 0.198468 model2 loss : 0.182120
[22:43:56.341] iteration 10070 : model1 loss : 0.272430 model2 loss : 0.284323
[22:43:56.666] iteration 10071 : model1 loss : 0.280859 model2 loss : 0.266873
[22:43:56.990] iteration 10072 : model1 loss : 0.131226 model2 loss : 0.186817
[22:43:57.316] iteration 10073 : model1 loss : 0.268143 model2 loss : 0.276497
[22:43:57.639] iteration 10074 : model1 loss : 0.175084 model2 loss : 0.223691
[22:43:57.961] iteration 10075 : model1 loss : 0.346922 model2 loss : 0.349927
[22:43:58.284] iteration 10076 : model1 loss : 0.116198 model2 loss : 0.142836
[22:43:58.613] iteration 10077 : model1 loss : 0.301634 model2 loss : 0.280074
[22:43:58.937] iteration 10078 : model1 loss : 0.320148 model2 loss : 0.331099
[22:43:59.259] iteration 10079 : model1 loss : 0.227419 model2 loss : 0.123887
[22:43:59.583] iteration 10080 : model1 loss : 0.269139 model2 loss : 0.279741
[22:43:59.905] iteration 10081 : model1 loss : 0.145389 model2 loss : 0.192529
[22:44:00.230] iteration 10082 : model1 loss : 0.225240 model2 loss : 0.233286
[22:44:00.552] iteration 10083 : model1 loss : 0.196098 model2 loss : 0.230019
[22:44:00.878] iteration 10084 : model1 loss : 0.243702 model2 loss : 0.284808
[22:44:01.207] iteration 10085 : model1 loss : 0.194252 model2 loss : 0.209716
[22:44:01.534] iteration 10086 : model1 loss : 0.218191 model2 loss : 0.258434
[22:44:01.857] iteration 10087 : model1 loss : 0.341944 model2 loss : 0.361439
[22:44:02.184] iteration 10088 : model1 loss : 0.216544 model2 loss : 0.192559
[22:44:02.506] iteration 10089 : model1 loss : 0.334923 model2 loss : 0.344349
[22:44:02.831] iteration 10090 : model1 loss : 0.231383 model2 loss : 0.234727
[22:44:03.155] iteration 10091 : model1 loss : 0.085604 model2 loss : 0.147869
[22:44:03.482] iteration 10092 : model1 loss : 0.259166 model2 loss : 0.293569
[22:44:03.810] iteration 10093 : model1 loss : 0.263789 model2 loss : 0.224259
[22:44:04.136] iteration 10094 : model1 loss : 0.221550 model2 loss : 0.297726
[22:44:04.462] iteration 10095 : model1 loss : 0.265735 model2 loss : 0.322720
[22:44:04.785] iteration 10096 : model1 loss : 0.243090 model2 loss : 0.324478
[22:44:05.107] iteration 10097 : model1 loss : 0.284054 model2 loss : 0.258938
[22:44:05.435] iteration 10098 : model1 loss : 0.109838 model2 loss : 0.205375
[22:44:05.761] iteration 10099 : model1 loss : 0.214954 model2 loss : 0.252731
[22:44:06.084] iteration 10100 : model1 loss : 0.271683 model2 loss : 0.273381
[22:44:06.619] iteration 10101 : model1 loss : 0.193729 model2 loss : 0.207802
[22:44:06.945] iteration 10102 : model1 loss : 0.306429 model2 loss : 0.298928
[22:44:07.268] iteration 10103 : model1 loss : 0.220610 model2 loss : 0.221674
[22:44:07.593] iteration 10104 : model1 loss : 0.272799 model2 loss : 0.302131
[22:44:07.916] iteration 10105 : model1 loss : 0.173946 model2 loss : 0.182470
[22:44:08.243] iteration 10106 : model1 loss : 0.184930 model2 loss : 0.208716
[22:44:08.571] iteration 10107 : model1 loss : 0.188166 model2 loss : 0.237793
[22:44:08.896] iteration 10108 : model1 loss : 0.283770 model2 loss : 0.260949
[22:44:09.218] iteration 10109 : model1 loss : 0.266894 model2 loss : 0.279616
[22:44:09.541] iteration 10110 : model1 loss : 0.176300 model2 loss : 0.112661
[22:44:09.863] iteration 10111 : model1 loss : 0.169176 model2 loss : 0.199399
[22:44:10.188] iteration 10112 : model1 loss : 0.305672 model2 loss : 0.289211
[22:44:10.511] iteration 10113 : model1 loss : 0.170811 model2 loss : 0.269447
[22:44:10.833] iteration 10114 : model1 loss : 0.181312 model2 loss : 0.286215
[22:44:11.161] iteration 10115 : model1 loss : 0.314431 model2 loss : 0.286008
[22:44:11.492] iteration 10116 : model1 loss : 0.207584 model2 loss : 0.259110
[22:44:11.819] iteration 10117 : model1 loss : 0.204879 model2 loss : 0.228413
[22:44:12.144] iteration 10118 : model1 loss : 0.134546 model2 loss : 0.205517
[22:44:12.470] iteration 10119 : model1 loss : 0.310149 model2 loss : 0.276603
[22:44:12.797] iteration 10120 : model1 loss : 0.250164 model2 loss : 0.267087
[22:44:13.121] iteration 10121 : model1 loss : 0.289638 model2 loss : 0.322440
[22:44:13.449] iteration 10122 : model1 loss : 0.197123 model2 loss : 0.241397
[22:44:13.773] iteration 10123 : model1 loss : 0.303711 model2 loss : 0.384874
[22:44:14.096] iteration 10124 : model1 loss : 0.250889 model2 loss : 0.305245
[22:44:14.421] iteration 10125 : model1 loss : 0.123986 model2 loss : 0.189043
[22:44:14.745] iteration 10126 : model1 loss : 0.215855 model2 loss : 0.255552
[22:44:15.068] iteration 10127 : model1 loss : 0.123094 model2 loss : 0.173876
[22:44:15.397] iteration 10128 : model1 loss : 0.181630 model2 loss : 0.218323
[22:44:15.720] iteration 10129 : model1 loss : 0.105645 model2 loss : 0.134675
[22:44:16.044] iteration 10130 : model1 loss : 0.182684 model2 loss : 0.201480
[22:44:16.373] iteration 10131 : model1 loss : 0.132352 model2 loss : 0.181596
[22:44:16.698] iteration 10132 : model1 loss : 0.217484 model2 loss : 0.277162
[22:44:17.023] iteration 10133 : model1 loss : 0.222282 model2 loss : 0.266443
[22:44:17.348] iteration 10134 : model1 loss : 0.293738 model2 loss : 0.335563
[22:44:17.672] iteration 10135 : model1 loss : 0.129957 model2 loss : 0.166855
[22:44:18.000] iteration 10136 : model1 loss : 0.331202 model2 loss : 0.366993
[22:44:18.327] iteration 10137 : model1 loss : 0.205941 model2 loss : 0.229439
[22:44:18.655] iteration 10138 : model1 loss : 0.145500 model2 loss : 0.158791
[22:44:18.980] iteration 10139 : model1 loss : 0.237317 model2 loss : 0.236738
[22:44:19.304] iteration 10140 : model1 loss : 0.220851 model2 loss : 0.300466
[22:44:19.628] iteration 10141 : model1 loss : 0.187841 model2 loss : 0.229224
[22:44:19.952] iteration 10142 : model1 loss : 0.241523 model2 loss : 0.272454
[22:44:20.276] iteration 10143 : model1 loss : 0.151968 model2 loss : 0.235048
[22:44:20.602] iteration 10144 : model1 loss : 0.072729 model2 loss : 0.120286
[22:44:20.925] iteration 10145 : model1 loss : 0.303166 model2 loss : 0.286566
[22:44:21.252] iteration 10146 : model1 loss : 0.187776 model2 loss : 0.178482
[22:44:21.577] iteration 10147 : model1 loss : 0.177883 model2 loss : 0.215826
[22:44:21.902] iteration 10148 : model1 loss : 0.210178 model2 loss : 0.225814
[22:44:22.228] iteration 10149 : model1 loss : 0.327400 model2 loss : 0.349970
[22:44:22.552] iteration 10150 : model1 loss : 0.187298 model2 loss : 0.245982
[22:44:23.105] iteration 10151 : model1 loss : 0.255481 model2 loss : 0.271779
[22:44:23.429] iteration 10152 : model1 loss : 0.340421 model2 loss : 0.356683
[22:44:23.754] iteration 10153 : model1 loss : 0.240459 model2 loss : 0.315787
[22:44:24.082] iteration 10154 : model1 loss : 0.119966 model2 loss : 0.176574
[22:44:24.407] iteration 10155 : model1 loss : 0.260160 model2 loss : 0.264529
[22:44:24.734] iteration 10156 : model1 loss : 0.096568 model2 loss : 0.122390
[22:44:25.063] iteration 10157 : model1 loss : 0.330081 model2 loss : 0.345275
[22:44:25.399] iteration 10158 : model1 loss : 0.298485 model2 loss : 0.341705
[22:44:25.723] iteration 10159 : model1 loss : 0.151201 model2 loss : 0.195264
[22:44:26.051] iteration 10160 : model1 loss : 0.218221 model2 loss : 0.199238
[22:44:26.375] iteration 10161 : model1 loss : 0.145706 model2 loss : 0.165856
[22:44:26.699] iteration 10162 : model1 loss : 0.148904 model2 loss : 0.181299
[22:44:27.027] iteration 10163 : model1 loss : 0.222329 model2 loss : 0.253458
[22:44:27.354] iteration 10164 : model1 loss : 0.289024 model2 loss : 0.312493
[22:44:27.680] iteration 10165 : model1 loss : 0.261538 model2 loss : 0.268445
[22:44:28.007] iteration 10166 : model1 loss : 0.195983 model2 loss : 0.221748
[22:44:28.336] iteration 10167 : model1 loss : 0.304064 model2 loss : 0.319148
[22:44:28.665] iteration 10168 : model1 loss : 0.266857 model2 loss : 0.257567
[22:44:28.994] iteration 10169 : model1 loss : 0.192083 model2 loss : 0.239668
[22:44:29.320] iteration 10170 : model1 loss : 0.204522 model2 loss : 0.242490
[22:44:29.649] iteration 10171 : model1 loss : 0.221276 model2 loss : 0.254932
[22:44:29.973] iteration 10172 : model1 loss : 0.245587 model2 loss : 0.251734
[22:44:30.303] iteration 10173 : model1 loss : 0.228920 model2 loss : 0.261926
[22:44:30.631] iteration 10174 : model1 loss : 0.253540 model2 loss : 0.240254
[22:44:30.960] iteration 10175 : model1 loss : 0.307537 model2 loss : 0.303850
[22:44:31.289] iteration 10176 : model1 loss : 0.165904 model2 loss : 0.277968
[22:44:31.617] iteration 10177 : model1 loss : 0.177176 model2 loss : 0.201413
[22:44:31.945] iteration 10178 : model1 loss : 0.249346 model2 loss : 0.255697
[22:44:32.273] iteration 10179 : model1 loss : 0.180514 model2 loss : 0.286761
[22:44:32.603] iteration 10180 : model1 loss : 0.168555 model2 loss : 0.159411
[22:44:32.934] iteration 10181 : model1 loss : 0.315463 model2 loss : 0.357833
[22:44:33.261] iteration 10182 : model1 loss : 0.187922 model2 loss : 0.205762
[22:44:33.588] iteration 10183 : model1 loss : 0.190918 model2 loss : 0.270197
[22:44:33.917] iteration 10184 : model1 loss : 0.217515 model2 loss : 0.198992
[22:44:34.247] iteration 10185 : model1 loss : 0.244277 model2 loss : 0.229129
[22:44:34.577] iteration 10186 : model1 loss : 0.337072 model2 loss : 0.322341
[22:44:34.906] iteration 10187 : model1 loss : 0.218754 model2 loss : 0.224568
[22:44:35.236] iteration 10188 : model1 loss : 0.206009 model2 loss : 0.207698
[22:44:35.565] iteration 10189 : model1 loss : 0.119548 model2 loss : 0.130328
[22:44:35.895] iteration 10190 : model1 loss : 0.199043 model2 loss : 0.244301
[22:44:36.225] iteration 10191 : model1 loss : 0.185606 model2 loss : 0.276861
[22:44:36.557] iteration 10192 : model1 loss : 0.266905 model2 loss : 0.314737
[22:44:36.887] iteration 10193 : model1 loss : 0.090908 model2 loss : 0.185103
[22:44:37.219] iteration 10194 : model1 loss : 0.212787 model2 loss : 0.203636
[22:44:37.548] iteration 10195 : model1 loss : 0.338993 model2 loss : 0.319784
[22:44:37.878] iteration 10196 : model1 loss : 0.203329 model2 loss : 0.211300
[22:44:38.208] iteration 10197 : model1 loss : 0.326770 model2 loss : 0.334709
[22:44:38.538] iteration 10198 : model1 loss : 0.200734 model2 loss : 0.337247
[22:44:38.869] iteration 10199 : model1 loss : 0.210952 model2 loss : 0.196752
[22:44:39.207] iteration 10200 : model1 loss : 0.120759 model2 loss : 0.183337
[22:44:39.750] iteration 10201 : model1 loss : 0.275612 model2 loss : 0.293402
[22:44:40.080] iteration 10202 : model1 loss : 0.222352 model2 loss : 0.260845
[22:44:40.409] iteration 10203 : model1 loss : 0.180276 model2 loss : 0.245851
[22:44:40.739] iteration 10204 : model1 loss : 0.323371 model2 loss : 0.323676
[22:44:41.070] iteration 10205 : model1 loss : 0.205404 model2 loss : 0.209322
[22:44:41.404] iteration 10206 : model1 loss : 0.103103 model2 loss : 0.119878
[22:44:41.734] iteration 10207 : model1 loss : 0.315259 model2 loss : 0.282881
[22:44:42.064] iteration 10208 : model1 loss : 0.358995 model2 loss : 0.356830
[22:44:42.395] iteration 10209 : model1 loss : 0.402772 model2 loss : 0.427732
[22:44:42.725] iteration 10210 : model1 loss : 0.342664 model2 loss : 0.346677
[22:44:43.056] iteration 10211 : model1 loss : 0.223872 model2 loss : 0.208951
[22:44:43.387] iteration 10212 : model1 loss : 0.267962 model2 loss : 0.356469
[22:44:43.715] iteration 10213 : model1 loss : 0.251339 model2 loss : 0.190053
[22:44:44.046] iteration 10214 : model1 loss : 0.193932 model2 loss : 0.148912
[22:44:44.376] iteration 10215 : model1 loss : 0.164414 model2 loss : 0.179343
[22:44:44.708] iteration 10216 : model1 loss : 0.110592 model2 loss : 0.207343
[22:44:45.037] iteration 10217 : model1 loss : 0.217753 model2 loss : 0.199404
[22:44:45.371] iteration 10218 : model1 loss : 0.184464 model2 loss : 0.167574
[22:44:45.700] iteration 10219 : model1 loss : 0.308472 model2 loss : 0.321868
[22:44:46.029] iteration 10220 : model1 loss : 0.317981 model2 loss : 0.337555
[22:44:46.361] iteration 10221 : model1 loss : 0.285040 model2 loss : 0.298840
[22:44:46.692] iteration 10222 : model1 loss : 0.185716 model2 loss : 0.249022
[22:44:47.024] iteration 10223 : model1 loss : 0.230607 model2 loss : 0.268501
[22:44:47.354] iteration 10224 : model1 loss : 0.220502 model2 loss : 0.169991
[22:44:47.683] iteration 10225 : model1 loss : 0.108198 model2 loss : 0.181330
[22:44:48.015] iteration 10226 : model1 loss : 0.206750 model2 loss : 0.207056
[22:44:48.346] iteration 10227 : model1 loss : 0.274616 model2 loss : 0.285616
[22:44:48.675] iteration 10228 : model1 loss : 0.286698 model2 loss : 0.231527
[22:44:49.003] iteration 10229 : model1 loss : 0.295805 model2 loss : 0.246820
[22:44:49.334] iteration 10230 : model1 loss : 0.151896 model2 loss : 0.148802
[22:44:49.665] iteration 10231 : model1 loss : 0.193545 model2 loss : 0.190749
[22:44:49.995] iteration 10232 : model1 loss : 0.174239 model2 loss : 0.184054
[22:44:50.327] iteration 10233 : model1 loss : 0.207280 model2 loss : 0.207755
[22:44:50.659] iteration 10234 : model1 loss : 0.307103 model2 loss : 0.289229
[22:44:50.990] iteration 10235 : model1 loss : 0.280314 model2 loss : 0.248878
[22:44:51.319] iteration 10236 : model1 loss : 0.289518 model2 loss : 0.278211
[22:44:51.650] iteration 10237 : model1 loss : 0.271563 model2 loss : 0.326532
[22:44:51.982] iteration 10238 : model1 loss : 0.335657 model2 loss : 0.293797
[22:44:52.314] iteration 10239 : model1 loss : 0.328065 model2 loss : 0.328332
[22:44:52.645] iteration 10240 : model1 loss : 0.139106 model2 loss : 0.200867
[22:44:52.974] iteration 10241 : model1 loss : 0.289730 model2 loss : 0.251327
[22:44:53.303] iteration 10242 : model1 loss : 0.103658 model2 loss : 0.164826
[22:44:53.632] iteration 10243 : model1 loss : 0.250262 model2 loss : 0.269513
[22:44:53.963] iteration 10244 : model1 loss : 0.273165 model2 loss : 0.291939
[22:44:54.293] iteration 10245 : model1 loss : 0.150542 model2 loss : 0.159465
[22:44:54.630] iteration 10246 : model1 loss : 0.205713 model2 loss : 0.251289
[22:44:54.961] iteration 10247 : model1 loss : 0.295299 model2 loss : 0.313046
[22:44:55.298] iteration 10248 : model1 loss : 0.268247 model2 loss : 0.299027
[22:44:55.629] iteration 10249 : model1 loss : 0.203082 model2 loss : 0.260629
[22:44:55.958] iteration 10250 : model1 loss : 0.366776 model2 loss : 0.362203
[22:44:56.517] iteration 10251 : model1 loss : 0.289566 model2 loss : 0.310183
[22:44:56.847] iteration 10252 : model1 loss : 0.154158 model2 loss : 0.134842
[22:44:57.178] iteration 10253 : model1 loss : 0.304295 model2 loss : 0.244149
[22:44:57.511] iteration 10254 : model1 loss : 0.210587 model2 loss : 0.190145
[22:44:57.841] iteration 10255 : model1 loss : 0.280542 model2 loss : 0.289341
[22:44:58.171] iteration 10256 : model1 loss : 0.183822 model2 loss : 0.200710
[22:44:58.501] iteration 10257 : model1 loss : 0.280659 model2 loss : 0.241166
[22:44:58.830] iteration 10258 : model1 loss : 0.252632 model2 loss : 0.228230
[22:44:59.160] iteration 10259 : model1 loss : 0.188708 model2 loss : 0.249559
[22:44:59.490] iteration 10260 : model1 loss : 0.168394 model2 loss : 0.210208
[22:44:59.823] iteration 10261 : model1 loss : 0.140144 model2 loss : 0.165666
[22:45:00.154] iteration 10262 : model1 loss : 0.160769 model2 loss : 0.186192
[22:45:00.485] iteration 10263 : model1 loss : 0.120652 model2 loss : 0.135578
[22:45:00.816] iteration 10264 : model1 loss : 0.160420 model2 loss : 0.202010
[22:45:01.146] iteration 10265 : model1 loss : 0.178322 model2 loss : 0.176596
[22:45:01.478] iteration 10266 : model1 loss : 0.323850 model2 loss : 0.332532
[22:45:01.810] iteration 10267 : model1 loss : 0.167683 model2 loss : 0.105852
[22:45:02.140] iteration 10268 : model1 loss : 0.337198 model2 loss : 0.337545
[22:45:02.472] iteration 10269 : model1 loss : 0.239853 model2 loss : 0.224886
[22:45:02.803] iteration 10270 : model1 loss : 0.198608 model2 loss : 0.194443
[22:45:03.134] iteration 10271 : model1 loss : 0.318568 model2 loss : 0.347857
[22:45:03.466] iteration 10272 : model1 loss : 0.200205 model2 loss : 0.196118
[22:45:03.796] iteration 10273 : model1 loss : 0.204962 model2 loss : 0.216576
[22:45:04.129] iteration 10274 : model1 loss : 0.197008 model2 loss : 0.199828
[22:45:04.460] iteration 10275 : model1 loss : 0.275619 model2 loss : 0.300837
[22:45:04.791] iteration 10276 : model1 loss : 0.277534 model2 loss : 0.273535
[22:45:05.124] iteration 10277 : model1 loss : 0.274233 model2 loss : 0.233917
[22:45:05.455] iteration 10278 : model1 loss : 0.191205 model2 loss : 0.277526
[22:45:05.786] iteration 10279 : model1 loss : 0.270685 model2 loss : 0.320100
[22:45:06.116] iteration 10280 : model1 loss : 0.228043 model2 loss : 0.220530
[22:45:06.447] iteration 10281 : model1 loss : 0.328498 model2 loss : 0.270680
[22:45:06.779] iteration 10282 : model1 loss : 0.232817 model2 loss : 0.228707
[22:45:07.112] iteration 10283 : model1 loss : 0.230961 model2 loss : 0.232949
[22:45:07.445] iteration 10284 : model1 loss : 0.234523 model2 loss : 0.199349
[22:45:07.777] iteration 10285 : model1 loss : 0.318898 model2 loss : 0.297355
[22:45:08.106] iteration 10286 : model1 loss : 0.280953 model2 loss : 0.283681
[22:45:08.436] iteration 10287 : model1 loss : 0.221305 model2 loss : 0.235796
[22:45:08.767] iteration 10288 : model1 loss : 0.207262 model2 loss : 0.255995
[22:45:09.098] iteration 10289 : model1 loss : 0.181391 model2 loss : 0.206631
[22:45:09.429] iteration 10290 : model1 loss : 0.268085 model2 loss : 0.305716
[22:45:09.761] iteration 10291 : model1 loss : 0.360691 model2 loss : 0.357190
[22:45:10.093] iteration 10292 : model1 loss : 0.187754 model2 loss : 0.204312
[22:45:10.427] iteration 10293 : model1 loss : 0.244411 model2 loss : 0.323865
[22:45:10.760] iteration 10294 : model1 loss : 0.218378 model2 loss : 0.219612
[22:45:11.091] iteration 10295 : model1 loss : 0.316678 model2 loss : 0.284364
[22:45:11.426] iteration 10296 : model1 loss : 0.245592 model2 loss : 0.248169
[22:45:11.759] iteration 10297 : model1 loss : 0.312329 model2 loss : 0.293864
[22:45:12.091] iteration 10298 : model1 loss : 0.244017 model2 loss : 0.255962
[22:45:12.422] iteration 10299 : model1 loss : 0.271910 model2 loss : 0.281709
[22:45:12.754] iteration 10300 : model1 loss : 0.166814 model2 loss : 0.207556
[22:45:13.313] iteration 10301 : model1 loss : 0.251967 model2 loss : 0.259278
[22:45:13.645] iteration 10302 : model1 loss : 0.215811 model2 loss : 0.200684
[22:45:13.977] iteration 10303 : model1 loss : 0.273273 model2 loss : 0.278841
[22:45:14.309] iteration 10304 : model1 loss : 0.252167 model2 loss : 0.254942
[22:45:14.643] iteration 10305 : model1 loss : 0.173746 model2 loss : 0.125527
[22:45:14.984] iteration 10306 : model1 loss : 0.194476 model2 loss : 0.184140
[22:45:15.314] iteration 10307 : model1 loss : 0.298810 model2 loss : 0.256786
[22:45:15.646] iteration 10308 : model1 loss : 0.289862 model2 loss : 0.216321
[22:45:15.976] iteration 10309 : model1 loss : 0.191065 model2 loss : 0.201547
[22:45:16.309] iteration 10310 : model1 loss : 0.138098 model2 loss : 0.174612
[22:45:16.642] iteration 10311 : model1 loss : 0.323449 model2 loss : 0.320827
[22:45:16.973] iteration 10312 : model1 loss : 0.215984 model2 loss : 0.193857
[22:45:17.302] iteration 10313 : model1 loss : 0.270973 model2 loss : 0.276301
[22:45:17.631] iteration 10314 : model1 loss : 0.173647 model2 loss : 0.170861
[22:45:17.964] iteration 10315 : model1 loss : 0.296059 model2 loss : 0.333415
[22:45:18.293] iteration 10316 : model1 loss : 0.169287 model2 loss : 0.208548
[22:45:18.624] iteration 10317 : model1 loss : 0.162049 model2 loss : 0.214867
[22:45:18.955] iteration 10318 : model1 loss : 0.192229 model2 loss : 0.145383
[22:45:19.285] iteration 10319 : model1 loss : 0.266368 model2 loss : 0.279583
[22:45:19.614] iteration 10320 : model1 loss : 0.254989 model2 loss : 0.261668
[22:45:19.942] iteration 10321 : model1 loss : 0.265106 model2 loss : 0.258106
[22:45:20.268] iteration 10322 : model1 loss : 0.253840 model2 loss : 0.286627
[22:45:20.596] iteration 10323 : model1 loss : 0.339403 model2 loss : 0.331372
[22:45:20.922] iteration 10324 : model1 loss : 0.131412 model2 loss : 0.234946
[22:45:21.249] iteration 10325 : model1 loss : 0.216568 model2 loss : 0.271940
[22:45:21.577] iteration 10326 : model1 loss : 0.265146 model2 loss : 0.234804
[22:45:21.904] iteration 10327 : model1 loss : 0.211997 model2 loss : 0.264901
[22:45:22.233] iteration 10328 : model1 loss : 0.266163 model2 loss : 0.281567
[22:45:22.561] iteration 10329 : model1 loss : 0.196834 model2 loss : 0.172817
[22:45:22.888] iteration 10330 : model1 loss : 0.216745 model2 loss : 0.218594
[22:45:23.217] iteration 10331 : model1 loss : 0.231805 model2 loss : 0.251937
[22:45:23.544] iteration 10332 : model1 loss : 0.228956 model2 loss : 0.293803
[22:45:23.870] iteration 10333 : model1 loss : 0.332311 model2 loss : 0.318280
[22:45:24.198] iteration 10334 : model1 loss : 0.341309 model2 loss : 0.404182
[22:45:24.525] iteration 10335 : model1 loss : 0.181309 model2 loss : 0.184800
[22:45:24.853] iteration 10336 : model1 loss : 0.212861 model2 loss : 0.195608
[22:45:25.184] iteration 10337 : model1 loss : 0.280626 model2 loss : 0.345048
[22:45:25.519] iteration 10338 : model1 loss : 0.160157 model2 loss : 0.175550
[22:45:25.852] iteration 10339 : model1 loss : 0.261600 model2 loss : 0.296345
[22:45:26.183] iteration 10340 : model1 loss : 0.120941 model2 loss : 0.204502
[22:45:26.514] iteration 10341 : model1 loss : 0.194363 model2 loss : 0.191090
[22:45:26.846] iteration 10342 : model1 loss : 0.290149 model2 loss : 0.313978
[22:45:27.177] iteration 10343 : model1 loss : 0.220129 model2 loss : 0.219090
[22:45:27.507] iteration 10344 : model1 loss : 0.172677 model2 loss : 0.197404
[22:45:27.841] iteration 10345 : model1 loss : 0.343824 model2 loss : 0.316748
[22:45:28.180] iteration 10346 : model1 loss : 0.111017 model2 loss : 0.185714
[22:45:28.516] iteration 10347 : model1 loss : 0.175552 model2 loss : 0.174586
[22:45:28.849] iteration 10348 : model1 loss : 0.263138 model2 loss : 0.254522
[22:45:29.182] iteration 10349 : model1 loss : 0.210203 model2 loss : 0.233377
[22:45:29.512] iteration 10350 : model1 loss : 0.222163 model2 loss : 0.260871
[22:45:30.062] iteration 10351 : model1 loss : 0.158452 model2 loss : 0.183982
[22:45:30.393] iteration 10352 : model1 loss : 0.322254 model2 loss : 0.366233
[22:45:30.725] iteration 10353 : model1 loss : 0.314519 model2 loss : 0.329704
[22:45:31.056] iteration 10354 : model1 loss : 0.175706 model2 loss : 0.208117
[22:45:31.389] iteration 10355 : model1 loss : 0.254682 model2 loss : 0.256568
[22:45:32.533] iteration 10356 : model1 loss : 0.268369 model2 loss : 0.220661
[22:45:32.865] iteration 10357 : model1 loss : 0.201136 model2 loss : 0.227538
[22:45:33.212] iteration 10358 : model1 loss : 0.288480 model2 loss : 0.304435
[22:45:33.557] iteration 10359 : model1 loss : 0.265126 model2 loss : 0.225567
[22:45:33.905] iteration 10360 : model1 loss : 0.203394 model2 loss : 0.254562
[22:45:34.250] iteration 10361 : model1 loss : 0.183356 model2 loss : 0.175538
[22:45:34.596] iteration 10362 : model1 loss : 0.265004 model2 loss : 0.181755
[22:45:34.940] iteration 10363 : model1 loss : 0.113345 model2 loss : 0.137202
[22:45:35.290] iteration 10364 : model1 loss : 0.226281 model2 loss : 0.220908
[22:45:35.635] iteration 10365 : model1 loss : 0.207840 model2 loss : 0.266351
[22:45:35.990] iteration 10366 : model1 loss : 0.310284 model2 loss : 0.333941
[22:45:36.335] iteration 10367 : model1 loss : 0.301514 model2 loss : 0.240572
[22:45:36.680] iteration 10368 : model1 loss : 0.131491 model2 loss : 0.189050
[22:45:37.026] iteration 10369 : model1 loss : 0.261058 model2 loss : 0.266678
[22:45:37.372] iteration 10370 : model1 loss : 0.331480 model2 loss : 0.327178
[22:45:37.718] iteration 10371 : model1 loss : 0.216591 model2 loss : 0.236775
[22:45:38.064] iteration 10372 : model1 loss : 0.211914 model2 loss : 0.202346
[22:45:38.411] iteration 10373 : model1 loss : 0.401576 model2 loss : 0.426827
[22:45:38.751] iteration 10374 : model1 loss : 0.143897 model2 loss : 0.148409
[22:45:39.093] iteration 10375 : model1 loss : 0.193791 model2 loss : 0.271072
[22:45:39.437] iteration 10376 : model1 loss : 0.324757 model2 loss : 0.326352
[22:45:39.778] iteration 10377 : model1 loss : 0.300461 model2 loss : 0.319468
[22:45:40.121] iteration 10378 : model1 loss : 0.263958 model2 loss : 0.329293
[22:45:40.466] iteration 10379 : model1 loss : 0.325866 model2 loss : 0.403892
[22:45:40.806] iteration 10380 : model1 loss : 0.370650 model2 loss : 0.332273
[22:45:41.152] iteration 10381 : model1 loss : 0.209671 model2 loss : 0.116344
[22:45:41.496] iteration 10382 : model1 loss : 0.270892 model2 loss : 0.282919
[22:45:41.837] iteration 10383 : model1 loss : 0.367220 model2 loss : 0.292318
[22:45:42.183] iteration 10384 : model1 loss : 0.231695 model2 loss : 0.164777
[22:45:42.526] iteration 10385 : model1 loss : 0.224054 model2 loss : 0.117120
[22:45:42.871] iteration 10386 : model1 loss : 0.193445 model2 loss : 0.213793
[22:45:43.217] iteration 10387 : model1 loss : 0.197561 model2 loss : 0.207238
[22:45:43.558] iteration 10388 : model1 loss : 0.260548 model2 loss : 0.293735
[22:45:43.902] iteration 10389 : model1 loss : 0.292002 model2 loss : 0.343285
[22:45:44.247] iteration 10390 : model1 loss : 0.205788 model2 loss : 0.196792
[22:45:44.588] iteration 10391 : model1 loss : 0.387049 model2 loss : 0.391396
[22:45:44.929] iteration 10392 : model1 loss : 0.274606 model2 loss : 0.268947
[22:45:45.269] iteration 10393 : model1 loss : 0.300759 model2 loss : 0.268862
[22:45:45.609] iteration 10394 : model1 loss : 0.377179 model2 loss : 0.349269
[22:45:45.949] iteration 10395 : model1 loss : 0.286956 model2 loss : 0.277599
[22:45:46.294] iteration 10396 : model1 loss : 0.240934 model2 loss : 0.177846
[22:45:46.639] iteration 10397 : model1 loss : 0.232114 model2 loss : 0.204667
[22:45:46.979] iteration 10398 : model1 loss : 0.331229 model2 loss : 0.348194
[22:45:47.323] iteration 10399 : model1 loss : 0.247578 model2 loss : 0.252209
[22:45:47.667] iteration 10400 : model1 loss : 0.192664 model2 loss : 0.173377
[22:45:48.291] iteration 10401 : model1 loss : 0.167391 model2 loss : 0.145462
[22:45:48.623] iteration 10402 : model1 loss : 0.292541 model2 loss : 0.316119
[22:45:48.954] iteration 10403 : model1 loss : 0.215355 model2 loss : 0.199281
[22:45:49.286] iteration 10404 : model1 loss : 0.260434 model2 loss : 0.238382
[22:45:49.617] iteration 10405 : model1 loss : 0.226573 model2 loss : 0.227563
[22:45:49.947] iteration 10406 : model1 loss : 0.400482 model2 loss : 0.405710
[22:45:50.279] iteration 10407 : model1 loss : 0.336904 model2 loss : 0.306664
[22:45:50.612] iteration 10408 : model1 loss : 0.138934 model2 loss : 0.176377
[22:45:50.945] iteration 10409 : model1 loss : 0.289198 model2 loss : 0.255943
[22:45:51.277] iteration 10410 : model1 loss : 0.277101 model2 loss : 0.298576
[22:45:51.610] iteration 10411 : model1 loss : 0.280132 model2 loss : 0.277676
[22:45:51.943] iteration 10412 : model1 loss : 0.197113 model2 loss : 0.314460
[22:45:52.276] iteration 10413 : model1 loss : 0.199754 model2 loss : 0.218890
[22:45:52.608] iteration 10414 : model1 loss : 0.192376 model2 loss : 0.232745
[22:45:52.942] iteration 10415 : model1 loss : 0.137775 model2 loss : 0.144250
[22:45:53.275] iteration 10416 : model1 loss : 0.253383 model2 loss : 0.246053
[22:45:53.610] iteration 10417 : model1 loss : 0.187930 model2 loss : 0.124225
[22:45:53.943] iteration 10418 : model1 loss : 0.264070 model2 loss : 0.317828
[22:45:54.277] iteration 10419 : model1 loss : 0.341107 model2 loss : 0.212915
[22:45:54.610] iteration 10420 : model1 loss : 0.266612 model2 loss : 0.277287
[22:45:54.940] iteration 10421 : model1 loss : 0.294520 model2 loss : 0.252286
[22:45:55.273] iteration 10422 : model1 loss : 0.248235 model2 loss : 0.288082
[22:45:55.601] iteration 10423 : model1 loss : 0.271083 model2 loss : 0.286735
[22:45:55.924] iteration 10424 : model1 loss : 0.199455 model2 loss : 0.244218
[22:45:56.251] iteration 10425 : model1 loss : 0.126080 model2 loss : 0.146974
[22:45:56.596] iteration 10426 : model1 loss : 0.166201 model2 loss : 0.196132
[22:45:56.937] iteration 10427 : model1 loss : 0.263086 model2 loss : 0.248447
[22:45:57.277] iteration 10428 : model1 loss : 0.147503 model2 loss : 0.157011
[22:45:57.615] iteration 10429 : model1 loss : 0.127926 model2 loss : 0.169432
[22:45:57.956] iteration 10430 : model1 loss : 0.387154 model2 loss : 0.302296
[22:45:58.301] iteration 10431 : model1 loss : 0.332847 model2 loss : 0.306134
[22:45:58.645] iteration 10432 : model1 loss : 0.229617 model2 loss : 0.298710
[22:45:58.993] iteration 10433 : model1 loss : 0.346880 model2 loss : 0.304720
[22:45:59.333] iteration 10434 : model1 loss : 0.250636 model2 loss : 0.274115
[22:45:59.675] iteration 10435 : model1 loss : 0.213667 model2 loss : 0.205218
[22:46:00.023] iteration 10436 : model1 loss : 0.316061 model2 loss : 0.236405
[22:46:00.369] iteration 10437 : model1 loss : 0.269299 model2 loss : 0.260999
[22:46:00.714] iteration 10438 : model1 loss : 0.146179 model2 loss : 0.167466
[22:46:01.053] iteration 10439 : model1 loss : 0.234564 model2 loss : 0.249960
[22:46:01.398] iteration 10440 : model1 loss : 0.323460 model2 loss : 0.306740
[22:46:01.742] iteration 10441 : model1 loss : 0.242319 model2 loss : 0.272681
[22:46:02.086] iteration 10442 : model1 loss : 0.214654 model2 loss : 0.224964
[22:46:02.427] iteration 10443 : model1 loss : 0.193995 model2 loss : 0.259532
[22:46:02.766] iteration 10444 : model1 loss : 0.216345 model2 loss : 0.177058
[22:46:03.112] iteration 10445 : model1 loss : 0.252083 model2 loss : 0.245870
[22:46:03.452] iteration 10446 : model1 loss : 0.222750 model2 loss : 0.207393
[22:46:03.795] iteration 10447 : model1 loss : 0.306840 model2 loss : 0.353603
[22:46:04.141] iteration 10448 : model1 loss : 0.275023 model2 loss : 0.300546
[22:46:04.490] iteration 10449 : model1 loss : 0.207711 model2 loss : 0.259625
[22:46:04.832] iteration 10450 : model1 loss : 0.274961 model2 loss : 0.303377
[22:46:05.517] iteration 10451 : model1 loss : 0.218471 model2 loss : 0.244036
[22:46:05.857] iteration 10452 : model1 loss : 0.201850 model2 loss : 0.195187
[22:46:06.199] iteration 10453 : model1 loss : 0.181182 model2 loss : 0.127905
[22:46:06.545] iteration 10454 : model1 loss : 0.260541 model2 loss : 0.183010
[22:46:06.888] iteration 10455 : model1 loss : 0.177942 model2 loss : 0.283098
[22:46:07.233] iteration 10456 : model1 loss : 0.134647 model2 loss : 0.187802
[22:46:07.572] iteration 10457 : model1 loss : 0.287885 model2 loss : 0.347026
[22:46:07.913] iteration 10458 : model1 loss : 0.258233 model2 loss : 0.261228
[22:46:08.256] iteration 10459 : model1 loss : 0.254160 model2 loss : 0.248153
[22:46:08.596] iteration 10460 : model1 loss : 0.337386 model2 loss : 0.333338
[22:46:08.935] iteration 10461 : model1 loss : 0.140584 model2 loss : 0.253536
[22:46:09.282] iteration 10462 : model1 loss : 0.319327 model2 loss : 0.351071
[22:46:09.627] iteration 10463 : model1 loss : 0.209219 model2 loss : 0.251571
[22:46:09.968] iteration 10464 : model1 loss : 0.190063 model2 loss : 0.164510
[22:46:10.312] iteration 10465 : model1 loss : 0.260877 model2 loss : 0.252484
[22:46:10.653] iteration 10466 : model1 loss : 0.253262 model2 loss : 0.272700
[22:46:10.997] iteration 10467 : model1 loss : 0.302487 model2 loss : 0.309088
[22:46:11.337] iteration 10468 : model1 loss : 0.278640 model2 loss : 0.297222
[22:46:11.681] iteration 10469 : model1 loss : 0.308370 model2 loss : 0.392846
[22:46:12.021] iteration 10470 : model1 loss : 0.273046 model2 loss : 0.238197
[22:46:12.365] iteration 10471 : model1 loss : 0.141313 model2 loss : 0.169593
[22:46:12.706] iteration 10472 : model1 loss : 0.308006 model2 loss : 0.278041
[22:46:13.046] iteration 10473 : model1 loss : 0.199334 model2 loss : 0.289608
[22:46:13.390] iteration 10474 : model1 loss : 0.159072 model2 loss : 0.242441
[22:46:13.731] iteration 10475 : model1 loss : 0.188910 model2 loss : 0.242174
[22:46:14.076] iteration 10476 : model1 loss : 0.240709 model2 loss : 0.242735
[22:46:14.424] iteration 10477 : model1 loss : 0.217009 model2 loss : 0.209142
[22:46:14.770] iteration 10478 : model1 loss : 0.280747 model2 loss : 0.266068
[22:46:15.118] iteration 10479 : model1 loss : 0.300745 model2 loss : 0.323553
[22:46:15.458] iteration 10480 : model1 loss : 0.252827 model2 loss : 0.256962
[22:46:15.804] iteration 10481 : model1 loss : 0.278016 model2 loss : 0.295419
[22:46:16.149] iteration 10482 : model1 loss : 0.227441 model2 loss : 0.241408
[22:46:16.494] iteration 10483 : model1 loss : 0.316346 model2 loss : 0.329248
[22:46:16.839] iteration 10484 : model1 loss : 0.135402 model2 loss : 0.166487
[22:46:17.183] iteration 10485 : model1 loss : 0.245701 model2 loss : 0.266627
[22:46:17.521] iteration 10486 : model1 loss : 0.276612 model2 loss : 0.273416
[22:46:17.863] iteration 10487 : model1 loss : 0.183963 model2 loss : 0.211804
[22:46:18.210] iteration 10488 : model1 loss : 0.251784 model2 loss : 0.175748
[22:46:18.552] iteration 10489 : model1 loss : 0.181555 model2 loss : 0.194954
[22:46:18.903] iteration 10490 : model1 loss : 0.192461 model2 loss : 0.302037
[22:46:19.248] iteration 10491 : model1 loss : 0.332635 model2 loss : 0.312796
[22:46:19.588] iteration 10492 : model1 loss : 0.264618 model2 loss : 0.231341
[22:46:19.929] iteration 10493 : model1 loss : 0.269359 model2 loss : 0.219894
[22:46:20.275] iteration 10494 : model1 loss : 0.271311 model2 loss : 0.296122
[22:46:20.616] iteration 10495 : model1 loss : 0.212273 model2 loss : 0.233415
[22:46:20.960] iteration 10496 : model1 loss : 0.260857 model2 loss : 0.282495
[22:46:21.304] iteration 10497 : model1 loss : 0.215458 model2 loss : 0.223179
[22:46:21.645] iteration 10498 : model1 loss : 0.246507 model2 loss : 0.226358
[22:46:21.986] iteration 10499 : model1 loss : 0.099818 model2 loss : 0.169363
[22:46:22.330] iteration 10500 : model1 loss : 0.188840 model2 loss : 0.283193
[22:46:22.984] iteration 10501 : model1 loss : 0.204123 model2 loss : 0.215613
[22:46:23.329] iteration 10502 : model1 loss : 0.182656 model2 loss : 0.228158
[22:46:23.678] iteration 10503 : model1 loss : 0.225324 model2 loss : 0.256893
[22:46:24.021] iteration 10504 : model1 loss : 0.195573 model2 loss : 0.284414
[22:46:24.370] iteration 10505 : model1 loss : 0.252784 model2 loss : 0.246445
[22:46:24.718] iteration 10506 : model1 loss : 0.246086 model2 loss : 0.243581
[22:46:25.062] iteration 10507 : model1 loss : 0.280019 model2 loss : 0.309067
[22:46:25.406] iteration 10508 : model1 loss : 0.224057 model2 loss : 0.250806
[22:46:25.751] iteration 10509 : model1 loss : 0.272433 model2 loss : 0.290233
[22:46:26.095] iteration 10510 : model1 loss : 0.379638 model2 loss : 0.268116
[22:46:26.446] iteration 10511 : model1 loss : 0.226727 model2 loss : 0.289730
[22:46:26.786] iteration 10512 : model1 loss : 0.250330 model2 loss : 0.251760
[22:46:27.124] iteration 10513 : model1 loss : 0.316230 model2 loss : 0.328595
[22:46:27.468] iteration 10514 : model1 loss : 0.274508 model2 loss : 0.357565
[22:46:27.813] iteration 10515 : model1 loss : 0.231175 model2 loss : 0.206975
[22:46:28.154] iteration 10516 : model1 loss : 0.275739 model2 loss : 0.300653
[22:46:28.498] iteration 10517 : model1 loss : 0.176278 model2 loss : 0.203374
[22:46:28.841] iteration 10518 : model1 loss : 0.239355 model2 loss : 0.204309
[22:46:29.187] iteration 10519 : model1 loss : 0.195473 model2 loss : 0.229620
[22:46:29.532] iteration 10520 : model1 loss : 0.187193 model2 loss : 0.239411
[22:46:29.875] iteration 10521 : model1 loss : 0.162125 model2 loss : 0.157872
[22:46:30.219] iteration 10522 : model1 loss : 0.275132 model2 loss : 0.306501
[22:46:30.564] iteration 10523 : model1 loss : 0.118125 model2 loss : 0.157952
[22:46:30.905] iteration 10524 : model1 loss : 0.277507 model2 loss : 0.282226
[22:46:31.249] iteration 10525 : model1 loss : 0.203921 model2 loss : 0.260474
[22:46:31.594] iteration 10526 : model1 loss : 0.264794 model2 loss : 0.294238
[22:46:31.939] iteration 10527 : model1 loss : 0.236801 model2 loss : 0.279518
[22:46:32.284] iteration 10528 : model1 loss : 0.217257 model2 loss : 0.218915
[22:46:32.629] iteration 10529 : model1 loss : 0.235286 model2 loss : 0.299012
[22:46:32.970] iteration 10530 : model1 loss : 0.283697 model2 loss : 0.310106
[22:46:33.317] iteration 10531 : model1 loss : 0.299351 model2 loss : 0.332663
[22:46:33.665] iteration 10532 : model1 loss : 0.301519 model2 loss : 0.307991
[22:46:34.006] iteration 10533 : model1 loss : 0.347598 model2 loss : 0.332176
[22:46:34.351] iteration 10534 : model1 loss : 0.332987 model2 loss : 0.345535
[22:46:34.695] iteration 10535 : model1 loss : 0.277975 model2 loss : 0.280412
[22:46:35.040] iteration 10536 : model1 loss : 0.292220 model2 loss : 0.323859
[22:46:35.385] iteration 10537 : model1 loss : 0.312847 model2 loss : 0.337823
[22:46:35.724] iteration 10538 : model1 loss : 0.217184 model2 loss : 0.282699
[22:46:36.065] iteration 10539 : model1 loss : 0.242295 model2 loss : 0.252054
[22:46:36.405] iteration 10540 : model1 loss : 0.232267 model2 loss : 0.123106
[22:46:36.745] iteration 10541 : model1 loss : 0.271891 model2 loss : 0.313700
[22:46:37.091] iteration 10542 : model1 loss : 0.325129 model2 loss : 0.314502
[22:46:37.439] iteration 10543 : model1 loss : 0.302817 model2 loss : 0.316797
[22:46:37.784] iteration 10544 : model1 loss : 0.168063 model2 loss : 0.209707
[22:46:38.125] iteration 10545 : model1 loss : 0.328193 model2 loss : 0.392970
[22:46:38.472] iteration 10546 : model1 loss : 0.361341 model2 loss : 0.356363
[22:46:38.818] iteration 10547 : model1 loss : 0.262861 model2 loss : 0.288162
[22:46:39.162] iteration 10548 : model1 loss : 0.340238 model2 loss : 0.318249
[22:46:39.502] iteration 10549 : model1 loss : 0.278019 model2 loss : 0.278322
[22:46:39.847] iteration 10550 : model1 loss : 0.193771 model2 loss : 0.221870
[22:46:40.516] iteration 10551 : model1 loss : 0.165520 model2 loss : 0.169081
[22:46:40.861] iteration 10552 : model1 loss : 0.219854 model2 loss : 0.188238
[22:46:41.201] iteration 10553 : model1 loss : 0.269144 model2 loss : 0.278193
[22:46:41.543] iteration 10554 : model1 loss : 0.266438 model2 loss : 0.311760
[22:46:41.888] iteration 10555 : model1 loss : 0.287626 model2 loss : 0.287272
[22:46:42.231] iteration 10556 : model1 loss : 0.244006 model2 loss : 0.308098
[22:46:42.572] iteration 10557 : model1 loss : 0.255850 model2 loss : 0.264373
[22:46:42.917] iteration 10558 : model1 loss : 0.232773 model2 loss : 0.265387
[22:46:43.257] iteration 10559 : model1 loss : 0.149595 model2 loss : 0.150608
[22:46:43.608] iteration 10560 : model1 loss : 0.336233 model2 loss : 0.405326
[22:46:43.952] iteration 10561 : model1 loss : 0.278306 model2 loss : 0.319741
[22:46:44.296] iteration 10562 : model1 loss : 0.275180 model2 loss : 0.264641
[22:46:44.639] iteration 10563 : model1 loss : 0.400537 model2 loss : 0.402813
[22:46:44.979] iteration 10564 : model1 loss : 0.206161 model2 loss : 0.297233
[22:46:45.318] iteration 10565 : model1 loss : 0.285986 model2 loss : 0.314927
[22:46:45.657] iteration 10566 : model1 loss : 0.291705 model2 loss : 0.279392
[22:46:46.003] iteration 10567 : model1 loss : 0.332638 model2 loss : 0.337939
[22:46:46.347] iteration 10568 : model1 loss : 0.307511 model2 loss : 0.246861
[22:46:46.691] iteration 10569 : model1 loss : 0.184463 model2 loss : 0.197214
[22:46:47.036] iteration 10570 : model1 loss : 0.164985 model2 loss : 0.184643
[22:46:47.378] iteration 10571 : model1 loss : 0.140023 model2 loss : 0.209900
[22:46:47.722] iteration 10572 : model1 loss : 0.270845 model2 loss : 0.287384
[22:46:48.064] iteration 10573 : model1 loss : 0.243902 model2 loss : 0.256460
[22:46:48.410] iteration 10574 : model1 loss : 0.219641 model2 loss : 0.212666
[22:46:48.755] iteration 10575 : model1 loss : 0.239601 model2 loss : 0.295909
[22:46:49.098] iteration 10576 : model1 loss : 0.234414 model2 loss : 0.213045
[22:46:49.442] iteration 10577 : model1 loss : 0.194180 model2 loss : 0.242433
[22:46:49.789] iteration 10578 : model1 loss : 0.275618 model2 loss : 0.287147
[22:46:50.132] iteration 10579 : model1 loss : 0.298062 model2 loss : 0.336066
[22:46:50.477] iteration 10580 : model1 loss : 0.186870 model2 loss : 0.208080
[22:46:50.819] iteration 10581 : model1 loss : 0.206944 model2 loss : 0.236211
[22:46:51.170] iteration 10582 : model1 loss : 0.270155 model2 loss : 0.282840
[22:46:51.514] iteration 10583 : model1 loss : 0.182812 model2 loss : 0.179113
[22:46:51.858] iteration 10584 : model1 loss : 0.206100 model2 loss : 0.252065
[22:46:52.198] iteration 10585 : model1 loss : 0.135440 model2 loss : 0.181043
[22:46:52.538] iteration 10586 : model1 loss : 0.218926 model2 loss : 0.269501
[22:46:52.877] iteration 10587 : model1 loss : 0.270642 model2 loss : 0.296842
[22:46:53.217] iteration 10588 : model1 loss : 0.246249 model2 loss : 0.264387
[22:46:53.556] iteration 10589 : model1 loss : 0.212096 model2 loss : 0.243298
[22:46:53.897] iteration 10590 : model1 loss : 0.255514 model2 loss : 0.275928
[22:46:54.237] iteration 10591 : model1 loss : 0.183606 model2 loss : 0.257575
[22:46:54.576] iteration 10592 : model1 loss : 0.157739 model2 loss : 0.165971
[22:46:54.920] iteration 10593 : model1 loss : 0.243384 model2 loss : 0.256136
[22:46:55.264] iteration 10594 : model1 loss : 0.240231 model2 loss : 0.263705
[22:46:55.606] iteration 10595 : model1 loss : 0.274456 model2 loss : 0.291947
[22:46:55.951] iteration 10596 : model1 loss : 0.223906 model2 loss : 0.232450
[22:46:56.292] iteration 10597 : model1 loss : 0.339232 model2 loss : 0.354922
[22:46:56.639] iteration 10598 : model1 loss : 0.226840 model2 loss : 0.320493
[22:46:56.978] iteration 10599 : model1 loss : 0.226644 model2 loss : 0.264194
[22:46:57.316] iteration 10600 : model1 loss : 0.195552 model2 loss : 0.226189
[22:46:57.955] iteration 10601 : model1 loss : 0.265843 model2 loss : 0.274721
[22:46:58.294] iteration 10602 : model1 loss : 0.334732 model2 loss : 0.330057
[22:46:58.632] iteration 10603 : model1 loss : 0.197496 model2 loss : 0.213033
[22:46:58.970] iteration 10604 : model1 loss : 0.266014 model2 loss : 0.304583
[22:46:59.307] iteration 10605 : model1 loss : 0.187299 model2 loss : 0.241677
[22:46:59.646] iteration 10606 : model1 loss : 0.274136 model2 loss : 0.309794
[22:46:59.984] iteration 10607 : model1 loss : 0.265195 model2 loss : 0.285171
[22:47:00.322] iteration 10608 : model1 loss : 0.217124 model2 loss : 0.191910
[22:47:00.661] iteration 10609 : model1 loss : 0.326756 model2 loss : 0.393691
[22:47:00.999] iteration 10610 : model1 loss : 0.235045 model2 loss : 0.240344
[22:47:01.337] iteration 10611 : model1 loss : 0.168127 model2 loss : 0.151490
[22:47:01.675] iteration 10612 : model1 loss : 0.173385 model2 loss : 0.220856
[22:47:02.013] iteration 10613 : model1 loss : 0.286250 model2 loss : 0.219679
[22:47:02.352] iteration 10614 : model1 loss : 0.299420 model2 loss : 0.307988
[22:47:02.691] iteration 10615 : model1 loss : 0.276614 model2 loss : 0.299795
[22:47:03.028] iteration 10616 : model1 loss : 0.138738 model2 loss : 0.172220
[22:47:03.371] iteration 10617 : model1 loss : 0.131955 model2 loss : 0.281901
[22:47:03.710] iteration 10618 : model1 loss : 0.184213 model2 loss : 0.194531
[22:47:04.050] iteration 10619 : model1 loss : 0.185084 model2 loss : 0.190600
[22:47:04.389] iteration 10620 : model1 loss : 0.270140 model2 loss : 0.283681
[22:47:04.727] iteration 10621 : model1 loss : 0.207499 model2 loss : 0.256495
[22:47:05.065] iteration 10622 : model1 loss : 0.201416 model2 loss : 0.221135
[22:47:05.404] iteration 10623 : model1 loss : 0.234523 model2 loss : 0.230014
[22:47:05.742] iteration 10624 : model1 loss : 0.246851 model2 loss : 0.244018
[22:47:06.081] iteration 10625 : model1 loss : 0.288754 model2 loss : 0.320746
[22:47:06.422] iteration 10626 : model1 loss : 0.269080 model2 loss : 0.239069
[22:47:06.761] iteration 10627 : model1 loss : 0.147028 model2 loss : 0.158605
[22:47:07.100] iteration 10628 : model1 loss : 0.176315 model2 loss : 0.229736
[22:47:07.439] iteration 10629 : model1 loss : 0.148458 model2 loss : 0.195679
[22:47:07.780] iteration 10630 : model1 loss : 0.135806 model2 loss : 0.138906
[22:47:08.120] iteration 10631 : model1 loss : 0.180387 model2 loss : 0.189558
[22:47:08.459] iteration 10632 : model1 loss : 0.161818 model2 loss : 0.192755
[22:47:08.800] iteration 10633 : model1 loss : 0.249014 model2 loss : 0.296535
[22:47:09.139] iteration 10634 : model1 loss : 0.219759 model2 loss : 0.242218
[22:47:09.478] iteration 10635 : model1 loss : 0.232711 model2 loss : 0.259926
[22:47:09.817] iteration 10636 : model1 loss : 0.120877 model2 loss : 0.107237
[22:47:10.159] iteration 10637 : model1 loss : 0.194262 model2 loss : 0.236366
[22:47:10.499] iteration 10638 : model1 loss : 0.258447 model2 loss : 0.348052
[22:47:10.838] iteration 10639 : model1 loss : 0.192743 model2 loss : 0.235481
[22:47:11.176] iteration 10640 : model1 loss : 0.275659 model2 loss : 0.265744
[22:47:11.535] iteration 10641 : model1 loss : 0.306964 model2 loss : 0.255741
[22:47:11.867] iteration 10642 : model1 loss : 0.307391 model2 loss : 0.282984
[22:47:12.196] iteration 10643 : model1 loss : 0.175583 model2 loss : 0.170715
[22:47:12.526] iteration 10644 : model1 loss : 0.233059 model2 loss : 0.229976
[22:47:12.856] iteration 10645 : model1 loss : 0.238512 model2 loss : 0.253776
[22:47:13.184] iteration 10646 : model1 loss : 0.317301 model2 loss : 0.338130
[22:47:13.514] iteration 10647 : model1 loss : 0.301149 model2 loss : 0.359581
[22:47:13.845] iteration 10648 : model1 loss : 0.209711 model2 loss : 0.231650
[22:47:14.174] iteration 10649 : model1 loss : 0.150671 model2 loss : 0.104131
[22:47:14.503] iteration 10650 : model1 loss : 0.184148 model2 loss : 0.222346
[22:47:15.034] iteration 10651 : model1 loss : 0.267145 model2 loss : 0.281143
[22:47:15.362] iteration 10652 : model1 loss : 0.278164 model2 loss : 0.279191
[22:47:15.691] iteration 10653 : model1 loss : 0.197194 model2 loss : 0.225149
[22:47:16.021] iteration 10654 : model1 loss : 0.210847 model2 loss : 0.221558
[22:47:16.351] iteration 10655 : model1 loss : 0.280456 model2 loss : 0.305209
[22:47:16.680] iteration 10656 : model1 loss : 0.189785 model2 loss : 0.256474
[22:47:17.010] iteration 10657 : model1 loss : 0.211389 model2 loss : 0.219545
[22:47:17.339] iteration 10658 : model1 loss : 0.218228 model2 loss : 0.248978
[22:47:17.668] iteration 10659 : model1 loss : 0.223761 model2 loss : 0.217360
[22:47:17.997] iteration 10660 : model1 loss : 0.207284 model2 loss : 0.174654
[22:47:18.328] iteration 10661 : model1 loss : 0.277744 model2 loss : 0.293257
[22:47:18.658] iteration 10662 : model1 loss : 0.277856 model2 loss : 0.246525
[22:47:18.987] iteration 10663 : model1 loss : 0.216480 model2 loss : 0.205765
[22:47:19.316] iteration 10664 : model1 loss : 0.253823 model2 loss : 0.278728
[22:47:19.645] iteration 10665 : model1 loss : 0.188275 model2 loss : 0.249848
[22:47:19.974] iteration 10666 : model1 loss : 0.327584 model2 loss : 0.301153
[22:47:20.305] iteration 10667 : model1 loss : 0.139925 model2 loss : 0.135448
[22:47:20.635] iteration 10668 : model1 loss : 0.269918 model2 loss : 0.324377
[22:47:20.964] iteration 10669 : model1 loss : 0.272723 model2 loss : 0.323082
[22:47:21.293] iteration 10670 : model1 loss : 0.255978 model2 loss : 0.184903
[22:47:21.622] iteration 10671 : model1 loss : 0.198751 model2 loss : 0.189235
[22:47:21.951] iteration 10672 : model1 loss : 0.255266 model2 loss : 0.280241
[22:47:22.280] iteration 10673 : model1 loss : 0.141862 model2 loss : 0.154243
[22:47:22.609] iteration 10674 : model1 loss : 0.178699 model2 loss : 0.208911
[22:47:22.938] iteration 10675 : model1 loss : 0.240120 model2 loss : 0.193871
[22:47:23.268] iteration 10676 : model1 loss : 0.292804 model2 loss : 0.290633
[22:47:23.598] iteration 10677 : model1 loss : 0.148501 model2 loss : 0.206808
[22:47:23.927] iteration 10678 : model1 loss : 0.197011 model2 loss : 0.215724
[22:47:24.255] iteration 10679 : model1 loss : 0.344801 model2 loss : 0.339035
[22:47:24.584] iteration 10680 : model1 loss : 0.276071 model2 loss : 0.286272
[22:47:24.913] iteration 10681 : model1 loss : 0.225736 model2 loss : 0.328659
[22:47:25.243] iteration 10682 : model1 loss : 0.267011 model2 loss : 0.308811
[22:47:25.571] iteration 10683 : model1 loss : 0.249443 model2 loss : 0.285422
[22:47:25.900] iteration 10684 : model1 loss : 0.208782 model2 loss : 0.264652
[22:47:26.229] iteration 10685 : model1 loss : 0.115466 model2 loss : 0.173594
[22:47:26.558] iteration 10686 : model1 loss : 0.215349 model2 loss : 0.190365
[22:47:26.888] iteration 10687 : model1 loss : 0.194737 model2 loss : 0.124008
[22:47:27.216] iteration 10688 : model1 loss : 0.327907 model2 loss : 0.336791
[22:47:27.548] iteration 10689 : model1 loss : 0.288181 model2 loss : 0.291581
[22:47:27.878] iteration 10690 : model1 loss : 0.226455 model2 loss : 0.267496
[22:47:28.213] iteration 10691 : model1 loss : 0.283997 model2 loss : 0.315300
[22:47:28.553] iteration 10692 : model1 loss : 0.217643 model2 loss : 0.307522
[22:47:28.891] iteration 10693 : model1 loss : 0.123454 model2 loss : 0.203726
[22:47:29.229] iteration 10694 : model1 loss : 0.228855 model2 loss : 0.276013
[22:47:29.568] iteration 10695 : model1 loss : 0.140231 model2 loss : 0.219867
[22:47:29.906] iteration 10696 : model1 loss : 0.171323 model2 loss : 0.169329
[22:47:30.244] iteration 10697 : model1 loss : 0.275674 model2 loss : 0.319370
[22:47:30.582] iteration 10698 : model1 loss : 0.095845 model2 loss : 0.098351
[22:47:30.920] iteration 10699 : model1 loss : 0.288869 model2 loss : 0.276533
[22:47:31.258] iteration 10700 : model1 loss : 0.206308 model2 loss : 0.211403
[22:47:31.903] iteration 10701 : model1 loss : 0.328390 model2 loss : 0.245762
[22:47:32.241] iteration 10702 : model1 loss : 0.260997 model2 loss : 0.317187
[22:47:32.580] iteration 10703 : model1 loss : 0.301480 model2 loss : 0.296778
[22:47:32.916] iteration 10704 : model1 loss : 0.263629 model2 loss : 0.276548
[22:47:33.255] iteration 10705 : model1 loss : 0.140076 model2 loss : 0.171321
[22:47:33.597] iteration 10706 : model1 loss : 0.174900 model2 loss : 0.169805
[22:47:33.936] iteration 10707 : model1 loss : 0.177598 model2 loss : 0.224612
[22:47:34.273] iteration 10708 : model1 loss : 0.211740 model2 loss : 0.268156
[22:47:34.612] iteration 10709 : model1 loss : 0.219467 model2 loss : 0.263211
[22:47:34.954] iteration 10710 : model1 loss : 0.206831 model2 loss : 0.226800
[22:47:35.298] iteration 10711 : model1 loss : 0.290775 model2 loss : 0.359432
[22:47:35.636] iteration 10712 : model1 loss : 0.221585 model2 loss : 0.240497
[22:47:35.975] iteration 10713 : model1 loss : 0.277407 model2 loss : 0.358790
[22:47:36.314] iteration 10714 : model1 loss : 0.188188 model2 loss : 0.236772
[22:47:36.652] iteration 10715 : model1 loss : 0.255788 model2 loss : 0.223926
[22:47:36.991] iteration 10716 : model1 loss : 0.209290 model2 loss : 0.242596
[22:47:37.330] iteration 10717 : model1 loss : 0.233135 model2 loss : 0.320467
[22:47:37.668] iteration 10718 : model1 loss : 0.229492 model2 loss : 0.284544
[22:47:38.011] iteration 10719 : model1 loss : 0.160619 model2 loss : 0.159110
[22:47:38.350] iteration 10720 : model1 loss : 0.095068 model2 loss : 0.145196
[22:47:38.688] iteration 10721 : model1 loss : 0.183060 model2 loss : 0.200293
[22:47:39.023] iteration 10722 : model1 loss : 0.197016 model2 loss : 0.284878
[22:47:39.362] iteration 10723 : model1 loss : 0.165107 model2 loss : 0.125037
[22:47:39.700] iteration 10724 : model1 loss : 0.181778 model2 loss : 0.235354
[22:47:40.038] iteration 10725 : model1 loss : 0.346329 model2 loss : 0.305920
[22:47:40.375] iteration 10726 : model1 loss : 0.218045 model2 loss : 0.264999
[22:47:40.712] iteration 10727 : model1 loss : 0.278347 model2 loss : 0.332915
[22:47:41.050] iteration 10728 : model1 loss : 0.194461 model2 loss : 0.230088
[22:47:41.390] iteration 10729 : model1 loss : 0.269361 model2 loss : 0.223974
[22:47:41.728] iteration 10730 : model1 loss : 0.332930 model2 loss : 0.330600
[22:47:42.066] iteration 10731 : model1 loss : 0.356095 model2 loss : 0.361336
[22:47:42.403] iteration 10732 : model1 loss : 0.177650 model2 loss : 0.193155
[22:47:42.741] iteration 10733 : model1 loss : 0.290696 model2 loss : 0.326077
[22:47:43.078] iteration 10734 : model1 loss : 0.205791 model2 loss : 0.250558
[22:47:43.416] iteration 10735 : model1 loss : 0.353056 model2 loss : 0.373673
[22:47:43.757] iteration 10736 : model1 loss : 0.229182 model2 loss : 0.236265
[22:47:44.094] iteration 10737 : model1 loss : 0.151177 model2 loss : 0.273151
[22:47:44.432] iteration 10738 : model1 loss : 0.247042 model2 loss : 0.316381
[22:47:44.769] iteration 10739 : model1 loss : 0.207548 model2 loss : 0.254052
[22:47:45.106] iteration 10740 : model1 loss : 0.174658 model2 loss : 0.217706
[22:47:45.447] iteration 10741 : model1 loss : 0.202645 model2 loss : 0.227353
[22:47:45.785] iteration 10742 : model1 loss : 0.222809 model2 loss : 0.216206
[22:47:46.123] iteration 10743 : model1 loss : 0.209540 model2 loss : 0.240485
[22:47:46.461] iteration 10744 : model1 loss : 0.332232 model2 loss : 0.329031
[22:47:46.799] iteration 10745 : model1 loss : 0.136324 model2 loss : 0.205875
[22:47:47.138] iteration 10746 : model1 loss : 0.144630 model2 loss : 0.148554
[22:47:47.478] iteration 10747 : model1 loss : 0.126673 model2 loss : 0.179041
[22:47:47.815] iteration 10748 : model1 loss : 0.345001 model2 loss : 0.225618
[22:47:48.152] iteration 10749 : model1 loss : 0.172471 model2 loss : 0.215598
[22:47:48.491] iteration 10750 : model1 loss : 0.109083 model2 loss : 0.172493
[22:47:49.141] iteration 10751 : model1 loss : 0.160389 model2 loss : 0.186393
[22:47:49.479] iteration 10752 : model1 loss : 0.238713 model2 loss : 0.229746
[22:47:49.819] iteration 10753 : model1 loss : 0.343478 model2 loss : 0.314977
[22:47:50.157] iteration 10754 : model1 loss : 0.102680 model2 loss : 0.144548
[22:47:50.495] iteration 10755 : model1 loss : 0.255851 model2 loss : 0.312754
[22:47:50.833] iteration 10756 : model1 loss : 0.255328 model2 loss : 0.258269
[22:47:51.172] iteration 10757 : model1 loss : 0.230464 model2 loss : 0.260210
[22:47:51.509] iteration 10758 : model1 loss : 0.330139 model2 loss : 0.343301
[22:47:51.849] iteration 10759 : model1 loss : 0.292055 model2 loss : 0.236500
[22:47:52.187] iteration 10760 : model1 loss : 0.187714 model2 loss : 0.243442
[22:47:52.518] iteration 10761 : model1 loss : 0.228861 model2 loss : 0.295857
[22:47:52.846] iteration 10762 : model1 loss : 0.205112 model2 loss : 0.202098
[22:47:53.175] iteration 10763 : model1 loss : 0.278948 model2 loss : 0.289978
[22:47:53.505] iteration 10764 : model1 loss : 0.389112 model2 loss : 0.305472
[22:47:53.833] iteration 10765 : model1 loss : 0.186923 model2 loss : 0.219119
[22:47:54.161] iteration 10766 : model1 loss : 0.216646 model2 loss : 0.257569
[22:47:54.489] iteration 10767 : model1 loss : 0.215867 model2 loss : 0.266547
[22:47:54.818] iteration 10768 : model1 loss : 0.184663 model2 loss : 0.206459
[22:47:55.151] iteration 10769 : model1 loss : 0.272224 model2 loss : 0.374214
[22:47:55.482] iteration 10770 : model1 loss : 0.175717 model2 loss : 0.277285
[22:47:55.814] iteration 10771 : model1 loss : 0.214820 model2 loss : 0.217351
[22:47:56.145] iteration 10772 : model1 loss : 0.189173 model2 loss : 0.203884
[22:47:56.476] iteration 10773 : model1 loss : 0.181365 model2 loss : 0.189262
[22:47:56.807] iteration 10774 : model1 loss : 0.174889 model2 loss : 0.157872
[22:47:57.138] iteration 10775 : model1 loss : 0.127272 model2 loss : 0.128990
[22:47:57.469] iteration 10776 : model1 loss : 0.173166 model2 loss : 0.196361
[22:47:57.801] iteration 10777 : model1 loss : 0.191691 model2 loss : 0.206165
[22:47:58.132] iteration 10778 : model1 loss : 0.256502 model2 loss : 0.225236
[22:47:58.463] iteration 10779 : model1 loss : 0.155389 model2 loss : 0.200574
[22:47:58.795] iteration 10780 : model1 loss : 0.116970 model2 loss : 0.200384
[22:47:59.123] iteration 10781 : model1 loss : 0.189735 model2 loss : 0.275510
[22:47:59.453] iteration 10782 : model1 loss : 0.271251 model2 loss : 0.269332
[22:47:59.783] iteration 10783 : model1 loss : 0.168915 model2 loss : 0.178674
[22:48:00.112] iteration 10784 : model1 loss : 0.271608 model2 loss : 0.268197
[22:48:00.442] iteration 10785 : model1 loss : 0.239450 model2 loss : 0.326804
[22:48:00.772] iteration 10786 : model1 loss : 0.264418 model2 loss : 0.241618
[22:48:01.104] iteration 10787 : model1 loss : 0.238717 model2 loss : 0.250655
[22:48:01.436] iteration 10788 : model1 loss : 0.133569 model2 loss : 0.206551
[22:48:01.766] iteration 10789 : model1 loss : 0.253507 model2 loss : 0.299679
[22:48:02.095] iteration 10790 : model1 loss : 0.290903 model2 loss : 0.279417
[22:48:02.425] iteration 10791 : model1 loss : 0.295536 model2 loss : 0.268629
[22:48:02.763] iteration 10792 : model1 loss : 0.205690 model2 loss : 0.156752
[22:48:03.093] iteration 10793 : model1 loss : 0.186731 model2 loss : 0.247429
[22:48:03.423] iteration 10794 : model1 loss : 0.199505 model2 loss : 0.213733
[22:48:03.751] iteration 10795 : model1 loss : 0.161723 model2 loss : 0.192241
[22:48:04.080] iteration 10796 : model1 loss : 0.265558 model2 loss : 0.334202
[22:48:04.411] iteration 10797 : model1 loss : 0.197117 model2 loss : 0.201632
[22:48:04.741] iteration 10798 : model1 loss : 0.274474 model2 loss : 0.257047
[22:48:05.071] iteration 10799 : model1 loss : 0.284016 model2 loss : 0.286086
[22:48:05.401] iteration 10800 : model1 loss : 0.148985 model2 loss : 0.230489
[22:48:05.961] iteration 10801 : model1 loss : 0.291301 model2 loss : 0.359202
[22:48:06.290] iteration 10802 : model1 loss : 0.185027 model2 loss : 0.254548
[22:48:06.621] iteration 10803 : model1 loss : 0.299950 model2 loss : 0.260493
[22:48:06.950] iteration 10804 : model1 loss : 0.247573 model2 loss : 0.258932
[22:48:07.280] iteration 10805 : model1 loss : 0.177247 model2 loss : 0.193275
[22:48:07.611] iteration 10806 : model1 loss : 0.162106 model2 loss : 0.194670
[22:48:07.940] iteration 10807 : model1 loss : 0.213911 model2 loss : 0.272970
[22:48:08.271] iteration 10808 : model1 loss : 0.255259 model2 loss : 0.229794
[22:48:08.601] iteration 10809 : model1 loss : 0.186741 model2 loss : 0.230487
[22:48:08.931] iteration 10810 : model1 loss : 0.205006 model2 loss : 0.300329
[22:48:09.260] iteration 10811 : model1 loss : 0.228370 model2 loss : 0.237079
[22:48:09.590] iteration 10812 : model1 loss : 0.179872 model2 loss : 0.217349
[22:48:09.921] iteration 10813 : model1 loss : 0.269071 model2 loss : 0.395763
[22:48:10.251] iteration 10814 : model1 loss : 0.182884 model2 loss : 0.222364
[22:48:10.582] iteration 10815 : model1 loss : 0.181727 model2 loss : 0.273192
[22:48:10.912] iteration 10816 : model1 loss : 0.358067 model2 loss : 0.315195
[22:48:11.256] iteration 10817 : model1 loss : 0.236318 model2 loss : 0.223612
[22:48:11.587] iteration 10818 : model1 loss : 0.228342 model2 loss : 0.193020
[22:48:11.916] iteration 10819 : model1 loss : 0.343232 model2 loss : 0.434963
[22:48:12.243] iteration 10820 : model1 loss : 0.174218 model2 loss : 0.190244
[22:48:12.572] iteration 10821 : model1 loss : 0.252141 model2 loss : 0.252749
[22:48:12.902] iteration 10822 : model1 loss : 0.368999 model2 loss : 0.265141
[22:48:13.231] iteration 10823 : model1 loss : 0.155492 model2 loss : 0.227923
[22:48:13.559] iteration 10824 : model1 loss : 0.223057 model2 loss : 0.221125
[22:48:13.887] iteration 10825 : model1 loss : 0.287843 model2 loss : 0.312174
[22:48:14.211] iteration 10826 : model1 loss : 0.211542 model2 loss : 0.206365
[22:48:14.539] iteration 10827 : model1 loss : 0.185662 model2 loss : 0.215880
[22:48:14.867] iteration 10828 : model1 loss : 0.231198 model2 loss : 0.245955
[22:48:15.194] iteration 10829 : model1 loss : 0.223285 model2 loss : 0.331524
[22:48:15.518] iteration 10830 : model1 loss : 0.300812 model2 loss : 0.235218
[22:48:15.844] iteration 10831 : model1 loss : 0.139995 model2 loss : 0.203662
[22:48:16.171] iteration 10832 : model1 loss : 0.224724 model2 loss : 0.261875
[22:48:16.499] iteration 10833 : model1 loss : 0.283202 model2 loss : 0.292328
[22:48:16.824] iteration 10834 : model1 loss : 0.113829 model2 loss : 0.196949
[22:48:17.149] iteration 10835 : model1 loss : 0.201092 model2 loss : 0.232462
[22:48:17.477] iteration 10836 : model1 loss : 0.245013 model2 loss : 0.221580
[22:48:17.804] iteration 10837 : model1 loss : 0.129252 model2 loss : 0.138248
[22:48:18.128] iteration 10838 : model1 loss : 0.216104 model2 loss : 0.238473
[22:48:18.455] iteration 10839 : model1 loss : 0.209075 model2 loss : 0.343385
[22:48:18.783] iteration 10840 : model1 loss : 0.267819 model2 loss : 0.214561
[22:48:19.112] iteration 10841 : model1 loss : 0.275325 model2 loss : 0.247448
[22:48:19.438] iteration 10842 : model1 loss : 0.137285 model2 loss : 0.177711
[22:48:19.770] iteration 10843 : model1 loss : 0.203536 model2 loss : 0.212007
[22:48:20.107] iteration 10844 : model1 loss : 0.228142 model2 loss : 0.305120
[22:48:20.445] iteration 10845 : model1 loss : 0.225226 model2 loss : 0.246199
[22:48:20.777] iteration 10846 : model1 loss : 0.205281 model2 loss : 0.263084
[22:48:21.113] iteration 10847 : model1 loss : 0.077748 model2 loss : 0.175056
[22:48:21.454] iteration 10848 : model1 loss : 0.192796 model2 loss : 0.218507
[22:48:21.794] iteration 10849 : model1 loss : 0.301385 model2 loss : 0.271525
[22:48:22.134] iteration 10850 : model1 loss : 0.400866 model2 loss : 0.402917
[22:48:22.737] iteration 10851 : model1 loss : 0.318677 model2 loss : 0.324710
[22:48:23.069] iteration 10852 : model1 loss : 0.252388 model2 loss : 0.264016
[22:48:23.406] iteration 10853 : model1 loss : 0.243557 model2 loss : 0.264435
[22:48:23.744] iteration 10854 : model1 loss : 0.367216 model2 loss : 0.334909
[22:48:24.079] iteration 10855 : model1 loss : 0.273889 model2 loss : 0.174525
[22:48:24.416] iteration 10856 : model1 loss : 0.224638 model2 loss : 0.307956
[22:48:24.752] iteration 10857 : model1 loss : 0.321542 model2 loss : 0.257192
[22:48:25.089] iteration 10858 : model1 loss : 0.239393 model2 loss : 0.264920
[22:48:25.428] iteration 10859 : model1 loss : 0.269059 model2 loss : 0.224529
[22:48:25.767] iteration 10860 : model1 loss : 0.184054 model2 loss : 0.234852
[22:48:26.103] iteration 10861 : model1 loss : 0.269499 model2 loss : 0.280720
[22:48:26.439] iteration 10862 : model1 loss : 0.285420 model2 loss : 0.295720
[22:48:26.776] iteration 10863 : model1 loss : 0.249151 model2 loss : 0.239765
[22:48:27.111] iteration 10864 : model1 loss : 0.222491 model2 loss : 0.219798
[22:48:27.448] iteration 10865 : model1 loss : 0.204985 model2 loss : 0.222429
[22:48:27.784] iteration 10866 : model1 loss : 0.202481 model2 loss : 0.185194
[22:48:28.120] iteration 10867 : model1 loss : 0.216045 model2 loss : 0.294593
[22:48:28.458] iteration 10868 : model1 loss : 0.332093 model2 loss : 0.274134
[22:48:28.792] iteration 10869 : model1 loss : 0.139554 model2 loss : 0.247745
[22:48:29.124] iteration 10870 : model1 loss : 0.185877 model2 loss : 0.267463
[22:48:29.462] iteration 10871 : model1 loss : 0.400365 model2 loss : 0.409795
[22:48:29.798] iteration 10872 : model1 loss : 0.346107 model2 loss : 0.332309
[22:48:30.140] iteration 10873 : model1 loss : 0.121627 model2 loss : 0.179421
[22:48:30.468] iteration 10874 : model1 loss : 0.224325 model2 loss : 0.161880
[22:48:30.798] iteration 10875 : model1 loss : 0.232395 model2 loss : 0.260089
[22:48:31.124] iteration 10876 : model1 loss : 0.325627 model2 loss : 0.305987
[22:48:31.455] iteration 10877 : model1 loss : 0.196874 model2 loss : 0.272156
[22:48:31.782] iteration 10878 : model1 loss : 0.224612 model2 loss : 0.169222
[22:48:32.108] iteration 10879 : model1 loss : 0.178921 model2 loss : 0.180051
[22:48:32.436] iteration 10880 : model1 loss : 0.269534 model2 loss : 0.306814
[22:48:32.760] iteration 10881 : model1 loss : 0.286947 model2 loss : 0.315758
[22:48:33.085] iteration 10882 : model1 loss : 0.278440 model2 loss : 0.338945
[22:48:33.415] iteration 10883 : model1 loss : 0.172257 model2 loss : 0.218440
[22:48:33.740] iteration 10884 : model1 loss : 0.207612 model2 loss : 0.199417
[22:48:34.065] iteration 10885 : model1 loss : 0.109033 model2 loss : 0.129083
[22:48:34.389] iteration 10886 : model1 loss : 0.306051 model2 loss : 0.315862
[22:48:34.718] iteration 10887 : model1 loss : 0.126158 model2 loss : 0.199168
[22:48:35.043] iteration 10888 : model1 loss : 0.312364 model2 loss : 0.282047
[22:48:35.376] iteration 10889 : model1 loss : 0.230580 model2 loss : 0.254952
[22:48:35.703] iteration 10890 : model1 loss : 0.285770 model2 loss : 0.296383
[22:48:36.031] iteration 10891 : model1 loss : 0.196165 model2 loss : 0.230883
[22:48:36.356] iteration 10892 : model1 loss : 0.136185 model2 loss : 0.171278
[22:48:36.680] iteration 10893 : model1 loss : 0.194861 model2 loss : 0.272839
[22:48:37.007] iteration 10894 : model1 loss : 0.134395 model2 loss : 0.197181
[22:48:37.335] iteration 10895 : model1 loss : 0.252697 model2 loss : 0.283643
[22:48:37.662] iteration 10896 : model1 loss : 0.170225 model2 loss : 0.170408
[22:48:37.986] iteration 10897 : model1 loss : 0.199460 model2 loss : 0.168830
[22:48:38.313] iteration 10898 : model1 loss : 0.228498 model2 loss : 0.248843
[22:48:38.641] iteration 10899 : model1 loss : 0.104851 model2 loss : 0.148046
[22:48:38.962] iteration 10900 : model1 loss : 0.205151 model2 loss : 0.230545
[22:48:40.198] iteration 10901 : model1 loss : 0.200817 model2 loss : 0.200845
[22:48:40.527] iteration 10902 : model1 loss : 0.171748 model2 loss : 0.187268
[22:48:40.855] iteration 10903 : model1 loss : 0.296882 model2 loss : 0.273191
[22:48:41.185] iteration 10904 : model1 loss : 0.209018 model2 loss : 0.243121
[22:48:41.512] iteration 10905 : model1 loss : 0.294886 model2 loss : 0.288739
[22:48:41.838] iteration 10906 : model1 loss : 0.273053 model2 loss : 0.266190
[22:48:42.162] iteration 10907 : model1 loss : 0.248117 model2 loss : 0.266511
[22:48:42.485] iteration 10908 : model1 loss : 0.273470 model2 loss : 0.316062
[22:48:42.808] iteration 10909 : model1 loss : 0.271550 model2 loss : 0.303138
[22:48:43.132] iteration 10910 : model1 loss : 0.196685 model2 loss : 0.174143
[22:48:43.458] iteration 10911 : model1 loss : 0.379487 model2 loss : 0.299274
[22:48:43.786] iteration 10912 : model1 loss : 0.162468 model2 loss : 0.150831
[22:48:44.110] iteration 10913 : model1 loss : 0.180390 model2 loss : 0.244977
[22:48:44.433] iteration 10914 : model1 loss : 0.200987 model2 loss : 0.217094
[22:48:44.759] iteration 10915 : model1 loss : 0.203874 model2 loss : 0.223618
[22:48:45.084] iteration 10916 : model1 loss : 0.215270 model2 loss : 0.230707
[22:48:45.412] iteration 10917 : model1 loss : 0.292304 model2 loss : 0.268621
[22:48:45.739] iteration 10918 : model1 loss : 0.219621 model2 loss : 0.263420
[22:48:46.063] iteration 10919 : model1 loss : 0.288861 model2 loss : 0.280762
[22:48:46.391] iteration 10920 : model1 loss : 0.250494 model2 loss : 0.246381
[22:48:46.716] iteration 10921 : model1 loss : 0.284908 model2 loss : 0.326182
[22:48:47.047] iteration 10922 : model1 loss : 0.301661 model2 loss : 0.340524
[22:48:47.372] iteration 10923 : model1 loss : 0.315230 model2 loss : 0.292608
[22:48:47.695] iteration 10924 : model1 loss : 0.260100 model2 loss : 0.256975
[22:48:48.018] iteration 10925 : model1 loss : 0.240914 model2 loss : 0.258484
[22:48:48.345] iteration 10926 : model1 loss : 0.327885 model2 loss : 0.339632
[22:48:48.673] iteration 10927 : model1 loss : 0.319021 model2 loss : 0.256571
[22:48:48.997] iteration 10928 : model1 loss : 0.211163 model2 loss : 0.242269
[22:48:49.326] iteration 10929 : model1 loss : 0.183594 model2 loss : 0.167773
[22:48:49.655] iteration 10930 : model1 loss : 0.215445 model2 loss : 0.165817
[22:48:49.983] iteration 10931 : model1 loss : 0.253518 model2 loss : 0.261500
[22:48:50.313] iteration 10932 : model1 loss : 0.405885 model2 loss : 0.338672
[22:48:50.644] iteration 10933 : model1 loss : 0.087103 model2 loss : 0.151022
[22:48:50.970] iteration 10934 : model1 loss : 0.270157 model2 loss : 0.323014
[22:48:51.302] iteration 10935 : model1 loss : 0.189476 model2 loss : 0.182462
[22:48:51.633] iteration 10936 : model1 loss : 0.425266 model2 loss : 0.431938
[22:48:51.963] iteration 10937 : model1 loss : 0.177892 model2 loss : 0.202850
[22:48:52.292] iteration 10938 : model1 loss : 0.190819 model2 loss : 0.185838
[22:48:52.624] iteration 10939 : model1 loss : 0.230332 model2 loss : 0.262700
[22:48:52.951] iteration 10940 : model1 loss : 0.262716 model2 loss : 0.246924
[22:48:53.276] iteration 10941 : model1 loss : 0.206478 model2 loss : 0.230200
[22:48:53.606] iteration 10942 : model1 loss : 0.318857 model2 loss : 0.329216
[22:48:53.935] iteration 10943 : model1 loss : 0.267498 model2 loss : 0.345764
[22:48:54.264] iteration 10944 : model1 loss : 0.193836 model2 loss : 0.292428
[22:48:54.592] iteration 10945 : model1 loss : 0.180581 model2 loss : 0.133329
[22:48:54.918] iteration 10946 : model1 loss : 0.237510 model2 loss : 0.273752
[22:48:55.247] iteration 10947 : model1 loss : 0.289010 model2 loss : 0.239182
[22:48:55.573] iteration 10948 : model1 loss : 0.179380 model2 loss : 0.194116
[22:48:55.896] iteration 10949 : model1 loss : 0.330186 model2 loss : 0.292581
[22:48:56.224] iteration 10950 : model1 loss : 0.192182 model2 loss : 0.301150
[22:48:56.785] iteration 10951 : model1 loss : 0.260284 model2 loss : 0.262534
[22:48:57.113] iteration 10952 : model1 loss : 0.340835 model2 loss : 0.329799
[22:48:57.442] iteration 10953 : model1 loss : 0.176041 model2 loss : 0.189287
[22:48:57.771] iteration 10954 : model1 loss : 0.310845 model2 loss : 0.256455
[22:48:58.100] iteration 10955 : model1 loss : 0.206586 model2 loss : 0.267561
[22:48:58.428] iteration 10956 : model1 loss : 0.237399 model2 loss : 0.255439
[22:48:58.764] iteration 10957 : model1 loss : 0.286101 model2 loss : 0.284156
[22:48:59.094] iteration 10958 : model1 loss : 0.270861 model2 loss : 0.304680
[22:48:59.423] iteration 10959 : model1 loss : 0.263457 model2 loss : 0.325902
[22:48:59.751] iteration 10960 : model1 loss : 0.281073 model2 loss : 0.362499
[22:49:00.081] iteration 10961 : model1 loss : 0.208126 model2 loss : 0.189409
[22:49:00.600] iteration 10962 : model1 loss : 0.275975 model2 loss : 0.310287
[22:49:00.929] iteration 10963 : model1 loss : 0.194058 model2 loss : 0.231414
[22:49:01.254] iteration 10964 : model1 loss : 0.275927 model2 loss : 0.257664
[22:49:01.584] iteration 10965 : model1 loss : 0.275425 model2 loss : 0.281857
[22:49:01.910] iteration 10966 : model1 loss : 0.302239 model2 loss : 0.220975
[22:49:02.236] iteration 10967 : model1 loss : 0.170955 model2 loss : 0.171686
[22:49:02.567] iteration 10968 : model1 loss : 0.159745 model2 loss : 0.164306
[22:49:02.896] iteration 10969 : model1 loss : 0.352370 model2 loss : 0.364689
[22:49:03.225] iteration 10970 : model1 loss : 0.284793 model2 loss : 0.336673
[22:49:03.552] iteration 10971 : model1 loss : 0.262144 model2 loss : 0.265112
[22:49:03.878] iteration 10972 : model1 loss : 0.258638 model2 loss : 0.282138
[22:49:04.209] iteration 10973 : model1 loss : 0.235656 model2 loss : 0.285916
[22:49:04.539] iteration 10974 : model1 loss : 0.174028 model2 loss : 0.215779
[22:49:04.868] iteration 10975 : model1 loss : 0.255444 model2 loss : 0.258476
[22:49:05.198] iteration 10976 : model1 loss : 0.138358 model2 loss : 0.223694
[22:49:05.527] iteration 10977 : model1 loss : 0.227514 model2 loss : 0.300298
[22:49:05.855] iteration 10978 : model1 loss : 0.255375 model2 loss : 0.270388
[22:49:06.191] iteration 10979 : model1 loss : 0.238506 model2 loss : 0.285909
[22:49:06.519] iteration 10980 : model1 loss : 0.197578 model2 loss : 0.230975
[22:49:06.852] iteration 10981 : model1 loss : 0.179057 model2 loss : 0.239995
[22:49:07.190] iteration 10982 : model1 loss : 0.230511 model2 loss : 0.354644
[22:49:07.522] iteration 10983 : model1 loss : 0.176186 model2 loss : 0.226125
[22:49:07.855] iteration 10984 : model1 loss : 0.269835 model2 loss : 0.326556
[22:49:08.188] iteration 10985 : model1 loss : 0.300049 model2 loss : 0.314420
[22:49:08.522] iteration 10986 : model1 loss : 0.255466 model2 loss : 0.268577
[22:49:08.851] iteration 10987 : model1 loss : 0.183542 model2 loss : 0.228466
[22:49:09.181] iteration 10988 : model1 loss : 0.177383 model2 loss : 0.208967
[22:49:09.508] iteration 10989 : model1 loss : 0.263784 model2 loss : 0.280953
[22:49:09.843] iteration 10990 : model1 loss : 0.179785 model2 loss : 0.230579
[22:49:10.176] iteration 10991 : model1 loss : 0.283978 model2 loss : 0.261292
[22:49:10.512] iteration 10992 : model1 loss : 0.246748 model2 loss : 0.233061
[22:49:10.845] iteration 10993 : model1 loss : 0.266841 model2 loss : 0.283832
[22:49:11.172] iteration 10994 : model1 loss : 0.184958 model2 loss : 0.166475
[22:49:11.505] iteration 10995 : model1 loss : 0.299001 model2 loss : 0.392568
[22:49:11.837] iteration 10996 : model1 loss : 0.242543 model2 loss : 0.245006
[22:49:12.172] iteration 10997 : model1 loss : 0.200068 model2 loss : 0.218787
[22:49:12.498] iteration 10998 : model1 loss : 0.236162 model2 loss : 0.267660
[22:49:12.828] iteration 10999 : model1 loss : 0.220659 model2 loss : 0.233596
[22:49:13.153] iteration 11000 : model1 loss : 0.222549 model2 loss : 0.211883
[22:49:13.720] iteration 11001 : model1 loss : 0.185894 model2 loss : 0.293687
[22:49:14.047] iteration 11002 : model1 loss : 0.262852 model2 loss : 0.285321
[22:49:14.376] iteration 11003 : model1 loss : 0.118698 model2 loss : 0.168319
[22:49:14.704] iteration 11004 : model1 loss : 0.136014 model2 loss : 0.176726
[22:49:15.033] iteration 11005 : model1 loss : 0.252000 model2 loss : 0.284552
[22:49:15.359] iteration 11006 : model1 loss : 0.215346 model2 loss : 0.207462
[22:49:15.687] iteration 11007 : model1 loss : 0.166128 model2 loss : 0.202529
[22:49:16.015] iteration 11008 : model1 loss : 0.292457 model2 loss : 0.327743
[22:49:16.346] iteration 11009 : model1 loss : 0.276943 model2 loss : 0.279300
[22:49:16.672] iteration 11010 : model1 loss : 0.263059 model2 loss : 0.331588
[22:49:17.001] iteration 11011 : model1 loss : 0.217748 model2 loss : 0.280662
[22:49:17.332] iteration 11012 : model1 loss : 0.227274 model2 loss : 0.237213
[22:49:17.663] iteration 11013 : model1 loss : 0.284330 model2 loss : 0.338640
[22:49:17.989] iteration 11014 : model1 loss : 0.186865 model2 loss : 0.217409
[22:49:18.316] iteration 11015 : model1 loss : 0.210893 model2 loss : 0.230830
[22:49:18.644] iteration 11016 : model1 loss : 0.247475 model2 loss : 0.290653
[22:49:18.970] iteration 11017 : model1 loss : 0.302833 model2 loss : 0.330341
[22:49:19.295] iteration 11018 : model1 loss : 0.331627 model2 loss : 0.288143
[22:49:19.623] iteration 11019 : model1 loss : 0.290245 model2 loss : 0.298344
[22:49:19.956] iteration 11020 : model1 loss : 0.196158 model2 loss : 0.192526
[22:49:20.290] iteration 11021 : model1 loss : 0.323307 model2 loss : 0.331570
[22:49:20.623] iteration 11022 : model1 loss : 0.174116 model2 loss : 0.205004
[22:49:20.955] iteration 11023 : model1 loss : 0.161828 model2 loss : 0.158320
[22:49:21.287] iteration 11024 : model1 loss : 0.301614 model2 loss : 0.317559
[22:49:21.616] iteration 11025 : model1 loss : 0.188943 model2 loss : 0.179543
[22:49:21.948] iteration 11026 : model1 loss : 0.189014 model2 loss : 0.264733
[22:49:22.280] iteration 11027 : model1 loss : 0.176088 model2 loss : 0.248806
[22:49:22.611] iteration 11028 : model1 loss : 0.250115 model2 loss : 0.240242
[22:49:22.940] iteration 11029 : model1 loss : 0.201357 model2 loss : 0.193447
[22:49:23.269] iteration 11030 : model1 loss : 0.151000 model2 loss : 0.134186
[22:49:23.598] iteration 11031 : model1 loss : 0.135008 model2 loss : 0.179681
[22:49:23.927] iteration 11032 : model1 loss : 0.263348 model2 loss : 0.279268
[22:49:24.258] iteration 11033 : model1 loss : 0.312205 model2 loss : 0.304515
[22:49:24.588] iteration 11034 : model1 loss : 0.172491 model2 loss : 0.197579
[22:49:24.917] iteration 11035 : model1 loss : 0.242532 model2 loss : 0.243184
[22:49:25.246] iteration 11036 : model1 loss : 0.200771 model2 loss : 0.217727
[22:49:25.576] iteration 11037 : model1 loss : 0.272561 model2 loss : 0.256663
[22:49:25.905] iteration 11038 : model1 loss : 0.230204 model2 loss : 0.247682
[22:49:26.235] iteration 11039 : model1 loss : 0.113902 model2 loss : 0.127108
[22:49:26.564] iteration 11040 : model1 loss : 0.193492 model2 loss : 0.239040
[22:49:26.892] iteration 11041 : model1 loss : 0.212611 model2 loss : 0.279565
[22:49:27.223] iteration 11042 : model1 loss : 0.214738 model2 loss : 0.217112
[22:49:27.552] iteration 11043 : model1 loss : 0.178955 model2 loss : 0.211734
[22:49:27.884] iteration 11044 : model1 loss : 0.171344 model2 loss : 0.229727
[22:49:28.218] iteration 11045 : model1 loss : 0.242712 model2 loss : 0.219501
[22:49:28.546] iteration 11046 : model1 loss : 0.313390 model2 loss : 0.373329
[22:49:28.875] iteration 11047 : model1 loss : 0.200165 model2 loss : 0.247300
[22:49:29.203] iteration 11048 : model1 loss : 0.289196 model2 loss : 0.342847
[22:49:29.532] iteration 11049 : model1 loss : 0.259381 model2 loss : 0.283093
[22:49:29.862] iteration 11050 : model1 loss : 0.248191 model2 loss : 0.264307
[22:49:30.402] iteration 11051 : model1 loss : 0.086658 model2 loss : 0.150142
[22:49:30.733] iteration 11052 : model1 loss : 0.358596 model2 loss : 0.404350
[22:49:31.060] iteration 11053 : model1 loss : 0.256478 model2 loss : 0.290939
[22:49:31.387] iteration 11054 : model1 loss : 0.170235 model2 loss : 0.193476
[22:49:31.715] iteration 11055 : model1 loss : 0.178860 model2 loss : 0.219896
[22:49:32.043] iteration 11056 : model1 loss : 0.173780 model2 loss : 0.171338
[22:49:32.370] iteration 11057 : model1 loss : 0.219312 model2 loss : 0.182389
[22:49:32.699] iteration 11058 : model1 loss : 0.166400 model2 loss : 0.191771
[22:49:33.026] iteration 11059 : model1 loss : 0.259440 model2 loss : 0.295211
[22:49:33.354] iteration 11060 : model1 loss : 0.263751 model2 loss : 0.271099
[22:49:33.681] iteration 11061 : model1 loss : 0.270432 model2 loss : 0.297869
[22:49:34.008] iteration 11062 : model1 loss : 0.275170 model2 loss : 0.223733
[22:49:34.335] iteration 11063 : model1 loss : 0.232293 model2 loss : 0.306989
[22:49:34.663] iteration 11064 : model1 loss : 0.285038 model2 loss : 0.296124
[22:49:34.991] iteration 11065 : model1 loss : 0.176389 model2 loss : 0.216500
[22:49:35.319] iteration 11066 : model1 loss : 0.232428 model2 loss : 0.299985
[22:49:35.646] iteration 11067 : model1 loss : 0.138434 model2 loss : 0.142741
[22:49:35.976] iteration 11068 : model1 loss : 0.252901 model2 loss : 0.228855
[22:49:36.303] iteration 11069 : model1 loss : 0.204257 model2 loss : 0.169938
[22:49:36.641] iteration 11070 : model1 loss : 0.183218 model2 loss : 0.183199
[22:49:36.980] iteration 11071 : model1 loss : 0.207357 model2 loss : 0.219936
[22:49:37.312] iteration 11072 : model1 loss : 0.270885 model2 loss : 0.322838
[22:49:37.642] iteration 11073 : model1 loss : 0.178044 model2 loss : 0.156923
[22:49:37.971] iteration 11074 : model1 loss : 0.101649 model2 loss : 0.167605
[22:49:38.301] iteration 11075 : model1 loss : 0.310223 model2 loss : 0.309677
[22:49:38.641] iteration 11076 : model1 loss : 0.297341 model2 loss : 0.286274
[22:49:38.980] iteration 11077 : model1 loss : 0.238981 model2 loss : 0.262407
[22:49:39.319] iteration 11078 : model1 loss : 0.307582 model2 loss : 0.272516
[22:49:39.657] iteration 11079 : model1 loss : 0.148849 model2 loss : 0.190739
[22:49:39.996] iteration 11080 : model1 loss : 0.110934 model2 loss : 0.160707
[22:49:40.336] iteration 11081 : model1 loss : 0.206515 model2 loss : 0.219939
[22:49:40.675] iteration 11082 : model1 loss : 0.322954 model2 loss : 0.299951
[22:49:41.014] iteration 11083 : model1 loss : 0.104522 model2 loss : 0.160520
[22:49:41.352] iteration 11084 : model1 loss : 0.216922 model2 loss : 0.282501
[22:49:41.690] iteration 11085 : model1 loss : 0.243412 model2 loss : 0.257262
[22:49:42.030] iteration 11086 : model1 loss : 0.321802 model2 loss : 0.278231
[22:49:42.368] iteration 11087 : model1 loss : 0.265314 model2 loss : 0.255712
[22:49:42.708] iteration 11088 : model1 loss : 0.296188 model2 loss : 0.334426
[22:49:43.047] iteration 11089 : model1 loss : 0.202941 model2 loss : 0.221247
[22:49:43.383] iteration 11090 : model1 loss : 0.216768 model2 loss : 0.236592
[22:49:43.721] iteration 11091 : model1 loss : 0.238287 model2 loss : 0.271662
[22:49:44.062] iteration 11092 : model1 loss : 0.262027 model2 loss : 0.245849
[22:49:44.401] iteration 11093 : model1 loss : 0.235315 model2 loss : 0.226765
[22:49:44.737] iteration 11094 : model1 loss : 0.265188 model2 loss : 0.309078
[22:49:45.076] iteration 11095 : model1 loss : 0.180483 model2 loss : 0.209082
[22:49:45.414] iteration 11096 : model1 loss : 0.220624 model2 loss : 0.230104
[22:49:45.752] iteration 11097 : model1 loss : 0.220330 model2 loss : 0.261438
[22:49:46.087] iteration 11098 : model1 loss : 0.193908 model2 loss : 0.225167
[22:49:46.426] iteration 11099 : model1 loss : 0.235232 model2 loss : 0.229833
[22:49:46.764] iteration 11100 : model1 loss : 0.151794 model2 loss : 0.193785
[22:49:47.403] iteration 11101 : model1 loss : 0.186333 model2 loss : 0.283669
[22:49:47.740] iteration 11102 : model1 loss : 0.232035 model2 loss : 0.221725
[22:49:48.078] iteration 11103 : model1 loss : 0.254405 model2 loss : 0.259356
[22:49:48.416] iteration 11104 : model1 loss : 0.257629 model2 loss : 0.276051
[22:49:48.754] iteration 11105 : model1 loss : 0.292441 model2 loss : 0.299522
[22:49:49.095] iteration 11106 : model1 loss : 0.161416 model2 loss : 0.136055
[22:49:49.434] iteration 11107 : model1 loss : 0.178653 model2 loss : 0.252706
[22:49:49.776] iteration 11108 : model1 loss : 0.181279 model2 loss : 0.203320
[22:49:50.115] iteration 11109 : model1 loss : 0.199045 model2 loss : 0.351802
[22:49:50.452] iteration 11110 : model1 loss : 0.206056 model2 loss : 0.226937
[22:49:50.790] iteration 11111 : model1 loss : 0.218718 model2 loss : 0.238142
[22:49:51.130] iteration 11112 : model1 loss : 0.273197 model2 loss : 0.325535
[22:49:51.468] iteration 11113 : model1 loss : 0.176642 model2 loss : 0.178829
[22:49:51.803] iteration 11114 : model1 loss : 0.306401 model2 loss : 0.348953
[22:49:52.143] iteration 11115 : model1 loss : 0.146279 model2 loss : 0.291163
[22:49:52.481] iteration 11116 : model1 loss : 0.171597 model2 loss : 0.206764
[22:49:52.820] iteration 11117 : model1 loss : 0.274464 model2 loss : 0.309921
[22:49:53.158] iteration 11118 : model1 loss : 0.294178 model2 loss : 0.293115
[22:49:53.497] iteration 11119 : model1 loss : 0.192322 model2 loss : 0.212460
[22:49:53.835] iteration 11120 : model1 loss : 0.136117 model2 loss : 0.212164
[22:49:54.173] iteration 11121 : model1 loss : 0.105279 model2 loss : 0.116749
[22:49:54.511] iteration 11122 : model1 loss : 0.274026 model2 loss : 0.194156
[22:49:54.850] iteration 11123 : model1 loss : 0.236586 model2 loss : 0.191275
[22:49:55.189] iteration 11124 : model1 loss : 0.238035 model2 loss : 0.255538
[22:49:55.528] iteration 11125 : model1 loss : 0.252481 model2 loss : 0.301171
[22:49:55.867] iteration 11126 : model1 loss : 0.241810 model2 loss : 0.262404
[22:49:56.206] iteration 11127 : model1 loss : 0.169999 model2 loss : 0.197442
[22:49:56.544] iteration 11128 : model1 loss : 0.199693 model2 loss : 0.195402
[22:49:56.882] iteration 11129 : model1 loss : 0.105564 model2 loss : 0.187345
[22:49:57.220] iteration 11130 : model1 loss : 0.191231 model2 loss : 0.208049
[22:49:57.560] iteration 11131 : model1 loss : 0.174382 model2 loss : 0.213468
[22:49:57.901] iteration 11132 : model1 loss : 0.244469 model2 loss : 0.262352
[22:49:58.240] iteration 11133 : model1 loss : 0.310169 model2 loss : 0.298472
[22:49:58.581] iteration 11134 : model1 loss : 0.309990 model2 loss : 0.289776
[22:49:58.921] iteration 11135 : model1 loss : 0.136139 model2 loss : 0.138452
[22:49:59.260] iteration 11136 : model1 loss : 0.308268 model2 loss : 0.350607
[22:49:59.598] iteration 11137 : model1 loss : 0.129869 model2 loss : 0.204098
[22:49:59.937] iteration 11138 : model1 loss : 0.204373 model2 loss : 0.241032
[22:50:00.276] iteration 11139 : model1 loss : 0.234529 model2 loss : 0.193734
[22:50:00.615] iteration 11140 : model1 loss : 0.291180 model2 loss : 0.305514
[22:50:00.955] iteration 11141 : model1 loss : 0.216542 model2 loss : 0.295704
[22:50:01.293] iteration 11142 : model1 loss : 0.100885 model2 loss : 0.250806
[22:50:01.631] iteration 11143 : model1 loss : 0.302021 model2 loss : 0.318704
[22:50:01.970] iteration 11144 : model1 loss : 0.207578 model2 loss : 0.264822
[22:50:02.308] iteration 11145 : model1 loss : 0.258491 model2 loss : 0.243283
[22:50:02.645] iteration 11146 : model1 loss : 0.280988 model2 loss : 0.325257
[22:50:02.982] iteration 11147 : model1 loss : 0.186792 model2 loss : 0.284679
[22:50:03.320] iteration 11148 : model1 loss : 0.205790 model2 loss : 0.272863
[22:50:03.658] iteration 11149 : model1 loss : 0.081468 model2 loss : 0.138308
[22:50:03.998] iteration 11150 : model1 loss : 0.362576 model2 loss : 0.216589
[22:50:04.659] iteration 11151 : model1 loss : 0.200267 model2 loss : 0.225079
[22:50:04.997] iteration 11152 : model1 loss : 0.183079 model2 loss : 0.180198
[22:50:05.337] iteration 11153 : model1 loss : 0.209212 model2 loss : 0.212036
[22:50:05.666] iteration 11154 : model1 loss : 0.193314 model2 loss : 0.233975
[22:50:05.996] iteration 11155 : model1 loss : 0.284620 model2 loss : 0.281584
[22:50:06.336] iteration 11156 : model1 loss : 0.215463 model2 loss : 0.226030
[22:50:06.675] iteration 11157 : model1 loss : 0.120162 model2 loss : 0.181362
[22:50:07.013] iteration 11158 : model1 loss : 0.222154 model2 loss : 0.209311
[22:50:07.352] iteration 11159 : model1 loss : 0.312772 model2 loss : 0.333988
[22:50:07.689] iteration 11160 : model1 loss : 0.310142 model2 loss : 0.260198
[22:50:08.029] iteration 11161 : model1 loss : 0.260249 model2 loss : 0.270927
[22:50:08.368] iteration 11162 : model1 loss : 0.241243 model2 loss : 0.253955
[22:50:08.709] iteration 11163 : model1 loss : 0.212274 model2 loss : 0.232174
[22:50:09.048] iteration 11164 : model1 loss : 0.237454 model2 loss : 0.234848
[22:50:09.389] iteration 11165 : model1 loss : 0.170720 model2 loss : 0.147175
[22:50:09.729] iteration 11166 : model1 loss : 0.311845 model2 loss : 0.423440
[22:50:10.069] iteration 11167 : model1 loss : 0.179116 model2 loss : 0.248889
[22:50:10.410] iteration 11168 : model1 loss : 0.284208 model2 loss : 0.297489
[22:50:10.749] iteration 11169 : model1 loss : 0.269063 model2 loss : 0.264080
[22:50:11.090] iteration 11170 : model1 loss : 0.304404 model2 loss : 0.238389
[22:50:11.431] iteration 11171 : model1 loss : 0.207208 model2 loss : 0.194150
[22:50:11.770] iteration 11172 : model1 loss : 0.232107 model2 loss : 0.246233
[22:50:12.108] iteration 11173 : model1 loss : 0.379582 model2 loss : 0.314273
[22:50:12.449] iteration 11174 : model1 loss : 0.353781 model2 loss : 0.363462
[22:50:12.812] iteration 11175 : model1 loss : 0.144248 model2 loss : 0.162330
[22:50:13.151] iteration 11176 : model1 loss : 0.214138 model2 loss : 0.217748
[22:50:13.489] iteration 11177 : model1 loss : 0.111722 model2 loss : 0.157989
[22:50:13.829] iteration 11178 : model1 loss : 0.283839 model2 loss : 0.289609
[22:50:14.168] iteration 11179 : model1 loss : 0.259761 model2 loss : 0.285597
[22:50:14.510] iteration 11180 : model1 loss : 0.262555 model2 loss : 0.337407
[22:50:14.847] iteration 11181 : model1 loss : 0.268213 model2 loss : 0.238101
[22:50:15.186] iteration 11182 : model1 loss : 0.231417 model2 loss : 0.313937
[22:50:15.525] iteration 11183 : model1 loss : 0.207127 model2 loss : 0.264535
[22:50:15.863] iteration 11184 : model1 loss : 0.177547 model2 loss : 0.214582
[22:50:16.202] iteration 11185 : model1 loss : 0.297867 model2 loss : 0.321579
[22:50:16.540] iteration 11186 : model1 loss : 0.215850 model2 loss : 0.235902
[22:50:16.878] iteration 11187 : model1 loss : 0.200049 model2 loss : 0.219233
[22:50:17.216] iteration 11188 : model1 loss : 0.302621 model2 loss : 0.324868
[22:50:17.555] iteration 11189 : model1 loss : 0.229492 model2 loss : 0.244633
[22:50:17.893] iteration 11190 : model1 loss : 0.277977 model2 loss : 0.278180
[22:50:18.231] iteration 11191 : model1 loss : 0.184590 model2 loss : 0.182609
[22:50:18.569] iteration 11192 : model1 loss : 0.334636 model2 loss : 0.308098
[22:50:18.907] iteration 11193 : model1 loss : 0.295128 model2 loss : 0.289149
[22:50:19.246] iteration 11194 : model1 loss : 0.354625 model2 loss : 0.367960
[22:50:19.584] iteration 11195 : model1 loss : 0.214649 model2 loss : 0.245773
[22:50:19.923] iteration 11196 : model1 loss : 0.269516 model2 loss : 0.273153
[22:50:20.262] iteration 11197 : model1 loss : 0.274099 model2 loss : 0.269970
[22:50:20.601] iteration 11198 : model1 loss : 0.257306 model2 loss : 0.237483
[22:50:20.942] iteration 11199 : model1 loss : 0.084024 model2 loss : 0.100383
[22:50:21.279] iteration 11200 : model1 loss : 0.268206 model2 loss : 0.302368
[22:50:21.887] iteration 11201 : model1 loss : 0.268759 model2 loss : 0.237833
[22:50:22.225] iteration 11202 : model1 loss : 0.297755 model2 loss : 0.276958
[22:50:22.563] iteration 11203 : model1 loss : 0.317513 model2 loss : 0.288316
[22:50:22.930] iteration 11204 : model1 loss : 0.214951 model2 loss : 0.170373
[22:50:23.304] iteration 11205 : model1 loss : 0.277782 model2 loss : 0.285567
[22:50:23.656] iteration 11206 : model1 loss : 0.103593 model2 loss : 0.143903
[22:50:24.010] iteration 11207 : model1 loss : 0.261311 model2 loss : 0.294830
[22:50:24.355] iteration 11208 : model1 loss : 0.402170 model2 loss : 0.401109
[22:50:24.693] iteration 11209 : model1 loss : 0.189242 model2 loss : 0.206795
[22:50:25.032] iteration 11210 : model1 loss : 0.344704 model2 loss : 0.323518
[22:50:25.372] iteration 11211 : model1 loss : 0.170650 model2 loss : 0.250239
[22:50:25.710] iteration 11212 : model1 loss : 0.296043 model2 loss : 0.320839
[22:50:26.049] iteration 11213 : model1 loss : 0.208468 model2 loss : 0.304025
[22:50:26.388] iteration 11214 : model1 loss : 0.259214 model2 loss : 0.249124
[22:50:26.725] iteration 11215 : model1 loss : 0.237993 model2 loss : 0.248119
[22:50:27.065] iteration 11216 : model1 loss : 0.248309 model2 loss : 0.312208
[22:50:27.404] iteration 11217 : model1 loss : 0.179234 model2 loss : 0.276789
[22:50:27.743] iteration 11218 : model1 loss : 0.204375 model2 loss : 0.260788
[22:50:28.088] iteration 11219 : model1 loss : 0.208717 model2 loss : 0.238197
[22:50:28.433] iteration 11220 : model1 loss : 0.229314 model2 loss : 0.234358
[22:50:28.773] iteration 11221 : model1 loss : 0.223632 model2 loss : 0.275290
[22:50:29.117] iteration 11222 : model1 loss : 0.231302 model2 loss : 0.288807
[22:50:29.464] iteration 11223 : model1 loss : 0.384032 model2 loss : 0.356767
[22:50:29.802] iteration 11224 : model1 loss : 0.257603 model2 loss : 0.291262
[22:50:30.143] iteration 11225 : model1 loss : 0.221648 model2 loss : 0.233168
[22:50:30.488] iteration 11226 : model1 loss : 0.299699 model2 loss : 0.312818
[22:50:30.833] iteration 11227 : model1 loss : 0.182088 model2 loss : 0.231334
[22:50:31.175] iteration 11228 : model1 loss : 0.169185 model2 loss : 0.271202
[22:50:31.515] iteration 11229 : model1 loss : 0.307800 model2 loss : 0.314549
[22:50:31.854] iteration 11230 : model1 loss : 0.213130 model2 loss : 0.285490
[22:50:32.199] iteration 11231 : model1 loss : 0.092734 model2 loss : 0.128225
[22:50:32.540] iteration 11232 : model1 loss : 0.107549 model2 loss : 0.199501
[22:50:32.885] iteration 11233 : model1 loss : 0.244461 model2 loss : 0.267476
[22:50:33.231] iteration 11234 : model1 loss : 0.217015 model2 loss : 0.242477
[22:50:33.575] iteration 11235 : model1 loss : 0.216148 model2 loss : 0.203725
[22:50:33.914] iteration 11236 : model1 loss : 0.187422 model2 loss : 0.218561
[22:50:34.256] iteration 11237 : model1 loss : 0.225923 model2 loss : 0.226083
[22:50:34.599] iteration 11238 : model1 loss : 0.153201 model2 loss : 0.196925
[22:50:34.929] iteration 11239 : model1 loss : 0.132812 model2 loss : 0.283861
[22:50:35.259] iteration 11240 : model1 loss : 0.170414 model2 loss : 0.201710
[22:50:35.593] iteration 11241 : model1 loss : 0.163685 model2 loss : 0.204926
[22:50:35.925] iteration 11242 : model1 loss : 0.272191 model2 loss : 0.309953
[22:50:36.259] iteration 11243 : model1 loss : 0.181572 model2 loss : 0.252665
[22:50:36.590] iteration 11244 : model1 loss : 0.185245 model2 loss : 0.198866
[22:50:36.921] iteration 11245 : model1 loss : 0.200408 model2 loss : 0.199052
[22:50:37.254] iteration 11246 : model1 loss : 0.234953 model2 loss : 0.202682
[22:50:37.587] iteration 11247 : model1 loss : 0.178922 model2 loss : 0.244203
[22:50:37.920] iteration 11248 : model1 loss : 0.249644 model2 loss : 0.250464
[22:50:38.253] iteration 11249 : model1 loss : 0.262744 model2 loss : 0.291739
[22:50:38.587] iteration 11250 : model1 loss : 0.222147 model2 loss : 0.216611
[22:50:39.134] iteration 11251 : model1 loss : 0.247535 model2 loss : 0.214126
[22:50:39.465] iteration 11252 : model1 loss : 0.199473 model2 loss : 0.212770
[22:50:39.798] iteration 11253 : model1 loss : 0.283894 model2 loss : 0.321364
[22:50:40.130] iteration 11254 : model1 loss : 0.213238 model2 loss : 0.226195
[22:50:40.464] iteration 11255 : model1 loss : 0.249280 model2 loss : 0.237065
[22:50:40.797] iteration 11256 : model1 loss : 0.359425 model2 loss : 0.346057
[22:50:41.129] iteration 11257 : model1 loss : 0.156034 model2 loss : 0.173824
[22:50:41.461] iteration 11258 : model1 loss : 0.335802 model2 loss : 0.355465
[22:50:41.792] iteration 11259 : model1 loss : 0.341938 model2 loss : 0.300454
[22:50:42.125] iteration 11260 : model1 loss : 0.193829 model2 loss : 0.315889
[22:50:42.456] iteration 11261 : model1 loss : 0.252171 model2 loss : 0.289040
[22:50:42.791] iteration 11262 : model1 loss : 0.245370 model2 loss : 0.273208
[22:50:43.122] iteration 11263 : model1 loss : 0.168423 model2 loss : 0.160880
[22:50:43.455] iteration 11264 : model1 loss : 0.266832 model2 loss : 0.274060
[22:50:43.788] iteration 11265 : model1 loss : 0.120037 model2 loss : 0.162000
[22:50:44.119] iteration 11266 : model1 loss : 0.213131 model2 loss : 0.205576
[22:50:44.450] iteration 11267 : model1 loss : 0.182458 model2 loss : 0.155729
[22:50:44.782] iteration 11268 : model1 loss : 0.169376 model2 loss : 0.249443
[22:50:45.113] iteration 11269 : model1 loss : 0.247787 model2 loss : 0.261555
[22:50:45.447] iteration 11270 : model1 loss : 0.194638 model2 loss : 0.244504
[22:50:45.778] iteration 11271 : model1 loss : 0.117739 model2 loss : 0.168311
[22:50:46.117] iteration 11272 : model1 loss : 0.255551 model2 loss : 0.276238
[22:50:46.463] iteration 11273 : model1 loss : 0.183711 model2 loss : 0.199371
[22:50:46.810] iteration 11274 : model1 loss : 0.186284 model2 loss : 0.180042
[22:50:47.157] iteration 11275 : model1 loss : 0.182784 model2 loss : 0.251739
[22:50:47.502] iteration 11276 : model1 loss : 0.196882 model2 loss : 0.193198
[22:50:47.835] iteration 11277 : model1 loss : 0.280389 model2 loss : 0.252295
[22:50:48.170] iteration 11278 : model1 loss : 0.157047 model2 loss : 0.192563
[22:50:48.506] iteration 11279 : model1 loss : 0.276986 model2 loss : 0.264076
[22:50:48.839] iteration 11280 : model1 loss : 0.243424 model2 loss : 0.282844
[22:50:49.183] iteration 11281 : model1 loss : 0.144910 model2 loss : 0.123964
[22:50:49.523] iteration 11282 : model1 loss : 0.247732 model2 loss : 0.246245
[22:50:49.861] iteration 11283 : model1 loss : 0.204318 model2 loss : 0.257313
[22:50:50.205] iteration 11284 : model1 loss : 0.195751 model2 loss : 0.244090
[22:50:50.548] iteration 11285 : model1 loss : 0.286985 model2 loss : 0.260334
[22:50:50.895] iteration 11286 : model1 loss : 0.238021 model2 loss : 0.306505
[22:50:51.236] iteration 11287 : model1 loss : 0.191050 model2 loss : 0.130457
[22:50:51.576] iteration 11288 : model1 loss : 0.187111 model2 loss : 0.222037
[22:50:51.922] iteration 11289 : model1 loss : 0.149248 model2 loss : 0.243660
[22:50:52.266] iteration 11290 : model1 loss : 0.188397 model2 loss : 0.195938
[22:50:52.605] iteration 11291 : model1 loss : 0.236925 model2 loss : 0.290284
[22:50:52.946] iteration 11292 : model1 loss : 0.245093 model2 loss : 0.223811
[22:50:53.284] iteration 11293 : model1 loss : 0.245203 model2 loss : 0.198566
[22:50:53.623] iteration 11294 : model1 loss : 0.275507 model2 loss : 0.283138
[22:50:53.953] iteration 11295 : model1 loss : 0.208036 model2 loss : 0.233776
[22:50:54.282] iteration 11296 : model1 loss : 0.293423 model2 loss : 0.265198
[22:50:54.612] iteration 11297 : model1 loss : 0.267498 model2 loss : 0.284214
[22:50:54.943] iteration 11298 : model1 loss : 0.286395 model2 loss : 0.362247
[22:50:55.276] iteration 11299 : model1 loss : 0.213043 model2 loss : 0.239841
[22:50:55.606] iteration 11300 : model1 loss : 0.328628 model2 loss : 0.403004
[22:50:56.168] iteration 11301 : model1 loss : 0.188580 model2 loss : 0.223159
[22:50:56.499] iteration 11302 : model1 loss : 0.259135 model2 loss : 0.237138
[22:50:56.829] iteration 11303 : model1 loss : 0.196324 model2 loss : 0.191459
[22:50:57.159] iteration 11304 : model1 loss : 0.141226 model2 loss : 0.130925
[22:50:57.488] iteration 11305 : model1 loss : 0.197071 model2 loss : 0.186316
[22:50:57.817] iteration 11306 : model1 loss : 0.254431 model2 loss : 0.262594
[22:50:58.146] iteration 11307 : model1 loss : 0.164812 model2 loss : 0.150758
[22:50:58.476] iteration 11308 : model1 loss : 0.268400 model2 loss : 0.318864
[22:50:58.806] iteration 11309 : model1 loss : 0.194856 model2 loss : 0.289618
[22:50:59.135] iteration 11310 : model1 loss : 0.251334 model2 loss : 0.276165
[22:50:59.470] iteration 11311 : model1 loss : 0.204028 model2 loss : 0.207381
[22:50:59.800] iteration 11312 : model1 loss : 0.209006 model2 loss : 0.217316
[22:51:00.133] iteration 11313 : model1 loss : 0.245633 model2 loss : 0.247713
[22:51:00.463] iteration 11314 : model1 loss : 0.196363 model2 loss : 0.184164
[22:51:00.793] iteration 11315 : model1 loss : 0.360070 model2 loss : 0.279109
[22:51:01.122] iteration 11316 : model1 loss : 0.234093 model2 loss : 0.186979
[22:51:01.451] iteration 11317 : model1 loss : 0.113320 model2 loss : 0.133492
[22:51:01.789] iteration 11318 : model1 loss : 0.204047 model2 loss : 0.216411
[22:51:02.115] iteration 11319 : model1 loss : 0.209549 model2 loss : 0.256640
[22:51:02.445] iteration 11320 : model1 loss : 0.303603 model2 loss : 0.300823
[22:51:02.774] iteration 11321 : model1 loss : 0.195208 model2 loss : 0.249314
[22:51:03.103] iteration 11322 : model1 loss : 0.269722 model2 loss : 0.292314
[22:51:03.429] iteration 11323 : model1 loss : 0.172096 model2 loss : 0.206186
[22:51:03.759] iteration 11324 : model1 loss : 0.242070 model2 loss : 0.183299
[22:51:04.089] iteration 11325 : model1 loss : 0.210493 model2 loss : 0.224120
[22:51:04.418] iteration 11326 : model1 loss : 0.292340 model2 loss : 0.297955
[22:51:04.749] iteration 11327 : model1 loss : 0.185918 model2 loss : 0.218429
[22:51:05.083] iteration 11328 : model1 loss : 0.291308 model2 loss : 0.274984
[22:51:05.416] iteration 11329 : model1 loss : 0.229077 model2 loss : 0.264207
[22:51:05.745] iteration 11330 : model1 loss : 0.209984 model2 loss : 0.218001
[22:51:06.072] iteration 11331 : model1 loss : 0.322149 model2 loss : 0.353413
[22:51:06.401] iteration 11332 : model1 loss : 0.090757 model2 loss : 0.147481
[22:51:06.730] iteration 11333 : model1 loss : 0.201125 model2 loss : 0.253037
[22:51:07.057] iteration 11334 : model1 loss : 0.261575 model2 loss : 0.294776
[22:51:07.383] iteration 11335 : model1 loss : 0.388852 model2 loss : 0.389623
[22:51:07.712] iteration 11336 : model1 loss : 0.219215 model2 loss : 0.304645
[22:51:08.046] iteration 11337 : model1 loss : 0.402075 model2 loss : 0.401763
[22:51:08.373] iteration 11338 : model1 loss : 0.202995 model2 loss : 0.218737
[22:51:08.701] iteration 11339 : model1 loss : 0.327420 model2 loss : 0.320053
[22:51:09.032] iteration 11340 : model1 loss : 0.127055 model2 loss : 0.134494
[22:51:09.364] iteration 11341 : model1 loss : 0.314493 model2 loss : 0.335795
[22:51:09.698] iteration 11342 : model1 loss : 0.199584 model2 loss : 0.205732
[22:51:10.024] iteration 11343 : model1 loss : 0.127117 model2 loss : 0.185485
[22:51:10.354] iteration 11344 : model1 loss : 0.277480 model2 loss : 0.290837
[22:51:10.683] iteration 11345 : model1 loss : 0.204811 model2 loss : 0.300192
[22:51:11.009] iteration 11346 : model1 loss : 0.293979 model2 loss : 0.248441
[22:51:11.338] iteration 11347 : model1 loss : 0.160856 model2 loss : 0.173461
[22:51:11.667] iteration 11348 : model1 loss : 0.172689 model2 loss : 0.188612
[22:51:11.997] iteration 11349 : model1 loss : 0.284275 model2 loss : 0.308783
[22:51:12.323] iteration 11350 : model1 loss : 0.209741 model2 loss : 0.323708
[22:51:12.876] iteration 11351 : model1 loss : 0.186287 model2 loss : 0.206653
[22:51:13.206] iteration 11352 : model1 loss : 0.197170 model2 loss : 0.262566
[22:51:13.539] iteration 11353 : model1 loss : 0.205382 model2 loss : 0.281137
[22:51:13.868] iteration 11354 : model1 loss : 0.126549 model2 loss : 0.160064
[22:51:14.194] iteration 11355 : model1 loss : 0.264564 model2 loss : 0.338479
[22:51:14.524] iteration 11356 : model1 loss : 0.214596 model2 loss : 0.218189
[22:51:14.856] iteration 11357 : model1 loss : 0.125806 model2 loss : 0.145518
[22:51:15.186] iteration 11358 : model1 loss : 0.204454 model2 loss : 0.244387
[22:51:15.512] iteration 11359 : model1 loss : 0.250922 model2 loss : 0.261521
[22:51:15.841] iteration 11360 : model1 loss : 0.176199 model2 loss : 0.186986
[22:51:16.170] iteration 11361 : model1 loss : 0.226983 model2 loss : 0.346452
[22:51:16.511] iteration 11362 : model1 loss : 0.138302 model2 loss : 0.169037
[22:51:16.851] iteration 11363 : model1 loss : 0.209727 model2 loss : 0.193146
[22:51:17.189] iteration 11364 : model1 loss : 0.335054 model2 loss : 0.337908
[22:51:17.528] iteration 11365 : model1 loss : 0.197997 model2 loss : 0.240441
[22:51:17.866] iteration 11366 : model1 loss : 0.284563 model2 loss : 0.315991
[22:51:18.201] iteration 11367 : model1 loss : 0.232154 model2 loss : 0.227946
[22:51:18.540] iteration 11368 : model1 loss : 0.197056 model2 loss : 0.213160
[22:51:18.878] iteration 11369 : model1 loss : 0.286124 model2 loss : 0.314300
[22:51:19.220] iteration 11370 : model1 loss : 0.103576 model2 loss : 0.171904
[22:51:19.547] iteration 11371 : model1 loss : 0.259533 model2 loss : 0.278827
[22:51:19.876] iteration 11372 : model1 loss : 0.235195 model2 loss : 0.251629
[22:51:20.205] iteration 11373 : model1 loss : 0.204992 model2 loss : 0.240686
[22:51:20.534] iteration 11374 : model1 loss : 0.196694 model2 loss : 0.209147
[22:51:20.860] iteration 11375 : model1 loss : 0.247288 model2 loss : 0.261721
[22:51:21.190] iteration 11376 : model1 loss : 0.219740 model2 loss : 0.141839
[22:51:21.519] iteration 11377 : model1 loss : 0.279325 model2 loss : 0.305221
[22:51:21.845] iteration 11378 : model1 loss : 0.208253 model2 loss : 0.236461
[22:51:22.172] iteration 11379 : model1 loss : 0.193921 model2 loss : 0.198418
[22:51:22.500] iteration 11380 : model1 loss : 0.130458 model2 loss : 0.130405
[22:51:22.830] iteration 11381 : model1 loss : 0.223474 model2 loss : 0.243759
[22:51:23.157] iteration 11382 : model1 loss : 0.160929 model2 loss : 0.212259
[22:51:23.483] iteration 11383 : model1 loss : 0.187092 model2 loss : 0.194516
[22:51:23.812] iteration 11384 : model1 loss : 0.279032 model2 loss : 0.322227
[22:51:24.143] iteration 11385 : model1 loss : 0.195094 model2 loss : 0.202219
[22:51:24.472] iteration 11386 : model1 loss : 0.264412 model2 loss : 0.254781
[22:51:24.801] iteration 11387 : model1 loss : 0.202258 model2 loss : 0.217354
[22:51:25.130] iteration 11388 : model1 loss : 0.229803 model2 loss : 0.216703
[22:51:25.460] iteration 11389 : model1 loss : 0.237323 model2 loss : 0.260326
[22:51:25.789] iteration 11390 : model1 loss : 0.175785 model2 loss : 0.212792
[22:51:26.118] iteration 11391 : model1 loss : 0.219881 model2 loss : 0.280356
[22:51:26.449] iteration 11392 : model1 loss : 0.153969 model2 loss : 0.141234
[22:51:26.785] iteration 11393 : model1 loss : 0.189689 model2 loss : 0.199962
[22:51:27.114] iteration 11394 : model1 loss : 0.189479 model2 loss : 0.279300
[22:51:27.445] iteration 11395 : model1 loss : 0.132972 model2 loss : 0.175492
[22:51:27.774] iteration 11396 : model1 loss : 0.192950 model2 loss : 0.285924
[22:51:28.103] iteration 11397 : model1 loss : 0.153060 model2 loss : 0.181738
[22:51:28.432] iteration 11398 : model1 loss : 0.213192 model2 loss : 0.238295
[22:51:28.761] iteration 11399 : model1 loss : 0.188928 model2 loss : 0.227015
[22:51:29.090] iteration 11400 : model1 loss : 0.295915 model2 loss : 0.296460
[22:51:29.666] iteration 11401 : model1 loss : 0.173295 model2 loss : 0.172737
[22:51:30.004] iteration 11402 : model1 loss : 0.124770 model2 loss : 0.141893
[22:51:30.344] iteration 11403 : model1 loss : 0.261761 model2 loss : 0.275593
[22:51:30.682] iteration 11404 : model1 loss : 0.209621 model2 loss : 0.251176
[22:51:31.021] iteration 11405 : model1 loss : 0.150102 model2 loss : 0.161162
[22:51:31.359] iteration 11406 : model1 loss : 0.166968 model2 loss : 0.157481
[22:51:31.697] iteration 11407 : model1 loss : 0.298425 model2 loss : 0.309793
[22:51:32.035] iteration 11408 : model1 loss : 0.167872 model2 loss : 0.158550
[22:51:32.373] iteration 11409 : model1 loss : 0.181695 model2 loss : 0.225744
[22:51:32.713] iteration 11410 : model1 loss : 0.185883 model2 loss : 0.220157
[22:51:33.054] iteration 11411 : model1 loss : 0.358695 model2 loss : 0.371027
[22:51:33.394] iteration 11412 : model1 loss : 0.163842 model2 loss : 0.186984
[22:51:33.732] iteration 11413 : model1 loss : 0.349164 model2 loss : 0.413391
[22:51:34.075] iteration 11414 : model1 loss : 0.240138 model2 loss : 0.298119
[22:51:34.414] iteration 11415 : model1 loss : 0.230313 model2 loss : 0.239860
[22:51:34.753] iteration 11416 : model1 loss : 0.125132 model2 loss : 0.127716
[22:51:35.091] iteration 11417 : model1 loss : 0.299964 model2 loss : 0.322209
[22:51:35.430] iteration 11418 : model1 loss : 0.189661 model2 loss : 0.216337
[22:51:35.771] iteration 11419 : model1 loss : 0.317574 model2 loss : 0.291253
[22:51:36.112] iteration 11420 : model1 loss : 0.211849 model2 loss : 0.234542
[22:51:36.450] iteration 11421 : model1 loss : 0.195282 model2 loss : 0.235087
[22:51:36.789] iteration 11422 : model1 loss : 0.319221 model2 loss : 0.334469
[22:51:37.130] iteration 11423 : model1 loss : 0.249614 model2 loss : 0.301062
[22:51:37.460] iteration 11424 : model1 loss : 0.268616 model2 loss : 0.271832
[22:51:37.789] iteration 11425 : model1 loss : 0.239716 model2 loss : 0.227038
[22:51:38.118] iteration 11426 : model1 loss : 0.278684 model2 loss : 0.302373
[22:51:38.450] iteration 11427 : model1 loss : 0.263597 model2 loss : 0.327252
[22:51:38.779] iteration 11428 : model1 loss : 0.202274 model2 loss : 0.299715
[22:51:39.107] iteration 11429 : model1 loss : 0.206420 model2 loss : 0.280610
[22:51:39.437] iteration 11430 : model1 loss : 0.178905 model2 loss : 0.189974
[22:51:39.766] iteration 11431 : model1 loss : 0.259355 model2 loss : 0.289955
[22:51:40.096] iteration 11432 : model1 loss : 0.285446 model2 loss : 0.288605
[22:51:40.425] iteration 11433 : model1 loss : 0.238930 model2 loss : 0.247874
[22:51:40.754] iteration 11434 : model1 loss : 0.231107 model2 loss : 0.206669
[22:51:41.083] iteration 11435 : model1 loss : 0.273558 model2 loss : 0.289921
[22:51:41.412] iteration 11436 : model1 loss : 0.199847 model2 loss : 0.216741
[22:51:41.741] iteration 11437 : model1 loss : 0.284546 model2 loss : 0.298161
[22:51:42.070] iteration 11438 : model1 loss : 0.183511 model2 loss : 0.282507
[22:51:42.399] iteration 11439 : model1 loss : 0.283207 model2 loss : 0.304353
[22:51:42.729] iteration 11440 : model1 loss : 0.270863 model2 loss : 0.309467
[22:51:43.058] iteration 11441 : model1 loss : 0.232522 model2 loss : 0.261352
[22:51:43.389] iteration 11442 : model1 loss : 0.256412 model2 loss : 0.256594
[22:51:43.718] iteration 11443 : model1 loss : 0.280597 model2 loss : 0.287122
[22:51:44.047] iteration 11444 : model1 loss : 0.242780 model2 loss : 0.229350
[22:51:44.377] iteration 11445 : model1 loss : 0.211937 model2 loss : 0.239681
[22:51:45.415] iteration 11446 : model1 loss : 0.347164 model2 loss : 0.361200
[22:51:45.745] iteration 11447 : model1 loss : 0.243706 model2 loss : 0.211148
[22:51:46.078] iteration 11448 : model1 loss : 0.187589 model2 loss : 0.218399
[22:51:46.407] iteration 11449 : model1 loss : 0.270176 model2 loss : 0.298014
[22:51:46.740] iteration 11450 : model1 loss : 0.271501 model2 loss : 0.190808
[22:51:47.301] iteration 11451 : model1 loss : 0.270166 model2 loss : 0.280697
[22:51:47.634] iteration 11452 : model1 loss : 0.209420 model2 loss : 0.202503
[22:51:47.964] iteration 11453 : model1 loss : 0.161939 model2 loss : 0.225116
[22:51:48.295] iteration 11454 : model1 loss : 0.171974 model2 loss : 0.258904
[22:51:48.623] iteration 11455 : model1 loss : 0.293792 model2 loss : 0.326933
[22:51:48.951] iteration 11456 : model1 loss : 0.130556 model2 loss : 0.165889
[22:51:49.282] iteration 11457 : model1 loss : 0.225108 model2 loss : 0.262814
[22:51:49.611] iteration 11458 : model1 loss : 0.163738 model2 loss : 0.246945
[22:51:49.941] iteration 11459 : model1 loss : 0.299707 model2 loss : 0.289595
[22:51:50.271] iteration 11460 : model1 loss : 0.287582 model2 loss : 0.332666
[22:51:50.600] iteration 11461 : model1 loss : 0.254200 model2 loss : 0.317173
[22:51:50.929] iteration 11462 : model1 loss : 0.119433 model2 loss : 0.175331
[22:51:51.260] iteration 11463 : model1 loss : 0.100881 model2 loss : 0.142896
[22:51:51.590] iteration 11464 : model1 loss : 0.210921 model2 loss : 0.246653
[22:51:51.920] iteration 11465 : model1 loss : 0.169090 model2 loss : 0.183190
[22:51:52.250] iteration 11466 : model1 loss : 0.199383 model2 loss : 0.221884
[22:51:52.580] iteration 11467 : model1 loss : 0.223208 model2 loss : 0.300607
[22:51:52.910] iteration 11468 : model1 loss : 0.256810 model2 loss : 0.234293
[22:51:53.239] iteration 11469 : model1 loss : 0.206806 model2 loss : 0.228904
[22:51:53.568] iteration 11470 : model1 loss : 0.238569 model2 loss : 0.280604
[22:51:53.897] iteration 11471 : model1 loss : 0.170471 model2 loss : 0.208038
[22:51:54.226] iteration 11472 : model1 loss : 0.218684 model2 loss : 0.193931
[22:51:54.555] iteration 11473 : model1 loss : 0.190826 model2 loss : 0.220052
[22:51:54.884] iteration 11474 : model1 loss : 0.259431 model2 loss : 0.319552
[22:51:55.213] iteration 11475 : model1 loss : 0.333931 model2 loss : 0.308790
[22:51:55.542] iteration 11476 : model1 loss : 0.253320 model2 loss : 0.286622
[22:51:55.871] iteration 11477 : model1 loss : 0.150308 model2 loss : 0.178320
[22:51:56.199] iteration 11478 : model1 loss : 0.137391 model2 loss : 0.204073
[22:51:56.528] iteration 11479 : model1 loss : 0.165888 model2 loss : 0.217386
[22:51:56.858] iteration 11480 : model1 loss : 0.234219 model2 loss : 0.231203
[22:51:57.188] iteration 11481 : model1 loss : 0.115671 model2 loss : 0.134283
[22:51:57.517] iteration 11482 : model1 loss : 0.316165 model2 loss : 0.332357
[22:51:57.847] iteration 11483 : model1 loss : 0.220209 model2 loss : 0.308596
[22:51:58.175] iteration 11484 : model1 loss : 0.287457 model2 loss : 0.281731
[22:51:58.507] iteration 11485 : model1 loss : 0.260431 model2 loss : 0.275242
[22:51:58.835] iteration 11486 : model1 loss : 0.277251 model2 loss : 0.269010
[22:51:59.164] iteration 11487 : model1 loss : 0.150295 model2 loss : 0.222785
[22:51:59.493] iteration 11488 : model1 loss : 0.134413 model2 loss : 0.211763
[22:51:59.823] iteration 11489 : model1 loss : 0.146214 model2 loss : 0.193917
[22:52:00.152] iteration 11490 : model1 loss : 0.184470 model2 loss : 0.192118
[22:52:00.481] iteration 11491 : model1 loss : 0.196042 model2 loss : 0.260271
[22:52:00.810] iteration 11492 : model1 loss : 0.273328 model2 loss : 0.265924
[22:52:01.139] iteration 11493 : model1 loss : 0.262679 model2 loss : 0.262583
[22:52:01.467] iteration 11494 : model1 loss : 0.126167 model2 loss : 0.258406
[22:52:01.798] iteration 11495 : model1 loss : 0.195319 model2 loss : 0.212274
[22:52:02.127] iteration 11496 : model1 loss : 0.172777 model2 loss : 0.248887
[22:52:02.455] iteration 11497 : model1 loss : 0.269558 model2 loss : 0.330548
[22:52:02.784] iteration 11498 : model1 loss : 0.261870 model2 loss : 0.280946
[22:52:03.115] iteration 11499 : model1 loss : 0.120112 model2 loss : 0.138531
[22:52:03.443] iteration 11500 : model1 loss : 0.162371 model2 loss : 0.171976
[22:52:04.028] iteration 11501 : model1 loss : 0.165268 model2 loss : 0.181026
[22:52:04.358] iteration 11502 : model1 loss : 0.136481 model2 loss : 0.210339
[22:52:04.687] iteration 11503 : model1 loss : 0.154637 model2 loss : 0.233953
[22:52:05.016] iteration 11504 : model1 loss : 0.264185 model2 loss : 0.287251
[22:52:05.344] iteration 11505 : model1 loss : 0.221403 model2 loss : 0.151042
[22:52:05.673] iteration 11506 : model1 loss : 0.292741 model2 loss : 0.359902
[22:52:06.003] iteration 11507 : model1 loss : 0.144921 model2 loss : 0.137782
[22:52:06.332] iteration 11508 : model1 loss : 0.216907 model2 loss : 0.224566
[22:52:06.660] iteration 11509 : model1 loss : 0.157980 model2 loss : 0.325992
[22:52:06.990] iteration 11510 : model1 loss : 0.265295 model2 loss : 0.264540
[22:52:07.321] iteration 11511 : model1 loss : 0.259641 model2 loss : 0.220589
[22:52:07.649] iteration 11512 : model1 loss : 0.187178 model2 loss : 0.257432
[22:52:07.977] iteration 11513 : model1 loss : 0.190900 model2 loss : 0.222107
[22:52:08.306] iteration 11514 : model1 loss : 0.285162 model2 loss : 0.207822
[22:52:08.635] iteration 11515 : model1 loss : 0.120726 model2 loss : 0.264406
[22:52:08.963] iteration 11516 : model1 loss : 0.198472 model2 loss : 0.190242
[22:52:09.293] iteration 11517 : model1 loss : 0.203960 model2 loss : 0.206977
[22:52:09.621] iteration 11518 : model1 loss : 0.191330 model2 loss : 0.230583
[22:52:09.950] iteration 11519 : model1 loss : 0.238507 model2 loss : 0.284237
[22:52:10.278] iteration 11520 : model1 loss : 0.247744 model2 loss : 0.337678
[22:52:10.606] iteration 11521 : model1 loss : 0.109141 model2 loss : 0.243462
[22:52:10.941] iteration 11522 : model1 loss : 0.173932 model2 loss : 0.192481
[22:52:11.268] iteration 11523 : model1 loss : 0.265231 model2 loss : 0.268020
[22:52:11.596] iteration 11524 : model1 loss : 0.142906 model2 loss : 0.130748
[22:52:11.925] iteration 11525 : model1 loss : 0.291437 model2 loss : 0.279800
[22:52:12.254] iteration 11526 : model1 loss : 0.263835 model2 loss : 0.328155
[22:52:12.583] iteration 11527 : model1 loss : 0.231162 model2 loss : 0.245620
[22:52:12.911] iteration 11528 : model1 loss : 0.253438 model2 loss : 0.327285
[22:52:13.239] iteration 11529 : model1 loss : 0.284571 model2 loss : 0.314135
[22:52:13.567] iteration 11530 : model1 loss : 0.203307 model2 loss : 0.243407
[22:52:13.898] iteration 11531 : model1 loss : 0.124118 model2 loss : 0.163005
[22:52:14.238] iteration 11532 : model1 loss : 0.198720 model2 loss : 0.246914
[22:52:14.566] iteration 11533 : model1 loss : 0.264001 model2 loss : 0.306775
[22:52:14.895] iteration 11534 : model1 loss : 0.213696 model2 loss : 0.278454
[22:52:15.223] iteration 11535 : model1 loss : 0.173400 model2 loss : 0.193558
[22:52:15.551] iteration 11536 : model1 loss : 0.245410 model2 loss : 0.318158
[22:52:15.879] iteration 11537 : model1 loss : 0.168256 model2 loss : 0.193341
[22:52:16.208] iteration 11538 : model1 loss : 0.227174 model2 loss : 0.192112
[22:52:16.536] iteration 11539 : model1 loss : 0.274429 model2 loss : 0.315811
[22:52:16.866] iteration 11540 : model1 loss : 0.176537 model2 loss : 0.216881
[22:52:17.194] iteration 11541 : model1 loss : 0.228206 model2 loss : 0.264280
[22:52:17.521] iteration 11542 : model1 loss : 0.303057 model2 loss : 0.291715
[22:52:17.850] iteration 11543 : model1 loss : 0.183974 model2 loss : 0.241368
[22:52:18.178] iteration 11544 : model1 loss : 0.243102 model2 loss : 0.300317
[22:52:18.507] iteration 11545 : model1 loss : 0.274381 model2 loss : 0.279335
[22:52:18.840] iteration 11546 : model1 loss : 0.223523 model2 loss : 0.257356
[22:52:19.168] iteration 11547 : model1 loss : 0.171433 model2 loss : 0.202176
[22:52:19.497] iteration 11548 : model1 loss : 0.268120 model2 loss : 0.272710
[22:52:19.826] iteration 11549 : model1 loss : 0.188361 model2 loss : 0.181037
[22:52:20.155] iteration 11550 : model1 loss : 0.321973 model2 loss : 0.358302
[22:52:20.744] iteration 11551 : model1 loss : 0.329246 model2 loss : 0.262982
[22:52:21.074] iteration 11552 : model1 loss : 0.160893 model2 loss : 0.200387
[22:52:21.401] iteration 11553 : model1 loss : 0.248678 model2 loss : 0.303366
[22:52:21.730] iteration 11554 : model1 loss : 0.193214 model2 loss : 0.225536
[22:52:22.059] iteration 11555 : model1 loss : 0.196681 model2 loss : 0.243322
[22:52:22.388] iteration 11556 : model1 loss : 0.197132 model2 loss : 0.213457
[22:52:22.719] iteration 11557 : model1 loss : 0.254705 model2 loss : 0.274532
[22:52:23.048] iteration 11558 : model1 loss : 0.263655 model2 loss : 0.307795
[22:52:23.379] iteration 11559 : model1 loss : 0.186570 model2 loss : 0.290492
[22:52:23.707] iteration 11560 : model1 loss : 0.155921 model2 loss : 0.199818
[22:52:24.051] iteration 11561 : model1 loss : 0.212026 model2 loss : 0.224409
[22:52:24.380] iteration 11562 : model1 loss : 0.234728 model2 loss : 0.262565
[22:52:24.711] iteration 11563 : model1 loss : 0.294589 model2 loss : 0.338388
[22:52:25.037] iteration 11564 : model1 loss : 0.218424 model2 loss : 0.222327
[22:52:25.366] iteration 11565 : model1 loss : 0.311043 model2 loss : 0.311271
[22:52:25.694] iteration 11566 : model1 loss : 0.204266 model2 loss : 0.195762
[22:52:26.022] iteration 11567 : model1 loss : 0.131080 model2 loss : 0.157202
[22:52:26.350] iteration 11568 : model1 loss : 0.195633 model2 loss : 0.215657
[22:52:26.679] iteration 11569 : model1 loss : 0.124282 model2 loss : 0.181902
[22:52:27.006] iteration 11570 : model1 loss : 0.264936 model2 loss : 0.367261
[22:52:27.334] iteration 11571 : model1 loss : 0.192627 model2 loss : 0.229232
[22:52:27.660] iteration 11572 : model1 loss : 0.246125 model2 loss : 0.247094
[22:52:27.988] iteration 11573 : model1 loss : 0.296549 model2 loss : 0.339770
[22:52:28.315] iteration 11574 : model1 loss : 0.204854 model2 loss : 0.234630
[22:52:28.642] iteration 11575 : model1 loss : 0.149271 model2 loss : 0.179243
[22:52:28.968] iteration 11576 : model1 loss : 0.208888 model2 loss : 0.260769
[22:52:29.296] iteration 11577 : model1 loss : 0.221704 model2 loss : 0.213530
[22:52:29.622] iteration 11578 : model1 loss : 0.290774 model2 loss : 0.364068
[22:52:29.950] iteration 11579 : model1 loss : 0.138402 model2 loss : 0.152554
[22:52:30.277] iteration 11580 : model1 loss : 0.275084 model2 loss : 0.277968
[22:52:30.605] iteration 11581 : model1 loss : 0.205098 model2 loss : 0.236454
[22:52:30.933] iteration 11582 : model1 loss : 0.271774 model2 loss : 0.281914
[22:52:31.261] iteration 11583 : model1 loss : 0.290281 model2 loss : 0.306452
[22:52:31.589] iteration 11584 : model1 loss : 0.134298 model2 loss : 0.203981
[22:52:31.917] iteration 11585 : model1 loss : 0.222227 model2 loss : 0.278787
[22:52:32.246] iteration 11586 : model1 loss : 0.187641 model2 loss : 0.248509
[22:52:32.573] iteration 11587 : model1 loss : 0.200793 model2 loss : 0.206165
[22:52:32.901] iteration 11588 : model1 loss : 0.273482 model2 loss : 0.292866
[22:52:33.228] iteration 11589 : model1 loss : 0.309399 model2 loss : 0.346844
[22:52:33.555] iteration 11590 : model1 loss : 0.261608 model2 loss : 0.346518
[22:52:33.883] iteration 11591 : model1 loss : 0.212144 model2 loss : 0.263642
[22:52:34.210] iteration 11592 : model1 loss : 0.224615 model2 loss : 0.262838
[22:52:34.536] iteration 11593 : model1 loss : 0.089812 model2 loss : 0.150827
[22:52:34.864] iteration 11594 : model1 loss : 0.164937 model2 loss : 0.191110
[22:52:35.191] iteration 11595 : model1 loss : 0.314269 model2 loss : 0.333243
[22:52:35.519] iteration 11596 : model1 loss : 0.279286 model2 loss : 0.257517
[22:52:35.846] iteration 11597 : model1 loss : 0.197292 model2 loss : 0.181466
[22:52:36.173] iteration 11598 : model1 loss : 0.254616 model2 loss : 0.348853
[22:52:36.500] iteration 11599 : model1 loss : 0.198102 model2 loss : 0.228898
[22:52:36.827] iteration 11600 : model1 loss : 0.211094 model2 loss : 0.229814
[22:52:37.387] iteration 11601 : model1 loss : 0.186188 model2 loss : 0.214433
[22:52:37.713] iteration 11602 : model1 loss : 0.210466 model2 loss : 0.270694
[22:52:38.040] iteration 11603 : model1 loss : 0.183324 model2 loss : 0.180167
[22:52:38.367] iteration 11604 : model1 loss : 0.159672 model2 loss : 0.227038
[22:52:38.695] iteration 11605 : model1 loss : 0.144320 model2 loss : 0.184328
[22:52:39.022] iteration 11606 : model1 loss : 0.237128 model2 loss : 0.307509
[22:52:39.349] iteration 11607 : model1 loss : 0.329009 model2 loss : 0.366103
[22:52:39.676] iteration 11608 : model1 loss : 0.223540 model2 loss : 0.200403
[22:52:40.004] iteration 11609 : model1 loss : 0.242879 model2 loss : 0.259319
[22:52:40.332] iteration 11610 : model1 loss : 0.224857 model2 loss : 0.300963
[22:52:40.659] iteration 11611 : model1 loss : 0.342290 model2 loss : 0.340553
[22:52:40.986] iteration 11612 : model1 loss : 0.159575 model2 loss : 0.195630
[22:52:41.313] iteration 11613 : model1 loss : 0.195307 model2 loss : 0.237547
[22:52:41.640] iteration 11614 : model1 loss : 0.365418 model2 loss : 0.392956
[22:52:41.968] iteration 11615 : model1 loss : 0.237462 model2 loss : 0.276521
[22:52:42.298] iteration 11616 : model1 loss : 0.282477 model2 loss : 0.234267
[22:52:42.625] iteration 11617 : model1 loss : 0.332088 model2 loss : 0.330070
[22:52:42.952] iteration 11618 : model1 loss : 0.128378 model2 loss : 0.166406
[22:52:43.279] iteration 11619 : model1 loss : 0.306682 model2 loss : 0.317474
[22:52:43.606] iteration 11620 : model1 loss : 0.199822 model2 loss : 0.223975
[22:52:43.933] iteration 11621 : model1 loss : 0.116788 model2 loss : 0.202974
[22:52:44.261] iteration 11622 : model1 loss : 0.229944 model2 loss : 0.275501
[22:52:44.588] iteration 11623 : model1 loss : 0.207093 model2 loss : 0.216219
[22:52:44.915] iteration 11624 : model1 loss : 0.228336 model2 loss : 0.314623
[22:52:45.243] iteration 11625 : model1 loss : 0.412541 model2 loss : 0.306340
[22:52:45.570] iteration 11626 : model1 loss : 0.288784 model2 loss : 0.238952
[22:52:45.896] iteration 11627 : model1 loss : 0.304138 model2 loss : 0.233717
[22:52:46.227] iteration 11628 : model1 loss : 0.153975 model2 loss : 0.199157
[22:52:46.554] iteration 11629 : model1 loss : 0.270392 model2 loss : 0.299679
[22:52:46.880] iteration 11630 : model1 loss : 0.212471 model2 loss : 0.290752
[22:52:47.207] iteration 11631 : model1 loss : 0.208125 model2 loss : 0.177896
[22:52:47.535] iteration 11632 : model1 loss : 0.324771 model2 loss : 0.340493
[22:52:47.861] iteration 11633 : model1 loss : 0.133280 model2 loss : 0.119877
[22:52:48.188] iteration 11634 : model1 loss : 0.310887 model2 loss : 0.393315
[22:52:48.516] iteration 11635 : model1 loss : 0.212428 model2 loss : 0.228334
[22:52:48.842] iteration 11636 : model1 loss : 0.236834 model2 loss : 0.247090
[22:52:49.170] iteration 11637 : model1 loss : 0.172267 model2 loss : 0.176789
[22:52:49.497] iteration 11638 : model1 loss : 0.307874 model2 loss : 0.409163
[22:52:49.825] iteration 11639 : model1 loss : 0.299230 model2 loss : 0.329132
[22:52:50.152] iteration 11640 : model1 loss : 0.280941 model2 loss : 0.270873
[22:52:50.480] iteration 11641 : model1 loss : 0.159331 model2 loss : 0.176719
[22:52:50.808] iteration 11642 : model1 loss : 0.273339 model2 loss : 0.328474
[22:52:51.135] iteration 11643 : model1 loss : 0.213646 model2 loss : 0.220905
[22:52:51.463] iteration 11644 : model1 loss : 0.175028 model2 loss : 0.189345
[22:52:51.790] iteration 11645 : model1 loss : 0.280344 model2 loss : 0.272238
[22:52:52.117] iteration 11646 : model1 loss : 0.190394 model2 loss : 0.237740
[22:52:52.445] iteration 11647 : model1 loss : 0.171649 model2 loss : 0.164636
[22:52:52.772] iteration 11648 : model1 loss : 0.174616 model2 loss : 0.252533
[22:52:53.100] iteration 11649 : model1 loss : 0.202592 model2 loss : 0.251022
[22:52:53.427] iteration 11650 : model1 loss : 0.256992 model2 loss : 0.298498
[22:52:53.967] iteration 11651 : model1 loss : 0.189659 model2 loss : 0.232044
[22:52:54.295] iteration 11652 : model1 loss : 0.149403 model2 loss : 0.232919
[22:52:54.622] iteration 11653 : model1 loss : 0.230490 model2 loss : 0.306078
[22:52:54.949] iteration 11654 : model1 loss : 0.266090 model2 loss : 0.272805
[22:52:55.278] iteration 11655 : model1 loss : 0.109524 model2 loss : 0.177748
[22:52:55.605] iteration 11656 : model1 loss : 0.357251 model2 loss : 0.305444
[22:52:55.932] iteration 11657 : model1 loss : 0.328772 model2 loss : 0.336094
[22:52:56.258] iteration 11658 : model1 loss : 0.255767 model2 loss : 0.262460
[22:52:56.584] iteration 11659 : model1 loss : 0.175144 model2 loss : 0.194606
[22:52:56.912] iteration 11660 : model1 loss : 0.295423 model2 loss : 0.320486
[22:52:57.240] iteration 11661 : model1 loss : 0.182278 model2 loss : 0.158139
[22:52:57.567] iteration 11662 : model1 loss : 0.302246 model2 loss : 0.296312
[22:52:57.898] iteration 11663 : model1 loss : 0.237040 model2 loss : 0.218343
[22:52:58.227] iteration 11664 : model1 loss : 0.147564 model2 loss : 0.152122
[22:52:58.555] iteration 11665 : model1 loss : 0.279663 model2 loss : 0.290041
[22:52:58.882] iteration 11666 : model1 loss : 0.168194 model2 loss : 0.161393
[22:52:59.210] iteration 11667 : model1 loss : 0.194479 model2 loss : 0.211029
[22:52:59.538] iteration 11668 : model1 loss : 0.122393 model2 loss : 0.156089
[22:52:59.866] iteration 11669 : model1 loss : 0.288638 model2 loss : 0.316175
[22:53:00.194] iteration 11670 : model1 loss : 0.126443 model2 loss : 0.144337
[22:53:00.522] iteration 11671 : model1 loss : 0.211365 model2 loss : 0.269860
[22:53:00.852] iteration 11672 : model1 loss : 0.149114 model2 loss : 0.156772
[22:53:01.179] iteration 11673 : model1 loss : 0.206898 model2 loss : 0.234563
[22:53:01.506] iteration 11674 : model1 loss : 0.254832 model2 loss : 0.280890
[22:53:01.834] iteration 11675 : model1 loss : 0.109465 model2 loss : 0.148690
[22:53:02.162] iteration 11676 : model1 loss : 0.181381 model2 loss : 0.178121
[22:53:02.491] iteration 11677 : model1 loss : 0.186982 model2 loss : 0.206043
[22:53:02.818] iteration 11678 : model1 loss : 0.319259 model2 loss : 0.351941
[22:53:03.145] iteration 11679 : model1 loss : 0.166750 model2 loss : 0.294633
[22:53:03.473] iteration 11680 : model1 loss : 0.090281 model2 loss : 0.216691
[22:53:03.802] iteration 11681 : model1 loss : 0.179774 model2 loss : 0.153932
[22:53:04.130] iteration 11682 : model1 loss : 0.209352 model2 loss : 0.206274
[22:53:04.458] iteration 11683 : model1 loss : 0.183348 model2 loss : 0.225572
[22:53:04.786] iteration 11684 : model1 loss : 0.170543 model2 loss : 0.172613
[22:53:05.115] iteration 11685 : model1 loss : 0.196116 model2 loss : 0.263546
[22:53:05.443] iteration 11686 : model1 loss : 0.282997 model2 loss : 0.294863
[22:53:05.770] iteration 11687 : model1 loss : 0.236665 model2 loss : 0.289422
[22:53:06.098] iteration 11688 : model1 loss : 0.277008 model2 loss : 0.336085
[22:53:06.425] iteration 11689 : model1 loss : 0.269058 model2 loss : 0.336835
[22:53:06.761] iteration 11690 : model1 loss : 0.288811 model2 loss : 0.307594
[22:53:07.090] iteration 11691 : model1 loss : 0.203937 model2 loss : 0.241212
[22:53:07.418] iteration 11692 : model1 loss : 0.168228 model2 loss : 0.213875
[22:53:07.746] iteration 11693 : model1 loss : 0.240148 model2 loss : 0.205466
[22:53:08.074] iteration 11694 : model1 loss : 0.252140 model2 loss : 0.280424
[22:53:08.402] iteration 11695 : model1 loss : 0.270834 model2 loss : 0.302775
[22:53:08.729] iteration 11696 : model1 loss : 0.212523 model2 loss : 0.202962
[22:53:09.057] iteration 11697 : model1 loss : 0.243458 model2 loss : 0.242423
[22:53:09.385] iteration 11698 : model1 loss : 0.228061 model2 loss : 0.242273
[22:53:09.713] iteration 11699 : model1 loss : 0.304727 model2 loss : 0.337807
[22:53:10.039] iteration 11700 : model1 loss : 0.279337 model2 loss : 0.284848
[22:53:10.593] iteration 11701 : model1 loss : 0.210336 model2 loss : 0.249088
[22:53:10.919] iteration 11702 : model1 loss : 0.209756 model2 loss : 0.241008
[22:53:11.244] iteration 11703 : model1 loss : 0.216910 model2 loss : 0.251269
[22:53:11.569] iteration 11704 : model1 loss : 0.268652 model2 loss : 0.285850
[22:53:11.891] iteration 11705 : model1 loss : 0.259909 model2 loss : 0.274830
[22:53:12.214] iteration 11706 : model1 loss : 0.202081 model2 loss : 0.201316
[22:53:12.538] iteration 11707 : model1 loss : 0.208750 model2 loss : 0.283552
[22:53:12.865] iteration 11708 : model1 loss : 0.161061 model2 loss : 0.255129
[22:53:13.192] iteration 11709 : model1 loss : 0.190047 model2 loss : 0.232442
[22:53:13.515] iteration 11710 : model1 loss : 0.303466 model2 loss : 0.209515
[22:53:13.838] iteration 11711 : model1 loss : 0.269569 model2 loss : 0.330736
[22:53:14.161] iteration 11712 : model1 loss : 0.264080 model2 loss : 0.284362
[22:53:14.486] iteration 11713 : model1 loss : 0.192363 model2 loss : 0.209067
[22:53:14.809] iteration 11714 : model1 loss : 0.178803 model2 loss : 0.192780
[22:53:15.132] iteration 11715 : model1 loss : 0.181000 model2 loss : 0.214796
[22:53:15.461] iteration 11716 : model1 loss : 0.105094 model2 loss : 0.197705
[22:53:15.783] iteration 11717 : model1 loss : 0.303581 model2 loss : 0.316827
[22:53:16.106] iteration 11718 : model1 loss : 0.199216 model2 loss : 0.218210
[22:53:16.434] iteration 11719 : model1 loss : 0.224561 model2 loss : 0.260831
[22:53:16.757] iteration 11720 : model1 loss : 0.171552 model2 loss : 0.226965
[22:53:17.081] iteration 11721 : model1 loss : 0.253921 model2 loss : 0.254504
[22:53:17.410] iteration 11722 : model1 loss : 0.396624 model2 loss : 0.410487
[22:53:17.739] iteration 11723 : model1 loss : 0.190159 model2 loss : 0.302626
[22:53:18.072] iteration 11724 : model1 loss : 0.130406 model2 loss : 0.164550
[22:53:18.397] iteration 11725 : model1 loss : 0.262402 model2 loss : 0.255703
[22:53:18.722] iteration 11726 : model1 loss : 0.180229 model2 loss : 0.171582
[22:53:19.044] iteration 11727 : model1 loss : 0.232586 model2 loss : 0.235406
[22:53:19.368] iteration 11728 : model1 loss : 0.196669 model2 loss : 0.301953
[22:53:19.700] iteration 11729 : model1 loss : 0.283114 model2 loss : 0.309760
[22:53:20.027] iteration 11730 : model1 loss : 0.291724 model2 loss : 0.343313
[22:53:20.355] iteration 11731 : model1 loss : 0.288130 model2 loss : 0.312593
[22:53:20.678] iteration 11732 : model1 loss : 0.279309 model2 loss : 0.306708
[22:53:21.006] iteration 11733 : model1 loss : 0.237455 model2 loss : 0.245897
[22:53:21.332] iteration 11734 : model1 loss : 0.196078 model2 loss : 0.192924
[22:53:21.656] iteration 11735 : model1 loss : 0.252860 model2 loss : 0.304134
[22:53:21.981] iteration 11736 : model1 loss : 0.370623 model2 loss : 0.385371
[22:53:22.306] iteration 11737 : model1 loss : 0.120229 model2 loss : 0.179526
[22:53:22.631] iteration 11738 : model1 loss : 0.275569 model2 loss : 0.280045
[22:53:22.962] iteration 11739 : model1 loss : 0.228804 model2 loss : 0.290720
[22:53:23.285] iteration 11740 : model1 loss : 0.241303 model2 loss : 0.285970
[22:53:23.609] iteration 11741 : model1 loss : 0.274503 model2 loss : 0.350555
[22:53:23.932] iteration 11742 : model1 loss : 0.339184 model2 loss : 0.315622
[22:53:24.255] iteration 11743 : model1 loss : 0.308940 model2 loss : 0.271726
[22:53:24.578] iteration 11744 : model1 loss : 0.165487 model2 loss : 0.208752
[22:53:24.906] iteration 11745 : model1 loss : 0.332263 model2 loss : 0.346580
[22:53:25.230] iteration 11746 : model1 loss : 0.140166 model2 loss : 0.169701
[22:53:25.554] iteration 11747 : model1 loss : 0.227210 model2 loss : 0.230487
[22:53:25.877] iteration 11748 : model1 loss : 0.300977 model2 loss : 0.329211
[22:53:26.200] iteration 11749 : model1 loss : 0.176536 model2 loss : 0.206710
[22:53:26.524] iteration 11750 : model1 loss : 0.195648 model2 loss : 0.223422
[22:53:27.069] iteration 11751 : model1 loss : 0.233063 model2 loss : 0.277054
[22:53:27.398] iteration 11752 : model1 loss : 0.241042 model2 loss : 0.290362
[22:53:27.721] iteration 11753 : model1 loss : 0.257769 model2 loss : 0.283112
[22:53:28.049] iteration 11754 : model1 loss : 0.283236 model2 loss : 0.281117
[22:53:28.373] iteration 11755 : model1 loss : 0.284529 model2 loss : 0.334604
[22:53:28.696] iteration 11756 : model1 loss : 0.227444 model2 loss : 0.280160
[22:53:29.018] iteration 11757 : model1 loss : 0.230259 model2 loss : 0.214326
[22:53:29.342] iteration 11758 : model1 loss : 0.363175 model2 loss : 0.389625
[22:53:29.664] iteration 11759 : model1 loss : 0.201763 model2 loss : 0.228600
[22:53:29.988] iteration 11760 : model1 loss : 0.266025 model2 loss : 0.293392
[22:53:30.311] iteration 11761 : model1 loss : 0.103237 model2 loss : 0.148764
[22:53:30.638] iteration 11762 : model1 loss : 0.374113 model2 loss : 0.321349
[22:53:30.962] iteration 11763 : model1 loss : 0.290166 model2 loss : 0.323656
[22:53:31.284] iteration 11764 : model1 loss : 0.200006 model2 loss : 0.206837
[22:53:31.612] iteration 11765 : model1 loss : 0.399433 model2 loss : 0.428959
[22:53:31.934] iteration 11766 : model1 loss : 0.286222 model2 loss : 0.231932
[22:53:32.258] iteration 11767 : model1 loss : 0.197816 model2 loss : 0.266660
[22:53:32.582] iteration 11768 : model1 loss : 0.312176 model2 loss : 0.233326
[22:53:32.905] iteration 11769 : model1 loss : 0.263997 model2 loss : 0.262070
[22:53:33.228] iteration 11770 : model1 loss : 0.342148 model2 loss : 0.320573
[22:53:33.552] iteration 11771 : model1 loss : 0.249751 model2 loss : 0.239614
[22:53:33.875] iteration 11772 : model1 loss : 0.257579 model2 loss : 0.272962
[22:53:34.202] iteration 11773 : model1 loss : 0.173041 model2 loss : 0.223695
[22:53:34.530] iteration 11774 : model1 loss : 0.173927 model2 loss : 0.197476
[22:53:34.859] iteration 11775 : model1 loss : 0.154151 model2 loss : 0.221317
[22:53:35.185] iteration 11776 : model1 loss : 0.173002 model2 loss : 0.240566
[22:53:35.509] iteration 11777 : model1 loss : 0.239540 model2 loss : 0.214207
[22:53:35.833] iteration 11778 : model1 loss : 0.293248 model2 loss : 0.311894
[22:53:36.166] iteration 11779 : model1 loss : 0.193735 model2 loss : 0.211498
[22:53:36.489] iteration 11780 : model1 loss : 0.256030 model2 loss : 0.297743
[22:53:36.821] iteration 11781 : model1 loss : 0.161470 model2 loss : 0.190388
[22:53:37.152] iteration 11782 : model1 loss : 0.304997 model2 loss : 0.285643
[22:53:37.483] iteration 11783 : model1 loss : 0.293228 model2 loss : 0.203623
[22:53:37.814] iteration 11784 : model1 loss : 0.262276 model2 loss : 0.245955
[22:53:38.149] iteration 11785 : model1 loss : 0.166160 model2 loss : 0.196138
[22:53:38.484] iteration 11786 : model1 loss : 0.262808 model2 loss : 0.336443
[22:53:38.819] iteration 11787 : model1 loss : 0.195004 model2 loss : 0.322275
[22:53:39.150] iteration 11788 : model1 loss : 0.174104 model2 loss : 0.212356
[22:53:39.482] iteration 11789 : model1 loss : 0.272189 model2 loss : 0.283611
[22:53:39.820] iteration 11790 : model1 loss : 0.290023 model2 loss : 0.246799
[22:53:40.156] iteration 11791 : model1 loss : 0.168217 model2 loss : 0.220817
[22:53:40.492] iteration 11792 : model1 loss : 0.220311 model2 loss : 0.275446
[22:53:40.834] iteration 11793 : model1 loss : 0.312943 model2 loss : 0.324116
[22:53:41.173] iteration 11794 : model1 loss : 0.281953 model2 loss : 0.309733
[22:53:41.511] iteration 11795 : model1 loss : 0.282189 model2 loss : 0.309898
[22:53:41.847] iteration 11796 : model1 loss : 0.197762 model2 loss : 0.186565
[22:53:42.185] iteration 11797 : model1 loss : 0.161596 model2 loss : 0.175063
[22:53:42.521] iteration 11798 : model1 loss : 0.333179 model2 loss : 0.342172
[22:53:42.861] iteration 11799 : model1 loss : 0.154902 model2 loss : 0.201805
[22:53:43.197] iteration 11800 : model1 loss : 0.173491 model2 loss : 0.167461
[22:53:43.846] iteration 11801 : model1 loss : 0.307063 model2 loss : 0.306502
[22:53:44.175] iteration 11802 : model1 loss : 0.214208 model2 loss : 0.220119
[22:53:44.504] iteration 11803 : model1 loss : 0.207760 model2 loss : 0.260508
[22:53:44.834] iteration 11804 : model1 loss : 0.192618 model2 loss : 0.157747
[22:53:45.162] iteration 11805 : model1 loss : 0.210891 model2 loss : 0.210879
[22:53:45.485] iteration 11806 : model1 loss : 0.188729 model2 loss : 0.220101
[22:53:45.814] iteration 11807 : model1 loss : 0.140441 model2 loss : 0.179637
[22:53:46.136] iteration 11808 : model1 loss : 0.272286 model2 loss : 0.300070
[22:53:46.461] iteration 11809 : model1 loss : 0.178478 model2 loss : 0.159423
[22:53:46.787] iteration 11810 : model1 loss : 0.182917 model2 loss : 0.196455
[22:53:47.110] iteration 11811 : model1 loss : 0.220015 model2 loss : 0.193821
[22:53:47.437] iteration 11812 : model1 loss : 0.259991 model2 loss : 0.277937
[22:53:47.761] iteration 11813 : model1 loss : 0.193875 model2 loss : 0.200716
[22:53:48.084] iteration 11814 : model1 loss : 0.234888 model2 loss : 0.245641
[22:53:48.410] iteration 11815 : model1 loss : 0.147394 model2 loss : 0.181388
[22:53:48.732] iteration 11816 : model1 loss : 0.204936 model2 loss : 0.255514
[22:53:49.055] iteration 11817 : model1 loss : 0.188906 model2 loss : 0.191186
[22:53:49.377] iteration 11818 : model1 loss : 0.202132 model2 loss : 0.189227
[22:53:49.700] iteration 11819 : model1 loss : 0.189405 model2 loss : 0.200089
[22:53:50.024] iteration 11820 : model1 loss : 0.126990 model2 loss : 0.203698
[22:53:50.348] iteration 11821 : model1 loss : 0.342831 model2 loss : 0.399409
[22:53:50.671] iteration 11822 : model1 loss : 0.224226 model2 loss : 0.245371
[22:53:50.994] iteration 11823 : model1 loss : 0.234527 model2 loss : 0.226612
[22:53:51.318] iteration 11824 : model1 loss : 0.207535 model2 loss : 0.276870
[22:53:51.645] iteration 11825 : model1 loss : 0.186777 model2 loss : 0.223795
[22:53:51.967] iteration 11826 : model1 loss : 0.110693 model2 loss : 0.114372
[22:53:52.291] iteration 11827 : model1 loss : 0.087001 model2 loss : 0.133192
[22:53:52.613] iteration 11828 : model1 loss : 0.286072 model2 loss : 0.226825
[22:53:52.936] iteration 11829 : model1 loss : 0.092013 model2 loss : 0.135129
[22:53:53.262] iteration 11830 : model1 loss : 0.174462 model2 loss : 0.182575
[22:53:53.587] iteration 11831 : model1 loss : 0.204907 model2 loss : 0.201250
[22:53:53.910] iteration 11832 : model1 loss : 0.156595 model2 loss : 0.194923
[22:53:54.233] iteration 11833 : model1 loss : 0.179000 model2 loss : 0.217815
[22:53:54.557] iteration 11834 : model1 loss : 0.201776 model2 loss : 0.232509
[22:53:54.884] iteration 11835 : model1 loss : 0.197740 model2 loss : 0.250975
[22:53:55.210] iteration 11836 : model1 loss : 0.164938 model2 loss : 0.176085
[22:53:55.540] iteration 11837 : model1 loss : 0.271211 model2 loss : 0.312139
[22:53:55.862] iteration 11838 : model1 loss : 0.192486 model2 loss : 0.235418
[22:53:56.186] iteration 11839 : model1 loss : 0.298108 model2 loss : 0.330866
[22:53:56.508] iteration 11840 : model1 loss : 0.181815 model2 loss : 0.169602
[22:53:56.831] iteration 11841 : model1 loss : 0.266632 model2 loss : 0.341910
[22:53:57.154] iteration 11842 : model1 loss : 0.321329 model2 loss : 0.330198
[22:53:57.477] iteration 11843 : model1 loss : 0.218750 model2 loss : 0.224699
[22:53:57.801] iteration 11844 : model1 loss : 0.208769 model2 loss : 0.331805
[22:53:58.124] iteration 11845 : model1 loss : 0.219455 model2 loss : 0.285990
[22:53:58.451] iteration 11846 : model1 loss : 0.268171 model2 loss : 0.301327
[22:53:58.774] iteration 11847 : model1 loss : 0.279629 model2 loss : 0.347378
[22:53:59.098] iteration 11848 : model1 loss : 0.382870 model2 loss : 0.311985
[22:53:59.423] iteration 11849 : model1 loss : 0.370752 model2 loss : 0.345314
[22:53:59.759] iteration 11850 : model1 loss : 0.179464 model2 loss : 0.262794
[22:54:00.307] iteration 11851 : model1 loss : 0.324920 model2 loss : 0.317762
[22:54:00.637] iteration 11852 : model1 loss : 0.264061 model2 loss : 0.220243
[22:54:00.963] iteration 11853 : model1 loss : 0.129144 model2 loss : 0.220378
[22:54:01.289] iteration 11854 : model1 loss : 0.244933 model2 loss : 0.213371
[22:54:01.615] iteration 11855 : model1 loss : 0.398664 model2 loss : 0.364982
[22:54:01.946] iteration 11856 : model1 loss : 0.347498 model2 loss : 0.408432
[22:54:02.269] iteration 11857 : model1 loss : 0.174987 model2 loss : 0.269817
[22:54:02.598] iteration 11858 : model1 loss : 0.237185 model2 loss : 0.204783
[22:54:02.926] iteration 11859 : model1 loss : 0.113661 model2 loss : 0.148822
[22:54:03.249] iteration 11860 : model1 loss : 0.136202 model2 loss : 0.200083
[22:54:03.573] iteration 11861 : model1 loss : 0.329123 model2 loss : 0.336583
[22:54:03.908] iteration 11862 : model1 loss : 0.237296 model2 loss : 0.298051
[22:54:04.236] iteration 11863 : model1 loss : 0.210344 model2 loss : 0.246769
[22:54:04.566] iteration 11864 : model1 loss : 0.263895 model2 loss : 0.289405
[22:54:04.896] iteration 11865 : model1 loss : 0.185898 model2 loss : 0.232947
[22:54:05.229] iteration 11866 : model1 loss : 0.260449 model2 loss : 0.298660
[22:54:05.561] iteration 11867 : model1 loss : 0.319012 model2 loss : 0.315405
[22:54:05.895] iteration 11868 : model1 loss : 0.256887 model2 loss : 0.288156
[22:54:06.225] iteration 11869 : model1 loss : 0.256034 model2 loss : 0.271932
[22:54:06.559] iteration 11870 : model1 loss : 0.309834 model2 loss : 0.264900
[22:54:06.889] iteration 11871 : model1 loss : 0.184338 model2 loss : 0.252949
[22:54:07.220] iteration 11872 : model1 loss : 0.290180 model2 loss : 0.322672
[22:54:07.558] iteration 11873 : model1 loss : 0.294127 model2 loss : 0.316768
[22:54:07.890] iteration 11874 : model1 loss : 0.138203 model2 loss : 0.158526
[22:54:08.221] iteration 11875 : model1 loss : 0.133587 model2 loss : 0.176168
[22:54:08.551] iteration 11876 : model1 loss : 0.115467 model2 loss : 0.160617
[22:54:08.881] iteration 11877 : model1 loss : 0.297721 model2 loss : 0.306171
[22:54:09.213] iteration 11878 : model1 loss : 0.209159 model2 loss : 0.225897
[22:54:09.544] iteration 11879 : model1 loss : 0.274457 model2 loss : 0.263267
[22:54:09.874] iteration 11880 : model1 loss : 0.195834 model2 loss : 0.215147
[22:54:10.204] iteration 11881 : model1 loss : 0.115471 model2 loss : 0.132396
[22:54:10.545] iteration 11882 : model1 loss : 0.323107 model2 loss : 0.302211
[22:54:10.889] iteration 11883 : model1 loss : 0.207200 model2 loss : 0.230250
[22:54:11.218] iteration 11884 : model1 loss : 0.124913 model2 loss : 0.163100
[22:54:11.547] iteration 11885 : model1 loss : 0.159732 model2 loss : 0.116391
[22:54:11.877] iteration 11886 : model1 loss : 0.229530 model2 loss : 0.231569
[22:54:12.206] iteration 11887 : model1 loss : 0.357574 model2 loss : 0.396387
[22:54:12.535] iteration 11888 : model1 loss : 0.213001 model2 loss : 0.211775
[22:54:12.865] iteration 11889 : model1 loss : 0.212651 model2 loss : 0.329364
[22:54:13.200] iteration 11890 : model1 loss : 0.218719 model2 loss : 0.262305
[22:54:13.532] iteration 11891 : model1 loss : 0.123239 model2 loss : 0.196726
[22:54:13.861] iteration 11892 : model1 loss : 0.232336 model2 loss : 0.268084
[22:54:14.188] iteration 11893 : model1 loss : 0.176572 model2 loss : 0.143825
[22:54:14.518] iteration 11894 : model1 loss : 0.152714 model2 loss : 0.200783
[22:54:14.851] iteration 11895 : model1 loss : 0.261136 model2 loss : 0.280932
[22:54:15.183] iteration 11896 : model1 loss : 0.181693 model2 loss : 0.206617
[22:54:15.518] iteration 11897 : model1 loss : 0.220355 model2 loss : 0.189448
[22:54:15.850] iteration 11898 : model1 loss : 0.267382 model2 loss : 0.240590
[22:54:16.186] iteration 11899 : model1 loss : 0.137186 model2 loss : 0.204195
[22:54:16.527] iteration 11900 : model1 loss : 0.345528 model2 loss : 0.366415
[22:54:17.169] iteration 11901 : model1 loss : 0.217406 model2 loss : 0.173920
[22:54:17.502] iteration 11902 : model1 loss : 0.246223 model2 loss : 0.285849
[22:54:17.834] iteration 11903 : model1 loss : 0.114260 model2 loss : 0.180367
[22:54:18.165] iteration 11904 : model1 loss : 0.176259 model2 loss : 0.246889
[22:54:18.496] iteration 11905 : model1 loss : 0.230078 model2 loss : 0.218994
[22:54:18.839] iteration 11906 : model1 loss : 0.114831 model2 loss : 0.135231
[22:54:19.172] iteration 11907 : model1 loss : 0.233811 model2 loss : 0.320817
[22:54:19.502] iteration 11908 : model1 loss : 0.280499 model2 loss : 0.269764
[22:54:19.835] iteration 11909 : model1 loss : 0.204069 model2 loss : 0.243223
[22:54:20.164] iteration 11910 : model1 loss : 0.274340 model2 loss : 0.285064
[22:54:20.492] iteration 11911 : model1 loss : 0.226675 model2 loss : 0.234056
[22:54:20.825] iteration 11912 : model1 loss : 0.209022 model2 loss : 0.203293
[22:54:21.153] iteration 11913 : model1 loss : 0.222286 model2 loss : 0.278431
[22:54:21.482] iteration 11914 : model1 loss : 0.309689 model2 loss : 0.405524
[22:54:21.814] iteration 11915 : model1 loss : 0.163557 model2 loss : 0.173295
[22:54:22.144] iteration 11916 : model1 loss : 0.262741 model2 loss : 0.332559
[22:54:22.475] iteration 11917 : model1 loss : 0.253641 model2 loss : 0.290274
[22:54:22.806] iteration 11918 : model1 loss : 0.328168 model2 loss : 0.391174
[22:54:23.137] iteration 11919 : model1 loss : 0.249261 model2 loss : 0.349954
[22:54:23.471] iteration 11920 : model1 loss : 0.271794 model2 loss : 0.300981
[22:54:23.802] iteration 11921 : model1 loss : 0.212922 model2 loss : 0.221621
[22:54:24.135] iteration 11922 : model1 loss : 0.284771 model2 loss : 0.318180
[22:54:24.466] iteration 11923 : model1 loss : 0.195003 model2 loss : 0.259103
[22:54:24.798] iteration 11924 : model1 loss : 0.210042 model2 loss : 0.252522
[22:54:25.131] iteration 11925 : model1 loss : 0.204088 model2 loss : 0.239425
[22:54:25.464] iteration 11926 : model1 loss : 0.259823 model2 loss : 0.241781
[22:54:25.795] iteration 11927 : model1 loss : 0.173789 model2 loss : 0.183137
[22:54:26.127] iteration 11928 : model1 loss : 0.188658 model2 loss : 0.264117
[22:54:26.457] iteration 11929 : model1 loss : 0.248420 model2 loss : 0.253894
[22:54:26.789] iteration 11930 : model1 loss : 0.173550 model2 loss : 0.212462
[22:54:27.121] iteration 11931 : model1 loss : 0.278487 model2 loss : 0.337341
[22:54:27.453] iteration 11932 : model1 loss : 0.270651 model2 loss : 0.287219
[22:54:27.785] iteration 11933 : model1 loss : 0.283945 model2 loss : 0.312910
[22:54:28.114] iteration 11934 : model1 loss : 0.262617 model2 loss : 0.207022
[22:54:28.448] iteration 11935 : model1 loss : 0.210771 model2 loss : 0.233207
[22:54:28.783] iteration 11936 : model1 loss : 0.256254 model2 loss : 0.264669
[22:54:29.117] iteration 11937 : model1 loss : 0.196189 model2 loss : 0.210557
[22:54:29.461] iteration 11938 : model1 loss : 0.262012 model2 loss : 0.277501
[22:54:29.803] iteration 11939 : model1 loss : 0.298330 model2 loss : 0.340451
[22:54:30.147] iteration 11940 : model1 loss : 0.194177 model2 loss : 0.188305
[22:54:30.487] iteration 11941 : model1 loss : 0.263729 model2 loss : 0.279179
[22:54:30.833] iteration 11942 : model1 loss : 0.346380 model2 loss : 0.299818
[22:54:31.177] iteration 11943 : model1 loss : 0.097731 model2 loss : 0.147949
[22:54:31.522] iteration 11944 : model1 loss : 0.305495 model2 loss : 0.313612
[22:54:31.863] iteration 11945 : model1 loss : 0.192262 model2 loss : 0.224577
[22:54:32.201] iteration 11946 : model1 loss : 0.223096 model2 loss : 0.286193
[22:54:32.545] iteration 11947 : model1 loss : 0.199220 model2 loss : 0.224041
[22:54:32.889] iteration 11948 : model1 loss : 0.248625 model2 loss : 0.292932
[22:54:33.233] iteration 11949 : model1 loss : 0.224520 model2 loss : 0.191328
[22:54:33.585] iteration 11950 : model1 loss : 0.170773 model2 loss : 0.200614
[22:54:34.238] iteration 11951 : model1 loss : 0.182874 model2 loss : 0.222512
[22:54:34.575] iteration 11952 : model1 loss : 0.321529 model2 loss : 0.388273
[22:54:34.912] iteration 11953 : model1 loss : 0.233103 model2 loss : 0.244737
[22:54:35.249] iteration 11954 : model1 loss : 0.180391 model2 loss : 0.276767
[22:54:35.586] iteration 11955 : model1 loss : 0.207690 model2 loss : 0.232308
[22:54:35.923] iteration 11956 : model1 loss : 0.240284 model2 loss : 0.285147
[22:54:36.261] iteration 11957 : model1 loss : 0.244160 model2 loss : 0.291540
[22:54:36.598] iteration 11958 : model1 loss : 0.136626 model2 loss : 0.190133
[22:54:36.936] iteration 11959 : model1 loss : 0.294801 model2 loss : 0.279090
[22:54:37.272] iteration 11960 : model1 loss : 0.293020 model2 loss : 0.248799
[22:54:37.608] iteration 11961 : model1 loss : 0.325826 model2 loss : 0.363202
[22:54:37.945] iteration 11962 : model1 loss : 0.250727 model2 loss : 0.335968
[22:54:38.282] iteration 11963 : model1 loss : 0.275195 model2 loss : 0.306110
[22:54:38.619] iteration 11964 : model1 loss : 0.272216 model2 loss : 0.271959
[22:54:38.960] iteration 11965 : model1 loss : 0.182388 model2 loss : 0.206441
[22:54:39.296] iteration 11966 : model1 loss : 0.197284 model2 loss : 0.213574
[22:54:39.634] iteration 11967 : model1 loss : 0.214733 model2 loss : 0.267015
[22:54:39.971] iteration 11968 : model1 loss : 0.225024 model2 loss : 0.309620
[22:54:40.308] iteration 11969 : model1 loss : 0.295596 model2 loss : 0.269512
[22:54:40.645] iteration 11970 : model1 loss : 0.215151 model2 loss : 0.273938
[22:54:40.981] iteration 11971 : model1 loss : 0.254077 model2 loss : 0.231219
[22:54:41.323] iteration 11972 : model1 loss : 0.246965 model2 loss : 0.221424
[22:54:41.656] iteration 11973 : model1 loss : 0.128003 model2 loss : 0.210096
[22:54:41.986] iteration 11974 : model1 loss : 0.176946 model2 loss : 0.196363
[22:54:42.318] iteration 11975 : model1 loss : 0.183544 model2 loss : 0.191202
[22:54:42.650] iteration 11976 : model1 loss : 0.197210 model2 loss : 0.194725
[22:54:42.982] iteration 11977 : model1 loss : 0.308225 model2 loss : 0.300123
[22:54:43.315] iteration 11978 : model1 loss : 0.323524 model2 loss : 0.286967
[22:54:43.650] iteration 11979 : model1 loss : 0.224845 model2 loss : 0.225668
[22:54:43.983] iteration 11980 : model1 loss : 0.279361 model2 loss : 0.304785
[22:54:44.322] iteration 11981 : model1 loss : 0.194342 model2 loss : 0.227326
[22:54:44.653] iteration 11982 : model1 loss : 0.178175 model2 loss : 0.178158
[22:54:44.987] iteration 11983 : model1 loss : 0.205266 model2 loss : 0.238098
[22:54:45.323] iteration 11984 : model1 loss : 0.270698 model2 loss : 0.273891
[22:54:45.654] iteration 11985 : model1 loss : 0.204610 model2 loss : 0.243404
[22:54:45.988] iteration 11986 : model1 loss : 0.287212 model2 loss : 0.304197
[22:54:46.321] iteration 11987 : model1 loss : 0.215299 model2 loss : 0.233737
[22:54:46.654] iteration 11988 : model1 loss : 0.334703 model2 loss : 0.328955
[22:54:46.988] iteration 11989 : model1 loss : 0.219288 model2 loss : 0.238251
[22:54:47.319] iteration 11990 : model1 loss : 0.171599 model2 loss : 0.168559
[22:54:48.413] iteration 11991 : model1 loss : 0.213450 model2 loss : 0.213658
[22:54:48.750] iteration 11992 : model1 loss : 0.201967 model2 loss : 0.277989
[22:54:49.089] iteration 11993 : model1 loss : 0.193624 model2 loss : 0.229556
[22:54:49.424] iteration 11994 : model1 loss : 0.261066 model2 loss : 0.275871
[22:54:49.762] iteration 11995 : model1 loss : 0.265934 model2 loss : 0.288465
[22:54:50.099] iteration 11996 : model1 loss : 0.206077 model2 loss : 0.270399
[22:54:50.431] iteration 11997 : model1 loss : 0.286574 model2 loss : 0.290148
[22:54:50.765] iteration 11998 : model1 loss : 0.203577 model2 loss : 0.263449
[22:54:51.103] iteration 11999 : model1 loss : 0.196169 model2 loss : 0.266429
[22:54:51.443] iteration 12000 : model1 loss : 0.184513 model2 loss : 0.183775
[22:55:57.251] iteration 12000 : model1_mean_dice : 0.742161 model1_mean_hd95 : 12.371806
[22:56:47.523] iteration 12000 : model2_mean_dice : 0.509372 model2_mean_hd95 : 14.765594
[22:56:47.745] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_12000.pth
[22:56:47.765] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_12000.pth
[22:56:48.098] iteration 12001 : model1 loss : 0.421419 model2 loss : 0.434698
[22:56:48.424] iteration 12002 : model1 loss : 0.113141 model2 loss : 0.143706
[22:56:48.757] iteration 12003 : model1 loss : 0.184591 model2 loss : 0.205220
[22:56:49.093] iteration 12004 : model1 loss : 0.171858 model2 loss : 0.225747
[22:56:49.428] iteration 12005 : model1 loss : 0.266958 model2 loss : 0.283156
[22:56:49.761] iteration 12006 : model1 loss : 0.290533 model2 loss : 0.364581
[22:56:50.092] iteration 12007 : model1 loss : 0.209351 model2 loss : 0.243776
[22:56:50.429] iteration 12008 : model1 loss : 0.165582 model2 loss : 0.252103
[22:56:50.768] iteration 12009 : model1 loss : 0.188046 model2 loss : 0.208315
[22:56:51.102] iteration 12010 : model1 loss : 0.222686 model2 loss : 0.260625
[22:56:51.434] iteration 12011 : model1 loss : 0.245230 model2 loss : 0.212357
[22:56:51.767] iteration 12012 : model1 loss : 0.206618 model2 loss : 0.265957
[22:56:52.103] iteration 12013 : model1 loss : 0.236428 model2 loss : 0.280107
[22:56:52.439] iteration 12014 : model1 loss : 0.256898 model2 loss : 0.263156
[22:56:52.771] iteration 12015 : model1 loss : 0.113633 model2 loss : 0.115127
[22:56:53.106] iteration 12016 : model1 loss : 0.089157 model2 loss : 0.146469
[22:56:53.442] iteration 12017 : model1 loss : 0.214523 model2 loss : 0.246096
[22:56:53.775] iteration 12018 : model1 loss : 0.164980 model2 loss : 0.254910
[22:56:54.110] iteration 12019 : model1 loss : 0.178417 model2 loss : 0.243094
[22:56:54.454] iteration 12020 : model1 loss : 0.213256 model2 loss : 0.253282
[22:56:54.791] iteration 12021 : model1 loss : 0.240543 model2 loss : 0.227058
[22:56:55.128] iteration 12022 : model1 loss : 0.306558 model2 loss : 0.289406
[22:56:55.466] iteration 12023 : model1 loss : 0.228001 model2 loss : 0.279405
[22:56:55.799] iteration 12024 : model1 loss : 0.274308 model2 loss : 0.304693
[22:56:56.136] iteration 12025 : model1 loss : 0.144596 model2 loss : 0.146026
[22:56:56.479] iteration 12026 : model1 loss : 0.224307 model2 loss : 0.259496
[22:56:56.817] iteration 12027 : model1 loss : 0.214413 model2 loss : 0.254093
[22:56:57.155] iteration 12028 : model1 loss : 0.190745 model2 loss : 0.234339
[22:56:57.489] iteration 12029 : model1 loss : 0.093853 model2 loss : 0.117751
[22:56:57.827] iteration 12030 : model1 loss : 0.181474 model2 loss : 0.189293
[22:56:58.165] iteration 12031 : model1 loss : 0.227414 model2 loss : 0.303720
[22:56:58.505] iteration 12032 : model1 loss : 0.230511 model2 loss : 0.227322
[22:56:58.843] iteration 12033 : model1 loss : 0.174377 model2 loss : 0.196676
[22:56:59.177] iteration 12034 : model1 loss : 0.261469 model2 loss : 0.296775
[22:56:59.516] iteration 12035 : model1 loss : 0.324076 model2 loss : 0.367781
[22:56:59.858] iteration 12036 : model1 loss : 0.230800 model2 loss : 0.221368
[22:57:00.197] iteration 12037 : model1 loss : 0.244957 model2 loss : 0.305448
[22:57:00.534] iteration 12038 : model1 loss : 0.194824 model2 loss : 0.273432
[22:57:00.872] iteration 12039 : model1 loss : 0.265318 model2 loss : 0.314210
[22:57:01.209] iteration 12040 : model1 loss : 0.184498 model2 loss : 0.217784
[22:57:01.551] iteration 12041 : model1 loss : 0.244578 model2 loss : 0.308432
[22:57:01.894] iteration 12042 : model1 loss : 0.239569 model2 loss : 0.304688
[22:57:02.237] iteration 12043 : model1 loss : 0.189450 model2 loss : 0.199855
[22:57:02.578] iteration 12044 : model1 loss : 0.174156 model2 loss : 0.237038
[22:57:02.914] iteration 12045 : model1 loss : 0.159278 model2 loss : 0.231881
[22:57:03.252] iteration 12046 : model1 loss : 0.137849 model2 loss : 0.122358
[22:57:03.577] iteration 12047 : model1 loss : 0.194467 model2 loss : 0.196624
[22:57:03.904] iteration 12048 : model1 loss : 0.099290 model2 loss : 0.141714
[22:57:04.232] iteration 12049 : model1 loss : 0.195782 model2 loss : 0.197793
[22:57:04.562] iteration 12050 : model1 loss : 0.231101 model2 loss : 0.238904
[22:57:05.095] iteration 12051 : model1 loss : 0.183432 model2 loss : 0.263103
[22:57:05.428] iteration 12052 : model1 loss : 0.260932 model2 loss : 0.260833
[22:57:05.760] iteration 12053 : model1 loss : 0.111632 model2 loss : 0.121961
[22:57:06.091] iteration 12054 : model1 loss : 0.228144 model2 loss : 0.226363
[22:57:06.421] iteration 12055 : model1 loss : 0.289952 model2 loss : 0.281335
[22:57:06.753] iteration 12056 : model1 loss : 0.223705 model2 loss : 0.208025
[22:57:07.082] iteration 12057 : model1 loss : 0.234520 model2 loss : 0.259273
[22:57:07.414] iteration 12058 : model1 loss : 0.149309 model2 loss : 0.166597
[22:57:07.745] iteration 12059 : model1 loss : 0.088807 model2 loss : 0.164276
[22:57:08.075] iteration 12060 : model1 loss : 0.270564 model2 loss : 0.233503
[22:57:08.406] iteration 12061 : model1 loss : 0.214226 model2 loss : 0.231610
[22:57:08.738] iteration 12062 : model1 loss : 0.332446 model2 loss : 0.414283
[22:57:09.070] iteration 12063 : model1 loss : 0.197105 model2 loss : 0.258144
[22:57:09.401] iteration 12064 : model1 loss : 0.262085 model2 loss : 0.295905
[22:57:09.733] iteration 12065 : model1 loss : 0.225032 model2 loss : 0.292205
[22:57:10.064] iteration 12066 : model1 loss : 0.247157 model2 loss : 0.245524
[22:57:10.397] iteration 12067 : model1 loss : 0.280558 model2 loss : 0.319848
[22:57:10.729] iteration 12068 : model1 loss : 0.259670 model2 loss : 0.278673
[22:57:11.061] iteration 12069 : model1 loss : 0.256995 model2 loss : 0.267337
[22:57:11.394] iteration 12070 : model1 loss : 0.239236 model2 loss : 0.225989
[22:57:11.724] iteration 12071 : model1 loss : 0.206923 model2 loss : 0.241039
[22:57:12.057] iteration 12072 : model1 loss : 0.226636 model2 loss : 0.245889
[22:57:12.386] iteration 12073 : model1 loss : 0.191022 model2 loss : 0.217611
[22:57:12.718] iteration 12074 : model1 loss : 0.120075 model2 loss : 0.163326
[22:57:13.049] iteration 12075 : model1 loss : 0.180452 model2 loss : 0.230430
[22:57:13.380] iteration 12076 : model1 loss : 0.265254 model2 loss : 0.242869
[22:57:13.711] iteration 12077 : model1 loss : 0.195203 model2 loss : 0.205024
[22:57:14.043] iteration 12078 : model1 loss : 0.239000 model2 loss : 0.252040
[22:57:14.370] iteration 12079 : model1 loss : 0.248062 model2 loss : 0.239679
[22:57:14.697] iteration 12080 : model1 loss : 0.216310 model2 loss : 0.186871
[22:57:15.023] iteration 12081 : model1 loss : 0.160585 model2 loss : 0.164823
[22:57:15.350] iteration 12082 : model1 loss : 0.285726 model2 loss : 0.308478
[22:57:15.677] iteration 12083 : model1 loss : 0.191363 model2 loss : 0.261598
[22:57:16.003] iteration 12084 : model1 loss : 0.240996 model2 loss : 0.262988
[22:57:16.330] iteration 12085 : model1 loss : 0.164534 model2 loss : 0.206684
[22:57:16.656] iteration 12086 : model1 loss : 0.306217 model2 loss : 0.300718
[22:57:16.982] iteration 12087 : model1 loss : 0.241753 model2 loss : 0.315928
[22:57:17.309] iteration 12088 : model1 loss : 0.223116 model2 loss : 0.285266
[22:57:17.635] iteration 12089 : model1 loss : 0.167309 model2 loss : 0.197065
[22:57:17.962] iteration 12090 : model1 loss : 0.257217 model2 loss : 0.242822
[22:57:18.288] iteration 12091 : model1 loss : 0.135242 model2 loss : 0.175271
[22:57:18.614] iteration 12092 : model1 loss : 0.205355 model2 loss : 0.269185
[22:57:18.940] iteration 12093 : model1 loss : 0.195904 model2 loss : 0.246621
[22:57:19.267] iteration 12094 : model1 loss : 0.247903 model2 loss : 0.282142
[22:57:19.593] iteration 12095 : model1 loss : 0.164192 model2 loss : 0.145919
[22:57:19.920] iteration 12096 : model1 loss : 0.321883 model2 loss : 0.356473
[22:57:20.250] iteration 12097 : model1 loss : 0.277277 model2 loss : 0.352650
[22:57:20.576] iteration 12098 : model1 loss : 0.206343 model2 loss : 0.264181
[22:57:20.902] iteration 12099 : model1 loss : 0.345589 model2 loss : 0.269144
[22:57:21.228] iteration 12100 : model1 loss : 0.116416 model2 loss : 0.196919
[22:57:21.759] iteration 12101 : model1 loss : 0.199748 model2 loss : 0.181898
[22:57:22.085] iteration 12102 : model1 loss : 0.187585 model2 loss : 0.200701
[22:57:22.412] iteration 12103 : model1 loss : 0.144057 model2 loss : 0.153264
[22:57:22.739] iteration 12104 : model1 loss : 0.281434 model2 loss : 0.286644
[22:57:23.065] iteration 12105 : model1 loss : 0.205748 model2 loss : 0.192357
[22:57:23.392] iteration 12106 : model1 loss : 0.338961 model2 loss : 0.345544
[22:57:23.718] iteration 12107 : model1 loss : 0.111271 model2 loss : 0.285574
[22:57:24.045] iteration 12108 : model1 loss : 0.307044 model2 loss : 0.300912
[22:57:24.370] iteration 12109 : model1 loss : 0.252553 model2 loss : 0.261815
[22:57:24.696] iteration 12110 : model1 loss : 0.251929 model2 loss : 0.279855
[22:57:25.024] iteration 12111 : model1 loss : 0.187482 model2 loss : 0.168832
[22:57:25.352] iteration 12112 : model1 loss : 0.235496 model2 loss : 0.261348
[22:57:25.679] iteration 12113 : model1 loss : 0.281720 model2 loss : 0.287883
[22:57:26.006] iteration 12114 : model1 loss : 0.156855 model2 loss : 0.117560
[22:57:26.333] iteration 12115 : model1 loss : 0.249719 model2 loss : 0.280630
[22:57:26.663] iteration 12116 : model1 loss : 0.144662 model2 loss : 0.210920
[22:57:26.990] iteration 12117 : model1 loss : 0.195105 model2 loss : 0.244873
[22:57:27.317] iteration 12118 : model1 loss : 0.238674 model2 loss : 0.317030
[22:57:27.645] iteration 12119 : model1 loss : 0.130848 model2 loss : 0.165144
[22:57:27.972] iteration 12120 : model1 loss : 0.273525 model2 loss : 0.272809
[22:57:28.298] iteration 12121 : model1 loss : 0.158987 model2 loss : 0.170520
[22:57:28.626] iteration 12122 : model1 loss : 0.094712 model2 loss : 0.118140
[22:57:28.953] iteration 12123 : model1 loss : 0.272526 model2 loss : 0.310598
[22:57:29.280] iteration 12124 : model1 loss : 0.300764 model2 loss : 0.326043
[22:57:29.607] iteration 12125 : model1 loss : 0.221268 model2 loss : 0.216281
[22:57:29.934] iteration 12126 : model1 loss : 0.235864 model2 loss : 0.259731
[22:57:30.264] iteration 12127 : model1 loss : 0.349946 model2 loss : 0.361319
[22:57:30.591] iteration 12128 : model1 loss : 0.188383 model2 loss : 0.270143
[22:57:30.917] iteration 12129 : model1 loss : 0.275529 model2 loss : 0.311840
[22:57:31.244] iteration 12130 : model1 loss : 0.162439 model2 loss : 0.188373
[22:57:31.571] iteration 12131 : model1 loss : 0.243214 model2 loss : 0.280957
[22:57:31.897] iteration 12132 : model1 loss : 0.220021 model2 loss : 0.247001
[22:57:32.223] iteration 12133 : model1 loss : 0.194778 model2 loss : 0.191375
[22:57:32.550] iteration 12134 : model1 loss : 0.185730 model2 loss : 0.202416
[22:57:32.878] iteration 12135 : model1 loss : 0.204728 model2 loss : 0.232562
[22:57:33.206] iteration 12136 : model1 loss : 0.147532 model2 loss : 0.189905
[22:57:33.529] iteration 12137 : model1 loss : 0.309040 model2 loss : 0.346445
[22:57:33.851] iteration 12138 : model1 loss : 0.103891 model2 loss : 0.157115
[22:57:34.178] iteration 12139 : model1 loss : 0.110930 model2 loss : 0.146758
[22:57:34.506] iteration 12140 : model1 loss : 0.238396 model2 loss : 0.304549
[22:57:34.828] iteration 12141 : model1 loss : 0.255180 model2 loss : 0.275477
[22:57:35.154] iteration 12142 : model1 loss : 0.172484 model2 loss : 0.222954
[22:57:35.485] iteration 12143 : model1 loss : 0.185619 model2 loss : 0.170529
[22:57:35.813] iteration 12144 : model1 loss : 0.126243 model2 loss : 0.124780
[22:57:36.139] iteration 12145 : model1 loss : 0.120834 model2 loss : 0.121735
[22:57:36.469] iteration 12146 : model1 loss : 0.180906 model2 loss : 0.205602
[22:57:36.796] iteration 12147 : model1 loss : 0.298940 model2 loss : 0.296750
[22:57:37.124] iteration 12148 : model1 loss : 0.199113 model2 loss : 0.230994
[22:57:37.451] iteration 12149 : model1 loss : 0.171007 model2 loss : 0.275387
[22:57:37.779] iteration 12150 : model1 loss : 0.217760 model2 loss : 0.273161
[22:57:38.319] iteration 12151 : model1 loss : 0.254566 model2 loss : 0.293255
[22:57:38.645] iteration 12152 : model1 loss : 0.279152 model2 loss : 0.317994
[22:57:38.973] iteration 12153 : model1 loss : 0.150570 model2 loss : 0.195293
[22:57:39.300] iteration 12154 : model1 loss : 0.292195 model2 loss : 0.316304
[22:57:39.628] iteration 12155 : model1 loss : 0.219350 model2 loss : 0.198318
[22:57:39.955] iteration 12156 : model1 loss : 0.116559 model2 loss : 0.093557
[22:57:40.284] iteration 12157 : model1 loss : 0.203096 model2 loss : 0.235598
[22:57:40.612] iteration 12158 : model1 loss : 0.344354 model2 loss : 0.385188
[22:57:40.939] iteration 12159 : model1 loss : 0.273815 model2 loss : 0.292144
[22:57:41.267] iteration 12160 : model1 loss : 0.270501 model2 loss : 0.323027
[22:57:41.594] iteration 12161 : model1 loss : 0.255267 model2 loss : 0.282857
[22:57:41.922] iteration 12162 : model1 loss : 0.191251 model2 loss : 0.204206
[22:57:42.250] iteration 12163 : model1 loss : 0.097241 model2 loss : 0.160699
[22:57:42.577] iteration 12164 : model1 loss : 0.317561 model2 loss : 0.302530
[22:57:42.904] iteration 12165 : model1 loss : 0.169051 model2 loss : 0.199771
[22:57:43.231] iteration 12166 : model1 loss : 0.134143 model2 loss : 0.174351
[22:57:43.559] iteration 12167 : model1 loss : 0.198337 model2 loss : 0.252289
[22:57:43.886] iteration 12168 : model1 loss : 0.190652 model2 loss : 0.233585
[22:57:44.213] iteration 12169 : model1 loss : 0.125622 model2 loss : 0.168224
[22:57:44.540] iteration 12170 : model1 loss : 0.257540 model2 loss : 0.284525
[22:57:44.867] iteration 12171 : model1 loss : 0.215670 model2 loss : 0.213645
[22:57:45.194] iteration 12172 : model1 loss : 0.171408 model2 loss : 0.231066
[22:57:45.523] iteration 12173 : model1 loss : 0.234878 model2 loss : 0.252721
[22:57:45.850] iteration 12174 : model1 loss : 0.198312 model2 loss : 0.194101
[22:57:46.177] iteration 12175 : model1 loss : 0.090052 model2 loss : 0.173662
[22:57:46.504] iteration 12176 : model1 loss : 0.271545 model2 loss : 0.231530
[22:57:46.831] iteration 12177 : model1 loss : 0.266795 model2 loss : 0.259250
[22:57:47.159] iteration 12178 : model1 loss : 0.185997 model2 loss : 0.240284
[22:57:47.486] iteration 12179 : model1 loss : 0.174889 model2 loss : 0.296717
[22:57:47.813] iteration 12180 : model1 loss : 0.246400 model2 loss : 0.212273
[22:57:48.140] iteration 12181 : model1 loss : 0.179230 model2 loss : 0.228233
[22:57:48.469] iteration 12182 : model1 loss : 0.245394 model2 loss : 0.258670
[22:57:48.796] iteration 12183 : model1 loss : 0.205547 model2 loss : 0.199391
[22:57:49.124] iteration 12184 : model1 loss : 0.294903 model2 loss : 0.328665
[22:57:49.451] iteration 12185 : model1 loss : 0.339089 model2 loss : 0.336476
[22:57:49.778] iteration 12186 : model1 loss : 0.236028 model2 loss : 0.237672
[22:57:50.105] iteration 12187 : model1 loss : 0.218739 model2 loss : 0.229501
[22:57:50.433] iteration 12188 : model1 loss : 0.162335 model2 loss : 0.179984
[22:57:50.760] iteration 12189 : model1 loss : 0.209455 model2 loss : 0.226267
[22:57:51.087] iteration 12190 : model1 loss : 0.207471 model2 loss : 0.253862
[22:57:51.414] iteration 12191 : model1 loss : 0.128125 model2 loss : 0.170957
[22:57:51.742] iteration 12192 : model1 loss : 0.128389 model2 loss : 0.193798
[22:57:52.068] iteration 12193 : model1 loss : 0.165722 model2 loss : 0.185708
[22:57:52.396] iteration 12194 : model1 loss : 0.170791 model2 loss : 0.171197
[22:57:52.723] iteration 12195 : model1 loss : 0.202590 model2 loss : 0.269071
[22:57:53.052] iteration 12196 : model1 loss : 0.198806 model2 loss : 0.211380
[22:57:53.379] iteration 12197 : model1 loss : 0.205987 model2 loss : 0.211072
[22:57:53.708] iteration 12198 : model1 loss : 0.270238 model2 loss : 0.324442
[22:57:54.036] iteration 12199 : model1 loss : 0.207406 model2 loss : 0.205381
[22:57:54.365] iteration 12200 : model1 loss : 0.132008 model2 loss : 0.147469
[22:57:54.898] iteration 12201 : model1 loss : 0.179177 model2 loss : 0.186792
[22:57:55.226] iteration 12202 : model1 loss : 0.156882 model2 loss : 0.121520
[22:57:55.692] iteration 12203 : model1 loss : 0.350912 model2 loss : 0.349998
[22:57:56.019] iteration 12204 : model1 loss : 0.257540 model2 loss : 0.280117
[22:57:56.347] iteration 12205 : model1 loss : 0.298778 model2 loss : 0.348992
[22:57:56.674] iteration 12206 : model1 loss : 0.259453 model2 loss : 0.227342
[22:57:57.002] iteration 12207 : model1 loss : 0.188436 model2 loss : 0.214314
[22:57:57.330] iteration 12208 : model1 loss : 0.229750 model2 loss : 0.230788
[22:57:57.658] iteration 12209 : model1 loss : 0.272935 model2 loss : 0.298820
[22:57:57.986] iteration 12210 : model1 loss : 0.226299 model2 loss : 0.257346
[22:57:58.313] iteration 12211 : model1 loss : 0.319189 model2 loss : 0.311012
[22:57:58.640] iteration 12212 : model1 loss : 0.286511 model2 loss : 0.234099
[22:57:58.967] iteration 12213 : model1 loss : 0.210318 model2 loss : 0.246564
[22:57:59.294] iteration 12214 : model1 loss : 0.118345 model2 loss : 0.156168
[22:57:59.621] iteration 12215 : model1 loss : 0.257314 model2 loss : 0.276465
[22:57:59.950] iteration 12216 : model1 loss : 0.194846 model2 loss : 0.231488
[22:58:00.278] iteration 12217 : model1 loss : 0.206774 model2 loss : 0.235898
[22:58:00.606] iteration 12218 : model1 loss : 0.270281 model2 loss : 0.363724
[22:58:00.933] iteration 12219 : model1 loss : 0.236708 model2 loss : 0.244976
[22:58:01.261] iteration 12220 : model1 loss : 0.262253 model2 loss : 0.317736
[22:58:01.589] iteration 12221 : model1 loss : 0.077364 model2 loss : 0.198276
[22:58:01.917] iteration 12222 : model1 loss : 0.248200 model2 loss : 0.297160
[22:58:02.245] iteration 12223 : model1 loss : 0.113209 model2 loss : 0.169067
[22:58:02.571] iteration 12224 : model1 loss : 0.318921 model2 loss : 0.348681
[22:58:02.899] iteration 12225 : model1 loss : 0.207414 model2 loss : 0.253758
[22:58:03.227] iteration 12226 : model1 loss : 0.196952 model2 loss : 0.266913
[22:58:03.554] iteration 12227 : model1 loss : 0.279141 model2 loss : 0.275750
[22:58:03.882] iteration 12228 : model1 loss : 0.205087 model2 loss : 0.259207
[22:58:04.209] iteration 12229 : model1 loss : 0.241911 model2 loss : 0.253294
[22:58:04.536] iteration 12230 : model1 loss : 0.173777 model2 loss : 0.258129
[22:58:04.863] iteration 12231 : model1 loss : 0.158000 model2 loss : 0.180438
[22:58:05.191] iteration 12232 : model1 loss : 0.302940 model2 loss : 0.291582
[22:58:05.518] iteration 12233 : model1 loss : 0.203109 model2 loss : 0.211047
[22:58:05.845] iteration 12234 : model1 loss : 0.264918 model2 loss : 0.298038
[22:58:06.173] iteration 12235 : model1 loss : 0.160735 model2 loss : 0.179476
[22:58:06.501] iteration 12236 : model1 loss : 0.272082 model2 loss : 0.285048
[22:58:06.827] iteration 12237 : model1 loss : 0.312379 model2 loss : 0.356113
[22:58:07.155] iteration 12238 : model1 loss : 0.105039 model2 loss : 0.138595
[22:58:07.483] iteration 12239 : model1 loss : 0.188903 model2 loss : 0.224862
[22:58:07.810] iteration 12240 : model1 loss : 0.264725 model2 loss : 0.287607
[22:58:08.137] iteration 12241 : model1 loss : 0.267969 model2 loss : 0.229142
[22:58:08.464] iteration 12242 : model1 loss : 0.273262 model2 loss : 0.305871
[22:58:08.792] iteration 12243 : model1 loss : 0.283192 model2 loss : 0.280947
[22:58:09.119] iteration 12244 : model1 loss : 0.211794 model2 loss : 0.258637
[22:58:09.447] iteration 12245 : model1 loss : 0.197984 model2 loss : 0.220746
[22:58:09.774] iteration 12246 : model1 loss : 0.093243 model2 loss : 0.127786
[22:58:10.101] iteration 12247 : model1 loss : 0.210093 model2 loss : 0.241103
[22:58:10.429] iteration 12248 : model1 loss : 0.165954 model2 loss : 0.164839
[22:58:10.756] iteration 12249 : model1 loss : 0.204883 model2 loss : 0.205837
[22:58:11.083] iteration 12250 : model1 loss : 0.266921 model2 loss : 0.281174
[22:58:11.621] iteration 12251 : model1 loss : 0.256973 model2 loss : 0.264906
[22:58:11.951] iteration 12252 : model1 loss : 0.208866 model2 loss : 0.259643
[22:58:12.278] iteration 12253 : model1 loss : 0.231210 model2 loss : 0.239603
[22:58:12.605] iteration 12254 : model1 loss : 0.195402 model2 loss : 0.212175
[22:58:12.932] iteration 12255 : model1 loss : 0.203944 model2 loss : 0.233535
[22:58:13.259] iteration 12256 : model1 loss : 0.279166 model2 loss : 0.288115
[22:58:13.587] iteration 12257 : model1 loss : 0.297104 model2 loss : 0.305821
[22:58:13.914] iteration 12258 : model1 loss : 0.141884 model2 loss : 0.169430
[22:58:14.243] iteration 12259 : model1 loss : 0.251626 model2 loss : 0.301546
[22:58:14.570] iteration 12260 : model1 loss : 0.088273 model2 loss : 0.201374
[22:58:14.898] iteration 12261 : model1 loss : 0.302003 model2 loss : 0.322335
[22:58:15.225] iteration 12262 : model1 loss : 0.143724 model2 loss : 0.161203
[22:58:15.552] iteration 12263 : model1 loss : 0.225718 model2 loss : 0.245961
[22:58:15.880] iteration 12264 : model1 loss : 0.258990 model2 loss : 0.311552
[22:58:16.207] iteration 12265 : model1 loss : 0.242910 model2 loss : 0.258169
[22:58:16.534] iteration 12266 : model1 loss : 0.322939 model2 loss : 0.323042
[22:58:16.862] iteration 12267 : model1 loss : 0.206316 model2 loss : 0.257804
[22:58:17.191] iteration 12268 : model1 loss : 0.317271 model2 loss : 0.299851
[22:58:17.518] iteration 12269 : model1 loss : 0.249467 model2 loss : 0.271144
[22:58:17.845] iteration 12270 : model1 loss : 0.171398 model2 loss : 0.181271
[22:58:18.172] iteration 12271 : model1 loss : 0.262746 model2 loss : 0.256012
[22:58:18.500] iteration 12272 : model1 loss : 0.183605 model2 loss : 0.204832
[22:58:18.828] iteration 12273 : model1 loss : 0.219111 model2 loss : 0.248499
[22:58:19.156] iteration 12274 : model1 loss : 0.275973 model2 loss : 0.318098
[22:58:19.483] iteration 12275 : model1 loss : 0.223194 model2 loss : 0.200529
[22:58:19.811] iteration 12276 : model1 loss : 0.309903 model2 loss : 0.337206
[22:58:20.138] iteration 12277 : model1 loss : 0.286274 model2 loss : 0.296281
[22:58:20.465] iteration 12278 : model1 loss : 0.172164 model2 loss : 0.170511
[22:58:20.793] iteration 12279 : model1 loss : 0.214903 model2 loss : 0.215632
[22:58:21.121] iteration 12280 : model1 loss : 0.285629 model2 loss : 0.309350
[22:58:21.448] iteration 12281 : model1 loss : 0.225070 model2 loss : 0.260650
[22:58:21.776] iteration 12282 : model1 loss : 0.218301 model2 loss : 0.245866
[22:58:22.104] iteration 12283 : model1 loss : 0.207584 model2 loss : 0.233300
[22:58:22.431] iteration 12284 : model1 loss : 0.258893 model2 loss : 0.274616
[22:58:22.758] iteration 12285 : model1 loss : 0.174167 model2 loss : 0.226162
[22:58:23.086] iteration 12286 : model1 loss : 0.329897 model2 loss : 0.343205
[22:58:23.413] iteration 12287 : model1 loss : 0.162009 model2 loss : 0.144821
[22:58:23.741] iteration 12288 : model1 loss : 0.309689 model2 loss : 0.328918
[22:58:24.068] iteration 12289 : model1 loss : 0.304623 model2 loss : 0.282788
[22:58:24.395] iteration 12290 : model1 loss : 0.186354 model2 loss : 0.258393
[22:58:24.722] iteration 12291 : model1 loss : 0.105431 model2 loss : 0.142003
[22:58:25.050] iteration 12292 : model1 loss : 0.194993 model2 loss : 0.270503
[22:58:25.377] iteration 12293 : model1 loss : 0.220130 model2 loss : 0.304809
[22:58:25.704] iteration 12294 : model1 loss : 0.265189 model2 loss : 0.309834
[22:58:26.031] iteration 12295 : model1 loss : 0.226831 model2 loss : 0.234241
[22:58:26.359] iteration 12296 : model1 loss : 0.290354 model2 loss : 0.257856
[22:58:26.687] iteration 12297 : model1 loss : 0.231877 model2 loss : 0.208346
[22:58:27.014] iteration 12298 : model1 loss : 0.130281 model2 loss : 0.141104
[22:58:27.342] iteration 12299 : model1 loss : 0.291315 model2 loss : 0.335265
[22:58:27.668] iteration 12300 : model1 loss : 0.337413 model2 loss : 0.373081
[22:58:28.201] iteration 12301 : model1 loss : 0.270635 model2 loss : 0.280793
[22:58:28.528] iteration 12302 : model1 loss : 0.259106 model2 loss : 0.305392
[22:58:28.856] iteration 12303 : model1 loss : 0.236880 model2 loss : 0.284152
[22:58:29.183] iteration 12304 : model1 loss : 0.290593 model2 loss : 0.298225
[22:58:29.511] iteration 12305 : model1 loss : 0.183822 model2 loss : 0.227389
[22:58:29.838] iteration 12306 : model1 loss : 0.276868 model2 loss : 0.281676
[22:58:30.164] iteration 12307 : model1 loss : 0.362607 model2 loss : 0.360472
[22:58:30.492] iteration 12308 : model1 loss : 0.239151 model2 loss : 0.287571
[22:58:30.818] iteration 12309 : model1 loss : 0.104651 model2 loss : 0.101980
[22:58:31.145] iteration 12310 : model1 loss : 0.197429 model2 loss : 0.181835
[22:58:31.471] iteration 12311 : model1 loss : 0.287983 model2 loss : 0.323143
[22:58:31.801] iteration 12312 : model1 loss : 0.209392 model2 loss : 0.219870
[22:58:32.128] iteration 12313 : model1 loss : 0.475165 model2 loss : 0.322969
[22:58:32.456] iteration 12314 : model1 loss : 0.199761 model2 loss : 0.251948
[22:58:32.784] iteration 12315 : model1 loss : 0.234079 model2 loss : 0.208667
[22:58:33.111] iteration 12316 : model1 loss : 0.166640 model2 loss : 0.180411
[22:58:33.438] iteration 12317 : model1 loss : 0.164617 model2 loss : 0.247962
[22:58:33.766] iteration 12318 : model1 loss : 0.388876 model2 loss : 0.385335
[22:58:34.093] iteration 12319 : model1 loss : 0.226552 model2 loss : 0.221182
[22:58:34.421] iteration 12320 : model1 loss : 0.297082 model2 loss : 0.307218
[22:58:34.748] iteration 12321 : model1 loss : 0.094556 model2 loss : 0.240627
[22:58:35.074] iteration 12322 : model1 loss : 0.087030 model2 loss : 0.111659
[22:58:35.404] iteration 12323 : model1 loss : 0.183163 model2 loss : 0.201064
[22:58:35.732] iteration 12324 : model1 loss : 0.184775 model2 loss : 0.196000
[22:58:36.059] iteration 12325 : model1 loss : 0.118352 model2 loss : 0.202702
[22:58:36.386] iteration 12326 : model1 loss : 0.211894 model2 loss : 0.295630
[22:58:36.715] iteration 12327 : model1 loss : 0.247954 model2 loss : 0.287010
[22:58:37.042] iteration 12328 : model1 loss : 0.197441 model2 loss : 0.170403
[22:58:37.369] iteration 12329 : model1 loss : 0.195746 model2 loss : 0.237008
[22:58:37.697] iteration 12330 : model1 loss : 0.161641 model2 loss : 0.228254
[22:58:38.024] iteration 12331 : model1 loss : 0.157755 model2 loss : 0.191126
[22:58:38.352] iteration 12332 : model1 loss : 0.101195 model2 loss : 0.117751
[22:58:38.678] iteration 12333 : model1 loss : 0.226524 model2 loss : 0.266112
[22:58:39.005] iteration 12334 : model1 loss : 0.236319 model2 loss : 0.295238
[22:58:39.333] iteration 12335 : model1 loss : 0.196794 model2 loss : 0.217072
[22:58:39.660] iteration 12336 : model1 loss : 0.265360 model2 loss : 0.350658
[22:58:39.987] iteration 12337 : model1 loss : 0.173784 model2 loss : 0.179417
[22:58:40.315] iteration 12338 : model1 loss : 0.228046 model2 loss : 0.264421
[22:58:40.642] iteration 12339 : model1 loss : 0.095732 model2 loss : 0.152581
[22:58:40.970] iteration 12340 : model1 loss : 0.195196 model2 loss : 0.200258
[22:58:41.298] iteration 12341 : model1 loss : 0.115173 model2 loss : 0.161756
[22:58:41.625] iteration 12342 : model1 loss : 0.128735 model2 loss : 0.136664
[22:58:41.952] iteration 12343 : model1 loss : 0.187420 model2 loss : 0.172869
[22:58:42.281] iteration 12344 : model1 loss : 0.175262 model2 loss : 0.221858
[22:58:42.608] iteration 12345 : model1 loss : 0.247891 model2 loss : 0.242900
[22:58:42.935] iteration 12346 : model1 loss : 0.196611 model2 loss : 0.184695
[22:58:43.263] iteration 12347 : model1 loss : 0.297206 model2 loss : 0.344017
[22:58:43.590] iteration 12348 : model1 loss : 0.197548 model2 loss : 0.213105
[22:58:43.919] iteration 12349 : model1 loss : 0.281265 model2 loss : 0.263810
[22:58:44.246] iteration 12350 : model1 loss : 0.103375 model2 loss : 0.161577
[22:58:44.762] iteration 12351 : model1 loss : 0.174250 model2 loss : 0.207521
[22:58:45.090] iteration 12352 : model1 loss : 0.292665 model2 loss : 0.315204
[22:58:45.418] iteration 12353 : model1 loss : 0.282688 model2 loss : 0.291137
[22:58:45.745] iteration 12354 : model1 loss : 0.227410 model2 loss : 0.273141
[22:58:46.072] iteration 12355 : model1 loss : 0.348415 model2 loss : 0.358900
[22:58:46.400] iteration 12356 : model1 loss : 0.271935 model2 loss : 0.291063
[22:58:46.728] iteration 12357 : model1 loss : 0.286184 model2 loss : 0.332877
[22:58:47.055] iteration 12358 : model1 loss : 0.193197 model2 loss : 0.140911
[22:58:47.383] iteration 12359 : model1 loss : 0.281424 model2 loss : 0.264473
[22:58:47.710] iteration 12360 : model1 loss : 0.252898 model2 loss : 0.273816
[22:58:48.038] iteration 12361 : model1 loss : 0.175844 model2 loss : 0.189530
[22:58:48.364] iteration 12362 : model1 loss : 0.210410 model2 loss : 0.199312
[22:58:48.693] iteration 12363 : model1 loss : 0.138973 model2 loss : 0.125572
[22:58:49.020] iteration 12364 : model1 loss : 0.182736 model2 loss : 0.182741
[22:58:49.347] iteration 12365 : model1 loss : 0.173256 model2 loss : 0.193874
[22:58:49.675] iteration 12366 : model1 loss : 0.217807 model2 loss : 0.306265
[22:58:50.003] iteration 12367 : model1 loss : 0.183194 model2 loss : 0.186550
[22:58:50.331] iteration 12368 : model1 loss : 0.160173 model2 loss : 0.235143
[22:58:50.658] iteration 12369 : model1 loss : 0.162254 model2 loss : 0.154760
[22:58:50.985] iteration 12370 : model1 loss : 0.112605 model2 loss : 0.168765
[22:58:51.314] iteration 12371 : model1 loss : 0.168791 model2 loss : 0.183841
[22:58:51.642] iteration 12372 : model1 loss : 0.317721 model2 loss : 0.251456
[22:58:51.970] iteration 12373 : model1 loss : 0.184853 model2 loss : 0.271918
[22:58:52.297] iteration 12374 : model1 loss : 0.192036 model2 loss : 0.193456
[22:58:52.626] iteration 12375 : model1 loss : 0.187767 model2 loss : 0.280028
[22:58:52.954] iteration 12376 : model1 loss : 0.240364 model2 loss : 0.292929
[22:58:53.282] iteration 12377 : model1 loss : 0.290210 model2 loss : 0.310769
[22:58:53.609] iteration 12378 : model1 loss : 0.250530 model2 loss : 0.291544
[22:58:53.938] iteration 12379 : model1 loss : 0.183271 model2 loss : 0.193132
[22:58:54.265] iteration 12380 : model1 loss : 0.264205 model2 loss : 0.279432
[22:58:54.593] iteration 12381 : model1 loss : 0.140069 model2 loss : 0.167325
[22:58:54.921] iteration 12382 : model1 loss : 0.180340 model2 loss : 0.290961
[22:58:55.250] iteration 12383 : model1 loss : 0.195777 model2 loss : 0.217246
[22:58:55.577] iteration 12384 : model1 loss : 0.130792 model2 loss : 0.147866
[22:58:55.905] iteration 12385 : model1 loss : 0.240771 model2 loss : 0.344266
[22:58:56.234] iteration 12386 : model1 loss : 0.205608 model2 loss : 0.255065
[22:58:56.565] iteration 12387 : model1 loss : 0.180285 model2 loss : 0.203570
[22:58:56.898] iteration 12388 : model1 loss : 0.257032 model2 loss : 0.297782
[22:58:57.232] iteration 12389 : model1 loss : 0.270214 model2 loss : 0.275470
[22:58:57.562] iteration 12390 : model1 loss : 0.247693 model2 loss : 0.227014
[22:58:57.895] iteration 12391 : model1 loss : 0.275706 model2 loss : 0.290558
[22:58:58.227] iteration 12392 : model1 loss : 0.231834 model2 loss : 0.244494
[22:58:58.560] iteration 12393 : model1 loss : 0.262476 model2 loss : 0.288619
[22:58:58.887] iteration 12394 : model1 loss : 0.320576 model2 loss : 0.413261
[22:58:59.215] iteration 12395 : model1 loss : 0.230982 model2 loss : 0.325257
[22:58:59.543] iteration 12396 : model1 loss : 0.302956 model2 loss : 0.330863
[22:58:59.871] iteration 12397 : model1 loss : 0.284499 model2 loss : 0.252609
[22:59:00.205] iteration 12398 : model1 loss : 0.279792 model2 loss : 0.223990
[22:59:00.540] iteration 12399 : model1 loss : 0.248070 model2 loss : 0.203876
[22:59:00.871] iteration 12400 : model1 loss : 0.235426 model2 loss : 0.185796
[22:59:01.438] iteration 12401 : model1 loss : 0.265462 model2 loss : 0.285499
[22:59:01.770] iteration 12402 : model1 loss : 0.215888 model2 loss : 0.172421
[22:59:02.105] iteration 12403 : model1 loss : 0.092053 model2 loss : 0.183913
[22:59:02.438] iteration 12404 : model1 loss : 0.176620 model2 loss : 0.237949
[22:59:02.768] iteration 12405 : model1 loss : 0.249111 model2 loss : 0.239341
[22:59:03.098] iteration 12406 : model1 loss : 0.152083 model2 loss : 0.157172
[22:59:03.428] iteration 12407 : model1 loss : 0.278745 model2 loss : 0.333384
[22:59:03.758] iteration 12408 : model1 loss : 0.259115 model2 loss : 0.272773
[22:59:04.089] iteration 12409 : model1 loss : 0.238297 model2 loss : 0.339683
[22:59:04.419] iteration 12410 : model1 loss : 0.156760 model2 loss : 0.150733
[22:59:04.747] iteration 12411 : model1 loss : 0.228975 model2 loss : 0.267801
[22:59:05.087] iteration 12412 : model1 loss : 0.139466 model2 loss : 0.129071
[22:59:05.428] iteration 12413 : model1 loss : 0.176509 model2 loss : 0.280561
[22:59:05.768] iteration 12414 : model1 loss : 0.223194 model2 loss : 0.312779
[22:59:06.111] iteration 12415 : model1 loss : 0.191376 model2 loss : 0.288590
[22:59:06.448] iteration 12416 : model1 loss : 0.277501 model2 loss : 0.294192
[22:59:06.778] iteration 12417 : model1 loss : 0.130111 model2 loss : 0.136836
[22:59:07.107] iteration 12418 : model1 loss : 0.162947 model2 loss : 0.156753
[22:59:07.438] iteration 12419 : model1 loss : 0.321479 model2 loss : 0.323134
[22:59:07.783] iteration 12420 : model1 loss : 0.168599 model2 loss : 0.285161
[22:59:08.123] iteration 12421 : model1 loss : 0.211599 model2 loss : 0.243700
[22:59:08.468] iteration 12422 : model1 loss : 0.207977 model2 loss : 0.256967
[22:59:08.837] iteration 12423 : model1 loss : 0.326083 model2 loss : 0.328567
[22:59:09.176] iteration 12424 : model1 loss : 0.172450 model2 loss : 0.243351
[22:59:09.510] iteration 12425 : model1 loss : 0.177513 model2 loss : 0.225032
[22:59:09.848] iteration 12426 : model1 loss : 0.168757 model2 loss : 0.206207
[22:59:10.189] iteration 12427 : model1 loss : 0.310048 model2 loss : 0.323136
[22:59:10.527] iteration 12428 : model1 loss : 0.214772 model2 loss : 0.180904
[22:59:10.870] iteration 12429 : model1 loss : 0.294286 model2 loss : 0.330341
[22:59:11.210] iteration 12430 : model1 loss : 0.174574 model2 loss : 0.216231
[22:59:11.549] iteration 12431 : model1 loss : 0.205079 model2 loss : 0.286208
[22:59:11.900] iteration 12432 : model1 loss : 0.290263 model2 loss : 0.283064
[22:59:12.239] iteration 12433 : model1 loss : 0.262493 model2 loss : 0.199279
[22:59:12.579] iteration 12434 : model1 loss : 0.141743 model2 loss : 0.188064
[22:59:12.921] iteration 12435 : model1 loss : 0.247638 model2 loss : 0.289098
[22:59:13.258] iteration 12436 : model1 loss : 0.113471 model2 loss : 0.258645
[22:59:13.597] iteration 12437 : model1 loss : 0.275296 model2 loss : 0.326764
[22:59:13.938] iteration 12438 : model1 loss : 0.162730 model2 loss : 0.135999
[22:59:14.279] iteration 12439 : model1 loss : 0.185347 model2 loss : 0.241533
[22:59:14.620] iteration 12440 : model1 loss : 0.204175 model2 loss : 0.262981
[22:59:14.960] iteration 12441 : model1 loss : 0.193389 model2 loss : 0.189730
[22:59:15.299] iteration 12442 : model1 loss : 0.239219 model2 loss : 0.231615
[22:59:15.638] iteration 12443 : model1 loss : 0.260910 model2 loss : 0.284673
[22:59:15.982] iteration 12444 : model1 loss : 0.266096 model2 loss : 0.276449
[22:59:16.321] iteration 12445 : model1 loss : 0.287448 model2 loss : 0.329449
[22:59:16.659] iteration 12446 : model1 loss : 0.340869 model2 loss : 0.280703
[22:59:16.998] iteration 12447 : model1 loss : 0.304686 model2 loss : 0.299824
[22:59:17.327] iteration 12448 : model1 loss : 0.184024 model2 loss : 0.267377
[22:59:17.655] iteration 12449 : model1 loss : 0.261690 model2 loss : 0.284499
[22:59:17.984] iteration 12450 : model1 loss : 0.215521 model2 loss : 0.252984
[22:59:18.544] iteration 12451 : model1 loss : 0.147632 model2 loss : 0.123738
[22:59:18.874] iteration 12452 : model1 loss : 0.222711 model2 loss : 0.283594
[22:59:19.202] iteration 12453 : model1 loss : 0.325677 model2 loss : 0.325093
[22:59:19.532] iteration 12454 : model1 loss : 0.268605 model2 loss : 0.329253
[22:59:19.860] iteration 12455 : model1 loss : 0.335013 model2 loss : 0.360999
[22:59:20.189] iteration 12456 : model1 loss : 0.188427 model2 loss : 0.191483
[22:59:20.518] iteration 12457 : model1 loss : 0.215162 model2 loss : 0.278599
[22:59:20.846] iteration 12458 : model1 loss : 0.175179 model2 loss : 0.235947
[22:59:21.175] iteration 12459 : model1 loss : 0.247584 model2 loss : 0.302890
[22:59:21.505] iteration 12460 : model1 loss : 0.207104 model2 loss : 0.255655
[22:59:21.834] iteration 12461 : model1 loss : 0.211703 model2 loss : 0.288155
[22:59:22.177] iteration 12462 : model1 loss : 0.116486 model2 loss : 0.128115
[22:59:22.505] iteration 12463 : model1 loss : 0.245758 model2 loss : 0.255789
[22:59:22.834] iteration 12464 : model1 loss : 0.213539 model2 loss : 0.232523
[22:59:23.162] iteration 12465 : model1 loss : 0.192067 model2 loss : 0.217805
[22:59:23.490] iteration 12466 : model1 loss : 0.201513 model2 loss : 0.225741
[22:59:23.820] iteration 12467 : model1 loss : 0.253703 model2 loss : 0.263429
[22:59:24.149] iteration 12468 : model1 loss : 0.197667 model2 loss : 0.263836
[22:59:24.477] iteration 12469 : model1 loss : 0.274131 model2 loss : 0.311463
[22:59:24.808] iteration 12470 : model1 loss : 0.315695 model2 loss : 0.305130
[22:59:25.137] iteration 12471 : model1 loss : 0.230436 model2 loss : 0.277740
[22:59:25.467] iteration 12472 : model1 loss : 0.169265 model2 loss : 0.205524
[22:59:25.794] iteration 12473 : model1 loss : 0.119102 model2 loss : 0.160307
[22:59:26.123] iteration 12474 : model1 loss : 0.313612 model2 loss : 0.316087
[22:59:26.452] iteration 12475 : model1 loss : 0.169211 model2 loss : 0.199957
[22:59:26.781] iteration 12476 : model1 loss : 0.322835 model2 loss : 0.393117
[22:59:27.117] iteration 12477 : model1 loss : 0.278235 model2 loss : 0.319934
[22:59:27.455] iteration 12478 : model1 loss : 0.160370 model2 loss : 0.195015
[22:59:27.783] iteration 12479 : model1 loss : 0.118086 model2 loss : 0.144873
[22:59:28.125] iteration 12480 : model1 loss : 0.227453 model2 loss : 0.233603
[22:59:28.466] iteration 12481 : model1 loss : 0.253365 model2 loss : 0.302007
[22:59:28.811] iteration 12482 : model1 loss : 0.279795 model2 loss : 0.293169
[22:59:29.162] iteration 12483 : model1 loss : 0.161691 model2 loss : 0.139355
[22:59:29.499] iteration 12484 : model1 loss : 0.195441 model2 loss : 0.229557
[22:59:29.834] iteration 12485 : model1 loss : 0.236758 model2 loss : 0.251532
[22:59:30.172] iteration 12486 : model1 loss : 0.296911 model2 loss : 0.296730
[22:59:30.511] iteration 12487 : model1 loss : 0.193504 model2 loss : 0.272702
[22:59:30.851] iteration 12488 : model1 loss : 0.235336 model2 loss : 0.256722
[22:59:31.191] iteration 12489 : model1 loss : 0.083154 model2 loss : 0.158519
[22:59:31.528] iteration 12490 : model1 loss : 0.320105 model2 loss : 0.354726
[22:59:31.867] iteration 12491 : model1 loss : 0.260801 model2 loss : 0.289015
[22:59:32.207] iteration 12492 : model1 loss : 0.187085 model2 loss : 0.227949
[22:59:32.546] iteration 12493 : model1 loss : 0.330861 model2 loss : 0.350920
[22:59:32.880] iteration 12494 : model1 loss : 0.193604 model2 loss : 0.243230
[22:59:33.223] iteration 12495 : model1 loss : 0.176498 model2 loss : 0.204943
[22:59:33.560] iteration 12496 : model1 loss : 0.194967 model2 loss : 0.281824
[22:59:33.895] iteration 12497 : model1 loss : 0.186581 model2 loss : 0.201253
[22:59:34.234] iteration 12498 : model1 loss : 0.203544 model2 loss : 0.256866
[22:59:34.570] iteration 12499 : model1 loss : 0.198797 model2 loss : 0.226377
[22:59:34.904] iteration 12500 : model1 loss : 0.254903 model2 loss : 0.276830
[22:59:35.547] iteration 12501 : model1 loss : 0.186948 model2 loss : 0.218951
[22:59:35.885] iteration 12502 : model1 loss : 0.296379 model2 loss : 0.332630
[22:59:36.223] iteration 12503 : model1 loss : 0.113850 model2 loss : 0.203716
[22:59:36.560] iteration 12504 : model1 loss : 0.342624 model2 loss : 0.345272
[22:59:36.893] iteration 12505 : model1 loss : 0.112121 model2 loss : 0.210249
[22:59:37.231] iteration 12506 : model1 loss : 0.195855 model2 loss : 0.219961
[22:59:37.571] iteration 12507 : model1 loss : 0.245290 model2 loss : 0.223272
[22:59:37.905] iteration 12508 : model1 loss : 0.251778 model2 loss : 0.227156
[22:59:38.242] iteration 12509 : model1 loss : 0.171284 model2 loss : 0.232376
[22:59:38.579] iteration 12510 : model1 loss : 0.169820 model2 loss : 0.217670
[22:59:38.914] iteration 12511 : model1 loss : 0.229276 model2 loss : 0.227168
[22:59:39.251] iteration 12512 : model1 loss : 0.228104 model2 loss : 0.293318
[22:59:39.586] iteration 12513 : model1 loss : 0.222302 model2 loss : 0.272005
[22:59:39.925] iteration 12514 : model1 loss : 0.229434 model2 loss : 0.242333
[22:59:40.261] iteration 12515 : model1 loss : 0.179913 model2 loss : 0.169924
[22:59:40.598] iteration 12516 : model1 loss : 0.189938 model2 loss : 0.188726
[22:59:40.936] iteration 12517 : model1 loss : 0.256064 model2 loss : 0.275976
[22:59:41.277] iteration 12518 : model1 loss : 0.280775 model2 loss : 0.332185
[22:59:41.614] iteration 12519 : model1 loss : 0.299065 model2 loss : 0.313175
[22:59:41.949] iteration 12520 : model1 loss : 0.287607 model2 loss : 0.302997
[22:59:42.286] iteration 12521 : model1 loss : 0.159728 model2 loss : 0.120689
[22:59:42.625] iteration 12522 : model1 loss : 0.229494 model2 loss : 0.270310
[22:59:42.959] iteration 12523 : model1 loss : 0.175221 model2 loss : 0.200187
[22:59:43.297] iteration 12524 : model1 loss : 0.233965 model2 loss : 0.237086
[22:59:43.637] iteration 12525 : model1 loss : 0.167825 model2 loss : 0.174554
[22:59:43.978] iteration 12526 : model1 loss : 0.148544 model2 loss : 0.195035
[22:59:44.316] iteration 12527 : model1 loss : 0.109383 model2 loss : 0.109508
[22:59:44.654] iteration 12528 : model1 loss : 0.174953 model2 loss : 0.191616
[22:59:44.989] iteration 12529 : model1 loss : 0.358064 model2 loss : 0.422698
[22:59:45.329] iteration 12530 : model1 loss : 0.121078 model2 loss : 0.169070
[22:59:45.665] iteration 12531 : model1 loss : 0.242968 model2 loss : 0.273412
[22:59:46.000] iteration 12532 : model1 loss : 0.121826 model2 loss : 0.209747
[22:59:46.338] iteration 12533 : model1 loss : 0.196087 model2 loss : 0.264896
[22:59:46.675] iteration 12534 : model1 loss : 0.255563 model2 loss : 0.273769
[22:59:47.007] iteration 12535 : model1 loss : 0.256649 model2 loss : 0.277790
[22:59:48.097] iteration 12536 : model1 loss : 0.123972 model2 loss : 0.151401
[22:59:48.434] iteration 12537 : model1 loss : 0.202445 model2 loss : 0.232603
[22:59:48.774] iteration 12538 : model1 loss : 0.257056 model2 loss : 0.354436
[22:59:49.111] iteration 12539 : model1 loss : 0.179971 model2 loss : 0.244267
[22:59:49.447] iteration 12540 : model1 loss : 0.198720 model2 loss : 0.252807
[22:59:49.782] iteration 12541 : model1 loss : 0.167801 model2 loss : 0.244004
[22:59:50.123] iteration 12542 : model1 loss : 0.134315 model2 loss : 0.224658
[22:59:50.464] iteration 12543 : model1 loss : 0.266113 model2 loss : 0.323070
[22:59:50.799] iteration 12544 : model1 loss : 0.221975 model2 loss : 0.219082
[22:59:51.139] iteration 12545 : model1 loss : 0.266777 model2 loss : 0.298012
[22:59:51.476] iteration 12546 : model1 loss : 0.311404 model2 loss : 0.334620
[22:59:51.811] iteration 12547 : model1 loss : 0.204943 model2 loss : 0.230566
[22:59:52.147] iteration 12548 : model1 loss : 0.268649 model2 loss : 0.278783
[22:59:52.483] iteration 12549 : model1 loss : 0.317381 model2 loss : 0.287950
[22:59:52.817] iteration 12550 : model1 loss : 0.204179 model2 loss : 0.244146
[22:59:53.476] iteration 12551 : model1 loss : 0.353105 model2 loss : 0.338898
[22:59:53.810] iteration 12552 : model1 loss : 0.193689 model2 loss : 0.234551
[22:59:54.147] iteration 12553 : model1 loss : 0.216004 model2 loss : 0.267747
[22:59:54.486] iteration 12554 : model1 loss : 0.206645 model2 loss : 0.242724
[22:59:54.825] iteration 12555 : model1 loss : 0.293379 model2 loss : 0.279095
[22:59:55.161] iteration 12556 : model1 loss : 0.118030 model2 loss : 0.159083
[22:59:55.501] iteration 12557 : model1 loss : 0.338350 model2 loss : 0.398879
[22:59:55.835] iteration 12558 : model1 loss : 0.274451 model2 loss : 0.284041
[22:59:56.172] iteration 12559 : model1 loss : 0.297769 model2 loss : 0.306056
[22:59:56.509] iteration 12560 : model1 loss : 0.126734 model2 loss : 0.108487
[22:59:56.843] iteration 12561 : model1 loss : 0.221892 model2 loss : 0.254815
[22:59:57.179] iteration 12562 : model1 loss : 0.195443 model2 loss : 0.221142
[22:59:57.517] iteration 12563 : model1 loss : 0.195838 model2 loss : 0.228814
[22:59:57.852] iteration 12564 : model1 loss : 0.372901 model2 loss : 0.397306
[22:59:58.189] iteration 12565 : model1 loss : 0.264284 model2 loss : 0.272998
[22:59:58.535] iteration 12566 : model1 loss : 0.180718 model2 loss : 0.205277
[22:59:58.870] iteration 12567 : model1 loss : 0.316492 model2 loss : 0.298006
[22:59:59.206] iteration 12568 : model1 loss : 0.276937 model2 loss : 0.267732
[22:59:59.544] iteration 12569 : model1 loss : 0.201317 model2 loss : 0.259640
[22:59:59.878] iteration 12570 : model1 loss : 0.179984 model2 loss : 0.226118
[23:00:00.218] iteration 12571 : model1 loss : 0.333183 model2 loss : 0.326088
[23:00:00.557] iteration 12572 : model1 loss : 0.303811 model2 loss : 0.368456
[23:00:00.891] iteration 12573 : model1 loss : 0.113417 model2 loss : 0.204276
[23:00:01.229] iteration 12574 : model1 loss : 0.181968 model2 loss : 0.194558
[23:00:01.566] iteration 12575 : model1 loss : 0.204918 model2 loss : 0.210901
[23:00:01.900] iteration 12576 : model1 loss : 0.140842 model2 loss : 0.222796
[23:00:02.238] iteration 12577 : model1 loss : 0.198753 model2 loss : 0.226968
[23:00:02.574] iteration 12578 : model1 loss : 0.326872 model2 loss : 0.380620
[23:00:02.908] iteration 12579 : model1 loss : 0.272775 model2 loss : 0.288408
[23:00:03.245] iteration 12580 : model1 loss : 0.260526 model2 loss : 0.274856
[23:00:03.581] iteration 12581 : model1 loss : 0.170723 model2 loss : 0.246365
[23:00:03.921] iteration 12582 : model1 loss : 0.200434 model2 loss : 0.243254
[23:00:04.257] iteration 12583 : model1 loss : 0.230623 model2 loss : 0.254304
[23:00:04.595] iteration 12584 : model1 loss : 0.259770 model2 loss : 0.231072
[23:00:04.930] iteration 12585 : model1 loss : 0.262521 model2 loss : 0.261442
[23:00:05.269] iteration 12586 : model1 loss : 0.221119 model2 loss : 0.210917
[23:00:05.607] iteration 12587 : model1 loss : 0.122334 model2 loss : 0.165990
[23:00:05.945] iteration 12588 : model1 loss : 0.188071 model2 loss : 0.185674
[23:00:06.285] iteration 12589 : model1 loss : 0.155089 model2 loss : 0.160028
[23:00:06.622] iteration 12590 : model1 loss : 0.274072 model2 loss : 0.354002
[23:00:06.956] iteration 12591 : model1 loss : 0.284060 model2 loss : 0.338043
[23:00:07.297] iteration 12592 : model1 loss : 0.252828 model2 loss : 0.306995
[23:00:07.634] iteration 12593 : model1 loss : 0.253054 model2 loss : 0.278075
[23:00:07.971] iteration 12594 : model1 loss : 0.207287 model2 loss : 0.264815
[23:00:08.310] iteration 12595 : model1 loss : 0.296267 model2 loss : 0.277556
[23:00:08.648] iteration 12596 : model1 loss : 0.230658 model2 loss : 0.285472
[23:00:08.983] iteration 12597 : model1 loss : 0.255153 model2 loss : 0.276342
[23:00:09.321] iteration 12598 : model1 loss : 0.187128 model2 loss : 0.261081
[23:00:09.659] iteration 12599 : model1 loss : 0.207062 model2 loss : 0.247564
[23:00:09.994] iteration 12600 : model1 loss : 0.259574 model2 loss : 0.276740
[23:00:10.627] iteration 12601 : model1 loss : 0.245368 model2 loss : 0.263365
[23:00:10.962] iteration 12602 : model1 loss : 0.175073 model2 loss : 0.259990
[23:00:11.301] iteration 12603 : model1 loss : 0.244454 model2 loss : 0.335833
[23:00:11.639] iteration 12604 : model1 loss : 0.205682 model2 loss : 0.221552
[23:00:11.973] iteration 12605 : model1 loss : 0.132041 model2 loss : 0.177882
[23:00:12.310] iteration 12606 : model1 loss : 0.174173 model2 loss : 0.165464
[23:00:12.652] iteration 12607 : model1 loss : 0.329134 model2 loss : 0.355550
[23:00:12.987] iteration 12608 : model1 loss : 0.255817 model2 loss : 0.312643
[23:00:13.329] iteration 12609 : model1 loss : 0.246632 model2 loss : 0.288681
[23:00:13.667] iteration 12610 : model1 loss : 0.220795 model2 loss : 0.245249
[23:00:14.008] iteration 12611 : model1 loss : 0.268858 model2 loss : 0.285701
[23:00:14.352] iteration 12612 : model1 loss : 0.334788 model2 loss : 0.327201
[23:00:14.689] iteration 12613 : model1 loss : 0.239284 model2 loss : 0.212049
[23:00:15.030] iteration 12614 : model1 loss : 0.186753 model2 loss : 0.220266
[23:00:15.370] iteration 12615 : model1 loss : 0.322209 model2 loss : 0.335001
[23:00:15.708] iteration 12616 : model1 loss : 0.199380 model2 loss : 0.200790
[23:00:16.051] iteration 12617 : model1 loss : 0.317226 model2 loss : 0.298119
[23:00:16.393] iteration 12618 : model1 loss : 0.346744 model2 loss : 0.359658
[23:00:16.730] iteration 12619 : model1 loss : 0.175485 model2 loss : 0.208513
[23:00:17.071] iteration 12620 : model1 loss : 0.279626 model2 loss : 0.307644
[23:00:17.409] iteration 12621 : model1 loss : 0.209569 model2 loss : 0.188207
[23:00:17.753] iteration 12622 : model1 loss : 0.231180 model2 loss : 0.205391
[23:00:18.095] iteration 12623 : model1 loss : 0.305223 model2 loss : 0.283515
[23:00:18.436] iteration 12624 : model1 loss : 0.190617 model2 loss : 0.222867
[23:00:18.773] iteration 12625 : model1 loss : 0.320310 model2 loss : 0.330579
[23:00:19.112] iteration 12626 : model1 loss : 0.172705 model2 loss : 0.200993
[23:00:19.451] iteration 12627 : model1 loss : 0.319116 model2 loss : 0.323278
[23:00:19.787] iteration 12628 : model1 loss : 0.208760 model2 loss : 0.260945
[23:00:20.123] iteration 12629 : model1 loss : 0.261743 model2 loss : 0.312048
[23:00:20.465] iteration 12630 : model1 loss : 0.207581 model2 loss : 0.293658
[23:00:20.800] iteration 12631 : model1 loss : 0.346525 model2 loss : 0.315450
[23:00:21.138] iteration 12632 : model1 loss : 0.229366 model2 loss : 0.297643
[23:00:21.476] iteration 12633 : model1 loss : 0.209434 model2 loss : 0.234822
[23:00:21.815] iteration 12634 : model1 loss : 0.188713 model2 loss : 0.206373
[23:00:22.159] iteration 12635 : model1 loss : 0.263960 model2 loss : 0.280377
[23:00:22.496] iteration 12636 : model1 loss : 0.086890 model2 loss : 0.136164
[23:00:22.830] iteration 12637 : model1 loss : 0.196006 model2 loss : 0.239917
[23:00:23.168] iteration 12638 : model1 loss : 0.227298 model2 loss : 0.260901
[23:00:23.505] iteration 12639 : model1 loss : 0.130666 model2 loss : 0.118235
[23:00:23.841] iteration 12640 : model1 loss : 0.187859 model2 loss : 0.199355
[23:00:24.187] iteration 12641 : model1 loss : 0.085634 model2 loss : 0.114336
[23:00:24.532] iteration 12642 : model1 loss : 0.174544 model2 loss : 0.228285
[23:00:24.868] iteration 12643 : model1 loss : 0.207433 model2 loss : 0.263863
[23:00:25.205] iteration 12644 : model1 loss : 0.194707 model2 loss : 0.228304
[23:00:25.543] iteration 12645 : model1 loss : 0.161128 model2 loss : 0.232570
[23:00:25.879] iteration 12646 : model1 loss : 0.146956 model2 loss : 0.241351
[23:00:26.217] iteration 12647 : model1 loss : 0.176797 model2 loss : 0.175319
[23:00:26.559] iteration 12648 : model1 loss : 0.194777 model2 loss : 0.278899
[23:00:26.898] iteration 12649 : model1 loss : 0.182384 model2 loss : 0.262503
[23:00:27.240] iteration 12650 : model1 loss : 0.240348 model2 loss : 0.263586
[23:00:27.874] iteration 12651 : model1 loss : 0.179480 model2 loss : 0.176305
[23:00:28.213] iteration 12652 : model1 loss : 0.129369 model2 loss : 0.128082
[23:00:28.551] iteration 12653 : model1 loss : 0.210023 model2 loss : 0.262684
[23:00:28.885] iteration 12654 : model1 loss : 0.150454 model2 loss : 0.219603
[23:00:29.223] iteration 12655 : model1 loss : 0.174908 model2 loss : 0.200784
[23:00:29.563] iteration 12656 : model1 loss : 0.129312 model2 loss : 0.137780
[23:00:29.901] iteration 12657 : model1 loss : 0.144354 model2 loss : 0.175040
[23:00:30.244] iteration 12658 : model1 loss : 0.243133 model2 loss : 0.327291
[23:00:30.584] iteration 12659 : model1 loss : 0.298568 model2 loss : 0.308404
[23:00:30.924] iteration 12660 : model1 loss : 0.287968 model2 loss : 0.371222
[23:00:31.264] iteration 12661 : model1 loss : 0.125699 model2 loss : 0.159135
[23:00:31.605] iteration 12662 : model1 loss : 0.279502 model2 loss : 0.292188
[23:00:31.944] iteration 12663 : model1 loss : 0.100556 model2 loss : 0.093810
[23:00:32.283] iteration 12664 : model1 loss : 0.191777 model2 loss : 0.243377
[23:00:32.622] iteration 12665 : model1 loss : 0.298327 model2 loss : 0.323316
[23:00:32.957] iteration 12666 : model1 loss : 0.214084 model2 loss : 0.211208
[23:00:33.297] iteration 12667 : model1 loss : 0.271076 model2 loss : 0.312673
[23:00:33.636] iteration 12668 : model1 loss : 0.260328 model2 loss : 0.291053
[23:00:33.973] iteration 12669 : model1 loss : 0.230558 model2 loss : 0.244820
[23:00:34.305] iteration 12670 : model1 loss : 0.185576 model2 loss : 0.174477
[23:00:34.636] iteration 12671 : model1 loss : 0.216240 model2 loss : 0.279084
[23:00:34.967] iteration 12672 : model1 loss : 0.184230 model2 loss : 0.214246
[23:00:35.297] iteration 12673 : model1 loss : 0.243674 model2 loss : 0.245468
[23:00:35.628] iteration 12674 : model1 loss : 0.323087 model2 loss : 0.328358
[23:00:35.959] iteration 12675 : model1 loss : 0.320297 model2 loss : 0.259601
[23:00:36.290] iteration 12676 : model1 loss : 0.226867 model2 loss : 0.255719
[23:00:36.622] iteration 12677 : model1 loss : 0.166902 model2 loss : 0.159967
[23:00:36.953] iteration 12678 : model1 loss : 0.266247 model2 loss : 0.251433
[23:00:37.284] iteration 12679 : model1 loss : 0.192512 model2 loss : 0.224128
[23:00:37.618] iteration 12680 : model1 loss : 0.337721 model2 loss : 0.310562
[23:00:37.948] iteration 12681 : model1 loss : 0.434261 model2 loss : 0.412795
[23:00:38.280] iteration 12682 : model1 loss : 0.392656 model2 loss : 0.357665
[23:00:38.616] iteration 12683 : model1 loss : 0.264003 model2 loss : 0.228516
[23:00:38.951] iteration 12684 : model1 loss : 0.154495 model2 loss : 0.137893
[23:00:39.284] iteration 12685 : model1 loss : 0.259204 model2 loss : 0.251260
[23:00:39.617] iteration 12686 : model1 loss : 0.341785 model2 loss : 0.304317
[23:00:39.952] iteration 12687 : model1 loss : 0.205620 model2 loss : 0.237885
[23:00:40.283] iteration 12688 : model1 loss : 0.307072 model2 loss : 0.279515
[23:00:40.614] iteration 12689 : model1 loss : 0.228020 model2 loss : 0.241431
[23:00:40.946] iteration 12690 : model1 loss : 0.120281 model2 loss : 0.167408
[23:00:41.282] iteration 12691 : model1 loss : 0.201497 model2 loss : 0.245987
[23:00:41.612] iteration 12692 : model1 loss : 0.354165 model2 loss : 0.306545
[23:00:41.944] iteration 12693 : model1 loss : 0.182511 model2 loss : 0.143371
[23:00:42.275] iteration 12694 : model1 loss : 0.289264 model2 loss : 0.301309
[23:00:42.607] iteration 12695 : model1 loss : 0.328585 model2 loss : 0.328201
[23:00:42.940] iteration 12696 : model1 loss : 0.212455 model2 loss : 0.213306
[23:00:43.270] iteration 12697 : model1 loss : 0.255787 model2 loss : 0.261761
[23:00:43.600] iteration 12698 : model1 loss : 0.208038 model2 loss : 0.278612
[23:00:43.930] iteration 12699 : model1 loss : 0.171861 model2 loss : 0.137951
[23:00:44.260] iteration 12700 : model1 loss : 0.390485 model2 loss : 0.333495
[23:00:44.797] iteration 12701 : model1 loss : 0.191209 model2 loss : 0.145597
[23:00:45.131] iteration 12702 : model1 loss : 0.103146 model2 loss : 0.110643
[23:00:45.461] iteration 12703 : model1 loss : 0.261828 model2 loss : 0.229406
[23:00:45.791] iteration 12704 : model1 loss : 0.258972 model2 loss : 0.243734
[23:00:46.122] iteration 12705 : model1 loss : 0.150012 model2 loss : 0.224768
[23:00:46.455] iteration 12706 : model1 loss : 0.223139 model2 loss : 0.218872
[23:00:46.786] iteration 12707 : model1 loss : 0.281168 model2 loss : 0.289270
[23:00:47.117] iteration 12708 : model1 loss : 0.202749 model2 loss : 0.191395
[23:00:47.447] iteration 12709 : model1 loss : 0.336588 model2 loss : 0.285113
[23:00:47.778] iteration 12710 : model1 loss : 0.251502 model2 loss : 0.210298
[23:00:48.111] iteration 12711 : model1 loss : 0.301486 model2 loss : 0.312457
[23:00:48.443] iteration 12712 : model1 loss : 0.271593 model2 loss : 0.266572
[23:00:48.775] iteration 12713 : model1 loss : 0.215349 model2 loss : 0.286219
[23:00:49.106] iteration 12714 : model1 loss : 0.226313 model2 loss : 0.244165
[23:00:49.438] iteration 12715 : model1 loss : 0.198468 model2 loss : 0.208013
[23:00:49.769] iteration 12716 : model1 loss : 0.131285 model2 loss : 0.140998
[23:00:50.102] iteration 12717 : model1 loss : 0.189955 model2 loss : 0.170738
[23:00:50.431] iteration 12718 : model1 loss : 0.309791 model2 loss : 0.308053
[23:00:50.761] iteration 12719 : model1 loss : 0.179063 model2 loss : 0.186302
[23:00:51.093] iteration 12720 : model1 loss : 0.237522 model2 loss : 0.236750
[23:00:51.426] iteration 12721 : model1 loss : 0.191723 model2 loss : 0.228757
[23:00:51.759] iteration 12722 : model1 loss : 0.118946 model2 loss : 0.154554
[23:00:52.092] iteration 12723 : model1 loss : 0.236012 model2 loss : 0.226975
[23:00:52.426] iteration 12724 : model1 loss : 0.174932 model2 loss : 0.190983
[23:00:52.756] iteration 12725 : model1 loss : 0.272795 model2 loss : 0.347825
[23:00:53.089] iteration 12726 : model1 loss : 0.254684 model2 loss : 0.242831
[23:00:53.421] iteration 12727 : model1 loss : 0.265311 model2 loss : 0.318521
[23:00:53.754] iteration 12728 : model1 loss : 0.100558 model2 loss : 0.135027
[23:00:54.085] iteration 12729 : model1 loss : 0.177478 model2 loss : 0.196850
[23:00:54.416] iteration 12730 : model1 loss : 0.223863 model2 loss : 0.277862
[23:00:54.746] iteration 12731 : model1 loss : 0.295287 model2 loss : 0.290795
[23:00:55.077] iteration 12732 : model1 loss : 0.147637 model2 loss : 0.144189
[23:00:55.409] iteration 12733 : model1 loss : 0.264210 model2 loss : 0.244108
[23:00:55.742] iteration 12734 : model1 loss : 0.240490 model2 loss : 0.236205
[23:00:56.075] iteration 12735 : model1 loss : 0.216771 model2 loss : 0.202296
[23:00:56.408] iteration 12736 : model1 loss : 0.213528 model2 loss : 0.227231
[23:00:56.739] iteration 12737 : model1 loss : 0.221258 model2 loss : 0.221120
[23:00:57.069] iteration 12738 : model1 loss : 0.324022 model2 loss : 0.321560
[23:00:57.412] iteration 12739 : model1 loss : 0.199786 model2 loss : 0.262779
[23:00:57.751] iteration 12740 : model1 loss : 0.219245 model2 loss : 0.261802
[23:00:58.090] iteration 12741 : model1 loss : 0.281159 model2 loss : 0.378863
[23:00:58.429] iteration 12742 : model1 loss : 0.186338 model2 loss : 0.309380
[23:00:58.772] iteration 12743 : model1 loss : 0.149577 model2 loss : 0.180682
[23:00:59.112] iteration 12744 : model1 loss : 0.095290 model2 loss : 0.132271
[23:00:59.451] iteration 12745 : model1 loss : 0.265303 model2 loss : 0.323054
[23:00:59.792] iteration 12746 : model1 loss : 0.226825 model2 loss : 0.219578
[23:01:00.130] iteration 12747 : model1 loss : 0.253590 model2 loss : 0.218123
[23:01:00.478] iteration 12748 : model1 loss : 0.220963 model2 loss : 0.211798
[23:01:00.817] iteration 12749 : model1 loss : 0.181980 model2 loss : 0.233175
[23:01:01.160] iteration 12750 : model1 loss : 0.182921 model2 loss : 0.209547
[23:01:01.810] iteration 12751 : model1 loss : 0.182043 model2 loss : 0.232054
[23:01:02.152] iteration 12752 : model1 loss : 0.271908 model2 loss : 0.300988
[23:01:02.497] iteration 12753 : model1 loss : 0.153575 model2 loss : 0.120777
[23:01:02.839] iteration 12754 : model1 loss : 0.258283 model2 loss : 0.286004
[23:01:03.179] iteration 12755 : model1 loss : 0.180208 model2 loss : 0.227293
[23:01:03.523] iteration 12756 : model1 loss : 0.123768 model2 loss : 0.197684
[23:01:03.862] iteration 12757 : model1 loss : 0.204268 model2 loss : 0.166842
[23:01:04.206] iteration 12758 : model1 loss : 0.242186 model2 loss : 0.311309
[23:01:04.545] iteration 12759 : model1 loss : 0.422141 model2 loss : 0.419529
[23:01:04.885] iteration 12760 : model1 loss : 0.274043 model2 loss : 0.341525
[23:01:05.229] iteration 12761 : model1 loss : 0.269355 model2 loss : 0.311624
[23:01:05.573] iteration 12762 : model1 loss : 0.207102 model2 loss : 0.216197
[23:01:05.909] iteration 12763 : model1 loss : 0.329847 model2 loss : 0.268354
[23:01:06.247] iteration 12764 : model1 loss : 0.119426 model2 loss : 0.183256
[23:01:06.586] iteration 12765 : model1 loss : 0.290089 model2 loss : 0.315265
[23:01:06.923] iteration 12766 : model1 loss : 0.289354 model2 loss : 0.305466
[23:01:07.266] iteration 12767 : model1 loss : 0.114366 model2 loss : 0.147482
[23:01:07.608] iteration 12768 : model1 loss : 0.205373 model2 loss : 0.237321
[23:01:07.943] iteration 12769 : model1 loss : 0.373051 model2 loss : 0.466531
[23:01:08.274] iteration 12770 : model1 loss : 0.279638 model2 loss : 0.277106
[23:01:08.605] iteration 12771 : model1 loss : 0.172091 model2 loss : 0.251011
[23:01:08.936] iteration 12772 : model1 loss : 0.160882 model2 loss : 0.183561
[23:01:09.266] iteration 12773 : model1 loss : 0.332545 model2 loss : 0.295970
[23:01:09.597] iteration 12774 : model1 loss : 0.149338 model2 loss : 0.222575
[23:01:09.936] iteration 12775 : model1 loss : 0.265537 model2 loss : 0.294270
[23:01:10.281] iteration 12776 : model1 loss : 0.139967 model2 loss : 0.176299
[23:01:10.621] iteration 12777 : model1 loss : 0.166210 model2 loss : 0.243815
[23:01:10.957] iteration 12778 : model1 loss : 0.179318 model2 loss : 0.181206
[23:01:11.303] iteration 12779 : model1 loss : 0.184895 model2 loss : 0.188482
[23:01:11.643] iteration 12780 : model1 loss : 0.087710 model2 loss : 0.172682
[23:01:11.979] iteration 12781 : model1 loss : 0.226809 model2 loss : 0.243932
[23:01:12.320] iteration 12782 : model1 loss : 0.201000 model2 loss : 0.211580
[23:01:12.661] iteration 12783 : model1 loss : 0.177410 model2 loss : 0.214056
[23:01:13.002] iteration 12784 : model1 loss : 0.174253 model2 loss : 0.116913
[23:01:13.342] iteration 12785 : model1 loss : 0.236242 model2 loss : 0.206918
[23:01:13.681] iteration 12786 : model1 loss : 0.159504 model2 loss : 0.167597
[23:01:14.018] iteration 12787 : model1 loss : 0.182051 model2 loss : 0.170201
[23:01:14.356] iteration 12788 : model1 loss : 0.282494 model2 loss : 0.325183
[23:01:14.696] iteration 12789 : model1 loss : 0.227152 model2 loss : 0.316020
[23:01:15.036] iteration 12790 : model1 loss : 0.190490 model2 loss : 0.197733
[23:01:15.381] iteration 12791 : model1 loss : 0.104432 model2 loss : 0.147752
[23:01:15.721] iteration 12792 : model1 loss : 0.217738 model2 loss : 0.198063
[23:01:16.062] iteration 12793 : model1 loss : 0.240777 model2 loss : 0.366910
[23:01:16.404] iteration 12794 : model1 loss : 0.218428 model2 loss : 0.290497
[23:01:16.742] iteration 12795 : model1 loss : 0.203891 model2 loss : 0.189666
[23:01:17.082] iteration 12796 : model1 loss : 0.192453 model2 loss : 0.206399
[23:01:17.425] iteration 12797 : model1 loss : 0.229995 model2 loss : 0.230141
[23:01:17.766] iteration 12798 : model1 loss : 0.227713 model2 loss : 0.217666
[23:01:18.107] iteration 12799 : model1 loss : 0.214356 model2 loss : 0.277599
[23:01:18.446] iteration 12800 : model1 loss : 0.368796 model2 loss : 0.428301
[23:01:19.081] iteration 12801 : model1 loss : 0.168932 model2 loss : 0.191940
[23:01:19.422] iteration 12802 : model1 loss : 0.192579 model2 loss : 0.240876
[23:01:19.769] iteration 12803 : model1 loss : 0.284718 model2 loss : 0.335860
[23:01:20.109] iteration 12804 : model1 loss : 0.212326 model2 loss : 0.260479
[23:01:20.450] iteration 12805 : model1 loss : 0.314217 model2 loss : 0.360519
[23:01:20.793] iteration 12806 : model1 loss : 0.239880 model2 loss : 0.230906
[23:01:21.134] iteration 12807 : model1 loss : 0.283676 model2 loss : 0.300906
[23:01:21.473] iteration 12808 : model1 loss : 0.275118 model2 loss : 0.317668
[23:01:21.822] iteration 12809 : model1 loss : 0.216369 model2 loss : 0.219980
[23:01:22.161] iteration 12810 : model1 loss : 0.269483 model2 loss : 0.332556
[23:01:22.505] iteration 12811 : model1 loss : 0.152163 model2 loss : 0.182890
[23:01:22.841] iteration 12812 : model1 loss : 0.388767 model2 loss : 0.352249
[23:01:23.189] iteration 12813 : model1 loss : 0.114522 model2 loss : 0.166827
[23:01:23.531] iteration 12814 : model1 loss : 0.212182 model2 loss : 0.229259
[23:01:23.871] iteration 12815 : model1 loss : 0.197324 model2 loss : 0.241950
[23:01:24.211] iteration 12816 : model1 loss : 0.117717 model2 loss : 0.144759
[23:01:24.554] iteration 12817 : model1 loss : 0.138793 model2 loss : 0.134666
[23:01:24.893] iteration 12818 : model1 loss : 0.154264 model2 loss : 0.168033
[23:01:25.234] iteration 12819 : model1 loss : 0.255461 model2 loss : 0.297946
[23:01:25.574] iteration 12820 : model1 loss : 0.229752 model2 loss : 0.242133
[23:01:25.910] iteration 12821 : model1 loss : 0.303423 model2 loss : 0.336900
[23:01:26.250] iteration 12822 : model1 loss : 0.272756 model2 loss : 0.321665
[23:01:26.595] iteration 12823 : model1 loss : 0.255765 model2 loss : 0.267247
[23:01:26.934] iteration 12824 : model1 loss : 0.212212 model2 loss : 0.233242
[23:01:27.276] iteration 12825 : model1 loss : 0.252308 model2 loss : 0.296566
[23:01:27.616] iteration 12826 : model1 loss : 0.173685 model2 loss : 0.195269
[23:01:27.957] iteration 12827 : model1 loss : 0.163624 model2 loss : 0.195119
[23:01:28.303] iteration 12828 : model1 loss : 0.286199 model2 loss : 0.252594
[23:01:28.646] iteration 12829 : model1 loss : 0.207388 model2 loss : 0.273071
[23:01:28.981] iteration 12830 : model1 loss : 0.280888 model2 loss : 0.274744
[23:01:29.322] iteration 12831 : model1 loss : 0.249693 model2 loss : 0.249381
[23:01:29.658] iteration 12832 : model1 loss : 0.274341 model2 loss : 0.269536
[23:01:29.996] iteration 12833 : model1 loss : 0.210675 model2 loss : 0.247064
[23:01:30.345] iteration 12834 : model1 loss : 0.160331 model2 loss : 0.274464
[23:01:30.682] iteration 12835 : model1 loss : 0.334730 model2 loss : 0.398764
[23:01:31.018] iteration 12836 : model1 loss : 0.205470 model2 loss : 0.239726
[23:01:31.358] iteration 12837 : model1 loss : 0.233658 model2 loss : 0.257738
[23:01:31.696] iteration 12838 : model1 loss : 0.187469 model2 loss : 0.219762
[23:01:32.035] iteration 12839 : model1 loss : 0.200263 model2 loss : 0.248392
[23:01:32.381] iteration 12840 : model1 loss : 0.183260 model2 loss : 0.190207
[23:01:32.725] iteration 12841 : model1 loss : 0.190645 model2 loss : 0.257722
[23:01:33.065] iteration 12842 : model1 loss : 0.209281 model2 loss : 0.211481
[23:01:33.407] iteration 12843 : model1 loss : 0.314805 model2 loss : 0.363612
[23:01:33.749] iteration 12844 : model1 loss : 0.271505 model2 loss : 0.255668
[23:01:34.090] iteration 12845 : model1 loss : 0.303978 model2 loss : 0.274177
[23:01:34.429] iteration 12846 : model1 loss : 0.212265 model2 loss : 0.269687
[23:01:34.775] iteration 12847 : model1 loss : 0.184955 model2 loss : 0.240817
[23:01:35.117] iteration 12848 : model1 loss : 0.327381 model2 loss : 0.360657
[23:01:35.468] iteration 12849 : model1 loss : 0.220557 model2 loss : 0.204950
[23:01:35.811] iteration 12850 : model1 loss : 0.202639 model2 loss : 0.233649
[23:01:36.488] iteration 12851 : model1 loss : 0.275946 model2 loss : 0.245755
[23:01:36.825] iteration 12852 : model1 loss : 0.261670 model2 loss : 0.287891
[23:01:37.163] iteration 12853 : model1 loss : 0.138864 model2 loss : 0.225662
[23:01:37.509] iteration 12854 : model1 loss : 0.205907 model2 loss : 0.235049
[23:01:37.844] iteration 12855 : model1 loss : 0.168889 model2 loss : 0.214770
[23:01:38.184] iteration 12856 : model1 loss : 0.307068 model2 loss : 0.360515
[23:01:38.520] iteration 12857 : model1 loss : 0.268608 model2 loss : 0.262726
[23:01:38.857] iteration 12858 : model1 loss : 0.308654 model2 loss : 0.307302
[23:01:39.205] iteration 12859 : model1 loss : 0.189138 model2 loss : 0.206179
[23:01:39.548] iteration 12860 : model1 loss : 0.127433 model2 loss : 0.139179
[23:01:39.883] iteration 12861 : model1 loss : 0.189862 model2 loss : 0.269911
[23:01:40.228] iteration 12862 : model1 loss : 0.261318 model2 loss : 0.284642
[23:01:40.569] iteration 12863 : model1 loss : 0.339841 model2 loss : 0.358653
[23:01:40.906] iteration 12864 : model1 loss : 0.272259 model2 loss : 0.300234
[23:01:41.247] iteration 12865 : model1 loss : 0.218794 model2 loss : 0.223402
[23:01:41.598] iteration 12866 : model1 loss : 0.211922 model2 loss : 0.242512
[23:01:41.938] iteration 12867 : model1 loss : 0.227223 model2 loss : 0.235282
[23:01:42.277] iteration 12868 : model1 loss : 0.111257 model2 loss : 0.187261
[23:01:42.617] iteration 12869 : model1 loss : 0.095836 model2 loss : 0.165452
[23:01:42.953] iteration 12870 : model1 loss : 0.258549 model2 loss : 0.292515
[23:01:43.294] iteration 12871 : model1 loss : 0.234677 model2 loss : 0.249059
[23:01:43.633] iteration 12872 : model1 loss : 0.361504 model2 loss : 0.329239
[23:01:43.971] iteration 12873 : model1 loss : 0.140809 model2 loss : 0.223687
[23:01:44.310] iteration 12874 : model1 loss : 0.200954 model2 loss : 0.272565
[23:01:44.650] iteration 12875 : model1 loss : 0.260049 model2 loss : 0.272013
[23:01:44.988] iteration 12876 : model1 loss : 0.218894 model2 loss : 0.244035
[23:01:45.329] iteration 12877 : model1 loss : 0.272386 model2 loss : 0.337512
[23:01:45.669] iteration 12878 : model1 loss : 0.262171 model2 loss : 0.269481
[23:01:46.005] iteration 12879 : model1 loss : 0.212698 model2 loss : 0.224285
[23:01:46.347] iteration 12880 : model1 loss : 0.247167 model2 loss : 0.241726
[23:01:46.694] iteration 12881 : model1 loss : 0.230495 model2 loss : 0.272573
[23:01:47.035] iteration 12882 : model1 loss : 0.155504 model2 loss : 0.223865
[23:01:47.375] iteration 12883 : model1 loss : 0.215503 model2 loss : 0.250003
[23:01:47.714] iteration 12884 : model1 loss : 0.208281 model2 loss : 0.256294
[23:01:48.055] iteration 12885 : model1 loss : 0.321412 model2 loss : 0.245134
[23:01:48.403] iteration 12886 : model1 loss : 0.100986 model2 loss : 0.181623
[23:01:48.744] iteration 12887 : model1 loss : 0.279638 model2 loss : 0.305958
[23:01:49.086] iteration 12888 : model1 loss : 0.165062 model2 loss : 0.154559
[23:01:49.428] iteration 12889 : model1 loss : 0.307654 model2 loss : 0.300162
[23:01:49.768] iteration 12890 : model1 loss : 0.194901 model2 loss : 0.206496
[23:01:50.114] iteration 12891 : model1 loss : 0.268168 model2 loss : 0.272162
[23:01:50.458] iteration 12892 : model1 loss : 0.168045 model2 loss : 0.191846
[23:01:50.795] iteration 12893 : model1 loss : 0.193485 model2 loss : 0.213278
[23:01:51.138] iteration 12894 : model1 loss : 0.197238 model2 loss : 0.231225
[23:01:51.482] iteration 12895 : model1 loss : 0.280376 model2 loss : 0.291916
[23:01:51.820] iteration 12896 : model1 loss : 0.350255 model2 loss : 0.355960
[23:01:52.166] iteration 12897 : model1 loss : 0.131283 model2 loss : 0.152482
[23:01:52.506] iteration 12898 : model1 loss : 0.185582 model2 loss : 0.296239
[23:01:52.847] iteration 12899 : model1 loss : 0.177153 model2 loss : 0.186176
[23:01:53.188] iteration 12900 : model1 loss : 0.296538 model2 loss : 0.350012
[23:01:53.844] iteration 12901 : model1 loss : 0.239388 model2 loss : 0.218790
[23:01:54.192] iteration 12902 : model1 loss : 0.124562 model2 loss : 0.229530
[23:01:54.536] iteration 12903 : model1 loss : 0.292107 model2 loss : 0.338850
[23:01:54.877] iteration 12904 : model1 loss : 0.184058 model2 loss : 0.191470
[23:01:55.217] iteration 12905 : model1 loss : 0.128573 model2 loss : 0.150922
[23:01:55.558] iteration 12906 : model1 loss : 0.111572 model2 loss : 0.113769
[23:01:55.898] iteration 12907 : model1 loss : 0.265117 model2 loss : 0.283141
[23:01:56.242] iteration 12908 : model1 loss : 0.165448 model2 loss : 0.186150
[23:01:56.587] iteration 12909 : model1 loss : 0.308105 model2 loss : 0.262404
[23:01:56.931] iteration 12910 : model1 loss : 0.214475 model2 loss : 0.246165
[23:01:57.272] iteration 12911 : model1 loss : 0.182295 model2 loss : 0.161864
[23:01:57.605] iteration 12912 : model1 loss : 0.166887 model2 loss : 0.292247
[23:01:57.935] iteration 12913 : model1 loss : 0.316136 model2 loss : 0.339475
[23:01:58.268] iteration 12914 : model1 loss : 0.261561 model2 loss : 0.294591
[23:01:58.601] iteration 12915 : model1 loss : 0.166722 model2 loss : 0.178587
[23:01:58.932] iteration 12916 : model1 loss : 0.254579 model2 loss : 0.244268
[23:01:59.264] iteration 12917 : model1 loss : 0.287126 model2 loss : 0.367534
[23:01:59.596] iteration 12918 : model1 loss : 0.313435 model2 loss : 0.315331
[23:01:59.929] iteration 12919 : model1 loss : 0.201282 model2 loss : 0.266592
[23:02:00.261] iteration 12920 : model1 loss : 0.201070 model2 loss : 0.239734
[23:02:00.591] iteration 12921 : model1 loss : 0.268754 model2 loss : 0.286858
[23:02:00.923] iteration 12922 : model1 loss : 0.195814 model2 loss : 0.215491
[23:02:01.256] iteration 12923 : model1 loss : 0.303838 model2 loss : 0.310093
[23:02:01.586] iteration 12924 : model1 loss : 0.201428 model2 loss : 0.184812
[23:02:01.917] iteration 12925 : model1 loss : 0.313420 model2 loss : 0.312565
[23:02:02.247] iteration 12926 : model1 loss : 0.174872 model2 loss : 0.219022
[23:02:02.578] iteration 12927 : model1 loss : 0.178594 model2 loss : 0.183315
[23:02:02.911] iteration 12928 : model1 loss : 0.164888 model2 loss : 0.172157
[23:02:03.241] iteration 12929 : model1 loss : 0.239705 model2 loss : 0.264489
[23:02:03.572] iteration 12930 : model1 loss : 0.204502 model2 loss : 0.240564
[23:02:03.902] iteration 12931 : model1 loss : 0.214393 model2 loss : 0.234967
[23:02:04.234] iteration 12932 : model1 loss : 0.206729 model2 loss : 0.232683
[23:02:04.566] iteration 12933 : model1 loss : 0.128716 model2 loss : 0.188235
[23:02:04.899] iteration 12934 : model1 loss : 0.237335 model2 loss : 0.225699
[23:02:05.232] iteration 12935 : model1 loss : 0.339032 model2 loss : 0.309034
[23:02:05.565] iteration 12936 : model1 loss : 0.103347 model2 loss : 0.148656
[23:02:05.898] iteration 12937 : model1 loss : 0.197910 model2 loss : 0.215836
[23:02:06.228] iteration 12938 : model1 loss : 0.222276 model2 loss : 0.224434
[23:02:06.560] iteration 12939 : model1 loss : 0.175950 model2 loss : 0.194739
[23:02:06.893] iteration 12940 : model1 loss : 0.229294 model2 loss : 0.277997
[23:02:07.237] iteration 12941 : model1 loss : 0.252102 model2 loss : 0.267676
[23:02:07.576] iteration 12942 : model1 loss : 0.190984 model2 loss : 0.176897
[23:02:07.917] iteration 12943 : model1 loss : 0.175794 model2 loss : 0.194080
[23:02:08.256] iteration 12944 : model1 loss : 0.121597 model2 loss : 0.151955
[23:02:08.596] iteration 12945 : model1 loss : 0.276568 model2 loss : 0.322440
[23:02:08.935] iteration 12946 : model1 loss : 0.119673 model2 loss : 0.138071
[23:02:09.280] iteration 12947 : model1 loss : 0.215438 model2 loss : 0.222895
[23:02:09.621] iteration 12948 : model1 loss : 0.197859 model2 loss : 0.189799
[23:02:09.963] iteration 12949 : model1 loss : 0.194358 model2 loss : 0.225271
[23:02:10.307] iteration 12950 : model1 loss : 0.172245 model2 loss : 0.154673
[23:02:10.971] iteration 12951 : model1 loss : 0.165811 model2 loss : 0.179615
[23:02:11.313] iteration 12952 : model1 loss : 0.251136 model2 loss : 0.241352
[23:02:11.658] iteration 12953 : model1 loss : 0.180014 model2 loss : 0.196719
[23:02:11.998] iteration 12954 : model1 loss : 0.189788 model2 loss : 0.197784
[23:02:12.341] iteration 12955 : model1 loss : 0.222277 model2 loss : 0.282851
[23:02:12.681] iteration 12956 : model1 loss : 0.246745 model2 loss : 0.292721
[23:02:13.020] iteration 12957 : model1 loss : 0.330791 model2 loss : 0.340009
[23:02:13.366] iteration 12958 : model1 loss : 0.197068 model2 loss : 0.228648
[23:02:13.711] iteration 12959 : model1 loss : 0.112307 model2 loss : 0.123646
[23:02:14.052] iteration 12960 : model1 loss : 0.331735 model2 loss : 0.380968
[23:02:14.396] iteration 12961 : model1 loss : 0.152674 model2 loss : 0.194029
[23:02:14.738] iteration 12962 : model1 loss : 0.135399 model2 loss : 0.174106
[23:02:15.083] iteration 12963 : model1 loss : 0.264138 model2 loss : 0.302440
[23:02:15.423] iteration 12964 : model1 loss : 0.102237 model2 loss : 0.196016
[23:02:15.767] iteration 12965 : model1 loss : 0.282536 model2 loss : 0.273519
[23:02:16.107] iteration 12966 : model1 loss : 0.116375 model2 loss : 0.170038
[23:02:16.451] iteration 12967 : model1 loss : 0.181534 model2 loss : 0.213896
[23:02:16.790] iteration 12968 : model1 loss : 0.240132 model2 loss : 0.293204
[23:02:17.129] iteration 12969 : model1 loss : 0.226200 model2 loss : 0.369810
[23:02:17.474] iteration 12970 : model1 loss : 0.229235 model2 loss : 0.255925
[23:02:17.813] iteration 12971 : model1 loss : 0.274657 model2 loss : 0.294690
[23:02:18.153] iteration 12972 : model1 loss : 0.098364 model2 loss : 0.153161
[23:02:18.493] iteration 12973 : model1 loss : 0.113201 model2 loss : 0.210462
[23:02:18.833] iteration 12974 : model1 loss : 0.162631 model2 loss : 0.187575
[23:02:19.173] iteration 12975 : model1 loss : 0.270333 model2 loss : 0.295296
[23:02:19.516] iteration 12976 : model1 loss : 0.398815 model2 loss : 0.421509
[23:02:19.858] iteration 12977 : model1 loss : 0.340071 model2 loss : 0.289364
[23:02:20.197] iteration 12978 : model1 loss : 0.249167 model2 loss : 0.289402
[23:02:20.538] iteration 12979 : model1 loss : 0.206388 model2 loss : 0.234898
[23:02:20.878] iteration 12980 : model1 loss : 0.200499 model2 loss : 0.267564
[23:02:21.217] iteration 12981 : model1 loss : 0.131079 model2 loss : 0.170377
[23:02:21.558] iteration 12982 : model1 loss : 0.164526 model2 loss : 0.244042
[23:02:21.889] iteration 12983 : model1 loss : 0.202103 model2 loss : 0.219290
[23:02:22.220] iteration 12984 : model1 loss : 0.280294 model2 loss : 0.282111
[23:02:22.553] iteration 12985 : model1 loss : 0.187314 model2 loss : 0.239319
[23:02:22.886] iteration 12986 : model1 loss : 0.161921 model2 loss : 0.237933
[23:02:23.218] iteration 12987 : model1 loss : 0.274857 model2 loss : 0.307766
[23:02:23.550] iteration 12988 : model1 loss : 0.268073 model2 loss : 0.280381
[23:02:23.882] iteration 12989 : model1 loss : 0.269576 model2 loss : 0.285561
[23:02:24.211] iteration 12990 : model1 loss : 0.232219 model2 loss : 0.332471
[23:02:24.540] iteration 12991 : model1 loss : 0.162557 model2 loss : 0.137668
[23:02:24.870] iteration 12992 : model1 loss : 0.179734 model2 loss : 0.189087
[23:02:25.198] iteration 12993 : model1 loss : 0.218855 model2 loss : 0.268594
[23:02:25.527] iteration 12994 : model1 loss : 0.239846 model2 loss : 0.249016
[23:02:25.856] iteration 12995 : model1 loss : 0.141498 model2 loss : 0.139076
[23:02:26.186] iteration 12996 : model1 loss : 0.149230 model2 loss : 0.172012
[23:02:26.515] iteration 12997 : model1 loss : 0.199808 model2 loss : 0.199963
[23:02:26.845] iteration 12998 : model1 loss : 0.150205 model2 loss : 0.184854
[23:02:27.174] iteration 12999 : model1 loss : 0.170404 model2 loss : 0.206118
[23:02:27.503] iteration 13000 : model1 loss : 0.254803 model2 loss : 0.269505
[23:02:28.049] iteration 13001 : model1 loss : 0.309628 model2 loss : 0.287219
[23:02:28.379] iteration 13002 : model1 loss : 0.097999 model2 loss : 0.254573
[23:02:28.707] iteration 13003 : model1 loss : 0.264687 model2 loss : 0.305027
[23:02:29.036] iteration 13004 : model1 loss : 0.313151 model2 loss : 0.383106
[23:02:29.366] iteration 13005 : model1 loss : 0.111559 model2 loss : 0.199644
[23:02:29.696] iteration 13006 : model1 loss : 0.160728 model2 loss : 0.152460
[23:02:30.033] iteration 13007 : model1 loss : 0.189293 model2 loss : 0.195318
[23:02:30.371] iteration 13008 : model1 loss : 0.310788 model2 loss : 0.324569
[23:02:30.709] iteration 13009 : model1 loss : 0.192783 model2 loss : 0.278737
[23:02:31.047] iteration 13010 : model1 loss : 0.193939 model2 loss : 0.277443
[23:02:31.386] iteration 13011 : model1 loss : 0.242041 model2 loss : 0.298560
[23:02:31.724] iteration 13012 : model1 loss : 0.228669 model2 loss : 0.254270
[23:02:32.062] iteration 13013 : model1 loss : 0.231766 model2 loss : 0.243141
[23:02:32.399] iteration 13014 : model1 loss : 0.213095 model2 loss : 0.243801
[23:02:32.733] iteration 13015 : model1 loss : 0.271633 model2 loss : 0.239134
[23:02:33.070] iteration 13016 : model1 loss : 0.180176 model2 loss : 0.227405
[23:02:33.416] iteration 13017 : model1 loss : 0.164914 model2 loss : 0.207863
[23:02:33.754] iteration 13018 : model1 loss : 0.208731 model2 loss : 0.245341
[23:02:34.089] iteration 13019 : model1 loss : 0.092080 model2 loss : 0.133226
[23:02:34.427] iteration 13020 : model1 loss : 0.118161 model2 loss : 0.128478
[23:02:34.778] iteration 13021 : model1 loss : 0.201361 model2 loss : 0.196223
[23:02:35.134] iteration 13022 : model1 loss : 0.266204 model2 loss : 0.293962
[23:02:35.464] iteration 13023 : model1 loss : 0.139208 model2 loss : 0.154082
[23:02:35.794] iteration 13024 : model1 loss : 0.201634 model2 loss : 0.282875
[23:02:36.123] iteration 13025 : model1 loss : 0.181617 model2 loss : 0.188580
[23:02:36.452] iteration 13026 : model1 loss : 0.280692 model2 loss : 0.312245
[23:02:36.781] iteration 13027 : model1 loss : 0.305396 model2 loss : 0.311849
[23:02:37.110] iteration 13028 : model1 loss : 0.253242 model2 loss : 0.262019
[23:02:37.439] iteration 13029 : model1 loss : 0.268032 model2 loss : 0.311880
[23:02:37.768] iteration 13030 : model1 loss : 0.259129 model2 loss : 0.279243
[23:02:38.098] iteration 13031 : model1 loss : 0.293698 model2 loss : 0.290236
[23:02:38.426] iteration 13032 : model1 loss : 0.229828 model2 loss : 0.240656
[23:02:38.755] iteration 13033 : model1 loss : 0.276456 model2 loss : 0.292534
[23:02:39.084] iteration 13034 : model1 loss : 0.258149 model2 loss : 0.253107
[23:02:39.412] iteration 13035 : model1 loss : 0.178858 model2 loss : 0.210534
[23:02:39.741] iteration 13036 : model1 loss : 0.239824 model2 loss : 0.216601
[23:02:40.071] iteration 13037 : model1 loss : 0.176934 model2 loss : 0.241840
[23:02:40.399] iteration 13038 : model1 loss : 0.279263 model2 loss : 0.290714
[23:02:40.726] iteration 13039 : model1 loss : 0.253710 model2 loss : 0.313694
[23:02:41.054] iteration 13040 : model1 loss : 0.200081 model2 loss : 0.257681
[23:02:41.381] iteration 13041 : model1 loss : 0.183402 model2 loss : 0.222384
[23:02:41.709] iteration 13042 : model1 loss : 0.118325 model2 loss : 0.193613
[23:02:42.036] iteration 13043 : model1 loss : 0.284853 model2 loss : 0.249218
[23:02:42.363] iteration 13044 : model1 loss : 0.401667 model2 loss : 0.420978
[23:02:42.690] iteration 13045 : model1 loss : 0.201794 model2 loss : 0.218577
[23:02:43.017] iteration 13046 : model1 loss : 0.210149 model2 loss : 0.270102
[23:02:43.345] iteration 13047 : model1 loss : 0.214598 model2 loss : 0.262438
[23:02:43.672] iteration 13048 : model1 loss : 0.232599 model2 loss : 0.280119
[23:02:43.999] iteration 13049 : model1 loss : 0.253546 model2 loss : 0.271333
[23:02:44.327] iteration 13050 : model1 loss : 0.281906 model2 loss : 0.261682
[23:02:44.843] iteration 13051 : model1 loss : 0.186914 model2 loss : 0.179620
[23:02:45.170] iteration 13052 : model1 loss : 0.219757 model2 loss : 0.241357
[23:02:45.498] iteration 13053 : model1 loss : 0.211428 model2 loss : 0.195836
[23:02:45.825] iteration 13054 : model1 loss : 0.142499 model2 loss : 0.167524
[23:02:46.153] iteration 13055 : model1 loss : 0.218513 model2 loss : 0.194233
[23:02:46.482] iteration 13056 : model1 loss : 0.232126 model2 loss : 0.255236
[23:02:46.809] iteration 13057 : model1 loss : 0.174646 model2 loss : 0.174908
[23:02:47.136] iteration 13058 : model1 loss : 0.182026 model2 loss : 0.183430
[23:02:47.463] iteration 13059 : model1 loss : 0.227823 model2 loss : 0.223400
[23:02:47.791] iteration 13060 : model1 loss : 0.292082 model2 loss : 0.360251
[23:02:48.119] iteration 13061 : model1 loss : 0.400751 model2 loss : 0.402953
[23:02:48.446] iteration 13062 : model1 loss : 0.155034 model2 loss : 0.188006
[23:02:48.773] iteration 13063 : model1 loss : 0.208454 model2 loss : 0.216409
[23:02:49.100] iteration 13064 : model1 loss : 0.337044 model2 loss : 0.287980
[23:02:49.427] iteration 13065 : model1 loss : 0.170284 model2 loss : 0.192961
[23:02:49.754] iteration 13066 : model1 loss : 0.249355 model2 loss : 0.224989
[23:02:50.082] iteration 13067 : model1 loss : 0.231107 model2 loss : 0.260562
[23:02:50.411] iteration 13068 : model1 loss : 0.121273 model2 loss : 0.191714
[23:02:50.739] iteration 13069 : model1 loss : 0.187674 model2 loss : 0.240289
[23:02:51.066] iteration 13070 : model1 loss : 0.237249 model2 loss : 0.265616
[23:02:51.394] iteration 13071 : model1 loss : 0.154451 model2 loss : 0.168438
[23:02:51.721] iteration 13072 : model1 loss : 0.160066 model2 loss : 0.233377
[23:02:52.048] iteration 13073 : model1 loss : 0.279087 model2 loss : 0.290071
[23:02:52.374] iteration 13074 : model1 loss : 0.225997 model2 loss : 0.218579
[23:02:52.700] iteration 13075 : model1 loss : 0.212616 model2 loss : 0.223987
[23:02:53.027] iteration 13076 : model1 loss : 0.291701 model2 loss : 0.293557
[23:02:53.354] iteration 13077 : model1 loss : 0.209588 model2 loss : 0.255397
[23:02:53.686] iteration 13078 : model1 loss : 0.185061 model2 loss : 0.201949
[23:02:54.011] iteration 13079 : model1 loss : 0.171951 model2 loss : 0.192228
[23:02:54.338] iteration 13080 : model1 loss : 0.121112 model2 loss : 0.151266
[23:02:55.311] iteration 13081 : model1 loss : 0.183657 model2 loss : 0.230595
[23:02:55.639] iteration 13082 : model1 loss : 0.101721 model2 loss : 0.164132
[23:02:55.970] iteration 13083 : model1 loss : 0.243379 model2 loss : 0.271972
[23:02:56.302] iteration 13084 : model1 loss : 0.289036 model2 loss : 0.259724
[23:02:56.632] iteration 13085 : model1 loss : 0.191875 model2 loss : 0.206655
[23:02:56.961] iteration 13086 : model1 loss : 0.366650 model2 loss : 0.345684
[23:02:57.291] iteration 13087 : model1 loss : 0.211120 model2 loss : 0.221676
[23:02:57.620] iteration 13088 : model1 loss : 0.229376 model2 loss : 0.273929
[23:02:57.950] iteration 13089 : model1 loss : 0.173799 model2 loss : 0.315046
[23:02:58.279] iteration 13090 : model1 loss : 0.176116 model2 loss : 0.204231
[23:02:58.608] iteration 13091 : model1 loss : 0.171280 model2 loss : 0.196814
[23:02:58.938] iteration 13092 : model1 loss : 0.272974 model2 loss : 0.265141
[23:02:59.267] iteration 13093 : model1 loss : 0.208320 model2 loss : 0.191678
[23:02:59.596] iteration 13094 : model1 loss : 0.135943 model2 loss : 0.156289
[23:02:59.926] iteration 13095 : model1 loss : 0.244776 model2 loss : 0.251124
[23:03:00.255] iteration 13096 : model1 loss : 0.265923 model2 loss : 0.326874
[23:03:00.585] iteration 13097 : model1 loss : 0.196808 model2 loss : 0.249895
[23:03:00.914] iteration 13098 : model1 loss : 0.245779 model2 loss : 0.279477
[23:03:01.244] iteration 13099 : model1 loss : 0.110798 model2 loss : 0.137063
[23:03:01.573] iteration 13100 : model1 loss : 0.195546 model2 loss : 0.273263
[23:03:02.115] iteration 13101 : model1 loss : 0.229685 model2 loss : 0.288398
[23:03:02.444] iteration 13102 : model1 loss : 0.193227 model2 loss : 0.239524
[23:03:02.773] iteration 13103 : model1 loss : 0.175165 model2 loss : 0.237867
[23:03:03.102] iteration 13104 : model1 loss : 0.230287 model2 loss : 0.161757
[23:03:03.431] iteration 13105 : model1 loss : 0.328292 model2 loss : 0.350965
[23:03:03.761] iteration 13106 : model1 loss : 0.116336 model2 loss : 0.177555
[23:03:04.089] iteration 13107 : model1 loss : 0.147920 model2 loss : 0.139076
[23:03:04.418] iteration 13108 : model1 loss : 0.259813 model2 loss : 0.297160
[23:03:04.746] iteration 13109 : model1 loss : 0.182242 model2 loss : 0.234368
[23:03:05.076] iteration 13110 : model1 loss : 0.312815 model2 loss : 0.308976
[23:03:05.405] iteration 13111 : model1 loss : 0.199700 model2 loss : 0.236486
[23:03:05.733] iteration 13112 : model1 loss : 0.182096 model2 loss : 0.229154
[23:03:06.063] iteration 13113 : model1 loss : 0.278294 model2 loss : 0.360377
[23:03:06.393] iteration 13114 : model1 loss : 0.255294 model2 loss : 0.310029
[23:03:06.722] iteration 13115 : model1 loss : 0.158433 model2 loss : 0.165628
[23:03:07.051] iteration 13116 : model1 loss : 0.103048 model2 loss : 0.103280
[23:03:07.378] iteration 13117 : model1 loss : 0.197900 model2 loss : 0.255466
[23:03:07.706] iteration 13118 : model1 loss : 0.177888 model2 loss : 0.209507
[23:03:08.037] iteration 13119 : model1 loss : 0.320861 model2 loss : 0.350672
[23:03:08.366] iteration 13120 : model1 loss : 0.176441 model2 loss : 0.172490
[23:03:08.694] iteration 13121 : model1 loss : 0.103787 model2 loss : 0.171550
[23:03:09.020] iteration 13122 : model1 loss : 0.300494 model2 loss : 0.317142
[23:03:09.348] iteration 13123 : model1 loss : 0.294371 model2 loss : 0.286014
[23:03:09.675] iteration 13124 : model1 loss : 0.206667 model2 loss : 0.171591
[23:03:10.004] iteration 13125 : model1 loss : 0.108189 model2 loss : 0.115153
[23:03:10.333] iteration 13126 : model1 loss : 0.073262 model2 loss : 0.125943
[23:03:10.659] iteration 13127 : model1 loss : 0.212046 model2 loss : 0.250350
[23:03:10.987] iteration 13128 : model1 loss : 0.152152 model2 loss : 0.210389
[23:03:11.314] iteration 13129 : model1 loss : 0.163662 model2 loss : 0.187682
[23:03:11.642] iteration 13130 : model1 loss : 0.264933 model2 loss : 0.269707
[23:03:11.970] iteration 13131 : model1 loss : 0.201349 model2 loss : 0.223417
[23:03:12.297] iteration 13132 : model1 loss : 0.224985 model2 loss : 0.227751
[23:03:12.624] iteration 13133 : model1 loss : 0.266423 model2 loss : 0.321513
[23:03:12.952] iteration 13134 : model1 loss : 0.172289 model2 loss : 0.182031
[23:03:13.280] iteration 13135 : model1 loss : 0.114740 model2 loss : 0.141785
[23:03:13.607] iteration 13136 : model1 loss : 0.185041 model2 loss : 0.223726
[23:03:13.934] iteration 13137 : model1 loss : 0.214537 model2 loss : 0.250008
[23:03:14.262] iteration 13138 : model1 loss : 0.269244 model2 loss : 0.327710
[23:03:14.589] iteration 13139 : model1 loss : 0.170150 model2 loss : 0.183405
[23:03:14.917] iteration 13140 : model1 loss : 0.400034 model2 loss : 0.403430
[23:03:15.245] iteration 13141 : model1 loss : 0.251026 model2 loss : 0.252825
[23:03:15.572] iteration 13142 : model1 loss : 0.219018 model2 loss : 0.289898
[23:03:15.900] iteration 13143 : model1 loss : 0.135284 model2 loss : 0.134352
[23:03:16.227] iteration 13144 : model1 loss : 0.151336 model2 loss : 0.190564
[23:03:16.554] iteration 13145 : model1 loss : 0.220400 model2 loss : 0.215166
[23:03:16.882] iteration 13146 : model1 loss : 0.335768 model2 loss : 0.308912
[23:03:17.210] iteration 13147 : model1 loss : 0.090616 model2 loss : 0.095163
[23:03:17.537] iteration 13148 : model1 loss : 0.192876 model2 loss : 0.211719
[23:03:17.864] iteration 13149 : model1 loss : 0.171917 model2 loss : 0.184567
[23:03:18.191] iteration 13150 : model1 loss : 0.218547 model2 loss : 0.245662
[23:03:18.740] iteration 13151 : model1 loss : 0.197175 model2 loss : 0.228690
[23:03:19.067] iteration 13152 : model1 loss : 0.225547 model2 loss : 0.206602
[23:03:19.394] iteration 13153 : model1 loss : 0.088661 model2 loss : 0.155810
[23:03:19.722] iteration 13154 : model1 loss : 0.104227 model2 loss : 0.223139
[23:03:20.050] iteration 13155 : model1 loss : 0.196615 model2 loss : 0.228924
[23:03:20.377] iteration 13156 : model1 loss : 0.216315 model2 loss : 0.256449
[23:03:20.707] iteration 13157 : model1 loss : 0.148801 model2 loss : 0.178567
[23:03:21.035] iteration 13158 : model1 loss : 0.189392 model2 loss : 0.201781
[23:03:21.362] iteration 13159 : model1 loss : 0.184277 model2 loss : 0.272622
[23:03:21.689] iteration 13160 : model1 loss : 0.322921 model2 loss : 0.361814
[23:03:22.016] iteration 13161 : model1 loss : 0.204531 model2 loss : 0.204803
[23:03:22.343] iteration 13162 : model1 loss : 0.190114 model2 loss : 0.210351
[23:03:22.670] iteration 13163 : model1 loss : 0.173011 model2 loss : 0.201650
[23:03:22.997] iteration 13164 : model1 loss : 0.067129 model2 loss : 0.120900
[23:03:23.326] iteration 13165 : model1 loss : 0.176228 model2 loss : 0.198332
[23:03:23.654] iteration 13166 : model1 loss : 0.268802 model2 loss : 0.327054
[23:03:23.981] iteration 13167 : model1 loss : 0.210733 model2 loss : 0.299010
[23:03:24.310] iteration 13168 : model1 loss : 0.172098 model2 loss : 0.252645
[23:03:24.637] iteration 13169 : model1 loss : 0.196850 model2 loss : 0.230156
[23:03:24.965] iteration 13170 : model1 loss : 0.221083 model2 loss : 0.193342
[23:03:25.293] iteration 13171 : model1 loss : 0.086590 model2 loss : 0.122057
[23:03:25.621] iteration 13172 : model1 loss : 0.223097 model2 loss : 0.278613
[23:03:25.948] iteration 13173 : model1 loss : 0.283100 model2 loss : 0.296457
[23:03:26.276] iteration 13174 : model1 loss : 0.196375 model2 loss : 0.221114
[23:03:26.604] iteration 13175 : model1 loss : 0.166268 model2 loss : 0.205980
[23:03:26.931] iteration 13176 : model1 loss : 0.341017 model2 loss : 0.344061
[23:03:27.260] iteration 13177 : model1 loss : 0.251369 model2 loss : 0.312168
[23:03:27.587] iteration 13178 : model1 loss : 0.223659 model2 loss : 0.269118
[23:03:27.914] iteration 13179 : model1 loss : 0.147873 model2 loss : 0.168684
[23:03:28.242] iteration 13180 : model1 loss : 0.277963 model2 loss : 0.323940
[23:03:28.569] iteration 13181 : model1 loss : 0.256271 model2 loss : 0.303558
[23:03:28.895] iteration 13182 : model1 loss : 0.217941 model2 loss : 0.253990
[23:03:29.222] iteration 13183 : model1 loss : 0.210828 model2 loss : 0.208624
[23:03:29.549] iteration 13184 : model1 loss : 0.241621 model2 loss : 0.286199
[23:03:29.875] iteration 13185 : model1 loss : 0.194659 model2 loss : 0.221697
[23:03:30.203] iteration 13186 : model1 loss : 0.150333 model2 loss : 0.243176
[23:03:30.531] iteration 13187 : model1 loss : 0.209196 model2 loss : 0.236292
[23:03:30.860] iteration 13188 : model1 loss : 0.181934 model2 loss : 0.204606
[23:03:31.189] iteration 13189 : model1 loss : 0.274494 model2 loss : 0.314119
[23:03:31.516] iteration 13190 : model1 loss : 0.248910 model2 loss : 0.241136
[23:03:31.844] iteration 13191 : model1 loss : 0.206134 model2 loss : 0.246283
[23:03:32.172] iteration 13192 : model1 loss : 0.196469 model2 loss : 0.219896
[23:03:32.500] iteration 13193 : model1 loss : 0.231878 model2 loss : 0.272677
[23:03:32.828] iteration 13194 : model1 loss : 0.319011 model2 loss : 0.333077
[23:03:33.155] iteration 13195 : model1 loss : 0.251450 model2 loss : 0.295962
[23:03:33.483] iteration 13196 : model1 loss : 0.255135 model2 loss : 0.259432
[23:03:33.811] iteration 13197 : model1 loss : 0.251697 model2 loss : 0.295901
[23:03:34.139] iteration 13198 : model1 loss : 0.262733 model2 loss : 0.252343
[23:03:34.467] iteration 13199 : model1 loss : 0.186252 model2 loss : 0.257300
[23:03:34.795] iteration 13200 : model1 loss : 0.281209 model2 loss : 0.274778
[23:03:35.333] iteration 13201 : model1 loss : 0.209719 model2 loss : 0.259978
[23:03:35.660] iteration 13202 : model1 loss : 0.261239 model2 loss : 0.323999
[23:03:35.988] iteration 13203 : model1 loss : 0.187368 model2 loss : 0.221789
[23:03:36.315] iteration 13204 : model1 loss : 0.208984 model2 loss : 0.268122
[23:03:36.642] iteration 13205 : model1 loss : 0.232807 model2 loss : 0.261060
[23:03:36.970] iteration 13206 : model1 loss : 0.207593 model2 loss : 0.239119
[23:03:37.297] iteration 13207 : model1 loss : 0.240815 model2 loss : 0.322938
[23:03:37.625] iteration 13208 : model1 loss : 0.169372 model2 loss : 0.147613
[23:03:37.952] iteration 13209 : model1 loss : 0.296375 model2 loss : 0.307648
[23:03:38.280] iteration 13210 : model1 loss : 0.266471 model2 loss : 0.284573
[23:03:38.607] iteration 13211 : model1 loss : 0.271868 model2 loss : 0.388062
[23:03:38.934] iteration 13212 : model1 loss : 0.133965 model2 loss : 0.206446
[23:03:39.262] iteration 13213 : model1 loss : 0.174669 model2 loss : 0.209469
[23:03:39.590] iteration 13214 : model1 loss : 0.142122 model2 loss : 0.233092
[23:03:39.917] iteration 13215 : model1 loss : 0.200229 model2 loss : 0.253508
[23:03:40.244] iteration 13216 : model1 loss : 0.152802 model2 loss : 0.124946
[23:03:40.572] iteration 13217 : model1 loss : 0.260848 model2 loss : 0.271082
[23:03:40.899] iteration 13218 : model1 loss : 0.249116 model2 loss : 0.247544
[23:03:41.226] iteration 13219 : model1 loss : 0.187965 model2 loss : 0.194672
[23:03:41.553] iteration 13220 : model1 loss : 0.201637 model2 loss : 0.211288
[23:03:41.881] iteration 13221 : model1 loss : 0.258810 model2 loss : 0.282496
[23:03:42.209] iteration 13222 : model1 loss : 0.323334 model2 loss : 0.316507
[23:03:42.537] iteration 13223 : model1 loss : 0.222822 model2 loss : 0.234166
[23:03:42.865] iteration 13224 : model1 loss : 0.148883 model2 loss : 0.223934
[23:03:43.192] iteration 13225 : model1 loss : 0.218752 model2 loss : 0.287888
[23:03:43.519] iteration 13226 : model1 loss : 0.176925 model2 loss : 0.197341
[23:03:43.846] iteration 13227 : model1 loss : 0.117154 model2 loss : 0.146055
[23:03:44.174] iteration 13228 : model1 loss : 0.275122 model2 loss : 0.325996
[23:03:44.500] iteration 13229 : model1 loss : 0.284371 model2 loss : 0.325343
[23:03:44.828] iteration 13230 : model1 loss : 0.202334 model2 loss : 0.207491
[23:03:45.156] iteration 13231 : model1 loss : 0.087701 model2 loss : 0.104006
[23:03:45.483] iteration 13232 : model1 loss : 0.234572 model2 loss : 0.303568
[23:03:45.811] iteration 13233 : model1 loss : 0.257701 model2 loss : 0.312311
[23:03:46.139] iteration 13234 : model1 loss : 0.193541 model2 loss : 0.162073
[23:03:46.468] iteration 13235 : model1 loss : 0.264492 model2 loss : 0.268955
[23:03:46.795] iteration 13236 : model1 loss : 0.230708 model2 loss : 0.240699
[23:03:47.123] iteration 13237 : model1 loss : 0.194752 model2 loss : 0.227539
[23:03:47.450] iteration 13238 : model1 loss : 0.332392 model2 loss : 0.307811
[23:03:47.777] iteration 13239 : model1 loss : 0.182527 model2 loss : 0.226505
[23:03:48.105] iteration 13240 : model1 loss : 0.255839 model2 loss : 0.242437
[23:03:48.433] iteration 13241 : model1 loss : 0.224566 model2 loss : 0.239972
[23:03:48.759] iteration 13242 : model1 loss : 0.220201 model2 loss : 0.275889
[23:03:49.088] iteration 13243 : model1 loss : 0.190439 model2 loss : 0.310805
[23:03:49.415] iteration 13244 : model1 loss : 0.259550 model2 loss : 0.322745
[23:03:49.743] iteration 13245 : model1 loss : 0.236929 model2 loss : 0.195815
[23:03:50.070] iteration 13246 : model1 loss : 0.072723 model2 loss : 0.076844
[23:03:50.398] iteration 13247 : model1 loss : 0.155446 model2 loss : 0.210100
[23:03:50.726] iteration 13248 : model1 loss : 0.199126 model2 loss : 0.234959
[23:03:51.054] iteration 13249 : model1 loss : 0.175137 model2 loss : 0.198298
[23:03:51.381] iteration 13250 : model1 loss : 0.275640 model2 loss : 0.267961
[23:03:51.888] iteration 13251 : model1 loss : 0.254487 model2 loss : 0.281776
[23:03:52.216] iteration 13252 : model1 loss : 0.155504 model2 loss : 0.219486
[23:03:52.543] iteration 13253 : model1 loss : 0.111945 model2 loss : 0.166669
[23:03:52.870] iteration 13254 : model1 loss : 0.198624 model2 loss : 0.161871
[23:03:53.197] iteration 13255 : model1 loss : 0.218329 model2 loss : 0.219431
[23:03:53.525] iteration 13256 : model1 loss : 0.249242 model2 loss : 0.234442
[23:03:53.853] iteration 13257 : model1 loss : 0.220014 model2 loss : 0.304715
[23:03:54.181] iteration 13258 : model1 loss : 0.189043 model2 loss : 0.177134
[23:03:54.509] iteration 13259 : model1 loss : 0.294327 model2 loss : 0.307643
[23:03:54.837] iteration 13260 : model1 loss : 0.133032 model2 loss : 0.220986
[23:03:55.164] iteration 13261 : model1 loss : 0.265064 model2 loss : 0.256812
[23:03:55.492] iteration 13262 : model1 loss : 0.147648 model2 loss : 0.124438
[23:03:55.822] iteration 13263 : model1 loss : 0.177759 model2 loss : 0.260751
[23:03:56.150] iteration 13264 : model1 loss : 0.135781 model2 loss : 0.234542
[23:03:56.478] iteration 13265 : model1 loss : 0.176581 model2 loss : 0.221434
[23:03:56.806] iteration 13266 : model1 loss : 0.194200 model2 loss : 0.229874
[23:03:57.134] iteration 13267 : model1 loss : 0.173608 model2 loss : 0.184956
[23:03:57.461] iteration 13268 : model1 loss : 0.404062 model2 loss : 0.403360
[23:03:57.788] iteration 13269 : model1 loss : 0.267149 model2 loss : 0.267053
[23:03:58.116] iteration 13270 : model1 loss : 0.263293 model2 loss : 0.296644
[23:03:58.443] iteration 13271 : model1 loss : 0.224447 model2 loss : 0.241544
[23:03:58.772] iteration 13272 : model1 loss : 0.162417 model2 loss : 0.193016
[23:03:59.100] iteration 13273 : model1 loss : 0.231580 model2 loss : 0.241199
[23:03:59.426] iteration 13274 : model1 loss : 0.275072 model2 loss : 0.298096
[23:03:59.754] iteration 13275 : model1 loss : 0.219315 model2 loss : 0.266053
[23:04:00.082] iteration 13276 : model1 loss : 0.175908 model2 loss : 0.193505
[23:04:00.410] iteration 13277 : model1 loss : 0.165414 model2 loss : 0.219973
[23:04:00.738] iteration 13278 : model1 loss : 0.137693 model2 loss : 0.185661
[23:04:01.066] iteration 13279 : model1 loss : 0.278634 model2 loss : 0.291102
[23:04:01.392] iteration 13280 : model1 loss : 0.201491 model2 loss : 0.260250
[23:04:01.721] iteration 13281 : model1 loss : 0.268534 model2 loss : 0.280946
[23:04:02.049] iteration 13282 : model1 loss : 0.135379 model2 loss : 0.154783
[23:04:02.377] iteration 13283 : model1 loss : 0.180921 model2 loss : 0.175994
[23:04:02.704] iteration 13284 : model1 loss : 0.204829 model2 loss : 0.231376
[23:04:03.031] iteration 13285 : model1 loss : 0.201604 model2 loss : 0.297806
[23:04:03.359] iteration 13286 : model1 loss : 0.211552 model2 loss : 0.284577
[23:04:03.686] iteration 13287 : model1 loss : 0.126941 model2 loss : 0.147116
[23:04:04.015] iteration 13288 : model1 loss : 0.117421 model2 loss : 0.207364
[23:04:04.342] iteration 13289 : model1 loss : 0.259502 model2 loss : 0.322327
[23:04:04.671] iteration 13290 : model1 loss : 0.233406 model2 loss : 0.284087
[23:04:05.001] iteration 13291 : model1 loss : 0.196854 model2 loss : 0.276488
[23:04:05.346] iteration 13292 : model1 loss : 0.213876 model2 loss : 0.288428
[23:04:05.690] iteration 13293 : model1 loss : 0.180070 model2 loss : 0.230418
[23:04:06.035] iteration 13294 : model1 loss : 0.223056 model2 loss : 0.285527
[23:04:06.375] iteration 13295 : model1 loss : 0.217945 model2 loss : 0.238482
[23:04:06.714] iteration 13296 : model1 loss : 0.263353 model2 loss : 0.327956
[23:04:07.058] iteration 13297 : model1 loss : 0.098528 model2 loss : 0.116596
[23:04:07.397] iteration 13298 : model1 loss : 0.242480 model2 loss : 0.300278
[23:04:07.741] iteration 13299 : model1 loss : 0.192755 model2 loss : 0.248106
[23:04:08.080] iteration 13300 : model1 loss : 0.246313 model2 loss : 0.275988
[23:04:08.732] iteration 13301 : model1 loss : 0.194965 model2 loss : 0.269070
[23:04:09.070] iteration 13302 : model1 loss : 0.222844 model2 loss : 0.287126
[23:04:09.409] iteration 13303 : model1 loss : 0.365277 model2 loss : 0.372821
[23:04:09.751] iteration 13304 : model1 loss : 0.182196 model2 loss : 0.165844
[23:04:10.093] iteration 13305 : model1 loss : 0.253406 model2 loss : 0.291656
[23:04:10.433] iteration 13306 : model1 loss : 0.212532 model2 loss : 0.280062
[23:04:10.769] iteration 13307 : model1 loss : 0.262432 model2 loss : 0.277234
[23:04:11.107] iteration 13308 : model1 loss : 0.131270 model2 loss : 0.138520
[23:04:11.447] iteration 13309 : model1 loss : 0.207090 model2 loss : 0.241335
[23:04:11.785] iteration 13310 : model1 loss : 0.209289 model2 loss : 0.184002
[23:04:12.122] iteration 13311 : model1 loss : 0.196356 model2 loss : 0.312533
[23:04:12.458] iteration 13312 : model1 loss : 0.162530 model2 loss : 0.210287
[23:04:12.796] iteration 13313 : model1 loss : 0.184430 model2 loss : 0.229160
[23:04:13.134] iteration 13314 : model1 loss : 0.217556 model2 loss : 0.232867
[23:04:13.472] iteration 13315 : model1 loss : 0.251726 model2 loss : 0.290066
[23:04:13.809] iteration 13316 : model1 loss : 0.242965 model2 loss : 0.310768
[23:04:14.149] iteration 13317 : model1 loss : 0.251820 model2 loss : 0.291464
[23:04:14.490] iteration 13318 : model1 loss : 0.271999 model2 loss : 0.287578
[23:04:14.831] iteration 13319 : model1 loss : 0.309503 model2 loss : 0.316955
[23:04:15.169] iteration 13320 : model1 loss : 0.284640 model2 loss : 0.205905
[23:04:15.507] iteration 13321 : model1 loss : 0.191432 model2 loss : 0.196176
[23:04:15.843] iteration 13322 : model1 loss : 0.250928 model2 loss : 0.247833
[23:04:16.182] iteration 13323 : model1 loss : 0.175999 model2 loss : 0.193152
[23:04:16.522] iteration 13324 : model1 loss : 0.238055 model2 loss : 0.263360
[23:04:16.858] iteration 13325 : model1 loss : 0.352405 model2 loss : 0.296357
[23:04:17.196] iteration 13326 : model1 loss : 0.275097 model2 loss : 0.198369
[23:04:17.532] iteration 13327 : model1 loss : 0.227930 model2 loss : 0.311040
[23:04:17.869] iteration 13328 : model1 loss : 0.401515 model2 loss : 0.432569
[23:04:18.206] iteration 13329 : model1 loss : 0.280339 model2 loss : 0.298200
[23:04:18.543] iteration 13330 : model1 loss : 0.191056 model2 loss : 0.177428
[23:04:18.877] iteration 13331 : model1 loss : 0.218839 model2 loss : 0.223047
[23:04:19.214] iteration 13332 : model1 loss : 0.197795 model2 loss : 0.245884
[23:04:19.550] iteration 13333 : model1 loss : 0.177785 model2 loss : 0.236116
[23:04:19.885] iteration 13334 : model1 loss : 0.206964 model2 loss : 0.210293
[23:04:20.223] iteration 13335 : model1 loss : 0.341051 model2 loss : 0.326599
[23:04:20.560] iteration 13336 : model1 loss : 0.214186 model2 loss : 0.177182
[23:04:20.898] iteration 13337 : model1 loss : 0.256428 model2 loss : 0.185216
[23:04:21.234] iteration 13338 : model1 loss : 0.340647 model2 loss : 0.363948
[23:04:21.572] iteration 13339 : model1 loss : 0.202703 model2 loss : 0.203453
[23:04:21.908] iteration 13340 : model1 loss : 0.294677 model2 loss : 0.345515
[23:04:22.248] iteration 13341 : model1 loss : 0.198028 model2 loss : 0.226847
[23:04:22.586] iteration 13342 : model1 loss : 0.267626 model2 loss : 0.242223
[23:04:22.919] iteration 13343 : model1 loss : 0.289164 model2 loss : 0.305034
[23:04:23.256] iteration 13344 : model1 loss : 0.215606 model2 loss : 0.249707
[23:04:23.593] iteration 13345 : model1 loss : 0.208819 model2 loss : 0.269680
[23:04:23.932] iteration 13346 : model1 loss : 0.259661 model2 loss : 0.261422
[23:04:24.270] iteration 13347 : model1 loss : 0.175749 model2 loss : 0.176618
[23:04:24.607] iteration 13348 : model1 loss : 0.270620 model2 loss : 0.286180
[23:04:24.943] iteration 13349 : model1 loss : 0.264785 model2 loss : 0.221413
[23:04:25.283] iteration 13350 : model1 loss : 0.122535 model2 loss : 0.163472
[23:04:25.920] iteration 13351 : model1 loss : 0.289984 model2 loss : 0.297251
[23:04:26.256] iteration 13352 : model1 loss : 0.264419 model2 loss : 0.293302
[23:04:26.593] iteration 13353 : model1 loss : 0.197775 model2 loss : 0.225583
[23:04:26.929] iteration 13354 : model1 loss : 0.198701 model2 loss : 0.244097
[23:04:27.271] iteration 13355 : model1 loss : 0.251046 model2 loss : 0.278235
[23:04:27.612] iteration 13356 : model1 loss : 0.210040 model2 loss : 0.304920
[23:04:27.946] iteration 13357 : model1 loss : 0.223282 model2 loss : 0.275372
[23:04:28.283] iteration 13358 : model1 loss : 0.240303 model2 loss : 0.291563
[23:04:28.619] iteration 13359 : model1 loss : 0.139990 model2 loss : 0.161414
[23:04:28.953] iteration 13360 : model1 loss : 0.204951 model2 loss : 0.214467
[23:04:29.290] iteration 13361 : model1 loss : 0.304928 model2 loss : 0.360332
[23:04:29.627] iteration 13362 : model1 loss : 0.286357 model2 loss : 0.307519
[23:04:29.966] iteration 13363 : model1 loss : 0.222637 model2 loss : 0.226083
[23:04:30.305] iteration 13364 : model1 loss : 0.265861 model2 loss : 0.296614
[23:04:30.642] iteration 13365 : model1 loss : 0.130690 model2 loss : 0.133142
[23:04:30.976] iteration 13366 : model1 loss : 0.233414 model2 loss : 0.261237
[23:04:31.313] iteration 13367 : model1 loss : 0.261627 model2 loss : 0.241616
[23:04:31.651] iteration 13368 : model1 loss : 0.202367 model2 loss : 0.213400
[23:04:31.986] iteration 13369 : model1 loss : 0.189946 model2 loss : 0.204258
[23:04:32.324] iteration 13370 : model1 loss : 0.223453 model2 loss : 0.321425
[23:04:32.661] iteration 13371 : model1 loss : 0.097771 model2 loss : 0.144298
[23:04:32.995] iteration 13372 : model1 loss : 0.212069 model2 loss : 0.302594
[23:04:33.332] iteration 13373 : model1 loss : 0.182149 model2 loss : 0.215511
[23:04:33.670] iteration 13374 : model1 loss : 0.136100 model2 loss : 0.208656
[23:04:34.006] iteration 13375 : model1 loss : 0.183961 model2 loss : 0.262204
[23:04:34.345] iteration 13376 : model1 loss : 0.263509 model2 loss : 0.261537
[23:04:34.685] iteration 13377 : model1 loss : 0.305436 model2 loss : 0.312518
[23:04:35.022] iteration 13378 : model1 loss : 0.247176 model2 loss : 0.306529
[23:04:35.362] iteration 13379 : model1 loss : 0.208063 model2 loss : 0.258786
[23:04:35.700] iteration 13380 : model1 loss : 0.153243 model2 loss : 0.188447
[23:04:36.036] iteration 13381 : model1 loss : 0.201557 model2 loss : 0.272381
[23:04:36.373] iteration 13382 : model1 loss : 0.204187 model2 loss : 0.239785
[23:04:36.709] iteration 13383 : model1 loss : 0.271367 model2 loss : 0.310336
[23:04:37.044] iteration 13384 : model1 loss : 0.136470 model2 loss : 0.176835
[23:04:37.382] iteration 13385 : model1 loss : 0.129084 model2 loss : 0.141476
[23:04:37.718] iteration 13386 : model1 loss : 0.250435 model2 loss : 0.267200
[23:04:38.055] iteration 13387 : model1 loss : 0.195294 model2 loss : 0.194252
[23:04:38.391] iteration 13388 : model1 loss : 0.233114 model2 loss : 0.297310
[23:04:38.727] iteration 13389 : model1 loss : 0.170098 model2 loss : 0.227494
[23:04:39.065] iteration 13390 : model1 loss : 0.242126 model2 loss : 0.251969
[23:04:39.401] iteration 13391 : model1 loss : 0.135231 model2 loss : 0.221544
[23:04:39.737] iteration 13392 : model1 loss : 0.213135 model2 loss : 0.219243
[23:04:40.073] iteration 13393 : model1 loss : 0.265487 model2 loss : 0.311013
[23:04:40.410] iteration 13394 : model1 loss : 0.305716 model2 loss : 0.302446
[23:04:40.748] iteration 13395 : model1 loss : 0.232854 model2 loss : 0.326729
[23:04:41.086] iteration 13396 : model1 loss : 0.127974 model2 loss : 0.137457
[23:04:41.422] iteration 13397 : model1 loss : 0.275286 model2 loss : 0.294752
[23:04:41.759] iteration 13398 : model1 loss : 0.264421 model2 loss : 0.218635
[23:04:42.095] iteration 13399 : model1 loss : 0.263796 model2 loss : 0.305020
[23:04:42.431] iteration 13400 : model1 loss : 0.119096 model2 loss : 0.156877
[23:04:43.043] iteration 13401 : model1 loss : 0.150509 model2 loss : 0.161328
[23:04:43.379] iteration 13402 : model1 loss : 0.258842 model2 loss : 0.283538
[23:04:43.717] iteration 13403 : model1 loss : 0.183774 model2 loss : 0.248704
[23:04:44.054] iteration 13404 : model1 loss : 0.192107 model2 loss : 0.222476
[23:04:44.392] iteration 13405 : model1 loss : 0.190333 model2 loss : 0.195398
[23:04:44.729] iteration 13406 : model1 loss : 0.187689 model2 loss : 0.224026
[23:04:45.066] iteration 13407 : model1 loss : 0.285055 model2 loss : 0.289143
[23:04:45.410] iteration 13408 : model1 loss : 0.147401 model2 loss : 0.253532
[23:04:45.748] iteration 13409 : model1 loss : 0.194679 model2 loss : 0.230724
[23:04:46.090] iteration 13410 : model1 loss : 0.187828 model2 loss : 0.261952
[23:04:46.432] iteration 13411 : model1 loss : 0.184469 model2 loss : 0.264817
[23:04:46.769] iteration 13412 : model1 loss : 0.098057 model2 loss : 0.187125
[23:04:47.106] iteration 13413 : model1 loss : 0.170950 model2 loss : 0.223568
[23:04:47.445] iteration 13414 : model1 loss : 0.235557 model2 loss : 0.262359
[23:04:47.780] iteration 13415 : model1 loss : 0.223478 model2 loss : 0.154582
[23:04:48.116] iteration 13416 : model1 loss : 0.146202 model2 loss : 0.152585
[23:04:48.452] iteration 13417 : model1 loss : 0.181223 model2 loss : 0.242020
[23:04:48.789] iteration 13418 : model1 loss : 0.150255 model2 loss : 0.228444
[23:04:49.125] iteration 13419 : model1 loss : 0.202890 model2 loss : 0.262807
[23:04:49.461] iteration 13420 : model1 loss : 0.183353 model2 loss : 0.173527
[23:04:49.797] iteration 13421 : model1 loss : 0.293040 model2 loss : 0.277779
[23:04:50.134] iteration 13422 : model1 loss : 0.252654 model2 loss : 0.283962
[23:04:50.471] iteration 13423 : model1 loss : 0.186074 model2 loss : 0.226854
[23:04:50.807] iteration 13424 : model1 loss : 0.160570 model2 loss : 0.133664
[23:04:51.144] iteration 13425 : model1 loss : 0.188068 model2 loss : 0.223591
[23:04:51.480] iteration 13426 : model1 loss : 0.285641 model2 loss : 0.278591
[23:04:51.819] iteration 13427 : model1 loss : 0.332943 model2 loss : 0.324510
[23:04:52.155] iteration 13428 : model1 loss : 0.262332 model2 loss : 0.259146
[23:04:52.494] iteration 13429 : model1 loss : 0.165104 model2 loss : 0.193650
[23:04:52.834] iteration 13430 : model1 loss : 0.273576 model2 loss : 0.242581
[23:04:53.173] iteration 13431 : model1 loss : 0.173750 model2 loss : 0.211179
[23:04:53.510] iteration 13432 : model1 loss : 0.308191 model2 loss : 0.368598
[23:04:53.847] iteration 13433 : model1 loss : 0.264203 model2 loss : 0.301388
[23:04:54.184] iteration 13434 : model1 loss : 0.317421 model2 loss : 0.335212
[23:04:54.520] iteration 13435 : model1 loss : 0.266243 model2 loss : 0.389133
[23:04:54.856] iteration 13436 : model1 loss : 0.328862 model2 loss : 0.286283
[23:04:55.194] iteration 13437 : model1 loss : 0.287985 model2 loss : 0.312318
[23:04:55.532] iteration 13438 : model1 loss : 0.333617 model2 loss : 0.301060
[23:04:55.869] iteration 13439 : model1 loss : 0.220990 model2 loss : 0.204324
[23:04:56.206] iteration 13440 : model1 loss : 0.191432 model2 loss : 0.234838
[23:04:56.542] iteration 13441 : model1 loss : 0.246545 model2 loss : 0.241521
[23:04:56.879] iteration 13442 : model1 loss : 0.246079 model2 loss : 0.277289
[23:04:57.214] iteration 13443 : model1 loss : 0.198637 model2 loss : 0.234338
[23:04:57.551] iteration 13444 : model1 loss : 0.258420 model2 loss : 0.285391
[23:04:57.887] iteration 13445 : model1 loss : 0.217647 model2 loss : 0.247835
[23:04:58.224] iteration 13446 : model1 loss : 0.116622 model2 loss : 0.153702
[23:04:58.561] iteration 13447 : model1 loss : 0.197733 model2 loss : 0.214834
[23:04:58.898] iteration 13448 : model1 loss : 0.151983 model2 loss : 0.246367
[23:04:59.237] iteration 13449 : model1 loss : 0.193084 model2 loss : 0.194269
[23:04:59.574] iteration 13450 : model1 loss : 0.184752 model2 loss : 0.199510
[23:05:00.216] iteration 13451 : model1 loss : 0.298025 model2 loss : 0.339085
[23:05:00.552] iteration 13452 : model1 loss : 0.194031 model2 loss : 0.260599
[23:05:00.889] iteration 13453 : model1 loss : 0.255139 model2 loss : 0.257902
[23:05:01.639] iteration 13454 : model1 loss : 0.294677 model2 loss : 0.307035
[23:05:01.974] iteration 13455 : model1 loss : 0.278355 model2 loss : 0.277185
[23:05:02.311] iteration 13456 : model1 loss : 0.115914 model2 loss : 0.114711
[23:05:02.647] iteration 13457 : model1 loss : 0.220580 model2 loss : 0.302241
[23:05:02.983] iteration 13458 : model1 loss : 0.318740 model2 loss : 0.297704
[23:05:03.322] iteration 13459 : model1 loss : 0.284307 model2 loss : 0.280943
[23:05:03.659] iteration 13460 : model1 loss : 0.209996 model2 loss : 0.220109
[23:05:03.995] iteration 13461 : model1 loss : 0.213853 model2 loss : 0.242621
[23:05:04.332] iteration 13462 : model1 loss : 0.251957 model2 loss : 0.254111
[23:05:04.674] iteration 13463 : model1 loss : 0.255244 model2 loss : 0.262720
[23:05:05.012] iteration 13464 : model1 loss : 0.266710 model2 loss : 0.290083
[23:05:05.354] iteration 13465 : model1 loss : 0.375324 model2 loss : 0.317073
[23:05:05.691] iteration 13466 : model1 loss : 0.325617 model2 loss : 0.310273
[23:05:06.028] iteration 13467 : model1 loss : 0.196325 model2 loss : 0.277960
[23:05:06.368] iteration 13468 : model1 loss : 0.172861 model2 loss : 0.183353
[23:05:06.706] iteration 13469 : model1 loss : 0.157436 model2 loss : 0.146855
[23:05:07.043] iteration 13470 : model1 loss : 0.179653 model2 loss : 0.220385
[23:05:07.383] iteration 13471 : model1 loss : 0.295827 model2 loss : 0.280592
[23:05:07.719] iteration 13472 : model1 loss : 0.197036 model2 loss : 0.202354
[23:05:08.059] iteration 13473 : model1 loss : 0.234600 model2 loss : 0.251759
[23:05:08.396] iteration 13474 : model1 loss : 0.223389 model2 loss : 0.178944
[23:05:08.731] iteration 13475 : model1 loss : 0.299723 model2 loss : 0.367607
[23:05:09.068] iteration 13476 : model1 loss : 0.259009 model2 loss : 0.310996
[23:05:09.401] iteration 13477 : model1 loss : 0.234994 model2 loss : 0.212983
[23:05:09.738] iteration 13478 : model1 loss : 0.187192 model2 loss : 0.243382
[23:05:10.075] iteration 13479 : model1 loss : 0.293993 model2 loss : 0.318250
[23:05:10.412] iteration 13480 : model1 loss : 0.210108 model2 loss : 0.202145
[23:05:10.755] iteration 13481 : model1 loss : 0.248265 model2 loss : 0.273641
[23:05:11.092] iteration 13482 : model1 loss : 0.280863 model2 loss : 0.302242
[23:05:11.429] iteration 13483 : model1 loss : 0.264521 model2 loss : 0.381880
[23:05:11.768] iteration 13484 : model1 loss : 0.168263 model2 loss : 0.204721
[23:05:12.101] iteration 13485 : model1 loss : 0.200570 model2 loss : 0.167191
[23:05:12.439] iteration 13486 : model1 loss : 0.180173 model2 loss : 0.205011
[23:05:12.776] iteration 13487 : model1 loss : 0.248460 model2 loss : 0.315900
[23:05:13.114] iteration 13488 : model1 loss : 0.151877 model2 loss : 0.200166
[23:05:13.463] iteration 13489 : model1 loss : 0.245441 model2 loss : 0.303705
[23:05:13.806] iteration 13490 : model1 loss : 0.286795 model2 loss : 0.326508
[23:05:14.146] iteration 13491 : model1 loss : 0.241363 model2 loss : 0.237352
[23:05:14.489] iteration 13492 : model1 loss : 0.345480 model2 loss : 0.395730
[23:05:14.837] iteration 13493 : model1 loss : 0.214784 model2 loss : 0.242114
[23:05:15.178] iteration 13494 : model1 loss : 0.213338 model2 loss : 0.272329
[23:05:15.519] iteration 13495 : model1 loss : 0.249116 model2 loss : 0.212518
[23:05:15.858] iteration 13496 : model1 loss : 0.191784 model2 loss : 0.222993
[23:05:16.200] iteration 13497 : model1 loss : 0.282212 model2 loss : 0.343805
[23:05:16.540] iteration 13498 : model1 loss : 0.171953 model2 loss : 0.236360
[23:05:16.878] iteration 13499 : model1 loss : 0.191140 model2 loss : 0.220331
[23:05:17.221] iteration 13500 : model1 loss : 0.319760 model2 loss : 0.376631
[23:05:17.846] iteration 13501 : model1 loss : 0.319803 model2 loss : 0.337053
[23:05:18.178] iteration 13502 : model1 loss : 0.123203 model2 loss : 0.116322
[23:05:18.509] iteration 13503 : model1 loss : 0.144585 model2 loss : 0.181676
[23:05:18.839] iteration 13504 : model1 loss : 0.121106 model2 loss : 0.133131
[23:05:19.167] iteration 13505 : model1 loss : 0.132255 model2 loss : 0.183336
[23:05:19.497] iteration 13506 : model1 loss : 0.164954 model2 loss : 0.194769
[23:05:19.828] iteration 13507 : model1 loss : 0.185142 model2 loss : 0.235613
[23:05:20.158] iteration 13508 : model1 loss : 0.283015 model2 loss : 0.398829
[23:05:20.494] iteration 13509 : model1 loss : 0.238019 model2 loss : 0.239742
[23:05:20.826] iteration 13510 : model1 loss : 0.324598 model2 loss : 0.286579
[23:05:21.157] iteration 13511 : model1 loss : 0.164176 model2 loss : 0.206244
[23:05:21.488] iteration 13512 : model1 loss : 0.190813 model2 loss : 0.215337
[23:05:21.814] iteration 13513 : model1 loss : 0.236767 model2 loss : 0.251249
[23:05:22.147] iteration 13514 : model1 loss : 0.200787 model2 loss : 0.216072
[23:05:22.479] iteration 13515 : model1 loss : 0.201556 model2 loss : 0.224388
[23:05:22.807] iteration 13516 : model1 loss : 0.230645 model2 loss : 0.259260
[23:05:23.145] iteration 13517 : model1 loss : 0.193703 model2 loss : 0.179314
[23:05:23.477] iteration 13518 : model1 loss : 0.270216 model2 loss : 0.319678
[23:05:23.815] iteration 13519 : model1 loss : 0.236108 model2 loss : 0.314048
[23:05:24.155] iteration 13520 : model1 loss : 0.118240 model2 loss : 0.219573
[23:05:24.493] iteration 13521 : model1 loss : 0.350647 model2 loss : 0.365437
[23:05:24.828] iteration 13522 : model1 loss : 0.158369 model2 loss : 0.150918
[23:05:25.166] iteration 13523 : model1 loss : 0.220392 model2 loss : 0.298755
[23:05:25.504] iteration 13524 : model1 loss : 0.193633 model2 loss : 0.200793
[23:05:25.840] iteration 13525 : model1 loss : 0.248794 model2 loss : 0.246197
[23:05:26.182] iteration 13526 : model1 loss : 0.248349 model2 loss : 0.295040
[23:05:26.526] iteration 13527 : model1 loss : 0.208796 model2 loss : 0.261191
[23:05:26.860] iteration 13528 : model1 loss : 0.258621 model2 loss : 0.282084
[23:05:27.202] iteration 13529 : model1 loss : 0.197121 model2 loss : 0.225215
[23:05:27.538] iteration 13530 : model1 loss : 0.167923 model2 loss : 0.222269
[23:05:27.876] iteration 13531 : model1 loss : 0.174833 model2 loss : 0.182486
[23:05:28.216] iteration 13532 : model1 loss : 0.216857 model2 loss : 0.318011
[23:05:28.555] iteration 13533 : model1 loss : 0.307008 model2 loss : 0.298080
[23:05:28.891] iteration 13534 : model1 loss : 0.127701 model2 loss : 0.213843
[23:05:29.234] iteration 13535 : model1 loss : 0.211899 model2 loss : 0.242468
[23:05:29.570] iteration 13536 : model1 loss : 0.202109 model2 loss : 0.149092
[23:05:29.908] iteration 13537 : model1 loss : 0.224007 model2 loss : 0.252141
[23:05:30.246] iteration 13538 : model1 loss : 0.265779 model2 loss : 0.288522
[23:05:30.584] iteration 13539 : model1 loss : 0.211404 model2 loss : 0.257947
[23:05:30.927] iteration 13540 : model1 loss : 0.251307 model2 loss : 0.266052
[23:05:31.258] iteration 13541 : model1 loss : 0.287702 model2 loss : 0.308557
[23:05:31.591] iteration 13542 : model1 loss : 0.194298 model2 loss : 0.287037
[23:05:31.921] iteration 13543 : model1 loss : 0.180437 model2 loss : 0.206903
[23:05:32.249] iteration 13544 : model1 loss : 0.089344 model2 loss : 0.140566
[23:05:32.579] iteration 13545 : model1 loss : 0.241501 model2 loss : 0.185117
[23:05:32.908] iteration 13546 : model1 loss : 0.207533 model2 loss : 0.236310
[23:05:33.238] iteration 13547 : model1 loss : 0.362477 model2 loss : 0.333191
[23:05:33.567] iteration 13548 : model1 loss : 0.186039 model2 loss : 0.192858
[23:05:33.895] iteration 13549 : model1 loss : 0.219541 model2 loss : 0.213910
[23:05:34.224] iteration 13550 : model1 loss : 0.286807 model2 loss : 0.348709
[23:05:34.812] iteration 13551 : model1 loss : 0.240880 model2 loss : 0.247442
[23:05:35.143] iteration 13552 : model1 loss : 0.212756 model2 loss : 0.218279
[23:05:35.472] iteration 13553 : model1 loss : 0.297300 model2 loss : 0.305125
[23:05:35.800] iteration 13554 : model1 loss : 0.254635 model2 loss : 0.318841
[23:05:36.130] iteration 13555 : model1 loss : 0.076918 model2 loss : 0.081440
[23:05:36.459] iteration 13556 : model1 loss : 0.307097 model2 loss : 0.370121
[23:05:36.792] iteration 13557 : model1 loss : 0.269265 model2 loss : 0.251657
[23:05:37.122] iteration 13558 : model1 loss : 0.177281 model2 loss : 0.224925
[23:05:37.454] iteration 13559 : model1 loss : 0.159714 model2 loss : 0.160885
[23:05:37.785] iteration 13560 : model1 loss : 0.273119 model2 loss : 0.274768
[23:05:38.117] iteration 13561 : model1 loss : 0.140219 model2 loss : 0.142209
[23:05:38.447] iteration 13562 : model1 loss : 0.153588 model2 loss : 0.167629
[23:05:38.778] iteration 13563 : model1 loss : 0.247346 model2 loss : 0.276646
[23:05:39.110] iteration 13564 : model1 loss : 0.166313 model2 loss : 0.194282
[23:05:39.441] iteration 13565 : model1 loss : 0.263210 model2 loss : 0.289630
[23:05:39.770] iteration 13566 : model1 loss : 0.229373 model2 loss : 0.278979
[23:05:40.100] iteration 13567 : model1 loss : 0.188149 model2 loss : 0.176593
[23:05:40.432] iteration 13568 : model1 loss : 0.291942 model2 loss : 0.331307
[23:05:40.793] iteration 13569 : model1 loss : 0.173091 model2 loss : 0.200592
[23:05:41.151] iteration 13570 : model1 loss : 0.290959 model2 loss : 0.355053
[23:05:41.495] iteration 13571 : model1 loss : 0.230523 model2 loss : 0.285369
[23:05:41.843] iteration 13572 : model1 loss : 0.195448 model2 loss : 0.338036
[23:05:42.205] iteration 13573 : model1 loss : 0.240937 model2 loss : 0.302820
[23:05:42.554] iteration 13574 : model1 loss : 0.328736 model2 loss : 0.333150
[23:05:42.912] iteration 13575 : model1 loss : 0.187598 model2 loss : 0.209407
[23:05:43.254] iteration 13576 : model1 loss : 0.169086 model2 loss : 0.203202
[23:05:43.592] iteration 13577 : model1 loss : 0.248873 model2 loss : 0.237276
[23:05:43.941] iteration 13578 : model1 loss : 0.242476 model2 loss : 0.372232
[23:05:44.291] iteration 13579 : model1 loss : 0.215114 model2 loss : 0.207270
[23:05:44.646] iteration 13580 : model1 loss : 0.160286 model2 loss : 0.228583
[23:05:44.983] iteration 13581 : model1 loss : 0.129411 model2 loss : 0.170813
[23:05:45.333] iteration 13582 : model1 loss : 0.336256 model2 loss : 0.336395
[23:05:45.681] iteration 13583 : model1 loss : 0.197283 model2 loss : 0.203055
[23:05:46.033] iteration 13584 : model1 loss : 0.234364 model2 loss : 0.308497
[23:05:46.393] iteration 13585 : model1 loss : 0.266574 model2 loss : 0.282424
[23:05:46.735] iteration 13586 : model1 loss : 0.206698 model2 loss : 0.197040
[23:05:47.090] iteration 13587 : model1 loss : 0.229949 model2 loss : 0.260617
[23:05:47.442] iteration 13588 : model1 loss : 0.250825 model2 loss : 0.288140
[23:05:47.790] iteration 13589 : model1 loss : 0.217289 model2 loss : 0.269165
[23:05:48.154] iteration 13590 : model1 loss : 0.185046 model2 loss : 0.219550
[23:05:48.494] iteration 13591 : model1 loss : 0.244664 model2 loss : 0.245911
[23:05:48.844] iteration 13592 : model1 loss : 0.223347 model2 loss : 0.266397
[23:05:49.192] iteration 13593 : model1 loss : 0.185692 model2 loss : 0.209397
[23:05:49.535] iteration 13594 : model1 loss : 0.296229 model2 loss : 0.335190
[23:05:49.879] iteration 13595 : model1 loss : 0.145518 model2 loss : 0.207999
[23:05:50.218] iteration 13596 : model1 loss : 0.185155 model2 loss : 0.211212
[23:05:50.558] iteration 13597 : model1 loss : 0.245597 model2 loss : 0.271170
[23:05:50.897] iteration 13598 : model1 loss : 0.115110 model2 loss : 0.134295
[23:05:51.236] iteration 13599 : model1 loss : 0.267046 model2 loss : 0.267735
[23:05:51.577] iteration 13600 : model1 loss : 0.107762 model2 loss : 0.123548
[23:05:52.265] iteration 13601 : model1 loss : 0.204319 model2 loss : 0.201352
[23:05:52.609] iteration 13602 : model1 loss : 0.221824 model2 loss : 0.200273
[23:05:52.960] iteration 13603 : model1 loss : 0.148257 model2 loss : 0.155622
[23:05:53.307] iteration 13604 : model1 loss : 0.219599 model2 loss : 0.242517
[23:05:53.657] iteration 13605 : model1 loss : 0.318796 model2 loss : 0.331558
[23:05:54.015] iteration 13606 : model1 loss : 0.309264 model2 loss : 0.274758
[23:05:54.362] iteration 13607 : model1 loss : 0.177344 model2 loss : 0.236048
[23:05:54.714] iteration 13608 : model1 loss : 0.265061 model2 loss : 0.285974
[23:05:55.060] iteration 13609 : model1 loss : 0.294921 model2 loss : 0.367767
[23:05:55.410] iteration 13610 : model1 loss : 0.250969 model2 loss : 0.358286
[23:05:55.769] iteration 13611 : model1 loss : 0.289998 model2 loss : 0.273623
[23:05:56.107] iteration 13612 : model1 loss : 0.367501 model2 loss : 0.410514
[23:05:56.449] iteration 13613 : model1 loss : 0.111520 model2 loss : 0.184574
[23:05:56.788] iteration 13614 : model1 loss : 0.099164 model2 loss : 0.178077
[23:05:57.131] iteration 13615 : model1 loss : 0.261574 model2 loss : 0.299917
[23:05:57.468] iteration 13616 : model1 loss : 0.265401 model2 loss : 0.277770
[23:05:57.807] iteration 13617 : model1 loss : 0.204135 model2 loss : 0.210475
[23:05:58.145] iteration 13618 : model1 loss : 0.195129 model2 loss : 0.279955
[23:05:58.482] iteration 13619 : model1 loss : 0.259030 model2 loss : 0.275030
[23:05:58.819] iteration 13620 : model1 loss : 0.156971 model2 loss : 0.206428
[23:05:59.159] iteration 13621 : model1 loss : 0.174397 model2 loss : 0.208654
[23:05:59.496] iteration 13622 : model1 loss : 0.306211 model2 loss : 0.314521
[23:05:59.832] iteration 13623 : model1 loss : 0.164639 model2 loss : 0.115826
[23:06:00.168] iteration 13624 : model1 loss : 0.216502 model2 loss : 0.192597
[23:06:00.500] iteration 13625 : model1 loss : 0.158114 model2 loss : 0.121686
[23:06:01.616] iteration 13626 : model1 loss : 0.165996 model2 loss : 0.177996
[23:06:01.955] iteration 13627 : model1 loss : 0.203941 model2 loss : 0.156952
[23:06:02.298] iteration 13628 : model1 loss : 0.265033 model2 loss : 0.297234
[23:06:02.642] iteration 13629 : model1 loss : 0.158291 model2 loss : 0.224682
[23:06:02.989] iteration 13630 : model1 loss : 0.279344 model2 loss : 0.269741
[23:06:03.326] iteration 13631 : model1 loss : 0.186665 model2 loss : 0.233267
[23:06:03.665] iteration 13632 : model1 loss : 0.108080 model2 loss : 0.101415
[23:06:04.003] iteration 13633 : model1 loss : 0.211382 model2 loss : 0.223831
[23:06:04.342] iteration 13634 : model1 loss : 0.284766 model2 loss : 0.293724
[23:06:04.690] iteration 13635 : model1 loss : 0.147200 model2 loss : 0.161415
[23:06:05.033] iteration 13636 : model1 loss : 0.214806 model2 loss : 0.241151
[23:06:05.375] iteration 13637 : model1 loss : 0.187554 model2 loss : 0.200459
[23:06:05.713] iteration 13638 : model1 loss : 0.260084 model2 loss : 0.326783
[23:06:06.051] iteration 13639 : model1 loss : 0.266406 model2 loss : 0.272962
[23:06:06.391] iteration 13640 : model1 loss : 0.178971 model2 loss : 0.228818
[23:06:06.730] iteration 13641 : model1 loss : 0.233733 model2 loss : 0.276829
[23:06:07.069] iteration 13642 : model1 loss : 0.148305 model2 loss : 0.177822
[23:06:07.409] iteration 13643 : model1 loss : 0.179876 model2 loss : 0.220365
[23:06:07.747] iteration 13644 : model1 loss : 0.323452 model2 loss : 0.329622
[23:06:08.090] iteration 13645 : model1 loss : 0.215198 model2 loss : 0.239549
[23:06:08.428] iteration 13646 : model1 loss : 0.177026 model2 loss : 0.218297
[23:06:08.764] iteration 13647 : model1 loss : 0.273323 model2 loss : 0.240240
[23:06:09.108] iteration 13648 : model1 loss : 0.099670 model2 loss : 0.184570
[23:06:09.446] iteration 13649 : model1 loss : 0.172795 model2 loss : 0.167305
[23:06:09.788] iteration 13650 : model1 loss : 0.243967 model2 loss : 0.336661
[23:06:10.444] iteration 13651 : model1 loss : 0.223181 model2 loss : 0.275940
[23:06:10.785] iteration 13652 : model1 loss : 0.254610 model2 loss : 0.309297
[23:06:11.125] iteration 13653 : model1 loss : 0.260692 model2 loss : 0.277180
[23:06:11.468] iteration 13654 : model1 loss : 0.186376 model2 loss : 0.273609
[23:06:11.807] iteration 13655 : model1 loss : 0.116769 model2 loss : 0.185232
[23:06:12.143] iteration 13656 : model1 loss : 0.205936 model2 loss : 0.240008
[23:06:12.482] iteration 13657 : model1 loss : 0.163079 model2 loss : 0.234150
[23:06:12.818] iteration 13658 : model1 loss : 0.097348 model2 loss : 0.222053
[23:06:13.156] iteration 13659 : model1 loss : 0.170513 model2 loss : 0.161419
[23:06:13.493] iteration 13660 : model1 loss : 0.227363 model2 loss : 0.246997
[23:06:13.830] iteration 13661 : model1 loss : 0.269298 model2 loss : 0.315832
[23:06:14.166] iteration 13662 : model1 loss : 0.337665 model2 loss : 0.313476
[23:06:14.503] iteration 13663 : model1 loss : 0.232809 model2 loss : 0.183025
[23:06:14.845] iteration 13664 : model1 loss : 0.161975 model2 loss : 0.185370
[23:06:15.183] iteration 13665 : model1 loss : 0.178116 model2 loss : 0.209344
[23:06:15.525] iteration 13666 : model1 loss : 0.134987 model2 loss : 0.160021
[23:06:15.861] iteration 13667 : model1 loss : 0.278209 model2 loss : 0.297657
[23:06:16.198] iteration 13668 : model1 loss : 0.267961 model2 loss : 0.273977
[23:06:16.535] iteration 13669 : model1 loss : 0.210664 model2 loss : 0.207692
[23:06:16.874] iteration 13670 : model1 loss : 0.203937 model2 loss : 0.209274
[23:06:17.211] iteration 13671 : model1 loss : 0.303594 model2 loss : 0.368433
[23:06:17.550] iteration 13672 : model1 loss : 0.264151 model2 loss : 0.298825
[23:06:17.891] iteration 13673 : model1 loss : 0.306474 model2 loss : 0.331475
[23:06:18.230] iteration 13674 : model1 loss : 0.331529 model2 loss : 0.356003
[23:06:18.569] iteration 13675 : model1 loss : 0.354252 model2 loss : 0.276718
[23:06:18.906] iteration 13676 : model1 loss : 0.312852 model2 loss : 0.249337
[23:06:19.244] iteration 13677 : model1 loss : 0.325075 model2 loss : 0.350638
[23:06:19.582] iteration 13678 : model1 loss : 0.234178 model2 loss : 0.302954
[23:06:19.919] iteration 13679 : model1 loss : 0.152981 model2 loss : 0.273686
[23:06:20.256] iteration 13680 : model1 loss : 0.177938 model2 loss : 0.213913
[23:06:20.595] iteration 13681 : model1 loss : 0.185818 model2 loss : 0.207793
[23:06:20.932] iteration 13682 : model1 loss : 0.265662 model2 loss : 0.330724
[23:06:21.271] iteration 13683 : model1 loss : 0.278263 model2 loss : 0.327149
[23:06:21.611] iteration 13684 : model1 loss : 0.261135 model2 loss : 0.293438
[23:06:21.948] iteration 13685 : model1 loss : 0.232253 model2 loss : 0.300278
[23:06:22.288] iteration 13686 : model1 loss : 0.211862 model2 loss : 0.215777
[23:06:22.626] iteration 13687 : model1 loss : 0.196612 model2 loss : 0.267228
[23:06:22.963] iteration 13688 : model1 loss : 0.248583 model2 loss : 0.289831
[23:06:23.303] iteration 13689 : model1 loss : 0.171716 model2 loss : 0.228798
[23:06:23.640] iteration 13690 : model1 loss : 0.244685 model2 loss : 0.296506
[23:06:23.978] iteration 13691 : model1 loss : 0.106370 model2 loss : 0.122942
[23:06:24.318] iteration 13692 : model1 loss : 0.080444 model2 loss : 0.138868
[23:06:24.657] iteration 13693 : model1 loss : 0.229456 model2 loss : 0.242923
[23:06:24.994] iteration 13694 : model1 loss : 0.225731 model2 loss : 0.239313
[23:06:25.333] iteration 13695 : model1 loss : 0.097552 model2 loss : 0.162599
[23:06:25.670] iteration 13696 : model1 loss : 0.124125 model2 loss : 0.171446
[23:06:26.011] iteration 13697 : model1 loss : 0.215577 model2 loss : 0.239329
[23:06:26.359] iteration 13698 : model1 loss : 0.199426 model2 loss : 0.165822
[23:06:26.700] iteration 13699 : model1 loss : 0.185233 model2 loss : 0.255589
[23:06:27.038] iteration 13700 : model1 loss : 0.244234 model2 loss : 0.225858
[23:06:27.729] iteration 13701 : model1 loss : 0.244259 model2 loss : 0.253837
[23:06:28.075] iteration 13702 : model1 loss : 0.248912 model2 loss : 0.277928
[23:06:28.416] iteration 13703 : model1 loss : 0.199001 model2 loss : 0.317520
[23:06:28.757] iteration 13704 : model1 loss : 0.281908 model2 loss : 0.279088
[23:06:29.096] iteration 13705 : model1 loss : 0.127354 model2 loss : 0.239880
[23:06:29.433] iteration 13706 : model1 loss : 0.144107 model2 loss : 0.210973
[23:06:29.770] iteration 13707 : model1 loss : 0.241360 model2 loss : 0.267670
[23:06:30.111] iteration 13708 : model1 loss : 0.140652 model2 loss : 0.149422
[23:06:30.452] iteration 13709 : model1 loss : 0.254564 model2 loss : 0.298463
[23:06:30.789] iteration 13710 : model1 loss : 0.254545 model2 loss : 0.325912
[23:06:31.119] iteration 13711 : model1 loss : 0.140028 model2 loss : 0.207470
[23:06:31.449] iteration 13712 : model1 loss : 0.264549 model2 loss : 0.287800
[23:06:31.780] iteration 13713 : model1 loss : 0.255379 model2 loss : 0.310708
[23:06:32.109] iteration 13714 : model1 loss : 0.264936 model2 loss : 0.291746
[23:06:32.438] iteration 13715 : model1 loss : 0.193504 model2 loss : 0.242972
[23:06:32.772] iteration 13716 : model1 loss : 0.217144 model2 loss : 0.235634
[23:06:33.101] iteration 13717 : model1 loss : 0.271850 model2 loss : 0.301167
[23:06:33.429] iteration 13718 : model1 loss : 0.175089 model2 loss : 0.272727
[23:06:33.765] iteration 13719 : model1 loss : 0.173645 model2 loss : 0.188782
[23:06:34.098] iteration 13720 : model1 loss : 0.315242 model2 loss : 0.356734
[23:06:34.429] iteration 13721 : model1 loss : 0.142838 model2 loss : 0.237279
[23:06:34.757] iteration 13722 : model1 loss : 0.244694 model2 loss : 0.224276
[23:06:35.086] iteration 13723 : model1 loss : 0.200754 model2 loss : 0.226044
[23:06:35.416] iteration 13724 : model1 loss : 0.218148 model2 loss : 0.241583
[23:06:35.750] iteration 13725 : model1 loss : 0.088630 model2 loss : 0.135354
[23:06:36.081] iteration 13726 : model1 loss : 0.174217 model2 loss : 0.195870
[23:06:36.411] iteration 13727 : model1 loss : 0.230104 model2 loss : 0.233568
[23:06:36.739] iteration 13728 : model1 loss : 0.281845 model2 loss : 0.304888
[23:06:37.069] iteration 13729 : model1 loss : 0.197998 model2 loss : 0.232077
[23:06:37.398] iteration 13730 : model1 loss : 0.208374 model2 loss : 0.260815
[23:06:37.731] iteration 13731 : model1 loss : 0.126916 model2 loss : 0.145087
[23:06:38.061] iteration 13732 : model1 loss : 0.192197 model2 loss : 0.215267
[23:06:38.391] iteration 13733 : model1 loss : 0.182117 model2 loss : 0.200321
[23:06:38.721] iteration 13734 : model1 loss : 0.280845 model2 loss : 0.283187
[23:06:39.050] iteration 13735 : model1 loss : 0.173804 model2 loss : 0.195494
[23:06:39.380] iteration 13736 : model1 loss : 0.187627 model2 loss : 0.187406
[23:06:39.710] iteration 13737 : model1 loss : 0.221177 model2 loss : 0.257393
[23:06:40.040] iteration 13738 : model1 loss : 0.292381 model2 loss : 0.397476
[23:06:40.369] iteration 13739 : model1 loss : 0.185620 model2 loss : 0.180073
[23:06:40.697] iteration 13740 : model1 loss : 0.209360 model2 loss : 0.142230
[23:06:41.026] iteration 13741 : model1 loss : 0.206359 model2 loss : 0.230188
[23:06:41.364] iteration 13742 : model1 loss : 0.192512 model2 loss : 0.286136
[23:06:41.694] iteration 13743 : model1 loss : 0.197070 model2 loss : 0.235967
[23:06:42.026] iteration 13744 : model1 loss : 0.252142 model2 loss : 0.271108
[23:06:42.355] iteration 13745 : model1 loss : 0.251965 model2 loss : 0.243138
[23:06:42.684] iteration 13746 : model1 loss : 0.149444 model2 loss : 0.179979
[23:06:43.018] iteration 13747 : model1 loss : 0.306865 model2 loss : 0.320135
[23:06:43.346] iteration 13748 : model1 loss : 0.258547 model2 loss : 0.289886
[23:06:43.675] iteration 13749 : model1 loss : 0.285721 model2 loss : 0.277071
[23:06:44.006] iteration 13750 : model1 loss : 0.196566 model2 loss : 0.246990
[23:06:44.554] iteration 13751 : model1 loss : 0.135038 model2 loss : 0.144883
[23:06:44.883] iteration 13752 : model1 loss : 0.271363 model2 loss : 0.244244
[23:06:45.213] iteration 13753 : model1 loss : 0.134726 model2 loss : 0.138756
[23:06:45.543] iteration 13754 : model1 loss : 0.182040 model2 loss : 0.278433
[23:06:45.873] iteration 13755 : model1 loss : 0.311357 model2 loss : 0.280856
[23:06:46.212] iteration 13756 : model1 loss : 0.184185 model2 loss : 0.204704
[23:06:46.550] iteration 13757 : model1 loss : 0.148410 model2 loss : 0.260940
[23:06:46.887] iteration 13758 : model1 loss : 0.275221 model2 loss : 0.274093
[23:06:47.229] iteration 13759 : model1 loss : 0.189690 model2 loss : 0.240495
[23:06:47.567] iteration 13760 : model1 loss : 0.191875 model2 loss : 0.159965
[23:06:47.909] iteration 13761 : model1 loss : 0.260004 model2 loss : 0.214180
[23:06:48.248] iteration 13762 : model1 loss : 0.316444 model2 loss : 0.358968
[23:06:48.592] iteration 13763 : model1 loss : 0.263726 model2 loss : 0.327161
[23:06:48.929] iteration 13764 : model1 loss : 0.230906 model2 loss : 0.296597
[23:06:49.268] iteration 13765 : model1 loss : 0.262365 model2 loss : 0.282929
[23:06:49.606] iteration 13766 : model1 loss : 0.306698 model2 loss : 0.319305
[23:06:49.943] iteration 13767 : model1 loss : 0.122150 model2 loss : 0.168192
[23:06:50.283] iteration 13768 : model1 loss : 0.237063 model2 loss : 0.225583
[23:06:50.624] iteration 13769 : model1 loss : 0.318396 model2 loss : 0.245198
[23:06:50.964] iteration 13770 : model1 loss : 0.262556 model2 loss : 0.302591
[23:06:51.303] iteration 13771 : model1 loss : 0.228908 model2 loss : 0.234427
[23:06:51.641] iteration 13772 : model1 loss : 0.272838 model2 loss : 0.281139
[23:06:51.979] iteration 13773 : model1 loss : 0.244465 model2 loss : 0.254029
[23:06:52.320] iteration 13774 : model1 loss : 0.275773 model2 loss : 0.323758
[23:06:52.658] iteration 13775 : model1 loss : 0.222480 model2 loss : 0.209850
[23:06:52.996] iteration 13776 : model1 loss : 0.200741 model2 loss : 0.190834
[23:06:53.336] iteration 13777 : model1 loss : 0.283742 model2 loss : 0.288464
[23:06:53.674] iteration 13778 : model1 loss : 0.281502 model2 loss : 0.338739
[23:06:54.010] iteration 13779 : model1 loss : 0.292404 model2 loss : 0.282612
[23:06:54.348] iteration 13780 : model1 loss : 0.276603 model2 loss : 0.273256
[23:06:54.689] iteration 13781 : model1 loss : 0.202579 model2 loss : 0.175274
[23:06:55.026] iteration 13782 : model1 loss : 0.259954 model2 loss : 0.284124
[23:06:55.363] iteration 13783 : model1 loss : 0.238707 model2 loss : 0.260917
[23:06:55.701] iteration 13784 : model1 loss : 0.222414 model2 loss : 0.260593
[23:06:56.038] iteration 13785 : model1 loss : 0.166088 model2 loss : 0.170512
[23:06:56.375] iteration 13786 : model1 loss : 0.245648 model2 loss : 0.243728
[23:06:56.713] iteration 13787 : model1 loss : 0.251509 model2 loss : 0.281865
[23:06:57.051] iteration 13788 : model1 loss : 0.179486 model2 loss : 0.232342
[23:06:57.395] iteration 13789 : model1 loss : 0.202894 model2 loss : 0.256665
[23:06:57.733] iteration 13790 : model1 loss : 0.243107 model2 loss : 0.218005
[23:06:58.070] iteration 13791 : model1 loss : 0.401133 model2 loss : 0.411001
[23:06:58.408] iteration 13792 : model1 loss : 0.198920 model2 loss : 0.212031
[23:06:58.749] iteration 13793 : model1 loss : 0.183365 model2 loss : 0.223032
[23:06:59.091] iteration 13794 : model1 loss : 0.150980 model2 loss : 0.182349
[23:06:59.434] iteration 13795 : model1 loss : 0.206736 model2 loss : 0.238467
[23:06:59.778] iteration 13796 : model1 loss : 0.209315 model2 loss : 0.200859
[23:07:00.114] iteration 13797 : model1 loss : 0.291183 model2 loss : 0.308768
[23:07:00.455] iteration 13798 : model1 loss : 0.226481 model2 loss : 0.284173
[23:07:00.792] iteration 13799 : model1 loss : 0.350315 model2 loss : 0.202277
[23:07:01.131] iteration 13800 : model1 loss : 0.216584 model2 loss : 0.260859
[23:07:01.784] iteration 13801 : model1 loss : 0.321934 model2 loss : 0.366142
[23:07:02.123] iteration 13802 : model1 loss : 0.179828 model2 loss : 0.188777
[23:07:02.459] iteration 13803 : model1 loss : 0.102950 model2 loss : 0.170070
[23:07:02.796] iteration 13804 : model1 loss : 0.248840 model2 loss : 0.271194
[23:07:03.133] iteration 13805 : model1 loss : 0.249262 model2 loss : 0.250122
[23:07:03.475] iteration 13806 : model1 loss : 0.175968 model2 loss : 0.182258
[23:07:03.812] iteration 13807 : model1 loss : 0.188963 model2 loss : 0.260910
[23:07:04.152] iteration 13808 : model1 loss : 0.207311 model2 loss : 0.232189
[23:07:04.488] iteration 13809 : model1 loss : 0.194856 model2 loss : 0.207304
[23:07:04.828] iteration 13810 : model1 loss : 0.206695 model2 loss : 0.200141
[23:07:05.165] iteration 13811 : model1 loss : 0.177267 model2 loss : 0.212611
[23:07:05.507] iteration 13812 : model1 loss : 0.139471 model2 loss : 0.245070
[23:07:05.847] iteration 13813 : model1 loss : 0.123291 model2 loss : 0.152943
[23:07:06.184] iteration 13814 : model1 loss : 0.231511 model2 loss : 0.256190
[23:07:06.523] iteration 13815 : model1 loss : 0.327450 model2 loss : 0.320677
[23:07:06.864] iteration 13816 : model1 loss : 0.218700 model2 loss : 0.280587
[23:07:07.205] iteration 13817 : model1 loss : 0.189301 model2 loss : 0.301942
[23:07:07.544] iteration 13818 : model1 loss : 0.185941 model2 loss : 0.244238
[23:07:07.886] iteration 13819 : model1 loss : 0.168795 model2 loss : 0.194189
[23:07:08.227] iteration 13820 : model1 loss : 0.219219 model2 loss : 0.238129
[23:07:08.565] iteration 13821 : model1 loss : 0.177954 model2 loss : 0.215840
[23:07:08.905] iteration 13822 : model1 loss : 0.181614 model2 loss : 0.268606
[23:07:09.241] iteration 13823 : model1 loss : 0.169354 model2 loss : 0.194523
[23:07:09.583] iteration 13824 : model1 loss : 0.192989 model2 loss : 0.226491
[23:07:09.922] iteration 13825 : model1 loss : 0.251712 model2 loss : 0.275548
[23:07:10.264] iteration 13826 : model1 loss : 0.296557 model2 loss : 0.290163
[23:07:10.604] iteration 13827 : model1 loss : 0.321688 model2 loss : 0.339949
[23:07:10.943] iteration 13828 : model1 loss : 0.318142 model2 loss : 0.298016
[23:07:11.281] iteration 13829 : model1 loss : 0.215166 model2 loss : 0.220813
[23:07:11.618] iteration 13830 : model1 loss : 0.196119 model2 loss : 0.268857
[23:07:11.959] iteration 13831 : model1 loss : 0.111375 model2 loss : 0.109909
[23:07:12.306] iteration 13832 : model1 loss : 0.279490 model2 loss : 0.287696
[23:07:12.651] iteration 13833 : model1 loss : 0.276487 model2 loss : 0.307801
[23:07:12.993] iteration 13834 : model1 loss : 0.273563 model2 loss : 0.303135
[23:07:13.331] iteration 13835 : model1 loss : 0.213626 model2 loss : 0.264377
[23:07:13.671] iteration 13836 : model1 loss : 0.190517 model2 loss : 0.180509
[23:07:14.019] iteration 13837 : model1 loss : 0.270223 model2 loss : 0.318112
[23:07:14.355] iteration 13838 : model1 loss : 0.266103 model2 loss : 0.279155
[23:07:14.695] iteration 13839 : model1 loss : 0.300191 model2 loss : 0.352205
[23:07:15.037] iteration 13840 : model1 loss : 0.110544 model2 loss : 0.160875
[23:07:15.375] iteration 13841 : model1 loss : 0.358412 model2 loss : 0.340418
[23:07:15.718] iteration 13842 : model1 loss : 0.192023 model2 loss : 0.215588
[23:07:16.057] iteration 13843 : model1 loss : 0.212269 model2 loss : 0.261447
[23:07:16.395] iteration 13844 : model1 loss : 0.237743 model2 loss : 0.222393
[23:07:16.732] iteration 13845 : model1 loss : 0.121460 model2 loss : 0.229170
[23:07:17.075] iteration 13846 : model1 loss : 0.308341 model2 loss : 0.379755
[23:07:17.414] iteration 13847 : model1 loss : 0.173993 model2 loss : 0.200379
[23:07:17.759] iteration 13848 : model1 loss : 0.184122 model2 loss : 0.252112
[23:07:18.101] iteration 13849 : model1 loss : 0.302860 model2 loss : 0.275795
[23:07:18.440] iteration 13850 : model1 loss : 0.247853 model2 loss : 0.241403
[23:07:19.090] iteration 13851 : model1 loss : 0.172737 model2 loss : 0.274847
[23:07:19.429] iteration 13852 : model1 loss : 0.273199 model2 loss : 0.277614
[23:07:19.768] iteration 13853 : model1 loss : 0.209184 model2 loss : 0.270881
[23:07:20.110] iteration 13854 : model1 loss : 0.112511 model2 loss : 0.172933
[23:07:20.452] iteration 13855 : model1 loss : 0.233318 model2 loss : 0.252874
[23:07:20.792] iteration 13856 : model1 loss : 0.213424 model2 loss : 0.256262
[23:07:21.129] iteration 13857 : model1 loss : 0.230106 model2 loss : 0.237629
[23:07:21.470] iteration 13858 : model1 loss : 0.097083 model2 loss : 0.172723
[23:07:21.814] iteration 13859 : model1 loss : 0.295718 model2 loss : 0.285694
[23:07:22.151] iteration 13860 : model1 loss : 0.315873 model2 loss : 0.338017
[23:07:22.492] iteration 13861 : model1 loss : 0.170981 model2 loss : 0.182595
[23:07:22.832] iteration 13862 : model1 loss : 0.136436 model2 loss : 0.166027
[23:07:23.176] iteration 13863 : model1 loss : 0.262797 model2 loss : 0.306547
[23:07:23.515] iteration 13864 : model1 loss : 0.170417 model2 loss : 0.171497
[23:07:23.854] iteration 13865 : model1 loss : 0.347903 model2 loss : 0.342521
[23:07:24.192] iteration 13866 : model1 loss : 0.094340 model2 loss : 0.129360
[23:07:24.532] iteration 13867 : model1 loss : 0.261927 model2 loss : 0.336093
[23:07:24.873] iteration 13868 : model1 loss : 0.172973 model2 loss : 0.309266
[23:07:25.215] iteration 13869 : model1 loss : 0.186688 model2 loss : 0.213492
[23:07:25.553] iteration 13870 : model1 loss : 0.183143 model2 loss : 0.194356
[23:07:25.897] iteration 13871 : model1 loss : 0.259060 model2 loss : 0.284904
[23:07:26.237] iteration 13872 : model1 loss : 0.161452 model2 loss : 0.247488
[23:07:26.577] iteration 13873 : model1 loss : 0.290056 model2 loss : 0.309313
[23:07:26.917] iteration 13874 : model1 loss : 0.096000 model2 loss : 0.166103
[23:07:27.257] iteration 13875 : model1 loss : 0.222186 model2 loss : 0.283694
[23:07:27.595] iteration 13876 : model1 loss : 0.279902 model2 loss : 0.284298
[23:07:27.936] iteration 13877 : model1 loss : 0.209366 model2 loss : 0.257805
[23:07:28.276] iteration 13878 : model1 loss : 0.193546 model2 loss : 0.203150
[23:07:28.614] iteration 13879 : model1 loss : 0.201673 model2 loss : 0.262508
[23:07:28.952] iteration 13880 : model1 loss : 0.235524 model2 loss : 0.296016
[23:07:29.293] iteration 13881 : model1 loss : 0.246451 model2 loss : 0.285375
[23:07:29.631] iteration 13882 : model1 loss : 0.234294 model2 loss : 0.268599
[23:07:29.970] iteration 13883 : model1 loss : 0.284811 model2 loss : 0.339026
[23:07:30.315] iteration 13884 : model1 loss : 0.184608 model2 loss : 0.235116
[23:07:30.658] iteration 13885 : model1 loss : 0.203318 model2 loss : 0.219938
[23:07:31.003] iteration 13886 : model1 loss : 0.209148 model2 loss : 0.168845
[23:07:31.342] iteration 13887 : model1 loss : 0.213511 model2 loss : 0.317250
[23:07:31.679] iteration 13888 : model1 loss : 0.320122 model2 loss : 0.320463
[23:07:32.018] iteration 13889 : model1 loss : 0.293070 model2 loss : 0.321559
[23:07:32.356] iteration 13890 : model1 loss : 0.358516 model2 loss : 0.362098
[23:07:32.696] iteration 13891 : model1 loss : 0.206285 model2 loss : 0.234959
[23:07:33.037] iteration 13892 : model1 loss : 0.263819 model2 loss : 0.298346
[23:07:33.378] iteration 13893 : model1 loss : 0.275112 model2 loss : 0.236602
[23:07:33.717] iteration 13894 : model1 loss : 0.151690 model2 loss : 0.210554
[23:07:34.055] iteration 13895 : model1 loss : 0.255669 model2 loss : 0.288585
[23:07:34.393] iteration 13896 : model1 loss : 0.282561 model2 loss : 0.257430
[23:07:34.732] iteration 13897 : model1 loss : 0.254271 model2 loss : 0.190923
[23:07:35.071] iteration 13898 : model1 loss : 0.135140 model2 loss : 0.129076
[23:07:35.420] iteration 13899 : model1 loss : 0.277565 model2 loss : 0.301261
[23:07:35.761] iteration 13900 : model1 loss : 0.313178 model2 loss : 0.300052
[23:07:36.406] iteration 13901 : model1 loss : 0.088789 model2 loss : 0.134972
[23:07:36.750] iteration 13902 : model1 loss : 0.190367 model2 loss : 0.223956
[23:07:37.089] iteration 13903 : model1 loss : 0.178500 model2 loss : 0.155902
[23:07:37.432] iteration 13904 : model1 loss : 0.333812 model2 loss : 0.352530
[23:07:37.770] iteration 13905 : model1 loss : 0.135107 model2 loss : 0.131095
[23:07:38.108] iteration 13906 : model1 loss : 0.220624 model2 loss : 0.281288
[23:07:38.455] iteration 13907 : model1 loss : 0.221385 model2 loss : 0.252286
[23:07:38.792] iteration 13908 : model1 loss : 0.174675 model2 loss : 0.199078
[23:07:39.131] iteration 13909 : model1 loss : 0.157552 model2 loss : 0.169581
[23:07:39.468] iteration 13910 : model1 loss : 0.177481 model2 loss : 0.198421
[23:07:39.806] iteration 13911 : model1 loss : 0.283794 model2 loss : 0.226658
[23:07:40.144] iteration 13912 : model1 loss : 0.178297 model2 loss : 0.212807
[23:07:40.483] iteration 13913 : model1 loss : 0.264330 model2 loss : 0.352901
[23:07:40.821] iteration 13914 : model1 loss : 0.273542 model2 loss : 0.315516
[23:07:41.165] iteration 13915 : model1 loss : 0.196217 model2 loss : 0.248311
[23:07:41.503] iteration 13916 : model1 loss : 0.223479 model2 loss : 0.207937
[23:07:41.841] iteration 13917 : model1 loss : 0.206964 model2 loss : 0.346612
[23:07:42.179] iteration 13918 : model1 loss : 0.234523 model2 loss : 0.262894
[23:07:42.516] iteration 13919 : model1 loss : 0.107891 model2 loss : 0.152042
[23:07:42.857] iteration 13920 : model1 loss : 0.196839 model2 loss : 0.204510
[23:07:43.196] iteration 13921 : model1 loss : 0.124599 model2 loss : 0.158022
[23:07:43.533] iteration 13922 : model1 loss : 0.185911 model2 loss : 0.207676
[23:07:43.870] iteration 13923 : model1 loss : 0.261579 model2 loss : 0.279423
[23:07:44.209] iteration 13924 : model1 loss : 0.210645 model2 loss : 0.249168
[23:07:44.548] iteration 13925 : model1 loss : 0.173764 model2 loss : 0.182453
[23:07:44.885] iteration 13926 : model1 loss : 0.140630 model2 loss : 0.141702
[23:07:45.222] iteration 13927 : model1 loss : 0.187179 model2 loss : 0.195774
[23:07:45.565] iteration 13928 : model1 loss : 0.197667 model2 loss : 0.236883
[23:07:45.903] iteration 13929 : model1 loss : 0.200017 model2 loss : 0.309125
[23:07:46.240] iteration 13930 : model1 loss : 0.262402 model2 loss : 0.323297
[23:07:46.578] iteration 13931 : model1 loss : 0.220760 model2 loss : 0.253610
[23:07:46.919] iteration 13932 : model1 loss : 0.103068 model2 loss : 0.161248
[23:07:47.256] iteration 13933 : model1 loss : 0.187011 model2 loss : 0.271373
[23:07:47.595] iteration 13934 : model1 loss : 0.189985 model2 loss : 0.278667
[23:07:47.931] iteration 13935 : model1 loss : 0.246581 model2 loss : 0.290428
[23:07:48.268] iteration 13936 : model1 loss : 0.244403 model2 loss : 0.297585
[23:07:48.607] iteration 13937 : model1 loss : 0.196728 model2 loss : 0.262577
[23:07:48.947] iteration 13938 : model1 loss : 0.185309 model2 loss : 0.224359
[23:07:49.287] iteration 13939 : model1 loss : 0.115615 model2 loss : 0.162860
[23:07:49.625] iteration 13940 : model1 loss : 0.218659 model2 loss : 0.228887
[23:07:49.965] iteration 13941 : model1 loss : 0.269874 model2 loss : 0.285268
[23:07:50.306] iteration 13942 : model1 loss : 0.281534 model2 loss : 0.324589
[23:07:50.645] iteration 13943 : model1 loss : 0.304739 model2 loss : 0.256899
[23:07:50.989] iteration 13944 : model1 loss : 0.194165 model2 loss : 0.239932
[23:07:51.330] iteration 13945 : model1 loss : 0.221237 model2 loss : 0.189300
[23:07:51.678] iteration 13946 : model1 loss : 0.102929 model2 loss : 0.164960
[23:07:52.015] iteration 13947 : model1 loss : 0.400150 model2 loss : 0.404192
[23:07:52.355] iteration 13948 : model1 loss : 0.139072 model2 loss : 0.186321
[23:07:52.697] iteration 13949 : model1 loss : 0.200899 model2 loss : 0.201711
[23:07:53.034] iteration 13950 : model1 loss : 0.196599 model2 loss : 0.273338
[23:07:53.687] iteration 13951 : model1 loss : 0.171885 model2 loss : 0.166554
[23:07:54.025] iteration 13952 : model1 loss : 0.295478 model2 loss : 0.314898
[23:07:54.366] iteration 13953 : model1 loss : 0.202970 model2 loss : 0.231049
[23:07:54.707] iteration 13954 : model1 loss : 0.254996 model2 loss : 0.286031
[23:07:55.046] iteration 13955 : model1 loss : 0.160385 model2 loss : 0.165923
[23:07:55.385] iteration 13956 : model1 loss : 0.157212 model2 loss : 0.185439
[23:07:55.723] iteration 13957 : model1 loss : 0.110413 model2 loss : 0.122188
[23:07:56.061] iteration 13958 : model1 loss : 0.285662 model2 loss : 0.260933
[23:07:56.402] iteration 13959 : model1 loss : 0.147892 model2 loss : 0.197041
[23:07:56.739] iteration 13960 : model1 loss : 0.165461 model2 loss : 0.229819
[23:07:57.086] iteration 13961 : model1 loss : 0.165952 model2 loss : 0.189649
[23:07:57.424] iteration 13962 : model1 loss : 0.142795 model2 loss : 0.218088
[23:07:57.763] iteration 13963 : model1 loss : 0.257954 model2 loss : 0.317829
[23:07:58.101] iteration 13964 : model1 loss : 0.202024 model2 loss : 0.237686
[23:07:58.444] iteration 13965 : model1 loss : 0.217092 model2 loss : 0.225971
[23:07:58.785] iteration 13966 : model1 loss : 0.204899 model2 loss : 0.258607
[23:07:59.122] iteration 13967 : model1 loss : 0.183835 model2 loss : 0.201572
[23:07:59.468] iteration 13968 : model1 loss : 0.207715 model2 loss : 0.285652
[23:07:59.805] iteration 13969 : model1 loss : 0.171463 model2 loss : 0.198242
[23:08:00.139] iteration 13970 : model1 loss : 0.190877 model2 loss : 0.237064
[23:08:00.483] iteration 13971 : model1 loss : 0.240442 model2 loss : 0.345429
[23:08:00.823] iteration 13972 : model1 loss : 0.137015 model2 loss : 0.197991
[23:08:01.161] iteration 13973 : model1 loss : 0.139408 model2 loss : 0.229540
[23:08:01.502] iteration 13974 : model1 loss : 0.222143 model2 loss : 0.224149
[23:08:01.844] iteration 13975 : model1 loss : 0.253491 model2 loss : 0.303403
[23:08:02.181] iteration 13976 : model1 loss : 0.327958 model2 loss : 0.388041
[23:08:02.519] iteration 13977 : model1 loss : 0.138994 model2 loss : 0.135063
[23:08:02.861] iteration 13978 : model1 loss : 0.235516 model2 loss : 0.247467
[23:08:03.207] iteration 13979 : model1 loss : 0.287977 model2 loss : 0.295342
[23:08:03.547] iteration 13980 : model1 loss : 0.253621 model2 loss : 0.267674
[23:08:03.886] iteration 13981 : model1 loss : 0.169369 model2 loss : 0.245059
[23:08:04.226] iteration 13982 : model1 loss : 0.185435 model2 loss : 0.250590
[23:08:04.563] iteration 13983 : model1 loss : 0.304761 model2 loss : 0.320687
[23:08:04.903] iteration 13984 : model1 loss : 0.247477 model2 loss : 0.310883
[23:08:05.241] iteration 13985 : model1 loss : 0.174297 model2 loss : 0.194040
[23:08:05.581] iteration 13986 : model1 loss : 0.188970 model2 loss : 0.212077
[23:08:05.920] iteration 13987 : model1 loss : 0.208578 model2 loss : 0.239315
[23:08:06.258] iteration 13988 : model1 loss : 0.386307 model2 loss : 0.369314
[23:08:06.598] iteration 13989 : model1 loss : 0.218460 model2 loss : 0.314452
[23:08:06.936] iteration 13990 : model1 loss : 0.146413 model2 loss : 0.164977
[23:08:07.275] iteration 13991 : model1 loss : 0.124457 model2 loss : 0.146703
[23:08:07.616] iteration 13992 : model1 loss : 0.272936 model2 loss : 0.267538
[23:08:07.954] iteration 13993 : model1 loss : 0.241012 model2 loss : 0.197050
[23:08:08.295] iteration 13994 : model1 loss : 0.275569 model2 loss : 0.314824
[23:08:08.636] iteration 13995 : model1 loss : 0.204112 model2 loss : 0.234377
[23:08:08.974] iteration 13996 : model1 loss : 0.285861 model2 loss : 0.294476
[23:08:09.314] iteration 13997 : model1 loss : 0.333081 model2 loss : 0.261483
[23:08:09.652] iteration 13998 : model1 loss : 0.144712 model2 loss : 0.201004
[23:08:09.993] iteration 13999 : model1 loss : 0.195882 model2 loss : 0.226289
[23:08:10.337] iteration 14000 : model1 loss : 0.171893 model2 loss : 0.254238
[23:08:10.941] iteration 14001 : model1 loss : 0.216966 model2 loss : 0.220924
[23:08:11.270] iteration 14002 : model1 loss : 0.180121 model2 loss : 0.202476
[23:08:11.600] iteration 14003 : model1 loss : 0.214435 model2 loss : 0.298388
[23:08:11.931] iteration 14004 : model1 loss : 0.342620 model2 loss : 0.380519
[23:08:12.260] iteration 14005 : model1 loss : 0.358633 model2 loss : 0.262605
[23:08:12.588] iteration 14006 : model1 loss : 0.253641 model2 loss : 0.230067
[23:08:12.918] iteration 14007 : model1 loss : 0.209686 model2 loss : 0.310963
[23:08:13.248] iteration 14008 : model1 loss : 0.176918 model2 loss : 0.173289
[23:08:13.577] iteration 14009 : model1 loss : 0.091552 model2 loss : 0.119419
[23:08:13.906] iteration 14010 : model1 loss : 0.214780 model2 loss : 0.206079
[23:08:14.238] iteration 14011 : model1 loss : 0.223432 model2 loss : 0.264019
[23:08:14.566] iteration 14012 : model1 loss : 0.273273 model2 loss : 0.282569
[23:08:14.896] iteration 14013 : model1 loss : 0.226168 model2 loss : 0.177578
[23:08:15.224] iteration 14014 : model1 loss : 0.174440 model2 loss : 0.182979
[23:08:15.555] iteration 14015 : model1 loss : 0.211100 model2 loss : 0.226121
[23:08:15.884] iteration 14016 : model1 loss : 0.191212 model2 loss : 0.209053
[23:08:16.213] iteration 14017 : model1 loss : 0.235718 model2 loss : 0.309844
[23:08:16.542] iteration 14018 : model1 loss : 0.157480 model2 loss : 0.171524
[23:08:16.871] iteration 14019 : model1 loss : 0.167290 model2 loss : 0.248632
[23:08:17.200] iteration 14020 : model1 loss : 0.338077 model2 loss : 0.286681
[23:08:17.530] iteration 14021 : model1 loss : 0.179221 model2 loss : 0.176963
[23:08:17.859] iteration 14022 : model1 loss : 0.185091 model2 loss : 0.202208
[23:08:18.189] iteration 14023 : model1 loss : 0.245875 model2 loss : 0.319724
[23:08:18.526] iteration 14024 : model1 loss : 0.254400 model2 loss : 0.325166
[23:08:18.864] iteration 14025 : model1 loss : 0.219193 model2 loss : 0.223927
[23:08:19.203] iteration 14026 : model1 loss : 0.195201 model2 loss : 0.193189
[23:08:19.540] iteration 14027 : model1 loss : 0.243283 model2 loss : 0.242284
[23:08:19.878] iteration 14028 : model1 loss : 0.154489 model2 loss : 0.220707
[23:08:20.218] iteration 14029 : model1 loss : 0.167768 model2 loss : 0.166540
[23:08:20.556] iteration 14030 : model1 loss : 0.168991 model2 loss : 0.199161
[23:08:20.897] iteration 14031 : model1 loss : 0.199114 model2 loss : 0.230578
[23:08:21.235] iteration 14032 : model1 loss : 0.279025 model2 loss : 0.259735
[23:08:21.575] iteration 14033 : model1 loss : 0.167564 model2 loss : 0.186543
[23:08:21.912] iteration 14034 : model1 loss : 0.295268 model2 loss : 0.322790
[23:08:22.243] iteration 14035 : model1 loss : 0.199912 model2 loss : 0.201460
[23:08:22.572] iteration 14036 : model1 loss : 0.169311 model2 loss : 0.176185
[23:08:22.902] iteration 14037 : model1 loss : 0.274202 model2 loss : 0.265134
[23:08:23.232] iteration 14038 : model1 loss : 0.178988 model2 loss : 0.179262
[23:08:23.561] iteration 14039 : model1 loss : 0.249651 model2 loss : 0.259116
[23:08:23.890] iteration 14040 : model1 loss : 0.172687 model2 loss : 0.248285
[23:08:24.222] iteration 14041 : model1 loss : 0.165414 model2 loss : 0.210869
[23:08:24.555] iteration 14042 : model1 loss : 0.172597 model2 loss : 0.224376
[23:08:24.885] iteration 14043 : model1 loss : 0.168791 model2 loss : 0.223302
[23:08:25.220] iteration 14044 : model1 loss : 0.330389 model2 loss : 0.331472
[23:08:25.549] iteration 14045 : model1 loss : 0.175699 model2 loss : 0.179848
[23:08:25.880] iteration 14046 : model1 loss : 0.210379 model2 loss : 0.245765
[23:08:26.210] iteration 14047 : model1 loss : 0.141325 model2 loss : 0.198576
[23:08:26.540] iteration 14048 : model1 loss : 0.181546 model2 loss : 0.249167
[23:08:26.872] iteration 14049 : model1 loss : 0.388328 model2 loss : 0.379887
[23:08:27.203] iteration 14050 : model1 loss : 0.247996 model2 loss : 0.204133
[23:08:27.734] iteration 14051 : model1 loss : 0.201974 model2 loss : 0.222777
[23:08:28.064] iteration 14052 : model1 loss : 0.308322 model2 loss : 0.320413
[23:08:28.395] iteration 14053 : model1 loss : 0.179353 model2 loss : 0.208212
[23:08:28.725] iteration 14054 : model1 loss : 0.249980 model2 loss : 0.281631
[23:08:29.057] iteration 14055 : model1 loss : 0.179828 model2 loss : 0.208907
[23:08:29.387] iteration 14056 : model1 loss : 0.231430 model2 loss : 0.314919
[23:08:29.719] iteration 14057 : model1 loss : 0.270122 model2 loss : 0.321322
[23:08:30.050] iteration 14058 : model1 loss : 0.106495 model2 loss : 0.179983
[23:08:30.382] iteration 14059 : model1 loss : 0.317588 model2 loss : 0.325733
[23:08:30.713] iteration 14060 : model1 loss : 0.170126 model2 loss : 0.219303
[23:08:31.044] iteration 14061 : model1 loss : 0.173456 model2 loss : 0.174514
[23:08:31.376] iteration 14062 : model1 loss : 0.290176 model2 loss : 0.271104
[23:08:31.707] iteration 14063 : model1 loss : 0.123268 model2 loss : 0.158211
[23:08:32.037] iteration 14064 : model1 loss : 0.134208 model2 loss : 0.137512
[23:08:32.367] iteration 14065 : model1 loss : 0.092283 model2 loss : 0.164896
[23:08:32.697] iteration 14066 : model1 loss : 0.187002 model2 loss : 0.196461
[23:08:33.028] iteration 14067 : model1 loss : 0.098692 model2 loss : 0.125113
[23:08:33.359] iteration 14068 : model1 loss : 0.250775 model2 loss : 0.355013
[23:08:33.689] iteration 14069 : model1 loss : 0.220791 model2 loss : 0.187426
[23:08:34.021] iteration 14070 : model1 loss : 0.267858 model2 loss : 0.313308
[23:08:34.350] iteration 14071 : model1 loss : 0.227959 model2 loss : 0.250791
[23:08:34.680] iteration 14072 : model1 loss : 0.151580 model2 loss : 0.167271
[23:08:35.012] iteration 14073 : model1 loss : 0.254059 model2 loss : 0.296508
[23:08:35.344] iteration 14074 : model1 loss : 0.211473 model2 loss : 0.236756
[23:08:35.674] iteration 14075 : model1 loss : 0.274231 model2 loss : 0.268648
[23:08:36.003] iteration 14076 : model1 loss : 0.184009 model2 loss : 0.191350
[23:08:36.335] iteration 14077 : model1 loss : 0.095484 model2 loss : 0.115784
[23:08:36.664] iteration 14078 : model1 loss : 0.368899 model2 loss : 0.282378
[23:08:36.995] iteration 14079 : model1 loss : 0.266770 model2 loss : 0.304643
[23:08:37.327] iteration 14080 : model1 loss : 0.327884 model2 loss : 0.330122
[23:08:37.657] iteration 14081 : model1 loss : 0.156004 model2 loss : 0.257599
[23:08:37.987] iteration 14082 : model1 loss : 0.176485 model2 loss : 0.223257
[23:08:38.317] iteration 14083 : model1 loss : 0.166206 model2 loss : 0.216428
[23:08:38.647] iteration 14084 : model1 loss : 0.112694 model2 loss : 0.171114
[23:08:38.979] iteration 14085 : model1 loss : 0.283281 model2 loss : 0.335230
[23:08:39.309] iteration 14086 : model1 loss : 0.326122 model2 loss : 0.329340
[23:08:39.639] iteration 14087 : model1 loss : 0.100761 model2 loss : 0.111099
[23:08:39.966] iteration 14088 : model1 loss : 0.188399 model2 loss : 0.236398
[23:08:40.293] iteration 14089 : model1 loss : 0.177824 model2 loss : 0.242842
[23:08:40.620] iteration 14090 : model1 loss : 0.168739 model2 loss : 0.251890
[23:08:40.947] iteration 14091 : model1 loss : 0.158862 model2 loss : 0.188346
[23:08:41.274] iteration 14092 : model1 loss : 0.268669 model2 loss : 0.298728
[23:08:41.600] iteration 14093 : model1 loss : 0.251369 model2 loss : 0.322371
[23:08:41.927] iteration 14094 : model1 loss : 0.251897 model2 loss : 0.310580
[23:08:42.255] iteration 14095 : model1 loss : 0.279562 model2 loss : 0.320242
[23:08:42.582] iteration 14096 : model1 loss : 0.171437 model2 loss : 0.168652
[23:08:42.909] iteration 14097 : model1 loss : 0.387744 model2 loss : 0.225546
[23:08:43.235] iteration 14098 : model1 loss : 0.308739 model2 loss : 0.302317
[23:08:43.562] iteration 14099 : model1 loss : 0.318372 model2 loss : 0.345716
[23:08:43.889] iteration 14100 : model1 loss : 0.167452 model2 loss : 0.200980
[23:08:44.394] iteration 14101 : model1 loss : 0.207708 model2 loss : 0.247941
[23:08:44.721] iteration 14102 : model1 loss : 0.282881 model2 loss : 0.305974
[23:08:45.050] iteration 14103 : model1 loss : 0.182352 model2 loss : 0.198755
[23:08:45.377] iteration 14104 : model1 loss : 0.092319 model2 loss : 0.130623
[23:08:45.704] iteration 14105 : model1 loss : 0.229885 model2 loss : 0.308794
[23:08:46.034] iteration 14106 : model1 loss : 0.256850 model2 loss : 0.265067
[23:08:46.362] iteration 14107 : model1 loss : 0.252449 model2 loss : 0.258756
[23:08:46.689] iteration 14108 : model1 loss : 0.181883 model2 loss : 0.286144
[23:08:47.015] iteration 14109 : model1 loss : 0.164367 model2 loss : 0.164129
[23:08:47.343] iteration 14110 : model1 loss : 0.240714 model2 loss : 0.220223
[23:08:47.686] iteration 14111 : model1 loss : 0.229022 model2 loss : 0.234438
[23:08:48.027] iteration 14112 : model1 loss : 0.232490 model2 loss : 0.203452
[23:08:48.364] iteration 14113 : model1 loss : 0.181528 model2 loss : 0.186741
[23:08:48.704] iteration 14114 : model1 loss : 0.270324 model2 loss : 0.299718
[23:08:49.045] iteration 14115 : model1 loss : 0.120602 model2 loss : 0.177780
[23:08:49.388] iteration 14116 : model1 loss : 0.240220 model2 loss : 0.260084
[23:08:49.727] iteration 14117 : model1 loss : 0.321648 model2 loss : 0.337974
[23:08:50.069] iteration 14118 : model1 loss : 0.124717 model2 loss : 0.162741
[23:08:50.414] iteration 14119 : model1 loss : 0.304460 model2 loss : 0.271403
[23:08:50.757] iteration 14120 : model1 loss : 0.093509 model2 loss : 0.176438
[23:08:51.096] iteration 14121 : model1 loss : 0.305464 model2 loss : 0.287363
[23:08:51.435] iteration 14122 : model1 loss : 0.238629 model2 loss : 0.128857
[23:08:51.775] iteration 14123 : model1 loss : 0.161186 model2 loss : 0.150185
[23:08:52.116] iteration 14124 : model1 loss : 0.299041 model2 loss : 0.297549
[23:08:52.448] iteration 14125 : model1 loss : 0.121837 model2 loss : 0.154018
[23:08:52.790] iteration 14126 : model1 loss : 0.182436 model2 loss : 0.251452
[23:08:53.129] iteration 14127 : model1 loss : 0.285494 model2 loss : 0.267718
[23:08:53.469] iteration 14128 : model1 loss : 0.194239 model2 loss : 0.275323
[23:08:53.808] iteration 14129 : model1 loss : 0.264025 model2 loss : 0.230723
[23:08:54.148] iteration 14130 : model1 loss : 0.199214 model2 loss : 0.205007
[23:08:54.490] iteration 14131 : model1 loss : 0.279896 model2 loss : 0.305796
[23:08:54.829] iteration 14132 : model1 loss : 0.198981 model2 loss : 0.219811
[23:08:55.166] iteration 14133 : model1 loss : 0.171129 model2 loss : 0.190733
[23:08:55.509] iteration 14134 : model1 loss : 0.342557 model2 loss : 0.334292
[23:08:55.848] iteration 14135 : model1 loss : 0.171800 model2 loss : 0.235659
[23:08:56.192] iteration 14136 : model1 loss : 0.233564 model2 loss : 0.244057
[23:08:56.535] iteration 14137 : model1 loss : 0.150916 model2 loss : 0.200074
[23:08:56.875] iteration 14138 : model1 loss : 0.101517 model2 loss : 0.137308
[23:08:57.215] iteration 14139 : model1 loss : 0.261619 model2 loss : 0.188488
[23:08:57.554] iteration 14140 : model1 loss : 0.296234 model2 loss : 0.309805
[23:08:57.891] iteration 14141 : model1 loss : 0.266396 model2 loss : 0.303110
[23:08:58.231] iteration 14142 : model1 loss : 0.309614 model2 loss : 0.324344
[23:08:58.575] iteration 14143 : model1 loss : 0.173514 model2 loss : 0.260162
[23:08:58.919] iteration 14144 : model1 loss : 0.311698 model2 loss : 0.290177
[23:08:59.258] iteration 14145 : model1 loss : 0.185777 model2 loss : 0.214164
[23:08:59.599] iteration 14146 : model1 loss : 0.184094 model2 loss : 0.219402
[23:08:59.939] iteration 14147 : model1 loss : 0.132429 model2 loss : 0.197820
[23:09:00.280] iteration 14148 : model1 loss : 0.226799 model2 loss : 0.230620
[23:09:00.622] iteration 14149 : model1 loss : 0.111359 model2 loss : 0.236698
[23:09:00.961] iteration 14150 : model1 loss : 0.236436 model2 loss : 0.265793
[23:09:01.608] iteration 14151 : model1 loss : 0.162077 model2 loss : 0.166890
[23:09:01.947] iteration 14152 : model1 loss : 0.283116 model2 loss : 0.320934
[23:09:02.290] iteration 14153 : model1 loss : 0.294848 model2 loss : 0.326207
[23:09:02.628] iteration 14154 : model1 loss : 0.283296 model2 loss : 0.323276
[23:09:02.967] iteration 14155 : model1 loss : 0.196048 model2 loss : 0.236206
[23:09:03.306] iteration 14156 : model1 loss : 0.349065 model2 loss : 0.363699
[23:09:03.645] iteration 14157 : model1 loss : 0.169243 model2 loss : 0.193867
[23:09:03.984] iteration 14158 : model1 loss : 0.111818 model2 loss : 0.128150
[23:09:04.324] iteration 14159 : model1 loss : 0.233721 model2 loss : 0.348547
[23:09:04.665] iteration 14160 : model1 loss : 0.076622 model2 loss : 0.146025
[23:09:05.005] iteration 14161 : model1 loss : 0.153926 model2 loss : 0.161944
[23:09:05.344] iteration 14162 : model1 loss : 0.301175 model2 loss : 0.278908
[23:09:05.684] iteration 14163 : model1 loss : 0.234985 model2 loss : 0.289180
[23:09:06.022] iteration 14164 : model1 loss : 0.257929 model2 loss : 0.233281
[23:09:06.360] iteration 14165 : model1 loss : 0.151767 model2 loss : 0.160881
[23:09:06.705] iteration 14166 : model1 loss : 0.181934 model2 loss : 0.233658
[23:09:07.047] iteration 14167 : model1 loss : 0.147358 model2 loss : 0.158184
[23:09:07.385] iteration 14168 : model1 loss : 0.183559 model2 loss : 0.202811
[23:09:07.725] iteration 14169 : model1 loss : 0.227986 model2 loss : 0.350205
[23:09:08.063] iteration 14170 : model1 loss : 0.088988 model2 loss : 0.149970
[23:09:09.181] iteration 14171 : model1 loss : 0.206325 model2 loss : 0.271765
[23:09:09.520] iteration 14172 : model1 loss : 0.066020 model2 loss : 0.078305
[23:09:09.863] iteration 14173 : model1 loss : 0.187855 model2 loss : 0.218565
[23:09:10.201] iteration 14174 : model1 loss : 0.264371 model2 loss : 0.266898
[23:09:10.544] iteration 14175 : model1 loss : 0.226939 model2 loss : 0.210749
[23:09:10.904] iteration 14176 : model1 loss : 0.198830 model2 loss : 0.214817
[23:09:11.243] iteration 14177 : model1 loss : 0.318872 model2 loss : 0.353788
[23:09:11.582] iteration 14178 : model1 loss : 0.296569 model2 loss : 0.299890
[23:09:11.921] iteration 14179 : model1 loss : 0.266799 model2 loss : 0.311232
[23:09:12.262] iteration 14180 : model1 loss : 0.100154 model2 loss : 0.165652
[23:09:12.599] iteration 14181 : model1 loss : 0.087116 model2 loss : 0.181197
[23:09:12.937] iteration 14182 : model1 loss : 0.129442 model2 loss : 0.180879
[23:09:13.275] iteration 14183 : model1 loss : 0.153868 model2 loss : 0.183233
[23:09:13.614] iteration 14184 : model1 loss : 0.237033 model2 loss : 0.280617
[23:09:13.953] iteration 14185 : model1 loss : 0.187472 model2 loss : 0.210242
[23:09:14.295] iteration 14186 : model1 loss : 0.175248 model2 loss : 0.220379
[23:09:14.634] iteration 14187 : model1 loss : 0.400381 model2 loss : 0.404988
[23:09:14.981] iteration 14188 : model1 loss : 0.191850 model2 loss : 0.235637
[23:09:15.324] iteration 14189 : model1 loss : 0.227981 model2 loss : 0.225048
[23:09:15.665] iteration 14190 : model1 loss : 0.265490 model2 loss : 0.295537
[23:09:16.002] iteration 14191 : model1 loss : 0.164631 model2 loss : 0.192574
[23:09:16.344] iteration 14192 : model1 loss : 0.122785 model2 loss : 0.156422
[23:09:16.685] iteration 14193 : model1 loss : 0.201066 model2 loss : 0.293308
[23:09:17.023] iteration 14194 : model1 loss : 0.183828 model2 loss : 0.219270
[23:09:17.361] iteration 14195 : model1 loss : 0.216787 model2 loss : 0.206385
[23:09:17.704] iteration 14196 : model1 loss : 0.159790 model2 loss : 0.215513
[23:09:18.047] iteration 14197 : model1 loss : 0.177226 model2 loss : 0.185566
[23:09:18.386] iteration 14198 : model1 loss : 0.220088 model2 loss : 0.306028
[23:09:18.727] iteration 14199 : model1 loss : 0.235242 model2 loss : 0.260469
[23:09:19.065] iteration 14200 : model1 loss : 0.175082 model2 loss : 0.220244
[23:09:19.716] iteration 14201 : model1 loss : 0.249885 model2 loss : 0.292615
[23:09:20.055] iteration 14202 : model1 loss : 0.264775 model2 loss : 0.325992
[23:09:20.394] iteration 14203 : model1 loss : 0.167202 model2 loss : 0.191008
[23:09:20.733] iteration 14204 : model1 loss : 0.285437 model2 loss : 0.376674
[23:09:21.075] iteration 14205 : model1 loss : 0.206185 model2 loss : 0.254696
[23:09:21.414] iteration 14206 : model1 loss : 0.325673 model2 loss : 0.340136
[23:09:21.752] iteration 14207 : model1 loss : 0.203431 model2 loss : 0.255817
[23:09:22.091] iteration 14208 : model1 loss : 0.215048 model2 loss : 0.126608
[23:09:22.434] iteration 14209 : model1 loss : 0.181508 model2 loss : 0.249997
[23:09:22.776] iteration 14210 : model1 loss : 0.161701 model2 loss : 0.218957
[23:09:23.117] iteration 14211 : model1 loss : 0.116293 model2 loss : 0.145971
[23:09:23.458] iteration 14212 : model1 loss : 0.121512 model2 loss : 0.119944
[23:09:23.798] iteration 14213 : model1 loss : 0.208822 model2 loss : 0.134024
[23:09:24.140] iteration 14214 : model1 loss : 0.210523 model2 loss : 0.261649
[23:09:24.479] iteration 14215 : model1 loss : 0.167859 model2 loss : 0.254277
[23:09:24.821] iteration 14216 : model1 loss : 0.281181 model2 loss : 0.346122
[23:09:25.161] iteration 14217 : model1 loss : 0.234251 model2 loss : 0.260479
[23:09:25.504] iteration 14218 : model1 loss : 0.176828 model2 loss : 0.277473
[23:09:25.842] iteration 14219 : model1 loss : 0.264986 model2 loss : 0.370462
[23:09:26.184] iteration 14220 : model1 loss : 0.178313 model2 loss : 0.170112
[23:09:26.512] iteration 14221 : model1 loss : 0.129609 model2 loss : 0.172191
[23:09:26.844] iteration 14222 : model1 loss : 0.193729 model2 loss : 0.313728
[23:09:27.174] iteration 14223 : model1 loss : 0.222850 model2 loss : 0.214430
[23:09:27.502] iteration 14224 : model1 loss : 0.219507 model2 loss : 0.219973
[23:09:27.831] iteration 14225 : model1 loss : 0.284971 model2 loss : 0.293495
[23:09:28.160] iteration 14226 : model1 loss : 0.288993 model2 loss : 0.272510
[23:09:28.488] iteration 14227 : model1 loss : 0.197775 model2 loss : 0.206398
[23:09:28.818] iteration 14228 : model1 loss : 0.131470 model2 loss : 0.155269
[23:09:29.149] iteration 14229 : model1 loss : 0.317639 model2 loss : 0.377602
[23:09:29.479] iteration 14230 : model1 loss : 0.174804 model2 loss : 0.207946
[23:09:29.808] iteration 14231 : model1 loss : 0.238195 model2 loss : 0.252689
[23:09:30.138] iteration 14232 : model1 loss : 0.266328 model2 loss : 0.289637
[23:09:30.467] iteration 14233 : model1 loss : 0.244127 model2 loss : 0.270019
[23:09:30.798] iteration 14234 : model1 loss : 0.148458 model2 loss : 0.166393
[23:09:31.130] iteration 14235 : model1 loss : 0.167533 model2 loss : 0.286417
[23:09:31.459] iteration 14236 : model1 loss : 0.134996 model2 loss : 0.148870
[23:09:31.789] iteration 14237 : model1 loss : 0.163865 model2 loss : 0.155109
[23:09:32.118] iteration 14238 : model1 loss : 0.101113 model2 loss : 0.152893
[23:09:32.450] iteration 14239 : model1 loss : 0.242696 model2 loss : 0.258976
[23:09:32.779] iteration 14240 : model1 loss : 0.254941 model2 loss : 0.290949
[23:09:33.108] iteration 14241 : model1 loss : 0.142197 model2 loss : 0.128267
[23:09:33.436] iteration 14242 : model1 loss : 0.293214 model2 loss : 0.327573
[23:09:33.766] iteration 14243 : model1 loss : 0.178496 model2 loss : 0.251095
[23:09:34.096] iteration 14244 : model1 loss : 0.193183 model2 loss : 0.196550
[23:09:34.427] iteration 14245 : model1 loss : 0.132018 model2 loss : 0.155137
[23:09:34.758] iteration 14246 : model1 loss : 0.240494 model2 loss : 0.168496
[23:09:35.089] iteration 14247 : model1 loss : 0.274527 model2 loss : 0.310551
[23:09:35.421] iteration 14248 : model1 loss : 0.194949 model2 loss : 0.247759
[23:09:35.753] iteration 14249 : model1 loss : 0.216926 model2 loss : 0.268025
[23:09:36.085] iteration 14250 : model1 loss : 0.191904 model2 loss : 0.287971
[23:09:36.652] iteration 14251 : model1 loss : 0.168047 model2 loss : 0.182940
[23:09:36.983] iteration 14252 : model1 loss : 0.124897 model2 loss : 0.193265
[23:09:37.311] iteration 14253 : model1 loss : 0.229298 model2 loss : 0.352987
[23:09:37.641] iteration 14254 : model1 loss : 0.107814 model2 loss : 0.165058
[23:09:37.969] iteration 14255 : model1 loss : 0.282878 model2 loss : 0.306290
[23:09:38.299] iteration 14256 : model1 loss : 0.099224 model2 loss : 0.217789
[23:09:38.629] iteration 14257 : model1 loss : 0.170551 model2 loss : 0.224338
[23:09:38.959] iteration 14258 : model1 loss : 0.122997 model2 loss : 0.190148
[23:09:39.288] iteration 14259 : model1 loss : 0.174016 model2 loss : 0.168163
[23:09:39.618] iteration 14260 : model1 loss : 0.139772 model2 loss : 0.148669
[23:09:39.947] iteration 14261 : model1 loss : 0.299898 model2 loss : 0.262528
[23:09:40.275] iteration 14262 : model1 loss : 0.256954 model2 loss : 0.321072
[23:09:40.604] iteration 14263 : model1 loss : 0.305723 model2 loss : 0.342493
[23:09:40.932] iteration 14264 : model1 loss : 0.214003 model2 loss : 0.269812
[23:09:41.262] iteration 14265 : model1 loss : 0.224400 model2 loss : 0.203668
[23:09:41.591] iteration 14266 : model1 loss : 0.216731 model2 loss : 0.236829
[23:09:41.920] iteration 14267 : model1 loss : 0.196512 model2 loss : 0.275677
[23:09:42.248] iteration 14268 : model1 loss : 0.133579 model2 loss : 0.203437
[23:09:42.578] iteration 14269 : model1 loss : 0.211731 model2 loss : 0.221780
[23:09:42.906] iteration 14270 : model1 loss : 0.241311 model2 loss : 0.263703
[23:09:43.235] iteration 14271 : model1 loss : 0.401508 model2 loss : 0.429414
[23:09:43.564] iteration 14272 : model1 loss : 0.176229 model2 loss : 0.184386
[23:09:43.894] iteration 14273 : model1 loss : 0.289091 model2 loss : 0.291764
[23:09:44.223] iteration 14274 : model1 loss : 0.235671 model2 loss : 0.235426
[23:09:44.553] iteration 14275 : model1 loss : 0.219070 model2 loss : 0.234120
[23:09:44.882] iteration 14276 : model1 loss : 0.216254 model2 loss : 0.205695
[23:09:45.211] iteration 14277 : model1 loss : 0.305701 model2 loss : 0.282615
[23:09:45.539] iteration 14278 : model1 loss : 0.273509 model2 loss : 0.204637
[23:09:45.869] iteration 14279 : model1 loss : 0.297254 model2 loss : 0.262827
[23:09:46.198] iteration 14280 : model1 loss : 0.074976 model2 loss : 0.121642
[23:09:46.529] iteration 14281 : model1 loss : 0.124445 model2 loss : 0.211464
[23:09:46.858] iteration 14282 : model1 loss : 0.120154 model2 loss : 0.159512
[23:09:47.186] iteration 14283 : model1 loss : 0.256838 model2 loss : 0.251690
[23:09:47.517] iteration 14284 : model1 loss : 0.107948 model2 loss : 0.142196
[23:09:47.846] iteration 14285 : model1 loss : 0.207371 model2 loss : 0.244189
[23:09:48.175] iteration 14286 : model1 loss : 0.208848 model2 loss : 0.306058
[23:09:48.506] iteration 14287 : model1 loss : 0.287284 model2 loss : 0.281236
[23:09:48.835] iteration 14288 : model1 loss : 0.400078 model2 loss : 0.406029
[23:09:49.164] iteration 14289 : model1 loss : 0.170316 model2 loss : 0.166517
[23:09:49.493] iteration 14290 : model1 loss : 0.198615 model2 loss : 0.200333
[23:09:49.823] iteration 14291 : model1 loss : 0.105673 model2 loss : 0.125387
[23:09:50.153] iteration 14292 : model1 loss : 0.209028 model2 loss : 0.226821
[23:09:50.483] iteration 14293 : model1 loss : 0.243431 model2 loss : 0.317674
[23:09:50.812] iteration 14294 : model1 loss : 0.132058 model2 loss : 0.192899
[23:09:51.142] iteration 14295 : model1 loss : 0.129075 model2 loss : 0.187360
[23:09:51.474] iteration 14296 : model1 loss : 0.188590 model2 loss : 0.257236
[23:09:51.802] iteration 14297 : model1 loss : 0.238371 model2 loss : 0.284161
[23:09:52.130] iteration 14298 : model1 loss : 0.144078 model2 loss : 0.133481
[23:09:52.458] iteration 14299 : model1 loss : 0.207655 model2 loss : 0.303882
[23:09:52.787] iteration 14300 : model1 loss : 0.178179 model2 loss : 0.196605
[23:09:53.357] iteration 14301 : model1 loss : 0.114406 model2 loss : 0.170940
[23:09:53.685] iteration 14302 : model1 loss : 0.294205 model2 loss : 0.327624
[23:09:54.016] iteration 14303 : model1 loss : 0.233199 model2 loss : 0.221408
[23:09:54.344] iteration 14304 : model1 loss : 0.120902 model2 loss : 0.162171
[23:09:54.675] iteration 14305 : model1 loss : 0.191271 model2 loss : 0.237156
[23:09:55.004] iteration 14306 : model1 loss : 0.122861 model2 loss : 0.149521
[23:09:55.336] iteration 14307 : model1 loss : 0.164238 model2 loss : 0.210951
[23:09:55.666] iteration 14308 : model1 loss : 0.190299 model2 loss : 0.194908
[23:09:55.994] iteration 14309 : model1 loss : 0.309949 model2 loss : 0.326429
[23:09:56.323] iteration 14310 : model1 loss : 0.171517 model2 loss : 0.234682
[23:09:56.654] iteration 14311 : model1 loss : 0.176816 model2 loss : 0.186590
[23:09:56.982] iteration 14312 : model1 loss : 0.111944 model2 loss : 0.232422
[23:09:57.312] iteration 14313 : model1 loss : 0.292546 model2 loss : 0.296828
[23:09:57.642] iteration 14314 : model1 loss : 0.244035 model2 loss : 0.249465
[23:09:57.970] iteration 14315 : model1 loss : 0.174943 model2 loss : 0.201445
[23:09:58.298] iteration 14316 : model1 loss : 0.278823 model2 loss : 0.352124
[23:09:58.628] iteration 14317 : model1 loss : 0.181209 model2 loss : 0.273929
[23:09:58.955] iteration 14318 : model1 loss : 0.159737 model2 loss : 0.185079
[23:09:59.284] iteration 14319 : model1 loss : 0.326821 model2 loss : 0.328062
[23:09:59.614] iteration 14320 : model1 loss : 0.203584 model2 loss : 0.204355
[23:09:59.944] iteration 14321 : model1 loss : 0.229905 model2 loss : 0.298723
[23:10:00.274] iteration 14322 : model1 loss : 0.129254 model2 loss : 0.183470
[23:10:00.603] iteration 14323 : model1 loss : 0.262850 model2 loss : 0.224119
[23:10:00.933] iteration 14324 : model1 loss : 0.196030 model2 loss : 0.243857
[23:10:01.262] iteration 14325 : model1 loss : 0.186527 model2 loss : 0.225435
[23:10:01.589] iteration 14326 : model1 loss : 0.282470 model2 loss : 0.291264
[23:10:01.914] iteration 14327 : model1 loss : 0.333961 model2 loss : 0.352096
[23:10:02.240] iteration 14328 : model1 loss : 0.322856 model2 loss : 0.358428
[23:10:02.567] iteration 14329 : model1 loss : 0.175239 model2 loss : 0.212811
[23:10:02.892] iteration 14330 : model1 loss : 0.169567 model2 loss : 0.164301
[23:10:03.219] iteration 14331 : model1 loss : 0.167897 model2 loss : 0.200813
[23:10:03.545] iteration 14332 : model1 loss : 0.177813 model2 loss : 0.207698
[23:10:03.871] iteration 14333 : model1 loss : 0.106647 model2 loss : 0.123703
[23:10:04.197] iteration 14334 : model1 loss : 0.207974 model2 loss : 0.204881
[23:10:04.523] iteration 14335 : model1 loss : 0.248460 model2 loss : 0.267709
[23:10:04.850] iteration 14336 : model1 loss : 0.212820 model2 loss : 0.268608
[23:10:05.178] iteration 14337 : model1 loss : 0.179697 model2 loss : 0.188644
[23:10:05.505] iteration 14338 : model1 loss : 0.247530 model2 loss : 0.269881
[23:10:05.832] iteration 14339 : model1 loss : 0.245670 model2 loss : 0.218253
[23:10:06.158] iteration 14340 : model1 loss : 0.177397 model2 loss : 0.214895
[23:10:06.484] iteration 14341 : model1 loss : 0.243229 model2 loss : 0.264665
[23:10:06.810] iteration 14342 : model1 loss : 0.196635 model2 loss : 0.300911
[23:10:07.136] iteration 14343 : model1 loss : 0.150717 model2 loss : 0.221303
[23:10:07.463] iteration 14344 : model1 loss : 0.206395 model2 loss : 0.225271
[23:10:07.790] iteration 14345 : model1 loss : 0.271371 model2 loss : 0.246257
[23:10:08.117] iteration 14346 : model1 loss : 0.286801 model2 loss : 0.347830
[23:10:08.442] iteration 14347 : model1 loss : 0.182210 model2 loss : 0.145923
[23:10:08.769] iteration 14348 : model1 loss : 0.105537 model2 loss : 0.208139
[23:10:09.095] iteration 14349 : model1 loss : 0.101957 model2 loss : 0.134212
[23:10:09.421] iteration 14350 : model1 loss : 0.274363 model2 loss : 0.265844
[23:10:09.934] iteration 14351 : model1 loss : 0.264989 model2 loss : 0.322016
[23:10:10.261] iteration 14352 : model1 loss : 0.256428 model2 loss : 0.292171
[23:10:10.587] iteration 14353 : model1 loss : 0.212048 model2 loss : 0.229029
[23:10:10.913] iteration 14354 : model1 loss : 0.263257 model2 loss : 0.234699
[23:10:11.240] iteration 14355 : model1 loss : 0.206588 model2 loss : 0.267683
[23:10:11.565] iteration 14356 : model1 loss : 0.191929 model2 loss : 0.227911
[23:10:11.891] iteration 14357 : model1 loss : 0.301710 model2 loss : 0.400680
[23:10:12.218] iteration 14358 : model1 loss : 0.171138 model2 loss : 0.194014
[23:10:12.546] iteration 14359 : model1 loss : 0.322746 model2 loss : 0.328861
[23:10:12.872] iteration 14360 : model1 loss : 0.205073 model2 loss : 0.259658
[23:10:13.197] iteration 14361 : model1 loss : 0.270822 model2 loss : 0.309410
[23:10:13.523] iteration 14362 : model1 loss : 0.184498 model2 loss : 0.281256
[23:10:13.849] iteration 14363 : model1 loss : 0.107874 model2 loss : 0.145043
[23:10:14.175] iteration 14364 : model1 loss : 0.270567 model2 loss : 0.295532
[23:10:14.503] iteration 14365 : model1 loss : 0.235164 model2 loss : 0.261692
[23:10:14.829] iteration 14366 : model1 loss : 0.136715 model2 loss : 0.218269
[23:10:15.155] iteration 14367 : model1 loss : 0.205736 model2 loss : 0.295334
[23:10:15.482] iteration 14368 : model1 loss : 0.189181 model2 loss : 0.224510
[23:10:15.808] iteration 14369 : model1 loss : 0.083302 model2 loss : 0.093161
[23:10:16.135] iteration 14370 : model1 loss : 0.137063 model2 loss : 0.130577
[23:10:16.461] iteration 14371 : model1 loss : 0.270132 model2 loss : 0.281203
[23:10:16.788] iteration 14372 : model1 loss : 0.339548 model2 loss : 0.366696
[23:10:17.115] iteration 14373 : model1 loss : 0.146396 model2 loss : 0.168990
[23:10:17.442] iteration 14374 : model1 loss : 0.265924 model2 loss : 0.274852
[23:10:17.769] iteration 14375 : model1 loss : 0.178201 model2 loss : 0.265804
[23:10:18.094] iteration 14376 : model1 loss : 0.283234 model2 loss : 0.330635
[23:10:18.421] iteration 14377 : model1 loss : 0.194890 model2 loss : 0.256429
[23:10:18.749] iteration 14378 : model1 loss : 0.272199 model2 loss : 0.240002
[23:10:19.075] iteration 14379 : model1 loss : 0.131333 model2 loss : 0.158231
[23:10:19.401] iteration 14380 : model1 loss : 0.269213 model2 loss : 0.311997
[23:10:19.728] iteration 14381 : model1 loss : 0.288853 model2 loss : 0.325275
[23:10:20.054] iteration 14382 : model1 loss : 0.237082 model2 loss : 0.261337
[23:10:20.381] iteration 14383 : model1 loss : 0.164806 model2 loss : 0.210359
[23:10:20.707] iteration 14384 : model1 loss : 0.198223 model2 loss : 0.278594
[23:10:21.036] iteration 14385 : model1 loss : 0.180598 model2 loss : 0.221152
[23:10:21.361] iteration 14386 : model1 loss : 0.282898 model2 loss : 0.307996
[23:10:21.687] iteration 14387 : model1 loss : 0.185380 model2 loss : 0.196397
[23:10:22.014] iteration 14388 : model1 loss : 0.172090 model2 loss : 0.180772
[23:10:22.340] iteration 14389 : model1 loss : 0.094358 model2 loss : 0.111296
[23:10:22.665] iteration 14390 : model1 loss : 0.181234 model2 loss : 0.215975
[23:10:22.991] iteration 14391 : model1 loss : 0.191201 model2 loss : 0.234679
[23:10:23.317] iteration 14392 : model1 loss : 0.210166 model2 loss : 0.237510
[23:10:23.644] iteration 14393 : model1 loss : 0.095759 model2 loss : 0.164523
[23:10:23.970] iteration 14394 : model1 loss : 0.205639 model2 loss : 0.225256
[23:10:24.295] iteration 14395 : model1 loss : 0.160465 model2 loss : 0.175996
[23:10:24.621] iteration 14396 : model1 loss : 0.249778 model2 loss : 0.288985
[23:10:24.947] iteration 14397 : model1 loss : 0.256909 model2 loss : 0.273168
[23:10:25.273] iteration 14398 : model1 loss : 0.318698 model2 loss : 0.331725
[23:10:25.599] iteration 14399 : model1 loss : 0.134482 model2 loss : 0.133065
[23:10:25.926] iteration 14400 : model1 loss : 0.158887 model2 loss : 0.226149
[23:10:26.457] iteration 14401 : model1 loss : 0.200299 model2 loss : 0.202911
[23:10:26.784] iteration 14402 : model1 loss : 0.243124 model2 loss : 0.261600
[23:10:27.110] iteration 14403 : model1 loss : 0.172035 model2 loss : 0.221899
[23:10:27.436] iteration 14404 : model1 loss : 0.231004 model2 loss : 0.237299
[23:10:27.763] iteration 14405 : model1 loss : 0.203299 model2 loss : 0.193792
[23:10:28.089] iteration 14406 : model1 loss : 0.263149 model2 loss : 0.298675
[23:10:28.415] iteration 14407 : model1 loss : 0.258510 model2 loss : 0.290329
[23:10:28.741] iteration 14408 : model1 loss : 0.083555 model2 loss : 0.103830
[23:10:29.067] iteration 14409 : model1 loss : 0.142586 model2 loss : 0.168705
[23:10:29.393] iteration 14410 : model1 loss : 0.182851 model2 loss : 0.251630
[23:10:29.720] iteration 14411 : model1 loss : 0.229311 model2 loss : 0.230996
[23:10:30.048] iteration 14412 : model1 loss : 0.217629 model2 loss : 0.322725
[23:10:30.375] iteration 14413 : model1 loss : 0.283636 model2 loss : 0.281599
[23:10:30.701] iteration 14414 : model1 loss : 0.210233 model2 loss : 0.231286
[23:10:31.027] iteration 14415 : model1 loss : 0.171691 model2 loss : 0.191180
[23:10:31.353] iteration 14416 : model1 loss : 0.223347 model2 loss : 0.188114
[23:10:31.680] iteration 14417 : model1 loss : 0.156208 model2 loss : 0.171067
[23:10:32.006] iteration 14418 : model1 loss : 0.247990 model2 loss : 0.303840
[23:10:32.333] iteration 14419 : model1 loss : 0.178266 model2 loss : 0.243257
[23:10:32.659] iteration 14420 : model1 loss : 0.166250 model2 loss : 0.203206
[23:10:32.984] iteration 14421 : model1 loss : 0.112332 model2 loss : 0.135794
[23:10:33.310] iteration 14422 : model1 loss : 0.261269 model2 loss : 0.279098
[23:10:33.637] iteration 14423 : model1 loss : 0.188442 model2 loss : 0.257272
[23:10:33.963] iteration 14424 : model1 loss : 0.200302 model2 loss : 0.243826
[23:10:34.289] iteration 14425 : model1 loss : 0.222502 model2 loss : 0.225644
[23:10:34.615] iteration 14426 : model1 loss : 0.136517 model2 loss : 0.149985
[23:10:34.942] iteration 14427 : model1 loss : 0.273144 model2 loss : 0.332202
[23:10:35.269] iteration 14428 : model1 loss : 0.265711 model2 loss : 0.292569
[23:10:35.595] iteration 14429 : model1 loss : 0.227671 model2 loss : 0.274995
[23:10:35.922] iteration 14430 : model1 loss : 0.173111 model2 loss : 0.290308
[23:10:36.248] iteration 14431 : model1 loss : 0.252900 model2 loss : 0.333431
[23:10:36.574] iteration 14432 : model1 loss : 0.245827 model2 loss : 0.290017
[23:10:36.900] iteration 14433 : model1 loss : 0.175498 model2 loss : 0.137518
[23:10:37.226] iteration 14434 : model1 loss : 0.234240 model2 loss : 0.255603
[23:10:37.553] iteration 14435 : model1 loss : 0.313829 model2 loss : 0.256552
[23:10:37.879] iteration 14436 : model1 loss : 0.221193 model2 loss : 0.317263
[23:10:38.206] iteration 14437 : model1 loss : 0.283932 model2 loss : 0.305347
[23:10:38.533] iteration 14438 : model1 loss : 0.300695 model2 loss : 0.216846
[23:10:38.858] iteration 14439 : model1 loss : 0.181792 model2 loss : 0.257467
[23:10:39.186] iteration 14440 : model1 loss : 0.202768 model2 loss : 0.223207
[23:10:39.516] iteration 14441 : model1 loss : 0.233047 model2 loss : 0.294962
[23:10:39.848] iteration 14442 : model1 loss : 0.181969 model2 loss : 0.209284
[23:10:40.180] iteration 14443 : model1 loss : 0.148885 model2 loss : 0.207192
[23:10:40.510] iteration 14444 : model1 loss : 0.117501 model2 loss : 0.181837
[23:10:40.840] iteration 14445 : model1 loss : 0.177852 model2 loss : 0.198417
[23:10:41.169] iteration 14446 : model1 loss : 0.358263 model2 loss : 0.313356
[23:10:41.500] iteration 14447 : model1 loss : 0.221648 model2 loss : 0.288980
[23:10:41.831] iteration 14448 : model1 loss : 0.152006 model2 loss : 0.268408
[23:10:42.159] iteration 14449 : model1 loss : 0.243714 model2 loss : 0.268614
[23:10:42.488] iteration 14450 : model1 loss : 0.294296 model2 loss : 0.307232
[23:10:43.021] iteration 14451 : model1 loss : 0.183661 model2 loss : 0.222692
[23:10:43.352] iteration 14452 : model1 loss : 0.109575 model2 loss : 0.149883
[23:10:43.681] iteration 14453 : model1 loss : 0.216774 model2 loss : 0.284292
[23:10:44.011] iteration 14454 : model1 loss : 0.269407 model2 loss : 0.307246
[23:10:44.341] iteration 14455 : model1 loss : 0.225247 model2 loss : 0.214108
[23:10:44.670] iteration 14456 : model1 loss : 0.181252 model2 loss : 0.193791
[23:10:45.000] iteration 14457 : model1 loss : 0.125828 model2 loss : 0.126016
[23:10:45.332] iteration 14458 : model1 loss : 0.202481 model2 loss : 0.263381
[23:10:45.661] iteration 14459 : model1 loss : 0.296721 model2 loss : 0.266230
[23:10:45.990] iteration 14460 : model1 loss : 0.333529 model2 loss : 0.265783
[23:10:46.319] iteration 14461 : model1 loss : 0.171254 model2 loss : 0.269869
[23:10:46.647] iteration 14462 : model1 loss : 0.274544 model2 loss : 0.270540
[23:10:46.976] iteration 14463 : model1 loss : 0.170388 model2 loss : 0.161790
[23:10:47.305] iteration 14464 : model1 loss : 0.265296 model2 loss : 0.271945
[23:10:47.634] iteration 14465 : model1 loss : 0.211866 model2 loss : 0.229590
[23:10:47.963] iteration 14466 : model1 loss : 0.285747 model2 loss : 0.388874
[23:10:48.292] iteration 14467 : model1 loss : 0.165447 model2 loss : 0.119889
[23:10:48.621] iteration 14468 : model1 loss : 0.126867 model2 loss : 0.196340
[23:10:48.950] iteration 14469 : model1 loss : 0.274573 model2 loss : 0.266293
[23:10:49.278] iteration 14470 : model1 loss : 0.181599 model2 loss : 0.190857
[23:10:49.608] iteration 14471 : model1 loss : 0.190229 model2 loss : 0.266256
[23:10:49.938] iteration 14472 : model1 loss : 0.210294 model2 loss : 0.275625
[23:10:50.268] iteration 14473 : model1 loss : 0.334305 model2 loss : 0.360059
[23:10:50.598] iteration 14474 : model1 loss : 0.284654 model2 loss : 0.311524
[23:10:50.927] iteration 14475 : model1 loss : 0.149814 model2 loss : 0.220447
[23:10:51.254] iteration 14476 : model1 loss : 0.231534 model2 loss : 0.261709
[23:10:51.584] iteration 14477 : model1 loss : 0.198992 model2 loss : 0.215245
[23:10:51.914] iteration 14478 : model1 loss : 0.094466 model2 loss : 0.152328
[23:10:52.243] iteration 14479 : model1 loss : 0.324234 model2 loss : 0.345433
[23:10:52.573] iteration 14480 : model1 loss : 0.215678 model2 loss : 0.230071
[23:10:52.903] iteration 14481 : model1 loss : 0.294326 model2 loss : 0.335346
[23:10:53.231] iteration 14482 : model1 loss : 0.319656 model2 loss : 0.333194
[23:10:53.560] iteration 14483 : model1 loss : 0.142079 model2 loss : 0.164890
[23:10:53.891] iteration 14484 : model1 loss : 0.213432 model2 loss : 0.249589
[23:10:54.219] iteration 14485 : model1 loss : 0.106108 model2 loss : 0.115145
[23:10:54.547] iteration 14486 : model1 loss : 0.229666 model2 loss : 0.236047
[23:10:54.876] iteration 14487 : model1 loss : 0.124997 model2 loss : 0.140249
[23:10:55.205] iteration 14488 : model1 loss : 0.198773 model2 loss : 0.252032
[23:10:55.536] iteration 14489 : model1 loss : 0.162670 model2 loss : 0.152934
[23:10:55.865] iteration 14490 : model1 loss : 0.213086 model2 loss : 0.280972
[23:10:56.195] iteration 14491 : model1 loss : 0.327619 model2 loss : 0.362988
[23:10:56.523] iteration 14492 : model1 loss : 0.415383 model2 loss : 0.454464
[23:10:56.852] iteration 14493 : model1 loss : 0.214860 model2 loss : 0.226960
[23:10:57.179] iteration 14494 : model1 loss : 0.203743 model2 loss : 0.319865
[23:10:57.508] iteration 14495 : model1 loss : 0.139575 model2 loss : 0.168035
[23:10:57.840] iteration 14496 : model1 loss : 0.183749 model2 loss : 0.225810
[23:10:58.170] iteration 14497 : model1 loss : 0.205890 model2 loss : 0.188772
[23:10:58.496] iteration 14498 : model1 loss : 0.135014 model2 loss : 0.144962
[23:10:58.823] iteration 14499 : model1 loss : 0.136251 model2 loss : 0.191049
[23:10:59.149] iteration 14500 : model1 loss : 0.256691 model2 loss : 0.261463
[23:10:59.683] iteration 14501 : model1 loss : 0.124521 model2 loss : 0.164169
[23:11:00.008] iteration 14502 : model1 loss : 0.246332 model2 loss : 0.253021
[23:11:00.336] iteration 14503 : model1 loss : 0.289746 model2 loss : 0.315288
[23:11:00.663] iteration 14504 : model1 loss : 0.139510 model2 loss : 0.191689
[23:11:00.992] iteration 14505 : model1 loss : 0.179609 model2 loss : 0.252469
[23:11:01.323] iteration 14506 : model1 loss : 0.167220 model2 loss : 0.204872
[23:11:01.653] iteration 14507 : model1 loss : 0.176336 model2 loss : 0.242264
[23:11:01.982] iteration 14508 : model1 loss : 0.310436 model2 loss : 0.330933
[23:11:02.311] iteration 14509 : model1 loss : 0.253663 model2 loss : 0.269761
[23:11:02.641] iteration 14510 : model1 loss : 0.240831 model2 loss : 0.240115
[23:11:02.971] iteration 14511 : model1 loss : 0.112741 model2 loss : 0.132337
[23:11:03.300] iteration 14512 : model1 loss : 0.260703 model2 loss : 0.315849
[23:11:03.630] iteration 14513 : model1 loss : 0.225002 model2 loss : 0.202460
[23:11:03.958] iteration 14514 : model1 loss : 0.195436 model2 loss : 0.227218
[23:11:04.287] iteration 14515 : model1 loss : 0.301549 model2 loss : 0.258457
[23:11:04.616] iteration 14516 : model1 loss : 0.102171 model2 loss : 0.182874
[23:11:04.946] iteration 14517 : model1 loss : 0.244373 model2 loss : 0.300728
[23:11:05.278] iteration 14518 : model1 loss : 0.223763 model2 loss : 0.253473
[23:11:05.608] iteration 14519 : model1 loss : 0.179364 model2 loss : 0.164937
[23:11:05.938] iteration 14520 : model1 loss : 0.169939 model2 loss : 0.235386
[23:11:06.268] iteration 14521 : model1 loss : 0.269185 model2 loss : 0.331893
[23:11:06.598] iteration 14522 : model1 loss : 0.283147 model2 loss : 0.300382
[23:11:06.927] iteration 14523 : model1 loss : 0.191517 model2 loss : 0.241759
[23:11:07.258] iteration 14524 : model1 loss : 0.096115 model2 loss : 0.151122
[23:11:07.587] iteration 14525 : model1 loss : 0.207169 model2 loss : 0.287182
[23:11:07.916] iteration 14526 : model1 loss : 0.141741 model2 loss : 0.278263
[23:11:08.254] iteration 14527 : model1 loss : 0.195993 model2 loss : 0.260920
[23:11:08.591] iteration 14528 : model1 loss : 0.239458 model2 loss : 0.228761
[23:11:08.929] iteration 14529 : model1 loss : 0.227442 model2 loss : 0.249539
[23:11:09.272] iteration 14530 : model1 loss : 0.207586 model2 loss : 0.227916
[23:11:09.610] iteration 14531 : model1 loss : 0.270173 model2 loss : 0.311493
[23:11:09.948] iteration 14532 : model1 loss : 0.255705 model2 loss : 0.267818
[23:11:10.290] iteration 14533 : model1 loss : 0.408050 model2 loss : 0.455566
[23:11:10.628] iteration 14534 : model1 loss : 0.328774 model2 loss : 0.352099
[23:11:10.967] iteration 14535 : model1 loss : 0.139514 model2 loss : 0.182397
[23:11:11.305] iteration 14536 : model1 loss : 0.178855 model2 loss : 0.212102
[23:11:11.646] iteration 14537 : model1 loss : 0.124444 model2 loss : 0.127817
[23:11:11.986] iteration 14538 : model1 loss : 0.186870 model2 loss : 0.204352
[23:11:12.324] iteration 14539 : model1 loss : 0.314379 model2 loss : 0.310787
[23:11:12.661] iteration 14540 : model1 loss : 0.160498 model2 loss : 0.172830
[23:11:12.999] iteration 14541 : model1 loss : 0.259732 model2 loss : 0.312085
[23:11:13.336] iteration 14542 : model1 loss : 0.358829 model2 loss : 0.351650
[23:11:13.676] iteration 14543 : model1 loss : 0.243626 model2 loss : 0.203903
[23:11:14.013] iteration 14544 : model1 loss : 0.149664 model2 loss : 0.147133
[23:11:14.351] iteration 14545 : model1 loss : 0.299050 model2 loss : 0.323600
[23:11:14.689] iteration 14546 : model1 loss : 0.192506 model2 loss : 0.248400
[23:11:15.027] iteration 14547 : model1 loss : 0.125811 model2 loss : 0.180705
[23:11:15.364] iteration 14548 : model1 loss : 0.236006 model2 loss : 0.250925
[23:11:15.702] iteration 14549 : model1 loss : 0.174433 model2 loss : 0.179132
[23:11:16.039] iteration 14550 : model1 loss : 0.108392 model2 loss : 0.196635
[23:11:16.689] iteration 14551 : model1 loss : 0.183678 model2 loss : 0.186512
[23:11:17.027] iteration 14552 : model1 loss : 0.214780 model2 loss : 0.206995
[23:11:17.364] iteration 14553 : model1 loss : 0.206253 model2 loss : 0.263191
[23:11:17.702] iteration 14554 : model1 loss : 0.305069 model2 loss : 0.308044
[23:11:18.043] iteration 14555 : model1 loss : 0.213172 model2 loss : 0.254537
[23:11:18.384] iteration 14556 : model1 loss : 0.158244 model2 loss : 0.202996
[23:11:18.721] iteration 14557 : model1 loss : 0.181531 model2 loss : 0.177570
[23:11:19.058] iteration 14558 : model1 loss : 0.325823 model2 loss : 0.327016
[23:11:19.397] iteration 14559 : model1 loss : 0.215468 model2 loss : 0.277532
[23:11:19.734] iteration 14560 : model1 loss : 0.177547 model2 loss : 0.256723
[23:11:20.076] iteration 14561 : model1 loss : 0.100475 model2 loss : 0.121777
[23:11:20.414] iteration 14562 : model1 loss : 0.234805 model2 loss : 0.279555
[23:11:20.756] iteration 14563 : model1 loss : 0.123541 model2 loss : 0.129012
[23:11:21.097] iteration 14564 : model1 loss : 0.187262 model2 loss : 0.213597
[23:11:21.434] iteration 14565 : model1 loss : 0.273711 model2 loss : 0.282707
[23:11:21.772] iteration 14566 : model1 loss : 0.293278 model2 loss : 0.271116
[23:11:22.115] iteration 14567 : model1 loss : 0.347232 model2 loss : 0.235797
[23:11:22.452] iteration 14568 : model1 loss : 0.158260 model2 loss : 0.157785
[23:11:22.791] iteration 14569 : model1 loss : 0.197190 model2 loss : 0.229634
[23:11:23.132] iteration 14570 : model1 loss : 0.280280 model2 loss : 0.349284
[23:11:23.470] iteration 14571 : model1 loss : 0.301454 model2 loss : 0.364639
[23:11:23.808] iteration 14572 : model1 loss : 0.215133 model2 loss : 0.263211
[23:11:24.145] iteration 14573 : model1 loss : 0.146815 model2 loss : 0.218279
[23:11:24.484] iteration 14574 : model1 loss : 0.262696 model2 loss : 0.260211
[23:11:24.824] iteration 14575 : model1 loss : 0.140339 model2 loss : 0.204787
[23:11:25.162] iteration 14576 : model1 loss : 0.172475 model2 loss : 0.190485
[23:11:25.506] iteration 14577 : model1 loss : 0.204653 model2 loss : 0.180416
[23:11:25.851] iteration 14578 : model1 loss : 0.186725 model2 loss : 0.197635
[23:11:26.192] iteration 14579 : model1 loss : 0.211474 model2 loss : 0.283262
[23:11:26.528] iteration 14580 : model1 loss : 0.254867 model2 loss : 0.247125
[23:11:26.860] iteration 14581 : model1 loss : 0.179752 model2 loss : 0.183706
[23:11:27.188] iteration 14582 : model1 loss : 0.262057 model2 loss : 0.281850
[23:11:27.518] iteration 14583 : model1 loss : 0.187195 model2 loss : 0.240030
[23:11:27.849] iteration 14584 : model1 loss : 0.184892 model2 loss : 0.236362
[23:11:28.178] iteration 14585 : model1 loss : 0.154734 model2 loss : 0.133438
[23:11:28.508] iteration 14586 : model1 loss : 0.227722 model2 loss : 0.273042
[23:11:28.840] iteration 14587 : model1 loss : 0.199938 model2 loss : 0.201102
[23:11:29.170] iteration 14588 : model1 loss : 0.295320 model2 loss : 0.386812
[23:11:29.499] iteration 14589 : model1 loss : 0.195592 model2 loss : 0.238118
[23:11:29.829] iteration 14590 : model1 loss : 0.269688 model2 loss : 0.236473
[23:11:30.157] iteration 14591 : model1 loss : 0.143094 model2 loss : 0.141405
[23:11:30.487] iteration 14592 : model1 loss : 0.186216 model2 loss : 0.142499
[23:11:30.813] iteration 14593 : model1 loss : 0.270754 model2 loss : 0.200348
[23:11:31.140] iteration 14594 : model1 loss : 0.264191 model2 loss : 0.359888
[23:11:31.468] iteration 14595 : model1 loss : 0.179447 model2 loss : 0.279360
[23:11:31.793] iteration 14596 : model1 loss : 0.104019 model2 loss : 0.175210
[23:11:32.119] iteration 14597 : model1 loss : 0.204987 model2 loss : 0.265024
[23:11:32.445] iteration 14598 : model1 loss : 0.194028 model2 loss : 0.280074
[23:11:32.770] iteration 14599 : model1 loss : 0.203084 model2 loss : 0.176365
[23:11:33.096] iteration 14600 : model1 loss : 0.201398 model2 loss : 0.206306
[23:11:33.620] iteration 14601 : model1 loss : 0.191374 model2 loss : 0.238048
[23:11:33.947] iteration 14602 : model1 loss : 0.325800 model2 loss : 0.358312
[23:11:34.273] iteration 14603 : model1 loss : 0.179423 model2 loss : 0.220628
[23:11:34.598] iteration 14604 : model1 loss : 0.308497 model2 loss : 0.335187
[23:11:34.924] iteration 14605 : model1 loss : 0.205350 model2 loss : 0.264753
[23:11:35.250] iteration 14606 : model1 loss : 0.201686 model2 loss : 0.258625
[23:11:35.576] iteration 14607 : model1 loss : 0.253885 model2 loss : 0.221836
[23:11:35.903] iteration 14608 : model1 loss : 0.094937 model2 loss : 0.129909
[23:11:36.231] iteration 14609 : model1 loss : 0.243126 model2 loss : 0.246311
[23:11:36.557] iteration 14610 : model1 loss : 0.282682 model2 loss : 0.275373
[23:11:36.883] iteration 14611 : model1 loss : 0.294987 model2 loss : 0.358217
[23:11:37.209] iteration 14612 : model1 loss : 0.249578 model2 loss : 0.273021
[23:11:37.535] iteration 14613 : model1 loss : 0.223076 model2 loss : 0.252649
[23:11:37.861] iteration 14614 : model1 loss : 0.260054 model2 loss : 0.323968
[23:11:38.188] iteration 14615 : model1 loss : 0.218135 model2 loss : 0.273553
[23:11:38.514] iteration 14616 : model1 loss : 0.276347 model2 loss : 0.314138
[23:11:38.840] iteration 14617 : model1 loss : 0.097806 model2 loss : 0.245542
[23:11:39.167] iteration 14618 : model1 loss : 0.181253 model2 loss : 0.210621
[23:11:39.494] iteration 14619 : model1 loss : 0.224224 model2 loss : 0.278810
[23:11:39.820] iteration 14620 : model1 loss : 0.164763 model2 loss : 0.203857
[23:11:40.148] iteration 14621 : model1 loss : 0.209694 model2 loss : 0.258532
[23:11:40.474] iteration 14622 : model1 loss : 0.212579 model2 loss : 0.220581
[23:11:40.801] iteration 14623 : model1 loss : 0.103231 model2 loss : 0.307238
[23:11:41.127] iteration 14624 : model1 loss : 0.115174 model2 loss : 0.212135
[23:11:41.454] iteration 14625 : model1 loss : 0.201486 model2 loss : 0.248755
[23:11:41.780] iteration 14626 : model1 loss : 0.193226 model2 loss : 0.222992
[23:11:42.106] iteration 14627 : model1 loss : 0.087010 model2 loss : 0.153739
[23:11:42.431] iteration 14628 : model1 loss : 0.244675 model2 loss : 0.237242
[23:11:42.758] iteration 14629 : model1 loss : 0.187158 model2 loss : 0.270759
[23:11:43.084] iteration 14630 : model1 loss : 0.268002 model2 loss : 0.257296
[23:11:43.411] iteration 14631 : model1 loss : 0.283982 model2 loss : 0.340206
[23:11:43.737] iteration 14632 : model1 loss : 0.177302 model2 loss : 0.377334
[23:11:44.064] iteration 14633 : model1 loss : 0.265732 model2 loss : 0.293145
[23:11:44.390] iteration 14634 : model1 loss : 0.291796 model2 loss : 0.252536
[23:11:44.717] iteration 14635 : model1 loss : 0.100938 model2 loss : 0.144868
[23:11:45.050] iteration 14636 : model1 loss : 0.201738 model2 loss : 0.256160
[23:11:45.390] iteration 14637 : model1 loss : 0.238142 model2 loss : 0.243994
[23:11:45.728] iteration 14638 : model1 loss : 0.080288 model2 loss : 0.169231
[23:11:46.069] iteration 14639 : model1 loss : 0.186292 model2 loss : 0.241651
[23:11:46.409] iteration 14640 : model1 loss : 0.212863 model2 loss : 0.252044
[23:11:46.746] iteration 14641 : model1 loss : 0.153021 model2 loss : 0.147686
[23:11:47.083] iteration 14642 : model1 loss : 0.150093 model2 loss : 0.188046
[23:11:47.423] iteration 14643 : model1 loss : 0.243745 model2 loss : 0.311412
[23:11:47.759] iteration 14644 : model1 loss : 0.299040 model2 loss : 0.306297
[23:11:48.095] iteration 14645 : model1 loss : 0.154906 model2 loss : 0.236717
[23:11:48.432] iteration 14646 : model1 loss : 0.274781 model2 loss : 0.341405
[23:11:48.769] iteration 14647 : model1 loss : 0.172320 model2 loss : 0.215592
[23:11:49.107] iteration 14648 : model1 loss : 0.164143 model2 loss : 0.293577
[23:11:49.443] iteration 14649 : model1 loss : 0.218151 model2 loss : 0.225714
[23:11:49.780] iteration 14650 : model1 loss : 0.219337 model2 loss : 0.221041
[23:11:50.419] iteration 14651 : model1 loss : 0.325725 model2 loss : 0.394451
[23:11:50.761] iteration 14652 : model1 loss : 0.304803 model2 loss : 0.307660
[23:11:51.098] iteration 14653 : model1 loss : 0.272925 model2 loss : 0.273017
[23:11:51.437] iteration 14654 : model1 loss : 0.283093 model2 loss : 0.278914
[23:11:51.775] iteration 14655 : model1 loss : 0.227070 model2 loss : 0.262556
[23:11:52.114] iteration 14656 : model1 loss : 0.234034 model2 loss : 0.276081
[23:11:52.452] iteration 14657 : model1 loss : 0.219859 model2 loss : 0.245693
[23:11:52.785] iteration 14658 : model1 loss : 0.283221 model2 loss : 0.283432
[23:11:53.116] iteration 14659 : model1 loss : 0.195618 model2 loss : 0.199026
[23:11:53.446] iteration 14660 : model1 loss : 0.274061 model2 loss : 0.278606
[23:11:53.777] iteration 14661 : model1 loss : 0.174801 model2 loss : 0.199671
[23:11:54.108] iteration 14662 : model1 loss : 0.100889 model2 loss : 0.200296
[23:11:54.436] iteration 14663 : model1 loss : 0.241058 model2 loss : 0.245731
[23:11:54.766] iteration 14664 : model1 loss : 0.182812 model2 loss : 0.220737
[23:11:55.098] iteration 14665 : model1 loss : 0.174745 model2 loss : 0.154226
[23:11:55.427] iteration 14666 : model1 loss : 0.192311 model2 loss : 0.222622
[23:11:55.758] iteration 14667 : model1 loss : 0.204561 model2 loss : 0.185269
[23:11:56.088] iteration 14668 : model1 loss : 0.198861 model2 loss : 0.199732
[23:11:56.420] iteration 14669 : model1 loss : 0.266633 model2 loss : 0.329162
[23:11:56.749] iteration 14670 : model1 loss : 0.184670 model2 loss : 0.198421
[23:11:57.078] iteration 14671 : model1 loss : 0.365590 model2 loss : 0.348564
[23:11:57.407] iteration 14672 : model1 loss : 0.294813 model2 loss : 0.331290
[23:11:57.735] iteration 14673 : model1 loss : 0.189857 model2 loss : 0.217421
[23:11:58.064] iteration 14674 : model1 loss : 0.206716 model2 loss : 0.190681
[23:11:58.392] iteration 14675 : model1 loss : 0.264508 model2 loss : 0.277159
[23:11:58.718] iteration 14676 : model1 loss : 0.290623 model2 loss : 0.321736
[23:11:59.044] iteration 14677 : model1 loss : 0.162594 model2 loss : 0.196001
[23:11:59.370] iteration 14678 : model1 loss : 0.285364 model2 loss : 0.365482
[23:11:59.696] iteration 14679 : model1 loss : 0.104457 model2 loss : 0.148954
[23:12:00.022] iteration 14680 : model1 loss : 0.201891 model2 loss : 0.225796
[23:12:00.350] iteration 14681 : model1 loss : 0.180061 model2 loss : 0.239831
[23:12:00.676] iteration 14682 : model1 loss : 0.199463 model2 loss : 0.223983
[23:12:01.003] iteration 14683 : model1 loss : 0.200821 model2 loss : 0.224417
[23:12:01.329] iteration 14684 : model1 loss : 0.207938 model2 loss : 0.247252
[23:12:01.655] iteration 14685 : model1 loss : 0.172714 model2 loss : 0.230269
[23:12:01.982] iteration 14686 : model1 loss : 0.122321 model2 loss : 0.135375
[23:12:02.308] iteration 14687 : model1 loss : 0.243425 model2 loss : 0.370449
[23:12:02.635] iteration 14688 : model1 loss : 0.176396 model2 loss : 0.166822
[23:12:02.961] iteration 14689 : model1 loss : 0.211340 model2 loss : 0.256017
[23:12:03.287] iteration 14690 : model1 loss : 0.238592 model2 loss : 0.273618
[23:12:03.613] iteration 14691 : model1 loss : 0.189648 model2 loss : 0.278658
[23:12:03.939] iteration 14692 : model1 loss : 0.232467 model2 loss : 0.212647
[23:12:04.267] iteration 14693 : model1 loss : 0.216938 model2 loss : 0.211789
[23:12:04.593] iteration 14694 : model1 loss : 0.181684 model2 loss : 0.256124
[23:12:04.919] iteration 14695 : model1 loss : 0.218800 model2 loss : 0.150740
[23:12:05.246] iteration 14696 : model1 loss : 0.282902 model2 loss : 0.250443
[23:12:05.571] iteration 14697 : model1 loss : 0.183975 model2 loss : 0.191330
[23:12:05.898] iteration 14698 : model1 loss : 0.118016 model2 loss : 0.186733
[23:12:06.225] iteration 14699 : model1 loss : 0.121693 model2 loss : 0.119260
[23:12:06.551] iteration 14700 : model1 loss : 0.241324 model2 loss : 0.248116
[23:12:07.066] iteration 14701 : model1 loss : 0.129360 model2 loss : 0.177825
[23:12:07.392] iteration 14702 : model1 loss : 0.290034 model2 loss : 0.348250
[23:12:07.717] iteration 14703 : model1 loss : 0.205181 model2 loss : 0.225476
[23:12:08.043] iteration 14704 : model1 loss : 0.150723 model2 loss : 0.207944
[23:12:08.370] iteration 14705 : model1 loss : 0.175425 model2 loss : 0.194620
[23:12:08.695] iteration 14706 : model1 loss : 0.318702 model2 loss : 0.400337
[23:12:09.022] iteration 14707 : model1 loss : 0.167324 model2 loss : 0.174963
[23:12:09.347] iteration 14708 : model1 loss : 0.241707 model2 loss : 0.253620
[23:12:09.672] iteration 14709 : model1 loss : 0.190994 model2 loss : 0.204853
[23:12:10.119] iteration 14710 : model1 loss : 0.192471 model2 loss : 0.230253
[23:12:10.449] iteration 14711 : model1 loss : 0.187590 model2 loss : 0.278698
[23:12:10.774] iteration 14712 : model1 loss : 0.157690 model2 loss : 0.175121
[23:12:11.099] iteration 14713 : model1 loss : 0.272910 model2 loss : 0.318124
[23:12:11.424] iteration 14714 : model1 loss : 0.206307 model2 loss : 0.260555
[23:12:11.749] iteration 14715 : model1 loss : 0.319582 model2 loss : 0.292664
[23:12:12.708] iteration 14716 : model1 loss : 0.226438 model2 loss : 0.236984
[23:12:13.035] iteration 14717 : model1 loss : 0.139494 model2 loss : 0.200957
[23:12:13.361] iteration 14718 : model1 loss : 0.178374 model2 loss : 0.258729
[23:12:13.688] iteration 14719 : model1 loss : 0.203990 model2 loss : 0.293331
[23:12:14.017] iteration 14720 : model1 loss : 0.115400 model2 loss : 0.192487
[23:12:14.343] iteration 14721 : model1 loss : 0.179724 model2 loss : 0.200667
[23:12:14.669] iteration 14722 : model1 loss : 0.193881 model2 loss : 0.208093
[23:12:14.995] iteration 14723 : model1 loss : 0.214633 model2 loss : 0.343791
[23:12:15.322] iteration 14724 : model1 loss : 0.253994 model2 loss : 0.271520
[23:12:15.650] iteration 14725 : model1 loss : 0.190825 model2 loss : 0.268593
[23:12:15.976] iteration 14726 : model1 loss : 0.193831 model2 loss : 0.232668
[23:12:16.302] iteration 14727 : model1 loss : 0.120702 model2 loss : 0.150945
[23:12:16.630] iteration 14728 : model1 loss : 0.355464 model2 loss : 0.353250
[23:12:16.957] iteration 14729 : model1 loss : 0.129996 model2 loss : 0.159301
[23:12:17.283] iteration 14730 : model1 loss : 0.187721 model2 loss : 0.205303
[23:12:17.609] iteration 14731 : model1 loss : 0.190496 model2 loss : 0.225148
[23:12:17.936] iteration 14732 : model1 loss : 0.160436 model2 loss : 0.267239
[23:12:18.262] iteration 14733 : model1 loss : 0.360909 model2 loss : 0.335492
[23:12:18.589] iteration 14734 : model1 loss : 0.250213 model2 loss : 0.249879
[23:12:18.915] iteration 14735 : model1 loss : 0.174479 model2 loss : 0.193295
[23:12:19.240] iteration 14736 : model1 loss : 0.189898 model2 loss : 0.203493
[23:12:19.567] iteration 14737 : model1 loss : 0.350957 model2 loss : 0.357343
[23:12:19.894] iteration 14738 : model1 loss : 0.185196 model2 loss : 0.252466
[23:12:20.219] iteration 14739 : model1 loss : 0.060660 model2 loss : 0.114839
[23:12:20.546] iteration 14740 : model1 loss : 0.206228 model2 loss : 0.220523
[23:12:20.872] iteration 14741 : model1 loss : 0.256725 model2 loss : 0.263413
[23:12:21.199] iteration 14742 : model1 loss : 0.185379 model2 loss : 0.219423
[23:12:21.527] iteration 14743 : model1 loss : 0.276182 model2 loss : 0.274859
[23:12:21.853] iteration 14744 : model1 loss : 0.315370 model2 loss : 0.305198
[23:12:22.178] iteration 14745 : model1 loss : 0.189084 model2 loss : 0.174819
[23:12:22.505] iteration 14746 : model1 loss : 0.334188 model2 loss : 0.333034
[23:12:22.831] iteration 14747 : model1 loss : 0.192541 model2 loss : 0.219904
[23:12:23.157] iteration 14748 : model1 loss : 0.180013 model2 loss : 0.200122
[23:12:23.484] iteration 14749 : model1 loss : 0.267025 model2 loss : 0.285746
[23:12:23.810] iteration 14750 : model1 loss : 0.196870 model2 loss : 0.191564
[23:12:24.355] iteration 14751 : model1 loss : 0.254032 model2 loss : 0.246943
[23:12:24.681] iteration 14752 : model1 loss : 0.296417 model2 loss : 0.292625
[23:12:25.008] iteration 14753 : model1 loss : 0.194629 model2 loss : 0.199694
[23:12:25.336] iteration 14754 : model1 loss : 0.165618 model2 loss : 0.190478
[23:12:25.662] iteration 14755 : model1 loss : 0.222836 model2 loss : 0.222603
[23:12:25.988] iteration 14756 : model1 loss : 0.167531 model2 loss : 0.184902
[23:12:26.315] iteration 14757 : model1 loss : 0.272136 model2 loss : 0.351267
[23:12:26.644] iteration 14758 : model1 loss : 0.259563 model2 loss : 0.265731
[23:12:26.970] iteration 14759 : model1 loss : 0.096021 model2 loss : 0.170516
[23:12:27.295] iteration 14760 : model1 loss : 0.196357 model2 loss : 0.199844
[23:12:27.622] iteration 14761 : model1 loss : 0.212370 model2 loss : 0.255519
[23:12:27.948] iteration 14762 : model1 loss : 0.103864 model2 loss : 0.175372
[23:12:28.275] iteration 14763 : model1 loss : 0.208785 model2 loss : 0.227361
[23:12:28.601] iteration 14764 : model1 loss : 0.356421 model2 loss : 0.371537
[23:12:28.931] iteration 14765 : model1 loss : 0.351448 model2 loss : 0.361872
[23:12:29.259] iteration 14766 : model1 loss : 0.215169 model2 loss : 0.220944
[23:12:29.595] iteration 14767 : model1 loss : 0.223522 model2 loss : 0.334947
[23:12:29.931] iteration 14768 : model1 loss : 0.366893 model2 loss : 0.308751
[23:12:30.272] iteration 14769 : model1 loss : 0.265247 model2 loss : 0.288154
[23:12:30.609] iteration 14770 : model1 loss : 0.146754 model2 loss : 0.174927
[23:12:30.945] iteration 14771 : model1 loss : 0.233499 model2 loss : 0.334193
[23:12:31.282] iteration 14772 : model1 loss : 0.229716 model2 loss : 0.226576
[23:12:31.618] iteration 14773 : model1 loss : 0.172363 model2 loss : 0.265246
[23:12:31.954] iteration 14774 : model1 loss : 0.147301 model2 loss : 0.176569
[23:12:32.290] iteration 14775 : model1 loss : 0.231595 model2 loss : 0.253913
[23:12:32.627] iteration 14776 : model1 loss : 0.189133 model2 loss : 0.153857
[23:12:32.964] iteration 14777 : model1 loss : 0.179758 model2 loss : 0.237206
[23:12:33.300] iteration 14778 : model1 loss : 0.145590 model2 loss : 0.155087
[23:12:33.636] iteration 14779 : model1 loss : 0.232082 model2 loss : 0.282815
[23:12:33.973] iteration 14780 : model1 loss : 0.115019 model2 loss : 0.169226
[23:12:34.309] iteration 14781 : model1 loss : 0.128527 model2 loss : 0.125527
[23:12:34.646] iteration 14782 : model1 loss : 0.279324 model2 loss : 0.310901
[23:12:34.982] iteration 14783 : model1 loss : 0.181240 model2 loss : 0.192360
[23:12:35.320] iteration 14784 : model1 loss : 0.227385 model2 loss : 0.157016
[23:12:35.657] iteration 14785 : model1 loss : 0.239187 model2 loss : 0.216541
[23:12:35.993] iteration 14786 : model1 loss : 0.240489 model2 loss : 0.285594
[23:12:36.330] iteration 14787 : model1 loss : 0.206768 model2 loss : 0.284717
[23:12:36.667] iteration 14788 : model1 loss : 0.236624 model2 loss : 0.164876
[23:12:36.995] iteration 14789 : model1 loss : 0.283760 model2 loss : 0.291444
[23:12:37.323] iteration 14790 : model1 loss : 0.174231 model2 loss : 0.197779
[23:12:37.651] iteration 14791 : model1 loss : 0.183735 model2 loss : 0.197390
[23:12:37.980] iteration 14792 : model1 loss : 0.223756 model2 loss : 0.220463
[23:12:38.309] iteration 14793 : model1 loss : 0.205079 model2 loss : 0.190384
[23:12:38.636] iteration 14794 : model1 loss : 0.203471 model2 loss : 0.233538
[23:12:38.965] iteration 14795 : model1 loss : 0.174310 model2 loss : 0.202033
[23:12:39.294] iteration 14796 : model1 loss : 0.152972 model2 loss : 0.200112
[23:12:39.621] iteration 14797 : model1 loss : 0.267710 model2 loss : 0.263849
[23:12:39.949] iteration 14798 : model1 loss : 0.144153 model2 loss : 0.211748
[23:12:40.277] iteration 14799 : model1 loss : 0.207223 model2 loss : 0.209129
[23:12:40.606] iteration 14800 : model1 loss : 0.238970 model2 loss : 0.318547
[23:12:41.158] iteration 14801 : model1 loss : 0.269753 model2 loss : 0.249700
[23:12:41.486] iteration 14802 : model1 loss : 0.135827 model2 loss : 0.144321
[23:12:41.814] iteration 14803 : model1 loss : 0.123028 model2 loss : 0.192363
[23:12:42.142] iteration 14804 : model1 loss : 0.220340 model2 loss : 0.210784
[23:12:42.469] iteration 14805 : model1 loss : 0.236253 model2 loss : 0.181916
[23:12:42.797] iteration 14806 : model1 loss : 0.166244 model2 loss : 0.204890
[23:12:43.124] iteration 14807 : model1 loss : 0.153159 model2 loss : 0.253078
[23:12:43.452] iteration 14808 : model1 loss : 0.198669 model2 loss : 0.250931
[23:12:43.780] iteration 14809 : model1 loss : 0.263466 model2 loss : 0.295818
[23:12:44.110] iteration 14810 : model1 loss : 0.228614 model2 loss : 0.260358
[23:12:44.444] iteration 14811 : model1 loss : 0.262946 model2 loss : 0.319516
[23:12:44.780] iteration 14812 : model1 loss : 0.147343 model2 loss : 0.143292
[23:12:45.117] iteration 14813 : model1 loss : 0.218720 model2 loss : 0.203088
[23:12:45.454] iteration 14814 : model1 loss : 0.401804 model2 loss : 0.425872
[23:12:45.790] iteration 14815 : model1 loss : 0.308320 model2 loss : 0.388543
[23:12:46.127] iteration 14816 : model1 loss : 0.175518 model2 loss : 0.158511
[23:12:46.465] iteration 14817 : model1 loss : 0.308378 model2 loss : 0.310627
[23:12:46.801] iteration 14818 : model1 loss : 0.276473 model2 loss : 0.343288
[23:12:47.138] iteration 14819 : model1 loss : 0.243593 model2 loss : 0.287171
[23:12:47.469] iteration 14820 : model1 loss : 0.253831 model2 loss : 0.290866
[23:12:47.808] iteration 14821 : model1 loss : 0.230541 model2 loss : 0.260519
[23:12:48.145] iteration 14822 : model1 loss : 0.219667 model2 loss : 0.230109
[23:12:48.482] iteration 14823 : model1 loss : 0.105687 model2 loss : 0.140826
[23:12:48.813] iteration 14824 : model1 loss : 0.168331 model2 loss : 0.201987
[23:12:49.149] iteration 14825 : model1 loss : 0.178418 model2 loss : 0.190917
[23:12:49.488] iteration 14826 : model1 loss : 0.094880 model2 loss : 0.114819
[23:12:49.824] iteration 14827 : model1 loss : 0.361435 model2 loss : 0.351797
[23:12:50.156] iteration 14828 : model1 loss : 0.271466 model2 loss : 0.352456
[23:12:50.497] iteration 14829 : model1 loss : 0.201133 model2 loss : 0.204904
[23:12:50.834] iteration 14830 : model1 loss : 0.217544 model2 loss : 0.253578
[23:12:51.170] iteration 14831 : model1 loss : 0.135846 model2 loss : 0.194942
[23:12:51.502] iteration 14832 : model1 loss : 0.113484 model2 loss : 0.137953
[23:12:51.838] iteration 14833 : model1 loss : 0.263080 model2 loss : 0.198482
[23:12:52.174] iteration 14834 : model1 loss : 0.178587 model2 loss : 0.292837
[23:12:52.511] iteration 14835 : model1 loss : 0.233548 model2 loss : 0.323998
[23:12:52.842] iteration 14836 : model1 loss : 0.173853 model2 loss : 0.259893
[23:12:53.179] iteration 14837 : model1 loss : 0.097295 model2 loss : 0.160645
[23:12:53.515] iteration 14838 : model1 loss : 0.232398 model2 loss : 0.281496
[23:12:53.854] iteration 14839 : model1 loss : 0.183271 model2 loss : 0.244386
[23:12:54.186] iteration 14840 : model1 loss : 0.190207 model2 loss : 0.124624
[23:12:54.522] iteration 14841 : model1 loss : 0.313371 model2 loss : 0.312519
[23:12:54.858] iteration 14842 : model1 loss : 0.130147 model2 loss : 0.292552
[23:12:55.195] iteration 14843 : model1 loss : 0.210362 model2 loss : 0.248989
[23:12:55.531] iteration 14844 : model1 loss : 0.106184 model2 loss : 0.105565
[23:12:55.868] iteration 14845 : model1 loss : 0.240281 model2 loss : 0.250772
[23:12:56.203] iteration 14846 : model1 loss : 0.178076 model2 loss : 0.206050
[23:12:56.540] iteration 14847 : model1 loss : 0.243528 model2 loss : 0.256025
[23:12:56.877] iteration 14848 : model1 loss : 0.217786 model2 loss : 0.186353
[23:12:57.213] iteration 14849 : model1 loss : 0.126523 model2 loss : 0.187101
[23:12:57.549] iteration 14850 : model1 loss : 0.230951 model2 loss : 0.260609
[23:12:58.224] iteration 14851 : model1 loss : 0.186189 model2 loss : 0.272008
[23:12:58.562] iteration 14852 : model1 loss : 0.194354 model2 loss : 0.253903
[23:12:58.908] iteration 14853 : model1 loss : 0.220716 model2 loss : 0.311290
[23:12:59.245] iteration 14854 : model1 loss : 0.187722 model2 loss : 0.238924
[23:12:59.573] iteration 14855 : model1 loss : 0.189985 model2 loss : 0.234537
[23:12:59.900] iteration 14856 : model1 loss : 0.172741 model2 loss : 0.202426
[23:13:00.229] iteration 14857 : model1 loss : 0.185589 model2 loss : 0.252004
[23:13:00.568] iteration 14858 : model1 loss : 0.166737 model2 loss : 0.199772
[23:13:00.905] iteration 14859 : model1 loss : 0.251821 model2 loss : 0.215352
[23:13:01.243] iteration 14860 : model1 loss : 0.232123 model2 loss : 0.169589
[23:13:01.580] iteration 14861 : model1 loss : 0.143139 model2 loss : 0.162265
[23:13:01.918] iteration 14862 : model1 loss : 0.171803 model2 loss : 0.187356
[23:13:02.255] iteration 14863 : model1 loss : 0.211229 model2 loss : 0.270635
[23:13:02.591] iteration 14864 : model1 loss : 0.258854 model2 loss : 0.327674
[23:13:02.928] iteration 14865 : model1 loss : 0.288391 model2 loss : 0.319491
[23:13:03.264] iteration 14866 : model1 loss : 0.209960 model2 loss : 0.216401
[23:13:03.592] iteration 14867 : model1 loss : 0.163595 model2 loss : 0.234109
[23:13:03.920] iteration 14868 : model1 loss : 0.215533 model2 loss : 0.235712
[23:13:04.248] iteration 14869 : model1 loss : 0.289280 model2 loss : 0.341203
[23:13:04.577] iteration 14870 : model1 loss : 0.097557 model2 loss : 0.151431
[23:13:04.906] iteration 14871 : model1 loss : 0.155174 model2 loss : 0.174558
[23:13:05.233] iteration 14872 : model1 loss : 0.319293 model2 loss : 0.344346
[23:13:05.561] iteration 14873 : model1 loss : 0.252551 model2 loss : 0.303450
[23:13:05.888] iteration 14874 : model1 loss : 0.181544 model2 loss : 0.192791
[23:13:06.218] iteration 14875 : model1 loss : 0.197591 model2 loss : 0.230554
[23:13:06.546] iteration 14876 : model1 loss : 0.121736 model2 loss : 0.126308
[23:13:06.873] iteration 14877 : model1 loss : 0.247565 model2 loss : 0.298891
[23:13:07.200] iteration 14878 : model1 loss : 0.282793 model2 loss : 0.333821
[23:13:07.528] iteration 14879 : model1 loss : 0.300327 model2 loss : 0.360218
[23:13:07.857] iteration 14880 : model1 loss : 0.288277 model2 loss : 0.268528
[23:13:08.183] iteration 14881 : model1 loss : 0.146182 model2 loss : 0.197008
[23:13:08.511] iteration 14882 : model1 loss : 0.403267 model2 loss : 0.463597
[23:13:08.838] iteration 14883 : model1 loss : 0.270430 model2 loss : 0.260334
[23:13:09.167] iteration 14884 : model1 loss : 0.195664 model2 loss : 0.243209
[23:13:09.495] iteration 14885 : model1 loss : 0.280094 model2 loss : 0.310350
[23:13:09.824] iteration 14886 : model1 loss : 0.287246 model2 loss : 0.351790
[23:13:10.151] iteration 14887 : model1 loss : 0.179653 model2 loss : 0.222704
[23:13:10.480] iteration 14888 : model1 loss : 0.116858 model2 loss : 0.191150
[23:13:10.807] iteration 14889 : model1 loss : 0.293408 model2 loss : 0.275579
[23:13:11.136] iteration 14890 : model1 loss : 0.261411 model2 loss : 0.277119
[23:13:11.464] iteration 14891 : model1 loss : 0.197049 model2 loss : 0.192531
[23:13:11.791] iteration 14892 : model1 loss : 0.267626 model2 loss : 0.295515
[23:13:12.119] iteration 14893 : model1 loss : 0.344487 model2 loss : 0.381000
[23:13:12.447] iteration 14894 : model1 loss : 0.307773 model2 loss : 0.377066
[23:13:12.775] iteration 14895 : model1 loss : 0.299500 model2 loss : 0.368607
[23:13:13.105] iteration 14896 : model1 loss : 0.187897 model2 loss : 0.206041
[23:13:13.435] iteration 14897 : model1 loss : 0.312596 model2 loss : 0.375828
[23:13:13.766] iteration 14898 : model1 loss : 0.275816 model2 loss : 0.271376
[23:13:14.094] iteration 14899 : model1 loss : 0.111210 model2 loss : 0.211121
[23:13:14.422] iteration 14900 : model1 loss : 0.253366 model2 loss : 0.253443
[23:13:14.986] iteration 14901 : model1 loss : 0.116890 model2 loss : 0.171401
[23:13:15.320] iteration 14902 : model1 loss : 0.259997 model2 loss : 0.310145
[23:13:15.647] iteration 14903 : model1 loss : 0.289109 model2 loss : 0.306694
[23:13:15.975] iteration 14904 : model1 loss : 0.244838 model2 loss : 0.278916
[23:13:16.304] iteration 14905 : model1 loss : 0.328901 model2 loss : 0.312102
[23:13:16.632] iteration 14906 : model1 loss : 0.236587 model2 loss : 0.275417
[23:13:16.959] iteration 14907 : model1 loss : 0.196434 model2 loss : 0.211934
[23:13:17.287] iteration 14908 : model1 loss : 0.187512 model2 loss : 0.228402
[23:13:17.615] iteration 14909 : model1 loss : 0.225356 model2 loss : 0.190454
[23:13:17.943] iteration 14910 : model1 loss : 0.297551 model2 loss : 0.286921
[23:13:18.271] iteration 14911 : model1 loss : 0.166342 model2 loss : 0.221231
[23:13:18.599] iteration 14912 : model1 loss : 0.216510 model2 loss : 0.260919
[23:13:18.927] iteration 14913 : model1 loss : 0.182761 model2 loss : 0.206166
[23:13:19.255] iteration 14914 : model1 loss : 0.225830 model2 loss : 0.312662
[23:13:19.582] iteration 14915 : model1 loss : 0.237811 model2 loss : 0.251389
[23:13:19.910] iteration 14916 : model1 loss : 0.255269 model2 loss : 0.266488
[23:13:20.239] iteration 14917 : model1 loss : 0.284757 model2 loss : 0.299910
[23:13:20.566] iteration 14918 : model1 loss : 0.286944 model2 loss : 0.310377
[23:13:20.895] iteration 14919 : model1 loss : 0.244121 model2 loss : 0.253648
[23:13:21.226] iteration 14920 : model1 loss : 0.222350 model2 loss : 0.229788
[23:13:21.554] iteration 14921 : model1 loss : 0.216536 model2 loss : 0.251472
[23:13:21.883] iteration 14922 : model1 loss : 0.270921 model2 loss : 0.291720
[23:13:22.211] iteration 14923 : model1 loss : 0.251881 model2 loss : 0.289439
[23:13:22.539] iteration 14924 : model1 loss : 0.174466 model2 loss : 0.242557
[23:13:22.868] iteration 14925 : model1 loss : 0.160094 model2 loss : 0.234732
[23:13:23.196] iteration 14926 : model1 loss : 0.222070 model2 loss : 0.273588
[23:13:23.524] iteration 14927 : model1 loss : 0.185532 model2 loss : 0.225708
[23:13:23.852] iteration 14928 : model1 loss : 0.212260 model2 loss : 0.250956
[23:13:24.183] iteration 14929 : model1 loss : 0.221316 model2 loss : 0.229412
[23:13:24.511] iteration 14930 : model1 loss : 0.166026 model2 loss : 0.192546
[23:13:24.840] iteration 14931 : model1 loss : 0.135952 model2 loss : 0.180619
[23:13:25.172] iteration 14932 : model1 loss : 0.220558 model2 loss : 0.256758
[23:13:25.503] iteration 14933 : model1 loss : 0.111013 model2 loss : 0.164805
[23:13:25.834] iteration 14934 : model1 loss : 0.100113 model2 loss : 0.167665
[23:13:26.162] iteration 14935 : model1 loss : 0.204449 model2 loss : 0.192719
[23:13:26.493] iteration 14936 : model1 loss : 0.400374 model2 loss : 0.402050
[23:13:26.821] iteration 14937 : model1 loss : 0.250625 model2 loss : 0.283669
[23:13:27.152] iteration 14938 : model1 loss : 0.149411 model2 loss : 0.210031
[23:13:27.479] iteration 14939 : model1 loss : 0.155043 model2 loss : 0.236311
[23:13:27.808] iteration 14940 : model1 loss : 0.256771 model2 loss : 0.268775
[23:13:28.136] iteration 14941 : model1 loss : 0.267238 model2 loss : 0.341130
[23:13:28.464] iteration 14942 : model1 loss : 0.129585 model2 loss : 0.143745
[23:13:28.793] iteration 14943 : model1 loss : 0.174698 model2 loss : 0.238758
[23:13:29.121] iteration 14944 : model1 loss : 0.273822 model2 loss : 0.284049
[23:13:29.449] iteration 14945 : model1 loss : 0.170523 model2 loss : 0.175693
[23:13:29.777] iteration 14946 : model1 loss : 0.126993 model2 loss : 0.156038
[23:13:30.104] iteration 14947 : model1 loss : 0.219705 model2 loss : 0.283660
[23:13:30.436] iteration 14948 : model1 loss : 0.249461 model2 loss : 0.278887
[23:13:30.764] iteration 14949 : model1 loss : 0.117293 model2 loss : 0.171029
[23:13:31.091] iteration 14950 : model1 loss : 0.239658 model2 loss : 0.204658
[23:13:31.685] iteration 14951 : model1 loss : 0.233129 model2 loss : 0.248582
[23:13:32.025] iteration 14952 : model1 loss : 0.266095 model2 loss : 0.323326
[23:13:32.361] iteration 14953 : model1 loss : 0.178977 model2 loss : 0.178238
[23:13:32.698] iteration 14954 : model1 loss : 0.121063 model2 loss : 0.231274
[23:13:33.034] iteration 14955 : model1 loss : 0.224144 model2 loss : 0.275544
[23:13:33.372] iteration 14956 : model1 loss : 0.251421 model2 loss : 0.265528
[23:13:33.709] iteration 14957 : model1 loss : 0.192380 model2 loss : 0.242997
[23:13:34.046] iteration 14958 : model1 loss : 0.270447 model2 loss : 0.307251
[23:13:34.382] iteration 14959 : model1 loss : 0.162106 model2 loss : 0.156822
[23:13:34.718] iteration 14960 : model1 loss : 0.212498 model2 loss : 0.253678
[23:13:35.055] iteration 14961 : model1 loss : 0.131498 model2 loss : 0.176856
[23:13:35.391] iteration 14962 : model1 loss : 0.116439 model2 loss : 0.242906
[23:13:35.727] iteration 14963 : model1 loss : 0.200656 model2 loss : 0.213281
[23:13:36.064] iteration 14964 : model1 loss : 0.173278 model2 loss : 0.213652
[23:13:36.403] iteration 14965 : model1 loss : 0.087362 model2 loss : 0.153486
[23:13:36.740] iteration 14966 : model1 loss : 0.183515 model2 loss : 0.258056
[23:13:37.076] iteration 14967 : model1 loss : 0.266274 model2 loss : 0.272795
[23:13:37.413] iteration 14968 : model1 loss : 0.266615 model2 loss : 0.311395
[23:13:37.751] iteration 14969 : model1 loss : 0.215214 model2 loss : 0.219799
[23:13:38.089] iteration 14970 : model1 loss : 0.110443 model2 loss : 0.154099
[23:13:38.427] iteration 14971 : model1 loss : 0.247537 model2 loss : 0.284120
[23:13:38.764] iteration 14972 : model1 loss : 0.300333 model2 loss : 0.351978
[23:13:39.100] iteration 14973 : model1 loss : 0.303014 model2 loss : 0.357198
[23:13:39.437] iteration 14974 : model1 loss : 0.207766 model2 loss : 0.260082
[23:13:39.776] iteration 14975 : model1 loss : 0.293200 model2 loss : 0.300405
[23:13:40.112] iteration 14976 : model1 loss : 0.166665 model2 loss : 0.287466
[23:13:40.451] iteration 14977 : model1 loss : 0.178116 model2 loss : 0.276470
[23:13:40.787] iteration 14978 : model1 loss : 0.178969 model2 loss : 0.176731
[23:13:41.125] iteration 14979 : model1 loss : 0.177498 model2 loss : 0.191567
[23:13:41.462] iteration 14980 : model1 loss : 0.189078 model2 loss : 0.175783
[23:13:41.799] iteration 14981 : model1 loss : 0.175815 model2 loss : 0.209474
[23:13:42.135] iteration 14982 : model1 loss : 0.125839 model2 loss : 0.175472
[23:13:42.471] iteration 14983 : model1 loss : 0.180156 model2 loss : 0.232956
[23:13:42.809] iteration 14984 : model1 loss : 0.194471 model2 loss : 0.240012
[23:13:43.151] iteration 14985 : model1 loss : 0.124003 model2 loss : 0.151788
[23:13:43.486] iteration 14986 : model1 loss : 0.177258 model2 loss : 0.213224
[23:13:43.822] iteration 14987 : model1 loss : 0.302896 model2 loss : 0.340079
[23:13:44.161] iteration 14988 : model1 loss : 0.109460 model2 loss : 0.161775
[23:13:44.499] iteration 14989 : model1 loss : 0.203098 model2 loss : 0.379809
[23:13:44.842] iteration 14990 : model1 loss : 0.142938 model2 loss : 0.209086
[23:13:45.179] iteration 14991 : model1 loss : 0.246253 model2 loss : 0.273760
[23:13:45.521] iteration 14992 : model1 loss : 0.242768 model2 loss : 0.263794
[23:13:45.862] iteration 14993 : model1 loss : 0.361948 model2 loss : 0.351244
[23:13:46.200] iteration 14994 : model1 loss : 0.106119 model2 loss : 0.208870
[23:13:46.542] iteration 14995 : model1 loss : 0.198325 model2 loss : 0.243503
[23:13:46.881] iteration 14996 : model1 loss : 0.201677 model2 loss : 0.236461
[23:13:47.228] iteration 14997 : model1 loss : 0.109251 model2 loss : 0.170662
[23:13:47.568] iteration 14998 : model1 loss : 0.202203 model2 loss : 0.203411
[23:13:47.905] iteration 14999 : model1 loss : 0.167147 model2 loss : 0.211104
[23:13:48.243] iteration 15000 : model1 loss : 0.173501 model2 loss : 0.185221
[23:14:57.437] iteration 15000 : model1_mean_dice : 0.749940 model1_mean_hd95 : 12.931273
[23:15:33.853] iteration 15000 : model2_mean_dice : 0.602254 model2_mean_hd95 : 14.231862
[23:15:34.001] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_15000.pth
[23:15:34.027] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_15000.pth
[23:15:34.366] iteration 15001 : model1 loss : 0.154758 model2 loss : 0.192217
[23:15:34.694] iteration 15002 : model1 loss : 0.343046 model2 loss : 0.354222
[23:15:35.026] iteration 15003 : model1 loss : 0.169547 model2 loss : 0.194580
[23:15:35.369] iteration 15004 : model1 loss : 0.230341 model2 loss : 0.265380
[23:15:35.710] iteration 15005 : model1 loss : 0.200416 model2 loss : 0.210582
[23:15:36.047] iteration 15006 : model1 loss : 0.290632 model2 loss : 0.343694
[23:15:36.384] iteration 15007 : model1 loss : 0.207269 model2 loss : 0.194263
[23:15:36.723] iteration 15008 : model1 loss : 0.260182 model2 loss : 0.338372
[23:15:37.058] iteration 15009 : model1 loss : 0.207707 model2 loss : 0.243758
[23:15:37.403] iteration 15010 : model1 loss : 0.240642 model2 loss : 0.243784
[23:15:37.738] iteration 15011 : model1 loss : 0.194508 model2 loss : 0.204998
[23:15:38.074] iteration 15012 : model1 loss : 0.184392 model2 loss : 0.230815
[23:15:38.409] iteration 15013 : model1 loss : 0.201343 model2 loss : 0.175723
[23:15:38.747] iteration 15014 : model1 loss : 0.167942 model2 loss : 0.275116
[23:15:39.082] iteration 15015 : model1 loss : 0.159893 model2 loss : 0.187284
[23:15:39.417] iteration 15016 : model1 loss : 0.183485 model2 loss : 0.206090
[23:15:39.752] iteration 15017 : model1 loss : 0.256383 model2 loss : 0.282035
[23:15:40.089] iteration 15018 : model1 loss : 0.109786 model2 loss : 0.148024
[23:15:40.425] iteration 15019 : model1 loss : 0.096336 model2 loss : 0.169607
[23:15:40.760] iteration 15020 : model1 loss : 0.204661 model2 loss : 0.193327
[23:15:41.097] iteration 15021 : model1 loss : 0.178515 model2 loss : 0.231468
[23:15:41.434] iteration 15022 : model1 loss : 0.282871 model2 loss : 0.301808
[23:15:41.777] iteration 15023 : model1 loss : 0.136786 model2 loss : 0.137968
[23:15:42.116] iteration 15024 : model1 loss : 0.235461 model2 loss : 0.278626
[23:15:42.453] iteration 15025 : model1 loss : 0.203908 model2 loss : 0.238631
[23:15:42.790] iteration 15026 : model1 loss : 0.332463 model2 loss : 0.351266
[23:15:43.127] iteration 15027 : model1 loss : 0.109420 model2 loss : 0.195132
[23:15:43.466] iteration 15028 : model1 loss : 0.258291 model2 loss : 0.331056
[23:15:43.802] iteration 15029 : model1 loss : 0.268317 model2 loss : 0.291723
[23:15:44.139] iteration 15030 : model1 loss : 0.237202 model2 loss : 0.272626
[23:15:44.477] iteration 15031 : model1 loss : 0.099260 model2 loss : 0.137294
[23:15:44.814] iteration 15032 : model1 loss : 0.114819 model2 loss : 0.137506
[23:15:45.152] iteration 15033 : model1 loss : 0.229253 model2 loss : 0.240272
[23:15:45.489] iteration 15034 : model1 loss : 0.187808 model2 loss : 0.225905
[23:15:45.827] iteration 15035 : model1 loss : 0.248453 model2 loss : 0.297956
[23:15:46.163] iteration 15036 : model1 loss : 0.298216 model2 loss : 0.308457
[23:15:46.500] iteration 15037 : model1 loss : 0.191717 model2 loss : 0.209387
[23:15:46.842] iteration 15038 : model1 loss : 0.176098 model2 loss : 0.186249
[23:15:47.183] iteration 15039 : model1 loss : 0.399588 model2 loss : 0.401272
[23:15:47.523] iteration 15040 : model1 loss : 0.224337 model2 loss : 0.212972
[23:15:47.851] iteration 15041 : model1 loss : 0.217241 model2 loss : 0.254673
[23:15:48.178] iteration 15042 : model1 loss : 0.245927 model2 loss : 0.333495
[23:15:48.505] iteration 15043 : model1 loss : 0.169861 model2 loss : 0.196575
[23:15:48.832] iteration 15044 : model1 loss : 0.183422 model2 loss : 0.233336
[23:15:49.160] iteration 15045 : model1 loss : 0.180073 model2 loss : 0.256717
[23:15:49.488] iteration 15046 : model1 loss : 0.083092 model2 loss : 0.107258
[23:15:49.816] iteration 15047 : model1 loss : 0.272358 model2 loss : 0.425959
[23:15:50.144] iteration 15048 : model1 loss : 0.216873 model2 loss : 0.248361
[23:15:50.473] iteration 15049 : model1 loss : 0.275172 model2 loss : 0.308446
[23:15:50.800] iteration 15050 : model1 loss : 0.275454 model2 loss : 0.277367
[23:15:51.364] iteration 15051 : model1 loss : 0.167393 model2 loss : 0.242438
[23:15:51.691] iteration 15052 : model1 loss : 0.198780 model2 loss : 0.224888
[23:15:52.018] iteration 15053 : model1 loss : 0.203765 model2 loss : 0.226995
[23:15:52.347] iteration 15054 : model1 loss : 0.179146 model2 loss : 0.186466
[23:15:52.691] iteration 15055 : model1 loss : 0.167068 model2 loss : 0.251846
[23:15:53.028] iteration 15056 : model1 loss : 0.296632 model2 loss : 0.317265
[23:15:53.356] iteration 15057 : model1 loss : 0.169878 model2 loss : 0.195268
[23:15:53.683] iteration 15058 : model1 loss : 0.214769 model2 loss : 0.316255
[23:15:54.010] iteration 15059 : model1 loss : 0.102958 model2 loss : 0.142619
[23:15:54.337] iteration 15060 : model1 loss : 0.245219 model2 loss : 0.287039
[23:15:54.667] iteration 15061 : model1 loss : 0.113021 model2 loss : 0.151766
[23:15:54.995] iteration 15062 : model1 loss : 0.209847 model2 loss : 0.267414
[23:15:55.323] iteration 15063 : model1 loss : 0.141653 model2 loss : 0.167071
[23:15:55.650] iteration 15064 : model1 loss : 0.175187 model2 loss : 0.185991
[23:15:55.978] iteration 15065 : model1 loss : 0.169711 model2 loss : 0.179293
[23:15:56.305] iteration 15066 : model1 loss : 0.200193 model2 loss : 0.239323
[23:15:56.633] iteration 15067 : model1 loss : 0.277136 model2 loss : 0.270316
[23:15:56.960] iteration 15068 : model1 loss : 0.173137 model2 loss : 0.228694
[23:15:57.290] iteration 15069 : model1 loss : 0.276141 model2 loss : 0.291514
[23:15:57.629] iteration 15070 : model1 loss : 0.192286 model2 loss : 0.271659
[23:15:57.975] iteration 15071 : model1 loss : 0.208513 model2 loss : 0.277941
[23:15:58.311] iteration 15072 : model1 loss : 0.125182 model2 loss : 0.189260
[23:15:58.648] iteration 15073 : model1 loss : 0.155455 model2 loss : 0.173630
[23:15:58.986] iteration 15074 : model1 loss : 0.271977 model2 loss : 0.301667
[23:15:59.325] iteration 15075 : model1 loss : 0.301003 model2 loss : 0.310598
[23:15:59.660] iteration 15076 : model1 loss : 0.111899 model2 loss : 0.194146
[23:16:00.002] iteration 15077 : model1 loss : 0.101649 model2 loss : 0.190256
[23:16:00.339] iteration 15078 : model1 loss : 0.153467 model2 loss : 0.299357
[23:16:00.675] iteration 15079 : model1 loss : 0.228499 model2 loss : 0.283409
[23:16:01.011] iteration 15080 : model1 loss : 0.077467 model2 loss : 0.105331
[23:16:01.348] iteration 15081 : model1 loss : 0.354682 model2 loss : 0.390062
[23:16:01.683] iteration 15082 : model1 loss : 0.249316 model2 loss : 0.241583
[23:16:02.020] iteration 15083 : model1 loss : 0.303246 model2 loss : 0.316501
[23:16:02.355] iteration 15084 : model1 loss : 0.258765 model2 loss : 0.315038
[23:16:02.691] iteration 15085 : model1 loss : 0.195839 model2 loss : 0.260243
[23:16:03.027] iteration 15086 : model1 loss : 0.304666 model2 loss : 0.213378
[23:16:03.363] iteration 15087 : model1 loss : 0.244821 model2 loss : 0.268890
[23:16:03.701] iteration 15088 : model1 loss : 0.116083 model2 loss : 0.149346
[23:16:04.032] iteration 15089 : model1 loss : 0.145987 model2 loss : 0.147213
[23:16:04.360] iteration 15090 : model1 loss : 0.191857 model2 loss : 0.239683
[23:16:04.687] iteration 15091 : model1 loss : 0.216253 model2 loss : 0.210392
[23:16:05.016] iteration 15092 : model1 loss : 0.126250 model2 loss : 0.173161
[23:16:05.345] iteration 15093 : model1 loss : 0.189697 model2 loss : 0.193575
[23:16:05.673] iteration 15094 : model1 loss : 0.135787 model2 loss : 0.233656
[23:16:06.001] iteration 15095 : model1 loss : 0.204437 model2 loss : 0.220307
[23:16:06.328] iteration 15096 : model1 loss : 0.282726 model2 loss : 0.306572
[23:16:06.656] iteration 15097 : model1 loss : 0.422508 model2 loss : 0.424141
[23:16:06.985] iteration 15098 : model1 loss : 0.098338 model2 loss : 0.109771
[23:16:07.312] iteration 15099 : model1 loss : 0.235400 model2 loss : 0.235266
[23:16:07.642] iteration 15100 : model1 loss : 0.264717 model2 loss : 0.318834
[23:16:08.169] iteration 15101 : model1 loss : 0.170397 model2 loss : 0.181993
[23:16:08.497] iteration 15102 : model1 loss : 0.139994 model2 loss : 0.200332
[23:16:08.826] iteration 15103 : model1 loss : 0.218215 model2 loss : 0.239365
[23:16:09.156] iteration 15104 : model1 loss : 0.238673 model2 loss : 0.251769
[23:16:09.487] iteration 15105 : model1 loss : 0.239767 model2 loss : 0.224612
[23:16:09.819] iteration 15106 : model1 loss : 0.273745 model2 loss : 0.295156
[23:16:10.152] iteration 15107 : model1 loss : 0.231685 model2 loss : 0.177352
[23:16:10.482] iteration 15108 : model1 loss : 0.228042 model2 loss : 0.241844
[23:16:10.812] iteration 15109 : model1 loss : 0.180543 model2 loss : 0.186732
[23:16:11.142] iteration 15110 : model1 loss : 0.163422 model2 loss : 0.210041
[23:16:11.471] iteration 15111 : model1 loss : 0.222756 model2 loss : 0.242024
[23:16:11.800] iteration 15112 : model1 loss : 0.169951 model2 loss : 0.170812
[23:16:12.130] iteration 15113 : model1 loss : 0.190971 model2 loss : 0.198439
[23:16:12.459] iteration 15114 : model1 loss : 0.208536 model2 loss : 0.209047
[23:16:12.791] iteration 15115 : model1 loss : 0.151177 model2 loss : 0.211880
[23:16:13.119] iteration 15116 : model1 loss : 0.175698 model2 loss : 0.160821
[23:16:13.448] iteration 15117 : model1 loss : 0.181906 model2 loss : 0.201861
[23:16:13.778] iteration 15118 : model1 loss : 0.184103 model2 loss : 0.145856
[23:16:14.106] iteration 15119 : model1 loss : 0.196729 model2 loss : 0.242065
[23:16:14.435] iteration 15120 : model1 loss : 0.104580 model2 loss : 0.079060
[23:16:14.763] iteration 15121 : model1 loss : 0.239251 model2 loss : 0.225413
[23:16:15.100] iteration 15122 : model1 loss : 0.162694 model2 loss : 0.164569
[23:16:15.428] iteration 15123 : model1 loss : 0.210657 model2 loss : 0.301248
[23:16:15.757] iteration 15124 : model1 loss : 0.361535 model2 loss : 0.359479
[23:16:16.087] iteration 15125 : model1 loss : 0.142222 model2 loss : 0.155763
[23:16:16.418] iteration 15126 : model1 loss : 0.283291 model2 loss : 0.290616
[23:16:16.746] iteration 15127 : model1 loss : 0.248029 model2 loss : 0.259964
[23:16:17.074] iteration 15128 : model1 loss : 0.178518 model2 loss : 0.228836
[23:16:17.405] iteration 15129 : model1 loss : 0.297579 model2 loss : 0.316821
[23:16:17.735] iteration 15130 : model1 loss : 0.327368 model2 loss : 0.349557
[23:16:18.067] iteration 15131 : model1 loss : 0.174039 model2 loss : 0.244867
[23:16:18.395] iteration 15132 : model1 loss : 0.143848 model2 loss : 0.165285
[23:16:18.725] iteration 15133 : model1 loss : 0.166398 model2 loss : 0.213884
[23:16:19.053] iteration 15134 : model1 loss : 0.224411 model2 loss : 0.308372
[23:16:19.381] iteration 15135 : model1 loss : 0.291769 model2 loss : 0.323806
[23:16:19.710] iteration 15136 : model1 loss : 0.113368 model2 loss : 0.167415
[23:16:20.038] iteration 15137 : model1 loss : 0.174012 model2 loss : 0.207993
[23:16:20.370] iteration 15138 : model1 loss : 0.197147 model2 loss : 0.212219
[23:16:20.698] iteration 15139 : model1 loss : 0.234340 model2 loss : 0.180476
[23:16:21.026] iteration 15140 : model1 loss : 0.169403 model2 loss : 0.266439
[23:16:21.357] iteration 15141 : model1 loss : 0.287172 model2 loss : 0.207827
[23:16:21.688] iteration 15142 : model1 loss : 0.143426 model2 loss : 0.154763
[23:16:22.020] iteration 15143 : model1 loss : 0.156594 model2 loss : 0.167912
[23:16:22.350] iteration 15144 : model1 loss : 0.097360 model2 loss : 0.188805
[23:16:22.680] iteration 15145 : model1 loss : 0.249434 model2 loss : 0.171179
[23:16:23.010] iteration 15146 : model1 loss : 0.271993 model2 loss : 0.241747
[23:16:23.340] iteration 15147 : model1 loss : 0.104708 model2 loss : 0.109048
[23:16:23.671] iteration 15148 : model1 loss : 0.301346 model2 loss : 0.209346
[23:16:24.003] iteration 15149 : model1 loss : 0.119383 model2 loss : 0.109775
[23:16:24.344] iteration 15150 : model1 loss : 0.078238 model2 loss : 0.089628
[23:16:25.032] iteration 15151 : model1 loss : 0.097847 model2 loss : 0.167291
[23:16:25.371] iteration 15152 : model1 loss : 0.284127 model2 loss : 0.301478
[23:16:25.724] iteration 15153 : model1 loss : 0.203434 model2 loss : 0.171220
[23:16:26.062] iteration 15154 : model1 loss : 0.193171 model2 loss : 0.202092
[23:16:26.406] iteration 15155 : model1 loss : 0.255355 model2 loss : 0.280473
[23:16:26.745] iteration 15156 : model1 loss : 0.265061 model2 loss : 0.281912
[23:16:27.084] iteration 15157 : model1 loss : 0.245244 model2 loss : 0.276763
[23:16:27.427] iteration 15158 : model1 loss : 0.207095 model2 loss : 0.271733
[23:16:27.773] iteration 15159 : model1 loss : 0.311310 model2 loss : 0.353745
[23:16:28.113] iteration 15160 : model1 loss : 0.262375 model2 loss : 0.271514
[23:16:28.446] iteration 15161 : model1 loss : 0.212334 model2 loss : 0.290761
[23:16:28.776] iteration 15162 : model1 loss : 0.088364 model2 loss : 0.082854
[23:16:29.117] iteration 15163 : model1 loss : 0.192150 model2 loss : 0.294936
[23:16:29.446] iteration 15164 : model1 loss : 0.242920 model2 loss : 0.279700
[23:16:29.777] iteration 15165 : model1 loss : 0.098465 model2 loss : 0.115409
[23:16:30.106] iteration 15166 : model1 loss : 0.252677 model2 loss : 0.268688
[23:16:30.445] iteration 15167 : model1 loss : 0.193716 model2 loss : 0.192109
[23:16:30.785] iteration 15168 : model1 loss : 0.089163 model2 loss : 0.112792
[23:16:31.124] iteration 15169 : model1 loss : 0.182675 model2 loss : 0.253001
[23:16:31.462] iteration 15170 : model1 loss : 0.252641 model2 loss : 0.265668
[23:16:31.800] iteration 15171 : model1 loss : 0.090706 model2 loss : 0.152385
[23:16:32.138] iteration 15172 : model1 loss : 0.191940 model2 loss : 0.208609
[23:16:32.475] iteration 15173 : model1 loss : 0.194397 model2 loss : 0.226721
[23:16:32.814] iteration 15174 : model1 loss : 0.200783 model2 loss : 0.281754
[23:16:33.152] iteration 15175 : model1 loss : 0.219005 model2 loss : 0.264834
[23:16:33.495] iteration 15176 : model1 loss : 0.277034 model2 loss : 0.279299
[23:16:33.832] iteration 15177 : model1 loss : 0.246697 model2 loss : 0.300556
[23:16:34.170] iteration 15178 : model1 loss : 0.219492 model2 loss : 0.236269
[23:16:34.509] iteration 15179 : model1 loss : 0.171258 model2 loss : 0.187347
[23:16:34.845] iteration 15180 : model1 loss : 0.267853 model2 loss : 0.250543
[23:16:35.187] iteration 15181 : model1 loss : 0.204891 model2 loss : 0.251910
[23:16:35.526] iteration 15182 : model1 loss : 0.268355 model2 loss : 0.278087
[23:16:35.866] iteration 15183 : model1 loss : 0.287301 model2 loss : 0.276573
[23:16:36.203] iteration 15184 : model1 loss : 0.186182 model2 loss : 0.200646
[23:16:36.539] iteration 15185 : model1 loss : 0.300212 model2 loss : 0.315730
[23:16:36.876] iteration 15186 : model1 loss : 0.299611 model2 loss : 0.356244
[23:16:37.210] iteration 15187 : model1 loss : 0.283485 model2 loss : 0.298945
[23:16:37.538] iteration 15188 : model1 loss : 0.228098 model2 loss : 0.247389
[23:16:37.867] iteration 15189 : model1 loss : 0.199126 model2 loss : 0.242753
[23:16:38.195] iteration 15190 : model1 loss : 0.322834 model2 loss : 0.325256
[23:16:38.522] iteration 15191 : model1 loss : 0.263248 model2 loss : 0.294254
[23:16:38.850] iteration 15192 : model1 loss : 0.318213 model2 loss : 0.340038
[23:16:39.177] iteration 15193 : model1 loss : 0.203558 model2 loss : 0.214287
[23:16:39.505] iteration 15194 : model1 loss : 0.099416 model2 loss : 0.132328
[23:16:39.833] iteration 15195 : model1 loss : 0.180665 model2 loss : 0.228678
[23:16:40.161] iteration 15196 : model1 loss : 0.265353 model2 loss : 0.270426
[23:16:40.499] iteration 15197 : model1 loss : 0.168689 model2 loss : 0.217891
[23:16:40.836] iteration 15198 : model1 loss : 0.192020 model2 loss : 0.212169
[23:16:41.176] iteration 15199 : model1 loss : 0.270353 model2 loss : 0.280472
[23:16:41.512] iteration 15200 : model1 loss : 0.251156 model2 loss : 0.316373
[23:16:42.148] iteration 15201 : model1 loss : 0.224477 model2 loss : 0.192100
[23:16:42.487] iteration 15202 : model1 loss : 0.201075 model2 loss : 0.173435
[23:16:42.823] iteration 15203 : model1 loss : 0.211938 model2 loss : 0.210404
[23:16:43.160] iteration 15204 : model1 loss : 0.198889 model2 loss : 0.332377
[23:16:43.497] iteration 15205 : model1 loss : 0.152386 model2 loss : 0.208501
[23:16:43.832] iteration 15206 : model1 loss : 0.220729 model2 loss : 0.276557
[23:16:44.169] iteration 15207 : model1 loss : 0.109922 model2 loss : 0.113249
[23:16:44.507] iteration 15208 : model1 loss : 0.126486 model2 loss : 0.126804
[23:16:44.843] iteration 15209 : model1 loss : 0.191082 model2 loss : 0.218808
[23:16:45.184] iteration 15210 : model1 loss : 0.281620 model2 loss : 0.314399
[23:16:45.522] iteration 15211 : model1 loss : 0.219465 model2 loss : 0.229371
[23:16:45.860] iteration 15212 : model1 loss : 0.125199 model2 loss : 0.173722
[23:16:46.198] iteration 15213 : model1 loss : 0.183650 model2 loss : 0.226761
[23:16:46.536] iteration 15214 : model1 loss : 0.194847 model2 loss : 0.219030
[23:16:46.873] iteration 15215 : model1 loss : 0.331411 model2 loss : 0.351242
[23:16:47.209] iteration 15216 : model1 loss : 0.290867 model2 loss : 0.364002
[23:16:47.545] iteration 15217 : model1 loss : 0.168512 model2 loss : 0.193624
[23:16:47.882] iteration 15218 : model1 loss : 0.222474 model2 loss : 0.246259
[23:16:48.219] iteration 15219 : model1 loss : 0.170391 model2 loss : 0.185222
[23:16:48.559] iteration 15220 : model1 loss : 0.139845 model2 loss : 0.164437
[23:16:48.895] iteration 15221 : model1 loss : 0.219393 model2 loss : 0.241012
[23:16:49.231] iteration 15222 : model1 loss : 0.112245 model2 loss : 0.205084
[23:16:49.569] iteration 15223 : model1 loss : 0.315644 model2 loss : 0.234310
[23:16:49.905] iteration 15224 : model1 loss : 0.167395 model2 loss : 0.222325
[23:16:50.247] iteration 15225 : model1 loss : 0.227948 model2 loss : 0.246764
[23:16:50.589] iteration 15226 : model1 loss : 0.278126 model2 loss : 0.291222
[23:16:50.939] iteration 15227 : model1 loss : 0.195341 model2 loss : 0.217627
[23:16:51.278] iteration 15228 : model1 loss : 0.193130 model2 loss : 0.226049
[23:16:51.616] iteration 15229 : model1 loss : 0.093062 model2 loss : 0.155647
[23:16:51.954] iteration 15230 : model1 loss : 0.218626 model2 loss : 0.261824
[23:16:52.292] iteration 15231 : model1 loss : 0.178216 model2 loss : 0.219276
[23:16:52.630] iteration 15232 : model1 loss : 0.204731 model2 loss : 0.208424
[23:16:52.972] iteration 15233 : model1 loss : 0.267278 model2 loss : 0.281641
[23:16:53.310] iteration 15234 : model1 loss : 0.210141 model2 loss : 0.249713
[23:16:53.648] iteration 15235 : model1 loss : 0.215071 model2 loss : 0.259618
[23:16:53.993] iteration 15236 : model1 loss : 0.268199 model2 loss : 0.314243
[23:16:54.331] iteration 15237 : model1 loss : 0.187777 model2 loss : 0.214684
[23:16:54.669] iteration 15238 : model1 loss : 0.219727 model2 loss : 0.257794
[23:16:55.009] iteration 15239 : model1 loss : 0.281426 model2 loss : 0.261447
[23:16:55.348] iteration 15240 : model1 loss : 0.129965 model2 loss : 0.149036
[23:16:55.691] iteration 15241 : model1 loss : 0.254783 model2 loss : 0.264571
[23:16:56.029] iteration 15242 : model1 loss : 0.159990 model2 loss : 0.176406
[23:16:56.367] iteration 15243 : model1 loss : 0.160926 model2 loss : 0.264325
[23:16:56.706] iteration 15244 : model1 loss : 0.098602 model2 loss : 0.156510
[23:16:57.046] iteration 15245 : model1 loss : 0.126007 model2 loss : 0.231037
[23:16:57.384] iteration 15246 : model1 loss : 0.261247 model2 loss : 0.298223
[23:16:57.721] iteration 15247 : model1 loss : 0.173685 model2 loss : 0.221692
[23:16:58.058] iteration 15248 : model1 loss : 0.180615 model2 loss : 0.238326
[23:16:58.393] iteration 15249 : model1 loss : 0.433672 model2 loss : 0.463250
[23:16:58.734] iteration 15250 : model1 loss : 0.344476 model2 loss : 0.340133
[23:16:59.397] iteration 15251 : model1 loss : 0.167792 model2 loss : 0.202247
[23:16:59.734] iteration 15252 : model1 loss : 0.168239 model2 loss : 0.158555
[23:17:00.071] iteration 15253 : model1 loss : 0.288327 model2 loss : 0.311768
[23:17:00.408] iteration 15254 : model1 loss : 0.127030 model2 loss : 0.212041
[23:17:00.743] iteration 15255 : model1 loss : 0.209816 model2 loss : 0.249863
[23:17:01.079] iteration 15256 : model1 loss : 0.202780 model2 loss : 0.233939
[23:17:01.415] iteration 15257 : model1 loss : 0.308230 model2 loss : 0.247468
[23:17:01.750] iteration 15258 : model1 loss : 0.175557 model2 loss : 0.210469
[23:17:02.085] iteration 15259 : model1 loss : 0.254344 model2 loss : 0.309812
[23:17:02.420] iteration 15260 : model1 loss : 0.257262 model2 loss : 0.294865
[23:17:03.421] iteration 15261 : model1 loss : 0.228040 model2 loss : 0.274809
[23:17:03.757] iteration 15262 : model1 loss : 0.150067 model2 loss : 0.182851
[23:17:04.094] iteration 15263 : model1 loss : 0.176709 model2 loss : 0.205541
[23:17:04.430] iteration 15264 : model1 loss : 0.115956 model2 loss : 0.175056
[23:17:04.766] iteration 15265 : model1 loss : 0.188976 model2 loss : 0.219554
[23:17:05.102] iteration 15266 : model1 loss : 0.267270 model2 loss : 0.275265
[23:17:05.442] iteration 15267 : model1 loss : 0.247374 model2 loss : 0.268825
[23:17:05.778] iteration 15268 : model1 loss : 0.269473 model2 loss : 0.200648
[23:17:06.114] iteration 15269 : model1 loss : 0.259587 model2 loss : 0.287083
[23:17:06.451] iteration 15270 : model1 loss : 0.166754 model2 loss : 0.159500
[23:17:06.793] iteration 15271 : model1 loss : 0.358312 model2 loss : 0.393458
[23:17:07.130] iteration 15272 : model1 loss : 0.287429 model2 loss : 0.361588
[23:17:07.467] iteration 15273 : model1 loss : 0.138370 model2 loss : 0.193103
[23:17:07.804] iteration 15274 : model1 loss : 0.233467 model2 loss : 0.244592
[23:17:08.147] iteration 15275 : model1 loss : 0.249178 model2 loss : 0.238135
[23:17:08.485] iteration 15276 : model1 loss : 0.206652 model2 loss : 0.290164
[23:17:08.823] iteration 15277 : model1 loss : 0.266711 model2 loss : 0.272388
[23:17:09.162] iteration 15278 : model1 loss : 0.124331 model2 loss : 0.171922
[23:17:09.504] iteration 15279 : model1 loss : 0.189278 model2 loss : 0.209766
[23:17:09.844] iteration 15280 : model1 loss : 0.124080 model2 loss : 0.102396
[23:17:10.182] iteration 15281 : model1 loss : 0.154969 model2 loss : 0.175892
[23:17:10.518] iteration 15282 : model1 loss : 0.102704 model2 loss : 0.159390
[23:17:10.859] iteration 15283 : model1 loss : 0.144166 model2 loss : 0.108618
[23:17:11.196] iteration 15284 : model1 loss : 0.125853 model2 loss : 0.152347
[23:17:11.536] iteration 15285 : model1 loss : 0.271503 model2 loss : 0.311725
[23:17:11.873] iteration 15286 : model1 loss : 0.229633 model2 loss : 0.300648
[23:17:12.208] iteration 15287 : model1 loss : 0.206792 model2 loss : 0.248005
[23:17:12.552] iteration 15288 : model1 loss : 0.179308 model2 loss : 0.259879
[23:17:12.886] iteration 15289 : model1 loss : 0.166042 model2 loss : 0.166946
[23:17:13.223] iteration 15290 : model1 loss : 0.252085 model2 loss : 0.320004
[23:17:13.564] iteration 15291 : model1 loss : 0.207333 model2 loss : 0.265890
[23:17:13.903] iteration 15292 : model1 loss : 0.257957 model2 loss : 0.267063
[23:17:14.232] iteration 15293 : model1 loss : 0.211853 model2 loss : 0.273065
[23:17:14.561] iteration 15294 : model1 loss : 0.186151 model2 loss : 0.215888
[23:17:14.888] iteration 15295 : model1 loss : 0.205634 model2 loss : 0.229374
[23:17:15.218] iteration 15296 : model1 loss : 0.305581 model2 loss : 0.239420
[23:17:15.557] iteration 15297 : model1 loss : 0.211338 model2 loss : 0.264385
[23:17:15.899] iteration 15298 : model1 loss : 0.207024 model2 loss : 0.215295
[23:17:16.236] iteration 15299 : model1 loss : 0.086345 model2 loss : 0.152796
[23:17:16.573] iteration 15300 : model1 loss : 0.175270 model2 loss : 0.222651
[23:17:17.227] iteration 15301 : model1 loss : 0.219173 model2 loss : 0.204631
[23:17:17.566] iteration 15302 : model1 loss : 0.166511 model2 loss : 0.172144
[23:17:17.908] iteration 15303 : model1 loss : 0.340924 model2 loss : 0.330237
[23:17:18.247] iteration 15304 : model1 loss : 0.182754 model2 loss : 0.249139
[23:17:18.588] iteration 15305 : model1 loss : 0.168703 model2 loss : 0.257074
[23:17:18.927] iteration 15306 : model1 loss : 0.251294 model2 loss : 0.259156
[23:17:19.300] iteration 15307 : model1 loss : 0.208608 model2 loss : 0.282004
[23:17:19.639] iteration 15308 : model1 loss : 0.255120 model2 loss : 0.288417
[23:17:19.974] iteration 15309 : model1 loss : 0.158226 model2 loss : 0.158155
[23:17:20.318] iteration 15310 : model1 loss : 0.243777 model2 loss : 0.232834
[23:17:20.656] iteration 15311 : model1 loss : 0.136412 model2 loss : 0.172432
[23:17:20.995] iteration 15312 : model1 loss : 0.176443 model2 loss : 0.248613
[23:17:21.333] iteration 15313 : model1 loss : 0.216141 model2 loss : 0.241320
[23:17:21.675] iteration 15314 : model1 loss : 0.081113 model2 loss : 0.122902
[23:17:22.010] iteration 15315 : model1 loss : 0.140950 model2 loss : 0.184757
[23:17:22.350] iteration 15316 : model1 loss : 0.200354 model2 loss : 0.200406
[23:17:22.690] iteration 15317 : model1 loss : 0.257416 model2 loss : 0.257294
[23:17:23.030] iteration 15318 : model1 loss : 0.138412 model2 loss : 0.154941
[23:17:23.366] iteration 15319 : model1 loss : 0.229284 model2 loss : 0.222724
[23:17:23.703] iteration 15320 : model1 loss : 0.166492 model2 loss : 0.196358
[23:17:24.039] iteration 15321 : model1 loss : 0.228870 model2 loss : 0.256274
[23:17:24.387] iteration 15322 : model1 loss : 0.123052 model2 loss : 0.115787
[23:17:24.733] iteration 15323 : model1 loss : 0.164647 model2 loss : 0.198263
[23:17:25.072] iteration 15324 : model1 loss : 0.243502 model2 loss : 0.275765
[23:17:25.410] iteration 15325 : model1 loss : 0.180287 model2 loss : 0.219309
[23:17:25.748] iteration 15326 : model1 loss : 0.226571 model2 loss : 0.314972
[23:17:26.085] iteration 15327 : model1 loss : 0.264184 model2 loss : 0.273508
[23:17:26.422] iteration 15328 : model1 loss : 0.295336 model2 loss : 0.300268
[23:17:26.760] iteration 15329 : model1 loss : 0.175487 model2 loss : 0.249434
[23:17:27.102] iteration 15330 : model1 loss : 0.167273 model2 loss : 0.206879
[23:17:27.443] iteration 15331 : model1 loss : 0.204891 model2 loss : 0.206150
[23:17:27.783] iteration 15332 : model1 loss : 0.120453 model2 loss : 0.111934
[23:17:28.122] iteration 15333 : model1 loss : 0.261743 model2 loss : 0.269641
[23:17:28.460] iteration 15334 : model1 loss : 0.144610 model2 loss : 0.276578
[23:17:28.799] iteration 15335 : model1 loss : 0.077666 model2 loss : 0.143488
[23:17:29.138] iteration 15336 : model1 loss : 0.316660 model2 loss : 0.326915
[23:17:29.482] iteration 15337 : model1 loss : 0.149088 model2 loss : 0.143034
[23:17:29.824] iteration 15338 : model1 loss : 0.195793 model2 loss : 0.194946
[23:17:30.162] iteration 15339 : model1 loss : 0.133663 model2 loss : 0.116791
[23:17:30.500] iteration 15340 : model1 loss : 0.094943 model2 loss : 0.150953
[23:17:30.837] iteration 15341 : model1 loss : 0.157690 model2 loss : 0.218642
[23:17:31.174] iteration 15342 : model1 loss : 0.294747 model2 loss : 0.319524
[23:17:31.513] iteration 15343 : model1 loss : 0.115256 model2 loss : 0.184301
[23:17:31.849] iteration 15344 : model1 loss : 0.209639 model2 loss : 0.228033
[23:17:32.188] iteration 15345 : model1 loss : 0.193510 model2 loss : 0.277880
[23:17:32.525] iteration 15346 : model1 loss : 0.203386 model2 loss : 0.206528
[23:17:32.861] iteration 15347 : model1 loss : 0.174253 model2 loss : 0.196774
[23:17:33.199] iteration 15348 : model1 loss : 0.301656 model2 loss : 0.318295
[23:17:33.537] iteration 15349 : model1 loss : 0.271619 model2 loss : 0.278933
[23:17:33.870] iteration 15350 : model1 loss : 0.287972 model2 loss : 0.282988
[23:17:34.508] iteration 15351 : model1 loss : 0.271158 model2 loss : 0.286871
[23:17:34.845] iteration 15352 : model1 loss : 0.077148 model2 loss : 0.110616
[23:17:35.182] iteration 15353 : model1 loss : 0.221852 model2 loss : 0.260901
[23:17:35.519] iteration 15354 : model1 loss : 0.215112 model2 loss : 0.244338
[23:17:35.855] iteration 15355 : model1 loss : 0.336148 model2 loss : 0.289492
[23:17:36.192] iteration 15356 : model1 loss : 0.200150 model2 loss : 0.215200
[23:17:36.529] iteration 15357 : model1 loss : 0.173961 model2 loss : 0.220641
[23:17:36.866] iteration 15358 : model1 loss : 0.196912 model2 loss : 0.309035
[23:17:37.203] iteration 15359 : model1 loss : 0.140247 model2 loss : 0.180358
[23:17:37.540] iteration 15360 : model1 loss : 0.166960 model2 loss : 0.208569
[23:17:37.878] iteration 15361 : model1 loss : 0.178319 model2 loss : 0.192703
[23:17:38.217] iteration 15362 : model1 loss : 0.181017 model2 loss : 0.232423
[23:17:38.553] iteration 15363 : model1 loss : 0.309613 model2 loss : 0.277862
[23:17:38.892] iteration 15364 : model1 loss : 0.147723 model2 loss : 0.197537
[23:17:39.230] iteration 15365 : model1 loss : 0.155978 model2 loss : 0.227539
[23:17:39.569] iteration 15366 : model1 loss : 0.170127 model2 loss : 0.241897
[23:17:39.908] iteration 15367 : model1 loss : 0.105713 model2 loss : 0.190842
[23:17:40.246] iteration 15368 : model1 loss : 0.288880 model2 loss : 0.352171
[23:17:40.584] iteration 15369 : model1 loss : 0.324204 model2 loss : 0.379312
[23:17:40.925] iteration 15370 : model1 loss : 0.187400 model2 loss : 0.211780
[23:17:41.262] iteration 15371 : model1 loss : 0.178264 model2 loss : 0.205807
[23:17:41.599] iteration 15372 : model1 loss : 0.398088 model2 loss : 0.402481
[23:17:41.938] iteration 15373 : model1 loss : 0.323112 model2 loss : 0.394807
[23:17:42.275] iteration 15374 : model1 loss : 0.174203 model2 loss : 0.226450
[23:17:42.613] iteration 15375 : model1 loss : 0.275024 model2 loss : 0.300586
[23:17:42.950] iteration 15376 : model1 loss : 0.111982 model2 loss : 0.178267
[23:17:43.287] iteration 15377 : model1 loss : 0.335343 model2 loss : 0.350468
[23:17:43.624] iteration 15378 : model1 loss : 0.105940 model2 loss : 0.217200
[23:17:43.960] iteration 15379 : model1 loss : 0.167348 model2 loss : 0.187200
[23:17:44.297] iteration 15380 : model1 loss : 0.187113 model2 loss : 0.216874
[23:17:44.633] iteration 15381 : model1 loss : 0.265754 model2 loss : 0.281612
[23:17:44.970] iteration 15382 : model1 loss : 0.215034 model2 loss : 0.251168
[23:17:45.307] iteration 15383 : model1 loss : 0.249272 model2 loss : 0.261463
[23:17:45.646] iteration 15384 : model1 loss : 0.210465 model2 loss : 0.247641
[23:17:45.982] iteration 15385 : model1 loss : 0.224139 model2 loss : 0.259407
[23:17:46.318] iteration 15386 : model1 loss : 0.395138 model2 loss : 0.403082
[23:17:46.655] iteration 15387 : model1 loss : 0.136188 model2 loss : 0.238704
[23:17:46.991] iteration 15388 : model1 loss : 0.249891 model2 loss : 0.272701
[23:17:47.328] iteration 15389 : model1 loss : 0.253892 model2 loss : 0.265762
[23:17:47.664] iteration 15390 : model1 loss : 0.179367 model2 loss : 0.195637
[23:17:48.000] iteration 15391 : model1 loss : 0.208354 model2 loss : 0.210403
[23:17:48.337] iteration 15392 : model1 loss : 0.097861 model2 loss : 0.168219
[23:17:48.674] iteration 15393 : model1 loss : 0.246611 model2 loss : 0.271796
[23:17:49.010] iteration 15394 : model1 loss : 0.166866 model2 loss : 0.176083
[23:17:49.348] iteration 15395 : model1 loss : 0.186953 model2 loss : 0.207173
[23:17:49.685] iteration 15396 : model1 loss : 0.343717 model2 loss : 0.347272
[23:17:50.022] iteration 15397 : model1 loss : 0.219668 model2 loss : 0.299437
[23:17:50.370] iteration 15398 : model1 loss : 0.304816 model2 loss : 0.317642
[23:17:50.707] iteration 15399 : model1 loss : 0.098228 model2 loss : 0.201670
[23:17:51.044] iteration 15400 : model1 loss : 0.211555 model2 loss : 0.222106
[23:17:51.685] iteration 15401 : model1 loss : 0.300736 model2 loss : 0.246302
[23:17:52.023] iteration 15402 : model1 loss : 0.167928 model2 loss : 0.215076
[23:17:52.360] iteration 15403 : model1 loss : 0.091211 model2 loss : 0.173318
[23:17:52.699] iteration 15404 : model1 loss : 0.318679 model2 loss : 0.329393
[23:17:53.035] iteration 15405 : model1 loss : 0.125897 model2 loss : 0.204567
[23:17:53.371] iteration 15406 : model1 loss : 0.164053 model2 loss : 0.200127
[23:17:53.708] iteration 15407 : model1 loss : 0.237449 model2 loss : 0.216400
[23:17:54.044] iteration 15408 : model1 loss : 0.107131 model2 loss : 0.120757
[23:17:54.382] iteration 15409 : model1 loss : 0.070179 model2 loss : 0.242498
[23:17:54.719] iteration 15410 : model1 loss : 0.159024 model2 loss : 0.167485
[23:17:55.056] iteration 15411 : model1 loss : 0.167263 model2 loss : 0.169713
[23:17:55.394] iteration 15412 : model1 loss : 0.211097 model2 loss : 0.244252
[23:17:55.731] iteration 15413 : model1 loss : 0.250740 model2 loss : 0.265532
[23:17:56.068] iteration 15414 : model1 loss : 0.320873 model2 loss : 0.330410
[23:17:56.405] iteration 15415 : model1 loss : 0.201630 model2 loss : 0.253311
[23:17:56.743] iteration 15416 : model1 loss : 0.162290 model2 loss : 0.175443
[23:17:57.082] iteration 15417 : model1 loss : 0.266871 model2 loss : 0.255915
[23:17:57.418] iteration 15418 : model1 loss : 0.172009 model2 loss : 0.181831
[23:17:57.755] iteration 15419 : model1 loss : 0.178688 model2 loss : 0.208076
[23:17:58.092] iteration 15420 : model1 loss : 0.206104 model2 loss : 0.342932
[23:17:58.428] iteration 15421 : model1 loss : 0.142140 model2 loss : 0.142054
[23:17:58.765] iteration 15422 : model1 loss : 0.176322 model2 loss : 0.339822
[23:17:59.103] iteration 15423 : model1 loss : 0.186108 model2 loss : 0.223028
[23:17:59.443] iteration 15424 : model1 loss : 0.211760 model2 loss : 0.258007
[23:17:59.780] iteration 15425 : model1 loss : 0.154641 model2 loss : 0.247567
[23:18:00.117] iteration 15426 : model1 loss : 0.332627 model2 loss : 0.345236
[23:18:00.454] iteration 15427 : model1 loss : 0.215753 model2 loss : 0.244048
[23:18:00.790] iteration 15428 : model1 loss : 0.166358 model2 loss : 0.122915
[23:18:01.127] iteration 15429 : model1 loss : 0.194204 model2 loss : 0.165462
[23:18:01.464] iteration 15430 : model1 loss : 0.346626 model2 loss : 0.378540
[23:18:01.802] iteration 15431 : model1 loss : 0.242364 model2 loss : 0.290806
[23:18:02.140] iteration 15432 : model1 loss : 0.272870 model2 loss : 0.284374
[23:18:02.477] iteration 15433 : model1 loss : 0.174211 model2 loss : 0.144771
[23:18:02.814] iteration 15434 : model1 loss : 0.257575 model2 loss : 0.311786
[23:18:03.151] iteration 15435 : model1 loss : 0.309112 model2 loss : 0.299416
[23:18:03.488] iteration 15436 : model1 loss : 0.112730 model2 loss : 0.143346
[23:18:03.826] iteration 15437 : model1 loss : 0.130078 model2 loss : 0.152097
[23:18:04.163] iteration 15438 : model1 loss : 0.241525 model2 loss : 0.268673
[23:18:04.500] iteration 15439 : model1 loss : 0.210713 model2 loss : 0.259529
[23:18:04.837] iteration 15440 : model1 loss : 0.259352 model2 loss : 0.270902
[23:18:05.175] iteration 15441 : model1 loss : 0.149049 model2 loss : 0.221147
[23:18:05.511] iteration 15442 : model1 loss : 0.256095 model2 loss : 0.316440
[23:18:05.848] iteration 15443 : model1 loss : 0.224875 model2 loss : 0.266404
[23:18:06.185] iteration 15444 : model1 loss : 0.109571 model2 loss : 0.199813
[23:18:06.521] iteration 15445 : model1 loss : 0.146833 model2 loss : 0.117978
[23:18:06.858] iteration 15446 : model1 loss : 0.234300 model2 loss : 0.226530
[23:18:07.197] iteration 15447 : model1 loss : 0.113527 model2 loss : 0.132853
[23:18:07.535] iteration 15448 : model1 loss : 0.086245 model2 loss : 0.146948
[23:18:07.872] iteration 15449 : model1 loss : 0.171542 model2 loss : 0.193069
[23:18:08.208] iteration 15450 : model1 loss : 0.254616 model2 loss : 0.268228
[23:18:08.816] iteration 15451 : model1 loss : 0.201145 model2 loss : 0.219779
[23:18:09.154] iteration 15452 : model1 loss : 0.282874 model2 loss : 0.298810
[23:18:09.490] iteration 15453 : model1 loss : 0.118205 model2 loss : 0.190051
[23:18:09.827] iteration 15454 : model1 loss : 0.231890 model2 loss : 0.231005
[23:18:10.165] iteration 15455 : model1 loss : 0.289649 model2 loss : 0.345902
[23:18:10.502] iteration 15456 : model1 loss : 0.095919 model2 loss : 0.094329
[23:18:10.839] iteration 15457 : model1 loss : 0.187805 model2 loss : 0.225333
[23:18:11.175] iteration 15458 : model1 loss : 0.198550 model2 loss : 0.232124
[23:18:11.512] iteration 15459 : model1 loss : 0.189978 model2 loss : 0.173526
[23:18:11.849] iteration 15460 : model1 loss : 0.189037 model2 loss : 0.236494
[23:18:12.185] iteration 15461 : model1 loss : 0.203049 model2 loss : 0.223207
[23:18:12.522] iteration 15462 : model1 loss : 0.100468 model2 loss : 0.167349
[23:18:12.858] iteration 15463 : model1 loss : 0.130336 model2 loss : 0.213340
[23:18:13.195] iteration 15464 : model1 loss : 0.256225 model2 loss : 0.276803
[23:18:13.531] iteration 15465 : model1 loss : 0.167400 model2 loss : 0.173150
[23:18:13.867] iteration 15466 : model1 loss : 0.176954 model2 loss : 0.215082
[23:18:14.203] iteration 15467 : model1 loss : 0.216292 model2 loss : 0.321416
[23:18:14.539] iteration 15468 : model1 loss : 0.329948 model2 loss : 0.356901
[23:18:14.875] iteration 15469 : model1 loss : 0.154240 model2 loss : 0.207782
[23:18:15.212] iteration 15470 : model1 loss : 0.201812 model2 loss : 0.265936
[23:18:15.548] iteration 15471 : model1 loss : 0.311889 model2 loss : 0.409109
[23:18:15.884] iteration 15472 : model1 loss : 0.190681 model2 loss : 0.232058
[23:18:16.220] iteration 15473 : model1 loss : 0.268161 model2 loss : 0.306854
[23:18:16.556] iteration 15474 : model1 loss : 0.296001 model2 loss : 0.343333
[23:18:16.895] iteration 15475 : model1 loss : 0.187053 model2 loss : 0.211388
[23:18:17.231] iteration 15476 : model1 loss : 0.260580 model2 loss : 0.283570
[23:18:17.567] iteration 15477 : model1 loss : 0.186499 model2 loss : 0.228156
[23:18:17.903] iteration 15478 : model1 loss : 0.162220 model2 loss : 0.145773
[23:18:18.240] iteration 15479 : model1 loss : 0.278233 model2 loss : 0.328332
[23:18:18.576] iteration 15480 : model1 loss : 0.113926 model2 loss : 0.142824
[23:18:18.912] iteration 15481 : model1 loss : 0.092641 model2 loss : 0.114537
[23:18:19.249] iteration 15482 : model1 loss : 0.200324 model2 loss : 0.261685
[23:18:19.587] iteration 15483 : model1 loss : 0.145238 model2 loss : 0.233510
[23:18:19.924] iteration 15484 : model1 loss : 0.183643 model2 loss : 0.233603
[23:18:20.261] iteration 15485 : model1 loss : 0.252713 model2 loss : 0.255667
[23:18:20.599] iteration 15486 : model1 loss : 0.150851 model2 loss : 0.183563
[23:18:20.935] iteration 15487 : model1 loss : 0.186455 model2 loss : 0.199678
[23:18:21.271] iteration 15488 : model1 loss : 0.212464 model2 loss : 0.304838
[23:18:21.610] iteration 15489 : model1 loss : 0.159640 model2 loss : 0.173753
[23:18:21.946] iteration 15490 : model1 loss : 0.196373 model2 loss : 0.251608
[23:18:22.283] iteration 15491 : model1 loss : 0.278490 model2 loss : 0.289317
[23:18:22.619] iteration 15492 : model1 loss : 0.289169 model2 loss : 0.353696
[23:18:22.955] iteration 15493 : model1 loss : 0.112401 model2 loss : 0.174514
[23:18:23.290] iteration 15494 : model1 loss : 0.123914 model2 loss : 0.199310
[23:18:23.631] iteration 15495 : model1 loss : 0.218676 model2 loss : 0.181994
[23:18:23.969] iteration 15496 : model1 loss : 0.200078 model2 loss : 0.247753
[23:18:24.306] iteration 15497 : model1 loss : 0.271195 model2 loss : 0.276971
[23:18:24.642] iteration 15498 : model1 loss : 0.187674 model2 loss : 0.251183
[23:18:24.980] iteration 15499 : model1 loss : 0.241700 model2 loss : 0.257283
[23:18:25.317] iteration 15500 : model1 loss : 0.275300 model2 loss : 0.326699
[23:18:25.951] iteration 15501 : model1 loss : 0.259413 model2 loss : 0.303553
[23:18:26.293] iteration 15502 : model1 loss : 0.269732 model2 loss : 0.271908
[23:18:26.627] iteration 15503 : model1 loss : 0.159920 model2 loss : 0.170522
[23:18:26.964] iteration 15504 : model1 loss : 0.226623 model2 loss : 0.258704
[23:18:27.297] iteration 15505 : model1 loss : 0.250535 model2 loss : 0.285568
[23:18:27.631] iteration 15506 : model1 loss : 0.259789 model2 loss : 0.315074
[23:18:27.979] iteration 15507 : model1 loss : 0.155091 model2 loss : 0.189945
[23:18:28.315] iteration 15508 : model1 loss : 0.089801 model2 loss : 0.150150
[23:18:28.647] iteration 15509 : model1 loss : 0.231561 model2 loss : 0.282739
[23:18:28.999] iteration 15510 : model1 loss : 0.219990 model2 loss : 0.262841
[23:18:29.335] iteration 15511 : model1 loss : 0.187078 model2 loss : 0.207724
[23:18:29.671] iteration 15512 : model1 loss : 0.188890 model2 loss : 0.201537
[23:18:30.003] iteration 15513 : model1 loss : 0.197241 model2 loss : 0.217798
[23:18:30.340] iteration 15514 : model1 loss : 0.184990 model2 loss : 0.207653
[23:18:30.668] iteration 15515 : model1 loss : 0.102010 model2 loss : 0.186018
[23:18:30.997] iteration 15516 : model1 loss : 0.188020 model2 loss : 0.217494
[23:18:31.325] iteration 15517 : model1 loss : 0.249553 model2 loss : 0.197771
[23:18:31.653] iteration 15518 : model1 loss : 0.178520 model2 loss : 0.196393
[23:18:31.983] iteration 15519 : model1 loss : 0.168320 model2 loss : 0.192764
[23:18:32.310] iteration 15520 : model1 loss : 0.097552 model2 loss : 0.176299
[23:18:32.639] iteration 15521 : model1 loss : 0.445773 model2 loss : 0.479301
[23:18:32.969] iteration 15522 : model1 loss : 0.148613 model2 loss : 0.196103
[23:18:33.296] iteration 15523 : model1 loss : 0.107317 model2 loss : 0.144920
[23:18:33.626] iteration 15524 : model1 loss : 0.316374 model2 loss : 0.319470
[23:18:33.954] iteration 15525 : model1 loss : 0.098757 model2 loss : 0.121312
[23:18:34.282] iteration 15526 : model1 loss : 0.113576 model2 loss : 0.177838
[23:18:34.609] iteration 15527 : model1 loss : 0.158661 model2 loss : 0.220578
[23:18:34.936] iteration 15528 : model1 loss : 0.259709 model2 loss : 0.272998
[23:18:35.263] iteration 15529 : model1 loss : 0.146715 model2 loss : 0.224319
[23:18:35.590] iteration 15530 : model1 loss : 0.236645 model2 loss : 0.274096
[23:18:35.916] iteration 15531 : model1 loss : 0.140463 model2 loss : 0.142425
[23:18:36.244] iteration 15532 : model1 loss : 0.249417 model2 loss : 0.265110
[23:18:36.571] iteration 15533 : model1 loss : 0.215067 model2 loss : 0.244999
[23:18:36.897] iteration 15534 : model1 loss : 0.169982 model2 loss : 0.207829
[23:18:37.224] iteration 15535 : model1 loss : 0.256454 model2 loss : 0.251229
[23:18:37.551] iteration 15536 : model1 loss : 0.217258 model2 loss : 0.301816
[23:18:37.877] iteration 15537 : model1 loss : 0.243273 model2 loss : 0.301648
[23:18:38.203] iteration 15538 : model1 loss : 0.180762 model2 loss : 0.228374
[23:18:38.529] iteration 15539 : model1 loss : 0.252340 model2 loss : 0.261756
[23:18:38.856] iteration 15540 : model1 loss : 0.121636 model2 loss : 0.115164
[23:18:39.183] iteration 15541 : model1 loss : 0.326940 model2 loss : 0.354444
[23:18:39.510] iteration 15542 : model1 loss : 0.276852 model2 loss : 0.348590
[23:18:39.837] iteration 15543 : model1 loss : 0.261829 model2 loss : 0.345399
[23:18:40.163] iteration 15544 : model1 loss : 0.293103 model2 loss : 0.275813
[23:18:40.490] iteration 15545 : model1 loss : 0.279120 model2 loss : 0.284918
[23:18:40.817] iteration 15546 : model1 loss : 0.284210 model2 loss : 0.327484
[23:18:41.146] iteration 15547 : model1 loss : 0.238747 model2 loss : 0.306884
[23:18:41.472] iteration 15548 : model1 loss : 0.251539 model2 loss : 0.286266
[23:18:41.797] iteration 15549 : model1 loss : 0.261684 model2 loss : 0.237244
[23:18:42.124] iteration 15550 : model1 loss : 0.249517 model2 loss : 0.298339
[23:18:42.646] iteration 15551 : model1 loss : 0.243360 model2 loss : 0.277813
[23:18:42.974] iteration 15552 : model1 loss : 0.246310 model2 loss : 0.290576
[23:18:43.301] iteration 15553 : model1 loss : 0.260418 model2 loss : 0.342634
[23:18:43.629] iteration 15554 : model1 loss : 0.290817 model2 loss : 0.316269
[23:18:43.956] iteration 15555 : model1 loss : 0.153170 model2 loss : 0.171775
[23:18:44.284] iteration 15556 : model1 loss : 0.261739 model2 loss : 0.290215
[23:18:44.612] iteration 15557 : model1 loss : 0.276672 model2 loss : 0.336713
[23:18:44.938] iteration 15558 : model1 loss : 0.197033 model2 loss : 0.292376
[23:18:45.267] iteration 15559 : model1 loss : 0.246207 model2 loss : 0.290533
[23:18:45.595] iteration 15560 : model1 loss : 0.265231 model2 loss : 0.278792
[23:18:45.921] iteration 15561 : model1 loss : 0.198149 model2 loss : 0.222702
[23:18:46.248] iteration 15562 : model1 loss : 0.107411 model2 loss : 0.141590
[23:18:46.574] iteration 15563 : model1 loss : 0.300507 model2 loss : 0.378827
[23:18:46.901] iteration 15564 : model1 loss : 0.167747 model2 loss : 0.177009
[23:18:47.229] iteration 15565 : model1 loss : 0.268065 model2 loss : 0.318734
[23:18:47.556] iteration 15566 : model1 loss : 0.219435 model2 loss : 0.279991
[23:18:47.884] iteration 15567 : model1 loss : 0.197953 model2 loss : 0.242468
[23:18:48.212] iteration 15568 : model1 loss : 0.095080 model2 loss : 0.118280
[23:18:48.539] iteration 15569 : model1 loss : 0.326529 model2 loss : 0.357008
[23:18:48.866] iteration 15570 : model1 loss : 0.203445 model2 loss : 0.226900
[23:18:49.194] iteration 15571 : model1 loss : 0.214213 model2 loss : 0.242214
[23:18:49.522] iteration 15572 : model1 loss : 0.118010 model2 loss : 0.132273
[23:18:49.849] iteration 15573 : model1 loss : 0.243903 model2 loss : 0.316326
[23:18:50.177] iteration 15574 : model1 loss : 0.201981 model2 loss : 0.223512
[23:18:50.504] iteration 15575 : model1 loss : 0.178100 model2 loss : 0.282947
[23:18:50.831] iteration 15576 : model1 loss : 0.321029 model2 loss : 0.317144
[23:18:51.158] iteration 15577 : model1 loss : 0.328881 model2 loss : 0.313317
[23:18:51.486] iteration 15578 : model1 loss : 0.117831 model2 loss : 0.117397
[23:18:51.812] iteration 15579 : model1 loss : 0.164440 model2 loss : 0.186620
[23:18:52.138] iteration 15580 : model1 loss : 0.108637 model2 loss : 0.134002
[23:18:52.461] iteration 15581 : model1 loss : 0.284835 model2 loss : 0.331722
[23:18:52.782] iteration 15582 : model1 loss : 0.157539 model2 loss : 0.187617
[23:18:53.103] iteration 15583 : model1 loss : 0.200066 model2 loss : 0.145424
[23:18:53.427] iteration 15584 : model1 loss : 0.173789 model2 loss : 0.237783
[23:18:53.750] iteration 15585 : model1 loss : 0.100741 model2 loss : 0.108835
[23:18:54.081] iteration 15586 : model1 loss : 0.158824 model2 loss : 0.146978
[23:18:54.418] iteration 15587 : model1 loss : 0.218597 model2 loss : 0.237519
[23:18:54.755] iteration 15588 : model1 loss : 0.159230 model2 loss : 0.220665
[23:18:55.087] iteration 15589 : model1 loss : 0.253017 model2 loss : 0.256102
[23:18:55.425] iteration 15590 : model1 loss : 0.198968 model2 loss : 0.264538
[23:18:55.762] iteration 15591 : model1 loss : 0.077176 model2 loss : 0.115372
[23:18:56.097] iteration 15592 : model1 loss : 0.179628 model2 loss : 0.190238
[23:18:56.437] iteration 15593 : model1 loss : 0.325609 model2 loss : 0.286770
[23:18:56.778] iteration 15594 : model1 loss : 0.320452 model2 loss : 0.322889
[23:18:57.116] iteration 15595 : model1 loss : 0.152635 model2 loss : 0.161245
[23:18:57.456] iteration 15596 : model1 loss : 0.250660 model2 loss : 0.275828
[23:18:57.792] iteration 15597 : model1 loss : 0.262654 model2 loss : 0.360425
[23:18:58.128] iteration 15598 : model1 loss : 0.187237 model2 loss : 0.203389
[23:18:58.465] iteration 15599 : model1 loss : 0.209052 model2 loss : 0.209834
[23:18:58.803] iteration 15600 : model1 loss : 0.240307 model2 loss : 0.272659
[23:18:59.430] iteration 15601 : model1 loss : 0.194477 model2 loss : 0.236661
[23:18:59.768] iteration 15602 : model1 loss : 0.199270 model2 loss : 0.212100
[23:19:00.105] iteration 15603 : model1 loss : 0.110816 model2 loss : 0.098712
[23:19:00.442] iteration 15604 : model1 loss : 0.230400 model2 loss : 0.220924
[23:19:00.785] iteration 15605 : model1 loss : 0.162315 model2 loss : 0.222281
[23:19:01.127] iteration 15606 : model1 loss : 0.202874 model2 loss : 0.291394
[23:19:01.463] iteration 15607 : model1 loss : 0.167265 model2 loss : 0.195236
[23:19:01.806] iteration 15608 : model1 loss : 0.104352 model2 loss : 0.151740
[23:19:02.141] iteration 15609 : model1 loss : 0.200350 model2 loss : 0.259660
[23:19:02.479] iteration 15610 : model1 loss : 0.259360 model2 loss : 0.307487
[23:19:02.815] iteration 15611 : model1 loss : 0.223498 model2 loss : 0.315862
[23:19:03.150] iteration 15612 : model1 loss : 0.174823 model2 loss : 0.186677
[23:19:03.483] iteration 15613 : model1 loss : 0.224800 model2 loss : 0.234266
[23:19:03.815] iteration 15614 : model1 loss : 0.173291 model2 loss : 0.247998
[23:19:04.151] iteration 15615 : model1 loss : 0.212253 model2 loss : 0.261236
[23:19:04.490] iteration 15616 : model1 loss : 0.105236 model2 loss : 0.175279
[23:19:04.825] iteration 15617 : model1 loss : 0.247996 model2 loss : 0.251064
[23:19:05.164] iteration 15618 : model1 loss : 0.260749 model2 loss : 0.284704
[23:19:05.501] iteration 15619 : model1 loss : 0.166080 model2 loss : 0.116465
[23:19:05.838] iteration 15620 : model1 loss : 0.190326 model2 loss : 0.230240
[23:19:06.179] iteration 15621 : model1 loss : 0.235122 model2 loss : 0.241606
[23:19:06.511] iteration 15622 : model1 loss : 0.202302 model2 loss : 0.208702
[23:19:06.853] iteration 15623 : model1 loss : 0.108539 model2 loss : 0.138928
[23:19:07.193] iteration 15624 : model1 loss : 0.191778 model2 loss : 0.211048
[23:19:07.526] iteration 15625 : model1 loss : 0.248469 model2 loss : 0.269036
[23:19:07.867] iteration 15626 : model1 loss : 0.140204 model2 loss : 0.215891
[23:19:08.209] iteration 15627 : model1 loss : 0.164867 model2 loss : 0.180022
[23:19:08.545] iteration 15628 : model1 loss : 0.156064 model2 loss : 0.174716
[23:19:08.881] iteration 15629 : model1 loss : 0.275548 model2 loss : 0.347263
[23:19:09.222] iteration 15630 : model1 loss : 0.184474 model2 loss : 0.256545
[23:19:09.560] iteration 15631 : model1 loss : 0.227866 model2 loss : 0.277909
[23:19:09.897] iteration 15632 : model1 loss : 0.304688 model2 loss : 0.338825
[23:19:10.230] iteration 15633 : model1 loss : 0.244557 model2 loss : 0.269713
[23:19:10.563] iteration 15634 : model1 loss : 0.225272 model2 loss : 0.185196
[23:19:10.900] iteration 15635 : model1 loss : 0.215999 model2 loss : 0.226291
[23:19:11.236] iteration 15636 : model1 loss : 0.266328 model2 loss : 0.303540
[23:19:11.569] iteration 15637 : model1 loss : 0.199746 model2 loss : 0.220095
[23:19:11.908] iteration 15638 : model1 loss : 0.171869 model2 loss : 0.202832
[23:19:12.246] iteration 15639 : model1 loss : 0.258256 model2 loss : 0.293765
[23:19:12.583] iteration 15640 : model1 loss : 0.125034 model2 loss : 0.210114
[23:19:12.922] iteration 15641 : model1 loss : 0.098432 model2 loss : 0.239421
[23:19:13.260] iteration 15642 : model1 loss : 0.162204 model2 loss : 0.177686
[23:19:13.597] iteration 15643 : model1 loss : 0.255861 model2 loss : 0.260929
[23:19:13.934] iteration 15644 : model1 loss : 0.267228 model2 loss : 0.274922
[23:19:14.273] iteration 15645 : model1 loss : 0.225383 model2 loss : 0.263087
[23:19:14.614] iteration 15646 : model1 loss : 0.151114 model2 loss : 0.204952
[23:19:14.957] iteration 15647 : model1 loss : 0.173214 model2 loss : 0.300734
[23:19:15.299] iteration 15648 : model1 loss : 0.181465 model2 loss : 0.192595
[23:19:15.643] iteration 15649 : model1 loss : 0.252238 model2 loss : 0.299078
[23:19:15.978] iteration 15650 : model1 loss : 0.198555 model2 loss : 0.226018
[23:19:16.581] iteration 15651 : model1 loss : 0.254059 model2 loss : 0.338880
[23:19:16.919] iteration 15652 : model1 loss : 0.284718 model2 loss : 0.300663
[23:19:17.260] iteration 15653 : model1 loss : 0.251646 model2 loss : 0.262609
[23:19:17.592] iteration 15654 : model1 loss : 0.317624 model2 loss : 0.319603
[23:19:17.931] iteration 15655 : model1 loss : 0.251828 model2 loss : 0.242199
[23:19:18.268] iteration 15656 : model1 loss : 0.179126 model2 loss : 0.217348
[23:19:18.605] iteration 15657 : model1 loss : 0.165025 model2 loss : 0.223552
[23:19:18.942] iteration 15658 : model1 loss : 0.155285 model2 loss : 0.226378
[23:19:19.282] iteration 15659 : model1 loss : 0.255485 model2 loss : 0.262277
[23:19:19.623] iteration 15660 : model1 loss : 0.184658 model2 loss : 0.218116
[23:19:19.961] iteration 15661 : model1 loss : 0.140189 model2 loss : 0.122026
[23:19:20.298] iteration 15662 : model1 loss : 0.273341 model2 loss : 0.285985
[23:19:20.636] iteration 15663 : model1 loss : 0.196900 model2 loss : 0.203138
[23:19:20.976] iteration 15664 : model1 loss : 0.285261 model2 loss : 0.368756
[23:19:21.311] iteration 15665 : model1 loss : 0.226374 model2 loss : 0.230338
[23:19:21.646] iteration 15666 : model1 loss : 0.198035 model2 loss : 0.217134
[23:19:21.982] iteration 15667 : model1 loss : 0.174643 model2 loss : 0.180045
[23:19:22.320] iteration 15668 : model1 loss : 0.233122 model2 loss : 0.249339
[23:19:22.658] iteration 15669 : model1 loss : 0.191579 model2 loss : 0.185970
[23:19:22.993] iteration 15670 : model1 loss : 0.251803 model2 loss : 0.315060
[23:19:23.328] iteration 15671 : model1 loss : 0.181763 model2 loss : 0.203778
[23:19:23.666] iteration 15672 : model1 loss : 0.215316 model2 loss : 0.232737
[23:19:24.004] iteration 15673 : model1 loss : 0.142552 model2 loss : 0.126196
[23:19:24.341] iteration 15674 : model1 loss : 0.233391 model2 loss : 0.361171
[23:19:24.676] iteration 15675 : model1 loss : 0.126862 model2 loss : 0.138478
[23:19:25.015] iteration 15676 : model1 loss : 0.156550 model2 loss : 0.198278
[23:19:25.353] iteration 15677 : model1 loss : 0.306046 model2 loss : 0.282584
[23:19:25.690] iteration 15678 : model1 loss : 0.255091 model2 loss : 0.273883
[23:19:26.025] iteration 15679 : model1 loss : 0.209985 model2 loss : 0.248051
[23:19:26.363] iteration 15680 : model1 loss : 0.179333 model2 loss : 0.181942
[23:19:26.698] iteration 15681 : model1 loss : 0.318874 model2 loss : 0.264038
[23:19:27.036] iteration 15682 : model1 loss : 0.184798 model2 loss : 0.204006
[23:19:27.371] iteration 15683 : model1 loss : 0.211671 model2 loss : 0.205860
[23:19:27.698] iteration 15684 : model1 loss : 0.159192 model2 loss : 0.162489
[23:19:28.025] iteration 15685 : model1 loss : 0.254992 model2 loss : 0.256177
[23:19:28.352] iteration 15686 : model1 loss : 0.261298 model2 loss : 0.277547
[23:19:28.679] iteration 15687 : model1 loss : 0.198643 model2 loss : 0.205262
[23:19:29.006] iteration 15688 : model1 loss : 0.151712 model2 loss : 0.172730
[23:19:29.334] iteration 15689 : model1 loss : 0.198235 model2 loss : 0.205467
[23:19:29.664] iteration 15690 : model1 loss : 0.264660 model2 loss : 0.286415
[23:19:29.991] iteration 15691 : model1 loss : 0.193396 model2 loss : 0.217871
[23:19:30.318] iteration 15692 : model1 loss : 0.332034 model2 loss : 0.333457
[23:19:30.645] iteration 15693 : model1 loss : 0.298377 model2 loss : 0.298080
[23:19:30.971] iteration 15694 : model1 loss : 0.250890 model2 loss : 0.272217
[23:19:31.301] iteration 15695 : model1 loss : 0.168133 model2 loss : 0.183788
[23:19:31.630] iteration 15696 : model1 loss : 0.171193 model2 loss : 0.314267
[23:19:31.957] iteration 15697 : model1 loss : 0.187465 model2 loss : 0.227702
[23:19:32.285] iteration 15698 : model1 loss : 0.194231 model2 loss : 0.200226
[23:19:32.611] iteration 15699 : model1 loss : 0.182842 model2 loss : 0.183304
[23:19:32.938] iteration 15700 : model1 loss : 0.107224 model2 loss : 0.149976
[23:19:33.506] iteration 15701 : model1 loss : 0.114449 model2 loss : 0.234322
[23:19:33.835] iteration 15702 : model1 loss : 0.255450 model2 loss : 0.279231
[23:19:34.161] iteration 15703 : model1 loss : 0.143306 model2 loss : 0.129756
[23:19:34.489] iteration 15704 : model1 loss : 0.171903 model2 loss : 0.217284
[23:19:34.819] iteration 15705 : model1 loss : 0.124614 model2 loss : 0.124210
[23:19:35.146] iteration 15706 : model1 loss : 0.238657 model2 loss : 0.305481
[23:19:35.482] iteration 15707 : model1 loss : 0.191855 model2 loss : 0.152416
[23:19:35.808] iteration 15708 : model1 loss : 0.104143 model2 loss : 0.212073
[23:19:36.141] iteration 15709 : model1 loss : 0.155371 model2 loss : 0.187343
[23:19:36.469] iteration 15710 : model1 loss : 0.119233 model2 loss : 0.141716
[23:19:36.798] iteration 15711 : model1 loss : 0.134201 model2 loss : 0.167753
[23:19:37.127] iteration 15712 : model1 loss : 0.211118 model2 loss : 0.239405
[23:19:37.457] iteration 15713 : model1 loss : 0.161525 model2 loss : 0.185087
[23:19:37.785] iteration 15714 : model1 loss : 0.305409 model2 loss : 0.334705
[23:19:38.114] iteration 15715 : model1 loss : 0.277124 model2 loss : 0.294240
[23:19:38.441] iteration 15716 : model1 loss : 0.231101 model2 loss : 0.221870
[23:19:38.768] iteration 15717 : model1 loss : 0.301513 model2 loss : 0.306956
[23:19:39.096] iteration 15718 : model1 loss : 0.263414 model2 loss : 0.312771
[23:19:39.424] iteration 15719 : model1 loss : 0.197110 model2 loss : 0.223481
[23:19:39.752] iteration 15720 : model1 loss : 0.111182 model2 loss : 0.152412
[23:19:40.083] iteration 15721 : model1 loss : 0.301490 model2 loss : 0.310316
[23:19:40.411] iteration 15722 : model1 loss : 0.233357 model2 loss : 0.288510
[23:19:40.735] iteration 15723 : model1 loss : 0.199544 model2 loss : 0.257006
[23:19:41.059] iteration 15724 : model1 loss : 0.198955 model2 loss : 0.295432
[23:19:41.383] iteration 15725 : model1 loss : 0.181548 model2 loss : 0.151370
[23:19:41.708] iteration 15726 : model1 loss : 0.184454 model2 loss : 0.192605
[23:19:42.033] iteration 15727 : model1 loss : 0.209025 model2 loss : 0.210994
[23:19:42.358] iteration 15728 : model1 loss : 0.212226 model2 loss : 0.214171
[23:19:42.683] iteration 15729 : model1 loss : 0.260575 model2 loss : 0.327711
[23:19:43.010] iteration 15730 : model1 loss : 0.270376 model2 loss : 0.302621
[23:19:43.336] iteration 15731 : model1 loss : 0.291053 model2 loss : 0.255341
[23:19:43.660] iteration 15732 : model1 loss : 0.268284 model2 loss : 0.328888
[23:19:43.986] iteration 15733 : model1 loss : 0.275404 model2 loss : 0.299574
[23:19:44.309] iteration 15734 : model1 loss : 0.342352 model2 loss : 0.385935
[23:19:44.634] iteration 15735 : model1 loss : 0.166722 model2 loss : 0.250377
[23:19:44.958] iteration 15736 : model1 loss : 0.255349 model2 loss : 0.252578
[23:19:45.284] iteration 15737 : model1 loss : 0.330480 model2 loss : 0.376397
[23:19:45.607] iteration 15738 : model1 loss : 0.264299 model2 loss : 0.283257
[23:19:45.928] iteration 15739 : model1 loss : 0.161106 model2 loss : 0.213192
[23:19:46.250] iteration 15740 : model1 loss : 0.294580 model2 loss : 0.252747
[23:19:46.572] iteration 15741 : model1 loss : 0.106996 model2 loss : 0.227056
[23:19:46.895] iteration 15742 : model1 loss : 0.259406 model2 loss : 0.278605
[23:19:47.223] iteration 15743 : model1 loss : 0.181878 model2 loss : 0.217404
[23:19:47.547] iteration 15744 : model1 loss : 0.200599 model2 loss : 0.223479
[23:19:47.868] iteration 15745 : model1 loss : 0.170109 model2 loss : 0.171574
[23:19:48.190] iteration 15746 : model1 loss : 0.137937 model2 loss : 0.209194
[23:19:48.516] iteration 15747 : model1 loss : 0.401041 model2 loss : 0.430905
[23:19:48.838] iteration 15748 : model1 loss : 0.203247 model2 loss : 0.259348
[23:19:49.159] iteration 15749 : model1 loss : 0.240598 model2 loss : 0.223670
[23:19:49.485] iteration 15750 : model1 loss : 0.114353 model2 loss : 0.117470
[23:19:50.025] iteration 15751 : model1 loss : 0.151810 model2 loss : 0.282105
[23:19:50.351] iteration 15752 : model1 loss : 0.187916 model2 loss : 0.237892
[23:19:50.676] iteration 15753 : model1 loss : 0.186381 model2 loss : 0.253759
[23:19:51.002] iteration 15754 : model1 loss : 0.258695 model2 loss : 0.260063
[23:19:51.330] iteration 15755 : model1 loss : 0.076719 model2 loss : 0.204402
[23:19:51.655] iteration 15756 : model1 loss : 0.198013 model2 loss : 0.264525
[23:19:51.981] iteration 15757 : model1 loss : 0.184712 model2 loss : 0.220862
[23:19:52.308] iteration 15758 : model1 loss : 0.176151 model2 loss : 0.211984
[23:19:52.634] iteration 15759 : model1 loss : 0.315505 model2 loss : 0.326391
[23:19:52.960] iteration 15760 : model1 loss : 0.131234 model2 loss : 0.160897
[23:19:53.286] iteration 15761 : model1 loss : 0.373304 model2 loss : 0.393164
[23:19:53.611] iteration 15762 : model1 loss : 0.324949 model2 loss : 0.374369
[23:19:53.937] iteration 15763 : model1 loss : 0.176298 model2 loss : 0.237557
[23:19:54.263] iteration 15764 : model1 loss : 0.219478 model2 loss : 0.220656
[23:19:54.591] iteration 15765 : model1 loss : 0.288942 model2 loss : 0.336504
[23:19:54.917] iteration 15766 : model1 loss : 0.099917 model2 loss : 0.143188
[23:19:55.243] iteration 15767 : model1 loss : 0.195178 model2 loss : 0.202522
[23:19:55.570] iteration 15768 : model1 loss : 0.098943 model2 loss : 0.185893
[23:19:55.896] iteration 15769 : model1 loss : 0.193561 model2 loss : 0.233213
[23:19:56.221] iteration 15770 : model1 loss : 0.213833 model2 loss : 0.282810
[23:19:56.547] iteration 15771 : model1 loss : 0.171945 model2 loss : 0.206995
[23:19:56.874] iteration 15772 : model1 loss : 0.199472 model2 loss : 0.259607
[23:19:57.201] iteration 15773 : model1 loss : 0.210440 model2 loss : 0.292312
[23:19:57.528] iteration 15774 : model1 loss : 0.168227 model2 loss : 0.183304
[23:19:57.854] iteration 15775 : model1 loss : 0.276503 model2 loss : 0.243060
[23:19:58.180] iteration 15776 : model1 loss : 0.185197 model2 loss : 0.217432
[23:19:58.506] iteration 15777 : model1 loss : 0.333024 model2 loss : 0.306025
[23:19:58.832] iteration 15778 : model1 loss : 0.141962 model2 loss : 0.154989
[23:19:59.157] iteration 15779 : model1 loss : 0.260157 model2 loss : 0.337224
[23:19:59.486] iteration 15780 : model1 loss : 0.118621 model2 loss : 0.127130
[23:19:59.813] iteration 15781 : model1 loss : 0.222760 model2 loss : 0.287744
[23:20:00.140] iteration 15782 : model1 loss : 0.275970 model2 loss : 0.263733
[23:20:00.467] iteration 15783 : model1 loss : 0.175786 model2 loss : 0.232451
[23:20:00.793] iteration 15784 : model1 loss : 0.197318 model2 loss : 0.257329
[23:20:01.121] iteration 15785 : model1 loss : 0.188979 model2 loss : 0.242258
[23:20:01.447] iteration 15786 : model1 loss : 0.201421 model2 loss : 0.261229
[23:20:01.772] iteration 15787 : model1 loss : 0.172339 model2 loss : 0.123689
[23:20:02.097] iteration 15788 : model1 loss : 0.203785 model2 loss : 0.202105
[23:20:02.424] iteration 15789 : model1 loss : 0.101451 model2 loss : 0.157842
[23:20:02.750] iteration 15790 : model1 loss : 0.160227 model2 loss : 0.180024
[23:20:03.076] iteration 15791 : model1 loss : 0.131713 model2 loss : 0.152694
[23:20:03.401] iteration 15792 : model1 loss : 0.125435 model2 loss : 0.182101
[23:20:03.727] iteration 15793 : model1 loss : 0.154318 model2 loss : 0.208610
[23:20:04.052] iteration 15794 : model1 loss : 0.215242 model2 loss : 0.219621
[23:20:04.378] iteration 15795 : model1 loss : 0.188724 model2 loss : 0.224851
[23:20:04.705] iteration 15796 : model1 loss : 0.173599 model2 loss : 0.170496
[23:20:05.033] iteration 15797 : model1 loss : 0.246656 model2 loss : 0.253938
[23:20:05.359] iteration 15798 : model1 loss : 0.171994 model2 loss : 0.219714
[23:20:05.685] iteration 15799 : model1 loss : 0.153409 model2 loss : 0.178506
[23:20:06.010] iteration 15800 : model1 loss : 0.183955 model2 loss : 0.196965
[23:20:06.514] iteration 15801 : model1 loss : 0.189676 model2 loss : 0.258440
[23:20:06.853] iteration 15802 : model1 loss : 0.247899 model2 loss : 0.317616
[23:20:07.201] iteration 15803 : model1 loss : 0.227077 model2 loss : 0.227870
[23:20:07.547] iteration 15804 : model1 loss : 0.233812 model2 loss : 0.280359
[23:20:07.884] iteration 15805 : model1 loss : 0.182604 model2 loss : 0.189962
[23:20:08.968] iteration 15806 : model1 loss : 0.094248 model2 loss : 0.200864
[23:20:09.310] iteration 15807 : model1 loss : 0.091826 model2 loss : 0.169607
[23:20:09.648] iteration 15808 : model1 loss : 0.197519 model2 loss : 0.207209
[23:20:09.987] iteration 15809 : model1 loss : 0.181366 model2 loss : 0.179913
[23:20:10.326] iteration 15810 : model1 loss : 0.192118 model2 loss : 0.226700
[23:20:10.669] iteration 15811 : model1 loss : 0.102275 model2 loss : 0.136220
[23:20:11.010] iteration 15812 : model1 loss : 0.117483 model2 loss : 0.191822
[23:20:11.348] iteration 15813 : model1 loss : 0.193795 model2 loss : 0.177780
[23:20:11.686] iteration 15814 : model1 loss : 0.196734 model2 loss : 0.267947
[23:20:12.026] iteration 15815 : model1 loss : 0.191980 model2 loss : 0.268274
[23:20:12.364] iteration 15816 : model1 loss : 0.183828 model2 loss : 0.242896
[23:20:12.701] iteration 15817 : model1 loss : 0.182762 model2 loss : 0.191528
[23:20:13.039] iteration 15818 : model1 loss : 0.175564 model2 loss : 0.187133
[23:20:13.376] iteration 15819 : model1 loss : 0.167603 model2 loss : 0.204088
[23:20:13.714] iteration 15820 : model1 loss : 0.130603 model2 loss : 0.197982
[23:20:14.055] iteration 15821 : model1 loss : 0.248257 model2 loss : 0.274730
[23:20:14.399] iteration 15822 : model1 loss : 0.228673 model2 loss : 0.293109
[23:20:14.737] iteration 15823 : model1 loss : 0.201760 model2 loss : 0.254341
[23:20:15.075] iteration 15824 : model1 loss : 0.237367 model2 loss : 0.256893
[23:20:15.416] iteration 15825 : model1 loss : 0.120621 model2 loss : 0.142816
[23:20:15.758] iteration 15826 : model1 loss : 0.128302 model2 loss : 0.130385
[23:20:16.096] iteration 15827 : model1 loss : 0.199998 model2 loss : 0.222111
[23:20:16.439] iteration 15828 : model1 loss : 0.166832 model2 loss : 0.167674
[23:20:16.777] iteration 15829 : model1 loss : 0.173800 model2 loss : 0.158802
[23:20:17.118] iteration 15830 : model1 loss : 0.193523 model2 loss : 0.236818
[23:20:17.460] iteration 15831 : model1 loss : 0.298193 model2 loss : 0.346640
[23:20:17.798] iteration 15832 : model1 loss : 0.115901 model2 loss : 0.198354
[23:20:18.139] iteration 15833 : model1 loss : 0.207000 model2 loss : 0.216133
[23:20:18.475] iteration 15834 : model1 loss : 0.169430 model2 loss : 0.243880
[23:20:18.813] iteration 15835 : model1 loss : 0.277819 model2 loss : 0.276939
[23:20:19.151] iteration 15836 : model1 loss : 0.184193 model2 loss : 0.187895
[23:20:19.492] iteration 15837 : model1 loss : 0.179459 model2 loss : 0.236487
[23:20:19.832] iteration 15838 : model1 loss : 0.196050 model2 loss : 0.094249
[23:20:20.187] iteration 15839 : model1 loss : 0.102205 model2 loss : 0.142643
[23:20:20.528] iteration 15840 : model1 loss : 0.260729 model2 loss : 0.344668
[23:20:20.867] iteration 15841 : model1 loss : 0.212904 model2 loss : 0.212537
[23:20:21.226] iteration 15842 : model1 loss : 0.250428 model2 loss : 0.311503
[23:20:21.570] iteration 15843 : model1 loss : 0.212524 model2 loss : 0.263497
[23:20:21.908] iteration 15844 : model1 loss : 0.159952 model2 loss : 0.199054
[23:20:22.247] iteration 15845 : model1 loss : 0.192496 model2 loss : 0.191817
[23:20:22.584] iteration 15846 : model1 loss : 0.268948 model2 loss : 0.276099
[23:20:22.922] iteration 15847 : model1 loss : 0.161005 model2 loss : 0.161435
[23:20:23.261] iteration 15848 : model1 loss : 0.224585 model2 loss : 0.237414
[23:20:23.599] iteration 15849 : model1 loss : 0.223383 model2 loss : 0.211678
[23:20:23.938] iteration 15850 : model1 loss : 0.145220 model2 loss : 0.135244
[23:20:24.596] iteration 15851 : model1 loss : 0.220072 model2 loss : 0.242521
[23:20:24.924] iteration 15852 : model1 loss : 0.163827 model2 loss : 0.167178
[23:20:25.252] iteration 15853 : model1 loss : 0.247025 model2 loss : 0.260605
[23:20:25.583] iteration 15854 : model1 loss : 0.138762 model2 loss : 0.217562
[23:20:25.911] iteration 15855 : model1 loss : 0.241560 model2 loss : 0.340016
[23:20:26.238] iteration 15856 : model1 loss : 0.107159 model2 loss : 0.161369
[23:20:26.565] iteration 15857 : model1 loss : 0.279274 model2 loss : 0.287774
[23:20:26.893] iteration 15858 : model1 loss : 0.202705 model2 loss : 0.227553
[23:20:27.220] iteration 15859 : model1 loss : 0.095125 model2 loss : 0.178899
[23:20:27.547] iteration 15860 : model1 loss : 0.211314 model2 loss : 0.262301
[23:20:27.875] iteration 15861 : model1 loss : 0.262634 model2 loss : 0.358335
[23:20:28.204] iteration 15862 : model1 loss : 0.136061 model2 loss : 0.191981
[23:20:28.530] iteration 15863 : model1 loss : 0.106465 model2 loss : 0.230172
[23:20:28.858] iteration 15864 : model1 loss : 0.273589 model2 loss : 0.353737
[23:20:29.184] iteration 15865 : model1 loss : 0.331947 model2 loss : 0.402691
[23:20:29.513] iteration 15866 : model1 loss : 0.175592 model2 loss : 0.150714
[23:20:29.842] iteration 15867 : model1 loss : 0.334581 model2 loss : 0.341121
[23:20:30.170] iteration 15868 : model1 loss : 0.185135 model2 loss : 0.258901
[23:20:30.498] iteration 15869 : model1 loss : 0.163241 model2 loss : 0.205057
[23:20:30.824] iteration 15870 : model1 loss : 0.205428 model2 loss : 0.228140
[23:20:31.152] iteration 15871 : model1 loss : 0.163753 model2 loss : 0.166554
[23:20:31.480] iteration 15872 : model1 loss : 0.173751 model2 loss : 0.235631
[23:20:31.806] iteration 15873 : model1 loss : 0.200745 model2 loss : 0.197312
[23:20:32.134] iteration 15874 : model1 loss : 0.255534 model2 loss : 0.311971
[23:20:32.461] iteration 15875 : model1 loss : 0.256133 model2 loss : 0.301885
[23:20:32.789] iteration 15876 : model1 loss : 0.161047 model2 loss : 0.172909
[23:20:33.118] iteration 15877 : model1 loss : 0.189350 model2 loss : 0.183784
[23:20:33.445] iteration 15878 : model1 loss : 0.164460 model2 loss : 0.182132
[23:20:33.773] iteration 15879 : model1 loss : 0.254566 model2 loss : 0.256109
[23:20:34.100] iteration 15880 : model1 loss : 0.125711 model2 loss : 0.175037
[23:20:34.426] iteration 15881 : model1 loss : 0.162200 model2 loss : 0.174540
[23:20:34.754] iteration 15882 : model1 loss : 0.142819 model2 loss : 0.183126
[23:20:35.082] iteration 15883 : model1 loss : 0.139717 model2 loss : 0.224808
[23:20:35.410] iteration 15884 : model1 loss : 0.253548 model2 loss : 0.264240
[23:20:35.739] iteration 15885 : model1 loss : 0.121570 model2 loss : 0.213897
[23:20:36.067] iteration 15886 : model1 loss : 0.246171 model2 loss : 0.293309
[23:20:36.397] iteration 15887 : model1 loss : 0.200254 model2 loss : 0.232900
[23:20:36.725] iteration 15888 : model1 loss : 0.094970 model2 loss : 0.086238
[23:20:37.051] iteration 15889 : model1 loss : 0.233958 model2 loss : 0.240610
[23:20:37.378] iteration 15890 : model1 loss : 0.151352 model2 loss : 0.205157
[23:20:37.705] iteration 15891 : model1 loss : 0.170779 model2 loss : 0.192155
[23:20:38.032] iteration 15892 : model1 loss : 0.180963 model2 loss : 0.219422
[23:20:38.362] iteration 15893 : model1 loss : 0.129059 model2 loss : 0.179008
[23:20:38.690] iteration 15894 : model1 loss : 0.127744 model2 loss : 0.118340
[23:20:39.017] iteration 15895 : model1 loss : 0.196239 model2 loss : 0.212440
[23:20:39.345] iteration 15896 : model1 loss : 0.163438 model2 loss : 0.178571
[23:20:39.675] iteration 15897 : model1 loss : 0.281046 model2 loss : 0.331026
[23:20:40.004] iteration 15898 : model1 loss : 0.270352 model2 loss : 0.279552
[23:20:40.330] iteration 15899 : model1 loss : 0.081003 model2 loss : 0.122205
[23:20:40.655] iteration 15900 : model1 loss : 0.170003 model2 loss : 0.200612
[23:20:41.201] iteration 15901 : model1 loss : 0.175770 model2 loss : 0.207201
[23:20:41.527] iteration 15902 : model1 loss : 0.159526 model2 loss : 0.170881
[23:20:41.851] iteration 15903 : model1 loss : 0.327795 model2 loss : 0.302508
[23:20:42.177] iteration 15904 : model1 loss : 0.328542 model2 loss : 0.336575
[23:20:42.501] iteration 15905 : model1 loss : 0.093486 model2 loss : 0.131977
[23:20:42.826] iteration 15906 : model1 loss : 0.117778 model2 loss : 0.155201
[23:20:43.152] iteration 15907 : model1 loss : 0.249687 model2 loss : 0.269468
[23:20:43.479] iteration 15908 : model1 loss : 0.097099 model2 loss : 0.121408
[23:20:43.805] iteration 15909 : model1 loss : 0.149755 model2 loss : 0.170731
[23:20:44.130] iteration 15910 : model1 loss : 0.079774 model2 loss : 0.163692
[23:20:44.456] iteration 15911 : model1 loss : 0.091800 model2 loss : 0.141262
[23:20:44.782] iteration 15912 : model1 loss : 0.215725 model2 loss : 0.298410
[23:20:45.106] iteration 15913 : model1 loss : 0.097357 model2 loss : 0.191692
[23:20:45.432] iteration 15914 : model1 loss : 0.257489 model2 loss : 0.286819
[23:20:45.759] iteration 15915 : model1 loss : 0.139290 model2 loss : 0.122731
[23:20:46.087] iteration 15916 : model1 loss : 0.276259 model2 loss : 0.276712
[23:20:46.412] iteration 15917 : model1 loss : 0.208929 model2 loss : 0.236957
[23:20:46.737] iteration 15918 : model1 loss : 0.208648 model2 loss : 0.301352
[23:20:47.062] iteration 15919 : model1 loss : 0.197205 model2 loss : 0.232963
[23:20:47.386] iteration 15920 : model1 loss : 0.198815 model2 loss : 0.226362
[23:20:47.712] iteration 15921 : model1 loss : 0.209297 model2 loss : 0.210888
[23:20:48.037] iteration 15922 : model1 loss : 0.166408 model2 loss : 0.167432
[23:20:48.362] iteration 15923 : model1 loss : 0.181670 model2 loss : 0.191963
[23:20:48.689] iteration 15924 : model1 loss : 0.223706 model2 loss : 0.234332
[23:20:49.015] iteration 15925 : model1 loss : 0.178538 model2 loss : 0.244273
[23:20:49.339] iteration 15926 : model1 loss : 0.131407 model2 loss : 0.148346
[23:20:49.665] iteration 15927 : model1 loss : 0.195011 model2 loss : 0.255935
[23:20:49.991] iteration 15928 : model1 loss : 0.143144 model2 loss : 0.240941
[23:20:50.318] iteration 15929 : model1 loss : 0.213463 model2 loss : 0.213459
[23:20:50.640] iteration 15930 : model1 loss : 0.269617 model2 loss : 0.323264
[23:20:50.962] iteration 15931 : model1 loss : 0.125792 model2 loss : 0.207434
[23:20:51.290] iteration 15932 : model1 loss : 0.168136 model2 loss : 0.165415
[23:20:51.615] iteration 15933 : model1 loss : 0.190545 model2 loss : 0.278086
[23:20:51.936] iteration 15934 : model1 loss : 0.178306 model2 loss : 0.218307
[23:20:52.260] iteration 15935 : model1 loss : 0.290630 model2 loss : 0.334912
[23:20:52.585] iteration 15936 : model1 loss : 0.097311 model2 loss : 0.152558
[23:20:52.906] iteration 15937 : model1 loss : 0.098344 model2 loss : 0.144744
[23:20:53.228] iteration 15938 : model1 loss : 0.176431 model2 loss : 0.191155
[23:20:53.552] iteration 15939 : model1 loss : 0.108628 model2 loss : 0.139074
[23:20:53.878] iteration 15940 : model1 loss : 0.268232 model2 loss : 0.267665
[23:20:54.203] iteration 15941 : model1 loss : 0.290161 model2 loss : 0.290055
[23:20:54.528] iteration 15942 : model1 loss : 0.326518 model2 loss : 0.378351
[23:20:54.853] iteration 15943 : model1 loss : 0.241399 model2 loss : 0.262595
[23:20:55.178] iteration 15944 : model1 loss : 0.125842 model2 loss : 0.120266
[23:20:55.503] iteration 15945 : model1 loss : 0.234775 model2 loss : 0.242488
[23:20:55.934] iteration 15946 : model1 loss : 0.201014 model2 loss : 0.231983
[23:20:56.258] iteration 15947 : model1 loss : 0.183475 model2 loss : 0.220736
[23:20:56.582] iteration 15948 : model1 loss : 0.119873 model2 loss : 0.171815
[23:20:56.907] iteration 15949 : model1 loss : 0.172799 model2 loss : 0.212157
[23:20:57.232] iteration 15950 : model1 loss : 0.213762 model2 loss : 0.282255
[23:20:57.762] iteration 15951 : model1 loss : 0.125396 model2 loss : 0.165411
[23:20:58.085] iteration 15952 : model1 loss : 0.290970 model2 loss : 0.355716
[23:20:58.410] iteration 15953 : model1 loss : 0.256935 model2 loss : 0.288598
[23:20:58.734] iteration 15954 : model1 loss : 0.202769 model2 loss : 0.230935
[23:20:59.059] iteration 15955 : model1 loss : 0.278188 model2 loss : 0.307651
[23:20:59.384] iteration 15956 : model1 loss : 0.269202 model2 loss : 0.286216
[23:20:59.709] iteration 15957 : model1 loss : 0.268071 model2 loss : 0.292049
[23:21:00.033] iteration 15958 : model1 loss : 0.191844 model2 loss : 0.240988
[23:21:00.360] iteration 15959 : model1 loss : 0.300820 model2 loss : 0.317601
[23:21:00.683] iteration 15960 : model1 loss : 0.287345 model2 loss : 0.253613
[23:21:01.009] iteration 15961 : model1 loss : 0.094043 model2 loss : 0.202704
[23:21:01.334] iteration 15962 : model1 loss : 0.200192 model2 loss : 0.255420
[23:21:01.661] iteration 15963 : model1 loss : 0.314182 model2 loss : 0.343580
[23:21:01.988] iteration 15964 : model1 loss : 0.220964 model2 loss : 0.294569
[23:21:02.312] iteration 15965 : model1 loss : 0.232877 model2 loss : 0.242786
[23:21:02.640] iteration 15966 : model1 loss : 0.244059 model2 loss : 0.255095
[23:21:02.970] iteration 15967 : model1 loss : 0.235999 model2 loss : 0.265144
[23:21:03.306] iteration 15968 : model1 loss : 0.275270 model2 loss : 0.341839
[23:21:03.646] iteration 15969 : model1 loss : 0.284964 model2 loss : 0.298744
[23:21:03.987] iteration 15970 : model1 loss : 0.190498 model2 loss : 0.238338
[23:21:04.323] iteration 15971 : model1 loss : 0.106679 model2 loss : 0.132977
[23:21:04.663] iteration 15972 : model1 loss : 0.252054 model2 loss : 0.275978
[23:21:05.004] iteration 15973 : model1 loss : 0.184550 model2 loss : 0.247960
[23:21:05.341] iteration 15974 : model1 loss : 0.330701 model2 loss : 0.312714
[23:21:05.685] iteration 15975 : model1 loss : 0.259212 model2 loss : 0.267546
[23:21:06.022] iteration 15976 : model1 loss : 0.327731 model2 loss : 0.320985
[23:21:06.365] iteration 15977 : model1 loss : 0.141159 model2 loss : 0.154379
[23:21:06.699] iteration 15978 : model1 loss : 0.191762 model2 loss : 0.244493
[23:21:07.036] iteration 15979 : model1 loss : 0.143403 model2 loss : 0.205324
[23:21:07.373] iteration 15980 : model1 loss : 0.315443 model2 loss : 0.363295
[23:21:07.714] iteration 15981 : model1 loss : 0.140676 model2 loss : 0.157634
[23:21:08.054] iteration 15982 : model1 loss : 0.268918 model2 loss : 0.321092
[23:21:08.391] iteration 15983 : model1 loss : 0.198080 model2 loss : 0.236637
[23:21:08.729] iteration 15984 : model1 loss : 0.278481 model2 loss : 0.348960
[23:21:09.069] iteration 15985 : model1 loss : 0.170575 model2 loss : 0.166408
[23:21:09.411] iteration 15986 : model1 loss : 0.177598 model2 loss : 0.220275
[23:21:09.753] iteration 15987 : model1 loss : 0.116202 model2 loss : 0.144143
[23:21:10.094] iteration 15988 : model1 loss : 0.247993 model2 loss : 0.290544
[23:21:10.433] iteration 15989 : model1 loss : 0.092508 model2 loss : 0.114235
[23:21:10.771] iteration 15990 : model1 loss : 0.217715 model2 loss : 0.213075
[23:21:11.113] iteration 15991 : model1 loss : 0.264053 model2 loss : 0.285734
[23:21:11.449] iteration 15992 : model1 loss : 0.202719 model2 loss : 0.264868
[23:21:11.795] iteration 15993 : model1 loss : 0.144334 model2 loss : 0.200061
[23:21:12.137] iteration 15994 : model1 loss : 0.162812 model2 loss : 0.174856
[23:21:12.475] iteration 15995 : model1 loss : 0.233208 model2 loss : 0.226543
[23:21:12.817] iteration 15996 : model1 loss : 0.281556 model2 loss : 0.237069
[23:21:13.155] iteration 15997 : model1 loss : 0.237113 model2 loss : 0.327154
[23:21:13.493] iteration 15998 : model1 loss : 0.108878 model2 loss : 0.216372
[23:21:13.833] iteration 15999 : model1 loss : 0.263286 model2 loss : 0.283764
[23:21:14.171] iteration 16000 : model1 loss : 0.198088 model2 loss : 0.262243
[23:21:14.820] iteration 16001 : model1 loss : 0.301904 model2 loss : 0.362538
[23:21:15.158] iteration 16002 : model1 loss : 0.224027 model2 loss : 0.234103
[23:21:15.500] iteration 16003 : model1 loss : 0.241527 model2 loss : 0.326110
[23:21:15.842] iteration 16004 : model1 loss : 0.093211 model2 loss : 0.119977
[23:21:16.180] iteration 16005 : model1 loss : 0.094378 model2 loss : 0.103178
[23:21:16.519] iteration 16006 : model1 loss : 0.207788 model2 loss : 0.240635
[23:21:16.862] iteration 16007 : model1 loss : 0.175278 model2 loss : 0.224845
[23:21:17.201] iteration 16008 : model1 loss : 0.258588 model2 loss : 0.268756
[23:21:17.538] iteration 16009 : model1 loss : 0.185527 model2 loss : 0.198573
[23:21:17.875] iteration 16010 : model1 loss : 0.262870 model2 loss : 0.262728
[23:21:18.212] iteration 16011 : model1 loss : 0.110161 model2 loss : 0.153209
[23:21:18.554] iteration 16012 : model1 loss : 0.306992 model2 loss : 0.269646
[23:21:18.899] iteration 16013 : model1 loss : 0.204486 model2 loss : 0.241736
[23:21:19.238] iteration 16014 : model1 loss : 0.275250 model2 loss : 0.287326
[23:21:19.577] iteration 16015 : model1 loss : 0.132497 model2 loss : 0.135526
[23:21:19.919] iteration 16016 : model1 loss : 0.140348 model2 loss : 0.226695
[23:21:20.262] iteration 16017 : model1 loss : 0.191589 model2 loss : 0.247915
[23:21:20.600] iteration 16018 : model1 loss : 0.178235 model2 loss : 0.181707
[23:21:20.938] iteration 16019 : model1 loss : 0.165151 model2 loss : 0.209555
[23:21:21.276] iteration 16020 : model1 loss : 0.147443 model2 loss : 0.204742
[23:21:21.617] iteration 16021 : model1 loss : 0.217159 model2 loss : 0.291751
[23:21:21.959] iteration 16022 : model1 loss : 0.194101 model2 loss : 0.190141
[23:21:22.304] iteration 16023 : model1 loss : 0.170072 model2 loss : 0.186557
[23:21:22.641] iteration 16024 : model1 loss : 0.256668 model2 loss : 0.302097
[23:21:22.978] iteration 16025 : model1 loss : 0.183101 model2 loss : 0.178545
[23:21:23.319] iteration 16026 : model1 loss : 0.286233 model2 loss : 0.271819
[23:21:23.659] iteration 16027 : model1 loss : 0.224820 model2 loss : 0.308907
[23:21:24.001] iteration 16028 : model1 loss : 0.166837 model2 loss : 0.221651
[23:21:24.343] iteration 16029 : model1 loss : 0.239773 model2 loss : 0.257437
[23:21:24.681] iteration 16030 : model1 loss : 0.258077 model2 loss : 0.289600
[23:21:25.021] iteration 16031 : model1 loss : 0.341877 model2 loss : 0.334586
[23:21:25.359] iteration 16032 : model1 loss : 0.207740 model2 loss : 0.204008
[23:21:25.697] iteration 16033 : model1 loss : 0.219398 model2 loss : 0.246814
[23:21:26.037] iteration 16034 : model1 loss : 0.226768 model2 loss : 0.211794
[23:21:26.377] iteration 16035 : model1 loss : 0.115402 model2 loss : 0.151877
[23:21:26.714] iteration 16036 : model1 loss : 0.204435 model2 loss : 0.231504
[23:21:27.052] iteration 16037 : model1 loss : 0.272637 model2 loss : 0.296117
[23:21:27.390] iteration 16038 : model1 loss : 0.154752 model2 loss : 0.178030
[23:21:27.729] iteration 16039 : model1 loss : 0.148256 model2 loss : 0.168008
[23:21:28.066] iteration 16040 : model1 loss : 0.267824 model2 loss : 0.306118
[23:21:28.403] iteration 16041 : model1 loss : 0.085844 model2 loss : 0.189161
[23:21:28.743] iteration 16042 : model1 loss : 0.102038 model2 loss : 0.191226
[23:21:29.084] iteration 16043 : model1 loss : 0.221964 model2 loss : 0.275064
[23:21:29.422] iteration 16044 : model1 loss : 0.114800 model2 loss : 0.113822
[23:21:29.760] iteration 16045 : model1 loss : 0.201794 model2 loss : 0.223024
[23:21:30.099] iteration 16046 : model1 loss : 0.180791 model2 loss : 0.240286
[23:21:30.438] iteration 16047 : model1 loss : 0.155503 model2 loss : 0.193589
[23:21:30.777] iteration 16048 : model1 loss : 0.160071 model2 loss : 0.232422
[23:21:31.116] iteration 16049 : model1 loss : 0.193730 model2 loss : 0.202337
[23:21:31.455] iteration 16050 : model1 loss : 0.261767 model2 loss : 0.256140
[23:21:32.110] iteration 16051 : model1 loss : 0.237992 model2 loss : 0.247659
[23:21:32.449] iteration 16052 : model1 loss : 0.225063 model2 loss : 0.299827
[23:21:32.794] iteration 16053 : model1 loss : 0.243608 model2 loss : 0.268111
[23:21:33.131] iteration 16054 : model1 loss : 0.106971 model2 loss : 0.114940
[23:21:33.470] iteration 16055 : model1 loss : 0.163392 model2 loss : 0.181292
[23:21:33.813] iteration 16056 : model1 loss : 0.083137 model2 loss : 0.112383
[23:21:34.155] iteration 16057 : model1 loss : 0.161285 model2 loss : 0.200329
[23:21:34.493] iteration 16058 : model1 loss : 0.257854 model2 loss : 0.324157
[23:21:34.832] iteration 16059 : model1 loss : 0.192518 model2 loss : 0.204359
[23:21:35.173] iteration 16060 : model1 loss : 0.244424 model2 loss : 0.353486
[23:21:35.515] iteration 16061 : model1 loss : 0.138932 model2 loss : 0.152387
[23:21:35.854] iteration 16062 : model1 loss : 0.196754 model2 loss : 0.205971
[23:21:36.198] iteration 16063 : model1 loss : 0.158551 model2 loss : 0.196722
[23:21:36.537] iteration 16064 : model1 loss : 0.091652 model2 loss : 0.187669
[23:21:36.875] iteration 16065 : model1 loss : 0.181366 model2 loss : 0.237617
[23:21:37.215] iteration 16066 : model1 loss : 0.152828 model2 loss : 0.256897
[23:21:37.562] iteration 16067 : model1 loss : 0.377651 model2 loss : 0.384470
[23:21:37.894] iteration 16068 : model1 loss : 0.167558 model2 loss : 0.195254
[23:21:38.236] iteration 16069 : model1 loss : 0.197675 model2 loss : 0.242532
[23:21:38.577] iteration 16070 : model1 loss : 0.081859 model2 loss : 0.129016
[23:21:38.915] iteration 16071 : model1 loss : 0.174658 model2 loss : 0.217636
[23:21:39.252] iteration 16072 : model1 loss : 0.238727 model2 loss : 0.231859
[23:21:39.593] iteration 16073 : model1 loss : 0.208052 model2 loss : 0.253692
[23:21:39.930] iteration 16074 : model1 loss : 0.259137 model2 loss : 0.269988
[23:21:40.266] iteration 16075 : model1 loss : 0.270894 model2 loss : 0.298204
[23:21:40.606] iteration 16076 : model1 loss : 0.158812 model2 loss : 0.169148
[23:21:40.944] iteration 16077 : model1 loss : 0.252722 model2 loss : 0.255479
[23:21:41.280] iteration 16078 : model1 loss : 0.252779 model2 loss : 0.266521
[23:21:41.620] iteration 16079 : model1 loss : 0.181968 model2 loss : 0.273956
[23:21:41.951] iteration 16080 : model1 loss : 0.208287 model2 loss : 0.234542
[23:21:42.279] iteration 16081 : model1 loss : 0.246022 model2 loss : 0.274994
[23:21:42.609] iteration 16082 : model1 loss : 0.215359 model2 loss : 0.233175
[23:21:42.935] iteration 16083 : model1 loss : 0.116151 model2 loss : 0.182593
[23:21:43.258] iteration 16084 : model1 loss : 0.078908 model2 loss : 0.139852
[23:21:43.586] iteration 16085 : model1 loss : 0.232926 model2 loss : 0.246963
[23:21:43.910] iteration 16086 : model1 loss : 0.186246 model2 loss : 0.189813
[23:21:44.235] iteration 16087 : model1 loss : 0.121570 model2 loss : 0.210217
[23:21:44.564] iteration 16088 : model1 loss : 0.226619 model2 loss : 0.255120
[23:21:44.889] iteration 16089 : model1 loss : 0.170220 model2 loss : 0.196917
[23:21:45.214] iteration 16090 : model1 loss : 0.185035 model2 loss : 0.187409
[23:21:45.539] iteration 16091 : model1 loss : 0.187142 model2 loss : 0.202934
[23:21:45.863] iteration 16092 : model1 loss : 0.163598 model2 loss : 0.192275
[23:21:46.187] iteration 16093 : model1 loss : 0.179115 model2 loss : 0.199133
[23:21:46.517] iteration 16094 : model1 loss : 0.245897 model2 loss : 0.280038
[23:21:46.846] iteration 16095 : model1 loss : 0.212363 model2 loss : 0.277224
[23:21:47.173] iteration 16096 : model1 loss : 0.203389 model2 loss : 0.290568
[23:21:47.497] iteration 16097 : model1 loss : 0.190043 model2 loss : 0.158665
[23:21:47.825] iteration 16098 : model1 loss : 0.214963 model2 loss : 0.298074
[23:21:48.151] iteration 16099 : model1 loss : 0.306083 model2 loss : 0.196087
[23:21:48.477] iteration 16100 : model1 loss : 0.263666 model2 loss : 0.302565
[23:21:49.032] iteration 16101 : model1 loss : 0.204939 model2 loss : 0.228449
[23:21:49.361] iteration 16102 : model1 loss : 0.106236 model2 loss : 0.165007
[23:21:49.689] iteration 16103 : model1 loss : 0.239733 model2 loss : 0.215370
[23:21:50.014] iteration 16104 : model1 loss : 0.208905 model2 loss : 0.205470
[23:21:50.343] iteration 16105 : model1 loss : 0.239819 model2 loss : 0.255379
[23:21:50.673] iteration 16106 : model1 loss : 0.184520 model2 loss : 0.188416
[23:21:51.001] iteration 16107 : model1 loss : 0.090178 model2 loss : 0.122355
[23:21:51.330] iteration 16108 : model1 loss : 0.260063 model2 loss : 0.285630
[23:21:51.657] iteration 16109 : model1 loss : 0.117965 model2 loss : 0.175131
[23:21:51.985] iteration 16110 : model1 loss : 0.234452 model2 loss : 0.281656
[23:21:52.310] iteration 16111 : model1 loss : 0.198111 model2 loss : 0.254547
[23:21:52.638] iteration 16112 : model1 loss : 0.249422 model2 loss : 0.303541
[23:21:52.966] iteration 16113 : model1 loss : 0.283344 model2 loss : 0.334216
[23:21:53.292] iteration 16114 : model1 loss : 0.180274 model2 loss : 0.317499
[23:21:53.620] iteration 16115 : model1 loss : 0.210548 model2 loss : 0.206883
[23:21:53.948] iteration 16116 : model1 loss : 0.288300 model2 loss : 0.360349
[23:21:54.276] iteration 16117 : model1 loss : 0.223634 model2 loss : 0.243569
[23:21:54.606] iteration 16118 : model1 loss : 0.201156 model2 loss : 0.220730
[23:21:54.933] iteration 16119 : model1 loss : 0.091789 model2 loss : 0.107441
[23:21:55.262] iteration 16120 : model1 loss : 0.331270 model2 loss : 0.368313
[23:21:55.592] iteration 16121 : model1 loss : 0.239195 model2 loss : 0.280593
[23:21:55.921] iteration 16122 : model1 loss : 0.342324 model2 loss : 0.367304
[23:21:56.250] iteration 16123 : model1 loss : 0.230892 model2 loss : 0.181167
[23:21:56.580] iteration 16124 : model1 loss : 0.211160 model2 loss : 0.223448
[23:21:56.911] iteration 16125 : model1 loss : 0.245152 model2 loss : 0.294314
[23:21:57.241] iteration 16126 : model1 loss : 0.245311 model2 loss : 0.250143
[23:21:57.570] iteration 16127 : model1 loss : 0.269257 model2 loss : 0.353190
[23:21:57.899] iteration 16128 : model1 loss : 0.192311 model2 loss : 0.231741
[23:21:58.229] iteration 16129 : model1 loss : 0.190290 model2 loss : 0.266494
[23:21:58.558] iteration 16130 : model1 loss : 0.296484 model2 loss : 0.305829
[23:21:58.888] iteration 16131 : model1 loss : 0.181169 model2 loss : 0.181911
[23:21:59.215] iteration 16132 : model1 loss : 0.194759 model2 loss : 0.299713
[23:21:59.545] iteration 16133 : model1 loss : 0.154894 model2 loss : 0.191514
[23:21:59.874] iteration 16134 : model1 loss : 0.137105 model2 loss : 0.202821
[23:22:00.203] iteration 16135 : model1 loss : 0.183259 model2 loss : 0.186700
[23:22:00.532] iteration 16136 : model1 loss : 0.273393 model2 loss : 0.321537
[23:22:00.863] iteration 16137 : model1 loss : 0.149652 model2 loss : 0.187152
[23:22:01.192] iteration 16138 : model1 loss : 0.186780 model2 loss : 0.218792
[23:22:01.523] iteration 16139 : model1 loss : 0.253052 model2 loss : 0.274656
[23:22:01.853] iteration 16140 : model1 loss : 0.166908 model2 loss : 0.186155
[23:22:02.182] iteration 16141 : model1 loss : 0.319135 model2 loss : 0.329906
[23:22:02.510] iteration 16142 : model1 loss : 0.253988 model2 loss : 0.347857
[23:22:02.838] iteration 16143 : model1 loss : 0.197703 model2 loss : 0.217709
[23:22:03.167] iteration 16144 : model1 loss : 0.203399 model2 loss : 0.170615
[23:22:03.496] iteration 16145 : model1 loss : 0.270204 model2 loss : 0.214257
[23:22:03.826] iteration 16146 : model1 loss : 0.282968 model2 loss : 0.278859
[23:22:04.152] iteration 16147 : model1 loss : 0.256966 model2 loss : 0.256275
[23:22:04.478] iteration 16148 : model1 loss : 0.234551 model2 loss : 0.330955
[23:22:04.804] iteration 16149 : model1 loss : 0.206534 model2 loss : 0.194862
[23:22:05.130] iteration 16150 : model1 loss : 0.209026 model2 loss : 0.294878
[23:22:05.669] iteration 16151 : model1 loss : 0.220562 model2 loss : 0.339258
[23:22:05.995] iteration 16152 : model1 loss : 0.268849 model2 loss : 0.255106
[23:22:06.322] iteration 16153 : model1 loss : 0.189057 model2 loss : 0.218617
[23:22:06.648] iteration 16154 : model1 loss : 0.262529 model2 loss : 0.333124
[23:22:06.973] iteration 16155 : model1 loss : 0.260001 model2 loss : 0.229293
[23:22:07.299] iteration 16156 : model1 loss : 0.214055 model2 loss : 0.310741
[23:22:07.626] iteration 16157 : model1 loss : 0.089306 model2 loss : 0.167275
[23:22:07.953] iteration 16158 : model1 loss : 0.154256 model2 loss : 0.206393
[23:22:08.279] iteration 16159 : model1 loss : 0.196484 model2 loss : 0.224585
[23:22:08.606] iteration 16160 : model1 loss : 0.188924 model2 loss : 0.244687
[23:22:08.934] iteration 16161 : model1 loss : 0.241601 model2 loss : 0.253714
[23:22:09.260] iteration 16162 : model1 loss : 0.113915 model2 loss : 0.226309
[23:22:09.586] iteration 16163 : model1 loss : 0.109185 model2 loss : 0.153319
[23:22:09.912] iteration 16164 : model1 loss : 0.278674 model2 loss : 0.315544
[23:22:10.238] iteration 16165 : model1 loss : 0.216987 model2 loss : 0.269953
[23:22:10.565] iteration 16166 : model1 loss : 0.095101 model2 loss : 0.145346
[23:22:10.891] iteration 16167 : model1 loss : 0.275385 model2 loss : 0.276731
[23:22:11.217] iteration 16168 : model1 loss : 0.184900 model2 loss : 0.245168
[23:22:11.543] iteration 16169 : model1 loss : 0.101667 model2 loss : 0.140286
[23:22:11.869] iteration 16170 : model1 loss : 0.186073 model2 loss : 0.202367
[23:22:12.195] iteration 16171 : model1 loss : 0.139842 model2 loss : 0.160759
[23:22:12.521] iteration 16172 : model1 loss : 0.263307 model2 loss : 0.286964
[23:22:12.847] iteration 16173 : model1 loss : 0.199926 model2 loss : 0.222114
[23:22:13.173] iteration 16174 : model1 loss : 0.254215 model2 loss : 0.329600
[23:22:13.499] iteration 16175 : model1 loss : 0.276453 model2 loss : 0.306689
[23:22:13.825] iteration 16176 : model1 loss : 0.202382 model2 loss : 0.320409
[23:22:14.150] iteration 16177 : model1 loss : 0.159713 model2 loss : 0.253045
[23:22:14.477] iteration 16178 : model1 loss : 0.233284 model2 loss : 0.253377
[23:22:14.803] iteration 16179 : model1 loss : 0.168381 model2 loss : 0.184164
[23:22:15.129] iteration 16180 : model1 loss : 0.274956 model2 loss : 0.326461
[23:22:15.455] iteration 16181 : model1 loss : 0.197835 model2 loss : 0.238371
[23:22:15.785] iteration 16182 : model1 loss : 0.296479 model2 loss : 0.345587
[23:22:16.114] iteration 16183 : model1 loss : 0.154634 model2 loss : 0.202027
[23:22:16.444] iteration 16184 : model1 loss : 0.344942 model2 loss : 0.265903
[23:22:16.774] iteration 16185 : model1 loss : 0.179548 model2 loss : 0.135699
[23:22:17.103] iteration 16186 : model1 loss : 0.121419 model2 loss : 0.146691
[23:22:17.435] iteration 16187 : model1 loss : 0.285619 model2 loss : 0.344282
[23:22:17.766] iteration 16188 : model1 loss : 0.280940 model2 loss : 0.225118
[23:22:18.096] iteration 16189 : model1 loss : 0.272926 model2 loss : 0.280467
[23:22:18.426] iteration 16190 : model1 loss : 0.247287 model2 loss : 0.292710
[23:22:18.757] iteration 16191 : model1 loss : 0.148248 model2 loss : 0.213079
[23:22:19.084] iteration 16192 : model1 loss : 0.185074 model2 loss : 0.256351
[23:22:19.410] iteration 16193 : model1 loss : 0.209413 model2 loss : 0.313700
[23:22:19.736] iteration 16194 : model1 loss : 0.146267 model2 loss : 0.153271
[23:22:20.061] iteration 16195 : model1 loss : 0.244857 model2 loss : 0.289214
[23:22:20.388] iteration 16196 : model1 loss : 0.188164 model2 loss : 0.213398
[23:22:20.714] iteration 16197 : model1 loss : 0.255517 model2 loss : 0.241355
[23:22:21.040] iteration 16198 : model1 loss : 0.184164 model2 loss : 0.266653
[23:22:21.367] iteration 16199 : model1 loss : 0.098210 model2 loss : 0.129538
[23:22:21.694] iteration 16200 : model1 loss : 0.238304 model2 loss : 0.233976
[23:22:22.230] iteration 16201 : model1 loss : 0.234897 model2 loss : 0.262549
[23:22:22.556] iteration 16202 : model1 loss : 0.184758 model2 loss : 0.218885
[23:22:22.883] iteration 16203 : model1 loss : 0.180154 model2 loss : 0.194857
[23:22:23.209] iteration 16204 : model1 loss : 0.177942 model2 loss : 0.206239
[23:22:23.535] iteration 16205 : model1 loss : 0.163816 model2 loss : 0.214368
[23:22:23.862] iteration 16206 : model1 loss : 0.167478 model2 loss : 0.209633
[23:22:24.189] iteration 16207 : model1 loss : 0.179823 model2 loss : 0.176533
[23:22:24.515] iteration 16208 : model1 loss : 0.174106 model2 loss : 0.183676
[23:22:24.841] iteration 16209 : model1 loss : 0.106169 model2 loss : 0.152707
[23:22:25.167] iteration 16210 : model1 loss : 0.216447 model2 loss : 0.266835
[23:22:25.494] iteration 16211 : model1 loss : 0.171753 model2 loss : 0.118591
[23:22:25.820] iteration 16212 : model1 loss : 0.158979 model2 loss : 0.223562
[23:22:26.146] iteration 16213 : model1 loss : 0.209257 model2 loss : 0.227192
[23:22:26.473] iteration 16214 : model1 loss : 0.134191 model2 loss : 0.157699
[23:22:26.798] iteration 16215 : model1 loss : 0.211270 model2 loss : 0.278301
[23:22:27.125] iteration 16216 : model1 loss : 0.243811 model2 loss : 0.289988
[23:22:27.450] iteration 16217 : model1 loss : 0.257635 model2 loss : 0.275366
[23:22:27.776] iteration 16218 : model1 loss : 0.210182 model2 loss : 0.226862
[23:22:28.102] iteration 16219 : model1 loss : 0.242297 model2 loss : 0.337970
[23:22:28.428] iteration 16220 : model1 loss : 0.270546 model2 loss : 0.285597
[23:22:28.754] iteration 16221 : model1 loss : 0.239620 model2 loss : 0.218794
[23:22:29.080] iteration 16222 : model1 loss : 0.106815 model2 loss : 0.099348
[23:22:29.406] iteration 16223 : model1 loss : 0.211085 model2 loss : 0.295597
[23:22:29.732] iteration 16224 : model1 loss : 0.191011 model2 loss : 0.254288
[23:22:30.058] iteration 16225 : model1 loss : 0.167081 model2 loss : 0.204795
[23:22:30.387] iteration 16226 : model1 loss : 0.249727 model2 loss : 0.310900
[23:22:30.712] iteration 16227 : model1 loss : 0.200654 model2 loss : 0.256795
[23:22:31.038] iteration 16228 : model1 loss : 0.199339 model2 loss : 0.204921
[23:22:31.365] iteration 16229 : model1 loss : 0.171935 model2 loss : 0.215985
[23:22:31.691] iteration 16230 : model1 loss : 0.194515 model2 loss : 0.275699
[23:22:32.017] iteration 16231 : model1 loss : 0.243723 model2 loss : 0.258515
[23:22:32.343] iteration 16232 : model1 loss : 0.259246 model2 loss : 0.257730
[23:22:32.669] iteration 16233 : model1 loss : 0.171512 model2 loss : 0.217452
[23:22:32.996] iteration 16234 : model1 loss : 0.117836 model2 loss : 0.120367
[23:22:33.322] iteration 16235 : model1 loss : 0.268099 model2 loss : 0.260953
[23:22:33.648] iteration 16236 : model1 loss : 0.160068 model2 loss : 0.178915
[23:22:33.974] iteration 16237 : model1 loss : 0.259500 model2 loss : 0.269513
[23:22:34.301] iteration 16238 : model1 loss : 0.107266 model2 loss : 0.131205
[23:22:34.627] iteration 16239 : model1 loss : 0.259919 model2 loss : 0.310752
[23:22:34.954] iteration 16240 : model1 loss : 0.209114 model2 loss : 0.302399
[23:22:35.281] iteration 16241 : model1 loss : 0.182525 model2 loss : 0.217403
[23:22:35.608] iteration 16242 : model1 loss : 0.116552 model2 loss : 0.124345
[23:22:35.934] iteration 16243 : model1 loss : 0.159509 model2 loss : 0.195354
[23:22:36.261] iteration 16244 : model1 loss : 0.260584 model2 loss : 0.291597
[23:22:36.587] iteration 16245 : model1 loss : 0.186220 model2 loss : 0.188679
[23:22:36.913] iteration 16246 : model1 loss : 0.197895 model2 loss : 0.226637
[23:22:37.242] iteration 16247 : model1 loss : 0.165801 model2 loss : 0.191477
[23:22:37.568] iteration 16248 : model1 loss : 0.134993 model2 loss : 0.113345
[23:22:37.894] iteration 16249 : model1 loss : 0.240502 model2 loss : 0.258939
[23:22:38.220] iteration 16250 : model1 loss : 0.173233 model2 loss : 0.210020
[23:22:38.741] iteration 16251 : model1 loss : 0.099362 model2 loss : 0.112327
[23:22:39.066] iteration 16252 : model1 loss : 0.284941 model2 loss : 0.312960
[23:22:39.392] iteration 16253 : model1 loss : 0.197806 model2 loss : 0.288285
[23:22:39.719] iteration 16254 : model1 loss : 0.283923 model2 loss : 0.287672
[23:22:40.046] iteration 16255 : model1 loss : 0.176645 model2 loss : 0.220149
[23:22:40.374] iteration 16256 : model1 loss : 0.181574 model2 loss : 0.194649
[23:22:40.700] iteration 16257 : model1 loss : 0.167073 model2 loss : 0.177957
[23:22:41.026] iteration 16258 : model1 loss : 0.185511 model2 loss : 0.241881
[23:22:41.353] iteration 16259 : model1 loss : 0.284548 model2 loss : 0.311536
[23:22:41.679] iteration 16260 : model1 loss : 0.277410 model2 loss : 0.275727
[23:22:42.005] iteration 16261 : model1 loss : 0.186312 model2 loss : 0.214842
[23:22:42.333] iteration 16262 : model1 loss : 0.171679 model2 loss : 0.180657
[23:22:42.658] iteration 16263 : model1 loss : 0.101500 model2 loss : 0.136957
[23:22:42.984] iteration 16264 : model1 loss : 0.171197 model2 loss : 0.240358
[23:22:43.310] iteration 16265 : model1 loss : 0.260612 model2 loss : 0.279150
[23:22:43.638] iteration 16266 : model1 loss : 0.116771 model2 loss : 0.130397
[23:22:43.964] iteration 16267 : model1 loss : 0.091203 model2 loss : 0.129662
[23:22:44.291] iteration 16268 : model1 loss : 0.296109 model2 loss : 0.179529
[23:22:44.617] iteration 16269 : model1 loss : 0.113101 model2 loss : 0.151288
[23:22:44.943] iteration 16270 : model1 loss : 0.249401 model2 loss : 0.259057
[23:22:45.269] iteration 16271 : model1 loss : 0.288242 model2 loss : 0.418339
[23:22:45.595] iteration 16272 : model1 loss : 0.235060 model2 loss : 0.235571
[23:22:45.922] iteration 16273 : model1 loss : 0.195650 model2 loss : 0.263869
[23:22:46.248] iteration 16274 : model1 loss : 0.190980 model2 loss : 0.199420
[23:22:46.574] iteration 16275 : model1 loss : 0.106989 model2 loss : 0.196361
[23:22:46.900] iteration 16276 : model1 loss : 0.209533 model2 loss : 0.218763
[23:22:47.226] iteration 16277 : model1 loss : 0.214275 model2 loss : 0.228463
[23:22:47.552] iteration 16278 : model1 loss : 0.145463 model2 loss : 0.110670
[23:22:47.878] iteration 16279 : model1 loss : 0.212857 model2 loss : 0.234737
[23:22:48.205] iteration 16280 : model1 loss : 0.267945 model2 loss : 0.307732
[23:22:48.532] iteration 16281 : model1 loss : 0.186664 model2 loss : 0.217957
[23:22:48.859] iteration 16282 : model1 loss : 0.133019 model2 loss : 0.130061
[23:22:49.184] iteration 16283 : model1 loss : 0.288703 model2 loss : 0.265877
[23:22:49.510] iteration 16284 : model1 loss : 0.162964 model2 loss : 0.183789
[23:22:49.837] iteration 16285 : model1 loss : 0.114606 model2 loss : 0.109711
[23:22:50.164] iteration 16286 : model1 loss : 0.287070 model2 loss : 0.284498
[23:22:50.491] iteration 16287 : model1 loss : 0.318028 model2 loss : 0.277625
[23:22:50.817] iteration 16288 : model1 loss : 0.244021 model2 loss : 0.238482
[23:22:51.143] iteration 16289 : model1 loss : 0.396413 model2 loss : 0.403442
[23:22:51.469] iteration 16290 : model1 loss : 0.177669 model2 loss : 0.182962
[23:22:51.795] iteration 16291 : model1 loss : 0.275586 model2 loss : 0.296759
[23:22:52.121] iteration 16292 : model1 loss : 0.203761 model2 loss : 0.312241
[23:22:52.447] iteration 16293 : model1 loss : 0.251343 model2 loss : 0.279464
[23:22:52.773] iteration 16294 : model1 loss : 0.190480 model2 loss : 0.219943
[23:22:53.100] iteration 16295 : model1 loss : 0.276514 model2 loss : 0.320403
[23:22:53.426] iteration 16296 : model1 loss : 0.285710 model2 loss : 0.295161
[23:22:53.752] iteration 16297 : model1 loss : 0.208017 model2 loss : 0.242157
[23:22:54.078] iteration 16298 : model1 loss : 0.260239 model2 loss : 0.292791
[23:22:54.405] iteration 16299 : model1 loss : 0.131566 model2 loss : 0.139532
[23:22:54.732] iteration 16300 : model1 loss : 0.267342 model2 loss : 0.247722
[23:22:55.292] iteration 16301 : model1 loss : 0.275363 model2 loss : 0.302397
[23:22:55.617] iteration 16302 : model1 loss : 0.207237 model2 loss : 0.238431
[23:22:55.943] iteration 16303 : model1 loss : 0.132030 model2 loss : 0.146955
[23:22:56.269] iteration 16304 : model1 loss : 0.141977 model2 loss : 0.216732
[23:22:56.595] iteration 16305 : model1 loss : 0.167313 model2 loss : 0.138601
[23:22:56.921] iteration 16306 : model1 loss : 0.291869 model2 loss : 0.384357
[23:22:57.248] iteration 16307 : model1 loss : 0.189794 model2 loss : 0.199461
[23:22:57.574] iteration 16308 : model1 loss : 0.162796 model2 loss : 0.182320
[23:22:57.899] iteration 16309 : model1 loss : 0.203410 model2 loss : 0.241575
[23:22:58.226] iteration 16310 : model1 loss : 0.332567 model2 loss : 0.279661
[23:22:58.552] iteration 16311 : model1 loss : 0.295645 model2 loss : 0.323549
[23:22:58.878] iteration 16312 : model1 loss : 0.242473 model2 loss : 0.239247
[23:22:59.204] iteration 16313 : model1 loss : 0.288965 model2 loss : 0.347246
[23:22:59.531] iteration 16314 : model1 loss : 0.229223 model2 loss : 0.258547
[23:22:59.859] iteration 16315 : model1 loss : 0.176584 model2 loss : 0.169475
[23:23:00.195] iteration 16316 : model1 loss : 0.211475 model2 loss : 0.187582
[23:23:00.531] iteration 16317 : model1 loss : 0.239450 model2 loss : 0.200541
[23:23:00.867] iteration 16318 : model1 loss : 0.178068 model2 loss : 0.179763
[23:23:01.206] iteration 16319 : model1 loss : 0.192106 model2 loss : 0.193721
[23:23:01.542] iteration 16320 : model1 loss : 0.238485 model2 loss : 0.331450
[23:23:01.879] iteration 16321 : model1 loss : 0.350302 model2 loss : 0.385450
[23:23:02.215] iteration 16322 : model1 loss : 0.239811 model2 loss : 0.262798
[23:23:02.551] iteration 16323 : model1 loss : 0.160421 model2 loss : 0.245460
[23:23:02.887] iteration 16324 : model1 loss : 0.201922 model2 loss : 0.281265
[23:23:03.223] iteration 16325 : model1 loss : 0.245108 model2 loss : 0.281322
[23:23:03.559] iteration 16326 : model1 loss : 0.202686 model2 loss : 0.244805
[23:23:03.898] iteration 16327 : model1 loss : 0.233082 model2 loss : 0.254595
[23:23:04.238] iteration 16328 : model1 loss : 0.233094 model2 loss : 0.187208
[23:23:04.578] iteration 16329 : model1 loss : 0.205557 model2 loss : 0.228425
[23:23:04.917] iteration 16330 : model1 loss : 0.279195 model2 loss : 0.302700
[23:23:05.257] iteration 16331 : model1 loss : 0.189953 model2 loss : 0.249735
[23:23:05.597] iteration 16332 : model1 loss : 0.327354 model2 loss : 0.310183
[23:23:05.933] iteration 16333 : model1 loss : 0.256278 model2 loss : 0.311839
[23:23:06.275] iteration 16334 : model1 loss : 0.206834 model2 loss : 0.246748
[23:23:06.618] iteration 16335 : model1 loss : 0.220650 model2 loss : 0.243356
[23:23:06.954] iteration 16336 : model1 loss : 0.205859 model2 loss : 0.214036
[23:23:07.290] iteration 16337 : model1 loss : 0.204680 model2 loss : 0.201519
[23:23:07.626] iteration 16338 : model1 loss : 0.186674 model2 loss : 0.232408
[23:23:07.963] iteration 16339 : model1 loss : 0.400670 model2 loss : 0.427201
[23:23:08.298] iteration 16340 : model1 loss : 0.142586 model2 loss : 0.172018
[23:23:08.635] iteration 16341 : model1 loss : 0.291134 model2 loss : 0.320319
[23:23:08.972] iteration 16342 : model1 loss : 0.200252 model2 loss : 0.185308
[23:23:09.307] iteration 16343 : model1 loss : 0.279043 model2 loss : 0.285957
[23:23:09.643] iteration 16344 : model1 loss : 0.186450 model2 loss : 0.227275
[23:23:09.978] iteration 16345 : model1 loss : 0.286228 model2 loss : 0.311164
[23:23:10.314] iteration 16346 : model1 loss : 0.185181 model2 loss : 0.224494
[23:23:10.649] iteration 16347 : model1 loss : 0.381317 model2 loss : 0.256992
[23:23:10.984] iteration 16348 : model1 loss : 0.239351 model2 loss : 0.234920
[23:23:11.321] iteration 16349 : model1 loss : 0.264930 model2 loss : 0.282282
[23:23:11.657] iteration 16350 : model1 loss : 0.163623 model2 loss : 0.191092
[23:23:13.012] iteration 16351 : model1 loss : 0.187639 model2 loss : 0.184730
[23:23:13.348] iteration 16352 : model1 loss : 0.206204 model2 loss : 0.236988
[23:23:13.684] iteration 16353 : model1 loss : 0.181276 model2 loss : 0.267205
[23:23:14.021] iteration 16354 : model1 loss : 0.174432 model2 loss : 0.195763
[23:23:14.359] iteration 16355 : model1 loss : 0.136885 model2 loss : 0.163414
[23:23:14.695] iteration 16356 : model1 loss : 0.124601 model2 loss : 0.205598
[23:23:15.031] iteration 16357 : model1 loss : 0.150735 model2 loss : 0.167283
[23:23:15.369] iteration 16358 : model1 loss : 0.256251 model2 loss : 0.313716
[23:23:15.705] iteration 16359 : model1 loss : 0.156510 model2 loss : 0.205337
[23:23:16.043] iteration 16360 : model1 loss : 0.286308 model2 loss : 0.295400
[23:23:16.383] iteration 16361 : model1 loss : 0.235222 model2 loss : 0.271132
[23:23:16.719] iteration 16362 : model1 loss : 0.219988 model2 loss : 0.220408
[23:23:17.055] iteration 16363 : model1 loss : 0.420856 model2 loss : 0.480162
[23:23:17.391] iteration 16364 : model1 loss : 0.295102 model2 loss : 0.340419
[23:23:17.727] iteration 16365 : model1 loss : 0.178135 model2 loss : 0.207928
[23:23:18.064] iteration 16366 : model1 loss : 0.091822 model2 loss : 0.204294
[23:23:18.406] iteration 16367 : model1 loss : 0.174160 model2 loss : 0.167192
[23:23:18.745] iteration 16368 : model1 loss : 0.169451 model2 loss : 0.201081
[23:23:19.082] iteration 16369 : model1 loss : 0.238145 model2 loss : 0.280032
[23:23:19.420] iteration 16370 : model1 loss : 0.278091 model2 loss : 0.308391
[23:23:19.755] iteration 16371 : model1 loss : 0.111582 model2 loss : 0.163934
[23:23:20.092] iteration 16372 : model1 loss : 0.208281 model2 loss : 0.216697
[23:23:20.430] iteration 16373 : model1 loss : 0.155924 model2 loss : 0.158493
[23:23:20.766] iteration 16374 : model1 loss : 0.161934 model2 loss : 0.221087
[23:23:21.103] iteration 16375 : model1 loss : 0.206569 model2 loss : 0.206237
[23:23:21.441] iteration 16376 : model1 loss : 0.342969 model2 loss : 0.354936
[23:23:21.777] iteration 16377 : model1 loss : 0.125364 model2 loss : 0.203860
[23:23:22.113] iteration 16378 : model1 loss : 0.133661 model2 loss : 0.117922
[23:23:22.449] iteration 16379 : model1 loss : 0.176380 model2 loss : 0.200261
[23:23:22.786] iteration 16380 : model1 loss : 0.180753 model2 loss : 0.218220
[23:23:23.122] iteration 16381 : model1 loss : 0.121518 model2 loss : 0.156827
[23:23:23.458] iteration 16382 : model1 loss : 0.255187 model2 loss : 0.297499
[23:23:23.795] iteration 16383 : model1 loss : 0.187738 model2 loss : 0.204431
[23:23:24.131] iteration 16384 : model1 loss : 0.176315 model2 loss : 0.221847
[23:23:24.468] iteration 16385 : model1 loss : 0.350757 model2 loss : 0.351934
[23:23:24.804] iteration 16386 : model1 loss : 0.259281 model2 loss : 0.308127
[23:23:25.140] iteration 16387 : model1 loss : 0.309604 model2 loss : 0.286475
[23:23:25.477] iteration 16388 : model1 loss : 0.185763 model2 loss : 0.186973
[23:23:25.814] iteration 16389 : model1 loss : 0.160032 model2 loss : 0.252633
[23:23:26.151] iteration 16390 : model1 loss : 0.104716 model2 loss : 0.164940
[23:23:26.488] iteration 16391 : model1 loss : 0.289686 model2 loss : 0.262532
[23:23:26.826] iteration 16392 : model1 loss : 0.108486 model2 loss : 0.148888
[23:23:27.163] iteration 16393 : model1 loss : 0.181938 model2 loss : 0.276677
[23:23:27.499] iteration 16394 : model1 loss : 0.189671 model2 loss : 0.173145
[23:23:27.835] iteration 16395 : model1 loss : 0.110625 model2 loss : 0.142699
[23:23:28.172] iteration 16396 : model1 loss : 0.095548 model2 loss : 0.142858
[23:23:28.509] iteration 16397 : model1 loss : 0.298693 model2 loss : 0.321589
[23:23:28.850] iteration 16398 : model1 loss : 0.112016 model2 loss : 0.114558
[23:23:29.187] iteration 16399 : model1 loss : 0.188875 model2 loss : 0.132563
[23:23:29.526] iteration 16400 : model1 loss : 0.203537 model2 loss : 0.237739
[23:23:30.178] iteration 16401 : model1 loss : 0.167237 model2 loss : 0.162980
[23:23:30.516] iteration 16402 : model1 loss : 0.140756 model2 loss : 0.195879
[23:23:30.853] iteration 16403 : model1 loss : 0.205810 model2 loss : 0.169036
[23:23:31.191] iteration 16404 : model1 loss : 0.216191 model2 loss : 0.182877
[23:23:31.528] iteration 16405 : model1 loss : 0.280648 model2 loss : 0.322713
[23:23:31.864] iteration 16406 : model1 loss : 0.182480 model2 loss : 0.200847
[23:23:32.201] iteration 16407 : model1 loss : 0.305733 model2 loss : 0.306247
[23:23:32.538] iteration 16408 : model1 loss : 0.254351 model2 loss : 0.276273
[23:23:32.874] iteration 16409 : model1 loss : 0.255016 model2 loss : 0.262396
[23:23:33.211] iteration 16410 : model1 loss : 0.279479 model2 loss : 0.300762
[23:23:33.550] iteration 16411 : model1 loss : 0.206550 model2 loss : 0.340231
[23:23:33.890] iteration 16412 : model1 loss : 0.168803 model2 loss : 0.216771
[23:23:34.226] iteration 16413 : model1 loss : 0.178839 model2 loss : 0.168646
[23:23:34.562] iteration 16414 : model1 loss : 0.173185 model2 loss : 0.177990
[23:23:34.898] iteration 16415 : model1 loss : 0.221403 model2 loss : 0.276769
[23:23:35.234] iteration 16416 : model1 loss : 0.166443 model2 loss : 0.193204
[23:23:35.571] iteration 16417 : model1 loss : 0.258578 model2 loss : 0.311457
[23:23:35.908] iteration 16418 : model1 loss : 0.205650 model2 loss : 0.216348
[23:23:36.250] iteration 16419 : model1 loss : 0.215226 model2 loss : 0.196032
[23:23:36.587] iteration 16420 : model1 loss : 0.170633 model2 loss : 0.191527
[23:23:36.923] iteration 16421 : model1 loss : 0.243627 model2 loss : 0.221548
[23:23:37.260] iteration 16422 : model1 loss : 0.171412 model2 loss : 0.155646
[23:23:37.596] iteration 16423 : model1 loss : 0.151757 model2 loss : 0.210867
[23:23:37.934] iteration 16424 : model1 loss : 0.243283 model2 loss : 0.234571
[23:23:38.270] iteration 16425 : model1 loss : 0.214131 model2 loss : 0.249882
[23:23:38.607] iteration 16426 : model1 loss : 0.285545 model2 loss : 0.295251
[23:23:38.947] iteration 16427 : model1 loss : 0.106039 model2 loss : 0.191064
[23:23:39.283] iteration 16428 : model1 loss : 0.192864 model2 loss : 0.212278
[23:23:39.620] iteration 16429 : model1 loss : 0.401554 model2 loss : 0.418722
[23:23:39.956] iteration 16430 : model1 loss : 0.191799 model2 loss : 0.244415
[23:23:40.294] iteration 16431 : model1 loss : 0.171730 model2 loss : 0.211159
[23:23:40.630] iteration 16432 : model1 loss : 0.166138 model2 loss : 0.222475
[23:23:40.967] iteration 16433 : model1 loss : 0.109434 model2 loss : 0.112073
[23:23:41.303] iteration 16434 : model1 loss : 0.305873 model2 loss : 0.251556
[23:23:41.640] iteration 16435 : model1 loss : 0.173272 model2 loss : 0.192859
[23:23:41.980] iteration 16436 : model1 loss : 0.194739 model2 loss : 0.196686
[23:23:42.323] iteration 16437 : model1 loss : 0.199954 model2 loss : 0.213186
[23:23:42.665] iteration 16438 : model1 loss : 0.129116 model2 loss : 0.169979
[23:23:43.006] iteration 16439 : model1 loss : 0.128193 model2 loss : 0.158827
[23:23:43.348] iteration 16440 : model1 loss : 0.127287 model2 loss : 0.165257
[23:23:43.689] iteration 16441 : model1 loss : 0.132476 model2 loss : 0.115067
[23:23:44.026] iteration 16442 : model1 loss : 0.221192 model2 loss : 0.245699
[23:23:44.364] iteration 16443 : model1 loss : 0.200024 model2 loss : 0.218269
[23:23:44.703] iteration 16444 : model1 loss : 0.185920 model2 loss : 0.236126
[23:23:45.042] iteration 16445 : model1 loss : 0.208082 model2 loss : 0.217119
[23:23:45.384] iteration 16446 : model1 loss : 0.183197 model2 loss : 0.216965
[23:23:45.721] iteration 16447 : model1 loss : 0.193315 model2 loss : 0.213552
[23:23:46.059] iteration 16448 : model1 loss : 0.209193 model2 loss : 0.247048
[23:23:46.397] iteration 16449 : model1 loss : 0.256190 model2 loss : 0.204394
[23:23:46.736] iteration 16450 : model1 loss : 0.225302 model2 loss : 0.293330
[23:23:47.389] iteration 16451 : model1 loss : 0.277759 model2 loss : 0.282553
[23:23:47.726] iteration 16452 : model1 loss : 0.229341 model2 loss : 0.194742
[23:23:48.063] iteration 16453 : model1 loss : 0.192553 model2 loss : 0.256431
[23:23:48.400] iteration 16454 : model1 loss : 0.248435 model2 loss : 0.257167
[23:23:48.740] iteration 16455 : model1 loss : 0.090747 model2 loss : 0.216123
[23:23:49.083] iteration 16456 : model1 loss : 0.250572 model2 loss : 0.261030
[23:23:49.427] iteration 16457 : model1 loss : 0.242093 model2 loss : 0.264525
[23:23:49.770] iteration 16458 : model1 loss : 0.203665 model2 loss : 0.221206
[23:23:50.111] iteration 16459 : model1 loss : 0.099636 model2 loss : 0.124552
[23:23:50.451] iteration 16460 : model1 loss : 0.195593 model2 loss : 0.284406
[23:23:50.790] iteration 16461 : model1 loss : 0.273176 model2 loss : 0.328221
[23:23:51.126] iteration 16462 : model1 loss : 0.207643 model2 loss : 0.161404
[23:23:51.469] iteration 16463 : model1 loss : 0.198561 model2 loss : 0.299288
[23:23:51.810] iteration 16464 : model1 loss : 0.080854 model2 loss : 0.162955
[23:23:52.149] iteration 16465 : model1 loss : 0.274463 model2 loss : 0.330033
[23:23:52.490] iteration 16466 : model1 loss : 0.118426 model2 loss : 0.157578
[23:23:52.827] iteration 16467 : model1 loss : 0.243001 model2 loss : 0.296811
[23:23:53.166] iteration 16468 : model1 loss : 0.202202 model2 loss : 0.188774
[23:23:53.504] iteration 16469 : model1 loss : 0.232633 model2 loss : 0.254084
[23:23:53.844] iteration 16470 : model1 loss : 0.186992 model2 loss : 0.261130
[23:23:54.183] iteration 16471 : model1 loss : 0.280812 model2 loss : 0.223212
[23:23:54.538] iteration 16472 : model1 loss : 0.221692 model2 loss : 0.240548
[23:23:54.879] iteration 16473 : model1 loss : 0.182931 model2 loss : 0.255495
[23:23:55.222] iteration 16474 : model1 loss : 0.202305 model2 loss : 0.255387
[23:23:55.562] iteration 16475 : model1 loss : 0.255478 model2 loss : 0.327183
[23:23:55.902] iteration 16476 : model1 loss : 0.246844 model2 loss : 0.318036
[23:23:56.243] iteration 16477 : model1 loss : 0.171281 model2 loss : 0.227255
[23:23:56.584] iteration 16478 : model1 loss : 0.229226 model2 loss : 0.308635
[23:23:56.922] iteration 16479 : model1 loss : 0.218443 model2 loss : 0.296565
[23:23:57.259] iteration 16480 : model1 loss : 0.125056 model2 loss : 0.191780
[23:23:57.598] iteration 16481 : model1 loss : 0.243553 model2 loss : 0.256303
[23:23:57.937] iteration 16482 : model1 loss : 0.158674 model2 loss : 0.248182
[23:23:58.278] iteration 16483 : model1 loss : 0.195509 model2 loss : 0.264105
[23:23:58.614] iteration 16484 : model1 loss : 0.260576 model2 loss : 0.303041
[23:23:58.951] iteration 16485 : model1 loss : 0.324170 model2 loss : 0.285879
[23:23:59.291] iteration 16486 : model1 loss : 0.316973 model2 loss : 0.258674
[23:23:59.627] iteration 16487 : model1 loss : 0.278257 model2 loss : 0.285232
[23:23:59.964] iteration 16488 : model1 loss : 0.230498 model2 loss : 0.287952
[23:24:00.300] iteration 16489 : model1 loss : 0.197753 model2 loss : 0.186315
[23:24:00.635] iteration 16490 : model1 loss : 0.325181 model2 loss : 0.349742
[23:24:00.971] iteration 16491 : model1 loss : 0.236400 model2 loss : 0.268065
[23:24:01.311] iteration 16492 : model1 loss : 0.288856 model2 loss : 0.346791
[23:24:01.652] iteration 16493 : model1 loss : 0.319744 model2 loss : 0.365459
[23:24:01.992] iteration 16494 : model1 loss : 0.171318 model2 loss : 0.199913
[23:24:02.321] iteration 16495 : model1 loss : 0.189593 model2 loss : 0.247453
[23:24:02.650] iteration 16496 : model1 loss : 0.259310 model2 loss : 0.265112
[23:24:02.979] iteration 16497 : model1 loss : 0.190696 model2 loss : 0.227701
[23:24:03.308] iteration 16498 : model1 loss : 0.172899 model2 loss : 0.196029
[23:24:03.638] iteration 16499 : model1 loss : 0.088733 model2 loss : 0.139123
[23:24:03.969] iteration 16500 : model1 loss : 0.162606 model2 loss : 0.198223
[23:24:04.535] iteration 16501 : model1 loss : 0.200346 model2 loss : 0.211480
[23:24:04.879] iteration 16502 : model1 loss : 0.234561 model2 loss : 0.223627
[23:24:05.236] iteration 16503 : model1 loss : 0.154400 model2 loss : 0.162438
[23:24:05.576] iteration 16504 : model1 loss : 0.140716 model2 loss : 0.167865
[23:24:05.916] iteration 16505 : model1 loss : 0.243796 model2 loss : 0.248688
[23:24:06.262] iteration 16506 : model1 loss : 0.163526 model2 loss : 0.239019
[23:24:06.598] iteration 16507 : model1 loss : 0.355494 model2 loss : 0.365498
[23:24:06.936] iteration 16508 : model1 loss : 0.120226 model2 loss : 0.129474
[23:24:07.277] iteration 16509 : model1 loss : 0.298265 model2 loss : 0.326588
[23:24:07.614] iteration 16510 : model1 loss : 0.187407 model2 loss : 0.196146
[23:24:07.980] iteration 16511 : model1 loss : 0.245477 model2 loss : 0.312826
[23:24:08.320] iteration 16512 : model1 loss : 0.113110 model2 loss : 0.158765
[23:24:08.661] iteration 16513 : model1 loss : 0.240270 model2 loss : 0.270273
[23:24:09.002] iteration 16514 : model1 loss : 0.253156 model2 loss : 0.265604
[23:24:09.344] iteration 16515 : model1 loss : 0.116531 model2 loss : 0.128887
[23:24:09.683] iteration 16516 : model1 loss : 0.201096 model2 loss : 0.211421
[23:24:10.021] iteration 16517 : model1 loss : 0.269900 model2 loss : 0.299446
[23:24:10.359] iteration 16518 : model1 loss : 0.266400 model2 loss : 0.307070
[23:24:10.700] iteration 16519 : model1 loss : 0.157979 model2 loss : 0.151705
[23:24:11.039] iteration 16520 : model1 loss : 0.253567 model2 loss : 0.301330
[23:24:11.375] iteration 16521 : model1 loss : 0.149290 model2 loss : 0.175788
[23:24:11.712] iteration 16522 : model1 loss : 0.210047 model2 loss : 0.235304
[23:24:12.049] iteration 16523 : model1 loss : 0.211521 model2 loss : 0.266264
[23:24:12.377] iteration 16524 : model1 loss : 0.260560 model2 loss : 0.262768
[23:24:12.707] iteration 16525 : model1 loss : 0.210750 model2 loss : 0.238210
[23:24:13.035] iteration 16526 : model1 loss : 0.308131 model2 loss : 0.319770
[23:24:13.369] iteration 16527 : model1 loss : 0.207543 model2 loss : 0.293845
[23:24:13.698] iteration 16528 : model1 loss : 0.178446 model2 loss : 0.188002
[23:24:14.026] iteration 16529 : model1 loss : 0.192019 model2 loss : 0.262223
[23:24:14.355] iteration 16530 : model1 loss : 0.129065 model2 loss : 0.141086
[23:24:14.686] iteration 16531 : model1 loss : 0.239428 model2 loss : 0.311946
[23:24:15.016] iteration 16532 : model1 loss : 0.273487 model2 loss : 0.287769
[23:24:15.345] iteration 16533 : model1 loss : 0.248112 model2 loss : 0.264890
[23:24:15.674] iteration 16534 : model1 loss : 0.207217 model2 loss : 0.192394
[23:24:16.004] iteration 16535 : model1 loss : 0.194706 model2 loss : 0.210132
[23:24:16.335] iteration 16536 : model1 loss : 0.256726 model2 loss : 0.295880
[23:24:16.665] iteration 16537 : model1 loss : 0.279038 model2 loss : 0.234862
[23:24:16.996] iteration 16538 : model1 loss : 0.247817 model2 loss : 0.263946
[23:24:17.325] iteration 16539 : model1 loss : 0.149414 model2 loss : 0.193413
[23:24:17.651] iteration 16540 : model1 loss : 0.231934 model2 loss : 0.194579
[23:24:17.977] iteration 16541 : model1 loss : 0.089026 model2 loss : 0.124915
[23:24:18.304] iteration 16542 : model1 loss : 0.228309 model2 loss : 0.235106
[23:24:18.630] iteration 16543 : model1 loss : 0.189216 model2 loss : 0.207624
[23:24:18.957] iteration 16544 : model1 loss : 0.174493 model2 loss : 0.257089
[23:24:19.284] iteration 16545 : model1 loss : 0.112075 model2 loss : 0.103580
[23:24:19.610] iteration 16546 : model1 loss : 0.165457 model2 loss : 0.267829
[23:24:19.936] iteration 16547 : model1 loss : 0.261362 model2 loss : 0.280755
[23:24:20.263] iteration 16548 : model1 loss : 0.224836 model2 loss : 0.276580
[23:24:20.590] iteration 16549 : model1 loss : 0.163352 model2 loss : 0.246064
[23:24:20.915] iteration 16550 : model1 loss : 0.093648 model2 loss : 0.100732
[23:24:21.421] iteration 16551 : model1 loss : 0.152928 model2 loss : 0.183400
[23:24:21.747] iteration 16552 : model1 loss : 0.214943 model2 loss : 0.229050
[23:24:22.074] iteration 16553 : model1 loss : 0.171705 model2 loss : 0.202234
[23:24:22.401] iteration 16554 : model1 loss : 0.229085 model2 loss : 0.299930
[23:24:22.728] iteration 16555 : model1 loss : 0.169052 model2 loss : 0.191707
[23:24:23.053] iteration 16556 : model1 loss : 0.147004 model2 loss : 0.182315
[23:24:23.380] iteration 16557 : model1 loss : 0.222447 model2 loss : 0.300485
[23:24:23.708] iteration 16558 : model1 loss : 0.186578 model2 loss : 0.180884
[23:24:24.034] iteration 16559 : model1 loss : 0.247535 model2 loss : 0.294608
[23:24:24.360] iteration 16560 : model1 loss : 0.192395 model2 loss : 0.257265
[23:24:24.687] iteration 16561 : model1 loss : 0.293620 model2 loss : 0.284785
[23:24:25.014] iteration 16562 : model1 loss : 0.253754 model2 loss : 0.301536
[23:24:25.342] iteration 16563 : model1 loss : 0.123353 model2 loss : 0.228087
[23:24:25.668] iteration 16564 : model1 loss : 0.132011 model2 loss : 0.171852
[23:24:25.995] iteration 16565 : model1 loss : 0.196421 model2 loss : 0.198814
[23:24:26.322] iteration 16566 : model1 loss : 0.187759 model2 loss : 0.211125
[23:24:26.648] iteration 16567 : model1 loss : 0.191850 model2 loss : 0.230253
[23:24:26.974] iteration 16568 : model1 loss : 0.132031 model2 loss : 0.183610
[23:24:27.301] iteration 16569 : model1 loss : 0.176288 model2 loss : 0.213124
[23:24:27.627] iteration 16570 : model1 loss : 0.406159 model2 loss : 0.356663
[23:24:27.953] iteration 16571 : model1 loss : 0.126960 model2 loss : 0.186724
[23:24:28.279] iteration 16572 : model1 loss : 0.181864 model2 loss : 0.184859
[23:24:28.605] iteration 16573 : model1 loss : 0.224724 model2 loss : 0.257214
[23:24:28.932] iteration 16574 : model1 loss : 0.235295 model2 loss : 0.178958
[23:24:29.258] iteration 16575 : model1 loss : 0.144931 model2 loss : 0.158357
[23:24:29.586] iteration 16576 : model1 loss : 0.172468 model2 loss : 0.208518
[23:24:29.924] iteration 16577 : model1 loss : 0.143848 model2 loss : 0.198572
[23:24:30.262] iteration 16578 : model1 loss : 0.239024 model2 loss : 0.244122
[23:24:30.601] iteration 16579 : model1 loss : 0.171233 model2 loss : 0.255520
[23:24:30.937] iteration 16580 : model1 loss : 0.271616 model2 loss : 0.274124
[23:24:31.274] iteration 16581 : model1 loss : 0.169236 model2 loss : 0.186362
[23:24:31.610] iteration 16582 : model1 loss : 0.195166 model2 loss : 0.188151
[23:24:31.946] iteration 16583 : model1 loss : 0.143067 model2 loss : 0.161641
[23:24:32.282] iteration 16584 : model1 loss : 0.291911 model2 loss : 0.246304
[23:24:32.619] iteration 16585 : model1 loss : 0.269035 model2 loss : 0.295929
[23:24:32.955] iteration 16586 : model1 loss : 0.184408 model2 loss : 0.323907
[23:24:33.294] iteration 16587 : model1 loss : 0.213858 model2 loss : 0.245661
[23:24:33.630] iteration 16588 : model1 loss : 0.192579 model2 loss : 0.203700
[23:24:33.967] iteration 16589 : model1 loss : 0.214639 model2 loss : 0.267493
[23:24:34.304] iteration 16590 : model1 loss : 0.112764 model2 loss : 0.121940
[23:24:34.640] iteration 16591 : model1 loss : 0.186210 model2 loss : 0.228219
[23:24:34.976] iteration 16592 : model1 loss : 0.230778 model2 loss : 0.237791
[23:24:35.314] iteration 16593 : model1 loss : 0.152053 model2 loss : 0.176972
[23:24:35.651] iteration 16594 : model1 loss : 0.160000 model2 loss : 0.172918
[23:24:35.988] iteration 16595 : model1 loss : 0.145614 model2 loss : 0.198782
[23:24:36.324] iteration 16596 : model1 loss : 0.260057 model2 loss : 0.245377
[23:24:36.661] iteration 16597 : model1 loss : 0.179459 model2 loss : 0.189172
[23:24:36.995] iteration 16598 : model1 loss : 0.179209 model2 loss : 0.210563
[23:24:37.332] iteration 16599 : model1 loss : 0.135319 model2 loss : 0.139412
[23:24:37.669] iteration 16600 : model1 loss : 0.262172 model2 loss : 0.299434
[23:24:38.298] iteration 16601 : model1 loss : 0.214605 model2 loss : 0.246775
[23:24:38.635] iteration 16602 : model1 loss : 0.234422 model2 loss : 0.260973
[23:24:38.972] iteration 16603 : model1 loss : 0.220550 model2 loss : 0.233720
[23:24:39.309] iteration 16604 : model1 loss : 0.188863 model2 loss : 0.204448
[23:24:39.648] iteration 16605 : model1 loss : 0.266866 model2 loss : 0.288225
[23:24:39.988] iteration 16606 : model1 loss : 0.173670 model2 loss : 0.196081
[23:24:40.326] iteration 16607 : model1 loss : 0.180981 model2 loss : 0.237590
[23:24:40.664] iteration 16608 : model1 loss : 0.399815 model2 loss : 0.402934
[23:24:41.001] iteration 16609 : model1 loss : 0.228819 model2 loss : 0.250115
[23:24:41.340] iteration 16610 : model1 loss : 0.322729 model2 loss : 0.333026
[23:24:41.680] iteration 16611 : model1 loss : 0.239386 model2 loss : 0.312579
[23:24:42.019] iteration 16612 : model1 loss : 0.239804 model2 loss : 0.258857
[23:24:42.359] iteration 16613 : model1 loss : 0.225410 model2 loss : 0.227177
[23:24:42.695] iteration 16614 : model1 loss : 0.166352 model2 loss : 0.157931
[23:24:43.032] iteration 16615 : model1 loss : 0.103019 model2 loss : 0.107742
[23:24:43.368] iteration 16616 : model1 loss : 0.215147 model2 loss : 0.236066
[23:24:43.704] iteration 16617 : model1 loss : 0.251893 model2 loss : 0.277557
[23:24:44.041] iteration 16618 : model1 loss : 0.103237 model2 loss : 0.177679
[23:24:44.378] iteration 16619 : model1 loss : 0.244149 model2 loss : 0.252255
[23:24:44.718] iteration 16620 : model1 loss : 0.275721 model2 loss : 0.276708
[23:24:45.054] iteration 16621 : model1 loss : 0.199281 model2 loss : 0.239330
[23:24:45.391] iteration 16622 : model1 loss : 0.186309 model2 loss : 0.207308
[23:24:45.727] iteration 16623 : model1 loss : 0.180008 model2 loss : 0.201048
[23:24:46.056] iteration 16624 : model1 loss : 0.175828 model2 loss : 0.201943
[23:24:46.385] iteration 16625 : model1 loss : 0.116120 model2 loss : 0.216074
[23:24:46.714] iteration 16626 : model1 loss : 0.200581 model2 loss : 0.207166
[23:24:47.042] iteration 16627 : model1 loss : 0.110089 model2 loss : 0.135794
[23:24:47.370] iteration 16628 : model1 loss : 0.200956 model2 loss : 0.256589
[23:24:47.696] iteration 16629 : model1 loss : 0.181625 model2 loss : 0.208521
[23:24:48.023] iteration 16630 : model1 loss : 0.181787 model2 loss : 0.203368
[23:24:48.349] iteration 16631 : model1 loss : 0.304774 model2 loss : 0.340102
[23:24:48.676] iteration 16632 : model1 loss : 0.253689 model2 loss : 0.274780
[23:24:49.004] iteration 16633 : model1 loss : 0.117330 model2 loss : 0.201236
[23:24:49.330] iteration 16634 : model1 loss : 0.120867 model2 loss : 0.152119
[23:24:49.653] iteration 16635 : model1 loss : 0.158742 model2 loss : 0.245938
[23:24:49.980] iteration 16636 : model1 loss : 0.173531 model2 loss : 0.230022
[23:24:50.308] iteration 16637 : model1 loss : 0.107054 model2 loss : 0.132366
[23:24:50.632] iteration 16638 : model1 loss : 0.148189 model2 loss : 0.120531
[23:24:50.953] iteration 16639 : model1 loss : 0.113092 model2 loss : 0.152112
[23:24:51.278] iteration 16640 : model1 loss : 0.262107 model2 loss : 0.264860
[23:24:51.603] iteration 16641 : model1 loss : 0.247301 model2 loss : 0.261335
[23:24:51.928] iteration 16642 : model1 loss : 0.099969 model2 loss : 0.196847
[23:24:52.250] iteration 16643 : model1 loss : 0.093511 model2 loss : 0.189636
[23:24:52.575] iteration 16644 : model1 loss : 0.155039 model2 loss : 0.220489
[23:24:52.896] iteration 16645 : model1 loss : 0.246633 model2 loss : 0.250954
[23:24:53.221] iteration 16646 : model1 loss : 0.283022 model2 loss : 0.353935
[23:24:53.546] iteration 16647 : model1 loss : 0.193180 model2 loss : 0.244362
[23:24:53.870] iteration 16648 : model1 loss : 0.106819 model2 loss : 0.100670
[23:24:54.198] iteration 16649 : model1 loss : 0.171875 model2 loss : 0.208563
[23:24:54.524] iteration 16650 : model1 loss : 0.196560 model2 loss : 0.274172
[23:24:55.041] iteration 16651 : model1 loss : 0.114351 model2 loss : 0.132371
[23:24:55.367] iteration 16652 : model1 loss : 0.193416 model2 loss : 0.234581
[23:24:55.692] iteration 16653 : model1 loss : 0.139410 model2 loss : 0.122694
[23:24:56.017] iteration 16654 : model1 loss : 0.272231 model2 loss : 0.315340
[23:24:56.339] iteration 16655 : model1 loss : 0.226798 model2 loss : 0.222216
[23:24:56.665] iteration 16656 : model1 loss : 0.174986 model2 loss : 0.230492
[23:24:56.991] iteration 16657 : model1 loss : 0.269583 model2 loss : 0.278364
[23:24:57.318] iteration 16658 : model1 loss : 0.253058 model2 loss : 0.220295
[23:24:57.644] iteration 16659 : model1 loss : 0.105223 model2 loss : 0.210319
[23:24:57.970] iteration 16660 : model1 loss : 0.250702 model2 loss : 0.258658
[23:24:58.296] iteration 16661 : model1 loss : 0.168587 model2 loss : 0.233737
[23:24:58.622] iteration 16662 : model1 loss : 0.179944 model2 loss : 0.191794
[23:24:58.947] iteration 16663 : model1 loss : 0.215888 model2 loss : 0.239542
[23:24:59.270] iteration 16664 : model1 loss : 0.187681 model2 loss : 0.175741
[23:24:59.597] iteration 16665 : model1 loss : 0.219148 model2 loss : 0.264196
[23:24:59.923] iteration 16666 : model1 loss : 0.225941 model2 loss : 0.245687
[23:25:00.248] iteration 16667 : model1 loss : 0.191176 model2 loss : 0.248605
[23:25:00.574] iteration 16668 : model1 loss : 0.282761 model2 loss : 0.219582
[23:25:00.901] iteration 16669 : model1 loss : 0.204690 model2 loss : 0.219048
[23:25:01.223] iteration 16670 : model1 loss : 0.151885 model2 loss : 0.204866
[23:25:01.549] iteration 16671 : model1 loss : 0.414780 model2 loss : 0.319542
[23:25:01.873] iteration 16672 : model1 loss : 0.110741 model2 loss : 0.174225
[23:25:02.197] iteration 16673 : model1 loss : 0.319498 model2 loss : 0.319971
[23:25:02.522] iteration 16674 : model1 loss : 0.295979 model2 loss : 0.285768
[23:25:02.847] iteration 16675 : model1 loss : 0.135162 model2 loss : 0.216935
[23:25:03.172] iteration 16676 : model1 loss : 0.271746 model2 loss : 0.334667
[23:25:03.496] iteration 16677 : model1 loss : 0.186995 model2 loss : 0.193114
[23:25:03.826] iteration 16678 : model1 loss : 0.174651 model2 loss : 0.228237
[23:25:04.151] iteration 16679 : model1 loss : 0.168887 model2 loss : 0.258480
[23:25:04.476] iteration 16680 : model1 loss : 0.243186 model2 loss : 0.314384
[23:25:04.802] iteration 16681 : model1 loss : 0.220039 model2 loss : 0.228991
[23:25:05.127] iteration 16682 : model1 loss : 0.274407 model2 loss : 0.341905
[23:25:05.449] iteration 16683 : model1 loss : 0.242816 model2 loss : 0.252861
[23:25:05.774] iteration 16684 : model1 loss : 0.098399 model2 loss : 0.158030
[23:25:06.098] iteration 16685 : model1 loss : 0.196533 model2 loss : 0.233235
[23:25:06.420] iteration 16686 : model1 loss : 0.265644 model2 loss : 0.266620
[23:25:06.741] iteration 16687 : model1 loss : 0.188849 model2 loss : 0.221735
[23:25:07.064] iteration 16688 : model1 loss : 0.104474 model2 loss : 0.228706
[23:25:07.385] iteration 16689 : model1 loss : 0.269701 model2 loss : 0.332379
[23:25:07.707] iteration 16690 : model1 loss : 0.255094 model2 loss : 0.339673
[23:25:08.032] iteration 16691 : model1 loss : 0.395718 model2 loss : 0.402892
[23:25:08.358] iteration 16692 : model1 loss : 0.170396 model2 loss : 0.215021
[23:25:08.683] iteration 16693 : model1 loss : 0.157141 model2 loss : 0.160205
[23:25:09.009] iteration 16694 : model1 loss : 0.193483 model2 loss : 0.244754
[23:25:09.332] iteration 16695 : model1 loss : 0.334706 model2 loss : 0.368176
[23:25:09.661] iteration 16696 : model1 loss : 0.240888 model2 loss : 0.265735
[23:25:09.990] iteration 16697 : model1 loss : 0.203447 model2 loss : 0.239134
[23:25:10.325] iteration 16698 : model1 loss : 0.248081 model2 loss : 0.275277
[23:25:10.663] iteration 16699 : model1 loss : 0.229489 model2 loss : 0.286869
[23:25:11.003] iteration 16700 : model1 loss : 0.265861 model2 loss : 0.230663
[23:25:11.669] iteration 16701 : model1 loss : 0.212731 model2 loss : 0.244534
[23:25:12.004] iteration 16702 : model1 loss : 0.181665 model2 loss : 0.320303
[23:25:12.337] iteration 16703 : model1 loss : 0.272464 model2 loss : 0.302207
[23:25:12.679] iteration 16704 : model1 loss : 0.166245 model2 loss : 0.201115
[23:25:13.014] iteration 16705 : model1 loss : 0.190871 model2 loss : 0.245163
[23:25:13.350] iteration 16706 : model1 loss : 0.205499 model2 loss : 0.255154
[23:25:13.683] iteration 16707 : model1 loss : 0.194273 model2 loss : 0.222193
[23:25:14.021] iteration 16708 : model1 loss : 0.177455 model2 loss : 0.216301
[23:25:14.359] iteration 16709 : model1 loss : 0.195088 model2 loss : 0.207338
[23:25:14.697] iteration 16710 : model1 loss : 0.175045 model2 loss : 0.211024
[23:25:15.037] iteration 16711 : model1 loss : 0.349667 model2 loss : 0.369393
[23:25:15.377] iteration 16712 : model1 loss : 0.251092 model2 loss : 0.245962
[23:25:15.718] iteration 16713 : model1 loss : 0.235881 model2 loss : 0.208860
[23:25:16.055] iteration 16714 : model1 loss : 0.284473 model2 loss : 0.293024
[23:25:16.392] iteration 16715 : model1 loss : 0.280680 model2 loss : 0.298773
[23:25:16.732] iteration 16716 : model1 loss : 0.295480 model2 loss : 0.283553
[23:25:17.075] iteration 16717 : model1 loss : 0.171540 model2 loss : 0.215034
[23:25:17.415] iteration 16718 : model1 loss : 0.329362 model2 loss : 0.311359
[23:25:17.754] iteration 16719 : model1 loss : 0.190614 model2 loss : 0.176938
[23:25:18.090] iteration 16720 : model1 loss : 0.222518 model2 loss : 0.227736
[23:25:18.427] iteration 16721 : model1 loss : 0.242744 model2 loss : 0.226274
[23:25:18.766] iteration 16722 : model1 loss : 0.217672 model2 loss : 0.277087
[23:25:19.103] iteration 16723 : model1 loss : 0.263627 model2 loss : 0.261054
[23:25:19.440] iteration 16724 : model1 loss : 0.151433 model2 loss : 0.228655
[23:25:19.774] iteration 16725 : model1 loss : 0.225505 model2 loss : 0.239437
[23:25:20.115] iteration 16726 : model1 loss : 0.186971 model2 loss : 0.273222
[23:25:20.452] iteration 16727 : model1 loss : 0.167061 model2 loss : 0.261285
[23:25:20.796] iteration 16728 : model1 loss : 0.256488 model2 loss : 0.265544
[23:25:21.130] iteration 16729 : model1 loss : 0.230568 model2 loss : 0.270014
[23:25:21.466] iteration 16730 : model1 loss : 0.089620 model2 loss : 0.192118
[23:25:21.803] iteration 16731 : model1 loss : 0.245557 model2 loss : 0.310107
[23:25:22.145] iteration 16732 : model1 loss : 0.264518 model2 loss : 0.364969
[23:25:22.486] iteration 16733 : model1 loss : 0.216677 model2 loss : 0.203373
[23:25:22.822] iteration 16734 : model1 loss : 0.160084 model2 loss : 0.164615
[23:25:23.156] iteration 16735 : model1 loss : 0.251580 model2 loss : 0.286015
[23:25:23.498] iteration 16736 : model1 loss : 0.213085 model2 loss : 0.235389
[23:25:23.835] iteration 16737 : model1 loss : 0.089839 model2 loss : 0.212159
[23:25:24.172] iteration 16738 : model1 loss : 0.196728 model2 loss : 0.205994
[23:25:24.512] iteration 16739 : model1 loss : 0.156329 model2 loss : 0.205069
[23:25:24.849] iteration 16740 : model1 loss : 0.261810 model2 loss : 0.312019
[23:25:25.191] iteration 16741 : model1 loss : 0.198159 model2 loss : 0.218265
[23:25:25.534] iteration 16742 : model1 loss : 0.265265 model2 loss : 0.294537
[23:25:25.878] iteration 16743 : model1 loss : 0.278050 model2 loss : 0.306697
[23:25:26.216] iteration 16744 : model1 loss : 0.212466 model2 loss : 0.247738
[23:25:26.557] iteration 16745 : model1 loss : 0.283592 model2 loss : 0.327117
[23:25:26.894] iteration 16746 : model1 loss : 0.184531 model2 loss : 0.193917
[23:25:27.231] iteration 16747 : model1 loss : 0.161920 model2 loss : 0.203004
[23:25:27.566] iteration 16748 : model1 loss : 0.139008 model2 loss : 0.149356
[23:25:27.906] iteration 16749 : model1 loss : 0.216781 model2 loss : 0.261088
[23:25:28.240] iteration 16750 : model1 loss : 0.275288 model2 loss : 0.288519
[23:25:28.864] iteration 16751 : model1 loss : 0.098362 model2 loss : 0.137166
[23:25:29.205] iteration 16752 : model1 loss : 0.107875 model2 loss : 0.128963
[23:25:29.538] iteration 16753 : model1 loss : 0.197119 model2 loss : 0.271353
[23:25:29.875] iteration 16754 : model1 loss : 0.277124 model2 loss : 0.359863
[23:25:30.207] iteration 16755 : model1 loss : 0.126281 model2 loss : 0.129899
[23:25:30.545] iteration 16756 : model1 loss : 0.280918 model2 loss : 0.249543
[23:25:30.880] iteration 16757 : model1 loss : 0.156420 model2 loss : 0.180132
[23:25:31.214] iteration 16758 : model1 loss : 0.179265 model2 loss : 0.213544
[23:25:31.548] iteration 16759 : model1 loss : 0.212008 model2 loss : 0.334246
[23:25:31.885] iteration 16760 : model1 loss : 0.341522 model2 loss : 0.410333
[23:25:32.220] iteration 16761 : model1 loss : 0.279714 model2 loss : 0.305860
[23:25:32.557] iteration 16762 : model1 loss : 0.260907 model2 loss : 0.283493
[23:25:32.893] iteration 16763 : model1 loss : 0.167579 model2 loss : 0.232793
[23:25:33.235] iteration 16764 : model1 loss : 0.167881 model2 loss : 0.188313
[23:25:33.575] iteration 16765 : model1 loss : 0.271681 model2 loss : 0.327638
[23:25:33.911] iteration 16766 : model1 loss : 0.264068 model2 loss : 0.316061
[23:25:34.246] iteration 16767 : model1 loss : 0.191088 model2 loss : 0.274000
[23:25:34.582] iteration 16768 : model1 loss : 0.255419 model2 loss : 0.290775
[23:25:34.922] iteration 16769 : model1 loss : 0.125257 model2 loss : 0.211994
[23:25:35.260] iteration 16770 : model1 loss : 0.137117 model2 loss : 0.214094
[23:25:35.591] iteration 16771 : model1 loss : 0.118108 model2 loss : 0.131953
[23:25:35.924] iteration 16772 : model1 loss : 0.094412 model2 loss : 0.184497
[23:25:36.261] iteration 16773 : model1 loss : 0.231030 model2 loss : 0.278672
[23:25:36.597] iteration 16774 : model1 loss : 0.210555 model2 loss : 0.203700
[23:25:36.935] iteration 16775 : model1 loss : 0.173821 model2 loss : 0.194192
[23:25:37.270] iteration 16776 : model1 loss : 0.227813 model2 loss : 0.246667
[23:25:37.611] iteration 16777 : model1 loss : 0.163915 model2 loss : 0.192762
[23:25:37.945] iteration 16778 : model1 loss : 0.191001 model2 loss : 0.194630
[23:25:38.280] iteration 16779 : model1 loss : 0.277217 model2 loss : 0.344774
[23:25:38.617] iteration 16780 : model1 loss : 0.098380 model2 loss : 0.132626
[23:25:38.949] iteration 16781 : model1 loss : 0.105328 model2 loss : 0.216054
[23:25:39.285] iteration 16782 : model1 loss : 0.150427 model2 loss : 0.182175
[23:25:39.618] iteration 16783 : model1 loss : 0.184530 model2 loss : 0.198432
[23:25:39.953] iteration 16784 : model1 loss : 0.207486 model2 loss : 0.196845
[23:25:40.292] iteration 16785 : model1 loss : 0.252947 model2 loss : 0.262233
[23:25:40.626] iteration 16786 : model1 loss : 0.222595 model2 loss : 0.234138
[23:25:40.964] iteration 16787 : model1 loss : 0.192876 model2 loss : 0.217309
[23:25:41.302] iteration 16788 : model1 loss : 0.198083 model2 loss : 0.255153
[23:25:41.636] iteration 16789 : model1 loss : 0.149029 model2 loss : 0.130868
[23:25:41.970] iteration 16790 : model1 loss : 0.101034 model2 loss : 0.157032
[23:25:42.310] iteration 16791 : model1 loss : 0.192222 model2 loss : 0.185373
[23:25:42.647] iteration 16792 : model1 loss : 0.169636 model2 loss : 0.196315
[23:25:42.981] iteration 16793 : model1 loss : 0.327742 model2 loss : 0.369353
[23:25:43.324] iteration 16794 : model1 loss : 0.220270 model2 loss : 0.249117
[23:25:43.661] iteration 16795 : model1 loss : 0.165379 model2 loss : 0.207817
[23:25:43.994] iteration 16796 : model1 loss : 0.161619 model2 loss : 0.175256
[23:25:44.332] iteration 16797 : model1 loss : 0.082707 model2 loss : 0.155646
[23:25:44.670] iteration 16798 : model1 loss : 0.101764 model2 loss : 0.157881
[23:25:45.005] iteration 16799 : model1 loss : 0.272806 model2 loss : 0.262720
[23:25:45.342] iteration 16800 : model1 loss : 0.324880 model2 loss : 0.340366
[23:25:45.983] iteration 16801 : model1 loss : 0.160828 model2 loss : 0.256488
[23:25:46.320] iteration 16802 : model1 loss : 0.109774 model2 loss : 0.189460
[23:25:46.658] iteration 16803 : model1 loss : 0.156752 model2 loss : 0.184517
[23:25:46.992] iteration 16804 : model1 loss : 0.179187 model2 loss : 0.230393
[23:25:47.325] iteration 16805 : model1 loss : 0.237818 model2 loss : 0.267212
[23:25:47.662] iteration 16806 : model1 loss : 0.211212 model2 loss : 0.243604
[23:25:47.999] iteration 16807 : model1 loss : 0.163266 model2 loss : 0.198694
[23:25:48.336] iteration 16808 : model1 loss : 0.251495 model2 loss : 0.297607
[23:25:48.671] iteration 16809 : model1 loss : 0.266235 model2 loss : 0.289887
[23:25:49.007] iteration 16810 : model1 loss : 0.103821 model2 loss : 0.108825
[23:25:49.342] iteration 16811 : model1 loss : 0.215035 model2 loss : 0.280852
[23:25:49.684] iteration 16812 : model1 loss : 0.252597 model2 loss : 0.285309
[23:25:50.019] iteration 16813 : model1 loss : 0.401744 model2 loss : 0.431844
[23:25:50.358] iteration 16814 : model1 loss : 0.154534 model2 loss : 0.145866
[23:25:50.698] iteration 16815 : model1 loss : 0.195121 model2 loss : 0.364344
[23:25:51.035] iteration 16816 : model1 loss : 0.213152 model2 loss : 0.245978
[23:25:51.377] iteration 16817 : model1 loss : 0.245929 model2 loss : 0.268889
[23:25:51.716] iteration 16818 : model1 loss : 0.152461 model2 loss : 0.180404
[23:25:52.053] iteration 16819 : model1 loss : 0.235869 model2 loss : 0.245974
[23:25:52.389] iteration 16820 : model1 loss : 0.228221 model2 loss : 0.285550
[23:25:52.725] iteration 16821 : model1 loss : 0.098309 model2 loss : 0.156033
[23:25:53.062] iteration 16822 : model1 loss : 0.169024 model2 loss : 0.197657
[23:25:53.399] iteration 16823 : model1 loss : 0.273042 model2 loss : 0.279143
[23:25:53.739] iteration 16824 : model1 loss : 0.109217 model2 loss : 0.108503
[23:25:54.075] iteration 16825 : model1 loss : 0.083891 model2 loss : 0.121875
[23:25:54.411] iteration 16826 : model1 loss : 0.175735 model2 loss : 0.255316
[23:25:54.752] iteration 16827 : model1 loss : 0.199280 model2 loss : 0.202532
[23:25:55.090] iteration 16828 : model1 loss : 0.268641 model2 loss : 0.301750
[23:25:55.428] iteration 16829 : model1 loss : 0.175925 model2 loss : 0.250450
[23:25:55.770] iteration 16830 : model1 loss : 0.334852 model2 loss : 0.335454
[23:25:56.107] iteration 16831 : model1 loss : 0.256287 model2 loss : 0.269817
[23:25:56.454] iteration 16832 : model1 loss : 0.232023 model2 loss : 0.287165
[23:25:56.791] iteration 16833 : model1 loss : 0.199149 model2 loss : 0.178137
[23:25:57.127] iteration 16834 : model1 loss : 0.167232 model2 loss : 0.182063
[23:25:57.469] iteration 16835 : model1 loss : 0.254850 model2 loss : 0.272570
[23:25:57.806] iteration 16836 : model1 loss : 0.253440 model2 loss : 0.323490
[23:25:58.143] iteration 16837 : model1 loss : 0.177886 model2 loss : 0.192161
[23:25:58.481] iteration 16838 : model1 loss : 0.125733 model2 loss : 0.155381
[23:25:58.819] iteration 16839 : model1 loss : 0.184187 model2 loss : 0.276187
[23:25:59.158] iteration 16840 : model1 loss : 0.190891 model2 loss : 0.217661
[23:25:59.496] iteration 16841 : model1 loss : 0.097118 model2 loss : 0.122428
[23:25:59.840] iteration 16842 : model1 loss : 0.243681 model2 loss : 0.306330
[23:26:00.182] iteration 16843 : model1 loss : 0.199201 model2 loss : 0.249234
[23:26:00.525] iteration 16844 : model1 loss : 0.193027 model2 loss : 0.313028
[23:26:00.863] iteration 16845 : model1 loss : 0.168551 model2 loss : 0.227431
[23:26:01.203] iteration 16846 : model1 loss : 0.198735 model2 loss : 0.184025
[23:26:01.541] iteration 16847 : model1 loss : 0.215762 model2 loss : 0.274969
[23:26:01.878] iteration 16848 : model1 loss : 0.222728 model2 loss : 0.164156
[23:26:02.219] iteration 16849 : model1 loss : 0.190379 model2 loss : 0.218534
[23:26:02.560] iteration 16850 : model1 loss : 0.216964 model2 loss : 0.249367
[23:26:03.183] iteration 16851 : model1 loss : 0.247722 model2 loss : 0.292895
[23:26:03.522] iteration 16852 : model1 loss : 0.098840 model2 loss : 0.149480
[23:26:03.861] iteration 16853 : model1 loss : 0.164552 model2 loss : 0.182226
[23:26:04.201] iteration 16854 : model1 loss : 0.205681 model2 loss : 0.236155
[23:26:04.541] iteration 16855 : model1 loss : 0.273471 model2 loss : 0.283315
[23:26:04.878] iteration 16856 : model1 loss : 0.270190 model2 loss : 0.305160
[23:26:05.220] iteration 16857 : model1 loss : 0.185982 model2 loss : 0.208456
[23:26:05.563] iteration 16858 : model1 loss : 0.178045 model2 loss : 0.245125
[23:26:05.904] iteration 16859 : model1 loss : 0.168884 model2 loss : 0.183530
[23:26:06.241] iteration 16860 : model1 loss : 0.265345 model2 loss : 0.288706
[23:26:06.583] iteration 16861 : model1 loss : 0.142370 model2 loss : 0.201145
[23:26:06.919] iteration 16862 : model1 loss : 0.185180 model2 loss : 0.242832
[23:26:07.260] iteration 16863 : model1 loss : 0.179914 model2 loss : 0.200828
[23:26:07.601] iteration 16864 : model1 loss : 0.174768 model2 loss : 0.179409
[23:26:07.938] iteration 16865 : model1 loss : 0.310315 model2 loss : 0.303690
[23:26:08.277] iteration 16866 : model1 loss : 0.207432 model2 loss : 0.215034
[23:26:08.617] iteration 16867 : model1 loss : 0.174523 model2 loss : 0.229226
[23:26:08.960] iteration 16868 : model1 loss : 0.174173 model2 loss : 0.253568
[23:26:09.302] iteration 16869 : model1 loss : 0.204849 model2 loss : 0.301053
[23:26:09.640] iteration 16870 : model1 loss : 0.178096 model2 loss : 0.259351
[23:26:09.978] iteration 16871 : model1 loss : 0.180812 model2 loss : 0.283221
[23:26:10.317] iteration 16872 : model1 loss : 0.188200 model2 loss : 0.223825
[23:26:10.655] iteration 16873 : model1 loss : 0.196954 model2 loss : 0.223398
[23:26:10.997] iteration 16874 : model1 loss : 0.251405 model2 loss : 0.259689
[23:26:11.338] iteration 16875 : model1 loss : 0.204919 model2 loss : 0.233630
[23:26:11.681] iteration 16876 : model1 loss : 0.214969 model2 loss : 0.253093
[23:26:12.020] iteration 16877 : model1 loss : 0.101714 model2 loss : 0.133812
[23:26:12.359] iteration 16878 : model1 loss : 0.277882 model2 loss : 0.302402
[23:26:12.700] iteration 16879 : model1 loss : 0.179975 model2 loss : 0.183727
[23:26:13.037] iteration 16880 : model1 loss : 0.166826 model2 loss : 0.225883
[23:26:13.378] iteration 16881 : model1 loss : 0.241958 model2 loss : 0.245005
[23:26:13.715] iteration 16882 : model1 loss : 0.302387 model2 loss : 0.245006
[23:26:14.056] iteration 16883 : model1 loss : 0.118237 model2 loss : 0.136588
[23:26:14.396] iteration 16884 : model1 loss : 0.255382 model2 loss : 0.216398
[23:26:14.736] iteration 16885 : model1 loss : 0.276358 model2 loss : 0.293168
[23:26:15.074] iteration 16886 : model1 loss : 0.199378 model2 loss : 0.253492
[23:26:15.411] iteration 16887 : model1 loss : 0.069693 model2 loss : 0.102166
[23:26:15.756] iteration 16888 : model1 loss : 0.226029 model2 loss : 0.282547
[23:26:16.094] iteration 16889 : model1 loss : 0.163170 model2 loss : 0.209198
[23:26:16.433] iteration 16890 : model1 loss : 0.105668 model2 loss : 0.116775
[23:26:16.771] iteration 16891 : model1 loss : 0.166783 model2 loss : 0.179415
[23:26:17.111] iteration 16892 : model1 loss : 0.205378 model2 loss : 0.225506
[23:26:17.448] iteration 16893 : model1 loss : 0.243007 model2 loss : 0.259835
[23:26:17.783] iteration 16894 : model1 loss : 0.133313 model2 loss : 0.135670
[23:26:18.121] iteration 16895 : model1 loss : 0.100774 model2 loss : 0.129646
[23:26:19.131] iteration 16896 : model1 loss : 0.177853 model2 loss : 0.184624
[23:26:19.471] iteration 16897 : model1 loss : 0.275236 model2 loss : 0.294104
[23:26:19.811] iteration 16898 : model1 loss : 0.163328 model2 loss : 0.199688
[23:26:20.149] iteration 16899 : model1 loss : 0.112587 model2 loss : 0.155874
[23:26:20.494] iteration 16900 : model1 loss : 0.244955 model2 loss : 0.303074
[23:26:21.155] iteration 16901 : model1 loss : 0.255605 model2 loss : 0.275471
[23:26:21.492] iteration 16902 : model1 loss : 0.251833 model2 loss : 0.280449
[23:26:21.834] iteration 16903 : model1 loss : 0.274642 model2 loss : 0.285849
[23:26:22.174] iteration 16904 : model1 loss : 0.223529 model2 loss : 0.303320
[23:26:22.511] iteration 16905 : model1 loss : 0.070982 model2 loss : 0.096637
[23:26:22.855] iteration 16906 : model1 loss : 0.278470 model2 loss : 0.302106
[23:26:23.194] iteration 16907 : model1 loss : 0.170520 model2 loss : 0.194562
[23:26:23.531] iteration 16908 : model1 loss : 0.264363 model2 loss : 0.342944
[23:26:23.871] iteration 16909 : model1 loss : 0.170565 model2 loss : 0.200307
[23:26:24.208] iteration 16910 : model1 loss : 0.111723 model2 loss : 0.136982
[23:26:24.548] iteration 16911 : model1 loss : 0.121404 model2 loss : 0.207965
[23:26:24.892] iteration 16912 : model1 loss : 0.296756 model2 loss : 0.290130
[23:26:25.231] iteration 16913 : model1 loss : 0.243307 model2 loss : 0.261601
[23:26:25.571] iteration 16914 : model1 loss : 0.101494 model2 loss : 0.172724
[23:26:25.908] iteration 16915 : model1 loss : 0.257576 model2 loss : 0.281965
[23:26:26.246] iteration 16916 : model1 loss : 0.222702 model2 loss : 0.225515
[23:26:26.583] iteration 16917 : model1 loss : 0.208262 model2 loss : 0.224640
[23:26:26.922] iteration 16918 : model1 loss : 0.170206 model2 loss : 0.235475
[23:26:27.263] iteration 16919 : model1 loss : 0.325870 model2 loss : 0.377247
[23:26:27.603] iteration 16920 : model1 loss : 0.233349 model2 loss : 0.259667
[23:26:27.946] iteration 16921 : model1 loss : 0.178223 model2 loss : 0.213270
[23:26:28.283] iteration 16922 : model1 loss : 0.090124 model2 loss : 0.156867
[23:26:28.620] iteration 16923 : model1 loss : 0.107342 model2 loss : 0.150920
[23:26:28.958] iteration 16924 : model1 loss : 0.192736 model2 loss : 0.186948
[23:26:29.295] iteration 16925 : model1 loss : 0.105238 model2 loss : 0.152088
[23:26:29.636] iteration 16926 : model1 loss : 0.103399 model2 loss : 0.144755
[23:26:29.973] iteration 16927 : model1 loss : 0.214204 model2 loss : 0.237244
[23:26:30.312] iteration 16928 : model1 loss : 0.176942 model2 loss : 0.244365
[23:26:30.650] iteration 16929 : model1 loss : 0.131470 model2 loss : 0.215117
[23:26:30.988] iteration 16930 : model1 loss : 0.200146 model2 loss : 0.305538
[23:26:31.325] iteration 16931 : model1 loss : 0.180632 model2 loss : 0.184556
[23:26:31.662] iteration 16932 : model1 loss : 0.100147 model2 loss : 0.131159
[23:26:32.000] iteration 16933 : model1 loss : 0.254794 model2 loss : 0.260286
[23:26:32.343] iteration 16934 : model1 loss : 0.317611 model2 loss : 0.353038
[23:26:32.684] iteration 16935 : model1 loss : 0.133911 model2 loss : 0.144019
[23:26:33.025] iteration 16936 : model1 loss : 0.260103 model2 loss : 0.317793
[23:26:33.394] iteration 16937 : model1 loss : 0.183691 model2 loss : 0.231820
[23:26:33.731] iteration 16938 : model1 loss : 0.082209 model2 loss : 0.164082
[23:26:34.068] iteration 16939 : model1 loss : 0.107885 model2 loss : 0.142291
[23:26:34.406] iteration 16940 : model1 loss : 0.254445 model2 loss : 0.320494
[23:26:34.743] iteration 16941 : model1 loss : 0.325773 model2 loss : 0.334009
[23:26:35.083] iteration 16942 : model1 loss : 0.258276 model2 loss : 0.258718
[23:26:35.422] iteration 16943 : model1 loss : 0.180889 model2 loss : 0.241630
[23:26:35.760] iteration 16944 : model1 loss : 0.258124 model2 loss : 0.260706
[23:26:36.099] iteration 16945 : model1 loss : 0.234976 model2 loss : 0.258408
[23:26:36.437] iteration 16946 : model1 loss : 0.104791 model2 loss : 0.153311
[23:26:36.775] iteration 16947 : model1 loss : 0.239507 model2 loss : 0.284372
[23:26:37.116] iteration 16948 : model1 loss : 0.099440 model2 loss : 0.093504
[23:26:37.456] iteration 16949 : model1 loss : 0.176644 model2 loss : 0.217283
[23:26:37.794] iteration 16950 : model1 loss : 0.261818 model2 loss : 0.278001
[23:26:38.457] iteration 16951 : model1 loss : 0.251974 model2 loss : 0.302560
[23:26:38.799] iteration 16952 : model1 loss : 0.082214 model2 loss : 0.143464
[23:26:39.135] iteration 16953 : model1 loss : 0.147257 model2 loss : 0.146243
[23:26:39.476] iteration 16954 : model1 loss : 0.290354 model2 loss : 0.225783
[23:26:39.821] iteration 16955 : model1 loss : 0.082777 model2 loss : 0.133966
[23:26:40.159] iteration 16956 : model1 loss : 0.142172 model2 loss : 0.183946
[23:26:40.499] iteration 16957 : model1 loss : 0.218509 model2 loss : 0.258563
[23:26:40.836] iteration 16958 : model1 loss : 0.122629 model2 loss : 0.121071
[23:26:41.173] iteration 16959 : model1 loss : 0.255808 model2 loss : 0.274825
[23:26:41.511] iteration 16960 : model1 loss : 0.253824 model2 loss : 0.273634
[23:26:41.848] iteration 16961 : model1 loss : 0.185162 model2 loss : 0.204952
[23:26:42.188] iteration 16962 : model1 loss : 0.250554 model2 loss : 0.265863
[23:26:42.527] iteration 16963 : model1 loss : 0.105524 model2 loss : 0.133983
[23:26:42.865] iteration 16964 : model1 loss : 0.077614 model2 loss : 0.097079
[23:26:43.206] iteration 16965 : model1 loss : 0.152354 model2 loss : 0.128216
[23:26:43.543] iteration 16966 : model1 loss : 0.178761 model2 loss : 0.211006
[23:26:43.880] iteration 16967 : model1 loss : 0.242298 model2 loss : 0.304639
[23:26:44.218] iteration 16968 : model1 loss : 0.092977 model2 loss : 0.164497
[23:26:44.555] iteration 16969 : model1 loss : 0.243988 model2 loss : 0.277119
[23:26:44.892] iteration 16970 : model1 loss : 0.167767 model2 loss : 0.236692
[23:26:45.231] iteration 16971 : model1 loss : 0.317158 model2 loss : 0.333615
[23:26:45.572] iteration 16972 : model1 loss : 0.160466 model2 loss : 0.204695
[23:26:45.910] iteration 16973 : model1 loss : 0.082057 model2 loss : 0.105347
[23:26:46.247] iteration 16974 : model1 loss : 0.250990 model2 loss : 0.260096
[23:26:46.584] iteration 16975 : model1 loss : 0.099201 model2 loss : 0.186850
[23:26:46.922] iteration 16976 : model1 loss : 0.193838 model2 loss : 0.205911
[23:26:47.259] iteration 16977 : model1 loss : 0.261071 model2 loss : 0.364433
[23:26:47.599] iteration 16978 : model1 loss : 0.269526 model2 loss : 0.293901
[23:26:47.938] iteration 16979 : model1 loss : 0.183058 model2 loss : 0.190453
[23:26:48.275] iteration 16980 : model1 loss : 0.081451 model2 loss : 0.100353
[23:26:48.613] iteration 16981 : model1 loss : 0.197161 model2 loss : 0.226965
[23:26:48.950] iteration 16982 : model1 loss : 0.212286 model2 loss : 0.349469
[23:26:49.287] iteration 16983 : model1 loss : 0.262306 model2 loss : 0.299032
[23:26:49.625] iteration 16984 : model1 loss : 0.256807 model2 loss : 0.310563
[23:26:49.962] iteration 16985 : model1 loss : 0.260663 model2 loss : 0.274493
[23:26:50.300] iteration 16986 : model1 loss : 0.268288 model2 loss : 0.313452
[23:26:50.637] iteration 16987 : model1 loss : 0.201422 model2 loss : 0.210282
[23:26:50.975] iteration 16988 : model1 loss : 0.126072 model2 loss : 0.161233
[23:26:51.314] iteration 16989 : model1 loss : 0.223624 model2 loss : 0.239051
[23:26:51.651] iteration 16990 : model1 loss : 0.192828 model2 loss : 0.163721
[23:26:51.989] iteration 16991 : model1 loss : 0.187747 model2 loss : 0.229859
[23:26:52.326] iteration 16992 : model1 loss : 0.145993 model2 loss : 0.228501
[23:26:52.662] iteration 16993 : model1 loss : 0.161047 model2 loss : 0.134936
[23:26:53.000] iteration 16994 : model1 loss : 0.168946 model2 loss : 0.208452
[23:26:53.339] iteration 16995 : model1 loss : 0.354267 model2 loss : 0.315095
[23:26:53.675] iteration 16996 : model1 loss : 0.225346 model2 loss : 0.271410
[23:26:54.008] iteration 16997 : model1 loss : 0.295227 model2 loss : 0.294765
[23:26:54.343] iteration 16998 : model1 loss : 0.094029 model2 loss : 0.202185
[23:26:54.685] iteration 16999 : model1 loss : 0.177856 model2 loss : 0.214742
[23:26:55.022] iteration 17000 : model1 loss : 0.230891 model2 loss : 0.262025
[23:26:55.699] iteration 17001 : model1 loss : 0.242454 model2 loss : 0.255173
[23:26:56.035] iteration 17002 : model1 loss : 0.225083 model2 loss : 0.272879
[23:26:56.380] iteration 17003 : model1 loss : 0.100851 model2 loss : 0.133599
[23:26:56.718] iteration 17004 : model1 loss : 0.174652 model2 loss : 0.244476
[23:26:57.054] iteration 17005 : model1 loss : 0.250276 model2 loss : 0.266904
[23:26:57.394] iteration 17006 : model1 loss : 0.232635 model2 loss : 0.239518
[23:26:57.728] iteration 17007 : model1 loss : 0.156752 model2 loss : 0.162401
[23:26:58.064] iteration 17008 : model1 loss : 0.194453 model2 loss : 0.184872
[23:26:58.404] iteration 17009 : model1 loss : 0.183016 model2 loss : 0.241636
[23:26:58.739] iteration 17010 : model1 loss : 0.182155 model2 loss : 0.237828
[23:26:59.083] iteration 17011 : model1 loss : 0.183890 model2 loss : 0.222814
[23:26:59.418] iteration 17012 : model1 loss : 0.168248 model2 loss : 0.199545
[23:26:59.754] iteration 17013 : model1 loss : 0.279173 model2 loss : 0.311056
[23:27:00.090] iteration 17014 : model1 loss : 0.126975 model2 loss : 0.190572
[23:27:00.429] iteration 17015 : model1 loss : 0.212826 model2 loss : 0.296636
[23:27:00.763] iteration 17016 : model1 loss : 0.202722 model2 loss : 0.236049
[23:27:01.104] iteration 17017 : model1 loss : 0.232165 model2 loss : 0.288393
[23:27:01.440] iteration 17018 : model1 loss : 0.260930 model2 loss : 0.273961
[23:27:01.779] iteration 17019 : model1 loss : 0.194158 model2 loss : 0.214169
[23:27:02.114] iteration 17020 : model1 loss : 0.202210 model2 loss : 0.246306
[23:27:02.450] iteration 17021 : model1 loss : 0.177322 model2 loss : 0.173607
[23:27:02.787] iteration 17022 : model1 loss : 0.119083 model2 loss : 0.186894
[23:27:03.127] iteration 17023 : model1 loss : 0.186560 model2 loss : 0.234462
[23:27:03.466] iteration 17024 : model1 loss : 0.321107 model2 loss : 0.324663
[23:27:03.803] iteration 17025 : model1 loss : 0.285956 model2 loss : 0.330163
[23:27:04.138] iteration 17026 : model1 loss : 0.173644 model2 loss : 0.278680
[23:27:04.472] iteration 17027 : model1 loss : 0.185421 model2 loss : 0.207492
[23:27:04.811] iteration 17028 : model1 loss : 0.275375 model2 loss : 0.345089
[23:27:05.150] iteration 17029 : model1 loss : 0.182999 model2 loss : 0.240127
[23:27:05.488] iteration 17030 : model1 loss : 0.286750 model2 loss : 0.337276
[23:27:05.824] iteration 17031 : model1 loss : 0.185399 model2 loss : 0.218277
[23:27:06.162] iteration 17032 : model1 loss : 0.098349 model2 loss : 0.142769
[23:27:06.499] iteration 17033 : model1 loss : 0.214895 model2 loss : 0.207726
[23:27:06.838] iteration 17034 : model1 loss : 0.247081 model2 loss : 0.260463
[23:27:07.175] iteration 17035 : model1 loss : 0.201704 model2 loss : 0.281097
[23:27:07.513] iteration 17036 : model1 loss : 0.182093 model2 loss : 0.211904
[23:27:07.850] iteration 17037 : model1 loss : 0.172409 model2 loss : 0.257320
[23:27:08.187] iteration 17038 : model1 loss : 0.217081 model2 loss : 0.229642
[23:27:08.526] iteration 17039 : model1 loss : 0.227010 model2 loss : 0.334747
[23:27:08.864] iteration 17040 : model1 loss : 0.223871 model2 loss : 0.229090
[23:27:09.201] iteration 17041 : model1 loss : 0.218372 model2 loss : 0.280392
[23:27:09.537] iteration 17042 : model1 loss : 0.322825 model2 loss : 0.392193
[23:27:09.872] iteration 17043 : model1 loss : 0.243497 model2 loss : 0.278408
[23:27:10.209] iteration 17044 : model1 loss : 0.262758 model2 loss : 0.290728
[23:27:10.546] iteration 17045 : model1 loss : 0.169206 model2 loss : 0.175608
[23:27:10.886] iteration 17046 : model1 loss : 0.104516 model2 loss : 0.140370
[23:27:11.223] iteration 17047 : model1 loss : 0.223645 model2 loss : 0.278360
[23:27:11.570] iteration 17048 : model1 loss : 0.170762 model2 loss : 0.185608
[23:27:11.907] iteration 17049 : model1 loss : 0.134654 model2 loss : 0.250275
[23:27:12.243] iteration 17050 : model1 loss : 0.251510 model2 loss : 0.355519
[23:27:12.903] iteration 17051 : model1 loss : 0.213206 model2 loss : 0.241238
[23:27:13.239] iteration 17052 : model1 loss : 0.329156 model2 loss : 0.346534
[23:27:13.575] iteration 17053 : model1 loss : 0.090521 model2 loss : 0.116743
[23:27:13.913] iteration 17054 : model1 loss : 0.120576 model2 loss : 0.179622
[23:27:14.249] iteration 17055 : model1 loss : 0.108156 model2 loss : 0.159216
[23:27:14.586] iteration 17056 : model1 loss : 0.216166 model2 loss : 0.292250
[23:27:14.924] iteration 17057 : model1 loss : 0.166752 model2 loss : 0.181033
[23:27:15.267] iteration 17058 : model1 loss : 0.171780 model2 loss : 0.224472
[23:27:15.604] iteration 17059 : model1 loss : 0.093304 model2 loss : 0.168239
[23:27:15.942] iteration 17060 : model1 loss : 0.296534 model2 loss : 0.320055
[23:27:16.279] iteration 17061 : model1 loss : 0.208960 model2 loss : 0.194084
[23:27:16.616] iteration 17062 : model1 loss : 0.136091 model2 loss : 0.173282
[23:27:16.954] iteration 17063 : model1 loss : 0.108693 model2 loss : 0.145599
[23:27:17.290] iteration 17064 : model1 loss : 0.133133 model2 loss : 0.114681
[23:27:17.627] iteration 17065 : model1 loss : 0.126806 model2 loss : 0.149194
[23:27:17.973] iteration 17066 : model1 loss : 0.166407 model2 loss : 0.250908
[23:27:18.314] iteration 17067 : model1 loss : 0.101353 model2 loss : 0.107926
[23:27:18.656] iteration 17068 : model1 loss : 0.272221 model2 loss : 0.261727
[23:27:18.997] iteration 17069 : model1 loss : 0.159683 model2 loss : 0.243797
[23:27:19.334] iteration 17070 : model1 loss : 0.185260 model2 loss : 0.179823
[23:27:19.672] iteration 17071 : model1 loss : 0.190109 model2 loss : 0.215451
[23:27:20.016] iteration 17072 : model1 loss : 0.183646 model2 loss : 0.252784
[23:27:20.354] iteration 17073 : model1 loss : 0.259919 model2 loss : 0.273476
[23:27:20.697] iteration 17074 : model1 loss : 0.270032 model2 loss : 0.290046
[23:27:21.038] iteration 17075 : model1 loss : 0.247278 model2 loss : 0.265108
[23:27:21.383] iteration 17076 : model1 loss : 0.204093 model2 loss : 0.251214
[23:27:21.720] iteration 17077 : model1 loss : 0.106947 model2 loss : 0.187005
[23:27:22.069] iteration 17078 : model1 loss : 0.183664 model2 loss : 0.247800
[23:27:22.406] iteration 17079 : model1 loss : 0.205693 model2 loss : 0.207970
[23:27:22.746] iteration 17080 : model1 loss : 0.202041 model2 loss : 0.221665
[23:27:23.103] iteration 17081 : model1 loss : 0.104479 model2 loss : 0.266854
[23:27:23.442] iteration 17082 : model1 loss : 0.179675 model2 loss : 0.194791
[23:27:23.780] iteration 17083 : model1 loss : 0.156712 model2 loss : 0.175651
[23:27:24.119] iteration 17084 : model1 loss : 0.243383 model2 loss : 0.226263
[23:27:24.456] iteration 17085 : model1 loss : 0.113891 model2 loss : 0.140799
[23:27:24.798] iteration 17086 : model1 loss : 0.079268 model2 loss : 0.129093
[23:27:25.136] iteration 17087 : model1 loss : 0.114462 model2 loss : 0.149566
[23:27:25.478] iteration 17088 : model1 loss : 0.250349 model2 loss : 0.261940
[23:27:25.815] iteration 17089 : model1 loss : 0.185941 model2 loss : 0.206407
[23:27:26.158] iteration 17090 : model1 loss : 0.101739 model2 loss : 0.154488
[23:27:26.495] iteration 17091 : model1 loss : 0.258550 model2 loss : 0.253925
[23:27:26.838] iteration 17092 : model1 loss : 0.129011 model2 loss : 0.167298
[23:27:27.174] iteration 17093 : model1 loss : 0.281747 model2 loss : 0.313349
[23:27:27.512] iteration 17094 : model1 loss : 0.263859 model2 loss : 0.352679
[23:27:27.852] iteration 17095 : model1 loss : 0.198497 model2 loss : 0.195072
[23:27:28.190] iteration 17096 : model1 loss : 0.196771 model2 loss : 0.291471
[23:27:28.534] iteration 17097 : model1 loss : 0.117863 model2 loss : 0.170986
[23:27:28.874] iteration 17098 : model1 loss : 0.134964 model2 loss : 0.186856
[23:27:29.215] iteration 17099 : model1 loss : 0.321573 model2 loss : 0.218972
[23:27:29.558] iteration 17100 : model1 loss : 0.194472 model2 loss : 0.260713
[23:27:30.190] iteration 17101 : model1 loss : 0.388642 model2 loss : 0.304937
[23:27:30.529] iteration 17102 : model1 loss : 0.294299 model2 loss : 0.279914
[23:27:30.873] iteration 17103 : model1 loss : 0.397751 model2 loss : 0.411820
[23:27:31.210] iteration 17104 : model1 loss : 0.181034 model2 loss : 0.221220
[23:27:31.546] iteration 17105 : model1 loss : 0.170729 model2 loss : 0.214607
[23:27:31.884] iteration 17106 : model1 loss : 0.168443 model2 loss : 0.186109
[23:27:32.222] iteration 17107 : model1 loss : 0.179039 model2 loss : 0.178299
[23:27:32.560] iteration 17108 : model1 loss : 0.261530 model2 loss : 0.338451
[23:27:32.897] iteration 17109 : model1 loss : 0.283882 model2 loss : 0.310609
[23:27:33.238] iteration 17110 : model1 loss : 0.233879 model2 loss : 0.237263
[23:27:33.574] iteration 17111 : model1 loss : 0.248998 model2 loss : 0.270798
[23:27:33.914] iteration 17112 : model1 loss : 0.258414 model2 loss : 0.283774
[23:27:34.256] iteration 17113 : model1 loss : 0.100356 model2 loss : 0.175085
[23:27:34.595] iteration 17114 : model1 loss : 0.232723 model2 loss : 0.260914
[23:27:34.933] iteration 17115 : model1 loss : 0.213886 model2 loss : 0.303757
[23:27:35.285] iteration 17116 : model1 loss : 0.276458 model2 loss : 0.315513
[23:27:35.622] iteration 17117 : model1 loss : 0.178176 model2 loss : 0.186444
[23:27:35.960] iteration 17118 : model1 loss : 0.142848 model2 loss : 0.222518
[23:27:36.300] iteration 17119 : model1 loss : 0.192307 model2 loss : 0.261040
[23:27:36.637] iteration 17120 : model1 loss : 0.290010 model2 loss : 0.329806
[23:27:36.977] iteration 17121 : model1 loss : 0.331634 model2 loss : 0.273866
[23:27:37.314] iteration 17122 : model1 loss : 0.173736 model2 loss : 0.252107
[23:27:37.653] iteration 17123 : model1 loss : 0.270804 model2 loss : 0.310255
[23:27:37.991] iteration 17124 : model1 loss : 0.099288 model2 loss : 0.170214
[23:27:38.332] iteration 17125 : model1 loss : 0.111653 model2 loss : 0.159360
[23:27:38.670] iteration 17126 : model1 loss : 0.178195 model2 loss : 0.229953
[23:27:39.010] iteration 17127 : model1 loss : 0.143289 model2 loss : 0.144265
[23:27:39.348] iteration 17128 : model1 loss : 0.213621 model2 loss : 0.280431
[23:27:39.691] iteration 17129 : model1 loss : 0.095698 model2 loss : 0.171207
[23:27:40.030] iteration 17130 : model1 loss : 0.102185 model2 loss : 0.119523
[23:27:40.372] iteration 17131 : model1 loss : 0.245364 model2 loss : 0.276739
[23:27:40.714] iteration 17132 : model1 loss : 0.261931 model2 loss : 0.261597
[23:27:41.053] iteration 17133 : model1 loss : 0.158878 model2 loss : 0.217527
[23:27:41.393] iteration 17134 : model1 loss : 0.176058 model2 loss : 0.198610
[23:27:41.729] iteration 17135 : model1 loss : 0.334054 model2 loss : 0.355086
[23:27:42.071] iteration 17136 : model1 loss : 0.282201 model2 loss : 0.267935
[23:27:42.408] iteration 17137 : model1 loss : 0.126487 model2 loss : 0.218007
[23:27:42.747] iteration 17138 : model1 loss : 0.264596 model2 loss : 0.301378
[23:27:43.084] iteration 17139 : model1 loss : 0.101011 model2 loss : 0.128175
[23:27:43.420] iteration 17140 : model1 loss : 0.263346 model2 loss : 0.284512
[23:27:43.759] iteration 17141 : model1 loss : 0.232239 model2 loss : 0.303692
[23:27:44.098] iteration 17142 : model1 loss : 0.229803 model2 loss : 0.346166
[23:27:44.437] iteration 17143 : model1 loss : 0.164568 model2 loss : 0.221677
[23:27:44.778] iteration 17144 : model1 loss : 0.147853 model2 loss : 0.171625
[23:27:45.116] iteration 17145 : model1 loss : 0.157076 model2 loss : 0.192066
[23:27:45.456] iteration 17146 : model1 loss : 0.173471 model2 loss : 0.283221
[23:27:45.794] iteration 17147 : model1 loss : 0.246809 model2 loss : 0.289590
[23:27:46.134] iteration 17148 : model1 loss : 0.256044 model2 loss : 0.283679
[23:27:46.477] iteration 17149 : model1 loss : 0.133267 model2 loss : 0.144100
[23:27:46.815] iteration 17150 : model1 loss : 0.209744 model2 loss : 0.243776
[23:27:47.507] iteration 17151 : model1 loss : 0.403019 model2 loss : 0.420613
[23:27:47.849] iteration 17152 : model1 loss : 0.243373 model2 loss : 0.290910
[23:27:48.191] iteration 17153 : model1 loss : 0.248143 model2 loss : 0.264579
[23:27:48.528] iteration 17154 : model1 loss : 0.352803 model2 loss : 0.364383
[23:27:48.868] iteration 17155 : model1 loss : 0.249004 model2 loss : 0.257613
[23:27:49.206] iteration 17156 : model1 loss : 0.103751 model2 loss : 0.195353
[23:27:49.547] iteration 17157 : model1 loss : 0.192309 model2 loss : 0.247424
[23:27:49.888] iteration 17158 : model1 loss : 0.239622 model2 loss : 0.223121
[23:27:50.229] iteration 17159 : model1 loss : 0.227185 model2 loss : 0.292511
[23:27:50.576] iteration 17160 : model1 loss : 0.154840 model2 loss : 0.160966
[23:27:50.912] iteration 17161 : model1 loss : 0.094440 model2 loss : 0.202451
[23:27:51.249] iteration 17162 : model1 loss : 0.080752 model2 loss : 0.125002
[23:27:51.590] iteration 17163 : model1 loss : 0.291130 model2 loss : 0.309354
[23:27:51.930] iteration 17164 : model1 loss : 0.157390 model2 loss : 0.165753
[23:27:52.268] iteration 17165 : model1 loss : 0.263006 model2 loss : 0.318667
[23:27:52.609] iteration 17166 : model1 loss : 0.081675 model2 loss : 0.160702
[23:27:52.947] iteration 17167 : model1 loss : 0.322806 model2 loss : 0.342538
[23:27:53.287] iteration 17168 : model1 loss : 0.199290 model2 loss : 0.239755
[23:27:53.624] iteration 17169 : model1 loss : 0.185063 model2 loss : 0.206501
[23:27:53.963] iteration 17170 : model1 loss : 0.137124 model2 loss : 0.186868
[23:27:54.299] iteration 17171 : model1 loss : 0.182440 model2 loss : 0.214293
[23:27:54.637] iteration 17172 : model1 loss : 0.271769 model2 loss : 0.288991
[23:27:54.976] iteration 17173 : model1 loss : 0.188498 model2 loss : 0.235293
[23:27:55.317] iteration 17174 : model1 loss : 0.210738 model2 loss : 0.204589
[23:27:55.658] iteration 17175 : model1 loss : 0.165236 model2 loss : 0.163775
[23:27:55.995] iteration 17176 : model1 loss : 0.277464 model2 loss : 0.290891
[23:27:56.337] iteration 17177 : model1 loss : 0.285999 model2 loss : 0.278998
[23:27:56.677] iteration 17178 : model1 loss : 0.144511 model2 loss : 0.243399
[23:27:57.018] iteration 17179 : model1 loss : 0.077304 model2 loss : 0.110481
[23:27:57.359] iteration 17180 : model1 loss : 0.215917 model2 loss : 0.313721
[23:27:57.697] iteration 17181 : model1 loss : 0.089433 model2 loss : 0.202510
[23:27:58.034] iteration 17182 : model1 loss : 0.116254 model2 loss : 0.159315
[23:27:58.373] iteration 17183 : model1 loss : 0.187524 model2 loss : 0.249988
[23:27:58.711] iteration 17184 : model1 loss : 0.216820 model2 loss : 0.134240
[23:27:59.052] iteration 17185 : model1 loss : 0.202714 model2 loss : 0.230328
[23:27:59.393] iteration 17186 : model1 loss : 0.313817 model2 loss : 0.375309
[23:27:59.731] iteration 17187 : model1 loss : 0.417131 model2 loss : 0.429998
[23:28:00.070] iteration 17188 : model1 loss : 0.282961 model2 loss : 0.359907
[23:28:00.410] iteration 17189 : model1 loss : 0.125220 model2 loss : 0.223031
[23:28:00.747] iteration 17190 : model1 loss : 0.247006 model2 loss : 0.227200
[23:28:01.084] iteration 17191 : model1 loss : 0.177767 model2 loss : 0.213779
[23:28:01.795] iteration 17192 : model1 loss : 0.139469 model2 loss : 0.201189
[23:28:02.133] iteration 17193 : model1 loss : 0.177006 model2 loss : 0.177080
[23:28:02.478] iteration 17194 : model1 loss : 0.170157 model2 loss : 0.186144
[23:28:02.819] iteration 17195 : model1 loss : 0.280386 model2 loss : 0.248747
[23:28:03.157] iteration 17196 : model1 loss : 0.286577 model2 loss : 0.321728
[23:28:03.494] iteration 17197 : model1 loss : 0.195930 model2 loss : 0.199545
[23:28:03.831] iteration 17198 : model1 loss : 0.142856 model2 loss : 0.141371
[23:28:04.167] iteration 17199 : model1 loss : 0.136787 model2 loss : 0.176431
[23:28:04.504] iteration 17200 : model1 loss : 0.234182 model2 loss : 0.235290
[23:28:05.172] iteration 17201 : model1 loss : 0.171621 model2 loss : 0.235411
[23:28:05.511] iteration 17202 : model1 loss : 0.173884 model2 loss : 0.224682
[23:28:05.848] iteration 17203 : model1 loss : 0.211626 model2 loss : 0.227440
[23:28:06.189] iteration 17204 : model1 loss : 0.258973 model2 loss : 0.284215
[23:28:06.529] iteration 17205 : model1 loss : 0.133005 model2 loss : 0.112312
[23:28:06.865] iteration 17206 : model1 loss : 0.266419 model2 loss : 0.319523
[23:28:07.203] iteration 17207 : model1 loss : 0.200705 model2 loss : 0.222235
[23:28:07.542] iteration 17208 : model1 loss : 0.320097 model2 loss : 0.326129
[23:28:07.880] iteration 17209 : model1 loss : 0.112764 model2 loss : 0.123619
[23:28:08.218] iteration 17210 : model1 loss : 0.319384 model2 loss : 0.339715
[23:28:08.559] iteration 17211 : model1 loss : 0.090199 model2 loss : 0.115006
[23:28:08.903] iteration 17212 : model1 loss : 0.151044 model2 loss : 0.178659
[23:28:09.241] iteration 17213 : model1 loss : 0.240017 model2 loss : 0.261735
[23:28:09.578] iteration 17214 : model1 loss : 0.190288 model2 loss : 0.219215
[23:28:09.916] iteration 17215 : model1 loss : 0.192636 model2 loss : 0.214238
[23:28:10.253] iteration 17216 : model1 loss : 0.211481 model2 loss : 0.262895
[23:28:10.592] iteration 17217 : model1 loss : 0.263365 model2 loss : 0.292950
[23:28:10.930] iteration 17218 : model1 loss : 0.291330 model2 loss : 0.323370
[23:28:11.267] iteration 17219 : model1 loss : 0.231553 model2 loss : 0.203400
[23:28:11.605] iteration 17220 : model1 loss : 0.239049 model2 loss : 0.285373
[23:28:11.946] iteration 17221 : model1 loss : 0.318048 model2 loss : 0.324071
[23:28:12.284] iteration 17222 : model1 loss : 0.104101 model2 loss : 0.166623
[23:28:12.621] iteration 17223 : model1 loss : 0.108635 model2 loss : 0.111898
[23:28:12.962] iteration 17224 : model1 loss : 0.255555 model2 loss : 0.324582
[23:28:13.300] iteration 17225 : model1 loss : 0.184027 model2 loss : 0.207406
[23:28:13.639] iteration 17226 : model1 loss : 0.167404 model2 loss : 0.190546
[23:28:13.976] iteration 17227 : model1 loss : 0.204667 model2 loss : 0.262468
[23:28:14.315] iteration 17228 : model1 loss : 0.161716 model2 loss : 0.190933
[23:28:14.662] iteration 17229 : model1 loss : 0.237227 model2 loss : 0.258117
[23:28:14.998] iteration 17230 : model1 loss : 0.233620 model2 loss : 0.272380
[23:28:15.339] iteration 17231 : model1 loss : 0.206466 model2 loss : 0.188748
[23:28:15.676] iteration 17232 : model1 loss : 0.255198 model2 loss : 0.253328
[23:28:16.018] iteration 17233 : model1 loss : 0.174443 model2 loss : 0.201778
[23:28:16.358] iteration 17234 : model1 loss : 0.112232 model2 loss : 0.222364
[23:28:16.696] iteration 17235 : model1 loss : 0.204518 model2 loss : 0.231846
[23:28:17.034] iteration 17236 : model1 loss : 0.092235 model2 loss : 0.181981
[23:28:17.371] iteration 17237 : model1 loss : 0.234207 model2 loss : 0.236588
[23:28:17.708] iteration 17238 : model1 loss : 0.143301 model2 loss : 0.132114
[23:28:18.046] iteration 17239 : model1 loss : 0.184544 model2 loss : 0.180566
[23:28:18.386] iteration 17240 : model1 loss : 0.172015 model2 loss : 0.232636
[23:28:18.726] iteration 17241 : model1 loss : 0.186162 model2 loss : 0.250193
[23:28:19.063] iteration 17242 : model1 loss : 0.273615 model2 loss : 0.250545
[23:28:19.400] iteration 17243 : model1 loss : 0.190602 model2 loss : 0.321784
[23:28:19.740] iteration 17244 : model1 loss : 0.204424 model2 loss : 0.200072
[23:28:20.077] iteration 17245 : model1 loss : 0.295156 model2 loss : 0.348380
[23:28:20.415] iteration 17246 : model1 loss : 0.185116 model2 loss : 0.206534
[23:28:20.752] iteration 17247 : model1 loss : 0.116332 model2 loss : 0.193976
[23:28:21.089] iteration 17248 : model1 loss : 0.242078 model2 loss : 0.260264
[23:28:21.427] iteration 17249 : model1 loss : 0.181453 model2 loss : 0.194298
[23:28:21.766] iteration 17250 : model1 loss : 0.117737 model2 loss : 0.194606
[23:28:22.409] iteration 17251 : model1 loss : 0.261710 model2 loss : 0.282015
[23:28:22.745] iteration 17252 : model1 loss : 0.114202 model2 loss : 0.161261
[23:28:23.083] iteration 17253 : model1 loss : 0.181541 model2 loss : 0.202272
[23:28:23.424] iteration 17254 : model1 loss : 0.172429 model2 loss : 0.180080
[23:28:23.764] iteration 17255 : model1 loss : 0.220424 model2 loss : 0.135385
[23:28:24.102] iteration 17256 : model1 loss : 0.269581 model2 loss : 0.317676
[23:28:24.443] iteration 17257 : model1 loss : 0.394068 model2 loss : 0.404462
[23:28:24.779] iteration 17258 : model1 loss : 0.158186 model2 loss : 0.217192
[23:28:25.119] iteration 17259 : model1 loss : 0.202096 model2 loss : 0.259117
[23:28:25.457] iteration 17260 : model1 loss : 0.277379 model2 loss : 0.289585
[23:28:25.798] iteration 17261 : model1 loss : 0.168103 model2 loss : 0.190264
[23:28:26.146] iteration 17262 : model1 loss : 0.203164 model2 loss : 0.216622
[23:28:26.483] iteration 17263 : model1 loss : 0.263753 model2 loss : 0.299683
[23:28:26.821] iteration 17264 : model1 loss : 0.231152 model2 loss : 0.248949
[23:28:27.158] iteration 17265 : model1 loss : 0.273479 model2 loss : 0.272162
[23:28:27.496] iteration 17266 : model1 loss : 0.245047 model2 loss : 0.263738
[23:28:27.840] iteration 17267 : model1 loss : 0.096560 model2 loss : 0.155848
[23:28:28.181] iteration 17268 : model1 loss : 0.147736 model2 loss : 0.191238
[23:28:28.520] iteration 17269 : model1 loss : 0.174640 model2 loss : 0.216051
[23:28:28.858] iteration 17270 : model1 loss : 0.311275 model2 loss : 0.273740
[23:28:29.195] iteration 17271 : model1 loss : 0.228615 model2 loss : 0.223451
[23:28:29.532] iteration 17272 : model1 loss : 0.201514 model2 loss : 0.216921
[23:28:29.869] iteration 17273 : model1 loss : 0.134277 model2 loss : 0.166992
[23:28:30.210] iteration 17274 : model1 loss : 0.191968 model2 loss : 0.230432
[23:28:30.547] iteration 17275 : model1 loss : 0.255083 model2 loss : 0.285591
[23:28:30.884] iteration 17276 : model1 loss : 0.321595 model2 loss : 0.333846
[23:28:31.230] iteration 17277 : model1 loss : 0.127124 model2 loss : 0.166444
[23:28:31.565] iteration 17278 : model1 loss : 0.268072 model2 loss : 0.313125
[23:28:31.909] iteration 17279 : model1 loss : 0.194894 model2 loss : 0.272265
[23:28:32.246] iteration 17280 : model1 loss : 0.164156 model2 loss : 0.180384
[23:28:32.586] iteration 17281 : model1 loss : 0.259908 model2 loss : 0.325957
[23:28:32.927] iteration 17282 : model1 loss : 0.105272 model2 loss : 0.190965
[23:28:33.269] iteration 17283 : model1 loss : 0.291573 model2 loss : 0.286312
[23:28:33.610] iteration 17284 : model1 loss : 0.177987 model2 loss : 0.194343
[23:28:33.951] iteration 17285 : model1 loss : 0.177601 model2 loss : 0.297841
[23:28:34.291] iteration 17286 : model1 loss : 0.210733 model2 loss : 0.228119
[23:28:34.630] iteration 17287 : model1 loss : 0.222827 model2 loss : 0.292565
[23:28:34.967] iteration 17288 : model1 loss : 0.196885 model2 loss : 0.201943
[23:28:35.305] iteration 17289 : model1 loss : 0.285555 model2 loss : 0.309713
[23:28:35.643] iteration 17290 : model1 loss : 0.150272 model2 loss : 0.147413
[23:28:35.983] iteration 17291 : model1 loss : 0.111881 model2 loss : 0.188562
[23:28:36.324] iteration 17292 : model1 loss : 0.116748 model2 loss : 0.114277
[23:28:36.662] iteration 17293 : model1 loss : 0.227679 model2 loss : 0.237946
[23:28:36.998] iteration 17294 : model1 loss : 0.181726 model2 loss : 0.177619
[23:28:37.336] iteration 17295 : model1 loss : 0.280928 model2 loss : 0.307121
[23:28:37.673] iteration 17296 : model1 loss : 0.261114 model2 loss : 0.275158
[23:28:38.012] iteration 17297 : model1 loss : 0.187450 model2 loss : 0.186003
[23:28:38.348] iteration 17298 : model1 loss : 0.177717 model2 loss : 0.228657
[23:28:38.688] iteration 17299 : model1 loss : 0.256673 model2 loss : 0.303084
[23:28:39.025] iteration 17300 : model1 loss : 0.162947 model2 loss : 0.174803
[23:28:39.638] iteration 17301 : model1 loss : 0.104719 model2 loss : 0.150710
[23:28:39.976] iteration 17302 : model1 loss : 0.318667 model2 loss : 0.332780
[23:28:40.316] iteration 17303 : model1 loss : 0.267930 model2 loss : 0.265452
[23:28:40.659] iteration 17304 : model1 loss : 0.102178 model2 loss : 0.115348
[23:28:40.995] iteration 17305 : model1 loss : 0.199062 model2 loss : 0.245034
[23:28:41.332] iteration 17306 : model1 loss : 0.190271 model2 loss : 0.297568
[23:28:41.671] iteration 17307 : model1 loss : 0.143658 model2 loss : 0.201534
[23:28:42.008] iteration 17308 : model1 loss : 0.203722 model2 loss : 0.262246
[23:28:42.345] iteration 17309 : model1 loss : 0.149339 model2 loss : 0.210449
[23:28:42.682] iteration 17310 : model1 loss : 0.085004 model2 loss : 0.107349
[23:28:43.022] iteration 17311 : model1 loss : 0.258607 model2 loss : 0.292729
[23:28:43.359] iteration 17312 : model1 loss : 0.302815 model2 loss : 0.313737
[23:28:43.696] iteration 17313 : model1 loss : 0.165450 model2 loss : 0.207371
[23:28:44.036] iteration 17314 : model1 loss : 0.204660 model2 loss : 0.223105
[23:28:44.375] iteration 17315 : model1 loss : 0.190773 model2 loss : 0.228300
[23:28:44.717] iteration 17316 : model1 loss : 0.248291 model2 loss : 0.252804
[23:28:45.054] iteration 17317 : model1 loss : 0.274482 model2 loss : 0.301856
[23:28:45.393] iteration 17318 : model1 loss : 0.091747 model2 loss : 0.128010
[23:28:45.730] iteration 17319 : model1 loss : 0.229888 model2 loss : 0.263461
[23:28:46.067] iteration 17320 : model1 loss : 0.215986 model2 loss : 0.237821
[23:28:46.404] iteration 17321 : model1 loss : 0.244506 model2 loss : 0.249989
[23:28:46.746] iteration 17322 : model1 loss : 0.188131 model2 loss : 0.313189
[23:28:47.087] iteration 17323 : model1 loss : 0.185413 model2 loss : 0.143483
[23:28:47.428] iteration 17324 : model1 loss : 0.142577 model2 loss : 0.121767
[23:28:47.765] iteration 17325 : model1 loss : 0.111679 model2 loss : 0.146698
[23:28:48.102] iteration 17326 : model1 loss : 0.169543 model2 loss : 0.222171
[23:28:48.441] iteration 17327 : model1 loss : 0.188289 model2 loss : 0.179944
[23:28:48.778] iteration 17328 : model1 loss : 0.228856 model2 loss : 0.256691
[23:28:49.116] iteration 17329 : model1 loss : 0.165838 model2 loss : 0.204726
[23:28:49.453] iteration 17330 : model1 loss : 0.125615 model2 loss : 0.172412
[23:28:49.796] iteration 17331 : model1 loss : 0.228446 model2 loss : 0.241721
[23:28:50.139] iteration 17332 : model1 loss : 0.226812 model2 loss : 0.233547
[23:28:50.476] iteration 17333 : model1 loss : 0.267506 model2 loss : 0.265357
[23:28:50.818] iteration 17334 : model1 loss : 0.271416 model2 loss : 0.322878
[23:28:51.155] iteration 17335 : model1 loss : 0.160299 model2 loss : 0.203418
[23:28:51.492] iteration 17336 : model1 loss : 0.185638 model2 loss : 0.245749
[23:28:51.833] iteration 17337 : model1 loss : 0.126242 model2 loss : 0.162592
[23:28:52.170] iteration 17338 : model1 loss : 0.259796 model2 loss : 0.317022
[23:28:52.507] iteration 17339 : model1 loss : 0.199879 model2 loss : 0.245909
[23:28:52.843] iteration 17340 : model1 loss : 0.081392 model2 loss : 0.093739
[23:28:53.180] iteration 17341 : model1 loss : 0.249245 model2 loss : 0.195800
[23:28:53.522] iteration 17342 : model1 loss : 0.249285 model2 loss : 0.355557
[23:28:53.859] iteration 17343 : model1 loss : 0.227655 model2 loss : 0.231458
[23:28:54.196] iteration 17344 : model1 loss : 0.250262 model2 loss : 0.297264
[23:28:54.535] iteration 17345 : model1 loss : 0.185341 model2 loss : 0.210792
[23:28:54.872] iteration 17346 : model1 loss : 0.202336 model2 loss : 0.256969
[23:28:55.211] iteration 17347 : model1 loss : 0.119259 model2 loss : 0.129689
[23:28:55.557] iteration 17348 : model1 loss : 0.162604 model2 loss : 0.160608
[23:28:55.894] iteration 17349 : model1 loss : 0.187446 model2 loss : 0.278537
[23:28:56.235] iteration 17350 : model1 loss : 0.221956 model2 loss : 0.260108
[23:28:56.855] iteration 17351 : model1 loss : 0.286419 model2 loss : 0.286973
[23:28:57.194] iteration 17352 : model1 loss : 0.087812 model2 loss : 0.124857
[23:28:57.531] iteration 17353 : model1 loss : 0.321333 model2 loss : 0.342407
[23:28:57.870] iteration 17354 : model1 loss : 0.329296 model2 loss : 0.332356
[23:28:58.208] iteration 17355 : model1 loss : 0.223486 model2 loss : 0.143869
[23:28:58.555] iteration 17356 : model1 loss : 0.320325 model2 loss : 0.248366
[23:28:58.894] iteration 17357 : model1 loss : 0.312715 model2 loss : 0.314519
[23:28:59.231] iteration 17358 : model1 loss : 0.286564 model2 loss : 0.276294
[23:28:59.575] iteration 17359 : model1 loss : 0.331354 model2 loss : 0.344098
[23:28:59.911] iteration 17360 : model1 loss : 0.273312 model2 loss : 0.296611
[23:29:00.247] iteration 17361 : model1 loss : 0.221054 model2 loss : 0.210625
[23:29:00.590] iteration 17362 : model1 loss : 0.255144 model2 loss : 0.281658
[23:29:00.939] iteration 17363 : model1 loss : 0.277357 model2 loss : 0.216110
[23:29:01.275] iteration 17364 : model1 loss : 0.202127 model2 loss : 0.193236
[23:29:01.620] iteration 17365 : model1 loss : 0.279116 model2 loss : 0.287869
[23:29:01.966] iteration 17366 : model1 loss : 0.192749 model2 loss : 0.196096
[23:29:02.303] iteration 17367 : model1 loss : 0.162806 model2 loss : 0.197435
[23:29:02.640] iteration 17368 : model1 loss : 0.239082 model2 loss : 0.342248
[23:29:02.977] iteration 17369 : model1 loss : 0.261511 model2 loss : 0.284455
[23:29:03.313] iteration 17370 : model1 loss : 0.336481 model2 loss : 0.285342
[23:29:03.650] iteration 17371 : model1 loss : 0.157617 model2 loss : 0.214503
[23:29:03.987] iteration 17372 : model1 loss : 0.193786 model2 loss : 0.229141
[23:29:04.324] iteration 17373 : model1 loss : 0.170591 model2 loss : 0.218986
[23:29:04.661] iteration 17374 : model1 loss : 0.267224 model2 loss : 0.325060
[23:29:04.998] iteration 17375 : model1 loss : 0.181466 model2 loss : 0.251084
[23:29:05.340] iteration 17376 : model1 loss : 0.182918 model2 loss : 0.225866
[23:29:05.677] iteration 17377 : model1 loss : 0.189747 model2 loss : 0.200335
[23:29:06.014] iteration 17378 : model1 loss : 0.221197 model2 loss : 0.242861
[23:29:06.355] iteration 17379 : model1 loss : 0.268262 model2 loss : 0.302221
[23:29:06.693] iteration 17380 : model1 loss : 0.178927 model2 loss : 0.216278
[23:29:07.031] iteration 17381 : model1 loss : 0.222540 model2 loss : 0.265608
[23:29:07.378] iteration 17382 : model1 loss : 0.162286 model2 loss : 0.175209
[23:29:07.714] iteration 17383 : model1 loss : 0.205809 model2 loss : 0.268996
[23:29:08.050] iteration 17384 : model1 loss : 0.208384 model2 loss : 0.240143
[23:29:08.387] iteration 17385 : model1 loss : 0.184410 model2 loss : 0.210394
[23:29:08.724] iteration 17386 : model1 loss : 0.198636 model2 loss : 0.216948
[23:29:09.070] iteration 17387 : model1 loss : 0.212078 model2 loss : 0.246192
[23:29:09.407] iteration 17388 : model1 loss : 0.163437 model2 loss : 0.216975
[23:29:09.745] iteration 17389 : model1 loss : 0.188116 model2 loss : 0.285954
[23:29:10.083] iteration 17390 : model1 loss : 0.254352 model2 loss : 0.249720
[23:29:10.419] iteration 17391 : model1 loss : 0.294265 model2 loss : 0.398061
[23:29:10.762] iteration 17392 : model1 loss : 0.252300 model2 loss : 0.297917
[23:29:11.099] iteration 17393 : model1 loss : 0.175565 model2 loss : 0.203122
[23:29:11.440] iteration 17394 : model1 loss : 0.159867 model2 loss : 0.173444
[23:29:11.778] iteration 17395 : model1 loss : 0.216561 model2 loss : 0.252519
[23:29:12.116] iteration 17396 : model1 loss : 0.193920 model2 loss : 0.263649
[23:29:12.454] iteration 17397 : model1 loss : 0.217620 model2 loss : 0.225001
[23:29:12.796] iteration 17398 : model1 loss : 0.102140 model2 loss : 0.155885
[23:29:13.138] iteration 17399 : model1 loss : 0.125278 model2 loss : 0.143946
[23:29:13.480] iteration 17400 : model1 loss : 0.181525 model2 loss : 0.228379
[23:29:14.076] iteration 17401 : model1 loss : 0.320377 model2 loss : 0.354103
[23:29:14.414] iteration 17402 : model1 loss : 0.178658 model2 loss : 0.201124
[23:29:14.758] iteration 17403 : model1 loss : 0.314521 model2 loss : 0.340802
[23:29:15.096] iteration 17404 : model1 loss : 0.443528 model2 loss : 0.434685
[23:29:15.433] iteration 17405 : model1 loss : 0.289235 model2 loss : 0.392917
[23:29:15.774] iteration 17406 : model1 loss : 0.265597 model2 loss : 0.264888
[23:29:16.112] iteration 17407 : model1 loss : 0.253304 model2 loss : 0.278077
[23:29:16.450] iteration 17408 : model1 loss : 0.171250 model2 loss : 0.212016
[23:29:16.789] iteration 17409 : model1 loss : 0.282046 model2 loss : 0.316677
[23:29:17.130] iteration 17410 : model1 loss : 0.245401 model2 loss : 0.249972
[23:29:17.469] iteration 17411 : model1 loss : 0.283834 model2 loss : 0.275718
[23:29:17.810] iteration 17412 : model1 loss : 0.163510 model2 loss : 0.197640
[23:29:18.148] iteration 17413 : model1 loss : 0.263161 model2 loss : 0.305264
[23:29:18.485] iteration 17414 : model1 loss : 0.215477 model2 loss : 0.252865
[23:29:18.830] iteration 17415 : model1 loss : 0.233625 model2 loss : 0.283748
[23:29:19.167] iteration 17416 : model1 loss : 0.153763 model2 loss : 0.259399
[23:29:19.505] iteration 17417 : model1 loss : 0.208242 model2 loss : 0.241230
[23:29:19.844] iteration 17418 : model1 loss : 0.120505 model2 loss : 0.163014
[23:29:20.186] iteration 17419 : model1 loss : 0.186141 model2 loss : 0.212936
[23:29:20.525] iteration 17420 : model1 loss : 0.227238 model2 loss : 0.185386
[23:29:20.866] iteration 17421 : model1 loss : 0.170963 model2 loss : 0.190223
[23:29:21.209] iteration 17422 : model1 loss : 0.280370 model2 loss : 0.281408
[23:29:21.545] iteration 17423 : model1 loss : 0.184241 model2 loss : 0.187590
[23:29:21.883] iteration 17424 : model1 loss : 0.198944 model2 loss : 0.202236
[23:29:22.220] iteration 17425 : model1 loss : 0.248476 model2 loss : 0.255651
[23:29:22.559] iteration 17426 : model1 loss : 0.196698 model2 loss : 0.220121
[23:29:22.894] iteration 17427 : model1 loss : 0.249411 model2 loss : 0.271424
[23:29:23.230] iteration 17428 : model1 loss : 0.277150 model2 loss : 0.267252
[23:29:23.566] iteration 17429 : model1 loss : 0.251280 model2 loss : 0.271665
[23:29:23.898] iteration 17430 : model1 loss : 0.207187 model2 loss : 0.196775
[23:29:24.234] iteration 17431 : model1 loss : 0.238129 model2 loss : 0.254114
[23:29:24.570] iteration 17432 : model1 loss : 0.180051 model2 loss : 0.171008
[23:29:24.906] iteration 17433 : model1 loss : 0.268849 model2 loss : 0.304560
[23:29:25.246] iteration 17434 : model1 loss : 0.142864 model2 loss : 0.142342
[23:29:25.582] iteration 17435 : model1 loss : 0.265626 model2 loss : 0.322061
[23:29:25.914] iteration 17436 : model1 loss : 0.226247 model2 loss : 0.277709
[23:29:26.251] iteration 17437 : model1 loss : 0.166292 model2 loss : 0.309378
[23:29:26.586] iteration 17438 : model1 loss : 0.274235 model2 loss : 0.264762
[23:29:26.917] iteration 17439 : model1 loss : 0.130754 model2 loss : 0.136905
[23:29:27.248] iteration 17440 : model1 loss : 0.173519 model2 loss : 0.229609
[23:29:28.422] iteration 17441 : model1 loss : 0.277940 model2 loss : 0.328832
[23:29:28.749] iteration 17442 : model1 loss : 0.135562 model2 loss : 0.247194
[23:29:29.083] iteration 17443 : model1 loss : 0.167775 model2 loss : 0.233683
[23:29:29.412] iteration 17444 : model1 loss : 0.189281 model2 loss : 0.188190
[23:29:29.738] iteration 17445 : model1 loss : 0.247299 model2 loss : 0.316491
[23:29:30.063] iteration 17446 : model1 loss : 0.185631 model2 loss : 0.207712
[23:29:30.391] iteration 17447 : model1 loss : 0.246145 model2 loss : 0.268476
[23:29:30.718] iteration 17448 : model1 loss : 0.180833 model2 loss : 0.245514
[23:29:31.041] iteration 17449 : model1 loss : 0.264447 model2 loss : 0.245494
[23:29:31.366] iteration 17450 : model1 loss : 0.263892 model2 loss : 0.327468
[23:29:31.948] iteration 17451 : model1 loss : 0.189656 model2 loss : 0.210910
[23:29:32.274] iteration 17452 : model1 loss : 0.284605 model2 loss : 0.299532
[23:29:32.600] iteration 17453 : model1 loss : 0.165376 model2 loss : 0.188803
[23:29:32.929] iteration 17454 : model1 loss : 0.281182 model2 loss : 0.306012
[23:29:33.259] iteration 17455 : model1 loss : 0.180183 model2 loss : 0.203998
[23:29:33.586] iteration 17456 : model1 loss : 0.091043 model2 loss : 0.131962
[23:29:33.913] iteration 17457 : model1 loss : 0.099506 model2 loss : 0.134690
[23:29:34.237] iteration 17458 : model1 loss : 0.173734 model2 loss : 0.214570
[23:29:34.563] iteration 17459 : model1 loss : 0.175460 model2 loss : 0.241184
[23:29:34.887] iteration 17460 : model1 loss : 0.345382 model2 loss : 0.303889
[23:29:35.217] iteration 17461 : model1 loss : 0.173984 model2 loss : 0.144842
[23:29:35.545] iteration 17462 : model1 loss : 0.127919 model2 loss : 0.099389
[23:29:35.887] iteration 17463 : model1 loss : 0.233932 model2 loss : 0.223989
[23:29:36.219] iteration 17464 : model1 loss : 0.082638 model2 loss : 0.217272
[23:29:36.556] iteration 17465 : model1 loss : 0.129897 model2 loss : 0.193956
[23:29:36.885] iteration 17466 : model1 loss : 0.268069 model2 loss : 0.294431
[23:29:37.210] iteration 17467 : model1 loss : 0.176326 model2 loss : 0.206962
[23:29:37.540] iteration 17468 : model1 loss : 0.153737 model2 loss : 0.162257
[23:29:37.865] iteration 17469 : model1 loss : 0.182238 model2 loss : 0.189147
[23:29:38.194] iteration 17470 : model1 loss : 0.163864 model2 loss : 0.211284
[23:29:38.521] iteration 17471 : model1 loss : 0.251481 model2 loss : 0.260253
[23:29:38.848] iteration 17472 : model1 loss : 0.191857 model2 loss : 0.211558
[23:29:39.176] iteration 17473 : model1 loss : 0.114493 model2 loss : 0.127424
[23:29:39.505] iteration 17474 : model1 loss : 0.108742 model2 loss : 0.159767
[23:29:39.830] iteration 17475 : model1 loss : 0.265162 model2 loss : 0.310327
[23:29:40.160] iteration 17476 : model1 loss : 0.383588 model2 loss : 0.409091
[23:29:40.490] iteration 17477 : model1 loss : 0.204338 model2 loss : 0.216185
[23:29:40.819] iteration 17478 : model1 loss : 0.207666 model2 loss : 0.216863
[23:29:41.150] iteration 17479 : model1 loss : 0.221581 model2 loss : 0.227488
[23:29:41.478] iteration 17480 : model1 loss : 0.150479 model2 loss : 0.150417
[23:29:41.802] iteration 17481 : model1 loss : 0.284051 model2 loss : 0.289173
[23:29:42.126] iteration 17482 : model1 loss : 0.169589 model2 loss : 0.202576
[23:29:42.451] iteration 17483 : model1 loss : 0.178897 model2 loss : 0.226170
[23:29:42.778] iteration 17484 : model1 loss : 0.239067 model2 loss : 0.276327
[23:29:43.103] iteration 17485 : model1 loss : 0.158946 model2 loss : 0.221370
[23:29:43.430] iteration 17486 : model1 loss : 0.281111 model2 loss : 0.306936
[23:29:43.755] iteration 17487 : model1 loss : 0.268531 model2 loss : 0.288422
[23:29:44.081] iteration 17488 : model1 loss : 0.169922 model2 loss : 0.215727
[23:29:44.408] iteration 17489 : model1 loss : 0.173169 model2 loss : 0.212538
[23:29:44.737] iteration 17490 : model1 loss : 0.240543 model2 loss : 0.298521
[23:29:45.063] iteration 17491 : model1 loss : 0.109016 model2 loss : 0.124578
[23:29:45.393] iteration 17492 : model1 loss : 0.329279 model2 loss : 0.322192
[23:29:45.725] iteration 17493 : model1 loss : 0.097799 model2 loss : 0.160582
[23:29:46.052] iteration 17494 : model1 loss : 0.192888 model2 loss : 0.243997
[23:29:46.383] iteration 17495 : model1 loss : 0.262779 model2 loss : 0.317457
[23:29:46.711] iteration 17496 : model1 loss : 0.168739 model2 loss : 0.210284
[23:29:47.036] iteration 17497 : model1 loss : 0.157009 model2 loss : 0.220164
[23:29:47.361] iteration 17498 : model1 loss : 0.173909 model2 loss : 0.201981
[23:29:47.684] iteration 17499 : model1 loss : 0.301122 model2 loss : 0.302506
[23:29:48.007] iteration 17500 : model1 loss : 0.121100 model2 loss : 0.205305
[23:29:48.593] iteration 17501 : model1 loss : 0.205169 model2 loss : 0.247475
[23:29:48.926] iteration 17502 : model1 loss : 0.295861 model2 loss : 0.320074
[23:29:49.260] iteration 17503 : model1 loss : 0.261884 model2 loss : 0.326037
[23:29:49.596] iteration 17504 : model1 loss : 0.133784 model2 loss : 0.192429
[23:29:49.933] iteration 17505 : model1 loss : 0.274808 model2 loss : 0.280384
[23:29:50.270] iteration 17506 : model1 loss : 0.271215 model2 loss : 0.287777
[23:29:50.608] iteration 17507 : model1 loss : 0.186696 model2 loss : 0.236968
[23:29:50.944] iteration 17508 : model1 loss : 0.276343 model2 loss : 0.266650
[23:29:51.285] iteration 17509 : model1 loss : 0.178679 model2 loss : 0.243049
[23:29:51.621] iteration 17510 : model1 loss : 0.273217 model2 loss : 0.296659
[23:29:51.960] iteration 17511 : model1 loss : 0.161110 model2 loss : 0.168969
[23:29:52.294] iteration 17512 : model1 loss : 0.192300 model2 loss : 0.246414
[23:29:52.634] iteration 17513 : model1 loss : 0.194421 model2 loss : 0.209813
[23:29:52.972] iteration 17514 : model1 loss : 0.183286 model2 loss : 0.270931
[23:29:53.306] iteration 17515 : model1 loss : 0.264330 model2 loss : 0.261135
[23:29:53.644] iteration 17516 : model1 loss : 0.151641 model2 loss : 0.170191
[23:29:53.981] iteration 17517 : model1 loss : 0.184490 model2 loss : 0.215614
[23:29:54.317] iteration 17518 : model1 loss : 0.295163 model2 loss : 0.294222
[23:29:54.655] iteration 17519 : model1 loss : 0.252153 model2 loss : 0.263549
[23:29:54.994] iteration 17520 : model1 loss : 0.267360 model2 loss : 0.256271
[23:29:55.331] iteration 17521 : model1 loss : 0.246404 model2 loss : 0.259015
[23:29:55.664] iteration 17522 : model1 loss : 0.188986 model2 loss : 0.195976
[23:29:55.997] iteration 17523 : model1 loss : 0.113640 model2 loss : 0.251112
[23:29:56.334] iteration 17524 : model1 loss : 0.187132 model2 loss : 0.229184
[23:29:56.671] iteration 17525 : model1 loss : 0.293851 model2 loss : 0.308100
[23:29:57.010] iteration 17526 : model1 loss : 0.172077 model2 loss : 0.259179
[23:29:57.347] iteration 17527 : model1 loss : 0.169405 model2 loss : 0.173126
[23:29:57.686] iteration 17528 : model1 loss : 0.110036 model2 loss : 0.147810
[23:29:58.023] iteration 17529 : model1 loss : 0.324371 model2 loss : 0.291052
[23:29:58.363] iteration 17530 : model1 loss : 0.198845 model2 loss : 0.245364
[23:29:58.697] iteration 17531 : model1 loss : 0.180987 model2 loss : 0.192119
[23:29:59.037] iteration 17532 : model1 loss : 0.294732 model2 loss : 0.314537
[23:29:59.375] iteration 17533 : model1 loss : 0.176665 model2 loss : 0.187400
[23:29:59.712] iteration 17534 : model1 loss : 0.279717 model2 loss : 0.320108
[23:30:00.047] iteration 17535 : model1 loss : 0.259021 model2 loss : 0.261918
[23:30:00.382] iteration 17536 : model1 loss : 0.166117 model2 loss : 0.186112
[23:30:00.719] iteration 17537 : model1 loss : 0.247030 model2 loss : 0.279447
[23:30:01.057] iteration 17538 : model1 loss : 0.212168 model2 loss : 0.259856
[23:30:01.399] iteration 17539 : model1 loss : 0.094434 model2 loss : 0.124412
[23:30:01.732] iteration 17540 : model1 loss : 0.377503 model2 loss : 0.298268
[23:30:02.069] iteration 17541 : model1 loss : 0.122593 model2 loss : 0.110171
[23:30:02.403] iteration 17542 : model1 loss : 0.241147 model2 loss : 0.270886
[23:30:02.736] iteration 17543 : model1 loss : 0.267583 model2 loss : 0.289957
[23:30:03.072] iteration 17544 : model1 loss : 0.113731 model2 loss : 0.127917
[23:30:03.406] iteration 17545 : model1 loss : 0.402290 model2 loss : 0.418673
[23:30:03.742] iteration 17546 : model1 loss : 0.169610 model2 loss : 0.194055
[23:30:04.082] iteration 17547 : model1 loss : 0.187232 model2 loss : 0.204867
[23:30:04.418] iteration 17548 : model1 loss : 0.270138 model2 loss : 0.270270
[23:30:04.756] iteration 17549 : model1 loss : 0.177371 model2 loss : 0.228206
[23:30:05.089] iteration 17550 : model1 loss : 0.188740 model2 loss : 0.221384
[23:30:05.749] iteration 17551 : model1 loss : 0.088298 model2 loss : 0.146290
[23:30:06.083] iteration 17552 : model1 loss : 0.205412 model2 loss : 0.211403
[23:30:06.420] iteration 17553 : model1 loss : 0.246898 model2 loss : 0.230585
[23:30:06.757] iteration 17554 : model1 loss : 0.261236 model2 loss : 0.317053
[23:30:07.090] iteration 17555 : model1 loss : 0.240837 model2 loss : 0.294937
[23:30:07.430] iteration 17556 : model1 loss : 0.104063 model2 loss : 0.107296
[23:30:07.767] iteration 17557 : model1 loss : 0.318029 model2 loss : 0.353098
[23:30:08.099] iteration 17558 : model1 loss : 0.274951 model2 loss : 0.293659
[23:30:08.438] iteration 17559 : model1 loss : 0.335777 model2 loss : 0.346545
[23:30:08.770] iteration 17560 : model1 loss : 0.098360 model2 loss : 0.128168
[23:30:09.102] iteration 17561 : model1 loss : 0.238667 model2 loss : 0.257013
[23:30:09.438] iteration 17562 : model1 loss : 0.280391 model2 loss : 0.313243
[23:30:09.770] iteration 17563 : model1 loss : 0.259620 model2 loss : 0.306660
[23:30:10.107] iteration 17564 : model1 loss : 0.247390 model2 loss : 0.267865
[23:30:10.442] iteration 17565 : model1 loss : 0.131837 model2 loss : 0.176489
[23:30:10.779] iteration 17566 : model1 loss : 0.123302 model2 loss : 0.204629
[23:30:11.114] iteration 17567 : model1 loss : 0.243422 model2 loss : 0.250587
[23:30:11.453] iteration 17568 : model1 loss : 0.223606 model2 loss : 0.295454
[23:30:11.786] iteration 17569 : model1 loss : 0.274208 model2 loss : 0.302177
[23:30:12.122] iteration 17570 : model1 loss : 0.108677 model2 loss : 0.243401
[23:30:12.458] iteration 17571 : model1 loss : 0.194140 model2 loss : 0.202367
[23:30:12.794] iteration 17572 : model1 loss : 0.184195 model2 loss : 0.204443
[23:30:13.130] iteration 17573 : model1 loss : 0.096595 model2 loss : 0.195286
[23:30:13.465] iteration 17574 : model1 loss : 0.188745 model2 loss : 0.270897
[23:30:13.799] iteration 17575 : model1 loss : 0.182972 model2 loss : 0.195202
[23:30:14.136] iteration 17576 : model1 loss : 0.169729 model2 loss : 0.223947
[23:30:14.468] iteration 17577 : model1 loss : 0.203183 model2 loss : 0.219112
[23:30:14.802] iteration 17578 : model1 loss : 0.105267 model2 loss : 0.167052
[23:30:15.142] iteration 17579 : model1 loss : 0.117503 model2 loss : 0.153465
[23:30:15.478] iteration 17580 : model1 loss : 0.258500 model2 loss : 0.285023
[23:30:15.813] iteration 17581 : model1 loss : 0.248511 model2 loss : 0.255895
[23:30:16.149] iteration 17582 : model1 loss : 0.091810 model2 loss : 0.138421
[23:30:16.484] iteration 17583 : model1 loss : 0.221382 model2 loss : 0.226247
[23:30:16.817] iteration 17584 : model1 loss : 0.152659 model2 loss : 0.169053
[23:30:17.152] iteration 17585 : model1 loss : 0.122611 model2 loss : 0.155841
[23:30:17.484] iteration 17586 : model1 loss : 0.211871 model2 loss : 0.167997
[23:30:17.821] iteration 17587 : model1 loss : 0.080870 model2 loss : 0.119910
[23:30:18.160] iteration 17588 : model1 loss : 0.181866 model2 loss : 0.168011
[23:30:18.492] iteration 17589 : model1 loss : 0.171730 model2 loss : 0.230037
[23:30:18.825] iteration 17590 : model1 loss : 0.156841 model2 loss : 0.183604
[23:30:19.167] iteration 17591 : model1 loss : 0.285856 model2 loss : 0.393921
[23:30:19.502] iteration 17592 : model1 loss : 0.196512 model2 loss : 0.223971
[23:30:19.835] iteration 17593 : model1 loss : 0.303625 model2 loss : 0.316963
[23:30:20.168] iteration 17594 : model1 loss : 0.092817 model2 loss : 0.122035
[23:30:20.502] iteration 17595 : model1 loss : 0.193696 model2 loss : 0.212548
[23:30:20.844] iteration 17596 : model1 loss : 0.225765 model2 loss : 0.290471
[23:30:21.181] iteration 17597 : model1 loss : 0.092281 model2 loss : 0.093916
[23:30:21.519] iteration 17598 : model1 loss : 0.198130 model2 loss : 0.149427
[23:30:21.857] iteration 17599 : model1 loss : 0.239800 model2 loss : 0.228806
[23:30:22.194] iteration 17600 : model1 loss : 0.176105 model2 loss : 0.195979
[23:30:22.837] iteration 17601 : model1 loss : 0.261202 model2 loss : 0.264467
[23:30:23.175] iteration 17602 : model1 loss : 0.118942 model2 loss : 0.128930
[23:30:23.511] iteration 17603 : model1 loss : 0.184356 model2 loss : 0.177942
[23:30:23.848] iteration 17604 : model1 loss : 0.254786 model2 loss : 0.250181
[23:30:24.181] iteration 17605 : model1 loss : 0.182571 model2 loss : 0.179245
[23:30:24.518] iteration 17606 : model1 loss : 0.261563 model2 loss : 0.279673
[23:30:24.854] iteration 17607 : model1 loss : 0.157780 model2 loss : 0.190380
[23:30:25.186] iteration 17608 : model1 loss : 0.175191 model2 loss : 0.201187
[23:30:25.523] iteration 17609 : model1 loss : 0.270089 model2 loss : 0.291360
[23:30:25.857] iteration 17610 : model1 loss : 0.150090 model2 loss : 0.238853
[23:30:26.192] iteration 17611 : model1 loss : 0.273926 model2 loss : 0.306341
[23:30:26.528] iteration 17612 : model1 loss : 0.250141 model2 loss : 0.282479
[23:30:26.860] iteration 17613 : model1 loss : 0.168389 model2 loss : 0.171831
[23:30:27.202] iteration 17614 : model1 loss : 0.219285 model2 loss : 0.222447
[23:30:27.539] iteration 17615 : model1 loss : 0.127710 model2 loss : 0.176651
[23:30:27.878] iteration 17616 : model1 loss : 0.247438 model2 loss : 0.262453
[23:30:28.215] iteration 17617 : model1 loss : 0.270739 model2 loss : 0.304774
[23:30:28.549] iteration 17618 : model1 loss : 0.316517 model2 loss : 0.325227
[23:30:28.886] iteration 17619 : model1 loss : 0.165083 model2 loss : 0.190697
[23:30:29.227] iteration 17620 : model1 loss : 0.214771 model2 loss : 0.297285
[23:30:29.565] iteration 17621 : model1 loss : 0.252430 model2 loss : 0.270835
[23:30:29.912] iteration 17622 : model1 loss : 0.258791 model2 loss : 0.280113
[23:30:30.249] iteration 17623 : model1 loss : 0.245999 model2 loss : 0.297163
[23:30:30.590] iteration 17624 : model1 loss : 0.215240 model2 loss : 0.224770
[23:30:30.924] iteration 17625 : model1 loss : 0.168107 model2 loss : 0.197561
[23:30:31.262] iteration 17626 : model1 loss : 0.171594 model2 loss : 0.213338
[23:30:31.596] iteration 17627 : model1 loss : 0.181643 model2 loss : 0.205398
[23:30:31.934] iteration 17628 : model1 loss : 0.260711 model2 loss : 0.275497
[23:30:32.274] iteration 17629 : model1 loss : 0.302739 model2 loss : 0.336865
[23:30:32.608] iteration 17630 : model1 loss : 0.103983 model2 loss : 0.205983
[23:30:32.949] iteration 17631 : model1 loss : 0.126915 model2 loss : 0.144931
[23:30:33.283] iteration 17632 : model1 loss : 0.091760 model2 loss : 0.166620
[23:30:33.619] iteration 17633 : model1 loss : 0.136960 model2 loss : 0.156660
[23:30:33.952] iteration 17634 : model1 loss : 0.391126 model2 loss : 0.402388
[23:30:34.290] iteration 17635 : model1 loss : 0.205811 model2 loss : 0.217339
[23:30:34.624] iteration 17636 : model1 loss : 0.410287 model2 loss : 0.431901
[23:30:34.957] iteration 17637 : model1 loss : 0.159919 model2 loss : 0.239525
[23:30:35.294] iteration 17638 : model1 loss : 0.285587 model2 loss : 0.295629
[23:30:35.627] iteration 17639 : model1 loss : 0.114254 model2 loss : 0.129686
[23:30:35.963] iteration 17640 : model1 loss : 0.168373 model2 loss : 0.174483
[23:30:36.300] iteration 17641 : model1 loss : 0.250596 model2 loss : 0.274635
[23:30:36.636] iteration 17642 : model1 loss : 0.188931 model2 loss : 0.234092
[23:30:36.970] iteration 17643 : model1 loss : 0.187813 model2 loss : 0.184234
[23:30:37.306] iteration 17644 : model1 loss : 0.153652 model2 loss : 0.209103
[23:30:37.643] iteration 17645 : model1 loss : 0.211539 model2 loss : 0.236628
[23:30:37.981] iteration 17646 : model1 loss : 0.141017 model2 loss : 0.199918
[23:30:38.318] iteration 17647 : model1 loss : 0.170979 model2 loss : 0.185666
[23:30:38.656] iteration 17648 : model1 loss : 0.084054 model2 loss : 0.151550
[23:30:38.993] iteration 17649 : model1 loss : 0.199438 model2 loss : 0.263732
[23:30:39.328] iteration 17650 : model1 loss : 0.156806 model2 loss : 0.175267
[23:30:39.974] iteration 17651 : model1 loss : 0.197230 model2 loss : 0.245165
[23:30:40.315] iteration 17652 : model1 loss : 0.181036 model2 loss : 0.215145
[23:30:40.650] iteration 17653 : model1 loss : 0.236383 model2 loss : 0.247424
[23:30:40.984] iteration 17654 : model1 loss : 0.188940 model2 loss : 0.282816
[23:30:41.318] iteration 17655 : model1 loss : 0.216507 model2 loss : 0.206234
[23:30:41.654] iteration 17656 : model1 loss : 0.153603 model2 loss : 0.166240
[23:30:41.993] iteration 17657 : model1 loss : 0.182831 model2 loss : 0.190631
[23:30:42.334] iteration 17658 : model1 loss : 0.192661 model2 loss : 0.233806
[23:30:42.673] iteration 17659 : model1 loss : 0.240713 model2 loss : 0.271165
[23:30:43.008] iteration 17660 : model1 loss : 0.070652 model2 loss : 0.188166
[23:30:43.343] iteration 17661 : model1 loss : 0.163449 model2 loss : 0.180923
[23:30:43.683] iteration 17662 : model1 loss : 0.152316 model2 loss : 0.192248
[23:30:44.018] iteration 17663 : model1 loss : 0.145983 model2 loss : 0.184885
[23:30:44.353] iteration 17664 : model1 loss : 0.224398 model2 loss : 0.279787
[23:30:44.685] iteration 17665 : model1 loss : 0.260751 model2 loss : 0.270272
[23:30:45.021] iteration 17666 : model1 loss : 0.265533 model2 loss : 0.331661
[23:30:45.361] iteration 17667 : model1 loss : 0.207583 model2 loss : 0.236572
[23:30:45.695] iteration 17668 : model1 loss : 0.245008 model2 loss : 0.270600
[23:30:46.032] iteration 17669 : model1 loss : 0.199236 model2 loss : 0.238795
[23:30:46.370] iteration 17670 : model1 loss : 0.342765 model2 loss : 0.412865
[23:30:46.706] iteration 17671 : model1 loss : 0.244892 model2 loss : 0.326447
[23:30:47.042] iteration 17672 : model1 loss : 0.276962 model2 loss : 0.371407
[23:30:47.379] iteration 17673 : model1 loss : 0.092550 model2 loss : 0.104602
[23:30:47.719] iteration 17674 : model1 loss : 0.279351 model2 loss : 0.289454
[23:30:48.060] iteration 17675 : model1 loss : 0.175918 model2 loss : 0.261562
[23:30:48.401] iteration 17676 : model1 loss : 0.275162 model2 loss : 0.349855
[23:30:48.737] iteration 17677 : model1 loss : 0.180066 model2 loss : 0.200702
[23:30:49.077] iteration 17678 : model1 loss : 0.123975 model2 loss : 0.123221
[23:30:49.412] iteration 17679 : model1 loss : 0.225282 model2 loss : 0.236673
[23:30:49.752] iteration 17680 : model1 loss : 0.273151 model2 loss : 0.293606
[23:30:50.087] iteration 17681 : model1 loss : 0.099987 model2 loss : 0.174485
[23:30:50.423] iteration 17682 : model1 loss : 0.093276 model2 loss : 0.177677
[23:30:50.760] iteration 17683 : model1 loss : 0.180526 model2 loss : 0.203081
[23:30:51.098] iteration 17684 : model1 loss : 0.144940 model2 loss : 0.146205
[23:30:51.436] iteration 17685 : model1 loss : 0.179942 model2 loss : 0.259469
[23:30:51.772] iteration 17686 : model1 loss : 0.203737 model2 loss : 0.210340
[23:30:52.112] iteration 17687 : model1 loss : 0.097729 model2 loss : 0.191863
[23:30:52.450] iteration 17688 : model1 loss : 0.213078 model2 loss : 0.216714
[23:30:52.784] iteration 17689 : model1 loss : 0.158245 model2 loss : 0.266555
[23:30:53.120] iteration 17690 : model1 loss : 0.192682 model2 loss : 0.227493
[23:30:53.454] iteration 17691 : model1 loss : 0.285076 model2 loss : 0.367195
[23:30:53.788] iteration 17692 : model1 loss : 0.240847 model2 loss : 0.243658
[23:30:54.135] iteration 17693 : model1 loss : 0.186558 model2 loss : 0.211667
[23:30:54.467] iteration 17694 : model1 loss : 0.269714 model2 loss : 0.340447
[23:30:54.803] iteration 17695 : model1 loss : 0.200931 model2 loss : 0.213797
[23:30:55.142] iteration 17696 : model1 loss : 0.275611 model2 loss : 0.292998
[23:30:55.478] iteration 17697 : model1 loss : 0.183915 model2 loss : 0.192804
[23:30:55.816] iteration 17698 : model1 loss : 0.249600 model2 loss : 0.273962
[23:30:56.148] iteration 17699 : model1 loss : 0.253705 model2 loss : 0.273597
[23:30:56.482] iteration 17700 : model1 loss : 0.178722 model2 loss : 0.187693
[23:30:57.111] iteration 17701 : model1 loss : 0.230557 model2 loss : 0.275035
[23:30:57.448] iteration 17702 : model1 loss : 0.115272 model2 loss : 0.104369
[23:30:57.782] iteration 17703 : model1 loss : 0.207813 model2 loss : 0.168193
[23:30:58.119] iteration 17704 : model1 loss : 0.198609 model2 loss : 0.267078
[23:30:58.454] iteration 17705 : model1 loss : 0.175268 model2 loss : 0.208116
[23:30:58.783] iteration 17706 : model1 loss : 0.143730 model2 loss : 0.171433
[23:30:59.109] iteration 17707 : model1 loss : 0.130076 model2 loss : 0.190259
[23:30:59.439] iteration 17708 : model1 loss : 0.206407 model2 loss : 0.221370
[23:30:59.767] iteration 17709 : model1 loss : 0.307795 model2 loss : 0.319276
[23:31:00.100] iteration 17710 : model1 loss : 0.291047 model2 loss : 0.309540
[23:31:00.429] iteration 17711 : model1 loss : 0.173199 model2 loss : 0.254312
[23:31:00.760] iteration 17712 : model1 loss : 0.140317 model2 loss : 0.183516
[23:31:01.087] iteration 17713 : model1 loss : 0.238669 model2 loss : 0.224936
[23:31:01.417] iteration 17714 : model1 loss : 0.235731 model2 loss : 0.240425
[23:31:01.750] iteration 17715 : model1 loss : 0.249424 model2 loss : 0.258398
[23:31:02.081] iteration 17716 : model1 loss : 0.156189 model2 loss : 0.126066
[23:31:02.407] iteration 17717 : model1 loss : 0.244317 model2 loss : 0.318560
[23:31:02.739] iteration 17718 : model1 loss : 0.085153 model2 loss : 0.114858
[23:31:03.065] iteration 17719 : model1 loss : 0.123766 model2 loss : 0.171549
[23:31:03.395] iteration 17720 : model1 loss : 0.238767 model2 loss : 0.262221
[23:31:03.721] iteration 17721 : model1 loss : 0.191345 model2 loss : 0.230606
[23:31:04.052] iteration 17722 : model1 loss : 0.209963 model2 loss : 0.205050
[23:31:04.377] iteration 17723 : model1 loss : 0.167156 model2 loss : 0.171952
[23:31:04.705] iteration 17724 : model1 loss : 0.226874 model2 loss : 0.242092
[23:31:05.032] iteration 17725 : model1 loss : 0.246541 model2 loss : 0.312448
[23:31:05.363] iteration 17726 : model1 loss : 0.226310 model2 loss : 0.275551
[23:31:05.692] iteration 17727 : model1 loss : 0.252269 model2 loss : 0.281826
[23:31:06.018] iteration 17728 : model1 loss : 0.161651 model2 loss : 0.238657
[23:31:06.342] iteration 17729 : model1 loss : 0.169365 model2 loss : 0.198165
[23:31:06.671] iteration 17730 : model1 loss : 0.184126 model2 loss : 0.213756
[23:31:06.994] iteration 17731 : model1 loss : 0.257741 model2 loss : 0.265507
[23:31:07.324] iteration 17732 : model1 loss : 0.188422 model2 loss : 0.186339
[23:31:07.661] iteration 17733 : model1 loss : 0.262275 model2 loss : 0.364898
[23:31:07.992] iteration 17734 : model1 loss : 0.083420 model2 loss : 0.169956
[23:31:08.325] iteration 17735 : model1 loss : 0.174286 model2 loss : 0.219947
[23:31:08.656] iteration 17736 : model1 loss : 0.168863 model2 loss : 0.214956
[23:31:08.983] iteration 17737 : model1 loss : 0.191459 model2 loss : 0.223371
[23:31:09.312] iteration 17738 : model1 loss : 0.187164 model2 loss : 0.220379
[23:31:09.640] iteration 17739 : model1 loss : 0.172513 model2 loss : 0.196445
[23:31:09.969] iteration 17740 : model1 loss : 0.192491 model2 loss : 0.241061
[23:31:10.296] iteration 17741 : model1 loss : 0.211011 model2 loss : 0.223789
[23:31:10.628] iteration 17742 : model1 loss : 0.207525 model2 loss : 0.193890
[23:31:10.955] iteration 17743 : model1 loss : 0.282660 model2 loss : 0.231724
[23:31:11.288] iteration 17744 : model1 loss : 0.206029 model2 loss : 0.231203
[23:31:11.619] iteration 17745 : model1 loss : 0.203709 model2 loss : 0.228735
[23:31:11.950] iteration 17746 : model1 loss : 0.265562 model2 loss : 0.277937
[23:31:12.276] iteration 17747 : model1 loss : 0.187609 model2 loss : 0.276087
[23:31:12.608] iteration 17748 : model1 loss : 0.252651 model2 loss : 0.323337
[23:31:12.938] iteration 17749 : model1 loss : 0.146004 model2 loss : 0.162913
[23:31:13.266] iteration 17750 : model1 loss : 0.220348 model2 loss : 0.135943
[23:31:13.823] iteration 17751 : model1 loss : 0.141710 model2 loss : 0.227548
[23:31:14.151] iteration 17752 : model1 loss : 0.088253 model2 loss : 0.092563
[23:31:14.478] iteration 17753 : model1 loss : 0.123260 model2 loss : 0.126753
[23:31:14.807] iteration 17754 : model1 loss : 0.119198 model2 loss : 0.171949
[23:31:15.134] iteration 17755 : model1 loss : 0.154040 model2 loss : 0.165244
[23:31:15.464] iteration 17756 : model1 loss : 0.231542 model2 loss : 0.268637
[23:31:15.795] iteration 17757 : model1 loss : 0.236358 model2 loss : 0.263688
[23:31:16.125] iteration 17758 : model1 loss : 0.202536 model2 loss : 0.193590
[23:31:16.449] iteration 17759 : model1 loss : 0.316758 model2 loss : 0.349888
[23:31:16.780] iteration 17760 : model1 loss : 0.260416 model2 loss : 0.276997
[23:31:17.110] iteration 17761 : model1 loss : 0.325338 model2 loss : 0.341119
[23:31:17.441] iteration 17762 : model1 loss : 0.192006 model2 loss : 0.226374
[23:31:17.767] iteration 17763 : model1 loss : 0.195571 model2 loss : 0.276805
[23:31:18.098] iteration 17764 : model1 loss : 0.271659 model2 loss : 0.247350
[23:31:18.424] iteration 17765 : model1 loss : 0.200229 model2 loss : 0.242027
[23:31:18.751] iteration 17766 : model1 loss : 0.138791 model2 loss : 0.208824
[23:31:19.075] iteration 17767 : model1 loss : 0.319451 model2 loss : 0.351284
[23:31:19.406] iteration 17768 : model1 loss : 0.163036 model2 loss : 0.207828
[23:31:19.736] iteration 17769 : model1 loss : 0.111038 model2 loss : 0.172110
[23:31:20.065] iteration 17770 : model1 loss : 0.284315 model2 loss : 0.316592
[23:31:20.389] iteration 17771 : model1 loss : 0.178068 model2 loss : 0.199725
[23:31:20.715] iteration 17772 : model1 loss : 0.275958 model2 loss : 0.364798
[23:31:21.042] iteration 17773 : model1 loss : 0.178869 model2 loss : 0.220161
[23:31:21.371] iteration 17774 : model1 loss : 0.193950 model2 loss : 0.276757
[23:31:21.694] iteration 17775 : model1 loss : 0.142490 model2 loss : 0.165680
[23:31:22.020] iteration 17776 : model1 loss : 0.258078 model2 loss : 0.314292
[23:31:22.350] iteration 17777 : model1 loss : 0.358085 model2 loss : 0.403504
[23:31:22.675] iteration 17778 : model1 loss : 0.199866 model2 loss : 0.325482
[23:31:22.999] iteration 17779 : model1 loss : 0.175455 model2 loss : 0.179650
[23:31:23.326] iteration 17780 : model1 loss : 0.148835 model2 loss : 0.177393
[23:31:23.655] iteration 17781 : model1 loss : 0.152353 model2 loss : 0.176017
[23:31:23.981] iteration 17782 : model1 loss : 0.185336 model2 loss : 0.215164
[23:31:24.308] iteration 17783 : model1 loss : 0.086608 model2 loss : 0.187572
[23:31:24.634] iteration 17784 : model1 loss : 0.165354 model2 loss : 0.214292
[23:31:24.961] iteration 17785 : model1 loss : 0.084456 model2 loss : 0.128435
[23:31:25.292] iteration 17786 : model1 loss : 0.163719 model2 loss : 0.202979
[23:31:25.624] iteration 17787 : model1 loss : 0.334000 model2 loss : 0.368336
[23:31:25.959] iteration 17788 : model1 loss : 0.266482 model2 loss : 0.299099
[23:31:26.292] iteration 17789 : model1 loss : 0.204930 model2 loss : 0.220618
[23:31:26.625] iteration 17790 : model1 loss : 0.173460 model2 loss : 0.196689
[23:31:26.958] iteration 17791 : model1 loss : 0.178578 model2 loss : 0.189955
[23:31:27.294] iteration 17792 : model1 loss : 0.116491 model2 loss : 0.139047
[23:31:27.631] iteration 17793 : model1 loss : 0.104111 model2 loss : 0.155592
[23:31:27.972] iteration 17794 : model1 loss : 0.137809 model2 loss : 0.264112
[23:31:28.311] iteration 17795 : model1 loss : 0.163689 model2 loss : 0.174363
[23:31:28.651] iteration 17796 : model1 loss : 0.088664 model2 loss : 0.131063
[23:31:28.985] iteration 17797 : model1 loss : 0.176443 model2 loss : 0.225674
[23:31:29.322] iteration 17798 : model1 loss : 0.240309 model2 loss : 0.338584
[23:31:29.659] iteration 17799 : model1 loss : 0.113054 model2 loss : 0.177049
[23:31:29.994] iteration 17800 : model1 loss : 0.113789 model2 loss : 0.167523
[23:31:30.671] iteration 17801 : model1 loss : 0.119066 model2 loss : 0.214097
[23:31:31.003] iteration 17802 : model1 loss : 0.185180 model2 loss : 0.246739
[23:31:31.335] iteration 17803 : model1 loss : 0.194547 model2 loss : 0.235413
[23:31:31.671] iteration 17804 : model1 loss : 0.172553 model2 loss : 0.223837
[23:31:32.007] iteration 17805 : model1 loss : 0.066898 model2 loss : 0.111125
[23:31:32.343] iteration 17806 : model1 loss : 0.178011 model2 loss : 0.230851
[23:31:32.680] iteration 17807 : model1 loss : 0.115886 model2 loss : 0.148485
[23:31:33.014] iteration 17808 : model1 loss : 0.312496 model2 loss : 0.378527
[23:31:33.347] iteration 17809 : model1 loss : 0.162562 model2 loss : 0.210492
[23:31:33.683] iteration 17810 : model1 loss : 0.197722 model2 loss : 0.284536
[23:31:34.020] iteration 17811 : model1 loss : 0.258856 model2 loss : 0.290767
[23:31:34.353] iteration 17812 : model1 loss : 0.215744 model2 loss : 0.226583
[23:31:34.686] iteration 17813 : model1 loss : 0.248915 model2 loss : 0.285227
[23:31:35.025] iteration 17814 : model1 loss : 0.207672 model2 loss : 0.258389
[23:31:35.359] iteration 17815 : model1 loss : 0.268103 model2 loss : 0.301466
[23:31:35.691] iteration 17816 : model1 loss : 0.253043 model2 loss : 0.270621
[23:31:36.023] iteration 17817 : model1 loss : 0.199323 model2 loss : 0.212659
[23:31:36.356] iteration 17818 : model1 loss : 0.199087 model2 loss : 0.254866
[23:31:36.692] iteration 17819 : model1 loss : 0.138405 model2 loss : 0.180859
[23:31:37.027] iteration 17820 : model1 loss : 0.102153 model2 loss : 0.184069
[23:31:37.359] iteration 17821 : model1 loss : 0.139175 model2 loss : 0.143796
[23:31:37.696] iteration 17822 : model1 loss : 0.165231 model2 loss : 0.188325
[23:31:38.029] iteration 17823 : model1 loss : 0.113387 model2 loss : 0.199212
[23:31:38.363] iteration 17824 : model1 loss : 0.181648 model2 loss : 0.217920
[23:31:38.704] iteration 17825 : model1 loss : 0.176573 model2 loss : 0.192705
[23:31:39.040] iteration 17826 : model1 loss : 0.202012 model2 loss : 0.305159
[23:31:39.373] iteration 17827 : model1 loss : 0.108432 model2 loss : 0.190330
[23:31:39.718] iteration 17828 : model1 loss : 0.203801 model2 loss : 0.180726
[23:31:40.058] iteration 17829 : model1 loss : 0.218320 model2 loss : 0.274451
[23:31:40.397] iteration 17830 : model1 loss : 0.170050 model2 loss : 0.209304
[23:31:40.740] iteration 17831 : model1 loss : 0.102024 model2 loss : 0.115822
[23:31:41.077] iteration 17832 : model1 loss : 0.267016 model2 loss : 0.285228
[23:31:41.415] iteration 17833 : model1 loss : 0.209893 model2 loss : 0.238559
[23:31:41.752] iteration 17834 : model1 loss : 0.167626 model2 loss : 0.188366
[23:31:42.091] iteration 17835 : model1 loss : 0.142829 model2 loss : 0.157515
[23:31:42.427] iteration 17836 : model1 loss : 0.181571 model2 loss : 0.195356
[23:31:42.761] iteration 17837 : model1 loss : 0.161907 model2 loss : 0.186230
[23:31:43.096] iteration 17838 : model1 loss : 0.339399 model2 loss : 0.435038
[23:31:43.429] iteration 17839 : model1 loss : 0.177290 model2 loss : 0.200469
[23:31:43.761] iteration 17840 : model1 loss : 0.245070 model2 loss : 0.347311
[23:31:44.099] iteration 17841 : model1 loss : 0.056074 model2 loss : 0.089254
[23:31:44.436] iteration 17842 : model1 loss : 0.265427 model2 loss : 0.267687
[23:31:44.777] iteration 17843 : model1 loss : 0.231778 model2 loss : 0.163019
[23:31:45.115] iteration 17844 : model1 loss : 0.252089 model2 loss : 0.257312
[23:31:45.454] iteration 17845 : model1 loss : 0.101845 model2 loss : 0.113876
[23:31:45.793] iteration 17846 : model1 loss : 0.194589 model2 loss : 0.220292
[23:31:46.126] iteration 17847 : model1 loss : 0.169678 model2 loss : 0.204002
[23:31:46.460] iteration 17848 : model1 loss : 0.187367 model2 loss : 0.216138
[23:31:46.797] iteration 17849 : model1 loss : 0.192458 model2 loss : 0.233701
[23:31:47.134] iteration 17850 : model1 loss : 0.217272 model2 loss : 0.281817
[23:31:47.778] iteration 17851 : model1 loss : 0.191131 model2 loss : 0.235185
[23:31:48.112] iteration 17852 : model1 loss : 0.097577 model2 loss : 0.121403
[23:31:48.445] iteration 17853 : model1 loss : 0.175335 model2 loss : 0.185216
[23:31:48.783] iteration 17854 : model1 loss : 0.136446 model2 loss : 0.207726
[23:31:49.116] iteration 17855 : model1 loss : 0.315627 model2 loss : 0.372269
[23:31:49.457] iteration 17856 : model1 loss : 0.163361 model2 loss : 0.108816
[23:31:49.794] iteration 17857 : model1 loss : 0.186204 model2 loss : 0.191852
[23:31:50.130] iteration 17858 : model1 loss : 0.234872 model2 loss : 0.286028
[23:31:50.470] iteration 17859 : model1 loss : 0.212704 model2 loss : 0.233114
[23:31:50.809] iteration 17860 : model1 loss : 0.169802 model2 loss : 0.191206
[23:31:51.141] iteration 17861 : model1 loss : 0.124811 model2 loss : 0.163267
[23:31:51.483] iteration 17862 : model1 loss : 0.164767 model2 loss : 0.208746
[23:31:51.821] iteration 17863 : model1 loss : 0.227433 model2 loss : 0.337124
[23:31:52.157] iteration 17864 : model1 loss : 0.170785 model2 loss : 0.250368
[23:31:52.496] iteration 17865 : model1 loss : 0.262962 model2 loss : 0.274526
[23:31:52.828] iteration 17866 : model1 loss : 0.172547 model2 loss : 0.200700
[23:31:53.167] iteration 17867 : model1 loss : 0.173049 model2 loss : 0.212382
[23:31:53.502] iteration 17868 : model1 loss : 0.115385 model2 loss : 0.083222
[23:31:53.837] iteration 17869 : model1 loss : 0.225840 model2 loss : 0.253675
[23:31:54.174] iteration 17870 : model1 loss : 0.234063 model2 loss : 0.298296
[23:31:54.510] iteration 17871 : model1 loss : 0.216068 model2 loss : 0.295686
[23:31:54.843] iteration 17872 : model1 loss : 0.202888 model2 loss : 0.294063
[23:31:55.180] iteration 17873 : model1 loss : 0.240881 model2 loss : 0.318432
[23:31:55.518] iteration 17874 : model1 loss : 0.187767 model2 loss : 0.236311
[23:31:55.855] iteration 17875 : model1 loss : 0.168804 model2 loss : 0.184144
[23:31:56.192] iteration 17876 : model1 loss : 0.336017 model2 loss : 0.355751
[23:31:56.528] iteration 17877 : model1 loss : 0.143166 model2 loss : 0.239779
[23:31:56.864] iteration 17878 : model1 loss : 0.280814 model2 loss : 0.280174
[23:31:57.198] iteration 17879 : model1 loss : 0.279571 model2 loss : 0.343736
[23:31:57.531] iteration 17880 : model1 loss : 0.262863 model2 loss : 0.305444
[23:31:57.863] iteration 17881 : model1 loss : 0.224956 model2 loss : 0.226942
[23:31:58.195] iteration 17882 : model1 loss : 0.171570 model2 loss : 0.230652
[23:31:58.529] iteration 17883 : model1 loss : 0.119507 model2 loss : 0.134447
[23:31:58.861] iteration 17884 : model1 loss : 0.262788 model2 loss : 0.276561
[23:31:59.198] iteration 17885 : model1 loss : 0.180342 model2 loss : 0.275360
[23:31:59.532] iteration 17886 : model1 loss : 0.150984 model2 loss : 0.238040
[23:31:59.868] iteration 17887 : model1 loss : 0.323270 model2 loss : 0.329576
[23:32:00.204] iteration 17888 : model1 loss : 0.184118 model2 loss : 0.220294
[23:32:00.541] iteration 17889 : model1 loss : 0.123197 model2 loss : 0.144522
[23:32:00.881] iteration 17890 : model1 loss : 0.157245 model2 loss : 0.253706
[23:32:01.214] iteration 17891 : model1 loss : 0.193640 model2 loss : 0.171097
[23:32:01.551] iteration 17892 : model1 loss : 0.137991 model2 loss : 0.140149
[23:32:01.895] iteration 17893 : model1 loss : 0.104517 model2 loss : 0.146286
[23:32:02.231] iteration 17894 : model1 loss : 0.331361 model2 loss : 0.351044
[23:32:02.567] iteration 17895 : model1 loss : 0.142988 model2 loss : 0.158129
[23:32:02.903] iteration 17896 : model1 loss : 0.209474 model2 loss : 0.250354
[23:32:03.241] iteration 17897 : model1 loss : 0.365749 model2 loss : 0.357572
[23:32:03.577] iteration 17898 : model1 loss : 0.256934 model2 loss : 0.269324
[23:32:03.913] iteration 17899 : model1 loss : 0.194990 model2 loss : 0.252962
[23:32:04.252] iteration 17900 : model1 loss : 0.095371 model2 loss : 0.145682
[23:32:04.938] iteration 17901 : model1 loss : 0.244268 model2 loss : 0.296043
[23:32:05.281] iteration 17902 : model1 loss : 0.258769 model2 loss : 0.259307
[23:32:05.618] iteration 17903 : model1 loss : 0.252008 model2 loss : 0.275591
[23:32:05.954] iteration 17904 : model1 loss : 0.211170 model2 loss : 0.257092
[23:32:06.286] iteration 17905 : model1 loss : 0.218025 model2 loss : 0.238382
[23:32:06.621] iteration 17906 : model1 loss : 0.207181 model2 loss : 0.225460
[23:32:06.958] iteration 17907 : model1 loss : 0.264525 model2 loss : 0.267584
[23:32:07.290] iteration 17908 : model1 loss : 0.176724 model2 loss : 0.195665
[23:32:07.622] iteration 17909 : model1 loss : 0.233628 model2 loss : 0.253201
[23:32:07.958] iteration 17910 : model1 loss : 0.246448 model2 loss : 0.277231
[23:32:08.293] iteration 17911 : model1 loss : 0.181104 model2 loss : 0.207426
[23:32:08.628] iteration 17912 : model1 loss : 0.122867 model2 loss : 0.134982
[23:32:08.963] iteration 17913 : model1 loss : 0.279867 model2 loss : 0.321284
[23:32:09.298] iteration 17914 : model1 loss : 0.211590 model2 loss : 0.280176
[23:32:09.634] iteration 17915 : model1 loss : 0.262722 model2 loss : 0.262595
[23:32:09.970] iteration 17916 : model1 loss : 0.275680 model2 loss : 0.321249
[23:32:10.308] iteration 17917 : model1 loss : 0.203424 model2 loss : 0.212641
[23:32:10.651] iteration 17918 : model1 loss : 0.202676 model2 loss : 0.124781
[23:32:10.986] iteration 17919 : model1 loss : 0.178264 model2 loss : 0.203728
[23:32:11.324] iteration 17920 : model1 loss : 0.230049 model2 loss : 0.285013
[23:32:11.660] iteration 17921 : model1 loss : 0.242705 model2 loss : 0.261973
[23:32:11.996] iteration 17922 : model1 loss : 0.255034 model2 loss : 0.273357
[23:32:12.334] iteration 17923 : model1 loss : 0.173938 model2 loss : 0.240167
[23:32:12.670] iteration 17924 : model1 loss : 0.224355 model2 loss : 0.278040
[23:32:13.010] iteration 17925 : model1 loss : 0.203278 model2 loss : 0.229776
[23:32:13.350] iteration 17926 : model1 loss : 0.271496 model2 loss : 0.312376
[23:32:13.686] iteration 17927 : model1 loss : 0.179976 model2 loss : 0.231458
[23:32:14.022] iteration 17928 : model1 loss : 0.199238 model2 loss : 0.214433
[23:32:14.358] iteration 17929 : model1 loss : 0.216355 model2 loss : 0.285992
[23:32:14.698] iteration 17930 : model1 loss : 0.211970 model2 loss : 0.189047
[23:32:15.034] iteration 17931 : model1 loss : 0.097473 model2 loss : 0.111220
[23:32:15.376] iteration 17932 : model1 loss : 0.209637 model2 loss : 0.199056
[23:32:15.714] iteration 17933 : model1 loss : 0.180730 model2 loss : 0.188627
[23:32:16.049] iteration 17934 : model1 loss : 0.092527 model2 loss : 0.148323
[23:32:16.386] iteration 17935 : model1 loss : 0.344196 model2 loss : 0.390887
[23:32:16.722] iteration 17936 : model1 loss : 0.402754 model2 loss : 0.434364
[23:32:17.056] iteration 17937 : model1 loss : 0.144186 model2 loss : 0.213022
[23:32:17.392] iteration 17938 : model1 loss : 0.229079 model2 loss : 0.226152
[23:32:17.729] iteration 17939 : model1 loss : 0.133642 model2 loss : 0.168747
[23:32:18.066] iteration 17940 : model1 loss : 0.257126 model2 loss : 0.292436
[23:32:18.402] iteration 17941 : model1 loss : 0.158189 model2 loss : 0.161065
[23:32:18.741] iteration 17942 : model1 loss : 0.174203 model2 loss : 0.133605
[23:32:19.078] iteration 17943 : model1 loss : 0.274548 model2 loss : 0.302560
[23:32:19.414] iteration 17944 : model1 loss : 0.164696 model2 loss : 0.212008
[23:32:19.753] iteration 17945 : model1 loss : 0.194647 model2 loss : 0.224288
[23:32:20.091] iteration 17946 : model1 loss : 0.170947 model2 loss : 0.198052
[23:32:20.430] iteration 17947 : model1 loss : 0.401917 model2 loss : 0.409349
[23:32:20.770] iteration 17948 : model1 loss : 0.176293 model2 loss : 0.203307
[23:32:21.105] iteration 17949 : model1 loss : 0.176782 model2 loss : 0.227487
[23:32:21.444] iteration 17950 : model1 loss : 0.162957 model2 loss : 0.174574
[23:32:22.091] iteration 17951 : model1 loss : 0.194320 model2 loss : 0.191089
[23:32:22.424] iteration 17952 : model1 loss : 0.205521 model2 loss : 0.177306
[23:32:22.763] iteration 17953 : model1 loss : 0.200068 model2 loss : 0.256207
[23:32:23.100] iteration 17954 : model1 loss : 0.169908 model2 loss : 0.159433
[23:32:23.438] iteration 17955 : model1 loss : 0.142659 model2 loss : 0.171114
[23:32:23.774] iteration 17956 : model1 loss : 0.128118 model2 loss : 0.150785
[23:32:24.112] iteration 17957 : model1 loss : 0.191329 model2 loss : 0.246138
[23:32:24.448] iteration 17958 : model1 loss : 0.288904 model2 loss : 0.240400
[23:32:24.783] iteration 17959 : model1 loss : 0.235857 model2 loss : 0.191913
[23:32:25.115] iteration 17960 : model1 loss : 0.231098 model2 loss : 0.232988
[23:32:25.454] iteration 17961 : model1 loss : 0.218625 model2 loss : 0.229341
[23:32:25.788] iteration 17962 : model1 loss : 0.282327 model2 loss : 0.266772
[23:32:26.124] iteration 17963 : model1 loss : 0.260005 model2 loss : 0.309057
[23:32:26.483] iteration 17964 : model1 loss : 0.176386 model2 loss : 0.214801
[23:32:26.817] iteration 17965 : model1 loss : 0.294894 model2 loss : 0.349516
[23:32:27.151] iteration 17966 : model1 loss : 0.266287 model2 loss : 0.291660
[23:32:27.487] iteration 17967 : model1 loss : 0.172048 model2 loss : 0.199915
[23:32:27.822] iteration 17968 : model1 loss : 0.182361 model2 loss : 0.190700
[23:32:28.156] iteration 17969 : model1 loss : 0.212393 model2 loss : 0.225785
[23:32:28.491] iteration 17970 : model1 loss : 0.184327 model2 loss : 0.230210
[23:32:28.826] iteration 17971 : model1 loss : 0.118432 model2 loss : 0.194344
[23:32:29.161] iteration 17972 : model1 loss : 0.212366 model2 loss : 0.274080
[23:32:29.496] iteration 17973 : model1 loss : 0.185662 model2 loss : 0.266184
[23:32:29.830] iteration 17974 : model1 loss : 0.116376 model2 loss : 0.176714
[23:32:30.165] iteration 17975 : model1 loss : 0.135782 model2 loss : 0.116919
[23:32:30.497] iteration 17976 : model1 loss : 0.171577 model2 loss : 0.256691
[23:32:30.831] iteration 17977 : model1 loss : 0.258473 model2 loss : 0.288483
[23:32:31.166] iteration 17978 : model1 loss : 0.106476 model2 loss : 0.195374
[23:32:31.499] iteration 17979 : model1 loss : 0.245342 model2 loss : 0.261237
[23:32:31.830] iteration 17980 : model1 loss : 0.192949 model2 loss : 0.223247
[23:32:32.164] iteration 17981 : model1 loss : 0.168649 model2 loss : 0.190647
[23:32:32.495] iteration 17982 : model1 loss : 0.213337 model2 loss : 0.246328
[23:32:32.827] iteration 17983 : model1 loss : 0.248964 model2 loss : 0.316344
[23:32:33.160] iteration 17984 : model1 loss : 0.248435 model2 loss : 0.308256
[23:32:33.491] iteration 17985 : model1 loss : 0.171314 model2 loss : 0.198088
[23:32:34.513] iteration 17986 : model1 loss : 0.232959 model2 loss : 0.260452
[23:32:34.848] iteration 17987 : model1 loss : 0.173063 model2 loss : 0.245062
[23:32:35.182] iteration 17988 : model1 loss : 0.202436 model2 loss : 0.248527
[23:32:35.517] iteration 17989 : model1 loss : 0.171551 model2 loss : 0.206102
[23:32:35.848] iteration 17990 : model1 loss : 0.244588 model2 loss : 0.270106
[23:32:36.182] iteration 17991 : model1 loss : 0.172769 model2 loss : 0.298873
[23:32:36.517] iteration 17992 : model1 loss : 0.176695 model2 loss : 0.221371
[23:32:36.848] iteration 17993 : model1 loss : 0.083997 model2 loss : 0.164459
[23:32:37.182] iteration 17994 : model1 loss : 0.185202 model2 loss : 0.242251
[23:32:37.513] iteration 17995 : model1 loss : 0.113786 model2 loss : 0.146798
[23:32:37.844] iteration 17996 : model1 loss : 0.170767 model2 loss : 0.188248
[23:32:38.178] iteration 17997 : model1 loss : 0.154699 model2 loss : 0.167206
[23:32:38.509] iteration 17998 : model1 loss : 0.161909 model2 loss : 0.226625
[23:32:38.840] iteration 17999 : model1 loss : 0.184759 model2 loss : 0.230471
[23:32:39.174] iteration 18000 : model1 loss : 0.219960 model2 loss : 0.273115
[23:33:42.767] iteration 18000 : model1_mean_dice : 0.763639 model1_mean_hd95 : 11.972011
[23:34:36.940] iteration 18000 : model2_mean_dice : 0.594182 model2_mean_hd95 : 14.218658
[23:34:37.203] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_18000.pth
[23:34:37.244] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_18000.pth
[23:34:37.585] iteration 18001 : model1 loss : 0.198510 model2 loss : 0.235240
[23:34:37.907] iteration 18002 : model1 loss : 0.181204 model2 loss : 0.223561
[23:34:38.238] iteration 18003 : model1 loss : 0.188716 model2 loss : 0.220584
[23:34:38.572] iteration 18004 : model1 loss : 0.274601 model2 loss : 0.290588
[23:34:38.903] iteration 18005 : model1 loss : 0.175486 model2 loss : 0.201934
[23:34:39.235] iteration 18006 : model1 loss : 0.135687 model2 loss : 0.168311
[23:34:39.568] iteration 18007 : model1 loss : 0.253603 model2 loss : 0.355968
[23:34:39.903] iteration 18008 : model1 loss : 0.202873 model2 loss : 0.209647
[23:34:40.234] iteration 18009 : model1 loss : 0.210576 model2 loss : 0.214362
[23:34:40.569] iteration 18010 : model1 loss : 0.259817 model2 loss : 0.323518
[23:34:40.909] iteration 18011 : model1 loss : 0.154739 model2 loss : 0.191208
[23:34:41.240] iteration 18012 : model1 loss : 0.251321 model2 loss : 0.300085
[23:34:41.574] iteration 18013 : model1 loss : 0.178994 model2 loss : 0.243419
[23:34:41.904] iteration 18014 : model1 loss : 0.071708 model2 loss : 0.118834
[23:34:42.243] iteration 18015 : model1 loss : 0.189785 model2 loss : 0.220234
[23:34:42.580] iteration 18016 : model1 loss : 0.260414 model2 loss : 0.285901
[23:34:42.920] iteration 18017 : model1 loss : 0.097160 model2 loss : 0.137554
[23:34:43.254] iteration 18018 : model1 loss : 0.293933 model2 loss : 0.375050
[23:34:43.591] iteration 18019 : model1 loss : 0.122385 model2 loss : 0.260597
[23:34:43.923] iteration 18020 : model1 loss : 0.173631 model2 loss : 0.239511
[23:34:44.261] iteration 18021 : model1 loss : 0.325087 model2 loss : 0.372338
[23:34:44.596] iteration 18022 : model1 loss : 0.260043 model2 loss : 0.298918
[23:34:44.931] iteration 18023 : model1 loss : 0.270684 model2 loss : 0.291951
[23:34:45.271] iteration 18024 : model1 loss : 0.270721 model2 loss : 0.259476
[23:34:45.607] iteration 18025 : model1 loss : 0.130413 model2 loss : 0.158866
[23:34:45.941] iteration 18026 : model1 loss : 0.199479 model2 loss : 0.205004
[23:34:46.276] iteration 18027 : model1 loss : 0.171136 model2 loss : 0.158532
[23:34:46.608] iteration 18028 : model1 loss : 0.247475 model2 loss : 0.299858
[23:34:46.942] iteration 18029 : model1 loss : 0.199141 model2 loss : 0.271552
[23:34:47.274] iteration 18030 : model1 loss : 0.174780 model2 loss : 0.188903
[23:34:47.605] iteration 18031 : model1 loss : 0.217628 model2 loss : 0.180404
[23:34:47.943] iteration 18032 : model1 loss : 0.167099 model2 loss : 0.222057
[23:34:48.277] iteration 18033 : model1 loss : 0.199875 model2 loss : 0.205435
[23:34:48.611] iteration 18034 : model1 loss : 0.264542 model2 loss : 0.275337
[23:34:48.947] iteration 18035 : model1 loss : 0.163941 model2 loss : 0.188064
[23:34:49.283] iteration 18036 : model1 loss : 0.200033 model2 loss : 0.253891
[23:34:49.617] iteration 18037 : model1 loss : 0.201681 model2 loss : 0.162928
[23:34:49.953] iteration 18038 : model1 loss : 0.244971 model2 loss : 0.265982
[23:34:50.292] iteration 18039 : model1 loss : 0.298043 model2 loss : 0.377156
[23:34:50.624] iteration 18040 : model1 loss : 0.287096 model2 loss : 0.316894
[23:34:50.958] iteration 18041 : model1 loss : 0.164631 model2 loss : 0.307582
[23:34:51.294] iteration 18042 : model1 loss : 0.193599 model2 loss : 0.190809
[23:34:51.632] iteration 18043 : model1 loss : 0.188909 model2 loss : 0.215088
[23:34:51.968] iteration 18044 : model1 loss : 0.163880 model2 loss : 0.171924
[23:34:52.300] iteration 18045 : model1 loss : 0.114998 model2 loss : 0.176292
[23:34:52.635] iteration 18046 : model1 loss : 0.134061 model2 loss : 0.169945
[23:34:52.970] iteration 18047 : model1 loss : 0.099187 model2 loss : 0.131817
[23:34:53.304] iteration 18048 : model1 loss : 0.178313 model2 loss : 0.179306
[23:34:53.638] iteration 18049 : model1 loss : 0.186044 model2 loss : 0.195897
[23:34:53.970] iteration 18050 : model1 loss : 0.155032 model2 loss : 0.156336
[23:34:54.580] iteration 18051 : model1 loss : 0.176204 model2 loss : 0.197534
[23:34:54.914] iteration 18052 : model1 loss : 0.216127 model2 loss : 0.271971
[23:34:55.249] iteration 18053 : model1 loss : 0.125867 model2 loss : 0.144621
[23:34:55.583] iteration 18054 : model1 loss : 0.251930 model2 loss : 0.270011
[23:34:55.924] iteration 18055 : model1 loss : 0.197225 model2 loss : 0.245079
[23:34:56.260] iteration 18056 : model1 loss : 0.279764 model2 loss : 0.285837
[23:34:56.595] iteration 18057 : model1 loss : 0.196009 model2 loss : 0.283086
[23:34:56.929] iteration 18058 : model1 loss : 0.234762 model2 loss : 0.252603
[23:34:57.261] iteration 18059 : model1 loss : 0.221043 model2 loss : 0.226086
[23:34:57.601] iteration 18060 : model1 loss : 0.265631 model2 loss : 0.265949
[23:34:57.937] iteration 18061 : model1 loss : 0.169943 model2 loss : 0.242899
[23:34:58.278] iteration 18062 : model1 loss : 0.401585 model2 loss : 0.413095
[23:34:58.610] iteration 18063 : model1 loss : 0.193661 model2 loss : 0.297149
[23:34:58.945] iteration 18064 : model1 loss : 0.100726 model2 loss : 0.171379
[23:34:59.278] iteration 18065 : model1 loss : 0.130344 model2 loss : 0.140876
[23:34:59.612] iteration 18066 : model1 loss : 0.216117 model2 loss : 0.304407
[23:34:59.952] iteration 18067 : model1 loss : 0.179157 model2 loss : 0.196827
[23:35:00.286] iteration 18068 : model1 loss : 0.178265 model2 loss : 0.265341
[23:35:00.618] iteration 18069 : model1 loss : 0.188779 model2 loss : 0.264358
[23:35:00.951] iteration 18070 : model1 loss : 0.111160 model2 loss : 0.117480
[23:35:01.289] iteration 18071 : model1 loss : 0.092906 model2 loss : 0.111474
[23:35:01.622] iteration 18072 : model1 loss : 0.104695 model2 loss : 0.151824
[23:35:01.956] iteration 18073 : model1 loss : 0.166692 model2 loss : 0.191303
[23:35:02.288] iteration 18074 : model1 loss : 0.228018 model2 loss : 0.249234
[23:35:02.624] iteration 18075 : model1 loss : 0.222899 model2 loss : 0.208670
[23:35:02.959] iteration 18076 : model1 loss : 0.229778 model2 loss : 0.291654
[23:35:03.292] iteration 18077 : model1 loss : 0.184922 model2 loss : 0.254911
[23:35:03.627] iteration 18078 : model1 loss : 0.274917 model2 loss : 0.337836
[23:35:03.960] iteration 18079 : model1 loss : 0.253550 model2 loss : 0.302119
[23:35:04.291] iteration 18080 : model1 loss : 0.198669 model2 loss : 0.327371
[23:35:04.624] iteration 18081 : model1 loss : 0.076659 model2 loss : 0.168796
[23:35:04.964] iteration 18082 : model1 loss : 0.234886 model2 loss : 0.217485
[23:35:05.301] iteration 18083 : model1 loss : 0.165125 model2 loss : 0.177315
[23:35:05.637] iteration 18084 : model1 loss : 0.157410 model2 loss : 0.170242
[23:35:05.977] iteration 18085 : model1 loss : 0.175521 model2 loss : 0.232055
[23:35:06.311] iteration 18086 : model1 loss : 0.239687 model2 loss : 0.286104
[23:35:06.647] iteration 18087 : model1 loss : 0.200023 model2 loss : 0.223489
[23:35:06.983] iteration 18088 : model1 loss : 0.165988 model2 loss : 0.233574
[23:35:07.318] iteration 18089 : model1 loss : 0.110212 model2 loss : 0.168188
[23:35:07.652] iteration 18090 : model1 loss : 0.232295 model2 loss : 0.279212
[23:35:07.987] iteration 18091 : model1 loss : 0.101341 model2 loss : 0.184347
[23:35:08.326] iteration 18092 : model1 loss : 0.147900 model2 loss : 0.256627
[23:35:08.659] iteration 18093 : model1 loss : 0.206738 model2 loss : 0.184674
[23:35:08.995] iteration 18094 : model1 loss : 0.218231 model2 loss : 0.280481
[23:35:09.331] iteration 18095 : model1 loss : 0.175767 model2 loss : 0.187364
[23:35:09.671] iteration 18096 : model1 loss : 0.257341 model2 loss : 0.282659
[23:35:10.004] iteration 18097 : model1 loss : 0.194004 model2 loss : 0.206609
[23:35:10.344] iteration 18098 : model1 loss : 0.145578 model2 loss : 0.237367
[23:35:10.679] iteration 18099 : model1 loss : 0.262209 model2 loss : 0.287630
[23:35:11.011] iteration 18100 : model1 loss : 0.199460 model2 loss : 0.202487
[23:35:11.620] iteration 18101 : model1 loss : 0.203510 model2 loss : 0.216091
[23:35:11.957] iteration 18102 : model1 loss : 0.093109 model2 loss : 0.164351
[23:35:12.292] iteration 18103 : model1 loss : 0.339924 model2 loss : 0.356451
[23:35:12.625] iteration 18104 : model1 loss : 0.283556 model2 loss : 0.293677
[23:35:12.961] iteration 18105 : model1 loss : 0.214502 model2 loss : 0.229509
[23:35:13.297] iteration 18106 : model1 loss : 0.089230 model2 loss : 0.200809
[23:35:13.632] iteration 18107 : model1 loss : 0.223909 model2 loss : 0.233412
[23:35:13.972] iteration 18108 : model1 loss : 0.349847 model2 loss : 0.391707
[23:35:14.311] iteration 18109 : model1 loss : 0.128803 model2 loss : 0.234495
[23:35:14.642] iteration 18110 : model1 loss : 0.165019 model2 loss : 0.285126
[23:35:14.973] iteration 18111 : model1 loss : 0.190759 model2 loss : 0.193939
[23:35:15.307] iteration 18112 : model1 loss : 0.285948 model2 loss : 0.293775
[23:35:15.642] iteration 18113 : model1 loss : 0.230703 model2 loss : 0.279112
[23:35:15.973] iteration 18114 : model1 loss : 0.170321 model2 loss : 0.194822
[23:35:16.306] iteration 18115 : model1 loss : 0.180762 model2 loss : 0.240763
[23:35:16.641] iteration 18116 : model1 loss : 0.144706 model2 loss : 0.182997
[23:35:16.973] iteration 18117 : model1 loss : 0.242798 model2 loss : 0.255852
[23:35:17.304] iteration 18118 : model1 loss : 0.183073 model2 loss : 0.194241
[23:35:17.640] iteration 18119 : model1 loss : 0.057351 model2 loss : 0.088585
[23:35:17.973] iteration 18120 : model1 loss : 0.205374 model2 loss : 0.214644
[23:35:18.305] iteration 18121 : model1 loss : 0.201129 model2 loss : 0.218001
[23:35:18.644] iteration 18122 : model1 loss : 0.182447 model2 loss : 0.266138
[23:35:18.981] iteration 18123 : model1 loss : 0.216409 model2 loss : 0.268163
[23:35:19.316] iteration 18124 : model1 loss : 0.184341 model2 loss : 0.179730
[23:35:19.654] iteration 18125 : model1 loss : 0.158704 model2 loss : 0.212904
[23:35:19.989] iteration 18126 : model1 loss : 0.196293 model2 loss : 0.207423
[23:35:20.322] iteration 18127 : model1 loss : 0.184718 model2 loss : 0.198525
[23:35:20.662] iteration 18128 : model1 loss : 0.218066 model2 loss : 0.261816
[23:35:20.994] iteration 18129 : model1 loss : 0.169383 model2 loss : 0.204368
[23:35:21.335] iteration 18130 : model1 loss : 0.263401 model2 loss : 0.283963
[23:35:21.672] iteration 18131 : model1 loss : 0.172231 model2 loss : 0.202383
[23:35:22.004] iteration 18132 : model1 loss : 0.188962 model2 loss : 0.240811
[23:35:22.336] iteration 18133 : model1 loss : 0.256757 model2 loss : 0.277479
[23:35:22.669] iteration 18134 : model1 loss : 0.177507 model2 loss : 0.237767
[23:35:23.001] iteration 18135 : model1 loss : 0.117439 model2 loss : 0.145934
[23:35:23.341] iteration 18136 : model1 loss : 0.166550 model2 loss : 0.184464
[23:35:23.675] iteration 18137 : model1 loss : 0.292789 model2 loss : 0.295075
[23:35:24.008] iteration 18138 : model1 loss : 0.256050 model2 loss : 0.291433
[23:35:24.340] iteration 18139 : model1 loss : 0.217633 model2 loss : 0.310937
[23:35:24.676] iteration 18140 : model1 loss : 0.168291 model2 loss : 0.188616
[23:35:25.016] iteration 18141 : model1 loss : 0.122909 model2 loss : 0.130540
[23:35:25.353] iteration 18142 : model1 loss : 0.295626 model2 loss : 0.344713
[23:35:25.685] iteration 18143 : model1 loss : 0.130519 model2 loss : 0.107530
[23:35:26.024] iteration 18144 : model1 loss : 0.136472 model2 loss : 0.156298
[23:35:26.362] iteration 18145 : model1 loss : 0.183414 model2 loss : 0.190129
[23:35:26.696] iteration 18146 : model1 loss : 0.315888 model2 loss : 0.321676
[23:35:27.033] iteration 18147 : model1 loss : 0.193787 model2 loss : 0.217961
[23:35:27.366] iteration 18148 : model1 loss : 0.169156 model2 loss : 0.207229
[23:35:27.697] iteration 18149 : model1 loss : 0.256008 model2 loss : 0.289158
[23:35:28.034] iteration 18150 : model1 loss : 0.202738 model2 loss : 0.228008
[23:35:28.676] iteration 18151 : model1 loss : 0.196624 model2 loss : 0.236304
[23:35:29.013] iteration 18152 : model1 loss : 0.240568 model2 loss : 0.309141
[23:35:29.354] iteration 18153 : model1 loss : 0.253419 model2 loss : 0.287568
[23:35:29.688] iteration 18154 : model1 loss : 0.179011 model2 loss : 0.192779
[23:35:30.025] iteration 18155 : model1 loss : 0.251092 model2 loss : 0.251554
[23:35:30.368] iteration 18156 : model1 loss : 0.277870 model2 loss : 0.336298
[23:35:30.709] iteration 18157 : model1 loss : 0.246596 model2 loss : 0.283564
[23:35:31.044] iteration 18158 : model1 loss : 0.222607 model2 loss : 0.264278
[23:35:31.381] iteration 18159 : model1 loss : 0.122282 model2 loss : 0.117493
[23:35:31.722] iteration 18160 : model1 loss : 0.277349 model2 loss : 0.304482
[23:35:32.057] iteration 18161 : model1 loss : 0.264567 model2 loss : 0.302091
[23:35:32.391] iteration 18162 : model1 loss : 0.267957 model2 loss : 0.297025
[23:35:32.729] iteration 18163 : model1 loss : 0.195014 model2 loss : 0.233276
[23:35:33.068] iteration 18164 : model1 loss : 0.208769 model2 loss : 0.235266
[23:35:33.407] iteration 18165 : model1 loss : 0.217848 model2 loss : 0.253319
[23:35:33.747] iteration 18166 : model1 loss : 0.256722 model2 loss : 0.229767
[23:35:34.089] iteration 18167 : model1 loss : 0.295973 model2 loss : 0.344921
[23:35:34.426] iteration 18168 : model1 loss : 0.161451 model2 loss : 0.205870
[23:35:34.764] iteration 18169 : model1 loss : 0.158929 model2 loss : 0.186562
[23:35:35.109] iteration 18170 : model1 loss : 0.253957 model2 loss : 0.221223
[23:35:35.446] iteration 18171 : model1 loss : 0.280261 model2 loss : 0.290821
[23:35:35.781] iteration 18172 : model1 loss : 0.078136 model2 loss : 0.150163
[23:35:36.112] iteration 18173 : model1 loss : 0.323994 model2 loss : 0.365923
[23:35:36.448] iteration 18174 : model1 loss : 0.204231 model2 loss : 0.213640
[23:35:36.798] iteration 18175 : model1 loss : 0.103952 model2 loss : 0.169607
[23:35:37.135] iteration 18176 : model1 loss : 0.107287 model2 loss : 0.128721
[23:35:37.472] iteration 18177 : model1 loss : 0.176188 model2 loss : 0.214024
[23:35:37.806] iteration 18178 : model1 loss : 0.197177 model2 loss : 0.178385
[23:35:38.144] iteration 18179 : model1 loss : 0.255827 model2 loss : 0.273296
[23:35:38.480] iteration 18180 : model1 loss : 0.255407 model2 loss : 0.231933
[23:35:38.816] iteration 18181 : model1 loss : 0.246325 model2 loss : 0.270045
[23:35:39.150] iteration 18182 : model1 loss : 0.243396 model2 loss : 0.242071
[23:35:39.486] iteration 18183 : model1 loss : 0.146971 model2 loss : 0.198180
[23:35:39.821] iteration 18184 : model1 loss : 0.130083 model2 loss : 0.122899
[23:35:40.156] iteration 18185 : model1 loss : 0.236909 model2 loss : 0.245700
[23:35:40.492] iteration 18186 : model1 loss : 0.127014 model2 loss : 0.157599
[23:35:40.826] iteration 18187 : model1 loss : 0.117638 model2 loss : 0.167441
[23:35:41.164] iteration 18188 : model1 loss : 0.088579 model2 loss : 0.129830
[23:35:41.499] iteration 18189 : model1 loss : 0.178372 model2 loss : 0.243748
[23:35:41.834] iteration 18190 : model1 loss : 0.268613 model2 loss : 0.289786
[23:35:42.170] iteration 18191 : model1 loss : 0.100228 model2 loss : 0.153386
[23:35:42.505] iteration 18192 : model1 loss : 0.118002 model2 loss : 0.138802
[23:35:42.842] iteration 18193 : model1 loss : 0.195955 model2 loss : 0.195117
[23:35:43.178] iteration 18194 : model1 loss : 0.214602 model2 loss : 0.257780
[23:35:43.513] iteration 18195 : model1 loss : 0.121649 model2 loss : 0.126557
[23:35:43.849] iteration 18196 : model1 loss : 0.215142 model2 loss : 0.257035
[23:35:44.186] iteration 18197 : model1 loss : 0.240502 model2 loss : 0.315443
[23:35:44.524] iteration 18198 : model1 loss : 0.102948 model2 loss : 0.166208
[23:35:44.857] iteration 18199 : model1 loss : 0.089905 model2 loss : 0.098787
[23:35:45.195] iteration 18200 : model1 loss : 0.198705 model2 loss : 0.258750
[23:35:45.832] iteration 18201 : model1 loss : 0.323461 model2 loss : 0.250015
[23:35:46.163] iteration 18202 : model1 loss : 0.102651 model2 loss : 0.146787
[23:35:46.495] iteration 18203 : model1 loss : 0.182643 model2 loss : 0.187739
[23:35:46.833] iteration 18204 : model1 loss : 0.285697 model2 loss : 0.322719
[23:35:47.169] iteration 18205 : model1 loss : 0.194033 model2 loss : 0.240479
[23:35:47.509] iteration 18206 : model1 loss : 0.274011 model2 loss : 0.281758
[23:35:47.844] iteration 18207 : model1 loss : 0.085378 model2 loss : 0.128955
[23:35:48.178] iteration 18208 : model1 loss : 0.202105 model2 loss : 0.205927
[23:35:48.509] iteration 18209 : model1 loss : 0.312591 model2 loss : 0.317091
[23:35:48.845] iteration 18210 : model1 loss : 0.255605 model2 loss : 0.288384
[23:35:49.183] iteration 18211 : model1 loss : 0.246974 model2 loss : 0.254905
[23:35:49.518] iteration 18212 : model1 loss : 0.250489 model2 loss : 0.268698
[23:35:49.852] iteration 18213 : model1 loss : 0.267464 model2 loss : 0.289033
[23:35:50.190] iteration 18214 : model1 loss : 0.186689 model2 loss : 0.192984
[23:35:50.525] iteration 18215 : model1 loss : 0.082789 model2 loss : 0.178531
[23:35:50.861] iteration 18216 : model1 loss : 0.193572 model2 loss : 0.260937
[23:35:51.196] iteration 18217 : model1 loss : 0.201454 model2 loss : 0.279532
[23:35:51.530] iteration 18218 : model1 loss : 0.262299 model2 loss : 0.292967
[23:35:51.866] iteration 18219 : model1 loss : 0.251938 model2 loss : 0.286798
[23:35:52.200] iteration 18220 : model1 loss : 0.197819 model2 loss : 0.224478
[23:35:52.532] iteration 18221 : model1 loss : 0.246182 model2 loss : 0.308575
[23:35:52.866] iteration 18222 : model1 loss : 0.085789 model2 loss : 0.106079
[23:35:53.203] iteration 18223 : model1 loss : 0.098512 model2 loss : 0.126340
[23:35:53.537] iteration 18224 : model1 loss : 0.239090 model2 loss : 0.223524
[23:35:53.872] iteration 18225 : model1 loss : 0.212937 model2 loss : 0.291606
[23:35:54.203] iteration 18226 : model1 loss : 0.178315 model2 loss : 0.189894
[23:35:54.534] iteration 18227 : model1 loss : 0.281269 model2 loss : 0.314583
[23:35:54.866] iteration 18228 : model1 loss : 0.251725 model2 loss : 0.272193
[23:35:55.202] iteration 18229 : model1 loss : 0.119247 model2 loss : 0.167239
[23:35:55.537] iteration 18230 : model1 loss : 0.173791 model2 loss : 0.192806
[23:35:55.874] iteration 18231 : model1 loss : 0.201125 model2 loss : 0.252333
[23:35:56.240] iteration 18232 : model1 loss : 0.179833 model2 loss : 0.210791
[23:35:56.574] iteration 18233 : model1 loss : 0.246729 model2 loss : 0.261083
[23:35:56.909] iteration 18234 : model1 loss : 0.170817 model2 loss : 0.213299
[23:35:57.244] iteration 18235 : model1 loss : 0.195176 model2 loss : 0.270534
[23:35:57.580] iteration 18236 : model1 loss : 0.080100 model2 loss : 0.125725
[23:35:57.914] iteration 18237 : model1 loss : 0.298765 model2 loss : 0.301387
[23:35:58.250] iteration 18238 : model1 loss : 0.120808 model2 loss : 0.150617
[23:35:58.582] iteration 18239 : model1 loss : 0.233590 model2 loss : 0.288600
[23:35:58.915] iteration 18240 : model1 loss : 0.172233 model2 loss : 0.180154
[23:35:59.250] iteration 18241 : model1 loss : 0.198726 model2 loss : 0.188403
[23:35:59.582] iteration 18242 : model1 loss : 0.236910 model2 loss : 0.251153
[23:35:59.914] iteration 18243 : model1 loss : 0.238293 model2 loss : 0.325238
[23:36:00.250] iteration 18244 : model1 loss : 0.163341 model2 loss : 0.169024
[23:36:00.584] iteration 18245 : model1 loss : 0.176880 model2 loss : 0.178813
[23:36:00.915] iteration 18246 : model1 loss : 0.185821 model2 loss : 0.240325
[23:36:01.255] iteration 18247 : model1 loss : 0.159340 model2 loss : 0.192577
[23:36:01.588] iteration 18248 : model1 loss : 0.159008 model2 loss : 0.183678
[23:36:01.921] iteration 18249 : model1 loss : 0.250134 model2 loss : 0.260221
[23:36:02.252] iteration 18250 : model1 loss : 0.240900 model2 loss : 0.262119
[23:36:02.893] iteration 18251 : model1 loss : 0.327729 model2 loss : 0.328204
[23:36:03.226] iteration 18252 : model1 loss : 0.172545 model2 loss : 0.184295
[23:36:03.558] iteration 18253 : model1 loss : 0.179510 model2 loss : 0.193219
[23:36:03.889] iteration 18254 : model1 loss : 0.174946 model2 loss : 0.192985
[23:36:04.221] iteration 18255 : model1 loss : 0.194873 model2 loss : 0.225444
[23:36:04.554] iteration 18256 : model1 loss : 0.178581 model2 loss : 0.219402
[23:36:04.885] iteration 18257 : model1 loss : 0.145502 model2 loss : 0.210341
[23:36:05.217] iteration 18258 : model1 loss : 0.184086 model2 loss : 0.232738
[23:36:05.556] iteration 18259 : model1 loss : 0.167513 model2 loss : 0.196119
[23:36:05.896] iteration 18260 : model1 loss : 0.205604 model2 loss : 0.208195
[23:36:06.228] iteration 18261 : model1 loss : 0.139931 model2 loss : 0.151381
[23:36:06.565] iteration 18262 : model1 loss : 0.212109 model2 loss : 0.236206
[23:36:06.901] iteration 18263 : model1 loss : 0.164382 model2 loss : 0.149555
[23:36:07.234] iteration 18264 : model1 loss : 0.203601 model2 loss : 0.197120
[23:36:07.572] iteration 18265 : model1 loss : 0.247672 model2 loss : 0.244735
[23:36:07.909] iteration 18266 : model1 loss : 0.165617 model2 loss : 0.209818
[23:36:08.244] iteration 18267 : model1 loss : 0.250609 model2 loss : 0.269238
[23:36:08.584] iteration 18268 : model1 loss : 0.191170 model2 loss : 0.238644
[23:36:08.915] iteration 18269 : model1 loss : 0.212301 model2 loss : 0.237822
[23:36:09.247] iteration 18270 : model1 loss : 0.331854 model2 loss : 0.394101
[23:36:09.580] iteration 18271 : model1 loss : 0.184931 model2 loss : 0.270211
[23:36:09.913] iteration 18272 : model1 loss : 0.344071 model2 loss : 0.411029
[23:36:10.250] iteration 18273 : model1 loss : 0.159843 model2 loss : 0.278331
[23:36:10.584] iteration 18274 : model1 loss : 0.280087 model2 loss : 0.293115
[23:36:10.917] iteration 18275 : model1 loss : 0.183950 model2 loss : 0.233294
[23:36:11.252] iteration 18276 : model1 loss : 0.230419 model2 loss : 0.252138
[23:36:11.590] iteration 18277 : model1 loss : 0.195664 model2 loss : 0.201190
[23:36:11.922] iteration 18278 : model1 loss : 0.173015 model2 loss : 0.214878
[23:36:12.257] iteration 18279 : model1 loss : 0.089861 model2 loss : 0.165679
[23:36:12.590] iteration 18280 : model1 loss : 0.184223 model2 loss : 0.195355
[23:36:12.922] iteration 18281 : model1 loss : 0.172511 model2 loss : 0.243421
[23:36:13.257] iteration 18282 : model1 loss : 0.337887 model2 loss : 0.380050
[23:36:13.588] iteration 18283 : model1 loss : 0.162614 model2 loss : 0.199070
[23:36:13.929] iteration 18284 : model1 loss : 0.155279 model2 loss : 0.143681
[23:36:14.264] iteration 18285 : model1 loss : 0.160802 model2 loss : 0.184008
[23:36:14.596] iteration 18286 : model1 loss : 0.197845 model2 loss : 0.178325
[23:36:14.926] iteration 18287 : model1 loss : 0.191734 model2 loss : 0.172451
[23:36:15.258] iteration 18288 : model1 loss : 0.180206 model2 loss : 0.190420
[23:36:15.588] iteration 18289 : model1 loss : 0.248160 model2 loss : 0.278610
[23:36:15.929] iteration 18290 : model1 loss : 0.187398 model2 loss : 0.241148
[23:36:16.263] iteration 18291 : model1 loss : 0.292958 model2 loss : 0.342120
[23:36:16.595] iteration 18292 : model1 loss : 0.205181 model2 loss : 0.246927
[23:36:16.930] iteration 18293 : model1 loss : 0.252164 model2 loss : 0.281275
[23:36:17.262] iteration 18294 : model1 loss : 0.185381 model2 loss : 0.188908
[23:36:17.598] iteration 18295 : model1 loss : 0.081214 model2 loss : 0.143977
[23:36:17.935] iteration 18296 : model1 loss : 0.161388 model2 loss : 0.210433
[23:36:18.273] iteration 18297 : model1 loss : 0.322413 model2 loss : 0.357233
[23:36:18.609] iteration 18298 : model1 loss : 0.252311 model2 loss : 0.276814
[23:36:18.946] iteration 18299 : model1 loss : 0.250056 model2 loss : 0.310315
[23:36:19.282] iteration 18300 : model1 loss : 0.125302 model2 loss : 0.178328
[23:36:19.964] iteration 18301 : model1 loss : 0.127897 model2 loss : 0.164307
[23:36:20.301] iteration 18302 : model1 loss : 0.142127 model2 loss : 0.170606
[23:36:20.639] iteration 18303 : model1 loss : 0.170867 model2 loss : 0.236848
[23:36:20.975] iteration 18304 : model1 loss : 0.164503 model2 loss : 0.206600
[23:36:21.315] iteration 18305 : model1 loss : 0.254937 model2 loss : 0.254494
[23:36:21.653] iteration 18306 : model1 loss : 0.155976 model2 loss : 0.200543
[23:36:21.990] iteration 18307 : model1 loss : 0.232209 model2 loss : 0.295883
[23:36:22.328] iteration 18308 : model1 loss : 0.199161 model2 loss : 0.205858
[23:36:22.664] iteration 18309 : model1 loss : 0.289336 model2 loss : 0.316954
[23:36:23.000] iteration 18310 : model1 loss : 0.166771 model2 loss : 0.182586
[23:36:23.336] iteration 18311 : model1 loss : 0.164416 model2 loss : 0.244977
[23:36:23.674] iteration 18312 : model1 loss : 0.198133 model2 loss : 0.276554
[23:36:24.010] iteration 18313 : model1 loss : 0.255756 model2 loss : 0.315114
[23:36:24.346] iteration 18314 : model1 loss : 0.210359 model2 loss : 0.274412
[23:36:24.683] iteration 18315 : model1 loss : 0.275660 model2 loss : 0.263502
[23:36:25.023] iteration 18316 : model1 loss : 0.156125 model2 loss : 0.209032
[23:36:25.360] iteration 18317 : model1 loss : 0.328076 model2 loss : 0.433760
[23:36:25.696] iteration 18318 : model1 loss : 0.202052 model2 loss : 0.152197
[23:36:26.035] iteration 18319 : model1 loss : 0.181465 model2 loss : 0.224128
[23:36:26.390] iteration 18320 : model1 loss : 0.181397 model2 loss : 0.233599
[23:36:26.718] iteration 18321 : model1 loss : 0.197346 model2 loss : 0.169360
[23:36:27.046] iteration 18322 : model1 loss : 0.116472 model2 loss : 0.200904
[23:36:27.374] iteration 18323 : model1 loss : 0.202204 model2 loss : 0.284786
[23:36:27.701] iteration 18324 : model1 loss : 0.368934 model2 loss : 0.424667
[23:36:28.029] iteration 18325 : model1 loss : 0.359276 model2 loss : 0.317519
[23:36:28.356] iteration 18326 : model1 loss : 0.259189 model2 loss : 0.319383
[23:36:28.685] iteration 18327 : model1 loss : 0.111377 model2 loss : 0.149582
[23:36:29.014] iteration 18328 : model1 loss : 0.114147 model2 loss : 0.143335
[23:36:29.341] iteration 18329 : model1 loss : 0.155353 model2 loss : 0.157527
[23:36:29.669] iteration 18330 : model1 loss : 0.207855 model2 loss : 0.272783
[23:36:29.997] iteration 18331 : model1 loss : 0.176311 model2 loss : 0.193534
[23:36:30.327] iteration 18332 : model1 loss : 0.224399 model2 loss : 0.256589
[23:36:30.654] iteration 18333 : model1 loss : 0.213739 model2 loss : 0.256063
[23:36:30.981] iteration 18334 : model1 loss : 0.161810 model2 loss : 0.168471
[23:36:31.309] iteration 18335 : model1 loss : 0.387649 model2 loss : 0.355547
[23:36:31.636] iteration 18336 : model1 loss : 0.208968 model2 loss : 0.231669
[23:36:31.963] iteration 18337 : model1 loss : 0.196046 model2 loss : 0.217948
[23:36:32.292] iteration 18338 : model1 loss : 0.229291 model2 loss : 0.255563
[23:36:32.619] iteration 18339 : model1 loss : 0.208453 model2 loss : 0.212737
[23:36:32.947] iteration 18340 : model1 loss : 0.288374 model2 loss : 0.354833
[23:36:33.275] iteration 18341 : model1 loss : 0.269670 model2 loss : 0.245414
[23:36:33.603] iteration 18342 : model1 loss : 0.228460 model2 loss : 0.278819
[23:36:33.931] iteration 18343 : model1 loss : 0.169398 model2 loss : 0.216678
[23:36:34.259] iteration 18344 : model1 loss : 0.165994 model2 loss : 0.218363
[23:36:34.586] iteration 18345 : model1 loss : 0.355512 model2 loss : 0.293794
[23:36:34.913] iteration 18346 : model1 loss : 0.211342 model2 loss : 0.223121
[23:36:35.240] iteration 18347 : model1 loss : 0.183826 model2 loss : 0.162072
[23:36:35.567] iteration 18348 : model1 loss : 0.225251 model2 loss : 0.265538
[23:36:35.893] iteration 18349 : model1 loss : 0.365465 model2 loss : 0.321191
[23:36:36.220] iteration 18350 : model1 loss : 0.180718 model2 loss : 0.204022
[23:36:36.747] iteration 18351 : model1 loss : 0.311386 model2 loss : 0.352561
[23:36:37.074] iteration 18352 : model1 loss : 0.209081 model2 loss : 0.211543
[23:36:37.401] iteration 18353 : model1 loss : 0.267646 model2 loss : 0.310310
[23:36:37.729] iteration 18354 : model1 loss : 0.270724 model2 loss : 0.316939
[23:36:38.055] iteration 18355 : model1 loss : 0.144126 model2 loss : 0.181872
[23:36:38.382] iteration 18356 : model1 loss : 0.104509 model2 loss : 0.216662
[23:36:38.709] iteration 18357 : model1 loss : 0.192810 model2 loss : 0.270107
[23:36:39.035] iteration 18358 : model1 loss : 0.262729 model2 loss : 0.280437
[23:36:39.362] iteration 18359 : model1 loss : 0.253631 model2 loss : 0.263272
[23:36:39.690] iteration 18360 : model1 loss : 0.221979 model2 loss : 0.250676
[23:36:40.017] iteration 18361 : model1 loss : 0.087600 model2 loss : 0.119395
[23:36:40.344] iteration 18362 : model1 loss : 0.282684 model2 loss : 0.306451
[23:36:40.670] iteration 18363 : model1 loss : 0.161111 model2 loss : 0.192445
[23:36:40.997] iteration 18364 : model1 loss : 0.134632 model2 loss : 0.213055
[23:36:41.322] iteration 18365 : model1 loss : 0.212963 model2 loss : 0.207562
[23:36:41.649] iteration 18366 : model1 loss : 0.309205 model2 loss : 0.304675
[23:36:41.976] iteration 18367 : model1 loss : 0.192757 model2 loss : 0.277976
[23:36:42.301] iteration 18368 : model1 loss : 0.202085 model2 loss : 0.228002
[23:36:42.629] iteration 18369 : model1 loss : 0.151202 model2 loss : 0.187151
[23:36:42.955] iteration 18370 : model1 loss : 0.203567 model2 loss : 0.210005
[23:36:43.279] iteration 18371 : model1 loss : 0.189863 model2 loss : 0.268763
[23:36:43.611] iteration 18372 : model1 loss : 0.191353 model2 loss : 0.229333
[23:36:43.937] iteration 18373 : model1 loss : 0.157342 model2 loss : 0.172556
[23:36:44.262] iteration 18374 : model1 loss : 0.179352 model2 loss : 0.288539
[23:36:44.588] iteration 18375 : model1 loss : 0.294131 model2 loss : 0.338952
[23:36:44.914] iteration 18376 : model1 loss : 0.218913 model2 loss : 0.203971
[23:36:45.240] iteration 18377 : model1 loss : 0.261864 model2 loss : 0.245479
[23:36:45.566] iteration 18378 : model1 loss : 0.180406 model2 loss : 0.203568
[23:36:45.892] iteration 18379 : model1 loss : 0.246573 model2 loss : 0.267389
[23:36:46.218] iteration 18380 : model1 loss : 0.171227 model2 loss : 0.223681
[23:36:46.543] iteration 18381 : model1 loss : 0.173523 model2 loss : 0.191113
[23:36:46.868] iteration 18382 : model1 loss : 0.272080 model2 loss : 0.295978
[23:36:47.193] iteration 18383 : model1 loss : 0.248442 model2 loss : 0.283061
[23:36:47.518] iteration 18384 : model1 loss : 0.215995 model2 loss : 0.224089
[23:36:47.844] iteration 18385 : model1 loss : 0.278486 model2 loss : 0.387786
[23:36:48.170] iteration 18386 : model1 loss : 0.100715 model2 loss : 0.141324
[23:36:48.496] iteration 18387 : model1 loss : 0.192455 model2 loss : 0.304020
[23:36:48.821] iteration 18388 : model1 loss : 0.192999 model2 loss : 0.242127
[23:36:49.146] iteration 18389 : model1 loss : 0.207726 model2 loss : 0.241672
[23:36:49.472] iteration 18390 : model1 loss : 0.206548 model2 loss : 0.282988
[23:36:49.798] iteration 18391 : model1 loss : 0.168616 model2 loss : 0.160060
[23:36:50.124] iteration 18392 : model1 loss : 0.232736 model2 loss : 0.316692
[23:36:50.450] iteration 18393 : model1 loss : 0.326349 model2 loss : 0.355826
[23:36:50.775] iteration 18394 : model1 loss : 0.250529 model2 loss : 0.281288
[23:36:51.100] iteration 18395 : model1 loss : 0.122486 model2 loss : 0.246569
[23:36:51.426] iteration 18396 : model1 loss : 0.138981 model2 loss : 0.132578
[23:36:51.753] iteration 18397 : model1 loss : 0.248283 model2 loss : 0.269920
[23:36:52.079] iteration 18398 : model1 loss : 0.244255 model2 loss : 0.287380
[23:36:52.405] iteration 18399 : model1 loss : 0.214800 model2 loss : 0.247570
[23:36:52.731] iteration 18400 : model1 loss : 0.262299 model2 loss : 0.258536
[23:36:53.227] iteration 18401 : model1 loss : 0.251996 model2 loss : 0.287082
[23:36:53.552] iteration 18402 : model1 loss : 0.230636 model2 loss : 0.284434
[23:36:53.877] iteration 18403 : model1 loss : 0.187606 model2 loss : 0.238798
[23:36:54.205] iteration 18404 : model1 loss : 0.266891 model2 loss : 0.217897
[23:36:54.530] iteration 18405 : model1 loss : 0.316884 model2 loss : 0.320639
[23:36:54.855] iteration 18406 : model1 loss : 0.194411 model2 loss : 0.275006
[23:36:55.181] iteration 18407 : model1 loss : 0.208119 model2 loss : 0.248705
[23:36:55.506] iteration 18408 : model1 loss : 0.203068 model2 loss : 0.234047
[23:36:55.832] iteration 18409 : model1 loss : 0.314597 model2 loss : 0.403019
[23:36:56.157] iteration 18410 : model1 loss : 0.199492 model2 loss : 0.191045
[23:36:56.484] iteration 18411 : model1 loss : 0.103301 model2 loss : 0.126791
[23:36:56.810] iteration 18412 : model1 loss : 0.315105 model2 loss : 0.317815
[23:36:57.135] iteration 18413 : model1 loss : 0.217468 model2 loss : 0.247728
[23:36:57.460] iteration 18414 : model1 loss : 0.125275 model2 loss : 0.153030
[23:36:57.787] iteration 18415 : model1 loss : 0.247763 model2 loss : 0.261836
[23:36:58.112] iteration 18416 : model1 loss : 0.182822 model2 loss : 0.203156
[23:36:58.438] iteration 18417 : model1 loss : 0.238787 model2 loss : 0.273208
[23:36:58.763] iteration 18418 : model1 loss : 0.275217 model2 loss : 0.291367
[23:36:59.090] iteration 18419 : model1 loss : 0.124124 model2 loss : 0.167198
[23:36:59.416] iteration 18420 : model1 loss : 0.171561 model2 loss : 0.183453
[23:36:59.740] iteration 18421 : model1 loss : 0.175823 model2 loss : 0.246018
[23:37:00.066] iteration 18422 : model1 loss : 0.113401 model2 loss : 0.132104
[23:37:00.392] iteration 18423 : model1 loss : 0.138935 model2 loss : 0.141344
[23:37:00.718] iteration 18424 : model1 loss : 0.096527 model2 loss : 0.180525
[23:37:01.154] iteration 18425 : model1 loss : 0.141257 model2 loss : 0.125398
[23:37:01.479] iteration 18426 : model1 loss : 0.253507 model2 loss : 0.269274
[23:37:01.805] iteration 18427 : model1 loss : 0.238695 model2 loss : 0.259472
[23:37:02.131] iteration 18428 : model1 loss : 0.118260 model2 loss : 0.160938
[23:37:02.458] iteration 18429 : model1 loss : 0.282321 model2 loss : 0.306136
[23:37:02.783] iteration 18430 : model1 loss : 0.111109 model2 loss : 0.145261
[23:37:03.110] iteration 18431 : model1 loss : 0.190417 model2 loss : 0.210639
[23:37:03.437] iteration 18432 : model1 loss : 0.321517 model2 loss : 0.327087
[23:37:03.762] iteration 18433 : model1 loss : 0.121156 model2 loss : 0.269730
[23:37:04.088] iteration 18434 : model1 loss : 0.122937 model2 loss : 0.102411
[23:37:04.414] iteration 18435 : model1 loss : 0.256989 model2 loss : 0.309863
[23:37:04.740] iteration 18436 : model1 loss : 0.261376 model2 loss : 0.285993
[23:37:05.065] iteration 18437 : model1 loss : 0.190865 model2 loss : 0.234224
[23:37:05.391] iteration 18438 : model1 loss : 0.167912 model2 loss : 0.176326
[23:37:05.717] iteration 18439 : model1 loss : 0.297016 model2 loss : 0.288846
[23:37:06.044] iteration 18440 : model1 loss : 0.166662 model2 loss : 0.170644
[23:37:06.371] iteration 18441 : model1 loss : 0.175915 model2 loss : 0.248546
[23:37:06.697] iteration 18442 : model1 loss : 0.266728 model2 loss : 0.307652
[23:37:07.023] iteration 18443 : model1 loss : 0.196077 model2 loss : 0.203165
[23:37:07.349] iteration 18444 : model1 loss : 0.162926 model2 loss : 0.253250
[23:37:07.674] iteration 18445 : model1 loss : 0.256372 model2 loss : 0.316957
[23:37:07.999] iteration 18446 : model1 loss : 0.091628 model2 loss : 0.121211
[23:37:08.324] iteration 18447 : model1 loss : 0.296901 model2 loss : 0.317066
[23:37:08.651] iteration 18448 : model1 loss : 0.097783 model2 loss : 0.109484
[23:37:08.976] iteration 18449 : model1 loss : 0.294678 model2 loss : 0.325307
[23:37:09.301] iteration 18450 : model1 loss : 0.082673 model2 loss : 0.106345
[23:37:09.816] iteration 18451 : model1 loss : 0.403338 model2 loss : 0.408245
[23:37:10.142] iteration 18452 : model1 loss : 0.293082 model2 loss : 0.277636
[23:37:10.468] iteration 18453 : model1 loss : 0.339215 model2 loss : 0.417353
[23:37:10.794] iteration 18454 : model1 loss : 0.243182 model2 loss : 0.263701
[23:37:11.120] iteration 18455 : model1 loss : 0.242557 model2 loss : 0.270792
[23:37:11.446] iteration 18456 : model1 loss : 0.236381 model2 loss : 0.174061
[23:37:11.771] iteration 18457 : model1 loss : 0.104393 model2 loss : 0.114399
[23:37:12.096] iteration 18458 : model1 loss : 0.246396 model2 loss : 0.277337
[23:37:12.422] iteration 18459 : model1 loss : 0.204374 model2 loss : 0.209548
[23:37:12.748] iteration 18460 : model1 loss : 0.235554 model2 loss : 0.228142
[23:37:13.073] iteration 18461 : model1 loss : 0.225771 model2 loss : 0.300840
[23:37:13.398] iteration 18462 : model1 loss : 0.222462 model2 loss : 0.232031
[23:37:13.723] iteration 18463 : model1 loss : 0.200901 model2 loss : 0.316918
[23:37:14.050] iteration 18464 : model1 loss : 0.110947 model2 loss : 0.232322
[23:37:14.376] iteration 18465 : model1 loss : 0.197123 model2 loss : 0.256531
[23:37:14.701] iteration 18466 : model1 loss : 0.218305 model2 loss : 0.215476
[23:37:15.027] iteration 18467 : model1 loss : 0.168936 model2 loss : 0.176398
[23:37:15.353] iteration 18468 : model1 loss : 0.207800 model2 loss : 0.261842
[23:37:15.678] iteration 18469 : model1 loss : 0.268278 model2 loss : 0.301705
[23:37:16.004] iteration 18470 : model1 loss : 0.095668 model2 loss : 0.102251
[23:37:16.330] iteration 18471 : model1 loss : 0.185161 model2 loss : 0.275746
[23:37:16.657] iteration 18472 : model1 loss : 0.103893 model2 loss : 0.167360
[23:37:16.982] iteration 18473 : model1 loss : 0.222694 model2 loss : 0.293061
[23:37:17.309] iteration 18474 : model1 loss : 0.195496 model2 loss : 0.242872
[23:37:17.635] iteration 18475 : model1 loss : 0.145253 model2 loss : 0.174351
[23:37:17.962] iteration 18476 : model1 loss : 0.235763 model2 loss : 0.269635
[23:37:18.288] iteration 18477 : model1 loss : 0.091211 model2 loss : 0.095855
[23:37:18.613] iteration 18478 : model1 loss : 0.193959 model2 loss : 0.234337
[23:37:18.939] iteration 18479 : model1 loss : 0.164012 model2 loss : 0.231537
[23:37:19.266] iteration 18480 : model1 loss : 0.214010 model2 loss : 0.225977
[23:37:19.597] iteration 18481 : model1 loss : 0.175408 model2 loss : 0.187107
[23:37:19.924] iteration 18482 : model1 loss : 0.330765 model2 loss : 0.387462
[23:37:20.249] iteration 18483 : model1 loss : 0.196407 model2 loss : 0.233358
[23:37:20.575] iteration 18484 : model1 loss : 0.197981 model2 loss : 0.191843
[23:37:20.901] iteration 18485 : model1 loss : 0.110494 model2 loss : 0.100646
[23:37:21.226] iteration 18486 : model1 loss : 0.098240 model2 loss : 0.148805
[23:37:21.552] iteration 18487 : model1 loss : 0.205858 model2 loss : 0.234835
[23:37:21.878] iteration 18488 : model1 loss : 0.216635 model2 loss : 0.254565
[23:37:22.204] iteration 18489 : model1 loss : 0.179562 model2 loss : 0.218735
[23:37:22.529] iteration 18490 : model1 loss : 0.198709 model2 loss : 0.240950
[23:37:22.855] iteration 18491 : model1 loss : 0.240437 model2 loss : 0.259581
[23:37:23.181] iteration 18492 : model1 loss : 0.071215 model2 loss : 0.085850
[23:37:23.505] iteration 18493 : model1 loss : 0.149495 model2 loss : 0.162493
[23:37:23.830] iteration 18494 : model1 loss : 0.104755 model2 loss : 0.122624
[23:37:24.157] iteration 18495 : model1 loss : 0.244960 model2 loss : 0.297046
[23:37:24.483] iteration 18496 : model1 loss : 0.204560 model2 loss : 0.262076
[23:37:24.808] iteration 18497 : model1 loss : 0.252429 model2 loss : 0.289983
[23:37:25.134] iteration 18498 : model1 loss : 0.209693 model2 loss : 0.210844
[23:37:25.460] iteration 18499 : model1 loss : 0.337270 model2 loss : 0.338978
[23:37:25.786] iteration 18500 : model1 loss : 0.102314 model2 loss : 0.182620
[23:37:26.321] iteration 18501 : model1 loss : 0.243311 model2 loss : 0.256659
[23:37:26.650] iteration 18502 : model1 loss : 0.296131 model2 loss : 0.332479
[23:37:26.976] iteration 18503 : model1 loss : 0.283952 model2 loss : 0.298518
[23:37:27.303] iteration 18504 : model1 loss : 0.170811 model2 loss : 0.202960
[23:37:27.631] iteration 18505 : model1 loss : 0.229440 model2 loss : 0.250091
[23:37:27.957] iteration 18506 : model1 loss : 0.155001 model2 loss : 0.204319
[23:37:28.284] iteration 18507 : model1 loss : 0.225496 model2 loss : 0.254691
[23:37:28.610] iteration 18508 : model1 loss : 0.232324 model2 loss : 0.230577
[23:37:28.936] iteration 18509 : model1 loss : 0.202941 model2 loss : 0.287454
[23:37:29.262] iteration 18510 : model1 loss : 0.181411 model2 loss : 0.177498
[23:37:29.588] iteration 18511 : model1 loss : 0.267378 model2 loss : 0.302237
[23:37:29.914] iteration 18512 : model1 loss : 0.142670 model2 loss : 0.152833
[23:37:30.239] iteration 18513 : model1 loss : 0.253274 model2 loss : 0.250856
[23:37:30.565] iteration 18514 : model1 loss : 0.177728 model2 loss : 0.202227
[23:37:30.891] iteration 18515 : model1 loss : 0.098482 model2 loss : 0.134222
[23:37:31.216] iteration 18516 : model1 loss : 0.250964 model2 loss : 0.278557
[23:37:31.542] iteration 18517 : model1 loss : 0.206420 model2 loss : 0.275243
[23:37:31.867] iteration 18518 : model1 loss : 0.175079 model2 loss : 0.233818
[23:37:32.193] iteration 18519 : model1 loss : 0.250240 model2 loss : 0.273575
[23:37:32.520] iteration 18520 : model1 loss : 0.147887 model2 loss : 0.138444
[23:37:32.846] iteration 18521 : model1 loss : 0.247203 model2 loss : 0.274376
[23:37:33.172] iteration 18522 : model1 loss : 0.247709 model2 loss : 0.268424
[23:37:33.497] iteration 18523 : model1 loss : 0.195478 model2 loss : 0.219623
[23:37:33.822] iteration 18524 : model1 loss : 0.212542 model2 loss : 0.286446
[23:37:34.147] iteration 18525 : model1 loss : 0.285993 model2 loss : 0.281991
[23:37:34.473] iteration 18526 : model1 loss : 0.126335 model2 loss : 0.143982
[23:37:34.797] iteration 18527 : model1 loss : 0.092624 model2 loss : 0.158781
[23:37:35.122] iteration 18528 : model1 loss : 0.233322 model2 loss : 0.254452
[23:37:35.448] iteration 18529 : model1 loss : 0.265737 model2 loss : 0.321413
[23:37:35.773] iteration 18530 : model1 loss : 0.232495 model2 loss : 0.194896
[23:37:36.706] iteration 18531 : model1 loss : 0.244235 model2 loss : 0.186245
[23:37:37.032] iteration 18532 : model1 loss : 0.100992 model2 loss : 0.133866
[23:37:37.358] iteration 18533 : model1 loss : 0.123015 model2 loss : 0.176883
[23:37:37.685] iteration 18534 : model1 loss : 0.284165 model2 loss : 0.274238
[23:37:38.012] iteration 18535 : model1 loss : 0.215632 model2 loss : 0.232675
[23:37:38.337] iteration 18536 : model1 loss : 0.305419 model2 loss : 0.323165
[23:37:38.663] iteration 18537 : model1 loss : 0.159731 model2 loss : 0.221954
[23:37:38.989] iteration 18538 : model1 loss : 0.320962 model2 loss : 0.334435
[23:37:39.316] iteration 18539 : model1 loss : 0.187685 model2 loss : 0.210441
[23:37:39.643] iteration 18540 : model1 loss : 0.090980 model2 loss : 0.124569
[23:37:39.968] iteration 18541 : model1 loss : 0.063251 model2 loss : 0.072390
[23:37:40.296] iteration 18542 : model1 loss : 0.095424 model2 loss : 0.121729
[23:37:40.622] iteration 18543 : model1 loss : 0.191806 model2 loss : 0.260112
[23:37:40.947] iteration 18544 : model1 loss : 0.189032 model2 loss : 0.183937
[23:37:41.273] iteration 18545 : model1 loss : 0.296421 model2 loss : 0.323879
[23:37:41.600] iteration 18546 : model1 loss : 0.175745 model2 loss : 0.134178
[23:37:41.926] iteration 18547 : model1 loss : 0.177975 model2 loss : 0.247319
[23:37:42.252] iteration 18548 : model1 loss : 0.202487 model2 loss : 0.283208
[23:37:42.578] iteration 18549 : model1 loss : 0.251496 model2 loss : 0.283932
[23:37:42.904] iteration 18550 : model1 loss : 0.197522 model2 loss : 0.219027
[23:37:43.433] iteration 18551 : model1 loss : 0.096040 model2 loss : 0.144190
[23:37:43.760] iteration 18552 : model1 loss : 0.098880 model2 loss : 0.089203
[23:37:44.087] iteration 18553 : model1 loss : 0.187383 model2 loss : 0.191592
[23:37:44.412] iteration 18554 : model1 loss : 0.170585 model2 loss : 0.173457
[23:37:44.740] iteration 18555 : model1 loss : 0.288084 model2 loss : 0.371126
[23:37:45.066] iteration 18556 : model1 loss : 0.251062 model2 loss : 0.290717
[23:37:45.392] iteration 18557 : model1 loss : 0.107812 model2 loss : 0.121429
[23:37:45.718] iteration 18558 : model1 loss : 0.079412 model2 loss : 0.113595
[23:37:46.045] iteration 18559 : model1 loss : 0.131283 model2 loss : 0.142006
[23:37:46.370] iteration 18560 : model1 loss : 0.187804 model2 loss : 0.223208
[23:37:46.695] iteration 18561 : model1 loss : 0.174055 model2 loss : 0.218654
[23:37:47.021] iteration 18562 : model1 loss : 0.113127 model2 loss : 0.159424
[23:37:47.347] iteration 18563 : model1 loss : 0.315084 model2 loss : 0.324141
[23:37:47.673] iteration 18564 : model1 loss : 0.174393 model2 loss : 0.252359
[23:37:47.999] iteration 18565 : model1 loss : 0.182479 model2 loss : 0.172346
[23:37:48.325] iteration 18566 : model1 loss : 0.164565 model2 loss : 0.247161
[23:37:48.651] iteration 18567 : model1 loss : 0.181470 model2 loss : 0.208400
[23:37:48.977] iteration 18568 : model1 loss : 0.193146 model2 loss : 0.260886
[23:37:49.304] iteration 18569 : model1 loss : 0.180747 model2 loss : 0.201749
[23:37:49.629] iteration 18570 : model1 loss : 0.277018 model2 loss : 0.294029
[23:37:49.956] iteration 18571 : model1 loss : 0.125987 model2 loss : 0.152732
[23:37:50.282] iteration 18572 : model1 loss : 0.156889 model2 loss : 0.184314
[23:37:50.609] iteration 18573 : model1 loss : 0.161153 model2 loss : 0.217162
[23:37:50.934] iteration 18574 : model1 loss : 0.170405 model2 loss : 0.191044
[23:37:51.260] iteration 18575 : model1 loss : 0.208009 model2 loss : 0.272815
[23:37:51.588] iteration 18576 : model1 loss : 0.173816 model2 loss : 0.258823
[23:37:51.914] iteration 18577 : model1 loss : 0.168900 model2 loss : 0.191327
[23:37:52.240] iteration 18578 : model1 loss : 0.177790 model2 loss : 0.281743
[23:37:52.567] iteration 18579 : model1 loss : 0.227437 model2 loss : 0.233265
[23:37:52.894] iteration 18580 : model1 loss : 0.248486 model2 loss : 0.304653
[23:37:53.220] iteration 18581 : model1 loss : 0.184100 model2 loss : 0.217019
[23:37:53.548] iteration 18582 : model1 loss : 0.259405 model2 loss : 0.273185
[23:37:53.873] iteration 18583 : model1 loss : 0.177053 model2 loss : 0.273959
[23:37:54.200] iteration 18584 : model1 loss : 0.175231 model2 loss : 0.201297
[23:37:54.526] iteration 18585 : model1 loss : 0.238596 model2 loss : 0.284102
[23:37:54.852] iteration 18586 : model1 loss : 0.186881 model2 loss : 0.273225
[23:37:55.182] iteration 18587 : model1 loss : 0.177640 model2 loss : 0.226617
[23:37:55.507] iteration 18588 : model1 loss : 0.197147 model2 loss : 0.198979
[23:37:55.833] iteration 18589 : model1 loss : 0.256648 model2 loss : 0.327930
[23:37:56.159] iteration 18590 : model1 loss : 0.193924 model2 loss : 0.198014
[23:37:56.486] iteration 18591 : model1 loss : 0.135926 model2 loss : 0.206015
[23:37:56.812] iteration 18592 : model1 loss : 0.187268 model2 loss : 0.201028
[23:37:57.138] iteration 18593 : model1 loss : 0.299306 model2 loss : 0.336696
[23:37:57.463] iteration 18594 : model1 loss : 0.092415 model2 loss : 0.133263
[23:37:57.789] iteration 18595 : model1 loss : 0.189128 model2 loss : 0.216433
[23:37:58.114] iteration 18596 : model1 loss : 0.193257 model2 loss : 0.235350
[23:37:58.440] iteration 18597 : model1 loss : 0.188874 model2 loss : 0.212162
[23:37:58.767] iteration 18598 : model1 loss : 0.282345 model2 loss : 0.291854
[23:37:59.093] iteration 18599 : model1 loss : 0.210327 model2 loss : 0.179267
[23:37:59.419] iteration 18600 : model1 loss : 0.259351 model2 loss : 0.266077
[23:37:59.963] iteration 18601 : model1 loss : 0.319449 model2 loss : 0.268269
[23:38:00.289] iteration 18602 : model1 loss : 0.139328 model2 loss : 0.145931
[23:38:00.616] iteration 18603 : model1 loss : 0.241956 model2 loss : 0.265958
[23:38:00.942] iteration 18604 : model1 loss : 0.107443 model2 loss : 0.171632
[23:38:01.268] iteration 18605 : model1 loss : 0.274715 model2 loss : 0.294440
[23:38:01.594] iteration 18606 : model1 loss : 0.241787 model2 loss : 0.265296
[23:38:01.921] iteration 18607 : model1 loss : 0.268495 model2 loss : 0.337304
[23:38:02.247] iteration 18608 : model1 loss : 0.163428 model2 loss : 0.259078
[23:38:02.573] iteration 18609 : model1 loss : 0.201887 model2 loss : 0.242458
[23:38:02.898] iteration 18610 : model1 loss : 0.180057 model2 loss : 0.182045
[23:38:03.223] iteration 18611 : model1 loss : 0.248155 model2 loss : 0.254448
[23:38:03.549] iteration 18612 : model1 loss : 0.085284 model2 loss : 0.143159
[23:38:03.875] iteration 18613 : model1 loss : 0.097160 model2 loss : 0.143694
[23:38:04.201] iteration 18614 : model1 loss : 0.273485 model2 loss : 0.305275
[23:38:04.526] iteration 18615 : model1 loss : 0.103222 model2 loss : 0.223997
[23:38:04.852] iteration 18616 : model1 loss : 0.147714 model2 loss : 0.158860
[23:38:05.178] iteration 18617 : model1 loss : 0.185540 model2 loss : 0.263782
[23:38:05.504] iteration 18618 : model1 loss : 0.200904 model2 loss : 0.237608
[23:38:05.830] iteration 18619 : model1 loss : 0.128578 model2 loss : 0.163747
[23:38:06.157] iteration 18620 : model1 loss : 0.112556 model2 loss : 0.133284
[23:38:06.482] iteration 18621 : model1 loss : 0.259260 model2 loss : 0.354821
[23:38:06.808] iteration 18622 : model1 loss : 0.178326 model2 loss : 0.220676
[23:38:07.134] iteration 18623 : model1 loss : 0.315002 model2 loss : 0.379719
[23:38:07.460] iteration 18624 : model1 loss : 0.154915 model2 loss : 0.201889
[23:38:07.786] iteration 18625 : model1 loss : 0.340413 model2 loss : 0.388910
[23:38:08.112] iteration 18626 : model1 loss : 0.219186 model2 loss : 0.248305
[23:38:08.437] iteration 18627 : model1 loss : 0.199096 model2 loss : 0.243977
[23:38:08.764] iteration 18628 : model1 loss : 0.256930 model2 loss : 0.300803
[23:38:09.089] iteration 18629 : model1 loss : 0.167714 model2 loss : 0.189573
[23:38:09.415] iteration 18630 : model1 loss : 0.278301 model2 loss : 0.277601
[23:38:09.742] iteration 18631 : model1 loss : 0.239005 model2 loss : 0.258400
[23:38:10.068] iteration 18632 : model1 loss : 0.168600 model2 loss : 0.199830
[23:38:10.394] iteration 18633 : model1 loss : 0.158692 model2 loss : 0.182845
[23:38:10.720] iteration 18634 : model1 loss : 0.101530 model2 loss : 0.148360
[23:38:11.046] iteration 18635 : model1 loss : 0.318918 model2 loss : 0.340707
[23:38:11.373] iteration 18636 : model1 loss : 0.142941 model2 loss : 0.184728
[23:38:11.698] iteration 18637 : model1 loss : 0.251257 model2 loss : 0.289851
[23:38:12.024] iteration 18638 : model1 loss : 0.238558 model2 loss : 0.271987
[23:38:12.350] iteration 18639 : model1 loss : 0.135899 model2 loss : 0.177275
[23:38:12.676] iteration 18640 : model1 loss : 0.098236 model2 loss : 0.131965
[23:38:13.001] iteration 18641 : model1 loss : 0.323408 model2 loss : 0.336917
[23:38:13.328] iteration 18642 : model1 loss : 0.227538 model2 loss : 0.274788
[23:38:13.654] iteration 18643 : model1 loss : 0.244944 model2 loss : 0.260633
[23:38:13.980] iteration 18644 : model1 loss : 0.114137 model2 loss : 0.174496
[23:38:14.306] iteration 18645 : model1 loss : 0.143556 model2 loss : 0.291294
[23:38:14.632] iteration 18646 : model1 loss : 0.110541 model2 loss : 0.183072
[23:38:14.958] iteration 18647 : model1 loss : 0.201266 model2 loss : 0.253009
[23:38:15.284] iteration 18648 : model1 loss : 0.230236 model2 loss : 0.239804
[23:38:15.610] iteration 18649 : model1 loss : 0.251324 model2 loss : 0.280338
[23:38:15.936] iteration 18650 : model1 loss : 0.169095 model2 loss : 0.213723
[23:38:16.453] iteration 18651 : model1 loss : 0.173833 model2 loss : 0.184048
[23:38:16.779] iteration 18652 : model1 loss : 0.135023 model2 loss : 0.280978
[23:38:17.104] iteration 18653 : model1 loss : 0.171366 model2 loss : 0.211527
[23:38:17.431] iteration 18654 : model1 loss : 0.276989 model2 loss : 0.232300
[23:38:17.757] iteration 18655 : model1 loss : 0.293673 model2 loss : 0.307179
[23:38:18.082] iteration 18656 : model1 loss : 0.273283 model2 loss : 0.323951
[23:38:18.407] iteration 18657 : model1 loss : 0.167525 model2 loss : 0.231847
[23:38:18.733] iteration 18658 : model1 loss : 0.234587 model2 loss : 0.279332
[23:38:19.059] iteration 18659 : model1 loss : 0.173494 model2 loss : 0.198187
[23:38:19.384] iteration 18660 : model1 loss : 0.259497 model2 loss : 0.321948
[23:38:19.710] iteration 18661 : model1 loss : 0.231124 model2 loss : 0.302520
[23:38:20.036] iteration 18662 : model1 loss : 0.280354 model2 loss : 0.318679
[23:38:20.362] iteration 18663 : model1 loss : 0.132560 model2 loss : 0.125949
[23:38:20.687] iteration 18664 : model1 loss : 0.245394 model2 loss : 0.293877
[23:38:21.013] iteration 18665 : model1 loss : 0.250447 model2 loss : 0.246727
[23:38:21.340] iteration 18666 : model1 loss : 0.200220 model2 loss : 0.237445
[23:38:21.665] iteration 18667 : model1 loss : 0.178663 model2 loss : 0.194435
[23:38:21.991] iteration 18668 : model1 loss : 0.087136 model2 loss : 0.092996
[23:38:22.317] iteration 18669 : model1 loss : 0.186320 model2 loss : 0.238435
[23:38:22.643] iteration 18670 : model1 loss : 0.190498 model2 loss : 0.211638
[23:38:22.969] iteration 18671 : model1 loss : 0.172196 model2 loss : 0.241161
[23:38:23.294] iteration 18672 : model1 loss : 0.109034 model2 loss : 0.148541
[23:38:23.619] iteration 18673 : model1 loss : 0.273776 model2 loss : 0.335319
[23:38:23.945] iteration 18674 : model1 loss : 0.204557 model2 loss : 0.281888
[23:38:24.270] iteration 18675 : model1 loss : 0.213647 model2 loss : 0.251056
[23:38:24.596] iteration 18676 : model1 loss : 0.121827 model2 loss : 0.214578
[23:38:24.922] iteration 18677 : model1 loss : 0.115377 model2 loss : 0.127854
[23:38:25.248] iteration 18678 : model1 loss : 0.161598 model2 loss : 0.189720
[23:38:25.573] iteration 18679 : model1 loss : 0.227545 model2 loss : 0.243903
[23:38:25.899] iteration 18680 : model1 loss : 0.187472 model2 loss : 0.249478
[23:38:26.226] iteration 18681 : model1 loss : 0.233376 model2 loss : 0.209785
[23:38:26.551] iteration 18682 : model1 loss : 0.246614 model2 loss : 0.256293
[23:38:26.878] iteration 18683 : model1 loss : 0.268088 model2 loss : 0.359466
[23:38:27.206] iteration 18684 : model1 loss : 0.264333 model2 loss : 0.352154
[23:38:27.533] iteration 18685 : model1 loss : 0.171034 model2 loss : 0.203513
[23:38:27.860] iteration 18686 : model1 loss : 0.163725 model2 loss : 0.126270
[23:38:28.185] iteration 18687 : model1 loss : 0.179427 model2 loss : 0.301572
[23:38:28.510] iteration 18688 : model1 loss : 0.074081 model2 loss : 0.077491
[23:38:28.836] iteration 18689 : model1 loss : 0.185623 model2 loss : 0.209653
[23:38:29.162] iteration 18690 : model1 loss : 0.190736 model2 loss : 0.194235
[23:38:29.487] iteration 18691 : model1 loss : 0.367213 model2 loss : 0.405112
[23:38:29.813] iteration 18692 : model1 loss : 0.335419 model2 loss : 0.366237
[23:38:30.139] iteration 18693 : model1 loss : 0.248010 model2 loss : 0.275161
[23:38:30.466] iteration 18694 : model1 loss : 0.065347 model2 loss : 0.144325
[23:38:30.791] iteration 18695 : model1 loss : 0.190541 model2 loss : 0.210209
[23:38:31.117] iteration 18696 : model1 loss : 0.131112 model2 loss : 0.143730
[23:38:31.443] iteration 18697 : model1 loss : 0.103341 model2 loss : 0.148732
[23:38:31.768] iteration 18698 : model1 loss : 0.315321 model2 loss : 0.319570
[23:38:32.094] iteration 18699 : model1 loss : 0.154447 model2 loss : 0.312423
[23:38:32.420] iteration 18700 : model1 loss : 0.232166 model2 loss : 0.281194
[23:38:32.918] iteration 18701 : model1 loss : 0.210956 model2 loss : 0.201591
[23:38:33.244] iteration 18702 : model1 loss : 0.095890 model2 loss : 0.114616
[23:38:33.570] iteration 18703 : model1 loss : 0.279690 model2 loss : 0.328323
[23:38:33.896] iteration 18704 : model1 loss : 0.120119 model2 loss : 0.161583
[23:38:34.223] iteration 18705 : model1 loss : 0.214699 model2 loss : 0.290499
[23:38:34.549] iteration 18706 : model1 loss : 0.208156 model2 loss : 0.262593
[23:38:34.876] iteration 18707 : model1 loss : 0.086415 model2 loss : 0.114714
[23:38:35.202] iteration 18708 : model1 loss : 0.396467 model2 loss : 0.411579
[23:38:35.529] iteration 18709 : model1 loss : 0.202065 model2 loss : 0.206291
[23:38:35.856] iteration 18710 : model1 loss : 0.229777 model2 loss : 0.284661
[23:38:36.181] iteration 18711 : model1 loss : 0.199433 model2 loss : 0.231251
[23:38:36.508] iteration 18712 : model1 loss : 0.244375 model2 loss : 0.220636
[23:38:36.833] iteration 18713 : model1 loss : 0.116524 model2 loss : 0.168060
[23:38:37.159] iteration 18714 : model1 loss : 0.206335 model2 loss : 0.219413
[23:38:37.486] iteration 18715 : model1 loss : 0.165470 model2 loss : 0.214234
[23:38:37.812] iteration 18716 : model1 loss : 0.190763 model2 loss : 0.239641
[23:38:38.138] iteration 18717 : model1 loss : 0.094082 model2 loss : 0.117429
[23:38:38.464] iteration 18718 : model1 loss : 0.144639 model2 loss : 0.162557
[23:38:38.790] iteration 18719 : model1 loss : 0.182290 model2 loss : 0.195059
[23:38:39.116] iteration 18720 : model1 loss : 0.255710 model2 loss : 0.309046
[23:38:39.443] iteration 18721 : model1 loss : 0.241785 model2 loss : 0.319304
[23:38:39.769] iteration 18722 : model1 loss : 0.192853 model2 loss : 0.215610
[23:38:40.095] iteration 18723 : model1 loss : 0.278947 model2 loss : 0.332482
[23:38:40.422] iteration 18724 : model1 loss : 0.162372 model2 loss : 0.217293
[23:38:40.749] iteration 18725 : model1 loss : 0.171859 model2 loss : 0.247949
[23:38:41.074] iteration 18726 : model1 loss : 0.187760 model2 loss : 0.189131
[23:38:41.400] iteration 18727 : model1 loss : 0.092771 model2 loss : 0.111721
[23:38:41.725] iteration 18728 : model1 loss : 0.135371 model2 loss : 0.170538
[23:38:42.050] iteration 18729 : model1 loss : 0.202505 model2 loss : 0.181918
[23:38:42.377] iteration 18730 : model1 loss : 0.260755 model2 loss : 0.294042
[23:38:42.703] iteration 18731 : model1 loss : 0.120147 model2 loss : 0.108626
[23:38:43.028] iteration 18732 : model1 loss : 0.186525 model2 loss : 0.279802
[23:38:43.356] iteration 18733 : model1 loss : 0.128865 model2 loss : 0.255999
[23:38:43.680] iteration 18734 : model1 loss : 0.188433 model2 loss : 0.214395
[23:38:44.007] iteration 18735 : model1 loss : 0.162246 model2 loss : 0.199150
[23:38:44.332] iteration 18736 : model1 loss : 0.193257 model2 loss : 0.253921
[23:38:44.658] iteration 18737 : model1 loss : 0.170228 model2 loss : 0.179285
[23:38:44.985] iteration 18738 : model1 loss : 0.174604 model2 loss : 0.206775
[23:38:45.313] iteration 18739 : model1 loss : 0.101320 model2 loss : 0.124994
[23:38:45.638] iteration 18740 : model1 loss : 0.115375 model2 loss : 0.129354
[23:38:45.966] iteration 18741 : model1 loss : 0.263542 model2 loss : 0.278412
[23:38:46.292] iteration 18742 : model1 loss : 0.149729 model2 loss : 0.172561
[23:38:46.618] iteration 18743 : model1 loss : 0.251579 model2 loss : 0.259116
[23:38:46.943] iteration 18744 : model1 loss : 0.228766 model2 loss : 0.253284
[23:38:47.271] iteration 18745 : model1 loss : 0.245373 model2 loss : 0.277073
[23:38:47.596] iteration 18746 : model1 loss : 0.195354 model2 loss : 0.216061
[23:38:47.922] iteration 18747 : model1 loss : 0.173559 model2 loss : 0.203625
[23:38:48.247] iteration 18748 : model1 loss : 0.239397 model2 loss : 0.277327
[23:38:48.573] iteration 18749 : model1 loss : 0.205579 model2 loss : 0.231320
[23:38:48.899] iteration 18750 : model1 loss : 0.241537 model2 loss : 0.260296
[23:38:49.403] iteration 18751 : model1 loss : 0.445067 model2 loss : 0.355073
[23:38:49.729] iteration 18752 : model1 loss : 0.135235 model2 loss : 0.188647
[23:38:50.058] iteration 18753 : model1 loss : 0.178121 model2 loss : 0.291290
[23:38:50.385] iteration 18754 : model1 loss : 0.154831 model2 loss : 0.159863
[23:38:50.710] iteration 18755 : model1 loss : 0.273280 model2 loss : 0.286574
[23:38:51.037] iteration 18756 : model1 loss : 0.100269 model2 loss : 0.228469
[23:38:51.365] iteration 18757 : model1 loss : 0.312681 model2 loss : 0.350265
[23:38:51.691] iteration 18758 : model1 loss : 0.101672 model2 loss : 0.129511
[23:38:52.017] iteration 18759 : model1 loss : 0.292326 model2 loss : 0.296960
[23:38:52.342] iteration 18760 : model1 loss : 0.336107 model2 loss : 0.381346
[23:38:52.670] iteration 18761 : model1 loss : 0.265322 model2 loss : 0.313001
[23:38:52.996] iteration 18762 : model1 loss : 0.185152 model2 loss : 0.206800
[23:38:53.321] iteration 18763 : model1 loss : 0.215051 model2 loss : 0.235322
[23:38:53.647] iteration 18764 : model1 loss : 0.129252 model2 loss : 0.141820
[23:38:53.974] iteration 18765 : model1 loss : 0.202728 model2 loss : 0.269930
[23:38:54.299] iteration 18766 : model1 loss : 0.178966 model2 loss : 0.242070
[23:38:54.625] iteration 18767 : model1 loss : 0.179713 model2 loss : 0.209102
[23:38:54.951] iteration 18768 : model1 loss : 0.246894 model2 loss : 0.260558
[23:38:55.283] iteration 18769 : model1 loss : 0.180895 model2 loss : 0.214311
[23:38:55.608] iteration 18770 : model1 loss : 0.281716 model2 loss : 0.299891
[23:38:55.934] iteration 18771 : model1 loss : 0.193453 model2 loss : 0.222835
[23:38:56.260] iteration 18772 : model1 loss : 0.118091 model2 loss : 0.124662
[23:38:56.587] iteration 18773 : model1 loss : 0.240328 model2 loss : 0.284081
[23:38:56.913] iteration 18774 : model1 loss : 0.224217 model2 loss : 0.260626
[23:38:57.237] iteration 18775 : model1 loss : 0.163163 model2 loss : 0.175831
[23:38:57.564] iteration 18776 : model1 loss : 0.115490 model2 loss : 0.187970
[23:38:57.892] iteration 18777 : model1 loss : 0.138687 model2 loss : 0.197111
[23:38:58.219] iteration 18778 : model1 loss : 0.317291 model2 loss : 0.314447
[23:38:58.544] iteration 18779 : model1 loss : 0.164669 model2 loss : 0.219556
[23:38:58.870] iteration 18780 : model1 loss : 0.180378 model2 loss : 0.228152
[23:38:59.197] iteration 18781 : model1 loss : 0.099117 model2 loss : 0.238532
[23:38:59.523] iteration 18782 : model1 loss : 0.272667 model2 loss : 0.275746
[23:38:59.849] iteration 18783 : model1 loss : 0.205217 model2 loss : 0.246870
[23:39:00.175] iteration 18784 : model1 loss : 0.192441 model2 loss : 0.194312
[23:39:00.503] iteration 18785 : model1 loss : 0.197577 model2 loss : 0.243260
[23:39:00.829] iteration 18786 : model1 loss : 0.250395 model2 loss : 0.258026
[23:39:01.154] iteration 18787 : model1 loss : 0.271143 model2 loss : 0.257680
[23:39:01.480] iteration 18788 : model1 loss : 0.249840 model2 loss : 0.260268
[23:39:01.807] iteration 18789 : model1 loss : 0.179696 model2 loss : 0.181680
[23:39:02.140] iteration 18790 : model1 loss : 0.170115 model2 loss : 0.227633
[23:39:02.467] iteration 18791 : model1 loss : 0.104458 model2 loss : 0.132681
[23:39:02.801] iteration 18792 : model1 loss : 0.168346 model2 loss : 0.236924
[23:39:03.133] iteration 18793 : model1 loss : 0.258261 model2 loss : 0.254122
[23:39:03.470] iteration 18794 : model1 loss : 0.200201 model2 loss : 0.193519
[23:39:03.807] iteration 18795 : model1 loss : 0.202847 model2 loss : 0.263648
[23:39:04.147] iteration 18796 : model1 loss : 0.275507 model2 loss : 0.299554
[23:39:04.482] iteration 18797 : model1 loss : 0.261172 model2 loss : 0.255081
[23:39:04.820] iteration 18798 : model1 loss : 0.306127 model2 loss : 0.379781
[23:39:05.163] iteration 18799 : model1 loss : 0.175838 model2 loss : 0.172236
[23:39:05.504] iteration 18800 : model1 loss : 0.156798 model2 loss : 0.191372
[23:39:06.141] iteration 18801 : model1 loss : 0.291856 model2 loss : 0.338140
[23:39:06.483] iteration 18802 : model1 loss : 0.137378 model2 loss : 0.202127
[23:39:06.820] iteration 18803 : model1 loss : 0.206783 model2 loss : 0.274014
[23:39:07.160] iteration 18804 : model1 loss : 0.200648 model2 loss : 0.176551
[23:39:07.499] iteration 18805 : model1 loss : 0.207373 model2 loss : 0.229600
[23:39:07.837] iteration 18806 : model1 loss : 0.176453 model2 loss : 0.196608
[23:39:08.175] iteration 18807 : model1 loss : 0.203064 model2 loss : 0.288284
[23:39:08.513] iteration 18808 : model1 loss : 0.201828 model2 loss : 0.196167
[23:39:08.855] iteration 18809 : model1 loss : 0.178446 model2 loss : 0.185552
[23:39:09.192] iteration 18810 : model1 loss : 0.222429 model2 loss : 0.242253
[23:39:09.528] iteration 18811 : model1 loss : 0.176735 model2 loss : 0.185340
[23:39:09.866] iteration 18812 : model1 loss : 0.199303 model2 loss : 0.214615
[23:39:10.208] iteration 18813 : model1 loss : 0.136512 model2 loss : 0.170184
[23:39:10.545] iteration 18814 : model1 loss : 0.098774 model2 loss : 0.095673
[23:39:10.884] iteration 18815 : model1 loss : 0.403296 model2 loss : 0.403671
[23:39:11.223] iteration 18816 : model1 loss : 0.081965 model2 loss : 0.120640
[23:39:11.565] iteration 18817 : model1 loss : 0.174231 model2 loss : 0.190407
[23:39:11.902] iteration 18818 : model1 loss : 0.094606 model2 loss : 0.160421
[23:39:12.239] iteration 18819 : model1 loss : 0.149737 model2 loss : 0.291285
[23:39:12.577] iteration 18820 : model1 loss : 0.193665 model2 loss : 0.241078
[23:39:12.915] iteration 18821 : model1 loss : 0.241454 model2 loss : 0.261598
[23:39:13.253] iteration 18822 : model1 loss : 0.326047 model2 loss : 0.346560
[23:39:13.592] iteration 18823 : model1 loss : 0.156243 model2 loss : 0.271489
[23:39:13.931] iteration 18824 : model1 loss : 0.197074 model2 loss : 0.206216
[23:39:14.267] iteration 18825 : model1 loss : 0.180726 model2 loss : 0.201182
[23:39:14.605] iteration 18826 : model1 loss : 0.247123 model2 loss : 0.261595
[23:39:14.941] iteration 18827 : model1 loss : 0.224676 model2 loss : 0.220370
[23:39:15.279] iteration 18828 : model1 loss : 0.184713 model2 loss : 0.174749
[23:39:15.622] iteration 18829 : model1 loss : 0.178129 model2 loss : 0.205480
[23:39:15.965] iteration 18830 : model1 loss : 0.075969 model2 loss : 0.123426
[23:39:16.306] iteration 18831 : model1 loss : 0.136927 model2 loss : 0.188085
[23:39:16.643] iteration 18832 : model1 loss : 0.203411 model2 loss : 0.209582
[23:39:16.981] iteration 18833 : model1 loss : 0.204057 model2 loss : 0.202616
[23:39:17.317] iteration 18834 : model1 loss : 0.336989 model2 loss : 0.354698
[23:39:17.660] iteration 18835 : model1 loss : 0.229438 model2 loss : 0.288575
[23:39:18.001] iteration 18836 : model1 loss : 0.263900 model2 loss : 0.311296
[23:39:18.342] iteration 18837 : model1 loss : 0.106089 model2 loss : 0.139278
[23:39:18.680] iteration 18838 : model1 loss : 0.180882 model2 loss : 0.206926
[23:39:19.018] iteration 18839 : model1 loss : 0.264292 model2 loss : 0.292360
[23:39:19.355] iteration 18840 : model1 loss : 0.156060 model2 loss : 0.196818
[23:39:19.692] iteration 18841 : model1 loss : 0.161495 model2 loss : 0.173908
[23:39:20.034] iteration 18842 : model1 loss : 0.169248 model2 loss : 0.170458
[23:39:20.372] iteration 18843 : model1 loss : 0.172455 model2 loss : 0.224967
[23:39:20.713] iteration 18844 : model1 loss : 0.215311 model2 loss : 0.242095
[23:39:21.050] iteration 18845 : model1 loss : 0.194363 model2 loss : 0.221193
[23:39:21.388] iteration 18846 : model1 loss : 0.193850 model2 loss : 0.203187
[23:39:21.729] iteration 18847 : model1 loss : 0.234366 model2 loss : 0.200176
[23:39:22.083] iteration 18848 : model1 loss : 0.271171 model2 loss : 0.253234
[23:39:22.420] iteration 18849 : model1 loss : 0.111010 model2 loss : 0.159406
[23:39:22.759] iteration 18850 : model1 loss : 0.244305 model2 loss : 0.261152
[23:39:23.420] iteration 18851 : model1 loss : 0.172944 model2 loss : 0.192248
[23:39:23.758] iteration 18852 : model1 loss : 0.180841 model2 loss : 0.242287
[23:39:24.096] iteration 18853 : model1 loss : 0.102012 model2 loss : 0.143979
[23:39:24.434] iteration 18854 : model1 loss : 0.328880 model2 loss : 0.376090
[23:39:24.771] iteration 18855 : model1 loss : 0.178284 model2 loss : 0.214478
[23:39:25.110] iteration 18856 : model1 loss : 0.259480 model2 loss : 0.291082
[23:39:25.450] iteration 18857 : model1 loss : 0.244032 model2 loss : 0.257667
[23:39:25.793] iteration 18858 : model1 loss : 0.178503 model2 loss : 0.206721
[23:39:26.148] iteration 18859 : model1 loss : 0.200999 model2 loss : 0.193022
[23:39:26.485] iteration 18860 : model1 loss : 0.203584 model2 loss : 0.240163
[23:39:26.824] iteration 18861 : model1 loss : 0.185199 model2 loss : 0.172242
[23:39:27.161] iteration 18862 : model1 loss : 0.199198 model2 loss : 0.199385
[23:39:27.498] iteration 18863 : model1 loss : 0.199821 model2 loss : 0.204855
[23:39:27.838] iteration 18864 : model1 loss : 0.100653 model2 loss : 0.135631
[23:39:28.175] iteration 18865 : model1 loss : 0.163278 model2 loss : 0.176876
[23:39:28.514] iteration 18866 : model1 loss : 0.176140 model2 loss : 0.210266
[23:39:28.852] iteration 18867 : model1 loss : 0.145688 model2 loss : 0.179809
[23:39:29.182] iteration 18868 : model1 loss : 0.253411 model2 loss : 0.358864
[23:39:29.511] iteration 18869 : model1 loss : 0.264689 model2 loss : 0.320133
[23:39:29.839] iteration 18870 : model1 loss : 0.299808 model2 loss : 0.300891
[23:39:30.167] iteration 18871 : model1 loss : 0.162807 model2 loss : 0.202267
[23:39:30.495] iteration 18872 : model1 loss : 0.120466 model2 loss : 0.143166
[23:39:30.823] iteration 18873 : model1 loss : 0.254984 model2 loss : 0.275501
[23:39:31.151] iteration 18874 : model1 loss : 0.094256 model2 loss : 0.114696
[23:39:31.481] iteration 18875 : model1 loss : 0.113061 model2 loss : 0.124367
[23:39:31.812] iteration 18876 : model1 loss : 0.155403 model2 loss : 0.218328
[23:39:32.139] iteration 18877 : model1 loss : 0.069430 model2 loss : 0.098813
[23:39:32.468] iteration 18878 : model1 loss : 0.279509 model2 loss : 0.268836
[23:39:32.796] iteration 18879 : model1 loss : 0.230678 model2 loss : 0.235914
[23:39:33.126] iteration 18880 : model1 loss : 0.188650 model2 loss : 0.216609
[23:39:33.456] iteration 18881 : model1 loss : 0.251909 model2 loss : 0.349486
[23:39:33.785] iteration 18882 : model1 loss : 0.229880 model2 loss : 0.229154
[23:39:34.115] iteration 18883 : model1 loss : 0.101920 model2 loss : 0.166477
[23:39:34.446] iteration 18884 : model1 loss : 0.172368 model2 loss : 0.214286
[23:39:34.774] iteration 18885 : model1 loss : 0.167893 model2 loss : 0.154481
[23:39:35.106] iteration 18886 : model1 loss : 0.182233 model2 loss : 0.217609
[23:39:35.437] iteration 18887 : model1 loss : 0.166081 model2 loss : 0.183289
[23:39:35.765] iteration 18888 : model1 loss : 0.169922 model2 loss : 0.219209
[23:39:36.093] iteration 18889 : model1 loss : 0.204427 model2 loss : 0.239296
[23:39:36.421] iteration 18890 : model1 loss : 0.207575 model2 loss : 0.225270
[23:39:36.751] iteration 18891 : model1 loss : 0.164709 model2 loss : 0.179754
[23:39:37.080] iteration 18892 : model1 loss : 0.087684 model2 loss : 0.253106
[23:39:37.408] iteration 18893 : model1 loss : 0.248801 model2 loss : 0.288378
[23:39:37.739] iteration 18894 : model1 loss : 0.228983 model2 loss : 0.277609
[23:39:38.069] iteration 18895 : model1 loss : 0.239642 model2 loss : 0.248526
[23:39:38.397] iteration 18896 : model1 loss : 0.192480 model2 loss : 0.212661
[23:39:38.728] iteration 18897 : model1 loss : 0.271117 model2 loss : 0.286449
[23:39:39.056] iteration 18898 : model1 loss : 0.191566 model2 loss : 0.247869
[23:39:39.385] iteration 18899 : model1 loss : 0.125747 model2 loss : 0.209036
[23:39:39.714] iteration 18900 : model1 loss : 0.290770 model2 loss : 0.386293
[23:39:40.263] iteration 18901 : model1 loss : 0.242438 model2 loss : 0.266357
[23:39:40.592] iteration 18902 : model1 loss : 0.178146 model2 loss : 0.195206
[23:39:40.920] iteration 18903 : model1 loss : 0.175054 model2 loss : 0.203484
[23:39:41.250] iteration 18904 : model1 loss : 0.355702 model2 loss : 0.329997
[23:39:41.578] iteration 18905 : model1 loss : 0.284757 model2 loss : 0.317905
[23:39:41.906] iteration 18906 : model1 loss : 0.221625 model2 loss : 0.344455
[23:39:42.235] iteration 18907 : model1 loss : 0.157343 model2 loss : 0.186176
[23:39:42.563] iteration 18908 : model1 loss : 0.115673 model2 loss : 0.188091
[23:39:42.893] iteration 18909 : model1 loss : 0.061988 model2 loss : 0.083598
[23:39:43.220] iteration 18910 : model1 loss : 0.200596 model2 loss : 0.262034
[23:39:43.549] iteration 18911 : model1 loss : 0.399521 model2 loss : 0.368476
[23:39:43.878] iteration 18912 : model1 loss : 0.272427 model2 loss : 0.284627
[23:39:44.208] iteration 18913 : model1 loss : 0.199675 model2 loss : 0.215428
[23:39:44.544] iteration 18914 : model1 loss : 0.176816 model2 loss : 0.174660
[23:39:44.873] iteration 18915 : model1 loss : 0.073624 model2 loss : 0.107650
[23:39:45.206] iteration 18916 : model1 loss : 0.113723 model2 loss : 0.204359
[23:39:45.534] iteration 18917 : model1 loss : 0.088394 model2 loss : 0.138074
[23:39:45.863] iteration 18918 : model1 loss : 0.264858 model2 loss : 0.250282
[23:39:46.195] iteration 18919 : model1 loss : 0.255697 model2 loss : 0.337816
[23:39:46.525] iteration 18920 : model1 loss : 0.208496 model2 loss : 0.246861
[23:39:46.855] iteration 18921 : model1 loss : 0.193056 model2 loss : 0.239180
[23:39:47.183] iteration 18922 : model1 loss : 0.098878 model2 loss : 0.103266
[23:39:47.513] iteration 18923 : model1 loss : 0.246154 model2 loss : 0.236602
[23:39:47.841] iteration 18924 : model1 loss : 0.251066 model2 loss : 0.262123
[23:39:48.170] iteration 18925 : model1 loss : 0.264821 model2 loss : 0.278594
[23:39:48.498] iteration 18926 : model1 loss : 0.180773 model2 loss : 0.197579
[23:39:48.826] iteration 18927 : model1 loss : 0.273206 model2 loss : 0.283185
[23:39:49.155] iteration 18928 : model1 loss : 0.199493 model2 loss : 0.220265
[23:39:49.484] iteration 18929 : model1 loss : 0.164460 model2 loss : 0.283729
[23:39:49.812] iteration 18930 : model1 loss : 0.152529 model2 loss : 0.162970
[23:39:50.144] iteration 18931 : model1 loss : 0.203103 model2 loss : 0.254698
[23:39:50.474] iteration 18932 : model1 loss : 0.177491 model2 loss : 0.231827
[23:39:50.804] iteration 18933 : model1 loss : 0.155506 model2 loss : 0.261962
[23:39:51.131] iteration 18934 : model1 loss : 0.208712 model2 loss : 0.238503
[23:39:51.460] iteration 18935 : model1 loss : 0.283508 model2 loss : 0.296364
[23:39:51.790] iteration 18936 : model1 loss : 0.109639 model2 loss : 0.245363
[23:39:52.118] iteration 18937 : model1 loss : 0.232622 model2 loss : 0.278815
[23:39:52.446] iteration 18938 : model1 loss : 0.210656 model2 loss : 0.246141
[23:39:52.776] iteration 18939 : model1 loss : 0.175820 model2 loss : 0.188733
[23:39:53.104] iteration 18940 : model1 loss : 0.100516 model2 loss : 0.129157
[23:39:53.432] iteration 18941 : model1 loss : 0.175177 model2 loss : 0.194667
[23:39:53.760] iteration 18942 : model1 loss : 0.277818 model2 loss : 0.303606
[23:39:54.092] iteration 18943 : model1 loss : 0.214540 model2 loss : 0.250912
[23:39:54.420] iteration 18944 : model1 loss : 0.114961 model2 loss : 0.135387
[23:39:54.749] iteration 18945 : model1 loss : 0.236062 model2 loss : 0.240023
[23:39:55.077] iteration 18946 : model1 loss : 0.305238 model2 loss : 0.272893
[23:39:55.407] iteration 18947 : model1 loss : 0.288034 model2 loss : 0.346912
[23:39:55.735] iteration 18948 : model1 loss : 0.103661 model2 loss : 0.114569
[23:39:56.062] iteration 18949 : model1 loss : 0.217854 model2 loss : 0.299442
[23:39:56.391] iteration 18950 : model1 loss : 0.156371 model2 loss : 0.173809
[23:39:56.951] iteration 18951 : model1 loss : 0.195809 model2 loss : 0.233634
[23:39:57.280] iteration 18952 : model1 loss : 0.133793 model2 loss : 0.188223
[23:39:57.611] iteration 18953 : model1 loss : 0.247990 model2 loss : 0.290515
[23:39:57.939] iteration 18954 : model1 loss : 0.143098 model2 loss : 0.162222
[23:39:58.268] iteration 18955 : model1 loss : 0.148660 model2 loss : 0.176564
[23:39:58.595] iteration 18956 : model1 loss : 0.379360 model2 loss : 0.393879
[23:39:58.923] iteration 18957 : model1 loss : 0.243682 model2 loss : 0.282843
[23:39:59.250] iteration 18958 : model1 loss : 0.167611 model2 loss : 0.175217
[23:39:59.578] iteration 18959 : model1 loss : 0.268499 model2 loss : 0.289154
[23:39:59.906] iteration 18960 : model1 loss : 0.220017 model2 loss : 0.244364
[23:40:00.235] iteration 18961 : model1 loss : 0.169924 model2 loss : 0.179719
[23:40:00.563] iteration 18962 : model1 loss : 0.150859 model2 loss : 0.199631
[23:40:00.891] iteration 18963 : model1 loss : 0.147422 model2 loss : 0.192830
[23:40:01.218] iteration 18964 : model1 loss : 0.189406 model2 loss : 0.183017
[23:40:01.546] iteration 18965 : model1 loss : 0.269653 model2 loss : 0.297931
[23:40:01.874] iteration 18966 : model1 loss : 0.179520 model2 loss : 0.172039
[23:40:02.202] iteration 18967 : model1 loss : 0.258415 model2 loss : 0.279546
[23:40:02.530] iteration 18968 : model1 loss : 0.180199 model2 loss : 0.202267
[23:40:02.858] iteration 18969 : model1 loss : 0.105198 model2 loss : 0.141264
[23:40:03.188] iteration 18970 : model1 loss : 0.269300 model2 loss : 0.236455
[23:40:03.518] iteration 18971 : model1 loss : 0.100029 model2 loss : 0.119230
[23:40:03.846] iteration 18972 : model1 loss : 0.265337 model2 loss : 0.288393
[23:40:04.175] iteration 18973 : model1 loss : 0.266839 model2 loss : 0.311208
[23:40:04.503] iteration 18974 : model1 loss : 0.166582 model2 loss : 0.200003
[23:40:04.831] iteration 18975 : model1 loss : 0.140026 model2 loss : 0.284609
[23:40:05.159] iteration 18976 : model1 loss : 0.172859 model2 loss : 0.193145
[23:40:05.490] iteration 18977 : model1 loss : 0.235027 model2 loss : 0.265536
[23:40:05.821] iteration 18978 : model1 loss : 0.284386 model2 loss : 0.288257
[23:40:06.149] iteration 18979 : model1 loss : 0.226654 model2 loss : 0.278135
[23:40:06.479] iteration 18980 : model1 loss : 0.123517 model2 loss : 0.137397
[23:40:06.811] iteration 18981 : model1 loss : 0.248381 model2 loss : 0.256999
[23:40:07.150] iteration 18982 : model1 loss : 0.107106 model2 loss : 0.118118
[23:40:07.491] iteration 18983 : model1 loss : 0.209039 model2 loss : 0.196293
[23:40:07.829] iteration 18984 : model1 loss : 0.101039 model2 loss : 0.127416
[23:40:08.168] iteration 18985 : model1 loss : 0.257070 model2 loss : 0.299788
[23:40:08.506] iteration 18986 : model1 loss : 0.197309 model2 loss : 0.244921
[23:40:08.851] iteration 18987 : model1 loss : 0.236757 model2 loss : 0.245510
[23:40:09.190] iteration 18988 : model1 loss : 0.129552 model2 loss : 0.182835
[23:40:09.529] iteration 18989 : model1 loss : 0.159538 model2 loss : 0.243524
[23:40:09.871] iteration 18990 : model1 loss : 0.256641 model2 loss : 0.231166
[23:40:10.214] iteration 18991 : model1 loss : 0.168793 model2 loss : 0.255300
[23:40:10.559] iteration 18992 : model1 loss : 0.198786 model2 loss : 0.225820
[23:40:10.898] iteration 18993 : model1 loss : 0.277920 model2 loss : 0.306740
[23:40:11.239] iteration 18994 : model1 loss : 0.288283 model2 loss : 0.293601
[23:40:11.577] iteration 18995 : model1 loss : 0.123660 model2 loss : 0.214848
[23:40:11.914] iteration 18996 : model1 loss : 0.229096 model2 loss : 0.236899
[23:40:12.252] iteration 18997 : model1 loss : 0.231925 model2 loss : 0.292814
[23:40:12.590] iteration 18998 : model1 loss : 0.216600 model2 loss : 0.290924
[23:40:12.936] iteration 18999 : model1 loss : 0.339260 model2 loss : 0.353099
[23:40:13.272] iteration 19000 : model1 loss : 0.205574 model2 loss : 0.244842
[23:40:13.916] iteration 19001 : model1 loss : 0.168496 model2 loss : 0.215702
[23:40:14.254] iteration 19002 : model1 loss : 0.082301 model2 loss : 0.112115
[23:40:14.592] iteration 19003 : model1 loss : 0.179533 model2 loss : 0.218628
[23:40:14.929] iteration 19004 : model1 loss : 0.216594 model2 loss : 0.208439
[23:40:15.266] iteration 19005 : model1 loss : 0.248417 model2 loss : 0.292345
[23:40:15.603] iteration 19006 : model1 loss : 0.254675 model2 loss : 0.248349
[23:40:15.939] iteration 19007 : model1 loss : 0.134318 model2 loss : 0.132363
[23:40:16.276] iteration 19008 : model1 loss : 0.244022 model2 loss : 0.328750
[23:40:16.614] iteration 19009 : model1 loss : 0.177687 model2 loss : 0.196277
[23:40:16.952] iteration 19010 : model1 loss : 0.214336 model2 loss : 0.206048
[23:40:17.289] iteration 19011 : model1 loss : 0.231106 model2 loss : 0.260619
[23:40:17.626] iteration 19012 : model1 loss : 0.260998 model2 loss : 0.291225
[23:40:17.964] iteration 19013 : model1 loss : 0.208703 model2 loss : 0.249477
[23:40:18.302] iteration 19014 : model1 loss : 0.182957 model2 loss : 0.243784
[23:40:18.639] iteration 19015 : model1 loss : 0.147649 model2 loss : 0.217197
[23:40:18.977] iteration 19016 : model1 loss : 0.182240 model2 loss : 0.195928
[23:40:19.316] iteration 19017 : model1 loss : 0.297463 model2 loss : 0.326679
[23:40:19.653] iteration 19018 : model1 loss : 0.187474 model2 loss : 0.192686
[23:40:19.990] iteration 19019 : model1 loss : 0.119732 model2 loss : 0.242040
[23:40:20.328] iteration 19020 : model1 loss : 0.214153 model2 loss : 0.285723
[23:40:20.667] iteration 19021 : model1 loss : 0.274214 model2 loss : 0.279383
[23:40:21.003] iteration 19022 : model1 loss : 0.193008 model2 loss : 0.247702
[23:40:21.340] iteration 19023 : model1 loss : 0.114274 model2 loss : 0.109731
[23:40:21.678] iteration 19024 : model1 loss : 0.262567 model2 loss : 0.274188
[23:40:22.020] iteration 19025 : model1 loss : 0.194854 model2 loss : 0.211392
[23:40:22.357] iteration 19026 : model1 loss : 0.230633 model2 loss : 0.218718
[23:40:22.694] iteration 19027 : model1 loss : 0.139782 model2 loss : 0.187690
[23:40:23.032] iteration 19028 : model1 loss : 0.257327 model2 loss : 0.295944
[23:40:23.369] iteration 19029 : model1 loss : 0.180062 model2 loss : 0.221817
[23:40:23.707] iteration 19030 : model1 loss : 0.230527 model2 loss : 0.271020
[23:40:24.042] iteration 19031 : model1 loss : 0.271483 model2 loss : 0.330501
[23:40:24.379] iteration 19032 : model1 loss : 0.177007 model2 loss : 0.205769
[23:40:24.716] iteration 19033 : model1 loss : 0.329087 model2 loss : 0.339379
[23:40:25.055] iteration 19034 : model1 loss : 0.238785 model2 loss : 0.245962
[23:40:25.394] iteration 19035 : model1 loss : 0.285183 model2 loss : 0.283998
[23:40:25.732] iteration 19036 : model1 loss : 0.183229 model2 loss : 0.230268
[23:40:26.069] iteration 19037 : model1 loss : 0.263474 model2 loss : 0.278898
[23:40:26.407] iteration 19038 : model1 loss : 0.226911 model2 loss : 0.279083
[23:40:26.743] iteration 19039 : model1 loss : 0.189048 model2 loss : 0.197255
[23:40:27.081] iteration 19040 : model1 loss : 0.114491 model2 loss : 0.110221
[23:40:27.419] iteration 19041 : model1 loss : 0.192416 model2 loss : 0.255091
[23:40:27.756] iteration 19042 : model1 loss : 0.202317 model2 loss : 0.263496
[23:40:28.096] iteration 19043 : model1 loss : 0.104985 model2 loss : 0.170163
[23:40:28.434] iteration 19044 : model1 loss : 0.296821 model2 loss : 0.308171
[23:40:28.770] iteration 19045 : model1 loss : 0.250006 model2 loss : 0.258697
[23:40:29.107] iteration 19046 : model1 loss : 0.237895 model2 loss : 0.253838
[23:40:29.444] iteration 19047 : model1 loss : 0.267565 model2 loss : 0.275007
[23:40:29.781] iteration 19048 : model1 loss : 0.181315 model2 loss : 0.243162
[23:40:30.122] iteration 19049 : model1 loss : 0.119156 model2 loss : 0.189957
[23:40:30.463] iteration 19050 : model1 loss : 0.211204 model2 loss : 0.217119
[23:40:31.114] iteration 19051 : model1 loss : 0.244897 model2 loss : 0.265561
[23:40:31.451] iteration 19052 : model1 loss : 0.234500 model2 loss : 0.309940
[23:40:31.790] iteration 19053 : model1 loss : 0.245766 model2 loss : 0.282227
[23:40:32.131] iteration 19054 : model1 loss : 0.196723 model2 loss : 0.224976
[23:40:32.468] iteration 19055 : model1 loss : 0.125859 model2 loss : 0.090674
[23:40:32.806] iteration 19056 : model1 loss : 0.164641 model2 loss : 0.244604
[23:40:33.146] iteration 19057 : model1 loss : 0.338002 model2 loss : 0.347811
[23:40:33.487] iteration 19058 : model1 loss : 0.153128 model2 loss : 0.268883
[23:40:33.828] iteration 19059 : model1 loss : 0.233295 model2 loss : 0.262313
[23:40:34.170] iteration 19060 : model1 loss : 0.226252 model2 loss : 0.235151
[23:40:34.506] iteration 19061 : model1 loss : 0.284409 model2 loss : 0.301795
[23:40:34.843] iteration 19062 : model1 loss : 0.250002 model2 loss : 0.237771
[23:40:35.179] iteration 19063 : model1 loss : 0.298218 model2 loss : 0.230793
[23:40:35.519] iteration 19064 : model1 loss : 0.292372 model2 loss : 0.273030
[23:40:35.857] iteration 19065 : model1 loss : 0.143793 model2 loss : 0.185945
[23:40:36.199] iteration 19066 : model1 loss : 0.315399 model2 loss : 0.327079
[23:40:36.540] iteration 19067 : model1 loss : 0.098093 model2 loss : 0.126435
[23:40:36.877] iteration 19068 : model1 loss : 0.183984 model2 loss : 0.296381
[23:40:37.216] iteration 19069 : model1 loss : 0.190607 model2 loss : 0.235077
[23:40:37.550] iteration 19070 : model1 loss : 0.175589 model2 loss : 0.261702
[23:40:37.885] iteration 19071 : model1 loss : 0.137394 model2 loss : 0.145266
[23:40:38.221] iteration 19072 : model1 loss : 0.095509 model2 loss : 0.089969
[23:40:38.556] iteration 19073 : model1 loss : 0.117592 model2 loss : 0.131158
[23:40:38.895] iteration 19074 : model1 loss : 0.228006 model2 loss : 0.233753
[23:40:39.230] iteration 19075 : model1 loss : 0.237093 model2 loss : 0.204024
[23:40:40.284] iteration 19076 : model1 loss : 0.364784 model2 loss : 0.292933
[23:40:40.612] iteration 19077 : model1 loss : 0.184947 model2 loss : 0.177439
[23:40:40.946] iteration 19078 : model1 loss : 0.206874 model2 loss : 0.252560
[23:40:41.276] iteration 19079 : model1 loss : 0.222612 model2 loss : 0.255921
[23:40:41.609] iteration 19080 : model1 loss : 0.114094 model2 loss : 0.121303
[23:40:41.937] iteration 19081 : model1 loss : 0.215584 model2 loss : 0.304105
[23:40:42.268] iteration 19082 : model1 loss : 0.102216 model2 loss : 0.137601
[23:40:42.598] iteration 19083 : model1 loss : 0.245474 model2 loss : 0.299616
[23:40:42.927] iteration 19084 : model1 loss : 0.293110 model2 loss : 0.310798
[23:40:43.255] iteration 19085 : model1 loss : 0.113166 model2 loss : 0.180577
[23:40:43.590] iteration 19086 : model1 loss : 0.192977 model2 loss : 0.247083
[23:40:43.918] iteration 19087 : model1 loss : 0.181618 model2 loss : 0.199644
[23:40:44.246] iteration 19088 : model1 loss : 0.318464 model2 loss : 0.351779
[23:40:44.573] iteration 19089 : model1 loss : 0.254055 model2 loss : 0.282464
[23:40:44.901] iteration 19090 : model1 loss : 0.214751 model2 loss : 0.239633
[23:40:45.229] iteration 19091 : model1 loss : 0.248326 model2 loss : 0.247926
[23:40:45.563] iteration 19092 : model1 loss : 0.253277 model2 loss : 0.259140
[23:40:45.895] iteration 19093 : model1 loss : 0.264347 model2 loss : 0.296648
[23:40:46.223] iteration 19094 : model1 loss : 0.167589 model2 loss : 0.188177
[23:40:46.552] iteration 19095 : model1 loss : 0.198649 model2 loss : 0.277193
[23:40:46.879] iteration 19096 : model1 loss : 0.205247 model2 loss : 0.189660
[23:40:47.207] iteration 19097 : model1 loss : 0.096709 model2 loss : 0.244656
[23:40:47.534] iteration 19098 : model1 loss : 0.129880 model2 loss : 0.163567
[23:40:47.862] iteration 19099 : model1 loss : 0.156506 model2 loss : 0.233614
[23:40:48.193] iteration 19100 : model1 loss : 0.200612 model2 loss : 0.210450
[23:40:48.763] iteration 19101 : model1 loss : 0.231039 model2 loss : 0.238418
[23:40:49.091] iteration 19102 : model1 loss : 0.271660 model2 loss : 0.387823
[23:40:49.421] iteration 19103 : model1 loss : 0.315782 model2 loss : 0.323903
[23:40:49.749] iteration 19104 : model1 loss : 0.104729 model2 loss : 0.204548
[23:40:50.079] iteration 19105 : model1 loss : 0.236007 model2 loss : 0.259223
[23:40:50.407] iteration 19106 : model1 loss : 0.231483 model2 loss : 0.312869
[23:40:50.735] iteration 19107 : model1 loss : 0.158865 model2 loss : 0.207105
[23:40:51.063] iteration 19108 : model1 loss : 0.260002 model2 loss : 0.306420
[23:40:51.394] iteration 19109 : model1 loss : 0.091914 model2 loss : 0.161161
[23:40:51.722] iteration 19110 : model1 loss : 0.147763 model2 loss : 0.173323
[23:40:52.050] iteration 19111 : model1 loss : 0.249455 model2 loss : 0.276886
[23:40:52.378] iteration 19112 : model1 loss : 0.173011 model2 loss : 0.239377
[23:40:52.706] iteration 19113 : model1 loss : 0.261077 model2 loss : 0.235289
[23:40:53.036] iteration 19114 : model1 loss : 0.088936 model2 loss : 0.092651
[23:40:53.364] iteration 19115 : model1 loss : 0.327948 model2 loss : 0.355470
[23:40:53.692] iteration 19116 : model1 loss : 0.231107 model2 loss : 0.232718
[23:40:54.023] iteration 19117 : model1 loss : 0.205676 model2 loss : 0.276946
[23:40:54.351] iteration 19118 : model1 loss : 0.252601 model2 loss : 0.177425
[23:40:54.679] iteration 19119 : model1 loss : 0.191658 model2 loss : 0.218181
[23:40:55.008] iteration 19120 : model1 loss : 0.194290 model2 loss : 0.255129
[23:40:55.338] iteration 19121 : model1 loss : 0.215586 model2 loss : 0.206256
[23:40:55.666] iteration 19122 : model1 loss : 0.266366 model2 loss : 0.306320
[23:40:55.994] iteration 19123 : model1 loss : 0.181401 model2 loss : 0.207062
[23:40:56.330] iteration 19124 : model1 loss : 0.102861 model2 loss : 0.144063
[23:40:56.667] iteration 19125 : model1 loss : 0.173035 model2 loss : 0.228112
[23:40:57.000] iteration 19126 : model1 loss : 0.193464 model2 loss : 0.216616
[23:40:57.328] iteration 19127 : model1 loss : 0.252804 model2 loss : 0.293897
[23:40:57.659] iteration 19128 : model1 loss : 0.228640 model2 loss : 0.291359
[23:40:57.987] iteration 19129 : model1 loss : 0.172929 model2 loss : 0.166950
[23:40:58.315] iteration 19130 : model1 loss : 0.095028 model2 loss : 0.091660
[23:40:58.643] iteration 19131 : model1 loss : 0.275611 model2 loss : 0.230874
[23:40:58.978] iteration 19132 : model1 loss : 0.282193 model2 loss : 0.281958
[23:40:59.308] iteration 19133 : model1 loss : 0.177775 model2 loss : 0.198817
[23:40:59.637] iteration 19134 : model1 loss : 0.197395 model2 loss : 0.247323
[23:40:59.967] iteration 19135 : model1 loss : 0.181976 model2 loss : 0.221118
[23:41:00.302] iteration 19136 : model1 loss : 0.246264 model2 loss : 0.286519
[23:41:00.636] iteration 19137 : model1 loss : 0.096987 model2 loss : 0.246474
[23:41:00.964] iteration 19138 : model1 loss : 0.207228 model2 loss : 0.248495
[23:41:01.293] iteration 19139 : model1 loss : 0.181630 model2 loss : 0.185975
[23:41:01.629] iteration 19140 : model1 loss : 0.187314 model2 loss : 0.206271
[23:41:01.958] iteration 19141 : model1 loss : 0.241576 model2 loss : 0.226700
[23:41:02.288] iteration 19142 : model1 loss : 0.330906 model2 loss : 0.361647
[23:41:02.616] iteration 19143 : model1 loss : 0.296579 model2 loss : 0.279414
[23:41:02.945] iteration 19144 : model1 loss : 0.094018 model2 loss : 0.085508
[23:41:03.273] iteration 19145 : model1 loss : 0.118437 model2 loss : 0.149596
[23:41:03.602] iteration 19146 : model1 loss : 0.282760 model2 loss : 0.227913
[23:41:03.930] iteration 19147 : model1 loss : 0.270719 model2 loss : 0.269850
[23:41:04.262] iteration 19148 : model1 loss : 0.165913 model2 loss : 0.187855
[23:41:04.592] iteration 19149 : model1 loss : 0.242775 model2 loss : 0.229306
[23:41:04.928] iteration 19150 : model1 loss : 0.253775 model2 loss : 0.236115
[23:41:05.494] iteration 19151 : model1 loss : 0.091761 model2 loss : 0.127072
[23:41:05.829] iteration 19152 : model1 loss : 0.164565 model2 loss : 0.184679
[23:41:06.158] iteration 19153 : model1 loss : 0.125821 model2 loss : 0.190462
[23:41:06.487] iteration 19154 : model1 loss : 0.212918 model2 loss : 0.183123
[23:41:06.817] iteration 19155 : model1 loss : 0.246394 model2 loss : 0.265191
[23:41:07.151] iteration 19156 : model1 loss : 0.242960 model2 loss : 0.235623
[23:41:07.479] iteration 19157 : model1 loss : 0.181558 model2 loss : 0.211011
[23:41:07.806] iteration 19158 : model1 loss : 0.179084 model2 loss : 0.168549
[23:41:08.135] iteration 19159 : model1 loss : 0.180353 model2 loss : 0.180190
[23:41:08.466] iteration 19160 : model1 loss : 0.098236 model2 loss : 0.120619
[23:41:08.794] iteration 19161 : model1 loss : 0.165918 model2 loss : 0.184804
[23:41:09.122] iteration 19162 : model1 loss : 0.117033 model2 loss : 0.132270
[23:41:09.452] iteration 19163 : model1 loss : 0.139802 model2 loss : 0.177508
[23:41:09.785] iteration 19164 : model1 loss : 0.200105 model2 loss : 0.207618
[23:41:10.112] iteration 19165 : model1 loss : 0.159442 model2 loss : 0.158277
[23:41:10.440] iteration 19166 : model1 loss : 0.217414 model2 loss : 0.223136
[23:41:10.768] iteration 19167 : model1 loss : 0.252166 model2 loss : 0.255323
[23:41:11.101] iteration 19168 : model1 loss : 0.173484 model2 loss : 0.192587
[23:41:11.430] iteration 19169 : model1 loss : 0.165777 model2 loss : 0.193701
[23:41:11.758] iteration 19170 : model1 loss : 0.234276 model2 loss : 0.289447
[23:41:12.086] iteration 19171 : model1 loss : 0.177072 model2 loss : 0.225115
[23:41:12.418] iteration 19172 : model1 loss : 0.209866 model2 loss : 0.222999
[23:41:12.745] iteration 19173 : model1 loss : 0.259206 model2 loss : 0.292512
[23:41:13.073] iteration 19174 : model1 loss : 0.249606 model2 loss : 0.267561
[23:41:13.401] iteration 19175 : model1 loss : 0.175025 model2 loss : 0.200176
[23:41:13.731] iteration 19176 : model1 loss : 0.182359 model2 loss : 0.199814
[23:41:14.060] iteration 19177 : model1 loss : 0.136799 model2 loss : 0.180507
[23:41:14.389] iteration 19178 : model1 loss : 0.231542 model2 loss : 0.237294
[23:41:14.718] iteration 19179 : model1 loss : 0.185515 model2 loss : 0.206103
[23:41:15.049] iteration 19180 : model1 loss : 0.094285 model2 loss : 0.107034
[23:41:15.385] iteration 19181 : model1 loss : 0.114263 model2 loss : 0.246103
[23:41:15.718] iteration 19182 : model1 loss : 0.281598 model2 loss : 0.301228
[23:41:16.045] iteration 19183 : model1 loss : 0.194760 model2 loss : 0.252704
[23:41:16.380] iteration 19184 : model1 loss : 0.329656 model2 loss : 0.398640
[23:41:16.710] iteration 19185 : model1 loss : 0.109125 model2 loss : 0.163349
[23:41:17.039] iteration 19186 : model1 loss : 0.091625 model2 loss : 0.095572
[23:41:17.368] iteration 19187 : model1 loss : 0.211808 model2 loss : 0.204763
[23:41:17.700] iteration 19188 : model1 loss : 0.187372 model2 loss : 0.174113
[23:41:18.028] iteration 19189 : model1 loss : 0.176002 model2 loss : 0.212227
[23:41:18.356] iteration 19190 : model1 loss : 0.173358 model2 loss : 0.166110
[23:41:18.684] iteration 19191 : model1 loss : 0.118939 model2 loss : 0.167148
[23:41:19.017] iteration 19192 : model1 loss : 0.210623 model2 loss : 0.242337
[23:41:19.347] iteration 19193 : model1 loss : 0.251542 model2 loss : 0.257146
[23:41:19.676] iteration 19194 : model1 loss : 0.243314 model2 loss : 0.208835
[23:41:20.004] iteration 19195 : model1 loss : 0.170021 model2 loss : 0.231189
[23:41:20.336] iteration 19196 : model1 loss : 0.334399 model2 loss : 0.345309
[23:41:20.667] iteration 19197 : model1 loss : 0.178654 model2 loss : 0.186326
[23:41:20.995] iteration 19198 : model1 loss : 0.181460 model2 loss : 0.207954
[23:41:21.323] iteration 19199 : model1 loss : 0.200838 model2 loss : 0.220150
[23:41:21.655] iteration 19200 : model1 loss : 0.191533 model2 loss : 0.227991
[23:41:22.192] iteration 19201 : model1 loss : 0.179974 model2 loss : 0.238537
[23:41:22.522] iteration 19202 : model1 loss : 0.252310 model2 loss : 0.271103
[23:41:22.847] iteration 19203 : model1 loss : 0.304159 model2 loss : 0.276283
[23:41:23.179] iteration 19204 : model1 loss : 0.160678 model2 loss : 0.229304
[23:41:23.509] iteration 19205 : model1 loss : 0.249936 model2 loss : 0.259483
[23:41:23.837] iteration 19206 : model1 loss : 0.180260 model2 loss : 0.268056
[23:41:24.169] iteration 19207 : model1 loss : 0.339792 model2 loss : 0.347541
[23:41:24.500] iteration 19208 : model1 loss : 0.271073 model2 loss : 0.312716
[23:41:24.827] iteration 19209 : model1 loss : 0.289936 model2 loss : 0.335628
[23:41:25.155] iteration 19210 : model1 loss : 0.320836 model2 loss : 0.329583
[23:41:25.480] iteration 19211 : model1 loss : 0.163276 model2 loss : 0.165930
[23:41:25.811] iteration 19212 : model1 loss : 0.167416 model2 loss : 0.183642
[23:41:26.140] iteration 19213 : model1 loss : 0.261049 model2 loss : 0.282667
[23:41:26.469] iteration 19214 : model1 loss : 0.288111 model2 loss : 0.299615
[23:41:26.801] iteration 19215 : model1 loss : 0.211034 model2 loss : 0.320925
[23:41:27.132] iteration 19216 : model1 loss : 0.190029 model2 loss : 0.183718
[23:41:27.466] iteration 19217 : model1 loss : 0.275864 model2 loss : 0.284366
[23:41:27.793] iteration 19218 : model1 loss : 0.248173 model2 loss : 0.298174
[23:41:28.127] iteration 19219 : model1 loss : 0.140205 model2 loss : 0.196167
[23:41:28.459] iteration 19220 : model1 loss : 0.165289 model2 loss : 0.177143
[23:41:28.786] iteration 19221 : model1 loss : 0.159695 model2 loss : 0.200371
[23:41:29.115] iteration 19222 : model1 loss : 0.159901 model2 loss : 0.179048
[23:41:29.439] iteration 19223 : model1 loss : 0.169478 model2 loss : 0.206927
[23:41:29.772] iteration 19224 : model1 loss : 0.155334 model2 loss : 0.277311
[23:41:30.101] iteration 19225 : model1 loss : 0.182646 model2 loss : 0.190742
[23:41:30.430] iteration 19226 : model1 loss : 0.216396 model2 loss : 0.225208
[23:41:30.762] iteration 19227 : model1 loss : 0.271812 model2 loss : 0.303770
[23:41:31.092] iteration 19228 : model1 loss : 0.290781 model2 loss : 0.307782
[23:41:31.421] iteration 19229 : model1 loss : 0.258839 model2 loss : 0.283888
[23:41:31.750] iteration 19230 : model1 loss : 0.152435 model2 loss : 0.196549
[23:41:32.077] iteration 19231 : model1 loss : 0.197506 model2 loss : 0.206045
[23:41:32.407] iteration 19232 : model1 loss : 0.147310 model2 loss : 0.236263
[23:41:32.738] iteration 19233 : model1 loss : 0.134394 model2 loss : 0.153199
[23:41:33.066] iteration 19234 : model1 loss : 0.121835 model2 loss : 0.218430
[23:41:33.398] iteration 19235 : model1 loss : 0.197660 model2 loss : 0.172376
[23:41:33.734] iteration 19236 : model1 loss : 0.176185 model2 loss : 0.201351
[23:41:34.063] iteration 19237 : model1 loss : 0.206787 model2 loss : 0.193429
[23:41:34.391] iteration 19238 : model1 loss : 0.111543 model2 loss : 0.238614
[23:41:34.726] iteration 19239 : model1 loss : 0.204046 model2 loss : 0.332773
[23:41:35.055] iteration 19240 : model1 loss : 0.229509 model2 loss : 0.270403
[23:41:35.386] iteration 19241 : model1 loss : 0.252266 model2 loss : 0.275406
[23:41:35.714] iteration 19242 : model1 loss : 0.155792 model2 loss : 0.243632
[23:41:36.038] iteration 19243 : model1 loss : 0.143602 model2 loss : 0.136171
[23:41:36.368] iteration 19244 : model1 loss : 0.255445 model2 loss : 0.261316
[23:41:36.696] iteration 19245 : model1 loss : 0.362507 model2 loss : 0.319117
[23:41:37.024] iteration 19246 : model1 loss : 0.113684 model2 loss : 0.147455
[23:41:37.352] iteration 19247 : model1 loss : 0.203955 model2 loss : 0.195732
[23:41:37.681] iteration 19248 : model1 loss : 0.338617 model2 loss : 0.382404
[23:41:38.011] iteration 19249 : model1 loss : 0.206517 model2 loss : 0.195865
[23:41:38.340] iteration 19250 : model1 loss : 0.148417 model2 loss : 0.207128
[23:41:38.892] iteration 19251 : model1 loss : 0.302109 model2 loss : 0.347783
[23:41:39.221] iteration 19252 : model1 loss : 0.240030 model2 loss : 0.272076
[23:41:39.548] iteration 19253 : model1 loss : 0.188685 model2 loss : 0.200422
[23:41:39.879] iteration 19254 : model1 loss : 0.187901 model2 loss : 0.213711
[23:41:40.209] iteration 19255 : model1 loss : 0.261754 model2 loss : 0.254426
[23:41:40.539] iteration 19256 : model1 loss : 0.235982 model2 loss : 0.232069
[23:41:40.868] iteration 19257 : model1 loss : 0.207260 model2 loss : 0.227095
[23:41:41.197] iteration 19258 : model1 loss : 0.235973 model2 loss : 0.253155
[23:41:41.526] iteration 19259 : model1 loss : 0.163266 model2 loss : 0.203718
[23:41:41.856] iteration 19260 : model1 loss : 0.088450 model2 loss : 0.173199
[23:41:42.184] iteration 19261 : model1 loss : 0.262727 model2 loss : 0.275041
[23:41:42.513] iteration 19262 : model1 loss : 0.217542 model2 loss : 0.236655
[23:41:42.843] iteration 19263 : model1 loss : 0.190881 model2 loss : 0.227237
[23:41:43.173] iteration 19264 : model1 loss : 0.108202 model2 loss : 0.121066
[23:41:43.503] iteration 19265 : model1 loss : 0.208596 model2 loss : 0.255853
[23:41:43.831] iteration 19266 : model1 loss : 0.114146 model2 loss : 0.115605
[23:41:44.160] iteration 19267 : model1 loss : 0.254573 model2 loss : 0.133045
[23:41:44.487] iteration 19268 : model1 loss : 0.253452 model2 loss : 0.284787
[23:41:44.812] iteration 19269 : model1 loss : 0.293968 model2 loss : 0.276053
[23:41:45.139] iteration 19270 : model1 loss : 0.357492 model2 loss : 0.368627
[23:41:45.465] iteration 19271 : model1 loss : 0.090833 model2 loss : 0.218730
[23:41:45.792] iteration 19272 : model1 loss : 0.253172 model2 loss : 0.247219
[23:41:46.118] iteration 19273 : model1 loss : 0.150431 model2 loss : 0.174438
[23:41:46.445] iteration 19274 : model1 loss : 0.209600 model2 loss : 0.286159
[23:41:46.770] iteration 19275 : model1 loss : 0.267780 model2 loss : 0.295301
[23:41:47.095] iteration 19276 : model1 loss : 0.089868 model2 loss : 0.117503
[23:41:47.421] iteration 19277 : model1 loss : 0.169864 model2 loss : 0.229562
[23:41:47.747] iteration 19278 : model1 loss : 0.265832 model2 loss : 0.307994
[23:41:48.073] iteration 19279 : model1 loss : 0.194334 model2 loss : 0.208570
[23:41:48.398] iteration 19280 : model1 loss : 0.263378 model2 loss : 0.271177
[23:41:48.724] iteration 19281 : model1 loss : 0.200610 model2 loss : 0.192182
[23:41:49.050] iteration 19282 : model1 loss : 0.167595 model2 loss : 0.181575
[23:41:49.375] iteration 19283 : model1 loss : 0.184692 model2 loss : 0.210786
[23:41:49.701] iteration 19284 : model1 loss : 0.240110 model2 loss : 0.281858
[23:41:50.028] iteration 19285 : model1 loss : 0.103348 model2 loss : 0.252855
[23:41:50.354] iteration 19286 : model1 loss : 0.077242 model2 loss : 0.142439
[23:41:50.680] iteration 19287 : model1 loss : 0.182234 model2 loss : 0.225396
[23:41:51.006] iteration 19288 : model1 loss : 0.076781 model2 loss : 0.111020
[23:41:51.332] iteration 19289 : model1 loss : 0.172554 model2 loss : 0.198335
[23:41:51.658] iteration 19290 : model1 loss : 0.269412 model2 loss : 0.284229
[23:41:51.984] iteration 19291 : model1 loss : 0.211805 model2 loss : 0.228494
[23:41:52.309] iteration 19292 : model1 loss : 0.256845 model2 loss : 0.302430
[23:41:52.637] iteration 19293 : model1 loss : 0.241092 model2 loss : 0.273728
[23:41:52.963] iteration 19294 : model1 loss : 0.252980 model2 loss : 0.299391
[23:41:53.289] iteration 19295 : model1 loss : 0.277205 model2 loss : 0.323690
[23:41:53.615] iteration 19296 : model1 loss : 0.096909 model2 loss : 0.092256
[23:41:53.940] iteration 19297 : model1 loss : 0.200887 model2 loss : 0.296374
[23:41:54.266] iteration 19298 : model1 loss : 0.169753 model2 loss : 0.190986
[23:41:54.592] iteration 19299 : model1 loss : 0.307193 model2 loss : 0.292148
[23:41:54.918] iteration 19300 : model1 loss : 0.187175 model2 loss : 0.227287
[23:41:55.456] iteration 19301 : model1 loss : 0.115891 model2 loss : 0.158681
[23:41:55.783] iteration 19302 : model1 loss : 0.187915 model2 loss : 0.213200
[23:41:56.109] iteration 19303 : model1 loss : 0.132229 model2 loss : 0.202814
[23:41:56.435] iteration 19304 : model1 loss : 0.166747 model2 loss : 0.197922
[23:41:56.761] iteration 19305 : model1 loss : 0.181606 model2 loss : 0.225206
[23:41:57.091] iteration 19306 : model1 loss : 0.221086 model2 loss : 0.255404
[23:41:57.419] iteration 19307 : model1 loss : 0.099601 model2 loss : 0.104541
[23:41:57.747] iteration 19308 : model1 loss : 0.261027 model2 loss : 0.222435
[23:41:58.076] iteration 19309 : model1 loss : 0.194449 model2 loss : 0.228960
[23:41:58.404] iteration 19310 : model1 loss : 0.279444 model2 loss : 0.323676
[23:41:58.735] iteration 19311 : model1 loss : 0.325024 model2 loss : 0.346342
[23:41:59.064] iteration 19312 : model1 loss : 0.173776 model2 loss : 0.176391
[23:41:59.394] iteration 19313 : model1 loss : 0.165138 model2 loss : 0.197533
[23:41:59.722] iteration 19314 : model1 loss : 0.116181 model2 loss : 0.222744
[23:42:00.052] iteration 19315 : model1 loss : 0.166584 model2 loss : 0.190134
[23:42:00.381] iteration 19316 : model1 loss : 0.136745 model2 loss : 0.140869
[23:42:00.710] iteration 19317 : model1 loss : 0.170615 model2 loss : 0.258004
[23:42:01.039] iteration 19318 : model1 loss : 0.255866 model2 loss : 0.238030
[23:42:01.364] iteration 19319 : model1 loss : 0.087317 model2 loss : 0.128760
[23:42:01.691] iteration 19320 : model1 loss : 0.281567 model2 loss : 0.293194
[23:42:02.016] iteration 19321 : model1 loss : 0.213933 model2 loss : 0.275335
[23:42:02.342] iteration 19322 : model1 loss : 0.273766 model2 loss : 0.257665
[23:42:02.669] iteration 19323 : model1 loss : 0.095724 model2 loss : 0.198478
[23:42:02.995] iteration 19324 : model1 loss : 0.117866 model2 loss : 0.203814
[23:42:03.321] iteration 19325 : model1 loss : 0.202474 model2 loss : 0.188837
[23:42:03.646] iteration 19326 : model1 loss : 0.239486 model2 loss : 0.248777
[23:42:03.971] iteration 19327 : model1 loss : 0.320754 model2 loss : 0.310899
[23:42:04.298] iteration 19328 : model1 loss : 0.320245 model2 loss : 0.341403
[23:42:04.624] iteration 19329 : model1 loss : 0.338464 model2 loss : 0.351058
[23:42:04.949] iteration 19330 : model1 loss : 0.303023 model2 loss : 0.302707
[23:42:05.276] iteration 19331 : model1 loss : 0.260088 model2 loss : 0.262893
[23:42:05.602] iteration 19332 : model1 loss : 0.214833 model2 loss : 0.277048
[23:42:05.929] iteration 19333 : model1 loss : 0.311415 model2 loss : 0.327012
[23:42:06.257] iteration 19334 : model1 loss : 0.223257 model2 loss : 0.211128
[23:42:06.582] iteration 19335 : model1 loss : 0.190393 model2 loss : 0.176727
[23:42:06.908] iteration 19336 : model1 loss : 0.242785 model2 loss : 0.324610
[23:42:07.236] iteration 19337 : model1 loss : 0.171067 model2 loss : 0.224809
[23:42:07.561] iteration 19338 : model1 loss : 0.202597 model2 loss : 0.164113
[23:42:07.887] iteration 19339 : model1 loss : 0.240224 model2 loss : 0.262254
[23:42:08.214] iteration 19340 : model1 loss : 0.214666 model2 loss : 0.222061
[23:42:08.541] iteration 19341 : model1 loss : 0.181787 model2 loss : 0.213270
[23:42:08.867] iteration 19342 : model1 loss : 0.098100 model2 loss : 0.116919
[23:42:09.193] iteration 19343 : model1 loss : 0.282082 model2 loss : 0.277368
[23:42:09.519] iteration 19344 : model1 loss : 0.182573 model2 loss : 0.236949
[23:42:09.846] iteration 19345 : model1 loss : 0.166687 model2 loss : 0.185817
[23:42:10.171] iteration 19346 : model1 loss : 0.185700 model2 loss : 0.193269
[23:42:10.498] iteration 19347 : model1 loss : 0.168854 model2 loss : 0.216922
[23:42:10.824] iteration 19348 : model1 loss : 0.218322 model2 loss : 0.286536
[23:42:11.150] iteration 19349 : model1 loss : 0.237032 model2 loss : 0.226700
[23:42:11.476] iteration 19350 : model1 loss : 0.091806 model2 loss : 0.199100
[23:42:11.964] iteration 19351 : model1 loss : 0.163919 model2 loss : 0.205761
[23:42:12.290] iteration 19352 : model1 loss : 0.174502 model2 loss : 0.250763
[23:42:12.615] iteration 19353 : model1 loss : 0.284200 model2 loss : 0.272734
[23:42:12.941] iteration 19354 : model1 loss : 0.100787 model2 loss : 0.120606
[23:42:13.266] iteration 19355 : model1 loss : 0.166347 model2 loss : 0.202556
[23:42:13.592] iteration 19356 : model1 loss : 0.173658 model2 loss : 0.190916
[23:42:13.920] iteration 19357 : model1 loss : 0.243075 model2 loss : 0.287707
[23:42:14.245] iteration 19358 : model1 loss : 0.121392 model2 loss : 0.149154
[23:42:14.570] iteration 19359 : model1 loss : 0.207291 model2 loss : 0.213859
[23:42:14.896] iteration 19360 : model1 loss : 0.092534 model2 loss : 0.094401
[23:42:15.221] iteration 19361 : model1 loss : 0.087277 model2 loss : 0.108603
[23:42:15.547] iteration 19362 : model1 loss : 0.244269 model2 loss : 0.292980
[23:42:15.877] iteration 19363 : model1 loss : 0.175349 model2 loss : 0.227353
[23:42:16.203] iteration 19364 : model1 loss : 0.190603 model2 loss : 0.218058
[23:42:16.528] iteration 19365 : model1 loss : 0.187008 model2 loss : 0.165012
[23:42:16.854] iteration 19366 : model1 loss : 0.162502 model2 loss : 0.178897
[23:42:17.180] iteration 19367 : model1 loss : 0.105317 model2 loss : 0.290254
[23:42:17.506] iteration 19368 : model1 loss : 0.204858 model2 loss : 0.218075
[23:42:17.831] iteration 19369 : model1 loss : 0.297880 model2 loss : 0.323737
[23:42:18.157] iteration 19370 : model1 loss : 0.215112 model2 loss : 0.208397
[23:42:18.484] iteration 19371 : model1 loss : 0.234851 model2 loss : 0.255221
[23:42:18.805] iteration 19372 : model1 loss : 0.244699 model2 loss : 0.284094
[23:42:19.130] iteration 19373 : model1 loss : 0.306663 model2 loss : 0.309728
[23:42:19.451] iteration 19374 : model1 loss : 0.268773 model2 loss : 0.304086
[23:42:19.774] iteration 19375 : model1 loss : 0.204140 model2 loss : 0.198240
[23:42:20.095] iteration 19376 : model1 loss : 0.178285 model2 loss : 0.220625
[23:42:20.416] iteration 19377 : model1 loss : 0.140143 model2 loss : 0.171726
[23:42:20.738] iteration 19378 : model1 loss : 0.117249 model2 loss : 0.112255
[23:42:21.059] iteration 19379 : model1 loss : 0.207812 model2 loss : 0.257858
[23:42:21.380] iteration 19380 : model1 loss : 0.307512 model2 loss : 0.292715
[23:42:21.702] iteration 19381 : model1 loss : 0.257054 model2 loss : 0.295051
[23:42:22.023] iteration 19382 : model1 loss : 0.254004 model2 loss : 0.259465
[23:42:22.344] iteration 19383 : model1 loss : 0.271239 model2 loss : 0.294480
[23:42:22.666] iteration 19384 : model1 loss : 0.188402 model2 loss : 0.196101
[23:42:22.986] iteration 19385 : model1 loss : 0.226751 model2 loss : 0.224908
[23:42:23.307] iteration 19386 : model1 loss : 0.136745 model2 loss : 0.158405
[23:42:23.633] iteration 19387 : model1 loss : 0.182241 model2 loss : 0.205740
[23:42:23.954] iteration 19388 : model1 loss : 0.241995 model2 loss : 0.221322
[23:42:24.275] iteration 19389 : model1 loss : 0.191468 model2 loss : 0.183527
[23:42:24.599] iteration 19390 : model1 loss : 0.182985 model2 loss : 0.203176
[23:42:24.921] iteration 19391 : model1 loss : 0.266908 model2 loss : 0.270196
[23:42:25.242] iteration 19392 : model1 loss : 0.172222 model2 loss : 0.157540
[23:42:25.565] iteration 19393 : model1 loss : 0.213359 model2 loss : 0.236330
[23:42:25.886] iteration 19394 : model1 loss : 0.187832 model2 loss : 0.224826
[23:42:26.208] iteration 19395 : model1 loss : 0.114513 model2 loss : 0.176074
[23:42:26.529] iteration 19396 : model1 loss : 0.261721 model2 loss : 0.294790
[23:42:26.855] iteration 19397 : model1 loss : 0.262719 model2 loss : 0.273713
[23:42:27.176] iteration 19398 : model1 loss : 0.286077 model2 loss : 0.320895
[23:42:27.497] iteration 19399 : model1 loss : 0.191244 model2 loss : 0.197825
[23:42:27.819] iteration 19400 : model1 loss : 0.193899 model2 loss : 0.251201
[23:42:28.348] iteration 19401 : model1 loss : 0.134728 model2 loss : 0.165677
[23:42:28.670] iteration 19402 : model1 loss : 0.219707 model2 loss : 0.219267
[23:42:28.992] iteration 19403 : model1 loss : 0.222974 model2 loss : 0.217760
[23:42:29.313] iteration 19404 : model1 loss : 0.199641 model2 loss : 0.167139
[23:42:29.635] iteration 19405 : model1 loss : 0.204850 model2 loss : 0.225659
[23:42:29.957] iteration 19406 : model1 loss : 0.240333 model2 loss : 0.275837
[23:42:30.284] iteration 19407 : model1 loss : 0.187877 model2 loss : 0.227928
[23:42:30.610] iteration 19408 : model1 loss : 0.111509 model2 loss : 0.189796
[23:42:30.933] iteration 19409 : model1 loss : 0.185714 model2 loss : 0.226420
[23:42:31.254] iteration 19410 : model1 loss : 0.260157 model2 loss : 0.285687
[23:42:31.576] iteration 19411 : model1 loss : 0.090360 model2 loss : 0.224015
[23:42:31.896] iteration 19412 : model1 loss : 0.260906 model2 loss : 0.326756
[23:42:32.217] iteration 19413 : model1 loss : 0.097455 model2 loss : 0.163053
[23:42:32.541] iteration 19414 : model1 loss : 0.169315 model2 loss : 0.200233
[23:42:32.862] iteration 19415 : model1 loss : 0.179690 model2 loss : 0.213405
[23:42:33.183] iteration 19416 : model1 loss : 0.199570 model2 loss : 0.211044
[23:42:33.504] iteration 19417 : model1 loss : 0.102219 model2 loss : 0.098472
[23:42:33.826] iteration 19418 : model1 loss : 0.303010 model2 loss : 0.289886
[23:42:34.147] iteration 19419 : model1 loss : 0.231785 model2 loss : 0.270820
[23:42:34.468] iteration 19420 : model1 loss : 0.273483 model2 loss : 0.268501
[23:42:34.789] iteration 19421 : model1 loss : 0.198929 model2 loss : 0.231917
[23:42:35.111] iteration 19422 : model1 loss : 0.326803 model2 loss : 0.360870
[23:42:35.433] iteration 19423 : model1 loss : 0.188917 model2 loss : 0.250484
[23:42:35.754] iteration 19424 : model1 loss : 0.171444 model2 loss : 0.191135
[23:42:36.078] iteration 19425 : model1 loss : 0.086504 model2 loss : 0.120225
[23:42:36.399] iteration 19426 : model1 loss : 0.227572 model2 loss : 0.234360
[23:42:36.720] iteration 19427 : model1 loss : 0.148384 model2 loss : 0.150459
[23:42:37.041] iteration 19428 : model1 loss : 0.330516 model2 loss : 0.333354
[23:42:37.362] iteration 19429 : model1 loss : 0.193465 model2 loss : 0.225762
[23:42:37.682] iteration 19430 : model1 loss : 0.193737 model2 loss : 0.213517
[23:42:38.004] iteration 19431 : model1 loss : 0.113828 model2 loss : 0.133657
[23:42:38.325] iteration 19432 : model1 loss : 0.198038 model2 loss : 0.228602
[23:42:38.647] iteration 19433 : model1 loss : 0.173618 model2 loss : 0.215615
[23:42:38.968] iteration 19434 : model1 loss : 0.178051 model2 loss : 0.197141
[23:42:39.289] iteration 19435 : model1 loss : 0.171962 model2 loss : 0.228868
[23:42:39.611] iteration 19436 : model1 loss : 0.095070 model2 loss : 0.142553
[23:42:39.932] iteration 19437 : model1 loss : 0.273712 model2 loss : 0.356446
[23:42:40.254] iteration 19438 : model1 loss : 0.212240 model2 loss : 0.253646
[23:42:40.575] iteration 19439 : model1 loss : 0.221531 model2 loss : 0.225905
[23:42:40.896] iteration 19440 : model1 loss : 0.265200 model2 loss : 0.330309
[23:42:41.218] iteration 19441 : model1 loss : 0.301765 model2 loss : 0.338071
[23:42:41.538] iteration 19442 : model1 loss : 0.183247 model2 loss : 0.181932
[23:42:41.859] iteration 19443 : model1 loss : 0.148483 model2 loss : 0.189575
[23:42:42.178] iteration 19444 : model1 loss : 0.108876 model2 loss : 0.148760
[23:42:42.498] iteration 19445 : model1 loss : 0.191025 model2 loss : 0.231905
[23:42:42.819] iteration 19446 : model1 loss : 0.238178 model2 loss : 0.259120
[23:42:43.140] iteration 19447 : model1 loss : 0.223496 model2 loss : 0.193500
[23:42:43.460] iteration 19448 : model1 loss : 0.227901 model2 loss : 0.210408
[23:42:43.785] iteration 19449 : model1 loss : 0.198763 model2 loss : 0.202174
[23:42:44.111] iteration 19450 : model1 loss : 0.236624 model2 loss : 0.260424
[23:42:44.613] iteration 19451 : model1 loss : 0.122168 model2 loss : 0.211235
[23:42:44.934] iteration 19452 : model1 loss : 0.404368 model2 loss : 0.412516
[23:42:45.255] iteration 19453 : model1 loss : 0.126608 model2 loss : 0.127877
[23:42:45.576] iteration 19454 : model1 loss : 0.205975 model2 loss : 0.222119
[23:42:45.899] iteration 19455 : model1 loss : 0.196945 model2 loss : 0.290331
[23:42:46.220] iteration 19456 : model1 loss : 0.304606 model2 loss : 0.316000
[23:42:46.540] iteration 19457 : model1 loss : 0.170877 model2 loss : 0.198994
[23:42:46.860] iteration 19458 : model1 loss : 0.179063 model2 loss : 0.189295
[23:42:47.185] iteration 19459 : model1 loss : 0.101207 model2 loss : 0.151973
[23:42:47.510] iteration 19460 : model1 loss : 0.187572 model2 loss : 0.199948
[23:42:47.832] iteration 19461 : model1 loss : 0.269556 model2 loss : 0.292096
[23:42:48.152] iteration 19462 : model1 loss : 0.335224 model2 loss : 0.375918
[23:42:48.472] iteration 19463 : model1 loss : 0.240056 model2 loss : 0.252144
[23:42:48.795] iteration 19464 : model1 loss : 0.084032 model2 loss : 0.120509
[23:42:49.115] iteration 19465 : model1 loss : 0.184124 model2 loss : 0.146277
[23:42:49.436] iteration 19466 : model1 loss : 0.210268 model2 loss : 0.192569
[23:42:49.756] iteration 19467 : model1 loss : 0.158555 model2 loss : 0.183925
[23:42:50.078] iteration 19468 : model1 loss : 0.088483 model2 loss : 0.191880
[23:42:50.399] iteration 19469 : model1 loss : 0.272496 model2 loss : 0.304881
[23:42:50.719] iteration 19470 : model1 loss : 0.226576 model2 loss : 0.314393
[23:42:51.040] iteration 19471 : model1 loss : 0.129064 model2 loss : 0.175314
[23:42:51.367] iteration 19472 : model1 loss : 0.114826 model2 loss : 0.216154
[23:42:51.687] iteration 19473 : model1 loss : 0.263229 model2 loss : 0.271774
[23:42:52.013] iteration 19474 : model1 loss : 0.201216 model2 loss : 0.249592
[23:42:52.340] iteration 19475 : model1 loss : 0.281712 model2 loss : 0.305503
[23:42:52.661] iteration 19476 : model1 loss : 0.188925 model2 loss : 0.192321
[23:42:52.982] iteration 19477 : model1 loss : 0.178108 model2 loss : 0.194609
[23:42:53.302] iteration 19478 : model1 loss : 0.119914 model2 loss : 0.134673
[23:42:53.622] iteration 19479 : model1 loss : 0.339066 model2 loss : 0.359666
[23:42:53.947] iteration 19480 : model1 loss : 0.160436 model2 loss : 0.175348
[23:42:54.267] iteration 19481 : model1 loss : 0.169856 model2 loss : 0.242737
[23:42:54.587] iteration 19482 : model1 loss : 0.103876 model2 loss : 0.173601
[23:42:54.907] iteration 19483 : model1 loss : 0.190984 model2 loss : 0.253713
[23:42:55.228] iteration 19484 : model1 loss : 0.133506 model2 loss : 0.247984
[23:42:55.548] iteration 19485 : model1 loss : 0.112074 model2 loss : 0.190146
[23:42:55.868] iteration 19486 : model1 loss : 0.331960 model2 loss : 0.346686
[23:42:56.191] iteration 19487 : model1 loss : 0.190951 model2 loss : 0.243577
[23:42:56.515] iteration 19488 : model1 loss : 0.099875 model2 loss : 0.093920
[23:42:56.836] iteration 19489 : model1 loss : 0.244754 model2 loss : 0.317781
[23:42:57.156] iteration 19490 : model1 loss : 0.103017 model2 loss : 0.184255
[23:42:57.476] iteration 19491 : model1 loss : 0.172426 model2 loss : 0.233618
[23:42:57.797] iteration 19492 : model1 loss : 0.215424 model2 loss : 0.272546
[23:42:58.117] iteration 19493 : model1 loss : 0.267669 model2 loss : 0.295557
[23:42:58.437] iteration 19494 : model1 loss : 0.240681 model2 loss : 0.264709
[23:42:58.787] iteration 19495 : model1 loss : 0.157192 model2 loss : 0.180925
[23:42:59.117] iteration 19496 : model1 loss : 0.287783 model2 loss : 0.274294
[23:42:59.450] iteration 19497 : model1 loss : 0.173468 model2 loss : 0.164343
[23:42:59.780] iteration 19498 : model1 loss : 0.201076 model2 loss : 0.225624
[23:43:00.116] iteration 19499 : model1 loss : 0.102713 model2 loss : 0.253172
[23:43:00.449] iteration 19500 : model1 loss : 0.250704 model2 loss : 0.287639
[23:43:01.065] iteration 19501 : model1 loss : 0.216089 model2 loss : 0.214809
[23:43:01.396] iteration 19502 : model1 loss : 0.278791 model2 loss : 0.299814
[23:43:01.728] iteration 19503 : model1 loss : 0.079890 model2 loss : 0.090196
[23:43:02.058] iteration 19504 : model1 loss : 0.345109 model2 loss : 0.346127
[23:43:02.389] iteration 19505 : model1 loss : 0.208059 model2 loss : 0.235329
[23:43:02.720] iteration 19506 : model1 loss : 0.271193 model2 loss : 0.300930
[23:43:03.051] iteration 19507 : model1 loss : 0.087968 model2 loss : 0.193865
[23:43:03.382] iteration 19508 : model1 loss : 0.210706 model2 loss : 0.244907
[23:43:03.716] iteration 19509 : model1 loss : 0.209316 model2 loss : 0.232144
[23:43:04.047] iteration 19510 : model1 loss : 0.327447 model2 loss : 0.341503
[23:43:04.377] iteration 19511 : model1 loss : 0.099899 model2 loss : 0.131265
[23:43:04.708] iteration 19512 : model1 loss : 0.160813 model2 loss : 0.196068
[23:43:05.038] iteration 19513 : model1 loss : 0.097268 model2 loss : 0.130048
[23:43:05.370] iteration 19514 : model1 loss : 0.176447 model2 loss : 0.229752
[23:43:05.700] iteration 19515 : model1 loss : 0.298627 model2 loss : 0.260569
[23:43:06.030] iteration 19516 : model1 loss : 0.285546 model2 loss : 0.328276
[23:43:06.363] iteration 19517 : model1 loss : 0.272624 model2 loss : 0.324994
[23:43:06.694] iteration 19518 : model1 loss : 0.269226 model2 loss : 0.293779
[23:43:07.025] iteration 19519 : model1 loss : 0.233509 model2 loss : 0.244003
[23:43:07.356] iteration 19520 : model1 loss : 0.207014 model2 loss : 0.191153
[23:43:07.689] iteration 19521 : model1 loss : 0.163515 model2 loss : 0.186830
[23:43:08.021] iteration 19522 : model1 loss : 0.193549 model2 loss : 0.206950
[23:43:08.351] iteration 19523 : model1 loss : 0.167412 model2 loss : 0.200640
[23:43:08.682] iteration 19524 : model1 loss : 0.088381 model2 loss : 0.106159
[23:43:09.015] iteration 19525 : model1 loss : 0.201927 model2 loss : 0.195657
[23:43:09.347] iteration 19526 : model1 loss : 0.271661 model2 loss : 0.309627
[23:43:09.678] iteration 19527 : model1 loss : 0.178349 model2 loss : 0.202436
[23:43:10.009] iteration 19528 : model1 loss : 0.174321 model2 loss : 0.163838
[23:43:10.342] iteration 19529 : model1 loss : 0.272074 model2 loss : 0.346193
[23:43:10.673] iteration 19530 : model1 loss : 0.193961 model2 loss : 0.195057
[23:43:11.003] iteration 19531 : model1 loss : 0.127378 model2 loss : 0.155208
[23:43:11.335] iteration 19532 : model1 loss : 0.146794 model2 loss : 0.156030
[23:43:11.665] iteration 19533 : model1 loss : 0.126204 model2 loss : 0.129830
[23:43:11.995] iteration 19534 : model1 loss : 0.230532 model2 loss : 0.277006
[23:43:12.327] iteration 19535 : model1 loss : 0.110611 model2 loss : 0.114255
[23:43:12.662] iteration 19536 : model1 loss : 0.145924 model2 loss : 0.201906
[23:43:12.993] iteration 19537 : model1 loss : 0.362287 model2 loss : 0.336300
[23:43:13.324] iteration 19538 : model1 loss : 0.276054 model2 loss : 0.309082
[23:43:13.655] iteration 19539 : model1 loss : 0.113213 model2 loss : 0.114190
[23:43:13.986] iteration 19540 : model1 loss : 0.258397 model2 loss : 0.261880
[23:43:14.323] iteration 19541 : model1 loss : 0.254660 model2 loss : 0.235721
[23:43:14.656] iteration 19542 : model1 loss : 0.151738 model2 loss : 0.172940
[23:43:14.987] iteration 19543 : model1 loss : 0.250039 model2 loss : 0.297654
[23:43:15.318] iteration 19544 : model1 loss : 0.185771 model2 loss : 0.135829
[23:43:15.656] iteration 19545 : model1 loss : 0.205351 model2 loss : 0.229280
[23:43:15.987] iteration 19546 : model1 loss : 0.247483 model2 loss : 0.262640
[23:43:16.318] iteration 19547 : model1 loss : 0.134017 model2 loss : 0.183153
[23:43:16.654] iteration 19548 : model1 loss : 0.174386 model2 loss : 0.174792
[23:43:16.985] iteration 19549 : model1 loss : 0.333508 model2 loss : 0.340725
[23:43:17.316] iteration 19550 : model1 loss : 0.112318 model2 loss : 0.113937
[23:43:17.957] iteration 19551 : model1 loss : 0.262142 model2 loss : 0.273081
[23:43:18.288] iteration 19552 : model1 loss : 0.164600 model2 loss : 0.176687
[23:43:18.624] iteration 19553 : model1 loss : 0.192396 model2 loss : 0.182368
[23:43:18.955] iteration 19554 : model1 loss : 0.182619 model2 loss : 0.205904
[23:43:19.291] iteration 19555 : model1 loss : 0.089729 model2 loss : 0.115020
[23:43:19.625] iteration 19556 : model1 loss : 0.188091 model2 loss : 0.225258
[23:43:19.960] iteration 19557 : model1 loss : 0.350348 model2 loss : 0.317173
[23:43:20.292] iteration 19558 : model1 loss : 0.163510 model2 loss : 0.203114
[23:43:20.627] iteration 19559 : model1 loss : 0.328036 model2 loss : 0.304141
[23:43:20.960] iteration 19560 : model1 loss : 0.250508 model2 loss : 0.273952
[23:43:21.291] iteration 19561 : model1 loss : 0.182923 model2 loss : 0.173604
[23:43:21.622] iteration 19562 : model1 loss : 0.140422 model2 loss : 0.107468
[23:43:21.954] iteration 19563 : model1 loss : 0.149057 model2 loss : 0.184632
[23:43:22.285] iteration 19564 : model1 loss : 0.207160 model2 loss : 0.189073
[23:43:22.617] iteration 19565 : model1 loss : 0.113967 model2 loss : 0.123586
[23:43:22.948] iteration 19566 : model1 loss : 0.202893 model2 loss : 0.223519
[23:43:23.279] iteration 19567 : model1 loss : 0.210472 model2 loss : 0.244400
[23:43:23.613] iteration 19568 : model1 loss : 0.258116 model2 loss : 0.271563
[23:43:23.943] iteration 19569 : model1 loss : 0.188283 model2 loss : 0.213700
[23:43:24.279] iteration 19570 : model1 loss : 0.313539 model2 loss : 0.310082
[23:43:24.614] iteration 19571 : model1 loss : 0.266053 model2 loss : 0.296268
[23:43:24.945] iteration 19572 : model1 loss : 0.172604 model2 loss : 0.196322
[23:43:25.277] iteration 19573 : model1 loss : 0.085941 model2 loss : 0.117875
[23:43:25.608] iteration 19574 : model1 loss : 0.175717 model2 loss : 0.179055
[23:43:25.941] iteration 19575 : model1 loss : 0.196047 model2 loss : 0.221626
[23:43:26.275] iteration 19576 : model1 loss : 0.249627 model2 loss : 0.264774
[23:43:26.608] iteration 19577 : model1 loss : 0.093334 model2 loss : 0.080542
[23:43:26.942] iteration 19578 : model1 loss : 0.262783 model2 loss : 0.263879
[23:43:27.273] iteration 19579 : model1 loss : 0.228277 model2 loss : 0.154578
[23:43:27.607] iteration 19580 : model1 loss : 0.253812 model2 loss : 0.272318
[23:43:27.942] iteration 19581 : model1 loss : 0.294870 model2 loss : 0.321365
[23:43:28.273] iteration 19582 : model1 loss : 0.114641 model2 loss : 0.161835
[23:43:28.605] iteration 19583 : model1 loss : 0.192642 model2 loss : 0.202200
[23:43:28.936] iteration 19584 : model1 loss : 0.256676 model2 loss : 0.252830
[23:43:29.268] iteration 19585 : model1 loss : 0.188637 model2 loss : 0.187050
[23:43:29.599] iteration 19586 : model1 loss : 0.153791 model2 loss : 0.217064
[23:43:29.931] iteration 19587 : model1 loss : 0.236589 model2 loss : 0.329959
[23:43:30.262] iteration 19588 : model1 loss : 0.263723 model2 loss : 0.260782
[23:43:30.594] iteration 19589 : model1 loss : 0.248122 model2 loss : 0.249639
[23:43:30.925] iteration 19590 : model1 loss : 0.231301 model2 loss : 0.265494
[23:43:31.258] iteration 19591 : model1 loss : 0.186193 model2 loss : 0.284600
[23:43:31.589] iteration 19592 : model1 loss : 0.175279 model2 loss : 0.163826
[23:43:31.928] iteration 19593 : model1 loss : 0.214680 model2 loss : 0.264169
[23:43:32.262] iteration 19594 : model1 loss : 0.218420 model2 loss : 0.181038
[23:43:32.596] iteration 19595 : model1 loss : 0.263130 model2 loss : 0.272854
[23:43:32.927] iteration 19596 : model1 loss : 0.271235 model2 loss : 0.304356
[23:43:33.263] iteration 19597 : model1 loss : 0.270844 model2 loss : 0.288383
[23:43:33.598] iteration 19598 : model1 loss : 0.245369 model2 loss : 0.295214
[23:43:33.930] iteration 19599 : model1 loss : 0.076298 model2 loss : 0.088968
[23:43:34.271] iteration 19600 : model1 loss : 0.268422 model2 loss : 0.276340
[23:43:34.869] iteration 19601 : model1 loss : 0.253317 model2 loss : 0.296671
[23:43:35.201] iteration 19602 : model1 loss : 0.189005 model2 loss : 0.223027
[23:43:35.532] iteration 19603 : model1 loss : 0.276069 model2 loss : 0.299490
[23:43:35.866] iteration 19604 : model1 loss : 0.170560 model2 loss : 0.205816
[23:43:36.197] iteration 19605 : model1 loss : 0.268370 model2 loss : 0.354045
[23:43:36.529] iteration 19606 : model1 loss : 0.211220 model2 loss : 0.190204
[23:43:36.861] iteration 19607 : model1 loss : 0.124390 model2 loss : 0.142764
[23:43:37.197] iteration 19608 : model1 loss : 0.222435 model2 loss : 0.221200
[23:43:37.529] iteration 19609 : model1 loss : 0.114099 model2 loss : 0.161352
[23:43:37.860] iteration 19610 : model1 loss : 0.199306 model2 loss : 0.211052
[23:43:38.195] iteration 19611 : model1 loss : 0.278341 model2 loss : 0.311498
[23:43:38.527] iteration 19612 : model1 loss : 0.169491 model2 loss : 0.230878
[23:43:38.860] iteration 19613 : model1 loss : 0.159699 model2 loss : 0.220016
[23:43:39.191] iteration 19614 : model1 loss : 0.184942 model2 loss : 0.183837
[23:43:39.523] iteration 19615 : model1 loss : 0.182550 model2 loss : 0.236449
[23:43:39.857] iteration 19616 : model1 loss : 0.187011 model2 loss : 0.163795
[23:43:40.190] iteration 19617 : model1 loss : 0.193655 model2 loss : 0.233283
[23:43:40.524] iteration 19618 : model1 loss : 0.226091 model2 loss : 0.235047
[23:43:40.859] iteration 19619 : model1 loss : 0.104946 model2 loss : 0.104763
[23:43:41.190] iteration 19620 : model1 loss : 0.168450 model2 loss : 0.145487
[23:43:42.071] iteration 19621 : model1 loss : 0.222397 model2 loss : 0.202977
[23:43:42.404] iteration 19622 : model1 loss : 0.179655 model2 loss : 0.221236
[23:43:42.740] iteration 19623 : model1 loss : 0.183899 model2 loss : 0.177996
[23:43:43.072] iteration 19624 : model1 loss : 0.182250 model2 loss : 0.195894
[23:43:43.408] iteration 19625 : model1 loss : 0.207034 model2 loss : 0.222180
[23:43:43.730] iteration 19626 : model1 loss : 0.087548 model2 loss : 0.112527
[23:43:44.054] iteration 19627 : model1 loss : 0.166451 model2 loss : 0.188231
[23:43:44.382] iteration 19628 : model1 loss : 0.175908 model2 loss : 0.174773
[23:43:44.705] iteration 19629 : model1 loss : 0.172326 model2 loss : 0.186470
[23:43:45.028] iteration 19630 : model1 loss : 0.170070 model2 loss : 0.212094
[23:43:45.351] iteration 19631 : model1 loss : 0.189907 model2 loss : 0.256171
[23:43:45.679] iteration 19632 : model1 loss : 0.268423 model2 loss : 0.257635
[23:43:46.007] iteration 19633 : model1 loss : 0.168789 model2 loss : 0.210263
[23:43:46.330] iteration 19634 : model1 loss : 0.170639 model2 loss : 0.210121
[23:43:46.654] iteration 19635 : model1 loss : 0.274289 model2 loss : 0.409763
[23:43:46.978] iteration 19636 : model1 loss : 0.107474 model2 loss : 0.118029
[23:43:47.302] iteration 19637 : model1 loss : 0.249690 model2 loss : 0.278345
[23:43:47.629] iteration 19638 : model1 loss : 0.091428 model2 loss : 0.148507
[23:43:47.957] iteration 19639 : model1 loss : 0.092369 model2 loss : 0.116624
[23:43:48.283] iteration 19640 : model1 loss : 0.169002 model2 loss : 0.261663
[23:43:48.610] iteration 19641 : model1 loss : 0.249000 model2 loss : 0.275986
[23:43:48.933] iteration 19642 : model1 loss : 0.172264 model2 loss : 0.174663
[23:43:49.256] iteration 19643 : model1 loss : 0.089931 model2 loss : 0.107964
[23:43:49.582] iteration 19644 : model1 loss : 0.194892 model2 loss : 0.210820
[23:43:49.907] iteration 19645 : model1 loss : 0.207383 model2 loss : 0.264598
[23:43:50.232] iteration 19646 : model1 loss : 0.260765 model2 loss : 0.283210
[23:43:50.558] iteration 19647 : model1 loss : 0.166778 model2 loss : 0.212697
[23:43:50.884] iteration 19648 : model1 loss : 0.191990 model2 loss : 0.232076
[23:43:51.205] iteration 19649 : model1 loss : 0.173950 model2 loss : 0.204378
[23:43:51.526] iteration 19650 : model1 loss : 0.164284 model2 loss : 0.190440
[23:43:52.053] iteration 19651 : model1 loss : 0.178926 model2 loss : 0.204314
[23:43:52.374] iteration 19652 : model1 loss : 0.252092 model2 loss : 0.278593
[23:43:52.695] iteration 19653 : model1 loss : 0.261618 model2 loss : 0.283470
[23:43:53.017] iteration 19654 : model1 loss : 0.379758 model2 loss : 0.338923
[23:43:53.338] iteration 19655 : model1 loss : 0.204657 model2 loss : 0.240500
[23:43:53.659] iteration 19656 : model1 loss : 0.196252 model2 loss : 0.267495
[23:43:53.980] iteration 19657 : model1 loss : 0.283256 model2 loss : 0.279377
[23:43:54.301] iteration 19658 : model1 loss : 0.276369 model2 loss : 0.272360
[23:43:54.626] iteration 19659 : model1 loss : 0.171847 model2 loss : 0.183417
[23:43:54.952] iteration 19660 : model1 loss : 0.177935 model2 loss : 0.178075
[23:43:55.279] iteration 19661 : model1 loss : 0.244225 model2 loss : 0.283717
[23:43:55.600] iteration 19662 : model1 loss : 0.105914 model2 loss : 0.130952
[23:43:55.920] iteration 19663 : model1 loss : 0.305006 model2 loss : 0.366395
[23:43:56.242] iteration 19664 : model1 loss : 0.242640 model2 loss : 0.281069
[23:43:56.563] iteration 19665 : model1 loss : 0.184041 model2 loss : 0.216213
[23:43:56.884] iteration 19666 : model1 loss : 0.153285 model2 loss : 0.160092
[23:43:57.210] iteration 19667 : model1 loss : 0.081877 model2 loss : 0.143948
[23:43:57.531] iteration 19668 : model1 loss : 0.197294 model2 loss : 0.205789
[23:43:57.857] iteration 19669 : model1 loss : 0.160789 model2 loss : 0.211078
[23:43:58.178] iteration 19670 : model1 loss : 0.103312 model2 loss : 0.147628
[23:43:58.503] iteration 19671 : model1 loss : 0.240115 model2 loss : 0.327516
[23:43:58.930] iteration 19672 : model1 loss : 0.180418 model2 loss : 0.226926
[23:43:59.251] iteration 19673 : model1 loss : 0.201248 model2 loss : 0.216724
[23:43:59.573] iteration 19674 : model1 loss : 0.067482 model2 loss : 0.149593
[23:43:59.898] iteration 19675 : model1 loss : 0.156021 model2 loss : 0.174585
[23:44:00.219] iteration 19676 : model1 loss : 0.114199 model2 loss : 0.218874
[23:44:00.543] iteration 19677 : model1 loss : 0.286097 model2 loss : 0.347937
[23:44:00.863] iteration 19678 : model1 loss : 0.244798 model2 loss : 0.257057
[23:44:01.188] iteration 19679 : model1 loss : 0.058718 model2 loss : 0.073129
[23:44:01.509] iteration 19680 : model1 loss : 0.228910 model2 loss : 0.184105
[23:44:01.832] iteration 19681 : model1 loss : 0.283298 model2 loss : 0.307599
[23:44:02.157] iteration 19682 : model1 loss : 0.288211 model2 loss : 0.290009
[23:44:02.483] iteration 19683 : model1 loss : 0.184152 model2 loss : 0.233562
[23:44:02.803] iteration 19684 : model1 loss : 0.227283 model2 loss : 0.200996
[23:44:03.126] iteration 19685 : model1 loss : 0.126478 model2 loss : 0.210723
[23:44:03.447] iteration 19686 : model1 loss : 0.185651 model2 loss : 0.204436
[23:44:03.769] iteration 19687 : model1 loss : 0.197087 model2 loss : 0.206892
[23:44:04.090] iteration 19688 : model1 loss : 0.152408 model2 loss : 0.210672
[23:44:04.411] iteration 19689 : model1 loss : 0.242069 model2 loss : 0.249214
[23:44:04.732] iteration 19690 : model1 loss : 0.320609 model2 loss : 0.358825
[23:44:05.053] iteration 19691 : model1 loss : 0.197947 model2 loss : 0.231845
[23:44:05.375] iteration 19692 : model1 loss : 0.103090 model2 loss : 0.151289
[23:44:05.696] iteration 19693 : model1 loss : 0.331474 model2 loss : 0.338850
[23:44:06.017] iteration 19694 : model1 loss : 0.179288 model2 loss : 0.190574
[23:44:06.338] iteration 19695 : model1 loss : 0.221121 model2 loss : 0.213510
[23:44:06.660] iteration 19696 : model1 loss : 0.247500 model2 loss : 0.256297
[23:44:06.981] iteration 19697 : model1 loss : 0.255433 model2 loss : 0.315608
[23:44:07.302] iteration 19698 : model1 loss : 0.223479 model2 loss : 0.228660
[23:44:07.623] iteration 19699 : model1 loss : 0.169834 model2 loss : 0.218886
[23:44:07.944] iteration 19700 : model1 loss : 0.260733 model2 loss : 0.274576
[23:44:08.465] iteration 19701 : model1 loss : 0.239125 model2 loss : 0.252957
[23:44:08.791] iteration 19702 : model1 loss : 0.211138 model2 loss : 0.268880
[23:44:09.117] iteration 19703 : model1 loss : 0.221977 model2 loss : 0.234031
[23:44:09.443] iteration 19704 : model1 loss : 0.275834 model2 loss : 0.290996
[23:44:09.768] iteration 19705 : model1 loss : 0.175531 model2 loss : 0.223149
[23:44:10.094] iteration 19706 : model1 loss : 0.187783 model2 loss : 0.297405
[23:44:10.420] iteration 19707 : model1 loss : 0.312935 model2 loss : 0.320013
[23:44:10.747] iteration 19708 : model1 loss : 0.169923 model2 loss : 0.208358
[23:44:11.073] iteration 19709 : model1 loss : 0.159668 model2 loss : 0.192548
[23:44:11.398] iteration 19710 : model1 loss : 0.075947 model2 loss : 0.104286
[23:44:11.724] iteration 19711 : model1 loss : 0.175898 model2 loss : 0.203345
[23:44:12.050] iteration 19712 : model1 loss : 0.260360 model2 loss : 0.229716
[23:44:12.377] iteration 19713 : model1 loss : 0.240018 model2 loss : 0.304965
[23:44:12.702] iteration 19714 : model1 loss : 0.315340 model2 loss : 0.324971
[23:44:13.028] iteration 19715 : model1 loss : 0.093078 model2 loss : 0.193905
[23:44:13.354] iteration 19716 : model1 loss : 0.266179 model2 loss : 0.314686
[23:44:13.680] iteration 19717 : model1 loss : 0.197742 model2 loss : 0.190669
[23:44:14.005] iteration 19718 : model1 loss : 0.121470 model2 loss : 0.196190
[23:44:14.330] iteration 19719 : model1 loss : 0.231745 model2 loss : 0.241823
[23:44:14.656] iteration 19720 : model1 loss : 0.121881 model2 loss : 0.176942
[23:44:14.982] iteration 19721 : model1 loss : 0.183549 model2 loss : 0.230841
[23:44:15.309] iteration 19722 : model1 loss : 0.207575 model2 loss : 0.227808
[23:44:15.634] iteration 19723 : model1 loss : 0.181584 model2 loss : 0.189097
[23:44:15.961] iteration 19724 : model1 loss : 0.170778 model2 loss : 0.261855
[23:44:16.287] iteration 19725 : model1 loss : 0.373284 model2 loss : 0.411603
[23:44:16.612] iteration 19726 : model1 loss : 0.179160 model2 loss : 0.168128
[23:44:16.939] iteration 19727 : model1 loss : 0.242841 model2 loss : 0.268731
[23:44:17.266] iteration 19728 : model1 loss : 0.213287 model2 loss : 0.203808
[23:44:17.595] iteration 19729 : model1 loss : 0.203705 model2 loss : 0.201145
[23:44:17.920] iteration 19730 : model1 loss : 0.411005 model2 loss : 0.443329
[23:44:18.246] iteration 19731 : model1 loss : 0.168217 model2 loss : 0.177053
[23:44:18.572] iteration 19732 : model1 loss : 0.153943 model2 loss : 0.198634
[23:44:18.898] iteration 19733 : model1 loss : 0.123281 model2 loss : 0.162924
[23:44:19.223] iteration 19734 : model1 loss : 0.077358 model2 loss : 0.146368
[23:44:19.550] iteration 19735 : model1 loss : 0.117907 model2 loss : 0.191573
[23:44:19.876] iteration 19736 : model1 loss : 0.227007 model2 loss : 0.212734
[23:44:20.202] iteration 19737 : model1 loss : 0.175381 model2 loss : 0.179618
[23:44:20.528] iteration 19738 : model1 loss : 0.083869 model2 loss : 0.112773
[23:44:20.853] iteration 19739 : model1 loss : 0.184038 model2 loss : 0.239948
[23:44:21.179] iteration 19740 : model1 loss : 0.238123 model2 loss : 0.269845
[23:44:21.504] iteration 19741 : model1 loss : 0.245125 model2 loss : 0.288994
[23:44:21.831] iteration 19742 : model1 loss : 0.402242 model2 loss : 0.402586
[23:44:22.156] iteration 19743 : model1 loss : 0.147502 model2 loss : 0.216792
[23:44:22.487] iteration 19744 : model1 loss : 0.202338 model2 loss : 0.277245
[23:44:22.815] iteration 19745 : model1 loss : 0.099331 model2 loss : 0.190669
[23:44:23.140] iteration 19746 : model1 loss : 0.177748 model2 loss : 0.234767
[23:44:23.467] iteration 19747 : model1 loss : 0.242372 model2 loss : 0.272691
[23:44:23.793] iteration 19748 : model1 loss : 0.249695 model2 loss : 0.259652
[23:44:24.119] iteration 19749 : model1 loss : 0.236761 model2 loss : 0.279878
[23:44:24.445] iteration 19750 : model1 loss : 0.255201 model2 loss : 0.261712
[23:44:24.953] iteration 19751 : model1 loss : 0.238803 model2 loss : 0.263412
[23:44:25.279] iteration 19752 : model1 loss : 0.187027 model2 loss : 0.217495
[23:44:25.607] iteration 19753 : model1 loss : 0.232726 model2 loss : 0.220757
[23:44:25.933] iteration 19754 : model1 loss : 0.238246 model2 loss : 0.246200
[23:44:26.259] iteration 19755 : model1 loss : 0.106754 model2 loss : 0.210315
[23:44:26.586] iteration 19756 : model1 loss : 0.196584 model2 loss : 0.204939
[23:44:26.912] iteration 19757 : model1 loss : 0.203486 model2 loss : 0.249702
[23:44:27.239] iteration 19758 : model1 loss : 0.100720 model2 loss : 0.199547
[23:44:27.567] iteration 19759 : model1 loss : 0.250279 model2 loss : 0.221589
[23:44:27.892] iteration 19760 : model1 loss : 0.293506 model2 loss : 0.330472
[23:44:28.218] iteration 19761 : model1 loss : 0.218104 model2 loss : 0.259026
[23:44:28.543] iteration 19762 : model1 loss : 0.163462 model2 loss : 0.179263
[23:44:28.869] iteration 19763 : model1 loss : 0.246134 model2 loss : 0.294887
[23:44:29.195] iteration 19764 : model1 loss : 0.202580 model2 loss : 0.228769
[23:44:29.520] iteration 19765 : model1 loss : 0.103416 model2 loss : 0.156715
[23:44:29.846] iteration 19766 : model1 loss : 0.293937 model2 loss : 0.339699
[23:44:30.172] iteration 19767 : model1 loss : 0.126474 model2 loss : 0.182623
[23:44:30.498] iteration 19768 : model1 loss : 0.186621 model2 loss : 0.197413
[23:44:30.824] iteration 19769 : model1 loss : 0.122996 model2 loss : 0.133523
[23:44:31.149] iteration 19770 : model1 loss : 0.188491 model2 loss : 0.280463
[23:44:31.475] iteration 19771 : model1 loss : 0.178878 model2 loss : 0.230524
[23:44:31.804] iteration 19772 : model1 loss : 0.157961 model2 loss : 0.178527
[23:44:32.130] iteration 19773 : model1 loss : 0.177069 model2 loss : 0.197581
[23:44:32.456] iteration 19774 : model1 loss : 0.235021 model2 loss : 0.251799
[23:44:32.781] iteration 19775 : model1 loss : 0.204881 model2 loss : 0.241116
[23:44:33.106] iteration 19776 : model1 loss : 0.346405 model2 loss : 0.362111
[23:44:33.430] iteration 19777 : model1 loss : 0.194716 model2 loss : 0.237256
[23:44:33.752] iteration 19778 : model1 loss : 0.190359 model2 loss : 0.273240
[23:44:34.073] iteration 19779 : model1 loss : 0.090450 model2 loss : 0.150029
[23:44:34.400] iteration 19780 : model1 loss : 0.200936 model2 loss : 0.233626
[23:44:34.726] iteration 19781 : model1 loss : 0.245605 model2 loss : 0.253574
[23:44:35.048] iteration 19782 : model1 loss : 0.260161 model2 loss : 0.317031
[23:44:35.375] iteration 19783 : model1 loss : 0.155342 model2 loss : 0.164158
[23:44:35.702] iteration 19784 : model1 loss : 0.113988 model2 loss : 0.161396
[23:44:36.023] iteration 19785 : model1 loss : 0.189799 model2 loss : 0.273909
[23:44:36.349] iteration 19786 : model1 loss : 0.272833 model2 loss : 0.270362
[23:44:36.674] iteration 19787 : model1 loss : 0.075120 model2 loss : 0.139790
[23:44:36.995] iteration 19788 : model1 loss : 0.275563 model2 loss : 0.286932
[23:44:37.316] iteration 19789 : model1 loss : 0.248914 model2 loss : 0.276108
[23:44:37.642] iteration 19790 : model1 loss : 0.086209 model2 loss : 0.122939
[23:44:37.964] iteration 19791 : model1 loss : 0.318315 model2 loss : 0.340775
[23:44:38.289] iteration 19792 : model1 loss : 0.333760 model2 loss : 0.371263
[23:44:38.609] iteration 19793 : model1 loss : 0.130628 model2 loss : 0.098911
[23:44:38.931] iteration 19794 : model1 loss : 0.197378 model2 loss : 0.246014
[23:44:39.252] iteration 19795 : model1 loss : 0.198832 model2 loss : 0.276371
[23:44:39.579] iteration 19796 : model1 loss : 0.186041 model2 loss : 0.197332
[23:44:39.901] iteration 19797 : model1 loss : 0.127364 model2 loss : 0.141882
[23:44:40.223] iteration 19798 : model1 loss : 0.259687 model2 loss : 0.302289
[23:44:40.544] iteration 19799 : model1 loss : 0.107277 model2 loss : 0.190137
[23:44:40.869] iteration 19800 : model1 loss : 0.329957 model2 loss : 0.381544
[23:44:41.373] iteration 19801 : model1 loss : 0.193656 model2 loss : 0.256389
[23:44:41.695] iteration 19802 : model1 loss : 0.191240 model2 loss : 0.270949
[23:44:42.017] iteration 19803 : model1 loss : 0.253076 model2 loss : 0.286452
[23:44:42.342] iteration 19804 : model1 loss : 0.280736 model2 loss : 0.308987
[23:44:42.663] iteration 19805 : model1 loss : 0.293964 model2 loss : 0.277108
[23:44:42.990] iteration 19806 : model1 loss : 0.239137 model2 loss : 0.263563
[23:44:43.311] iteration 19807 : model1 loss : 0.115555 model2 loss : 0.122798
[23:44:43.633] iteration 19808 : model1 loss : 0.164971 model2 loss : 0.171452
[23:44:43.954] iteration 19809 : model1 loss : 0.277936 model2 loss : 0.307682
[23:44:44.274] iteration 19810 : model1 loss : 0.198015 model2 loss : 0.333073
[23:44:44.597] iteration 19811 : model1 loss : 0.080565 model2 loss : 0.098497
[23:44:44.922] iteration 19812 : model1 loss : 0.114677 model2 loss : 0.135898
[23:44:45.244] iteration 19813 : model1 loss : 0.172416 model2 loss : 0.199581
[23:44:45.569] iteration 19814 : model1 loss : 0.163958 model2 loss : 0.182403
[23:44:45.891] iteration 19815 : model1 loss : 0.272887 model2 loss : 0.296196
[23:44:46.217] iteration 19816 : model1 loss : 0.086456 model2 loss : 0.104933
[23:44:46.539] iteration 19817 : model1 loss : 0.124539 model2 loss : 0.170538
[23:44:46.860] iteration 19818 : model1 loss : 0.183266 model2 loss : 0.223112
[23:44:47.185] iteration 19819 : model1 loss : 0.165498 model2 loss : 0.232436
[23:44:47.508] iteration 19820 : model1 loss : 0.257274 model2 loss : 0.332553
[23:44:47.833] iteration 19821 : model1 loss : 0.145957 model2 loss : 0.157201
[23:44:48.158] iteration 19822 : model1 loss : 0.168736 model2 loss : 0.193009
[23:44:48.479] iteration 19823 : model1 loss : 0.137548 model2 loss : 0.190653
[23:44:48.800] iteration 19824 : model1 loss : 0.203845 model2 loss : 0.279485
[23:44:49.122] iteration 19825 : model1 loss : 0.183176 model2 loss : 0.217017
[23:44:49.443] iteration 19826 : model1 loss : 0.261773 model2 loss : 0.294103
[23:44:49.764] iteration 19827 : model1 loss : 0.164281 model2 loss : 0.168057
[23:44:50.086] iteration 19828 : model1 loss : 0.245688 model2 loss : 0.307780
[23:44:50.408] iteration 19829 : model1 loss : 0.178672 model2 loss : 0.235876
[23:44:50.731] iteration 19830 : model1 loss : 0.189776 model2 loss : 0.293825
[23:44:51.055] iteration 19831 : model1 loss : 0.174072 model2 loss : 0.273183
[23:44:51.376] iteration 19832 : model1 loss : 0.241081 model2 loss : 0.287851
[23:44:51.699] iteration 19833 : model1 loss : 0.191008 model2 loss : 0.227705
[23:44:52.021] iteration 19834 : model1 loss : 0.159918 model2 loss : 0.212076
[23:44:52.343] iteration 19835 : model1 loss : 0.177804 model2 loss : 0.187918
[23:44:52.664] iteration 19836 : model1 loss : 0.075816 model2 loss : 0.111227
[23:44:52.988] iteration 19837 : model1 loss : 0.121793 model2 loss : 0.153215
[23:44:53.309] iteration 19838 : model1 loss : 0.173566 model2 loss : 0.163515
[23:44:53.633] iteration 19839 : model1 loss : 0.132963 model2 loss : 0.146031
[23:44:53.955] iteration 19840 : model1 loss : 0.171062 model2 loss : 0.201193
[23:44:54.276] iteration 19841 : model1 loss : 0.156832 model2 loss : 0.218842
[23:44:54.597] iteration 19842 : model1 loss : 0.183971 model2 loss : 0.193789
[23:44:54.918] iteration 19843 : model1 loss : 0.247059 model2 loss : 0.277267
[23:44:55.243] iteration 19844 : model1 loss : 0.135380 model2 loss : 0.124989
[23:44:55.566] iteration 19845 : model1 loss : 0.270627 model2 loss : 0.295832
[23:44:55.895] iteration 19846 : model1 loss : 0.254501 model2 loss : 0.298558
[23:44:56.217] iteration 19847 : model1 loss : 0.265738 model2 loss : 0.299921
[23:44:56.538] iteration 19848 : model1 loss : 0.241008 model2 loss : 0.330473
[23:44:56.860] iteration 19849 : model1 loss : 0.193407 model2 loss : 0.206269
[23:44:57.180] iteration 19850 : model1 loss : 0.180483 model2 loss : 0.195199
[23:44:57.706] iteration 19851 : model1 loss : 0.303519 model2 loss : 0.298153
[23:44:58.027] iteration 19852 : model1 loss : 0.178828 model2 loss : 0.210570
[23:44:58.349] iteration 19853 : model1 loss : 0.237993 model2 loss : 0.263681
[23:44:58.670] iteration 19854 : model1 loss : 0.180459 model2 loss : 0.237220
[23:44:58.991] iteration 19855 : model1 loss : 0.122743 model2 loss : 0.157360
[23:44:59.313] iteration 19856 : model1 loss : 0.233130 model2 loss : 0.257307
[23:44:59.635] iteration 19857 : model1 loss : 0.108044 model2 loss : 0.154538
[23:44:59.956] iteration 19858 : model1 loss : 0.113445 model2 loss : 0.124711
[23:45:00.278] iteration 19859 : model1 loss : 0.325527 model2 loss : 0.338115
[23:45:00.598] iteration 19860 : model1 loss : 0.265294 model2 loss : 0.289681
[23:45:00.923] iteration 19861 : model1 loss : 0.244465 model2 loss : 0.263405
[23:45:01.244] iteration 19862 : model1 loss : 0.219634 model2 loss : 0.253883
[23:45:01.568] iteration 19863 : model1 loss : 0.191574 model2 loss : 0.240900
[23:45:01.889] iteration 19864 : model1 loss : 0.172958 model2 loss : 0.179173
[23:45:02.215] iteration 19865 : model1 loss : 0.180945 model2 loss : 0.192935
[23:45:02.536] iteration 19866 : model1 loss : 0.204764 model2 loss : 0.199657
[23:45:02.857] iteration 19867 : model1 loss : 0.202339 model2 loss : 0.239683
[23:45:03.178] iteration 19868 : model1 loss : 0.194942 model2 loss : 0.235052
[23:45:03.499] iteration 19869 : model1 loss : 0.097597 model2 loss : 0.105905
[23:45:03.820] iteration 19870 : model1 loss : 0.131146 model2 loss : 0.134528
[23:45:04.142] iteration 19871 : model1 loss : 0.203967 model2 loss : 0.296114
[23:45:04.462] iteration 19872 : model1 loss : 0.143524 model2 loss : 0.171397
[23:45:04.783] iteration 19873 : model1 loss : 0.066179 model2 loss : 0.101235
[23:45:05.109] iteration 19874 : model1 loss : 0.292289 model2 loss : 0.305721
[23:45:05.435] iteration 19875 : model1 loss : 0.195974 model2 loss : 0.197830
[23:45:05.757] iteration 19876 : model1 loss : 0.279450 model2 loss : 0.297673
[23:45:06.079] iteration 19877 : model1 loss : 0.292794 model2 loss : 0.283999
[23:45:06.402] iteration 19878 : model1 loss : 0.193206 model2 loss : 0.179359
[23:45:06.727] iteration 19879 : model1 loss : 0.163428 model2 loss : 0.218858
[23:45:07.047] iteration 19880 : model1 loss : 0.250057 model2 loss : 0.275246
[23:45:07.370] iteration 19881 : model1 loss : 0.287340 model2 loss : 0.321238
[23:45:07.692] iteration 19882 : model1 loss : 0.291398 model2 loss : 0.307308
[23:45:08.013] iteration 19883 : model1 loss : 0.192229 model2 loss : 0.218934
[23:45:08.338] iteration 19884 : model1 loss : 0.178705 model2 loss : 0.251259
[23:45:08.669] iteration 19885 : model1 loss : 0.155716 model2 loss : 0.175961
[23:45:09.004] iteration 19886 : model1 loss : 0.159166 model2 loss : 0.212988
[23:45:09.340] iteration 19887 : model1 loss : 0.258675 model2 loss : 0.306076
[23:45:09.678] iteration 19888 : model1 loss : 0.234605 model2 loss : 0.281848
[23:45:10.012] iteration 19889 : model1 loss : 0.185615 model2 loss : 0.217354
[23:45:10.349] iteration 19890 : model1 loss : 0.110995 model2 loss : 0.208033
[23:45:10.682] iteration 19891 : model1 loss : 0.100594 model2 loss : 0.133119
[23:45:11.017] iteration 19892 : model1 loss : 0.195942 model2 loss : 0.237454
[23:45:11.350] iteration 19893 : model1 loss : 0.177507 model2 loss : 0.171059
[23:45:11.684] iteration 19894 : model1 loss : 0.264492 model2 loss : 0.274877
[23:45:12.026] iteration 19895 : model1 loss : 0.180168 model2 loss : 0.215159
[23:45:12.361] iteration 19896 : model1 loss : 0.249081 model2 loss : 0.291966
[23:45:12.695] iteration 19897 : model1 loss : 0.180744 model2 loss : 0.210247
[23:45:13.036] iteration 19898 : model1 loss : 0.172787 model2 loss : 0.228747
[23:45:13.375] iteration 19899 : model1 loss : 0.164646 model2 loss : 0.162302
[23:45:13.716] iteration 19900 : model1 loss : 0.253093 model2 loss : 0.283279
[23:45:14.354] iteration 19901 : model1 loss : 0.169232 model2 loss : 0.234068
[23:45:14.688] iteration 19902 : model1 loss : 0.245626 model2 loss : 0.290105
[23:45:15.021] iteration 19903 : model1 loss : 0.185519 model2 loss : 0.202852
[23:45:15.355] iteration 19904 : model1 loss : 0.244449 model2 loss : 0.306647
[23:45:15.692] iteration 19905 : model1 loss : 0.217628 model2 loss : 0.193398
[23:45:16.026] iteration 19906 : model1 loss : 0.279788 model2 loss : 0.323012
[23:45:16.366] iteration 19907 : model1 loss : 0.149345 model2 loss : 0.192819
[23:45:16.704] iteration 19908 : model1 loss : 0.103291 model2 loss : 0.151048
[23:45:17.038] iteration 19909 : model1 loss : 0.191832 model2 loss : 0.206138
[23:45:17.371] iteration 19910 : model1 loss : 0.189124 model2 loss : 0.218192
[23:45:17.706] iteration 19911 : model1 loss : 0.209343 model2 loss : 0.196173
[23:45:18.039] iteration 19912 : model1 loss : 0.196561 model2 loss : 0.166340
[23:45:18.372] iteration 19913 : model1 loss : 0.225668 model2 loss : 0.236032
[23:45:18.710] iteration 19914 : model1 loss : 0.140811 model2 loss : 0.123992
[23:45:19.052] iteration 19915 : model1 loss : 0.353506 model2 loss : 0.325373
[23:45:19.386] iteration 19916 : model1 loss : 0.096939 model2 loss : 0.121961
[23:45:19.718] iteration 19917 : model1 loss : 0.261688 model2 loss : 0.250837
[23:45:20.056] iteration 19918 : model1 loss : 0.234910 model2 loss : 0.228958
[23:45:20.397] iteration 19919 : model1 loss : 0.267318 model2 loss : 0.337969
[23:45:20.734] iteration 19920 : model1 loss : 0.082214 model2 loss : 0.124520
[23:45:21.071] iteration 19921 : model1 loss : 0.175747 model2 loss : 0.178978
[23:45:21.410] iteration 19922 : model1 loss : 0.164726 model2 loss : 0.219784
[23:45:21.747] iteration 19923 : model1 loss : 0.130358 model2 loss : 0.195322
[23:45:22.080] iteration 19924 : model1 loss : 0.152841 model2 loss : 0.186778
[23:45:22.412] iteration 19925 : model1 loss : 0.248729 model2 loss : 0.340675
[23:45:22.744] iteration 19926 : model1 loss : 0.250065 model2 loss : 0.308571
[23:45:23.081] iteration 19927 : model1 loss : 0.161078 model2 loss : 0.214457
[23:45:23.414] iteration 19928 : model1 loss : 0.270056 model2 loss : 0.275993
[23:45:23.750] iteration 19929 : model1 loss : 0.266884 model2 loss : 0.300090
[23:45:24.084] iteration 19930 : model1 loss : 0.197484 model2 loss : 0.297517
[23:45:24.420] iteration 19931 : model1 loss : 0.256559 model2 loss : 0.272872
[23:45:24.753] iteration 19932 : model1 loss : 0.194682 model2 loss : 0.206855
[23:45:25.085] iteration 19933 : model1 loss : 0.119148 model2 loss : 0.211022
[23:45:25.423] iteration 19934 : model1 loss : 0.113609 model2 loss : 0.133787
[23:45:25.759] iteration 19935 : model1 loss : 0.166315 model2 loss : 0.267297
[23:45:26.100] iteration 19936 : model1 loss : 0.263104 model2 loss : 0.282556
[23:45:26.456] iteration 19937 : model1 loss : 0.171590 model2 loss : 0.200327
[23:45:26.791] iteration 19938 : model1 loss : 0.239074 model2 loss : 0.262638
[23:45:27.131] iteration 19939 : model1 loss : 0.179199 model2 loss : 0.209548
[23:45:27.464] iteration 19940 : model1 loss : 0.165444 model2 loss : 0.190438
[23:45:27.797] iteration 19941 : model1 loss : 0.144158 model2 loss : 0.179656
[23:45:28.131] iteration 19942 : model1 loss : 0.227446 model2 loss : 0.326903
[23:45:28.466] iteration 19943 : model1 loss : 0.291771 model2 loss : 0.344556
[23:45:28.799] iteration 19944 : model1 loss : 0.187394 model2 loss : 0.185797
[23:45:29.133] iteration 19945 : model1 loss : 0.167048 model2 loss : 0.252100
[23:45:29.466] iteration 19946 : model1 loss : 0.139953 model2 loss : 0.187863
[23:45:29.798] iteration 19947 : model1 loss : 0.085914 model2 loss : 0.119760
[23:45:30.138] iteration 19948 : model1 loss : 0.106343 model2 loss : 0.127545
[23:45:30.472] iteration 19949 : model1 loss : 0.170699 model2 loss : 0.166604
[23:45:30.808] iteration 19950 : model1 loss : 0.187482 model2 loss : 0.233792
[23:45:31.432] iteration 19951 : model1 loss : 0.163433 model2 loss : 0.196027
[23:45:31.769] iteration 19952 : model1 loss : 0.210863 model2 loss : 0.296491
[23:45:32.102] iteration 19953 : model1 loss : 0.242591 model2 loss : 0.391828
[23:45:32.438] iteration 19954 : model1 loss : 0.154943 model2 loss : 0.178651
[23:45:32.772] iteration 19955 : model1 loss : 0.175559 model2 loss : 0.203241
[23:45:33.106] iteration 19956 : model1 loss : 0.187281 model2 loss : 0.230764
[23:45:33.439] iteration 19957 : model1 loss : 0.171647 model2 loss : 0.240242
[23:45:33.774] iteration 19958 : model1 loss : 0.186270 model2 loss : 0.198446
[23:45:34.110] iteration 19959 : model1 loss : 0.195432 model2 loss : 0.210882
[23:45:34.448] iteration 19960 : model1 loss : 0.197002 model2 loss : 0.199764
[23:45:34.781] iteration 19961 : model1 loss : 0.205206 model2 loss : 0.201240
[23:45:35.118] iteration 19962 : model1 loss : 0.198621 model2 loss : 0.328646
[23:45:35.452] iteration 19963 : model1 loss : 0.187899 model2 loss : 0.277941
[23:45:35.786] iteration 19964 : model1 loss : 0.153113 model2 loss : 0.197928
[23:45:36.120] iteration 19965 : model1 loss : 0.114370 model2 loss : 0.170877
[23:45:36.457] iteration 19966 : model1 loss : 0.250950 model2 loss : 0.282619
[23:45:36.792] iteration 19967 : model1 loss : 0.197106 model2 loss : 0.244090
[23:45:37.131] iteration 19968 : model1 loss : 0.269937 model2 loss : 0.280347
[23:45:37.464] iteration 19969 : model1 loss : 0.086967 model2 loss : 0.120724
[23:45:37.800] iteration 19970 : model1 loss : 0.166684 model2 loss : 0.265945
[23:45:38.133] iteration 19971 : model1 loss : 0.118557 model2 loss : 0.112127
[23:45:38.468] iteration 19972 : model1 loss : 0.217492 model2 loss : 0.238818
[23:45:38.806] iteration 19973 : model1 loss : 0.175093 model2 loss : 0.211024
[23:45:39.141] iteration 19974 : model1 loss : 0.175635 model2 loss : 0.205921
[23:45:39.484] iteration 19975 : model1 loss : 0.219270 model2 loss : 0.213221
[23:45:39.817] iteration 19976 : model1 loss : 0.253427 model2 loss : 0.259706
[23:45:40.152] iteration 19977 : model1 loss : 0.263548 model2 loss : 0.292158
[23:45:40.488] iteration 19978 : model1 loss : 0.198314 model2 loss : 0.238299
[23:45:40.822] iteration 19979 : model1 loss : 0.168011 model2 loss : 0.225185
[23:45:41.154] iteration 19980 : model1 loss : 0.234590 model2 loss : 0.230055
[23:45:41.491] iteration 19981 : model1 loss : 0.261494 model2 loss : 0.271112
[23:45:41.827] iteration 19982 : model1 loss : 0.088055 model2 loss : 0.200439
[23:45:42.160] iteration 19983 : model1 loss : 0.211880 model2 loss : 0.273076
[23:45:42.498] iteration 19984 : model1 loss : 0.092131 model2 loss : 0.123421
[23:45:42.829] iteration 19985 : model1 loss : 0.110033 model2 loss : 0.138387
[23:45:43.165] iteration 19986 : model1 loss : 0.214390 model2 loss : 0.228768
[23:45:43.500] iteration 19987 : model1 loss : 0.105667 model2 loss : 0.139408
[23:45:43.833] iteration 19988 : model1 loss : 0.243505 model2 loss : 0.288828
[23:45:44.167] iteration 19989 : model1 loss : 0.082407 model2 loss : 0.147029
[23:45:44.500] iteration 19990 : model1 loss : 0.202994 model2 loss : 0.255120
[23:45:44.836] iteration 19991 : model1 loss : 0.197688 model2 loss : 0.243903
[23:45:45.171] iteration 19992 : model1 loss : 0.165500 model2 loss : 0.221289
[23:45:45.504] iteration 19993 : model1 loss : 0.234717 model2 loss : 0.273447
[23:45:45.841] iteration 19994 : model1 loss : 0.198237 model2 loss : 0.202912
[23:45:46.174] iteration 19995 : model1 loss : 0.174247 model2 loss : 0.187933
[23:45:46.515] iteration 19996 : model1 loss : 0.084210 model2 loss : 0.155127
[23:45:46.849] iteration 19997 : model1 loss : 0.170084 model2 loss : 0.181718
[23:45:47.189] iteration 19998 : model1 loss : 0.202266 model2 loss : 0.252395
[23:45:47.529] iteration 19999 : model1 loss : 0.181433 model2 loss : 0.184067
[23:45:47.861] iteration 20000 : model1 loss : 0.415142 model2 loss : 0.434459
[23:45:48.466] iteration 20001 : model1 loss : 0.078430 model2 loss : 0.102087
[23:45:48.798] iteration 20002 : model1 loss : 0.160400 model2 loss : 0.188393
[23:45:49.131] iteration 20003 : model1 loss : 0.169626 model2 loss : 0.242163
[23:45:49.471] iteration 20004 : model1 loss : 0.164552 model2 loss : 0.227763
[23:45:49.805] iteration 20005 : model1 loss : 0.183394 model2 loss : 0.189895
[23:45:50.137] iteration 20006 : model1 loss : 0.178743 model2 loss : 0.223742
[23:45:50.474] iteration 20007 : model1 loss : 0.128329 model2 loss : 0.198422
[23:45:50.810] iteration 20008 : model1 loss : 0.171819 model2 loss : 0.197049
[23:45:51.150] iteration 20009 : model1 loss : 0.161428 model2 loss : 0.178256
[23:45:51.485] iteration 20010 : model1 loss : 0.135787 model2 loss : 0.161468
[23:45:51.819] iteration 20011 : model1 loss : 0.319147 model2 loss : 0.326512
[23:45:52.152] iteration 20012 : model1 loss : 0.076282 model2 loss : 0.093181
[23:45:52.493] iteration 20013 : model1 loss : 0.212278 model2 loss : 0.235888
[23:45:52.826] iteration 20014 : model1 loss : 0.200287 model2 loss : 0.244960
[23:45:53.158] iteration 20015 : model1 loss : 0.171839 model2 loss : 0.179596
[23:45:53.490] iteration 20016 : model1 loss : 0.187254 model2 loss : 0.218100
[23:45:53.823] iteration 20017 : model1 loss : 0.249955 model2 loss : 0.291994
[23:45:54.156] iteration 20018 : model1 loss : 0.195375 model2 loss : 0.207799
[23:45:54.491] iteration 20019 : model1 loss : 0.207191 model2 loss : 0.249413
[23:45:54.823] iteration 20020 : model1 loss : 0.145342 model2 loss : 0.154390
[23:45:55.163] iteration 20021 : model1 loss : 0.217983 model2 loss : 0.218547
[23:45:55.501] iteration 20022 : model1 loss : 0.172875 model2 loss : 0.238142
[23:45:55.834] iteration 20023 : model1 loss : 0.245854 model2 loss : 0.249878
[23:45:56.167] iteration 20024 : model1 loss : 0.167773 model2 loss : 0.230354
[23:45:56.494] iteration 20025 : model1 loss : 0.172885 model2 loss : 0.176994
[23:45:56.820] iteration 20026 : model1 loss : 0.250130 model2 loss : 0.311581
[23:45:57.150] iteration 20027 : model1 loss : 0.229210 model2 loss : 0.245833
[23:45:57.480] iteration 20028 : model1 loss : 0.312808 model2 loss : 0.330203
[23:45:57.804] iteration 20029 : model1 loss : 0.118507 model2 loss : 0.145369
[23:45:58.127] iteration 20030 : model1 loss : 0.313275 model2 loss : 0.320607
[23:45:58.450] iteration 20031 : model1 loss : 0.118443 model2 loss : 0.104135
[23:45:58.779] iteration 20032 : model1 loss : 0.226986 model2 loss : 0.262960
[23:45:59.107] iteration 20033 : model1 loss : 0.235892 model2 loss : 0.247976
[23:45:59.434] iteration 20034 : model1 loss : 0.167566 model2 loss : 0.198534
[23:45:59.757] iteration 20035 : model1 loss : 0.232489 model2 loss : 0.275232
[23:46:00.083] iteration 20036 : model1 loss : 0.168597 model2 loss : 0.193290
[23:46:00.410] iteration 20037 : model1 loss : 0.256565 model2 loss : 0.288171
[23:46:00.738] iteration 20038 : model1 loss : 0.098752 model2 loss : 0.111063
[23:46:01.063] iteration 20039 : model1 loss : 0.272751 model2 loss : 0.274798
[23:46:01.385] iteration 20040 : model1 loss : 0.167892 model2 loss : 0.197422
[23:46:01.706] iteration 20041 : model1 loss : 0.253521 model2 loss : 0.284487
[23:46:02.027] iteration 20042 : model1 loss : 0.131552 model2 loss : 0.160236
[23:46:02.348] iteration 20043 : model1 loss : 0.237301 model2 loss : 0.159516
[23:46:02.669] iteration 20044 : model1 loss : 0.185097 model2 loss : 0.215256
[23:46:02.989] iteration 20045 : model1 loss : 0.102488 model2 loss : 0.215218
[23:46:03.311] iteration 20046 : model1 loss : 0.172518 model2 loss : 0.196651
[23:46:03.632] iteration 20047 : model1 loss : 0.154644 model2 loss : 0.181873
[23:46:03.953] iteration 20048 : model1 loss : 0.123972 model2 loss : 0.236614
[23:46:04.274] iteration 20049 : model1 loss : 0.280486 model2 loss : 0.290736
[23:46:04.596] iteration 20050 : model1 loss : 0.251298 model2 loss : 0.348964
[23:46:05.105] iteration 20051 : model1 loss : 0.090927 model2 loss : 0.136083
[23:46:05.432] iteration 20052 : model1 loss : 0.167046 model2 loss : 0.155298
[23:46:05.757] iteration 20053 : model1 loss : 0.211514 model2 loss : 0.206758
[23:46:06.078] iteration 20054 : model1 loss : 0.274367 model2 loss : 0.293665
[23:46:06.404] iteration 20055 : model1 loss : 0.378798 model2 loss : 0.390839
[23:46:06.725] iteration 20056 : model1 loss : 0.101627 model2 loss : 0.254833
[23:46:07.047] iteration 20057 : model1 loss : 0.216707 model2 loss : 0.154933
[23:46:07.368] iteration 20058 : model1 loss : 0.178229 model2 loss : 0.177947
[23:46:07.689] iteration 20059 : model1 loss : 0.168095 model2 loss : 0.232683
[23:46:08.010] iteration 20060 : model1 loss : 0.228999 model2 loss : 0.244092
[23:46:08.332] iteration 20061 : model1 loss : 0.256896 model2 loss : 0.272178
[23:46:08.653] iteration 20062 : model1 loss : 0.117810 model2 loss : 0.177665
[23:46:08.974] iteration 20063 : model1 loss : 0.337966 model2 loss : 0.332029
[23:46:09.295] iteration 20064 : model1 loss : 0.165477 model2 loss : 0.284792
[23:46:09.617] iteration 20065 : model1 loss : 0.106916 model2 loss : 0.162749
[23:46:09.938] iteration 20066 : model1 loss : 0.119754 model2 loss : 0.159799
[23:46:10.259] iteration 20067 : model1 loss : 0.243503 model2 loss : 0.255539
[23:46:10.581] iteration 20068 : model1 loss : 0.279971 model2 loss : 0.259223
[23:46:10.906] iteration 20069 : model1 loss : 0.191934 model2 loss : 0.242454
[23:46:11.226] iteration 20070 : model1 loss : 0.094565 model2 loss : 0.158926
[23:46:11.547] iteration 20071 : model1 loss : 0.235189 model2 loss : 0.262487
[23:46:11.868] iteration 20072 : model1 loss : 0.161666 model2 loss : 0.173556
[23:46:12.189] iteration 20073 : model1 loss : 0.102236 model2 loss : 0.160580
[23:46:12.511] iteration 20074 : model1 loss : 0.193909 model2 loss : 0.194729
[23:46:12.833] iteration 20075 : model1 loss : 0.230018 model2 loss : 0.312964
[23:46:13.158] iteration 20076 : model1 loss : 0.293673 model2 loss : 0.320489
[23:46:13.479] iteration 20077 : model1 loss : 0.252751 model2 loss : 0.251725
[23:46:13.800] iteration 20078 : model1 loss : 0.238570 model2 loss : 0.306890
[23:46:14.127] iteration 20079 : model1 loss : 0.272935 model2 loss : 0.262968
[23:46:14.448] iteration 20080 : model1 loss : 0.336895 model2 loss : 0.347980
[23:46:14.773] iteration 20081 : model1 loss : 0.196109 model2 loss : 0.223599
[23:46:15.095] iteration 20082 : model1 loss : 0.093356 model2 loss : 0.146585
[23:46:15.417] iteration 20083 : model1 loss : 0.256131 model2 loss : 0.290054
[23:46:15.743] iteration 20084 : model1 loss : 0.252891 model2 loss : 0.268475
[23:46:16.068] iteration 20085 : model1 loss : 0.107441 model2 loss : 0.207437
[23:46:16.395] iteration 20086 : model1 loss : 0.309216 model2 loss : 0.336749
[23:46:16.721] iteration 20087 : model1 loss : 0.169521 model2 loss : 0.240428
[23:46:17.047] iteration 20088 : model1 loss : 0.216905 model2 loss : 0.201176
[23:46:17.374] iteration 20089 : model1 loss : 0.264711 model2 loss : 0.323149
[23:46:17.700] iteration 20090 : model1 loss : 0.157096 model2 loss : 0.176038
[23:46:18.027] iteration 20091 : model1 loss : 0.111279 model2 loss : 0.166225
[23:46:18.353] iteration 20092 : model1 loss : 0.197809 model2 loss : 0.267115
[23:46:18.680] iteration 20093 : model1 loss : 0.185323 model2 loss : 0.208819
[23:46:19.006] iteration 20094 : model1 loss : 0.192381 model2 loss : 0.216682
[23:46:19.332] iteration 20095 : model1 loss : 0.174302 model2 loss : 0.219414
[23:46:19.659] iteration 20096 : model1 loss : 0.189320 model2 loss : 0.182552
[23:46:19.984] iteration 20097 : model1 loss : 0.265306 model2 loss : 0.229016
[23:46:20.311] iteration 20098 : model1 loss : 0.192544 model2 loss : 0.237664
[23:46:20.638] iteration 20099 : model1 loss : 0.262912 model2 loss : 0.277989
[23:46:20.965] iteration 20100 : model1 loss : 0.142792 model2 loss : 0.128799
[23:46:21.494] iteration 20101 : model1 loss : 0.200053 model2 loss : 0.235017
[23:46:21.820] iteration 20102 : model1 loss : 0.254546 model2 loss : 0.298368
[23:46:22.146] iteration 20103 : model1 loss : 0.188706 model2 loss : 0.219973
[23:46:22.471] iteration 20104 : model1 loss : 0.151540 model2 loss : 0.165968
[23:46:22.797] iteration 20105 : model1 loss : 0.247648 model2 loss : 0.248357
[23:46:23.124] iteration 20106 : model1 loss : 0.206341 model2 loss : 0.212186
[23:46:23.451] iteration 20107 : model1 loss : 0.193706 model2 loss : 0.207291
[23:46:23.777] iteration 20108 : model1 loss : 0.095813 model2 loss : 0.149876
[23:46:24.102] iteration 20109 : model1 loss : 0.222917 model2 loss : 0.230812
[23:46:24.429] iteration 20110 : model1 loss : 0.179477 model2 loss : 0.208591
[23:46:24.755] iteration 20111 : model1 loss : 0.214149 model2 loss : 0.200542
[23:46:25.080] iteration 20112 : model1 loss : 0.310874 model2 loss : 0.293919
[23:46:25.406] iteration 20113 : model1 loss : 0.269753 model2 loss : 0.282201
[23:46:25.732] iteration 20114 : model1 loss : 0.197013 model2 loss : 0.324928
[23:46:26.059] iteration 20115 : model1 loss : 0.113820 model2 loss : 0.132813
[23:46:26.384] iteration 20116 : model1 loss : 0.187414 model2 loss : 0.219959
[23:46:26.709] iteration 20117 : model1 loss : 0.290656 model2 loss : 0.316036
[23:46:27.034] iteration 20118 : model1 loss : 0.189805 model2 loss : 0.241910
[23:46:27.360] iteration 20119 : model1 loss : 0.209744 model2 loss : 0.227647
[23:46:27.686] iteration 20120 : model1 loss : 0.248305 model2 loss : 0.283705
[23:46:28.013] iteration 20121 : model1 loss : 0.249484 model2 loss : 0.289287
[23:46:28.338] iteration 20122 : model1 loss : 0.211745 model2 loss : 0.238775
[23:46:28.663] iteration 20123 : model1 loss : 0.283087 model2 loss : 0.297676
[23:46:28.989] iteration 20124 : model1 loss : 0.193271 model2 loss : 0.262435
[23:46:29.316] iteration 20125 : model1 loss : 0.288794 model2 loss : 0.278888
[23:46:29.642] iteration 20126 : model1 loss : 0.170129 model2 loss : 0.201090
[23:46:29.967] iteration 20127 : model1 loss : 0.268743 model2 loss : 0.262328
[23:46:30.293] iteration 20128 : model1 loss : 0.184103 model2 loss : 0.180422
[23:46:30.619] iteration 20129 : model1 loss : 0.236344 model2 loss : 0.255441
[23:46:30.943] iteration 20130 : model1 loss : 0.264504 model2 loss : 0.286686
[23:46:31.270] iteration 20131 : model1 loss : 0.292211 model2 loss : 0.328580
[23:46:31.595] iteration 20132 : model1 loss : 0.124588 model2 loss : 0.128679
[23:46:31.920] iteration 20133 : model1 loss : 0.243977 model2 loss : 0.256898
[23:46:32.245] iteration 20134 : model1 loss : 0.205845 model2 loss : 0.274047
[23:46:32.571] iteration 20135 : model1 loss : 0.192712 model2 loss : 0.211073
[23:46:32.898] iteration 20136 : model1 loss : 0.106415 model2 loss : 0.127973
[23:46:33.223] iteration 20137 : model1 loss : 0.228260 model2 loss : 0.249692
[23:46:33.549] iteration 20138 : model1 loss : 0.159385 model2 loss : 0.182261
[23:46:33.875] iteration 20139 : model1 loss : 0.180786 model2 loss : 0.244948
[23:46:34.199] iteration 20140 : model1 loss : 0.245483 model2 loss : 0.280854
[23:46:34.525] iteration 20141 : model1 loss : 0.175698 model2 loss : 0.182844
[23:46:34.850] iteration 20142 : model1 loss : 0.325881 model2 loss : 0.352946
[23:46:35.176] iteration 20143 : model1 loss : 0.172142 model2 loss : 0.229691
[23:46:35.501] iteration 20144 : model1 loss : 0.252453 model2 loss : 0.275597
[23:46:35.827] iteration 20145 : model1 loss : 0.172632 model2 loss : 0.203841
[23:46:36.153] iteration 20146 : model1 loss : 0.196117 model2 loss : 0.173846
[23:46:36.478] iteration 20147 : model1 loss : 0.226945 model2 loss : 0.232075
[23:46:36.804] iteration 20148 : model1 loss : 0.129084 model2 loss : 0.204026
[23:46:37.129] iteration 20149 : model1 loss : 0.180201 model2 loss : 0.194822
[23:46:37.455] iteration 20150 : model1 loss : 0.173020 model2 loss : 0.197381
[23:46:37.983] iteration 20151 : model1 loss : 0.106049 model2 loss : 0.114185
[23:46:38.309] iteration 20152 : model1 loss : 0.237605 model2 loss : 0.258902
[23:46:38.635] iteration 20153 : model1 loss : 0.158192 model2 loss : 0.196027
[23:46:38.961] iteration 20154 : model1 loss : 0.163784 model2 loss : 0.175283
[23:46:39.284] iteration 20155 : model1 loss : 0.086236 model2 loss : 0.138294
[23:46:39.610] iteration 20156 : model1 loss : 0.175707 model2 loss : 0.257628
[23:46:39.934] iteration 20157 : model1 loss : 0.168131 model2 loss : 0.222921
[23:46:40.259] iteration 20158 : model1 loss : 0.250649 model2 loss : 0.265195
[23:46:40.585] iteration 20159 : model1 loss : 0.201846 model2 loss : 0.265845
[23:46:40.910] iteration 20160 : model1 loss : 0.226412 model2 loss : 0.211079
[23:46:41.235] iteration 20161 : model1 loss : 0.185290 model2 loss : 0.242646
[23:46:41.560] iteration 20162 : model1 loss : 0.193094 model2 loss : 0.411398
[23:46:41.885] iteration 20163 : model1 loss : 0.182468 model2 loss : 0.238954
[23:46:42.210] iteration 20164 : model1 loss : 0.237831 model2 loss : 0.283724
[23:46:42.535] iteration 20165 : model1 loss : 0.089869 model2 loss : 0.121323
[23:46:43.401] iteration 20166 : model1 loss : 0.331789 model2 loss : 0.333244
[23:46:43.728] iteration 20167 : model1 loss : 0.217877 model2 loss : 0.222595
[23:46:44.058] iteration 20168 : model1 loss : 0.287826 model2 loss : 0.274200
[23:46:44.383] iteration 20169 : model1 loss : 0.251060 model2 loss : 0.307122
[23:46:44.712] iteration 20170 : model1 loss : 0.263969 model2 loss : 0.298031
[23:46:45.041] iteration 20171 : model1 loss : 0.174734 model2 loss : 0.230492
[23:46:45.372] iteration 20172 : model1 loss : 0.110134 model2 loss : 0.191649
[23:46:45.698] iteration 20173 : model1 loss : 0.259356 model2 loss : 0.352757
[23:46:46.024] iteration 20174 : model1 loss : 0.264517 model2 loss : 0.331861
[23:46:46.350] iteration 20175 : model1 loss : 0.095344 model2 loss : 0.106684
[23:46:46.681] iteration 20176 : model1 loss : 0.258963 model2 loss : 0.313799
[23:46:47.007] iteration 20177 : model1 loss : 0.223420 model2 loss : 0.203650
[23:46:47.333] iteration 20178 : model1 loss : 0.246790 model2 loss : 0.257420
[23:46:47.658] iteration 20179 : model1 loss : 0.138977 model2 loss : 0.195798
[23:46:47.987] iteration 20180 : model1 loss : 0.260232 model2 loss : 0.257085
[23:46:48.314] iteration 20181 : model1 loss : 0.144160 model2 loss : 0.185747
[23:46:48.640] iteration 20182 : model1 loss : 0.188290 model2 loss : 0.210810
[23:46:48.966] iteration 20183 : model1 loss : 0.255718 model2 loss : 0.360979
[23:46:49.295] iteration 20184 : model1 loss : 0.107844 model2 loss : 0.118018
[23:46:49.621] iteration 20185 : model1 loss : 0.233210 model2 loss : 0.250476
[23:46:49.947] iteration 20186 : model1 loss : 0.278767 model2 loss : 0.278079
[23:46:50.274] iteration 20187 : model1 loss : 0.179441 model2 loss : 0.220031
[23:46:50.596] iteration 20188 : model1 loss : 0.154113 model2 loss : 0.207664
[23:46:50.922] iteration 20189 : model1 loss : 0.184440 model2 loss : 0.185543
[23:46:51.248] iteration 20190 : model1 loss : 0.098688 model2 loss : 0.156840
[23:46:51.574] iteration 20191 : model1 loss : 0.111330 model2 loss : 0.183579
[23:46:51.904] iteration 20192 : model1 loss : 0.305648 model2 loss : 0.342781
[23:46:52.230] iteration 20193 : model1 loss : 0.181315 model2 loss : 0.255975
[23:46:52.555] iteration 20194 : model1 loss : 0.169739 model2 loss : 0.188691
[23:46:52.880] iteration 20195 : model1 loss : 0.109101 model2 loss : 0.101055
[23:46:53.203] iteration 20196 : model1 loss : 0.109049 model2 loss : 0.198395
[23:46:53.530] iteration 20197 : model1 loss : 0.224263 model2 loss : 0.164394
[23:46:53.855] iteration 20198 : model1 loss : 0.219052 model2 loss : 0.253679
[23:46:54.180] iteration 20199 : model1 loss : 0.273757 model2 loss : 0.258492
[23:46:54.504] iteration 20200 : model1 loss : 0.169443 model2 loss : 0.237231
[23:46:55.054] iteration 20201 : model1 loss : 0.178565 model2 loss : 0.191516
[23:46:55.380] iteration 20202 : model1 loss : 0.400807 model2 loss : 0.462992
[23:46:55.707] iteration 20203 : model1 loss : 0.166672 model2 loss : 0.216669
[23:46:56.036] iteration 20204 : model1 loss : 0.156257 model2 loss : 0.155194
[23:46:56.362] iteration 20205 : model1 loss : 0.174775 model2 loss : 0.195967
[23:46:56.687] iteration 20206 : model1 loss : 0.221526 model2 loss : 0.259175
[23:46:57.012] iteration 20207 : model1 loss : 0.164180 model2 loss : 0.203310
[23:46:57.338] iteration 20208 : model1 loss : 0.168335 model2 loss : 0.174797
[23:46:57.664] iteration 20209 : model1 loss : 0.114472 model2 loss : 0.194480
[23:46:57.990] iteration 20210 : model1 loss : 0.194666 model2 loss : 0.169796
[23:46:58.316] iteration 20211 : model1 loss : 0.254502 model2 loss : 0.333951
[23:46:58.643] iteration 20212 : model1 loss : 0.277449 model2 loss : 0.313865
[23:46:58.969] iteration 20213 : model1 loss : 0.124950 model2 loss : 0.124230
[23:46:59.295] iteration 20214 : model1 loss : 0.173650 model2 loss : 0.190507
[23:46:59.621] iteration 20215 : model1 loss : 0.113534 model2 loss : 0.130245
[23:46:59.947] iteration 20216 : model1 loss : 0.147181 model2 loss : 0.190585
[23:47:00.273] iteration 20217 : model1 loss : 0.154020 model2 loss : 0.143080
[23:47:00.599] iteration 20218 : model1 loss : 0.210167 model2 loss : 0.282980
[23:47:00.924] iteration 20219 : model1 loss : 0.316988 model2 loss : 0.318921
[23:47:01.250] iteration 20220 : model1 loss : 0.288318 model2 loss : 0.317279
[23:47:01.576] iteration 20221 : model1 loss : 0.289280 model2 loss : 0.367377
[23:47:01.902] iteration 20222 : model1 loss : 0.270853 model2 loss : 0.327307
[23:47:02.227] iteration 20223 : model1 loss : 0.188638 model2 loss : 0.195460
[23:47:02.553] iteration 20224 : model1 loss : 0.254414 model2 loss : 0.241570
[23:47:02.880] iteration 20225 : model1 loss : 0.233012 model2 loss : 0.235561
[23:47:03.206] iteration 20226 : model1 loss : 0.168023 model2 loss : 0.174035
[23:47:03.531] iteration 20227 : model1 loss : 0.176807 model2 loss : 0.211045
[23:47:03.857] iteration 20228 : model1 loss : 0.085940 model2 loss : 0.128572
[23:47:04.184] iteration 20229 : model1 loss : 0.200911 model2 loss : 0.253772
[23:47:04.510] iteration 20230 : model1 loss : 0.115340 model2 loss : 0.177829
[23:47:04.837] iteration 20231 : model1 loss : 0.188305 model2 loss : 0.283965
[23:47:05.163] iteration 20232 : model1 loss : 0.165955 model2 loss : 0.183805
[23:47:05.489] iteration 20233 : model1 loss : 0.275590 model2 loss : 0.317171
[23:47:05.816] iteration 20234 : model1 loss : 0.199919 model2 loss : 0.227331
[23:47:06.142] iteration 20235 : model1 loss : 0.175438 model2 loss : 0.216347
[23:47:06.470] iteration 20236 : model1 loss : 0.184595 model2 loss : 0.186420
[23:47:06.796] iteration 20237 : model1 loss : 0.189832 model2 loss : 0.240697
[23:47:07.122] iteration 20238 : model1 loss : 0.224473 model2 loss : 0.233242
[23:47:07.448] iteration 20239 : model1 loss : 0.176954 model2 loss : 0.186911
[23:47:07.778] iteration 20240 : model1 loss : 0.248361 model2 loss : 0.246273
[23:47:08.104] iteration 20241 : model1 loss : 0.305764 model2 loss : 0.361964
[23:47:08.431] iteration 20242 : model1 loss : 0.251825 model2 loss : 0.278273
[23:47:08.757] iteration 20243 : model1 loss : 0.166533 model2 loss : 0.176259
[23:47:09.084] iteration 20244 : model1 loss : 0.253042 model2 loss : 0.250555
[23:47:09.410] iteration 20245 : model1 loss : 0.203939 model2 loss : 0.206099
[23:47:09.735] iteration 20246 : model1 loss : 0.186846 model2 loss : 0.177590
[23:47:10.062] iteration 20247 : model1 loss : 0.098832 model2 loss : 0.134540
[23:47:10.388] iteration 20248 : model1 loss : 0.177819 model2 loss : 0.182426
[23:47:10.715] iteration 20249 : model1 loss : 0.155898 model2 loss : 0.173780
[23:47:11.041] iteration 20250 : model1 loss : 0.255084 model2 loss : 0.276712
[23:47:11.576] iteration 20251 : model1 loss : 0.101139 model2 loss : 0.118818
[23:47:11.902] iteration 20252 : model1 loss : 0.181381 model2 loss : 0.208753
[23:47:12.228] iteration 20253 : model1 loss : 0.129442 model2 loss : 0.161541
[23:47:12.553] iteration 20254 : model1 loss : 0.242963 model2 loss : 0.284507
[23:47:12.879] iteration 20255 : model1 loss : 0.247233 model2 loss : 0.296096
[23:47:13.205] iteration 20256 : model1 loss : 0.285339 model2 loss : 0.307361
[23:47:13.531] iteration 20257 : model1 loss : 0.212871 model2 loss : 0.285876
[23:47:13.858] iteration 20258 : model1 loss : 0.169414 model2 loss : 0.198834
[23:47:14.183] iteration 20259 : model1 loss : 0.190124 model2 loss : 0.271837
[23:47:14.509] iteration 20260 : model1 loss : 0.188984 model2 loss : 0.197540
[23:47:14.834] iteration 20261 : model1 loss : 0.199869 model2 loss : 0.270783
[23:47:15.161] iteration 20262 : model1 loss : 0.182392 model2 loss : 0.261734
[23:47:15.486] iteration 20263 : model1 loss : 0.270007 model2 loss : 0.264021
[23:47:15.813] iteration 20264 : model1 loss : 0.092861 model2 loss : 0.185340
[23:47:16.139] iteration 20265 : model1 loss : 0.198895 model2 loss : 0.200263
[23:47:16.464] iteration 20266 : model1 loss : 0.261231 model2 loss : 0.293823
[23:47:16.791] iteration 20267 : model1 loss : 0.096835 model2 loss : 0.187454
[23:47:17.118] iteration 20268 : model1 loss : 0.121078 model2 loss : 0.141679
[23:47:17.444] iteration 20269 : model1 loss : 0.186913 model2 loss : 0.257032
[23:47:17.770] iteration 20270 : model1 loss : 0.127897 model2 loss : 0.130040
[23:47:18.095] iteration 20271 : model1 loss : 0.209090 model2 loss : 0.239320
[23:47:18.422] iteration 20272 : model1 loss : 0.156679 model2 loss : 0.188676
[23:47:18.749] iteration 20273 : model1 loss : 0.173497 model2 loss : 0.204042
[23:47:19.076] iteration 20274 : model1 loss : 0.325377 model2 loss : 0.405566
[23:47:19.404] iteration 20275 : model1 loss : 0.180488 model2 loss : 0.238098
[23:47:19.729] iteration 20276 : model1 loss : 0.128927 model2 loss : 0.136560
[23:47:20.055] iteration 20277 : model1 loss : 0.112691 model2 loss : 0.111355
[23:47:20.381] iteration 20278 : model1 loss : 0.208073 model2 loss : 0.256383
[23:47:20.707] iteration 20279 : model1 loss : 0.245834 model2 loss : 0.265810
[23:47:21.033] iteration 20280 : model1 loss : 0.175462 model2 loss : 0.230413
[23:47:21.360] iteration 20281 : model1 loss : 0.248217 model2 loss : 0.267724
[23:47:21.685] iteration 20282 : model1 loss : 0.275020 model2 loss : 0.301791
[23:47:22.011] iteration 20283 : model1 loss : 0.247166 model2 loss : 0.265406
[23:47:22.337] iteration 20284 : model1 loss : 0.255278 model2 loss : 0.293403
[23:47:22.663] iteration 20285 : model1 loss : 0.147486 model2 loss : 0.224944
[23:47:22.988] iteration 20286 : model1 loss : 0.129893 model2 loss : 0.221751
[23:47:23.314] iteration 20287 : model1 loss : 0.166900 model2 loss : 0.195171
[23:47:23.640] iteration 20288 : model1 loss : 0.262245 model2 loss : 0.288232
[23:47:23.967] iteration 20289 : model1 loss : 0.162161 model2 loss : 0.179029
[23:47:24.293] iteration 20290 : model1 loss : 0.088740 model2 loss : 0.125377
[23:47:24.618] iteration 20291 : model1 loss : 0.244800 model2 loss : 0.267313
[23:47:24.945] iteration 20292 : model1 loss : 0.256225 model2 loss : 0.321173
[23:47:25.270] iteration 20293 : model1 loss : 0.261543 model2 loss : 0.273660
[23:47:25.596] iteration 20294 : model1 loss : 0.248948 model2 loss : 0.270006
[23:47:25.920] iteration 20295 : model1 loss : 0.190326 model2 loss : 0.221778
[23:47:26.247] iteration 20296 : model1 loss : 0.252057 model2 loss : 0.270041
[23:47:26.575] iteration 20297 : model1 loss : 0.113435 model2 loss : 0.155000
[23:47:26.901] iteration 20298 : model1 loss : 0.203494 model2 loss : 0.215764
[23:47:27.226] iteration 20299 : model1 loss : 0.090355 model2 loss : 0.135212
[23:47:27.552] iteration 20300 : model1 loss : 0.257346 model2 loss : 0.281921
[23:47:28.093] iteration 20301 : model1 loss : 0.323410 model2 loss : 0.361777
[23:47:28.421] iteration 20302 : model1 loss : 0.100216 model2 loss : 0.125742
[23:47:28.746] iteration 20303 : model1 loss : 0.253216 model2 loss : 0.282994
[23:47:29.073] iteration 20304 : model1 loss : 0.197179 model2 loss : 0.204517
[23:47:29.399] iteration 20305 : model1 loss : 0.228801 model2 loss : 0.301254
[23:47:29.725] iteration 20306 : model1 loss : 0.174882 model2 loss : 0.209807
[23:47:30.052] iteration 20307 : model1 loss : 0.178811 model2 loss : 0.242527
[23:47:30.380] iteration 20308 : model1 loss : 0.182894 model2 loss : 0.205373
[23:47:30.706] iteration 20309 : model1 loss : 0.172612 model2 loss : 0.160158
[23:47:31.032] iteration 20310 : model1 loss : 0.312106 model2 loss : 0.190299
[23:47:31.360] iteration 20311 : model1 loss : 0.185815 model2 loss : 0.261681
[23:47:31.686] iteration 20312 : model1 loss : 0.165351 model2 loss : 0.191438
[23:47:32.014] iteration 20313 : model1 loss : 0.210607 model2 loss : 0.236787
[23:47:32.340] iteration 20314 : model1 loss : 0.279516 model2 loss : 0.281284
[23:47:32.667] iteration 20315 : model1 loss : 0.148895 model2 loss : 0.143689
[23:47:32.993] iteration 20316 : model1 loss : 0.244483 model2 loss : 0.212641
[23:47:33.320] iteration 20317 : model1 loss : 0.261005 model2 loss : 0.257278
[23:47:33.646] iteration 20318 : model1 loss : 0.262393 model2 loss : 0.293157
[23:47:33.970] iteration 20319 : model1 loss : 0.335338 model2 loss : 0.347428
[23:47:34.297] iteration 20320 : model1 loss : 0.191939 model2 loss : 0.243784
[23:47:34.622] iteration 20321 : model1 loss : 0.201430 model2 loss : 0.215389
[23:47:34.948] iteration 20322 : model1 loss : 0.228785 model2 loss : 0.280206
[23:47:35.275] iteration 20323 : model1 loss : 0.185557 model2 loss : 0.226735
[23:47:35.600] iteration 20324 : model1 loss : 0.233465 model2 loss : 0.281236
[23:47:35.927] iteration 20325 : model1 loss : 0.177534 model2 loss : 0.182351
[23:47:36.253] iteration 20326 : model1 loss : 0.101269 model2 loss : 0.124299
[23:47:36.578] iteration 20327 : model1 loss : 0.104496 model2 loss : 0.116923
[23:47:36.903] iteration 20328 : model1 loss : 0.178453 model2 loss : 0.221176
[23:47:37.230] iteration 20329 : model1 loss : 0.172674 model2 loss : 0.189215
[23:47:37.555] iteration 20330 : model1 loss : 0.167669 model2 loss : 0.187849
[23:47:37.881] iteration 20331 : model1 loss : 0.259192 model2 loss : 0.284781
[23:47:38.207] iteration 20332 : model1 loss : 0.124538 model2 loss : 0.154417
[23:47:38.533] iteration 20333 : model1 loss : 0.108733 model2 loss : 0.113248
[23:47:38.859] iteration 20334 : model1 loss : 0.212915 model2 loss : 0.236753
[23:47:39.185] iteration 20335 : model1 loss : 0.174401 model2 loss : 0.210553
[23:47:39.512] iteration 20336 : model1 loss : 0.189179 model2 loss : 0.283087
[23:47:39.836] iteration 20337 : model1 loss : 0.209052 model2 loss : 0.209518
[23:47:40.163] iteration 20338 : model1 loss : 0.143215 model2 loss : 0.210452
[23:47:40.490] iteration 20339 : model1 loss : 0.155678 model2 loss : 0.172247
[23:47:40.815] iteration 20340 : model1 loss : 0.193149 model2 loss : 0.228568
[23:47:41.142] iteration 20341 : model1 loss : 0.129945 model2 loss : 0.198164
[23:47:41.467] iteration 20342 : model1 loss : 0.201342 model2 loss : 0.179108
[23:47:41.792] iteration 20343 : model1 loss : 0.104026 model2 loss : 0.107081
[23:47:42.119] iteration 20344 : model1 loss : 0.271643 model2 loss : 0.254115
[23:47:42.444] iteration 20345 : model1 loss : 0.339677 model2 loss : 0.360031
[23:47:42.769] iteration 20346 : model1 loss : 0.098232 model2 loss : 0.115030
[23:47:43.095] iteration 20347 : model1 loss : 0.163790 model2 loss : 0.207546
[23:47:43.421] iteration 20348 : model1 loss : 0.194413 model2 loss : 0.240125
[23:47:43.747] iteration 20349 : model1 loss : 0.177398 model2 loss : 0.200623
[23:47:44.073] iteration 20350 : model1 loss : 0.134211 model2 loss : 0.210328
[23:47:44.602] iteration 20351 : model1 loss : 0.257759 model2 loss : 0.271564
[23:47:44.928] iteration 20352 : model1 loss : 0.219564 model2 loss : 0.203313
[23:47:45.254] iteration 20353 : model1 loss : 0.152508 model2 loss : 0.146523
[23:47:45.581] iteration 20354 : model1 loss : 0.206168 model2 loss : 0.340496
[23:47:45.907] iteration 20355 : model1 loss : 0.273541 model2 loss : 0.310315
[23:47:46.232] iteration 20356 : model1 loss : 0.179102 model2 loss : 0.217974
[23:47:46.559] iteration 20357 : model1 loss : 0.195821 model2 loss : 0.203182
[23:47:46.885] iteration 20358 : model1 loss : 0.182429 model2 loss : 0.208872
[23:47:47.210] iteration 20359 : model1 loss : 0.167201 model2 loss : 0.192599
[23:47:47.536] iteration 20360 : model1 loss : 0.267993 model2 loss : 0.276313
[23:47:47.862] iteration 20361 : model1 loss : 0.170566 model2 loss : 0.185299
[23:47:48.188] iteration 20362 : model1 loss : 0.261352 model2 loss : 0.246151
[23:47:48.514] iteration 20363 : model1 loss : 0.176035 model2 loss : 0.199344
[23:47:48.839] iteration 20364 : model1 loss : 0.188101 model2 loss : 0.231719
[23:47:49.164] iteration 20365 : model1 loss : 0.231430 model2 loss : 0.208537
[23:47:49.490] iteration 20366 : model1 loss : 0.206859 model2 loss : 0.221995
[23:47:49.816] iteration 20367 : model1 loss : 0.202105 model2 loss : 0.347083
[23:47:50.143] iteration 20368 : model1 loss : 0.245626 model2 loss : 0.260735
[23:47:50.469] iteration 20369 : model1 loss : 0.291062 model2 loss : 0.289342
[23:47:50.795] iteration 20370 : model1 loss : 0.109088 model2 loss : 0.125250
[23:47:51.122] iteration 20371 : model1 loss : 0.085172 model2 loss : 0.088221
[23:47:51.448] iteration 20372 : model1 loss : 0.243107 model2 loss : 0.267809
[23:47:51.775] iteration 20373 : model1 loss : 0.227942 model2 loss : 0.220010
[23:47:52.101] iteration 20374 : model1 loss : 0.286661 model2 loss : 0.318526
[23:47:52.427] iteration 20375 : model1 loss : 0.143345 model2 loss : 0.154797
[23:47:52.753] iteration 20376 : model1 loss : 0.229428 model2 loss : 0.254941
[23:47:53.079] iteration 20377 : model1 loss : 0.250813 model2 loss : 0.295554
[23:47:53.406] iteration 20378 : model1 loss : 0.194501 model2 loss : 0.250985
[23:47:53.731] iteration 20379 : model1 loss : 0.172726 model2 loss : 0.214312
[23:47:54.060] iteration 20380 : model1 loss : 0.162684 model2 loss : 0.142066
[23:47:54.386] iteration 20381 : model1 loss : 0.170796 model2 loss : 0.195606
[23:47:54.712] iteration 20382 : model1 loss : 0.088051 model2 loss : 0.235263
[23:47:55.038] iteration 20383 : model1 loss : 0.183994 model2 loss : 0.212649
[23:47:55.364] iteration 20384 : model1 loss : 0.204032 model2 loss : 0.219993
[23:47:55.689] iteration 20385 : model1 loss : 0.105148 model2 loss : 0.167911
[23:47:56.014] iteration 20386 : model1 loss : 0.167689 model2 loss : 0.176512
[23:47:56.339] iteration 20387 : model1 loss : 0.262243 model2 loss : 0.353482
[23:47:56.666] iteration 20388 : model1 loss : 0.132583 model2 loss : 0.228547
[23:47:56.992] iteration 20389 : model1 loss : 0.176703 model2 loss : 0.232829
[23:47:57.318] iteration 20390 : model1 loss : 0.248287 model2 loss : 0.319261
[23:47:57.645] iteration 20391 : model1 loss : 0.107928 model2 loss : 0.177022
[23:47:57.969] iteration 20392 : model1 loss : 0.298166 model2 loss : 0.325143
[23:47:58.295] iteration 20393 : model1 loss : 0.206992 model2 loss : 0.267003
[23:47:58.620] iteration 20394 : model1 loss : 0.254998 model2 loss : 0.270693
[23:47:58.946] iteration 20395 : model1 loss : 0.178702 model2 loss : 0.234331
[23:47:59.272] iteration 20396 : model1 loss : 0.058938 model2 loss : 0.156805
[23:47:59.598] iteration 20397 : model1 loss : 0.132820 model2 loss : 0.166825
[23:47:59.924] iteration 20398 : model1 loss : 0.160688 model2 loss : 0.240970
[23:48:00.248] iteration 20399 : model1 loss : 0.186049 model2 loss : 0.192601
[23:48:00.574] iteration 20400 : model1 loss : 0.109956 model2 loss : 0.116443
[23:48:01.118] iteration 20401 : model1 loss : 0.249692 model2 loss : 0.298097
[23:48:01.444] iteration 20402 : model1 loss : 0.191879 model2 loss : 0.209477
[23:48:01.769] iteration 20403 : model1 loss : 0.136534 model2 loss : 0.201233
[23:48:02.096] iteration 20404 : model1 loss : 0.124490 model2 loss : 0.177084
[23:48:02.421] iteration 20405 : model1 loss : 0.195063 model2 loss : 0.295851
[23:48:02.746] iteration 20406 : model1 loss : 0.133879 model2 loss : 0.147892
[23:48:03.072] iteration 20407 : model1 loss : 0.081999 model2 loss : 0.098132
[23:48:03.398] iteration 20408 : model1 loss : 0.212824 model2 loss : 0.269461
[23:48:03.724] iteration 20409 : model1 loss : 0.260072 model2 loss : 0.264551
[23:48:04.049] iteration 20410 : model1 loss : 0.086484 model2 loss : 0.185692
[23:48:04.374] iteration 20411 : model1 loss : 0.165788 model2 loss : 0.197396
[23:48:04.700] iteration 20412 : model1 loss : 0.172626 model2 loss : 0.173592
[23:48:05.023] iteration 20413 : model1 loss : 0.187495 model2 loss : 0.192755
[23:48:05.346] iteration 20414 : model1 loss : 0.175519 model2 loss : 0.200124
[23:48:05.667] iteration 20415 : model1 loss : 0.096995 model2 loss : 0.133143
[23:48:05.988] iteration 20416 : model1 loss : 0.192215 model2 loss : 0.256968
[23:48:06.309] iteration 20417 : model1 loss : 0.120386 model2 loss : 0.148935
[23:48:06.631] iteration 20418 : model1 loss : 0.257051 model2 loss : 0.292221
[23:48:06.952] iteration 20419 : model1 loss : 0.181337 model2 loss : 0.208429
[23:48:07.273] iteration 20420 : model1 loss : 0.187377 model2 loss : 0.216156
[23:48:07.596] iteration 20421 : model1 loss : 0.200736 model2 loss : 0.223727
[23:48:07.916] iteration 20422 : model1 loss : 0.149963 model2 loss : 0.217187
[23:48:08.237] iteration 20423 : model1 loss : 0.194996 model2 loss : 0.295956
[23:48:08.559] iteration 20424 : model1 loss : 0.267180 model2 loss : 0.280669
[23:48:08.881] iteration 20425 : model1 loss : 0.142386 model2 loss : 0.234446
[23:48:09.202] iteration 20426 : model1 loss : 0.238030 model2 loss : 0.257602
[23:48:09.524] iteration 20427 : model1 loss : 0.267110 model2 loss : 0.309786
[23:48:09.845] iteration 20428 : model1 loss : 0.163476 model2 loss : 0.185908
[23:48:10.167] iteration 20429 : model1 loss : 0.218869 model2 loss : 0.256620
[23:48:10.488] iteration 20430 : model1 loss : 0.224421 model2 loss : 0.261927
[23:48:10.809] iteration 20431 : model1 loss : 0.182237 model2 loss : 0.252887
[23:48:11.130] iteration 20432 : model1 loss : 0.131724 model2 loss : 0.119770
[23:48:11.452] iteration 20433 : model1 loss : 0.103440 model2 loss : 0.178015
[23:48:11.773] iteration 20434 : model1 loss : 0.111280 model2 loss : 0.126144
[23:48:12.094] iteration 20435 : model1 loss : 0.186072 model2 loss : 0.210131
[23:48:12.420] iteration 20436 : model1 loss : 0.154650 model2 loss : 0.179599
[23:48:12.744] iteration 20437 : model1 loss : 0.166170 model2 loss : 0.186013
[23:48:13.065] iteration 20438 : model1 loss : 0.252592 model2 loss : 0.261043
[23:48:13.390] iteration 20439 : model1 loss : 0.274242 model2 loss : 0.352012
[23:48:13.712] iteration 20440 : model1 loss : 0.271516 model2 loss : 0.290313
[23:48:14.033] iteration 20441 : model1 loss : 0.254095 model2 loss : 0.287763
[23:48:14.363] iteration 20442 : model1 loss : 0.186692 model2 loss : 0.224852
[23:48:14.687] iteration 20443 : model1 loss : 0.184838 model2 loss : 0.273132
[23:48:15.009] iteration 20444 : model1 loss : 0.303492 model2 loss : 0.325747
[23:48:15.335] iteration 20445 : model1 loss : 0.341141 model2 loss : 0.349623
[23:48:15.662] iteration 20446 : model1 loss : 0.222386 model2 loss : 0.289961
[23:48:15.996] iteration 20447 : model1 loss : 0.074974 model2 loss : 0.118276
[23:48:16.335] iteration 20448 : model1 loss : 0.174364 model2 loss : 0.235108
[23:48:16.671] iteration 20449 : model1 loss : 0.088593 model2 loss : 0.134387
[23:48:17.007] iteration 20450 : model1 loss : 0.193241 model2 loss : 0.202105
[23:48:17.675] iteration 20451 : model1 loss : 0.119856 model2 loss : 0.154479
[23:48:18.012] iteration 20452 : model1 loss : 0.171334 model2 loss : 0.165328
[23:48:18.347] iteration 20453 : model1 loss : 0.288383 model2 loss : 0.310235
[23:48:18.679] iteration 20454 : model1 loss : 0.160587 model2 loss : 0.150146
[23:48:19.010] iteration 20455 : model1 loss : 0.142775 model2 loss : 0.210417
[23:48:19.349] iteration 20456 : model1 loss : 0.272547 model2 loss : 0.338390
[23:48:19.686] iteration 20457 : model1 loss : 0.223140 model2 loss : 0.221782
[23:48:20.023] iteration 20458 : model1 loss : 0.217071 model2 loss : 0.211312
[23:48:20.359] iteration 20459 : model1 loss : 0.181661 model2 loss : 0.280132
[23:48:20.697] iteration 20460 : model1 loss : 0.096234 model2 loss : 0.169040
[23:48:21.034] iteration 20461 : model1 loss : 0.150682 model2 loss : 0.184697
[23:48:21.370] iteration 20462 : model1 loss : 0.191105 model2 loss : 0.204279
[23:48:21.706] iteration 20463 : model1 loss : 0.165357 model2 loss : 0.182504
[23:48:22.045] iteration 20464 : model1 loss : 0.272020 model2 loss : 0.310838
[23:48:22.382] iteration 20465 : model1 loss : 0.159826 model2 loss : 0.200206
[23:48:22.718] iteration 20466 : model1 loss : 0.165394 model2 loss : 0.181661
[23:48:23.054] iteration 20467 : model1 loss : 0.159714 model2 loss : 0.184168
[23:48:23.390] iteration 20468 : model1 loss : 0.106204 model2 loss : 0.168006
[23:48:23.727] iteration 20469 : model1 loss : 0.096061 model2 loss : 0.181390
[23:48:24.063] iteration 20470 : model1 loss : 0.181054 model2 loss : 0.229106
[23:48:24.399] iteration 20471 : model1 loss : 0.183568 model2 loss : 0.198340
[23:48:24.737] iteration 20472 : model1 loss : 0.243459 model2 loss : 0.266228
[23:48:25.073] iteration 20473 : model1 loss : 0.240329 model2 loss : 0.286266
[23:48:25.410] iteration 20474 : model1 loss : 0.081550 model2 loss : 0.176848
[23:48:25.746] iteration 20475 : model1 loss : 0.091815 model2 loss : 0.101600
[23:48:26.083] iteration 20476 : model1 loss : 0.268419 model2 loss : 0.270674
[23:48:26.424] iteration 20477 : model1 loss : 0.085535 model2 loss : 0.127545
[23:48:26.761] iteration 20478 : model1 loss : 0.253482 model2 loss : 0.316895
[23:48:27.097] iteration 20479 : model1 loss : 0.171899 model2 loss : 0.191969
[23:48:27.434] iteration 20480 : model1 loss : 0.253808 model2 loss : 0.277138
[23:48:27.771] iteration 20481 : model1 loss : 0.177263 model2 loss : 0.175287
[23:48:28.107] iteration 20482 : model1 loss : 0.224320 model2 loss : 0.229057
[23:48:28.444] iteration 20483 : model1 loss : 0.166614 model2 loss : 0.194366
[23:48:28.780] iteration 20484 : model1 loss : 0.219559 model2 loss : 0.255843
[23:48:29.118] iteration 20485 : model1 loss : 0.176449 model2 loss : 0.222384
[23:48:29.454] iteration 20486 : model1 loss : 0.243051 model2 loss : 0.309117
[23:48:29.791] iteration 20487 : model1 loss : 0.102777 model2 loss : 0.162566
[23:48:30.128] iteration 20488 : model1 loss : 0.285644 model2 loss : 0.313002
[23:48:30.465] iteration 20489 : model1 loss : 0.168954 model2 loss : 0.255326
[23:48:30.801] iteration 20490 : model1 loss : 0.151750 model2 loss : 0.157128
[23:48:31.137] iteration 20491 : model1 loss : 0.189091 model2 loss : 0.135546
[23:48:31.473] iteration 20492 : model1 loss : 0.251040 model2 loss : 0.300242
[23:48:31.810] iteration 20493 : model1 loss : 0.199116 model2 loss : 0.203968
[23:48:32.149] iteration 20494 : model1 loss : 0.208792 model2 loss : 0.188987
[23:48:32.487] iteration 20495 : model1 loss : 0.120637 model2 loss : 0.142865
[23:48:32.830] iteration 20496 : model1 loss : 0.174422 model2 loss : 0.230853
[23:48:33.166] iteration 20497 : model1 loss : 0.209990 model2 loss : 0.264725
[23:48:33.503] iteration 20498 : model1 loss : 0.246769 model2 loss : 0.288624
[23:48:33.841] iteration 20499 : model1 loss : 0.132327 model2 loss : 0.143165
[23:48:34.177] iteration 20500 : model1 loss : 0.201976 model2 loss : 0.266886
[23:48:34.836] iteration 20501 : model1 loss : 0.107239 model2 loss : 0.180256
[23:48:35.173] iteration 20502 : model1 loss : 0.109272 model2 loss : 0.107839
[23:48:35.509] iteration 20503 : model1 loss : 0.180916 model2 loss : 0.175416
[23:48:35.846] iteration 20504 : model1 loss : 0.164863 model2 loss : 0.257600
[23:48:36.182] iteration 20505 : model1 loss : 0.225784 model2 loss : 0.236561
[23:48:36.518] iteration 20506 : model1 loss : 0.170295 model2 loss : 0.229504
[23:48:36.854] iteration 20507 : model1 loss : 0.083357 model2 loss : 0.116261
[23:48:37.191] iteration 20508 : model1 loss : 0.262297 model2 loss : 0.380235
[23:48:37.532] iteration 20509 : model1 loss : 0.081045 model2 loss : 0.113048
[23:48:37.877] iteration 20510 : model1 loss : 0.164532 model2 loss : 0.177362
[23:48:38.217] iteration 20511 : model1 loss : 0.266237 model2 loss : 0.306843
[23:48:38.555] iteration 20512 : model1 loss : 0.271980 model2 loss : 0.283923
[23:48:38.891] iteration 20513 : model1 loss : 0.250020 model2 loss : 0.282569
[23:48:39.227] iteration 20514 : model1 loss : 0.210945 model2 loss : 0.200610
[23:48:39.563] iteration 20515 : model1 loss : 0.246450 model2 loss : 0.257492
[23:48:39.899] iteration 20516 : model1 loss : 0.160099 model2 loss : 0.184896
[23:48:40.239] iteration 20517 : model1 loss : 0.090369 model2 loss : 0.148013
[23:48:40.579] iteration 20518 : model1 loss : 0.304411 model2 loss : 0.363532
[23:48:40.915] iteration 20519 : model1 loss : 0.209931 model2 loss : 0.282217
[23:48:41.256] iteration 20520 : model1 loss : 0.185957 model2 loss : 0.172024
[23:48:41.593] iteration 20521 : model1 loss : 0.114057 model2 loss : 0.171988
[23:48:41.930] iteration 20522 : model1 loss : 0.247860 model2 loss : 0.273918
[23:48:42.265] iteration 20523 : model1 loss : 0.176803 model2 loss : 0.229271
[23:48:42.602] iteration 20524 : model1 loss : 0.204629 model2 loss : 0.215134
[23:48:42.939] iteration 20525 : model1 loss : 0.172647 model2 loss : 0.169551
[23:48:43.277] iteration 20526 : model1 loss : 0.261919 model2 loss : 0.272377
[23:48:43.613] iteration 20527 : model1 loss : 0.317651 model2 loss : 0.324813
[23:48:43.950] iteration 20528 : model1 loss : 0.166013 model2 loss : 0.181070
[23:48:44.289] iteration 20529 : model1 loss : 0.257486 model2 loss : 0.359216
[23:48:44.626] iteration 20530 : model1 loss : 0.241401 model2 loss : 0.261626
[23:48:44.962] iteration 20531 : model1 loss : 0.267463 model2 loss : 0.315133
[23:48:45.302] iteration 20532 : model1 loss : 0.070708 model2 loss : 0.153613
[23:48:45.639] iteration 20533 : model1 loss : 0.159578 model2 loss : 0.223660
[23:48:45.976] iteration 20534 : model1 loss : 0.164839 model2 loss : 0.233007
[23:48:46.313] iteration 20535 : model1 loss : 0.311072 model2 loss : 0.403942
[23:48:46.649] iteration 20536 : model1 loss : 0.239272 model2 loss : 0.256953
[23:48:46.987] iteration 20537 : model1 loss : 0.159390 model2 loss : 0.194007
[23:48:47.324] iteration 20538 : model1 loss : 0.218617 model2 loss : 0.215168
[23:48:47.666] iteration 20539 : model1 loss : 0.272173 model2 loss : 0.277822
[23:48:48.006] iteration 20540 : model1 loss : 0.189334 model2 loss : 0.211999
[23:48:48.342] iteration 20541 : model1 loss : 0.084244 model2 loss : 0.101625
[23:48:48.680] iteration 20542 : model1 loss : 0.204441 model2 loss : 0.261113
[23:48:49.019] iteration 20543 : model1 loss : 0.179574 model2 loss : 0.210151
[23:48:49.360] iteration 20544 : model1 loss : 0.270446 model2 loss : 0.269605
[23:48:49.697] iteration 20545 : model1 loss : 0.176021 model2 loss : 0.204238
[23:48:50.034] iteration 20546 : model1 loss : 0.089108 model2 loss : 0.133804
[23:48:50.371] iteration 20547 : model1 loss : 0.103034 model2 loss : 0.171574
[23:48:50.708] iteration 20548 : model1 loss : 0.129347 model2 loss : 0.174201
[23:48:51.050] iteration 20549 : model1 loss : 0.243810 model2 loss : 0.304896
[23:48:51.391] iteration 20550 : model1 loss : 0.278895 model2 loss : 0.308310
[23:48:52.045] iteration 20551 : model1 loss : 0.069891 model2 loss : 0.119145
[23:48:52.381] iteration 20552 : model1 loss : 0.193272 model2 loss : 0.237870
[23:48:52.719] iteration 20553 : model1 loss : 0.283865 model2 loss : 0.339857
[23:48:53.062] iteration 20554 : model1 loss : 0.202990 model2 loss : 0.275676
[23:48:53.403] iteration 20555 : model1 loss : 0.100139 model2 loss : 0.113855
[23:48:53.741] iteration 20556 : model1 loss : 0.117322 model2 loss : 0.123456
[23:48:54.078] iteration 20557 : model1 loss : 0.265907 model2 loss : 0.252402
[23:48:54.415] iteration 20558 : model1 loss : 0.174425 model2 loss : 0.199625
[23:48:54.751] iteration 20559 : model1 loss : 0.313975 model2 loss : 0.268622
[23:48:55.091] iteration 20560 : model1 loss : 0.197033 model2 loss : 0.221528
[23:48:55.429] iteration 20561 : model1 loss : 0.194215 model2 loss : 0.260612
[23:48:55.770] iteration 20562 : model1 loss : 0.231197 model2 loss : 0.244883
[23:48:56.111] iteration 20563 : model1 loss : 0.264877 model2 loss : 0.290301
[23:48:56.452] iteration 20564 : model1 loss : 0.242575 model2 loss : 0.368451
[23:48:56.789] iteration 20565 : model1 loss : 0.227690 model2 loss : 0.269437
[23:48:57.128] iteration 20566 : model1 loss : 0.177772 model2 loss : 0.192231
[23:48:57.466] iteration 20567 : model1 loss : 0.172221 model2 loss : 0.203444
[23:48:57.806] iteration 20568 : model1 loss : 0.232307 model2 loss : 0.256319
[23:48:58.145] iteration 20569 : model1 loss : 0.069438 model2 loss : 0.077171
[23:48:58.481] iteration 20570 : model1 loss : 0.291251 model2 loss : 0.304274
[23:48:58.818] iteration 20571 : model1 loss : 0.237664 model2 loss : 0.269754
[23:48:59.156] iteration 20572 : model1 loss : 0.202894 model2 loss : 0.161332
[23:48:59.493] iteration 20573 : model1 loss : 0.313518 model2 loss : 0.330255
[23:48:59.833] iteration 20574 : model1 loss : 0.330179 model2 loss : 0.250565
[23:49:00.173] iteration 20575 : model1 loss : 0.199665 model2 loss : 0.228209
[23:49:00.513] iteration 20576 : model1 loss : 0.264156 model2 loss : 0.305957
[23:49:00.851] iteration 20577 : model1 loss : 0.159848 model2 loss : 0.208725
[23:49:01.192] iteration 20578 : model1 loss : 0.167283 model2 loss : 0.220184
[23:49:01.532] iteration 20579 : model1 loss : 0.225252 model2 loss : 0.224965
[23:49:01.870] iteration 20580 : model1 loss : 0.166656 model2 loss : 0.191837
[23:49:02.209] iteration 20581 : model1 loss : 0.161853 model2 loss : 0.149012
[23:49:02.547] iteration 20582 : model1 loss : 0.251956 model2 loss : 0.269121
[23:49:02.885] iteration 20583 : model1 loss : 0.075591 model2 loss : 0.191879
[23:49:03.222] iteration 20584 : model1 loss : 0.257381 model2 loss : 0.260571
[23:49:03.556] iteration 20585 : model1 loss : 0.184241 model2 loss : 0.179132
[23:49:03.892] iteration 20586 : model1 loss : 0.163958 model2 loss : 0.188694
[23:49:04.221] iteration 20587 : model1 loss : 0.268791 model2 loss : 0.272118
[23:49:04.549] iteration 20588 : model1 loss : 0.237996 model2 loss : 0.268658
[23:49:04.879] iteration 20589 : model1 loss : 0.169255 model2 loss : 0.183309
[23:49:05.208] iteration 20590 : model1 loss : 0.232413 model2 loss : 0.213408
[23:49:05.539] iteration 20591 : model1 loss : 0.296384 model2 loss : 0.260432
[23:49:05.867] iteration 20592 : model1 loss : 0.273134 model2 loss : 0.326042
[23:49:06.195] iteration 20593 : model1 loss : 0.251706 model2 loss : 0.218577
[23:49:06.524] iteration 20594 : model1 loss : 0.157222 model2 loss : 0.163538
[23:49:06.853] iteration 20595 : model1 loss : 0.206835 model2 loss : 0.219008
[23:49:07.181] iteration 20596 : model1 loss : 0.179015 model2 loss : 0.175634
[23:49:07.510] iteration 20597 : model1 loss : 0.250560 model2 loss : 0.301498
[23:49:07.838] iteration 20598 : model1 loss : 0.262779 model2 loss : 0.267245
[23:49:08.166] iteration 20599 : model1 loss : 0.117098 model2 loss : 0.164995
[23:49:08.495] iteration 20600 : model1 loss : 0.163823 model2 loss : 0.193854
[23:49:09.055] iteration 20601 : model1 loss : 0.189248 model2 loss : 0.204328
[23:49:09.385] iteration 20602 : model1 loss : 0.317879 model2 loss : 0.320240
[23:49:09.717] iteration 20603 : model1 loss : 0.170245 model2 loss : 0.181740
[23:49:10.044] iteration 20604 : model1 loss : 0.262324 model2 loss : 0.168543
[23:49:10.380] iteration 20605 : model1 loss : 0.089843 model2 loss : 0.096094
[23:49:10.711] iteration 20606 : model1 loss : 0.279312 model2 loss : 0.275634
[23:49:11.039] iteration 20607 : model1 loss : 0.108758 model2 loss : 0.179325
[23:49:11.367] iteration 20608 : model1 loss : 0.168815 model2 loss : 0.207369
[23:49:11.698] iteration 20609 : model1 loss : 0.267608 model2 loss : 0.275959
[23:49:12.026] iteration 20610 : model1 loss : 0.204043 model2 loss : 0.243094
[23:49:12.354] iteration 20611 : model1 loss : 0.154375 model2 loss : 0.153521
[23:49:12.685] iteration 20612 : model1 loss : 0.254167 model2 loss : 0.274208
[23:49:13.013] iteration 20613 : model1 loss : 0.178686 model2 loss : 0.209437
[23:49:13.343] iteration 20614 : model1 loss : 0.190288 model2 loss : 0.231331
[23:49:13.673] iteration 20615 : model1 loss : 0.170679 model2 loss : 0.179372
[23:49:14.002] iteration 20616 : model1 loss : 0.247342 model2 loss : 0.257524
[23:49:14.330] iteration 20617 : model1 loss : 0.163187 model2 loss : 0.167847
[23:49:14.659] iteration 20618 : model1 loss : 0.187751 model2 loss : 0.220184
[23:49:14.988] iteration 20619 : model1 loss : 0.157880 model2 loss : 0.167808
[23:49:15.319] iteration 20620 : model1 loss : 0.188091 model2 loss : 0.237716
[23:49:15.647] iteration 20621 : model1 loss : 0.228806 model2 loss : 0.287366
[23:49:15.978] iteration 20622 : model1 loss : 0.123666 model2 loss : 0.201864
[23:49:16.306] iteration 20623 : model1 loss : 0.232360 model2 loss : 0.255282
[23:49:16.637] iteration 20624 : model1 loss : 0.337672 model2 loss : 0.294778
[23:49:16.965] iteration 20625 : model1 loss : 0.110945 model2 loss : 0.185430
[23:49:17.292] iteration 20626 : model1 loss : 0.110171 model2 loss : 0.133771
[23:49:17.619] iteration 20627 : model1 loss : 0.137767 model2 loss : 0.164747
[23:49:17.948] iteration 20628 : model1 loss : 0.177498 model2 loss : 0.261179
[23:49:18.276] iteration 20629 : model1 loss : 0.178459 model2 loss : 0.208055
[23:49:18.614] iteration 20630 : model1 loss : 0.171546 model2 loss : 0.177859
[23:49:18.942] iteration 20631 : model1 loss : 0.243033 model2 loss : 0.251319
[23:49:19.270] iteration 20632 : model1 loss : 0.200212 model2 loss : 0.217086
[23:49:19.600] iteration 20633 : model1 loss : 0.227179 model2 loss : 0.275284
[23:49:19.929] iteration 20634 : model1 loss : 0.264654 model2 loss : 0.345756
[23:49:20.256] iteration 20635 : model1 loss : 0.283803 model2 loss : 0.305122
[23:49:20.584] iteration 20636 : model1 loss : 0.163757 model2 loss : 0.206428
[23:49:20.913] iteration 20637 : model1 loss : 0.214691 model2 loss : 0.233887
[23:49:21.242] iteration 20638 : model1 loss : 0.169921 model2 loss : 0.192358
[23:49:21.571] iteration 20639 : model1 loss : 0.120392 model2 loss : 0.268959
[23:49:21.901] iteration 20640 : model1 loss : 0.083934 model2 loss : 0.112793
[23:49:22.230] iteration 20641 : model1 loss : 0.102707 model2 loss : 0.163859
[23:49:22.558] iteration 20642 : model1 loss : 0.258807 model2 loss : 0.274546
[23:49:22.886] iteration 20643 : model1 loss : 0.203219 model2 loss : 0.198279
[23:49:23.215] iteration 20644 : model1 loss : 0.086548 model2 loss : 0.117867
[23:49:23.553] iteration 20645 : model1 loss : 0.185763 model2 loss : 0.220022
[23:49:23.884] iteration 20646 : model1 loss : 0.261644 model2 loss : 0.257717
[23:49:24.227] iteration 20647 : model1 loss : 0.251014 model2 loss : 0.312604
[23:49:24.566] iteration 20648 : model1 loss : 0.196095 model2 loss : 0.266646
[23:49:24.907] iteration 20649 : model1 loss : 0.292550 model2 loss : 0.379304
[23:49:25.245] iteration 20650 : model1 loss : 0.206899 model2 loss : 0.256474
[23:49:25.900] iteration 20651 : model1 loss : 0.186507 model2 loss : 0.261860
[23:49:26.239] iteration 20652 : model1 loss : 0.177566 model2 loss : 0.238273
[23:49:26.577] iteration 20653 : model1 loss : 0.200111 model2 loss : 0.199041
[23:49:26.916] iteration 20654 : model1 loss : 0.140627 model2 loss : 0.186692
[23:49:27.256] iteration 20655 : model1 loss : 0.234362 model2 loss : 0.261414
[23:49:27.593] iteration 20656 : model1 loss : 0.185839 model2 loss : 0.220939
[23:49:27.931] iteration 20657 : model1 loss : 0.218409 model2 loss : 0.268166
[23:49:28.270] iteration 20658 : model1 loss : 0.265306 model2 loss : 0.244775
[23:49:28.608] iteration 20659 : model1 loss : 0.259470 model2 loss : 0.280764
[23:49:28.954] iteration 20660 : model1 loss : 0.194282 model2 loss : 0.261022
[23:49:29.296] iteration 20661 : model1 loss : 0.239179 model2 loss : 0.255711
[23:49:29.634] iteration 20662 : model1 loss : 0.178202 model2 loss : 0.227342
[23:49:29.972] iteration 20663 : model1 loss : 0.175935 model2 loss : 0.211792
[23:49:30.314] iteration 20664 : model1 loss : 0.185075 model2 loss : 0.200564
[23:49:30.652] iteration 20665 : model1 loss : 0.197839 model2 loss : 0.260501
[23:49:30.993] iteration 20666 : model1 loss : 0.178607 model2 loss : 0.259302
[23:49:31.330] iteration 20667 : model1 loss : 0.125150 model2 loss : 0.148267
[23:49:31.668] iteration 20668 : model1 loss : 0.153393 model2 loss : 0.160949
[23:49:32.007] iteration 20669 : model1 loss : 0.176923 model2 loss : 0.194490
[23:49:32.348] iteration 20670 : model1 loss : 0.230343 model2 loss : 0.258132
[23:49:32.690] iteration 20671 : model1 loss : 0.094168 model2 loss : 0.107873
[23:49:33.028] iteration 20672 : model1 loss : 0.193182 model2 loss : 0.197821
[23:49:33.369] iteration 20673 : model1 loss : 0.156838 model2 loss : 0.165826
[23:49:33.707] iteration 20674 : model1 loss : 0.248638 model2 loss : 0.252887
[23:49:34.044] iteration 20675 : model1 loss : 0.313970 model2 loss : 0.405187
[23:49:34.382] iteration 20676 : model1 loss : 0.202267 model2 loss : 0.251883
[23:49:34.719] iteration 20677 : model1 loss : 0.265068 model2 loss : 0.279760
[23:49:35.058] iteration 20678 : model1 loss : 0.264779 model2 loss : 0.298434
[23:49:35.400] iteration 20679 : model1 loss : 0.216061 model2 loss : 0.280098
[23:49:35.743] iteration 20680 : model1 loss : 0.188339 model2 loss : 0.196930
[23:49:36.085] iteration 20681 : model1 loss : 0.098566 model2 loss : 0.145593
[23:49:36.424] iteration 20682 : model1 loss : 0.253860 model2 loss : 0.272720
[23:49:36.766] iteration 20683 : model1 loss : 0.262314 model2 loss : 0.255203
[23:49:37.103] iteration 20684 : model1 loss : 0.232519 model2 loss : 0.235989
[23:49:37.439] iteration 20685 : model1 loss : 0.269246 model2 loss : 0.276795
[23:49:37.776] iteration 20686 : model1 loss : 0.210594 model2 loss : 0.221390
[23:49:38.115] iteration 20687 : model1 loss : 0.192033 model2 loss : 0.246820
[23:49:38.457] iteration 20688 : model1 loss : 0.167247 model2 loss : 0.187628
[23:49:38.794] iteration 20689 : model1 loss : 0.194518 model2 loss : 0.230341
[23:49:39.131] iteration 20690 : model1 loss : 0.175935 model2 loss : 0.191685
[23:49:39.471] iteration 20691 : model1 loss : 0.182515 model2 loss : 0.305977
[23:49:39.810] iteration 20692 : model1 loss : 0.146019 model2 loss : 0.211224
[23:49:40.149] iteration 20693 : model1 loss : 0.116062 model2 loss : 0.162591
[23:49:40.486] iteration 20694 : model1 loss : 0.250446 model2 loss : 0.260373
[23:49:40.824] iteration 20695 : model1 loss : 0.154360 model2 loss : 0.218045
[23:49:41.163] iteration 20696 : model1 loss : 0.275942 model2 loss : 0.336003
[23:49:41.501] iteration 20697 : model1 loss : 0.111764 model2 loss : 0.099921
[23:49:41.840] iteration 20698 : model1 loss : 0.187730 model2 loss : 0.214633
[23:49:42.178] iteration 20699 : model1 loss : 0.266805 model2 loss : 0.338767
[23:49:42.516] iteration 20700 : model1 loss : 0.195992 model2 loss : 0.223849
[23:49:43.147] iteration 20701 : model1 loss : 0.212831 model2 loss : 0.195053
[23:49:43.487] iteration 20702 : model1 loss : 0.280942 model2 loss : 0.264756
[23:49:43.828] iteration 20703 : model1 loss : 0.230279 model2 loss : 0.211666
[23:49:44.165] iteration 20704 : model1 loss : 0.230893 model2 loss : 0.160850
[23:49:44.505] iteration 20705 : model1 loss : 0.110961 model2 loss : 0.108754
[23:49:44.846] iteration 20706 : model1 loss : 0.081250 model2 loss : 0.079277
[23:49:45.183] iteration 20707 : model1 loss : 0.157522 model2 loss : 0.255010
[23:49:45.525] iteration 20708 : model1 loss : 0.260616 model2 loss : 0.264243
[23:49:45.865] iteration 20709 : model1 loss : 0.082847 model2 loss : 0.155149
[23:49:46.202] iteration 20710 : model1 loss : 0.230552 model2 loss : 0.322362
[23:49:47.224] iteration 20711 : model1 loss : 0.168495 model2 loss : 0.185341
[23:49:47.552] iteration 20712 : model1 loss : 0.136326 model2 loss : 0.231748
[23:49:47.881] iteration 20713 : model1 loss : 0.269311 model2 loss : 0.275915
[23:49:48.210] iteration 20714 : model1 loss : 0.115621 model2 loss : 0.133719
[23:49:48.540] iteration 20715 : model1 loss : 0.184640 model2 loss : 0.302941
[23:49:48.868] iteration 20716 : model1 loss : 0.227731 model2 loss : 0.243427
[23:49:49.198] iteration 20717 : model1 loss : 0.219958 model2 loss : 0.220595
[23:49:49.529] iteration 20718 : model1 loss : 0.304705 model2 loss : 0.298558
[23:49:49.858] iteration 20719 : model1 loss : 0.142897 model2 loss : 0.243597
[23:49:50.187] iteration 20720 : model1 loss : 0.284000 model2 loss : 0.253396
[23:49:50.518] iteration 20721 : model1 loss : 0.176462 model2 loss : 0.213426
[23:49:50.848] iteration 20722 : model1 loss : 0.091567 model2 loss : 0.127502
[23:49:51.177] iteration 20723 : model1 loss : 0.193058 model2 loss : 0.213158
[23:49:51.505] iteration 20724 : model1 loss : 0.097590 model2 loss : 0.117974
[23:49:51.835] iteration 20725 : model1 loss : 0.119505 model2 loss : 0.183115
[23:49:52.163] iteration 20726 : model1 loss : 0.094179 model2 loss : 0.102149
[23:49:52.491] iteration 20727 : model1 loss : 0.186706 model2 loss : 0.244567
[23:49:52.819] iteration 20728 : model1 loss : 0.150345 model2 loss : 0.176406
[23:49:53.148] iteration 20729 : model1 loss : 0.157916 model2 loss : 0.222947
[23:49:53.480] iteration 20730 : model1 loss : 0.184471 model2 loss : 0.204101
[23:49:53.808] iteration 20731 : model1 loss : 0.156241 model2 loss : 0.159164
[23:49:54.136] iteration 20732 : model1 loss : 0.258513 model2 loss : 0.271853
[23:49:54.468] iteration 20733 : model1 loss : 0.194413 model2 loss : 0.208953
[23:49:54.796] iteration 20734 : model1 loss : 0.263006 model2 loss : 0.340874
[23:49:55.125] iteration 20735 : model1 loss : 0.204865 model2 loss : 0.226754
[23:49:55.454] iteration 20736 : model1 loss : 0.194619 model2 loss : 0.246406
[23:49:55.782] iteration 20737 : model1 loss : 0.234896 model2 loss : 0.282328
[23:49:56.111] iteration 20738 : model1 loss : 0.173281 model2 loss : 0.194869
[23:49:56.438] iteration 20739 : model1 loss : 0.255577 model2 loss : 0.311011
[23:49:56.766] iteration 20740 : model1 loss : 0.261001 model2 loss : 0.306696
[23:49:57.094] iteration 20741 : model1 loss : 0.171861 model2 loss : 0.197685
[23:49:57.424] iteration 20742 : model1 loss : 0.149030 model2 loss : 0.218328
[23:49:57.755] iteration 20743 : model1 loss : 0.182117 model2 loss : 0.230761
[23:49:58.083] iteration 20744 : model1 loss : 0.189045 model2 loss : 0.246805
[23:49:58.410] iteration 20745 : model1 loss : 0.256663 model2 loss : 0.302592
[23:49:58.738] iteration 20746 : model1 loss : 0.235989 model2 loss : 0.242151
[23:49:59.067] iteration 20747 : model1 loss : 0.175568 model2 loss : 0.229166
[23:49:59.397] iteration 20748 : model1 loss : 0.161275 model2 loss : 0.226296
[23:49:59.726] iteration 20749 : model1 loss : 0.253986 model2 loss : 0.260769
[23:50:00.054] iteration 20750 : model1 loss : 0.297417 model2 loss : 0.311552
[23:50:00.597] iteration 20751 : model1 loss : 0.185449 model2 loss : 0.230772
[23:50:00.925] iteration 20752 : model1 loss : 0.140009 model2 loss : 0.217721
[23:50:01.254] iteration 20753 : model1 loss : 0.184271 model2 loss : 0.265899
[23:50:01.582] iteration 20754 : model1 loss : 0.157793 model2 loss : 0.247956
[23:50:01.911] iteration 20755 : model1 loss : 0.251515 model2 loss : 0.270936
[23:50:02.240] iteration 20756 : model1 loss : 0.138602 model2 loss : 0.144530
[23:50:02.568] iteration 20757 : model1 loss : 0.229888 model2 loss : 0.239565
[23:50:02.897] iteration 20758 : model1 loss : 0.134712 model2 loss : 0.124752
[23:50:03.227] iteration 20759 : model1 loss : 0.269705 model2 loss : 0.351877
[23:50:03.556] iteration 20760 : model1 loss : 0.091612 model2 loss : 0.143800
[23:50:03.883] iteration 20761 : model1 loss : 0.263788 model2 loss : 0.374916
[23:50:04.211] iteration 20762 : model1 loss : 0.268720 model2 loss : 0.311689
[23:50:04.541] iteration 20763 : model1 loss : 0.171640 model2 loss : 0.191235
[23:50:04.870] iteration 20764 : model1 loss : 0.164136 model2 loss : 0.189534
[23:50:05.203] iteration 20765 : model1 loss : 0.253554 model2 loss : 0.325822
[23:50:05.528] iteration 20766 : model1 loss : 0.079867 model2 loss : 0.190058
[23:50:05.858] iteration 20767 : model1 loss : 0.248930 model2 loss : 0.266893
[23:50:06.186] iteration 20768 : model1 loss : 0.171722 model2 loss : 0.229611
[23:50:06.514] iteration 20769 : model1 loss : 0.109905 model2 loss : 0.179674
[23:50:06.842] iteration 20770 : model1 loss : 0.225361 model2 loss : 0.248332
[23:50:07.170] iteration 20771 : model1 loss : 0.297417 model2 loss : 0.301580
[23:50:07.499] iteration 20772 : model1 loss : 0.187173 model2 loss : 0.221106
[23:50:07.827] iteration 20773 : model1 loss : 0.192196 model2 loss : 0.221494
[23:50:08.156] iteration 20774 : model1 loss : 0.243756 model2 loss : 0.271755
[23:50:08.487] iteration 20775 : model1 loss : 0.283113 model2 loss : 0.246401
[23:50:08.825] iteration 20776 : model1 loss : 0.184670 model2 loss : 0.296322
[23:50:09.164] iteration 20777 : model1 loss : 0.141739 model2 loss : 0.210223
[23:50:09.510] iteration 20778 : model1 loss : 0.089985 model2 loss : 0.160254
[23:50:09.848] iteration 20779 : model1 loss : 0.234171 model2 loss : 0.220314
[23:50:10.188] iteration 20780 : model1 loss : 0.161410 model2 loss : 0.195003
[23:50:10.527] iteration 20781 : model1 loss : 0.250753 model2 loss : 0.175791
[23:50:10.868] iteration 20782 : model1 loss : 0.237019 model2 loss : 0.296374
[23:50:11.206] iteration 20783 : model1 loss : 0.090736 model2 loss : 0.111299
[23:50:11.543] iteration 20784 : model1 loss : 0.274257 model2 loss : 0.294463
[23:50:11.882] iteration 20785 : model1 loss : 0.183540 model2 loss : 0.245162
[23:50:12.223] iteration 20786 : model1 loss : 0.257981 model2 loss : 0.285943
[23:50:12.569] iteration 20787 : model1 loss : 0.101918 model2 loss : 0.155133
[23:50:12.911] iteration 20788 : model1 loss : 0.102879 model2 loss : 0.123585
[23:50:13.249] iteration 20789 : model1 loss : 0.256419 model2 loss : 0.284162
[23:50:13.590] iteration 20790 : model1 loss : 0.256185 model2 loss : 0.264083
[23:50:13.927] iteration 20791 : model1 loss : 0.139913 model2 loss : 0.143109
[23:50:14.265] iteration 20792 : model1 loss : 0.327548 model2 loss : 0.363124
[23:50:14.603] iteration 20793 : model1 loss : 0.192477 model2 loss : 0.224046
[23:50:14.944] iteration 20794 : model1 loss : 0.231846 model2 loss : 0.262465
[23:50:15.281] iteration 20795 : model1 loss : 0.270009 model2 loss : 0.289965
[23:50:15.619] iteration 20796 : model1 loss : 0.162626 model2 loss : 0.182375
[23:50:15.956] iteration 20797 : model1 loss : 0.219351 model2 loss : 0.300934
[23:50:16.295] iteration 20798 : model1 loss : 0.276446 model2 loss : 0.349101
[23:50:16.632] iteration 20799 : model1 loss : 0.188885 model2 loss : 0.241633
[23:50:16.970] iteration 20800 : model1 loss : 0.119394 model2 loss : 0.138268
[23:50:17.611] iteration 20801 : model1 loss : 0.257391 model2 loss : 0.261266
[23:50:17.950] iteration 20802 : model1 loss : 0.110437 model2 loss : 0.173754
[23:50:18.290] iteration 20803 : model1 loss : 0.076938 model2 loss : 0.129671
[23:50:18.631] iteration 20804 : model1 loss : 0.303890 model2 loss : 0.350780
[23:50:18.969] iteration 20805 : model1 loss : 0.251465 model2 loss : 0.280178
[23:50:19.306] iteration 20806 : model1 loss : 0.284627 model2 loss : 0.340108
[23:50:19.643] iteration 20807 : model1 loss : 0.098605 model2 loss : 0.148571
[23:50:19.980] iteration 20808 : model1 loss : 0.198669 model2 loss : 0.242614
[23:50:20.318] iteration 20809 : model1 loss : 0.126466 model2 loss : 0.156042
[23:50:20.655] iteration 20810 : model1 loss : 0.178425 model2 loss : 0.180520
[23:50:20.993] iteration 20811 : model1 loss : 0.343074 model2 loss : 0.360837
[23:50:21.331] iteration 20812 : model1 loss : 0.120692 model2 loss : 0.155139
[23:50:21.667] iteration 20813 : model1 loss : 0.166812 model2 loss : 0.225851
[23:50:22.005] iteration 20814 : model1 loss : 0.246731 model2 loss : 0.266462
[23:50:22.342] iteration 20815 : model1 loss : 0.178023 model2 loss : 0.202962
[23:50:22.679] iteration 20816 : model1 loss : 0.244126 model2 loss : 0.281882
[23:50:23.019] iteration 20817 : model1 loss : 0.183900 model2 loss : 0.186336
[23:50:23.358] iteration 20818 : model1 loss : 0.265131 model2 loss : 0.318733
[23:50:23.697] iteration 20819 : model1 loss : 0.322573 model2 loss : 0.422484
[23:50:24.034] iteration 20820 : model1 loss : 0.251137 model2 loss : 0.259254
[23:50:24.370] iteration 20821 : model1 loss : 0.240182 model2 loss : 0.262899
[23:50:24.706] iteration 20822 : model1 loss : 0.186934 model2 loss : 0.199101
[23:50:25.043] iteration 20823 : model1 loss : 0.075458 model2 loss : 0.089056
[23:50:25.382] iteration 20824 : model1 loss : 0.097905 model2 loss : 0.122280
[23:50:25.720] iteration 20825 : model1 loss : 0.191334 model2 loss : 0.273740
[23:50:26.061] iteration 20826 : model1 loss : 0.198705 model2 loss : 0.232241
[23:50:26.402] iteration 20827 : model1 loss : 0.256972 model2 loss : 0.286209
[23:50:26.738] iteration 20828 : model1 loss : 0.262199 model2 loss : 0.285190
[23:50:27.075] iteration 20829 : model1 loss : 0.171366 model2 loss : 0.252109
[23:50:27.412] iteration 20830 : model1 loss : 0.111172 model2 loss : 0.142049
[23:50:27.752] iteration 20831 : model1 loss : 0.091307 model2 loss : 0.110336
[23:50:28.088] iteration 20832 : model1 loss : 0.122938 model2 loss : 0.283980
[23:50:28.425] iteration 20833 : model1 loss : 0.111491 model2 loss : 0.155605
[23:50:28.763] iteration 20834 : model1 loss : 0.283281 model2 loss : 0.324553
[23:50:29.103] iteration 20835 : model1 loss : 0.211394 model2 loss : 0.226087
[23:50:29.440] iteration 20836 : model1 loss : 0.178903 model2 loss : 0.233653
[23:50:29.778] iteration 20837 : model1 loss : 0.185716 model2 loss : 0.228598
[23:50:30.118] iteration 20838 : model1 loss : 0.192783 model2 loss : 0.240498
[23:50:30.456] iteration 20839 : model1 loss : 0.116604 model2 loss : 0.091233
[23:50:30.795] iteration 20840 : model1 loss : 0.195611 model2 loss : 0.239844
[23:50:31.132] iteration 20841 : model1 loss : 0.176399 model2 loss : 0.244427
[23:50:31.469] iteration 20842 : model1 loss : 0.093436 model2 loss : 0.167551
[23:50:31.798] iteration 20843 : model1 loss : 0.262606 model2 loss : 0.258739
[23:50:32.127] iteration 20844 : model1 loss : 0.158261 model2 loss : 0.179856
[23:50:32.457] iteration 20845 : model1 loss : 0.269513 model2 loss : 0.310971
[23:50:32.786] iteration 20846 : model1 loss : 0.119824 model2 loss : 0.140029
[23:50:33.114] iteration 20847 : model1 loss : 0.216469 model2 loss : 0.250517
[23:50:33.443] iteration 20848 : model1 loss : 0.192315 model2 loss : 0.237799
[23:50:33.771] iteration 20849 : model1 loss : 0.187725 model2 loss : 0.292545
[23:50:34.101] iteration 20850 : model1 loss : 0.112392 model2 loss : 0.123919
[23:50:34.745] iteration 20851 : model1 loss : 0.166798 model2 loss : 0.227073
[23:50:35.074] iteration 20852 : model1 loss : 0.172636 model2 loss : 0.221836
[23:50:35.405] iteration 20853 : model1 loss : 0.186200 model2 loss : 0.239485
[23:50:35.734] iteration 20854 : model1 loss : 0.204090 model2 loss : 0.241181
[23:50:36.062] iteration 20855 : model1 loss : 0.093037 model2 loss : 0.140950
[23:50:36.392] iteration 20856 : model1 loss : 0.173897 model2 loss : 0.201900
[23:50:36.723] iteration 20857 : model1 loss : 0.197746 model2 loss : 0.165405
[23:50:37.051] iteration 20858 : model1 loss : 0.098215 model2 loss : 0.129661
[23:50:37.379] iteration 20859 : model1 loss : 0.198460 model2 loss : 0.224969
[23:50:37.708] iteration 20860 : model1 loss : 0.186328 model2 loss : 0.222998
[23:50:38.035] iteration 20861 : model1 loss : 0.260223 model2 loss : 0.345756
[23:50:38.363] iteration 20862 : model1 loss : 0.133648 model2 loss : 0.156428
[23:50:38.691] iteration 20863 : model1 loss : 0.280280 model2 loss : 0.313237
[23:50:39.020] iteration 20864 : model1 loss : 0.248499 model2 loss : 0.249313
[23:50:39.350] iteration 20865 : model1 loss : 0.146859 model2 loss : 0.207590
[23:50:39.678] iteration 20866 : model1 loss : 0.093621 model2 loss : 0.154823
[23:50:40.006] iteration 20867 : model1 loss : 0.168919 model2 loss : 0.247886
[23:50:40.334] iteration 20868 : model1 loss : 0.403922 model2 loss : 0.414944
[23:50:40.663] iteration 20869 : model1 loss : 0.171842 model2 loss : 0.201227
[23:50:40.994] iteration 20870 : model1 loss : 0.228930 model2 loss : 0.220837
[23:50:41.324] iteration 20871 : model1 loss : 0.276063 model2 loss : 0.281790
[23:50:41.652] iteration 20872 : model1 loss : 0.178235 model2 loss : 0.203683
[23:50:41.986] iteration 20873 : model1 loss : 0.147966 model2 loss : 0.190285
[23:50:42.316] iteration 20874 : model1 loss : 0.189216 model2 loss : 0.185613
[23:50:42.643] iteration 20875 : model1 loss : 0.212887 model2 loss : 0.218305
[23:50:42.971] iteration 20876 : model1 loss : 0.246457 model2 loss : 0.226375
[23:50:43.298] iteration 20877 : model1 loss : 0.223723 model2 loss : 0.270054
[23:50:43.626] iteration 20878 : model1 loss : 0.231425 model2 loss : 0.239343
[23:50:43.957] iteration 20879 : model1 loss : 0.171528 model2 loss : 0.230795
[23:50:44.287] iteration 20880 : model1 loss : 0.277014 model2 loss : 0.382281
[23:50:44.611] iteration 20881 : model1 loss : 0.134570 model2 loss : 0.126101
[23:50:44.934] iteration 20882 : model1 loss : 0.255353 model2 loss : 0.268304
[23:50:45.258] iteration 20883 : model1 loss : 0.218497 model2 loss : 0.249347
[23:50:45.588] iteration 20884 : model1 loss : 0.205912 model2 loss : 0.210266
[23:50:45.912] iteration 20885 : model1 loss : 0.080596 model2 loss : 0.121202
[23:50:46.243] iteration 20886 : model1 loss : 0.240014 model2 loss : 0.259410
[23:50:46.568] iteration 20887 : model1 loss : 0.254789 model2 loss : 0.261553
[23:50:46.891] iteration 20888 : model1 loss : 0.326148 model2 loss : 0.362055
[23:50:47.215] iteration 20889 : model1 loss : 0.276298 model2 loss : 0.313003
[23:50:47.539] iteration 20890 : model1 loss : 0.182526 model2 loss : 0.236263
[23:50:47.864] iteration 20891 : model1 loss : 0.091347 model2 loss : 0.124538
[23:50:48.187] iteration 20892 : model1 loss : 0.147331 model2 loss : 0.104509
[23:50:48.510] iteration 20893 : model1 loss : 0.114964 model2 loss : 0.144256
[23:50:48.835] iteration 20894 : model1 loss : 0.277227 model2 loss : 0.320015
[23:50:49.160] iteration 20895 : model1 loss : 0.099359 model2 loss : 0.132479
[23:50:49.486] iteration 20896 : model1 loss : 0.165245 model2 loss : 0.200473
[23:50:49.814] iteration 20897 : model1 loss : 0.176286 model2 loss : 0.194912
[23:50:50.139] iteration 20898 : model1 loss : 0.167018 model2 loss : 0.195364
[23:50:50.462] iteration 20899 : model1 loss : 0.317995 model2 loss : 0.326799
[23:50:50.786] iteration 20900 : model1 loss : 0.215671 model2 loss : 0.295241
[23:50:51.347] iteration 20901 : model1 loss : 0.178801 model2 loss : 0.190531
[23:50:51.671] iteration 20902 : model1 loss : 0.192639 model2 loss : 0.266200
[23:50:51.994] iteration 20903 : model1 loss : 0.223629 model2 loss : 0.284577
[23:50:52.319] iteration 20904 : model1 loss : 0.176324 model2 loss : 0.205202
[23:50:52.643] iteration 20905 : model1 loss : 0.102600 model2 loss : 0.114434
[23:50:52.966] iteration 20906 : model1 loss : 0.179528 model2 loss : 0.247412
[23:50:53.291] iteration 20907 : model1 loss : 0.143189 model2 loss : 0.161166
[23:50:53.615] iteration 20908 : model1 loss : 0.083878 model2 loss : 0.101833
[23:50:53.939] iteration 20909 : model1 loss : 0.139821 model2 loss : 0.165460
[23:50:54.262] iteration 20910 : model1 loss : 0.303152 model2 loss : 0.420487
[23:50:54.590] iteration 20911 : model1 loss : 0.213541 model2 loss : 0.256522
[23:50:54.918] iteration 20912 : model1 loss : 0.195745 model2 loss : 0.209567
[23:50:55.241] iteration 20913 : model1 loss : 0.263075 model2 loss : 0.279939
[23:50:55.568] iteration 20914 : model1 loss : 0.177482 model2 loss : 0.221131
[23:50:55.894] iteration 20915 : model1 loss : 0.226110 model2 loss : 0.234645
[23:50:56.218] iteration 20916 : model1 loss : 0.239952 model2 loss : 0.261824
[23:50:56.544] iteration 20917 : model1 loss : 0.315859 model2 loss : 0.355888
[23:50:56.874] iteration 20918 : model1 loss : 0.156273 model2 loss : 0.181946
[23:50:57.197] iteration 20919 : model1 loss : 0.099930 model2 loss : 0.171766
[23:50:57.523] iteration 20920 : model1 loss : 0.145443 model2 loss : 0.171495
[23:50:57.847] iteration 20921 : model1 loss : 0.192858 model2 loss : 0.266131
[23:50:58.389] iteration 20922 : model1 loss : 0.067609 model2 loss : 0.121060
[23:50:58.718] iteration 20923 : model1 loss : 0.251320 model2 loss : 0.263845
[23:50:59.042] iteration 20924 : model1 loss : 0.146529 model2 loss : 0.172867
[23:50:59.366] iteration 20925 : model1 loss : 0.181902 model2 loss : 0.215124
[23:50:59.694] iteration 20926 : model1 loss : 0.219338 model2 loss : 0.259642
[23:51:00.022] iteration 20927 : model1 loss : 0.251417 model2 loss : 0.301150
[23:51:00.349] iteration 20928 : model1 loss : 0.149143 model2 loss : 0.167120
[23:51:00.677] iteration 20929 : model1 loss : 0.256761 model2 loss : 0.249573
[23:51:01.007] iteration 20930 : model1 loss : 0.074148 model2 loss : 0.082612
[23:51:01.336] iteration 20931 : model1 loss : 0.165278 model2 loss : 0.221731
[23:51:01.660] iteration 20932 : model1 loss : 0.107605 model2 loss : 0.137263
[23:51:01.985] iteration 20933 : model1 loss : 0.120917 model2 loss : 0.136737
[23:51:02.308] iteration 20934 : model1 loss : 0.273981 model2 loss : 0.295096
[23:51:02.639] iteration 20935 : model1 loss : 0.171601 model2 loss : 0.198385
[23:51:02.963] iteration 20936 : model1 loss : 0.088927 model2 loss : 0.156521
[23:51:03.289] iteration 20937 : model1 loss : 0.324956 model2 loss : 0.345856
[23:51:03.615] iteration 20938 : model1 loss : 0.137999 model2 loss : 0.171747
[23:51:03.942] iteration 20939 : model1 loss : 0.247495 model2 loss : 0.269420
[23:51:04.267] iteration 20940 : model1 loss : 0.232078 model2 loss : 0.253731
[23:51:04.590] iteration 20941 : model1 loss : 0.270335 model2 loss : 0.283110
[23:51:04.914] iteration 20942 : model1 loss : 0.284542 model2 loss : 0.277556
[23:51:05.242] iteration 20943 : model1 loss : 0.204881 model2 loss : 0.254712
[23:51:05.567] iteration 20944 : model1 loss : 0.108517 model2 loss : 0.168836
[23:51:05.894] iteration 20945 : model1 loss : 0.096171 model2 loss : 0.144638
[23:51:06.218] iteration 20946 : model1 loss : 0.115024 model2 loss : 0.124726
[23:51:06.543] iteration 20947 : model1 loss : 0.097342 model2 loss : 0.093816
[23:51:06.866] iteration 20948 : model1 loss : 0.204275 model2 loss : 0.211865
[23:51:07.189] iteration 20949 : model1 loss : 0.250761 model2 loss : 0.287763
[23:51:07.516] iteration 20950 : model1 loss : 0.159106 model2 loss : 0.190524
[23:51:08.041] iteration 20951 : model1 loss : 0.107555 model2 loss : 0.257282
[23:51:08.364] iteration 20952 : model1 loss : 0.388814 model2 loss : 0.358061
[23:51:08.689] iteration 20953 : model1 loss : 0.190048 model2 loss : 0.220211
[23:51:09.014] iteration 20954 : model1 loss : 0.180790 model2 loss : 0.260357
[23:51:09.338] iteration 20955 : model1 loss : 0.057711 model2 loss : 0.086016
[23:51:09.662] iteration 20956 : model1 loss : 0.250142 model2 loss : 0.264780
[23:51:09.988] iteration 20957 : model1 loss : 0.180680 model2 loss : 0.199844
[23:51:10.314] iteration 20958 : model1 loss : 0.240036 model2 loss : 0.246160
[23:51:10.639] iteration 20959 : model1 loss : 0.194004 model2 loss : 0.196988
[23:51:10.966] iteration 20960 : model1 loss : 0.185404 model2 loss : 0.237675
[23:51:11.294] iteration 20961 : model1 loss : 0.233462 model2 loss : 0.251737
[23:51:11.617] iteration 20962 : model1 loss : 0.173556 model2 loss : 0.198327
[23:51:11.940] iteration 20963 : model1 loss : 0.197744 model2 loss : 0.200880
[23:51:12.263] iteration 20964 : model1 loss : 0.295610 model2 loss : 0.296776
[23:51:12.587] iteration 20965 : model1 loss : 0.203368 model2 loss : 0.209181
[23:51:12.916] iteration 20966 : model1 loss : 0.099112 model2 loss : 0.123740
[23:51:13.238] iteration 20967 : model1 loss : 0.078340 model2 loss : 0.117579
[23:51:13.563] iteration 20968 : model1 loss : 0.162335 model2 loss : 0.184824
[23:51:13.888] iteration 20969 : model1 loss : 0.262280 model2 loss : 0.282452
[23:51:14.211] iteration 20970 : model1 loss : 0.330762 model2 loss : 0.299858
[23:51:14.537] iteration 20971 : model1 loss : 0.089625 model2 loss : 0.183999
[23:51:14.862] iteration 20972 : model1 loss : 0.269853 model2 loss : 0.311414
[23:51:15.186] iteration 20973 : model1 loss : 0.195020 model2 loss : 0.204199
[23:51:15.511] iteration 20974 : model1 loss : 0.264217 model2 loss : 0.307998
[23:51:15.834] iteration 20975 : model1 loss : 0.215914 model2 loss : 0.263188
[23:51:16.159] iteration 20976 : model1 loss : 0.247682 model2 loss : 0.267648
[23:51:16.486] iteration 20977 : model1 loss : 0.168141 model2 loss : 0.218385
[23:51:16.815] iteration 20978 : model1 loss : 0.168543 model2 loss : 0.187535
[23:51:17.138] iteration 20979 : model1 loss : 0.163618 model2 loss : 0.178500
[23:51:17.461] iteration 20980 : model1 loss : 0.248637 model2 loss : 0.230407
[23:51:17.787] iteration 20981 : model1 loss : 0.205039 model2 loss : 0.216183
[23:51:18.108] iteration 20982 : model1 loss : 0.193173 model2 loss : 0.200813
[23:51:18.429] iteration 20983 : model1 loss : 0.247521 model2 loss : 0.301433
[23:51:18.750] iteration 20984 : model1 loss : 0.246908 model2 loss : 0.259335
[23:51:19.071] iteration 20985 : model1 loss : 0.183288 model2 loss : 0.202763
[23:51:19.392] iteration 20986 : model1 loss : 0.258420 model2 loss : 0.342067
[23:51:19.714] iteration 20987 : model1 loss : 0.175866 model2 loss : 0.190949
[23:51:20.039] iteration 20988 : model1 loss : 0.168538 model2 loss : 0.173855
[23:51:20.363] iteration 20989 : model1 loss : 0.373806 model2 loss : 0.334285
[23:51:20.684] iteration 20990 : model1 loss : 0.291710 model2 loss : 0.301924
[23:51:21.005] iteration 20991 : model1 loss : 0.115499 model2 loss : 0.109976
[23:51:21.326] iteration 20992 : model1 loss : 0.181196 model2 loss : 0.169537
[23:51:21.649] iteration 20993 : model1 loss : 0.099767 model2 loss : 0.159366
[23:51:21.970] iteration 20994 : model1 loss : 0.145213 model2 loss : 0.156754
[23:51:22.296] iteration 20995 : model1 loss : 0.260791 model2 loss : 0.260635
[23:51:22.621] iteration 20996 : model1 loss : 0.173207 model2 loss : 0.225916
[23:51:22.942] iteration 20997 : model1 loss : 0.192358 model2 loss : 0.237802
[23:51:23.264] iteration 20998 : model1 loss : 0.177908 model2 loss : 0.183908
[23:51:23.585] iteration 20999 : model1 loss : 0.178188 model2 loss : 0.211241
[23:51:23.908] iteration 21000 : model1 loss : 0.213657 model2 loss : 0.266603
[23:51:44.758] iteration 21000 : model1_mean_dice : 0.764497 model1_mean_hd95 : 11.923089
[23:52:01.810] iteration 21000 : model2_mean_dice : 0.675587 model2_mean_hd95 : 11.947370
[23:52:01.974] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_21000.pth
[23:52:01.991] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_21000.pth
[23:52:02.326] iteration 21001 : model1 loss : 0.182656 model2 loss : 0.191507
[23:52:02.645] iteration 21002 : model1 loss : 0.111402 model2 loss : 0.132944
[23:52:02.965] iteration 21003 : model1 loss : 0.124605 model2 loss : 0.186567
[23:52:03.285] iteration 21004 : model1 loss : 0.165496 model2 loss : 0.261565
[23:52:03.607] iteration 21005 : model1 loss : 0.153799 model2 loss : 0.225212
[23:52:03.930] iteration 21006 : model1 loss : 0.167369 model2 loss : 0.199165
[23:52:04.253] iteration 21007 : model1 loss : 0.168652 model2 loss : 0.262310
[23:52:04.574] iteration 21008 : model1 loss : 0.148720 model2 loss : 0.173637
[23:52:04.902] iteration 21009 : model1 loss : 0.269431 model2 loss : 0.288188
[23:52:05.222] iteration 21010 : model1 loss : 0.181819 model2 loss : 0.216364
[23:52:05.544] iteration 21011 : model1 loss : 0.260158 model2 loss : 0.293166
[23:52:05.865] iteration 21012 : model1 loss : 0.213326 model2 loss : 0.199619
[23:52:06.191] iteration 21013 : model1 loss : 0.268337 model2 loss : 0.288976
[23:52:06.513] iteration 21014 : model1 loss : 0.186437 model2 loss : 0.269264
[23:52:06.835] iteration 21015 : model1 loss : 0.250531 model2 loss : 0.303127
[23:52:07.159] iteration 21016 : model1 loss : 0.220166 model2 loss : 0.225949
[23:52:07.481] iteration 21017 : model1 loss : 0.190700 model2 loss : 0.244286
[23:52:07.803] iteration 21018 : model1 loss : 0.345528 model2 loss : 0.391952
[23:52:08.127] iteration 21019 : model1 loss : 0.174841 model2 loss : 0.145090
[23:52:08.453] iteration 21020 : model1 loss : 0.156892 model2 loss : 0.180216
[23:52:08.779] iteration 21021 : model1 loss : 0.266359 model2 loss : 0.315906
[23:52:09.105] iteration 21022 : model1 loss : 0.071360 model2 loss : 0.116371
[23:52:09.428] iteration 21023 : model1 loss : 0.234169 model2 loss : 0.238226
[23:52:09.760] iteration 21024 : model1 loss : 0.238755 model2 loss : 0.252916
[23:52:10.088] iteration 21025 : model1 loss : 0.221945 model2 loss : 0.206308
[23:52:10.417] iteration 21026 : model1 loss : 0.166152 model2 loss : 0.190123
[23:52:10.741] iteration 21027 : model1 loss : 0.218336 model2 loss : 0.244188
[23:52:11.072] iteration 21028 : model1 loss : 0.181744 model2 loss : 0.242087
[23:52:11.399] iteration 21029 : model1 loss : 0.330229 model2 loss : 0.318978
[23:52:11.722] iteration 21030 : model1 loss : 0.258453 model2 loss : 0.275448
[23:52:12.051] iteration 21031 : model1 loss : 0.259737 model2 loss : 0.300238
[23:52:12.378] iteration 21032 : model1 loss : 0.222429 model2 loss : 0.218054
[23:52:12.701] iteration 21033 : model1 loss : 0.174514 model2 loss : 0.271115
[23:52:13.024] iteration 21034 : model1 loss : 0.176439 model2 loss : 0.199521
[23:52:13.348] iteration 21035 : model1 loss : 0.254918 model2 loss : 0.247137
[23:52:13.678] iteration 21036 : model1 loss : 0.258908 model2 loss : 0.335479
[23:52:14.006] iteration 21037 : model1 loss : 0.272012 model2 loss : 0.253392
[23:52:14.334] iteration 21038 : model1 loss : 0.263733 model2 loss : 0.279832
[23:52:14.662] iteration 21039 : model1 loss : 0.260076 model2 loss : 0.336262
[23:52:14.985] iteration 21040 : model1 loss : 0.097129 model2 loss : 0.110049
[23:52:15.313] iteration 21041 : model1 loss : 0.167150 model2 loss : 0.205176
[23:52:15.638] iteration 21042 : model1 loss : 0.121404 model2 loss : 0.191613
[23:52:15.962] iteration 21043 : model1 loss : 0.104499 model2 loss : 0.132755
[23:52:16.287] iteration 21044 : model1 loss : 0.184319 model2 loss : 0.208058
[23:52:16.622] iteration 21045 : model1 loss : 0.191570 model2 loss : 0.189987
[23:52:16.945] iteration 21046 : model1 loss : 0.240000 model2 loss : 0.262965
[23:52:17.271] iteration 21047 : model1 loss : 0.134311 model2 loss : 0.143947
[23:52:17.595] iteration 21048 : model1 loss : 0.258883 model2 loss : 0.278654
[23:52:17.923] iteration 21049 : model1 loss : 0.201742 model2 loss : 0.178154
[23:52:18.246] iteration 21050 : model1 loss : 0.246461 model2 loss : 0.251437
[23:52:18.777] iteration 21051 : model1 loss : 0.164960 model2 loss : 0.221234
[23:52:19.100] iteration 21052 : model1 loss : 0.174495 model2 loss : 0.192184
[23:52:19.424] iteration 21053 : model1 loss : 0.153622 model2 loss : 0.153562
[23:52:19.750] iteration 21054 : model1 loss : 0.271788 model2 loss : 0.305394
[23:52:20.073] iteration 21055 : model1 loss : 0.076399 model2 loss : 0.102264
[23:52:20.396] iteration 21056 : model1 loss : 0.191909 model2 loss : 0.193151
[23:52:20.722] iteration 21057 : model1 loss : 0.100974 model2 loss : 0.120916
[23:52:21.046] iteration 21058 : model1 loss : 0.161544 model2 loss : 0.202857
[23:52:21.370] iteration 21059 : model1 loss : 0.318190 model2 loss : 0.330149
[23:52:21.694] iteration 21060 : model1 loss : 0.195778 model2 loss : 0.185838
[23:52:22.017] iteration 21061 : model1 loss : 0.081876 model2 loss : 0.216798
[23:52:22.340] iteration 21062 : model1 loss : 0.275484 model2 loss : 0.285181
[23:52:22.663] iteration 21063 : model1 loss : 0.167154 model2 loss : 0.196484
[23:52:22.986] iteration 21064 : model1 loss : 0.096904 model2 loss : 0.140098
[23:52:23.309] iteration 21065 : model1 loss : 0.187302 model2 loss : 0.226597
[23:52:23.635] iteration 21066 : model1 loss : 0.241588 model2 loss : 0.273188
[23:52:23.958] iteration 21067 : model1 loss : 0.103825 model2 loss : 0.098365
[23:52:24.285] iteration 21068 : model1 loss : 0.160925 model2 loss : 0.215744
[23:52:24.608] iteration 21069 : model1 loss : 0.181644 model2 loss : 0.190182
[23:52:24.931] iteration 21070 : model1 loss : 0.237461 model2 loss : 0.277574
[23:52:25.253] iteration 21071 : model1 loss : 0.124390 model2 loss : 0.141506
[23:52:25.578] iteration 21072 : model1 loss : 0.109651 model2 loss : 0.105113
[23:52:25.902] iteration 21073 : model1 loss : 0.251337 model2 loss : 0.224120
[23:52:26.225] iteration 21074 : model1 loss : 0.240947 model2 loss : 0.257341
[23:52:26.551] iteration 21075 : model1 loss : 0.169642 model2 loss : 0.190802
[23:52:26.873] iteration 21076 : model1 loss : 0.160715 model2 loss : 0.196656
[23:52:27.197] iteration 21077 : model1 loss : 0.262125 model2 loss : 0.300143
[23:52:27.519] iteration 21078 : model1 loss : 0.255818 model2 loss : 0.317436
[23:52:27.842] iteration 21079 : model1 loss : 0.073992 model2 loss : 0.119019
[23:52:28.164] iteration 21080 : model1 loss : 0.182021 model2 loss : 0.275891
[23:52:28.487] iteration 21081 : model1 loss : 0.240192 model2 loss : 0.253975
[23:52:28.815] iteration 21082 : model1 loss : 0.141408 model2 loss : 0.185017
[23:52:29.142] iteration 21083 : model1 loss : 0.156034 model2 loss : 0.184793
[23:52:29.470] iteration 21084 : model1 loss : 0.190393 model2 loss : 0.201223
[23:52:29.797] iteration 21085 : model1 loss : 0.213087 model2 loss : 0.202151
[23:52:30.123] iteration 21086 : model1 loss : 0.179102 model2 loss : 0.198674
[23:52:30.450] iteration 21087 : model1 loss : 0.303290 model2 loss : 0.313017
[23:52:30.778] iteration 21088 : model1 loss : 0.268468 model2 loss : 0.294788
[23:52:31.101] iteration 21089 : model1 loss : 0.117339 model2 loss : 0.190507
[23:52:31.425] iteration 21090 : model1 loss : 0.265031 model2 loss : 0.284943
[23:52:31.753] iteration 21091 : model1 loss : 0.204808 model2 loss : 0.213901
[23:52:32.082] iteration 21092 : model1 loss : 0.233388 model2 loss : 0.243490
[23:52:32.408] iteration 21093 : model1 loss : 0.195007 model2 loss : 0.206866
[23:52:32.737] iteration 21094 : model1 loss : 0.265660 model2 loss : 0.334640
[23:52:33.062] iteration 21095 : model1 loss : 0.197608 model2 loss : 0.296669
[23:52:33.388] iteration 21096 : model1 loss : 0.095481 model2 loss : 0.111147
[23:52:33.716] iteration 21097 : model1 loss : 0.190845 model2 loss : 0.290372
[23:52:34.043] iteration 21098 : model1 loss : 0.119341 model2 loss : 0.132902
[23:52:34.372] iteration 21099 : model1 loss : 0.274287 model2 loss : 0.287711
[23:52:34.699] iteration 21100 : model1 loss : 0.108770 model2 loss : 0.163968
[23:52:35.252] iteration 21101 : model1 loss : 0.186081 model2 loss : 0.225900
[23:52:35.576] iteration 21102 : model1 loss : 0.188319 model2 loss : 0.169330
[23:52:35.904] iteration 21103 : model1 loss : 0.204830 model2 loss : 0.216233
[23:52:36.231] iteration 21104 : model1 loss : 0.276283 model2 loss : 0.300863
[23:52:36.559] iteration 21105 : model1 loss : 0.071807 model2 loss : 0.119688
[23:52:36.887] iteration 21106 : model1 loss : 0.182674 model2 loss : 0.228500
[23:52:37.215] iteration 21107 : model1 loss : 0.112132 model2 loss : 0.222099
[23:52:37.542] iteration 21108 : model1 loss : 0.194754 model2 loss : 0.225617
[23:52:37.872] iteration 21109 : model1 loss : 0.170161 model2 loss : 0.166158
[23:52:38.199] iteration 21110 : model1 loss : 0.236655 model2 loss : 0.290712
[23:52:38.527] iteration 21111 : model1 loss : 0.213032 model2 loss : 0.298078
[23:52:38.855] iteration 21112 : model1 loss : 0.198629 model2 loss : 0.234487
[23:52:39.183] iteration 21113 : model1 loss : 0.251582 model2 loss : 0.277142
[23:52:39.510] iteration 21114 : model1 loss : 0.236532 model2 loss : 0.254891
[23:52:39.838] iteration 21115 : model1 loss : 0.104203 model2 loss : 0.140306
[23:52:40.166] iteration 21116 : model1 loss : 0.153453 model2 loss : 0.178338
[23:52:40.494] iteration 21117 : model1 loss : 0.238510 model2 loss : 0.208046
[23:52:40.822] iteration 21118 : model1 loss : 0.146747 model2 loss : 0.172466
[23:52:41.151] iteration 21119 : model1 loss : 0.180833 model2 loss : 0.227803
[23:52:41.479] iteration 21120 : model1 loss : 0.267472 model2 loss : 0.286446
[23:52:41.808] iteration 21121 : model1 loss : 0.168549 model2 loss : 0.224256
[23:52:42.134] iteration 21122 : model1 loss : 0.251980 model2 loss : 0.299430
[23:52:42.463] iteration 21123 : model1 loss : 0.179157 model2 loss : 0.201454
[23:52:42.791] iteration 21124 : model1 loss : 0.158808 model2 loss : 0.172921
[23:52:43.117] iteration 21125 : model1 loss : 0.108532 model2 loss : 0.137649
[23:52:43.446] iteration 21126 : model1 loss : 0.214765 model2 loss : 0.236632
[23:52:43.775] iteration 21127 : model1 loss : 0.323298 model2 loss : 0.404003
[23:52:44.103] iteration 21128 : model1 loss : 0.196436 model2 loss : 0.223427
[23:52:44.432] iteration 21129 : model1 loss : 0.189532 model2 loss : 0.225800
[23:52:44.760] iteration 21130 : model1 loss : 0.177790 model2 loss : 0.183711
[23:52:45.088] iteration 21131 : model1 loss : 0.154665 model2 loss : 0.201845
[23:52:45.417] iteration 21132 : model1 loss : 0.263775 model2 loss : 0.359406
[23:52:45.747] iteration 21133 : model1 loss : 0.162547 model2 loss : 0.182561
[23:52:46.074] iteration 21134 : model1 loss : 0.196462 model2 loss : 0.262561
[23:52:46.403] iteration 21135 : model1 loss : 0.090784 model2 loss : 0.146868
[23:52:46.731] iteration 21136 : model1 loss : 0.111630 model2 loss : 0.109092
[23:52:47.058] iteration 21137 : model1 loss : 0.176745 model2 loss : 0.250349
[23:52:47.386] iteration 21138 : model1 loss : 0.174966 model2 loss : 0.264321
[23:52:47.714] iteration 21139 : model1 loss : 0.171313 model2 loss : 0.193668
[23:52:48.039] iteration 21140 : model1 loss : 0.180910 model2 loss : 0.217314
[23:52:48.362] iteration 21141 : model1 loss : 0.185104 model2 loss : 0.159858
[23:52:48.686] iteration 21142 : model1 loss : 0.266613 model2 loss : 0.304201
[23:52:49.012] iteration 21143 : model1 loss : 0.123744 model2 loss : 0.155429
[23:52:49.339] iteration 21144 : model1 loss : 0.204253 model2 loss : 0.211428
[23:52:49.665] iteration 21145 : model1 loss : 0.123306 model2 loss : 0.172369
[23:52:49.988] iteration 21146 : model1 loss : 0.199820 model2 loss : 0.255327
[23:52:50.317] iteration 21147 : model1 loss : 0.157577 model2 loss : 0.177356
[23:52:50.645] iteration 21148 : model1 loss : 0.159029 model2 loss : 0.214397
[23:52:50.972] iteration 21149 : model1 loss : 0.289242 model2 loss : 0.306197
[23:52:51.300] iteration 21150 : model1 loss : 0.243667 model2 loss : 0.249527
[23:52:51.868] iteration 21151 : model1 loss : 0.220625 model2 loss : 0.231365
[23:52:52.197] iteration 21152 : model1 loss : 0.167342 model2 loss : 0.175976
[23:52:52.525] iteration 21153 : model1 loss : 0.129809 model2 loss : 0.122079
[23:52:52.860] iteration 21154 : model1 loss : 0.276764 model2 loss : 0.342154
[23:52:53.188] iteration 21155 : model1 loss : 0.191987 model2 loss : 0.229600
[23:52:53.516] iteration 21156 : model1 loss : 0.185376 model2 loss : 0.200178
[23:52:53.845] iteration 21157 : model1 loss : 0.246754 model2 loss : 0.266987
[23:52:54.173] iteration 21158 : model1 loss : 0.324590 model2 loss : 0.325050
[23:52:54.501] iteration 21159 : model1 loss : 0.300695 model2 loss : 0.310949
[23:52:54.830] iteration 21160 : model1 loss : 0.167791 model2 loss : 0.174307
[23:52:55.157] iteration 21161 : model1 loss : 0.242522 model2 loss : 0.306897
[23:52:55.485] iteration 21162 : model1 loss : 0.246681 model2 loss : 0.265382
[23:52:55.814] iteration 21163 : model1 loss : 0.198656 model2 loss : 0.251688
[23:52:56.141] iteration 21164 : model1 loss : 0.153355 model2 loss : 0.164111
[23:52:56.478] iteration 21165 : model1 loss : 0.187344 model2 loss : 0.196687
[23:52:56.815] iteration 21166 : model1 loss : 0.130701 model2 loss : 0.218594
[23:52:57.151] iteration 21167 : model1 loss : 0.193913 model2 loss : 0.258777
[23:52:57.487] iteration 21168 : model1 loss : 0.114191 model2 loss : 0.186324
[23:52:57.824] iteration 21169 : model1 loss : 0.175007 model2 loss : 0.188260
[23:52:58.159] iteration 21170 : model1 loss : 0.230758 model2 loss : 0.240059
[23:52:58.498] iteration 21171 : model1 loss : 0.166391 model2 loss : 0.272595
[23:52:58.834] iteration 21172 : model1 loss : 0.190660 model2 loss : 0.267973
[23:52:59.176] iteration 21173 : model1 loss : 0.156779 model2 loss : 0.176578
[23:52:59.512] iteration 21174 : model1 loss : 0.240921 model2 loss : 0.250297
[23:52:59.848] iteration 21175 : model1 loss : 0.107345 model2 loss : 0.140374
[23:53:00.184] iteration 21176 : model1 loss : 0.194062 model2 loss : 0.184037
[23:53:00.520] iteration 21177 : model1 loss : 0.243910 model2 loss : 0.279097
[23:53:00.856] iteration 21178 : model1 loss : 0.147141 model2 loss : 0.165749
[23:53:01.192] iteration 21179 : model1 loss : 0.114112 model2 loss : 0.129118
[23:53:01.543] iteration 21180 : model1 loss : 0.235589 model2 loss : 0.275317
[23:53:01.880] iteration 21181 : model1 loss : 0.246455 model2 loss : 0.256691
[23:53:02.215] iteration 21182 : model1 loss : 0.169151 model2 loss : 0.167102
[23:53:02.552] iteration 21183 : model1 loss : 0.087504 model2 loss : 0.291047
[23:53:02.888] iteration 21184 : model1 loss : 0.171621 model2 loss : 0.162641
[23:53:03.224] iteration 21185 : model1 loss : 0.159836 model2 loss : 0.212813
[23:53:03.560] iteration 21186 : model1 loss : 0.066220 model2 loss : 0.079878
[23:53:03.897] iteration 21187 : model1 loss : 0.261540 model2 loss : 0.264538
[23:53:04.234] iteration 21188 : model1 loss : 0.076667 model2 loss : 0.078359
[23:53:04.571] iteration 21189 : model1 loss : 0.130988 model2 loss : 0.114044
[23:53:04.907] iteration 21190 : model1 loss : 0.108556 model2 loss : 0.154881
[23:53:05.243] iteration 21191 : model1 loss : 0.248085 model2 loss : 0.265064
[23:53:05.580] iteration 21192 : model1 loss : 0.198462 model2 loss : 0.240437
[23:53:05.916] iteration 21193 : model1 loss : 0.181069 model2 loss : 0.208787
[23:53:06.253] iteration 21194 : model1 loss : 0.163617 model2 loss : 0.170377
[23:53:06.590] iteration 21195 : model1 loss : 0.182831 model2 loss : 0.214446
[23:53:06.927] iteration 21196 : model1 loss : 0.262309 model2 loss : 0.265715
[23:53:07.265] iteration 21197 : model1 loss : 0.153848 model2 loss : 0.256739
[23:53:07.602] iteration 21198 : model1 loss : 0.304076 model2 loss : 0.320797
[23:53:07.938] iteration 21199 : model1 loss : 0.190983 model2 loss : 0.247988
[23:53:08.275] iteration 21200 : model1 loss : 0.084113 model2 loss : 0.097817
[23:53:08.910] iteration 21201 : model1 loss : 0.169981 model2 loss : 0.198801
[23:53:09.245] iteration 21202 : model1 loss : 0.259886 model2 loss : 0.290748
[23:53:09.585] iteration 21203 : model1 loss : 0.233985 model2 loss : 0.265833
[23:53:09.920] iteration 21204 : model1 loss : 0.162187 model2 loss : 0.224275
[23:53:10.253] iteration 21205 : model1 loss : 0.248833 model2 loss : 0.284046
[23:53:10.584] iteration 21206 : model1 loss : 0.220833 model2 loss : 0.175186
[23:53:10.921] iteration 21207 : model1 loss : 0.277433 model2 loss : 0.322336
[23:53:11.256] iteration 21208 : model1 loss : 0.252780 model2 loss : 0.278671
[23:53:11.593] iteration 21209 : model1 loss : 0.159729 model2 loss : 0.205744
[23:53:11.928] iteration 21210 : model1 loss : 0.212452 model2 loss : 0.260063
[23:53:12.265] iteration 21211 : model1 loss : 0.256418 model2 loss : 0.269116
[23:53:12.602] iteration 21212 : model1 loss : 0.142890 model2 loss : 0.148688
[23:53:12.938] iteration 21213 : model1 loss : 0.178315 model2 loss : 0.197104
[23:53:13.275] iteration 21214 : model1 loss : 0.234355 model2 loss : 0.305579
[23:53:13.616] iteration 21215 : model1 loss : 0.173133 model2 loss : 0.204602
[23:53:13.952] iteration 21216 : model1 loss : 0.250030 model2 loss : 0.251477
[23:53:14.288] iteration 21217 : model1 loss : 0.274916 model2 loss : 0.269376
[23:53:14.625] iteration 21218 : model1 loss : 0.167905 model2 loss : 0.194325
[23:53:14.962] iteration 21219 : model1 loss : 0.230834 model2 loss : 0.237447
[23:53:15.300] iteration 21220 : model1 loss : 0.150244 model2 loss : 0.213653
[23:53:15.638] iteration 21221 : model1 loss : 0.214045 model2 loss : 0.302446
[23:53:15.976] iteration 21222 : model1 loss : 0.163650 model2 loss : 0.237703
[23:53:16.316] iteration 21223 : model1 loss : 0.258669 model2 loss : 0.321320
[23:53:16.654] iteration 21224 : model1 loss : 0.186552 model2 loss : 0.255813
[23:53:16.992] iteration 21225 : model1 loss : 0.194835 model2 loss : 0.204201
[23:53:17.329] iteration 21226 : model1 loss : 0.241559 model2 loss : 0.263307
[23:53:17.666] iteration 21227 : model1 loss : 0.196643 model2 loss : 0.185867
[23:53:18.002] iteration 21228 : model1 loss : 0.251789 model2 loss : 0.322580
[23:53:18.341] iteration 21229 : model1 loss : 0.267633 model2 loss : 0.285370
[23:53:18.678] iteration 21230 : model1 loss : 0.084238 model2 loss : 0.125902
[23:53:19.015] iteration 21231 : model1 loss : 0.226589 model2 loss : 0.231423
[23:53:19.352] iteration 21232 : model1 loss : 0.158384 model2 loss : 0.205492
[23:53:19.690] iteration 21233 : model1 loss : 0.080729 model2 loss : 0.094516
[23:53:20.029] iteration 21234 : model1 loss : 0.199559 model2 loss : 0.206068
[23:53:20.367] iteration 21235 : model1 loss : 0.200032 model2 loss : 0.226893
[23:53:20.695] iteration 21236 : model1 loss : 0.164631 model2 loss : 0.246746
[23:53:21.024] iteration 21237 : model1 loss : 0.097659 model2 loss : 0.107406
[23:53:21.352] iteration 21238 : model1 loss : 0.262958 model2 loss : 0.280039
[23:53:21.680] iteration 21239 : model1 loss : 0.150232 model2 loss : 0.157625
[23:53:22.008] iteration 21240 : model1 loss : 0.175727 model2 loss : 0.210420
[23:53:22.335] iteration 21241 : model1 loss : 0.186996 model2 loss : 0.167317
[23:53:22.663] iteration 21242 : model1 loss : 0.251990 model2 loss : 0.314064
[23:53:22.990] iteration 21243 : model1 loss : 0.218981 model2 loss : 0.203520
[23:53:23.318] iteration 21244 : model1 loss : 0.248390 model2 loss : 0.273585
[23:53:23.646] iteration 21245 : model1 loss : 0.163592 model2 loss : 0.246210
[23:53:23.973] iteration 21246 : model1 loss : 0.151215 model2 loss : 0.157850
[23:53:24.301] iteration 21247 : model1 loss : 0.090999 model2 loss : 0.162380
[23:53:24.629] iteration 21248 : model1 loss : 0.196278 model2 loss : 0.232030
[23:53:24.955] iteration 21249 : model1 loss : 0.155432 model2 loss : 0.165014
[23:53:25.283] iteration 21250 : model1 loss : 0.247453 model2 loss : 0.264551
[23:53:25.833] iteration 21251 : model1 loss : 0.167998 model2 loss : 0.183207
[23:53:26.162] iteration 21252 : model1 loss : 0.134077 model2 loss : 0.169062
[23:53:26.490] iteration 21253 : model1 loss : 0.103924 model2 loss : 0.152082
[23:53:26.819] iteration 21254 : model1 loss : 0.263034 model2 loss : 0.307109
[23:53:27.147] iteration 21255 : model1 loss : 0.165289 model2 loss : 0.206691
[23:53:28.163] iteration 21256 : model1 loss : 0.097590 model2 loss : 0.129331
[23:53:28.490] iteration 21257 : model1 loss : 0.288428 model2 loss : 0.288580
[23:53:28.822] iteration 21258 : model1 loss : 0.174815 model2 loss : 0.191954
[23:53:29.150] iteration 21259 : model1 loss : 0.180803 model2 loss : 0.168602
[23:53:29.476] iteration 21260 : model1 loss : 0.118001 model2 loss : 0.168132
[23:53:29.799] iteration 21261 : model1 loss : 0.057828 model2 loss : 0.065844
[23:53:30.124] iteration 21262 : model1 loss : 0.174241 model2 loss : 0.289040
[23:53:30.453] iteration 21263 : model1 loss : 0.104446 model2 loss : 0.146886
[23:53:30.781] iteration 21264 : model1 loss : 0.193134 model2 loss : 0.215505
[23:53:31.110] iteration 21265 : model1 loss : 0.267582 model2 loss : 0.276196
[23:53:31.443] iteration 21266 : model1 loss : 0.175107 model2 loss : 0.212101
[23:53:31.771] iteration 21267 : model1 loss : 0.259284 model2 loss : 0.281780
[23:53:32.099] iteration 21268 : model1 loss : 0.241895 model2 loss : 0.231577
[23:53:32.427] iteration 21269 : model1 loss : 0.110880 model2 loss : 0.099810
[23:53:32.759] iteration 21270 : model1 loss : 0.199068 model2 loss : 0.231798
[23:53:33.087] iteration 21271 : model1 loss : 0.170864 model2 loss : 0.240092
[23:53:33.415] iteration 21272 : model1 loss : 0.097899 model2 loss : 0.128936
[23:53:33.745] iteration 21273 : model1 loss : 0.247312 model2 loss : 0.307938
[23:53:34.074] iteration 21274 : model1 loss : 0.113612 model2 loss : 0.145777
[23:53:34.405] iteration 21275 : model1 loss : 0.223716 model2 loss : 0.313082
[23:53:34.734] iteration 21276 : model1 loss : 0.261407 model2 loss : 0.298152
[23:53:35.062] iteration 21277 : model1 loss : 0.172852 model2 loss : 0.171553
[23:53:35.392] iteration 21278 : model1 loss : 0.143210 model2 loss : 0.177350
[23:53:35.720] iteration 21279 : model1 loss : 0.159087 model2 loss : 0.175318
[23:53:36.050] iteration 21280 : model1 loss : 0.204042 model2 loss : 0.153326
[23:53:36.378] iteration 21281 : model1 loss : 0.187064 model2 loss : 0.179042
[23:53:36.707] iteration 21282 : model1 loss : 0.198992 model2 loss : 0.217546
[23:53:37.036] iteration 21283 : model1 loss : 0.096279 model2 loss : 0.103872
[23:53:37.366] iteration 21284 : model1 loss : 0.245363 model2 loss : 0.282421
[23:53:37.697] iteration 21285 : model1 loss : 0.184078 model2 loss : 0.207016
[23:53:38.026] iteration 21286 : model1 loss : 0.176923 model2 loss : 0.232619
[23:53:38.356] iteration 21287 : model1 loss : 0.228479 model2 loss : 0.264354
[23:53:38.685] iteration 21288 : model1 loss : 0.277322 model2 loss : 0.288123
[23:53:39.014] iteration 21289 : model1 loss : 0.242541 model2 loss : 0.292063
[23:53:39.346] iteration 21290 : model1 loss : 0.252915 model2 loss : 0.265145
[23:53:39.675] iteration 21291 : model1 loss : 0.143931 model2 loss : 0.182348
[23:53:40.008] iteration 21292 : model1 loss : 0.293154 model2 loss : 0.286138
[23:53:40.337] iteration 21293 : model1 loss : 0.218192 model2 loss : 0.224233
[23:53:40.666] iteration 21294 : model1 loss : 0.267853 model2 loss : 0.271922
[23:53:40.996] iteration 21295 : model1 loss : 0.104575 model2 loss : 0.113425
[23:53:41.326] iteration 21296 : model1 loss : 0.170200 model2 loss : 0.161133
[23:53:41.656] iteration 21297 : model1 loss : 0.167399 model2 loss : 0.213634
[23:53:41.987] iteration 21298 : model1 loss : 0.129845 model2 loss : 0.183050
[23:53:42.315] iteration 21299 : model1 loss : 0.190124 model2 loss : 0.260122
[23:53:42.644] iteration 21300 : model1 loss : 0.183361 model2 loss : 0.252807
[23:53:43.225] iteration 21301 : model1 loss : 0.089454 model2 loss : 0.122920
[23:53:43.556] iteration 21302 : model1 loss : 0.196412 model2 loss : 0.309539
[23:53:43.886] iteration 21303 : model1 loss : 0.185548 model2 loss : 0.176770
[23:53:44.214] iteration 21304 : model1 loss : 0.204551 model2 loss : 0.274423
[23:53:44.544] iteration 21305 : model1 loss : 0.184009 model2 loss : 0.197117
[23:53:44.874] iteration 21306 : model1 loss : 0.191200 model2 loss : 0.218449
[23:53:45.202] iteration 21307 : model1 loss : 0.177743 model2 loss : 0.187123
[23:53:45.529] iteration 21308 : model1 loss : 0.114794 model2 loss : 0.110867
[23:53:45.858] iteration 21309 : model1 loss : 0.081090 model2 loss : 0.131008
[23:53:46.187] iteration 21310 : model1 loss : 0.239719 model2 loss : 0.262389
[23:53:46.515] iteration 21311 : model1 loss : 0.088202 model2 loss : 0.128033
[23:53:46.846] iteration 21312 : model1 loss : 0.248335 model2 loss : 0.294927
[23:53:47.176] iteration 21313 : model1 loss : 0.169421 model2 loss : 0.208965
[23:53:47.503] iteration 21314 : model1 loss : 0.183175 model2 loss : 0.183593
[23:53:47.831] iteration 21315 : model1 loss : 0.248203 model2 loss : 0.273570
[23:53:48.158] iteration 21316 : model1 loss : 0.179997 model2 loss : 0.201012
[23:53:48.487] iteration 21317 : model1 loss : 0.236829 model2 loss : 0.240740
[23:53:48.818] iteration 21318 : model1 loss : 0.189507 model2 loss : 0.186901
[23:53:49.146] iteration 21319 : model1 loss : 0.193875 model2 loss : 0.349694
[23:53:49.475] iteration 21320 : model1 loss : 0.177156 model2 loss : 0.252530
[23:53:49.806] iteration 21321 : model1 loss : 0.177051 model2 loss : 0.190830
[23:53:50.136] iteration 21322 : model1 loss : 0.208493 model2 loss : 0.271976
[23:53:50.466] iteration 21323 : model1 loss : 0.252292 model2 loss : 0.308050
[23:53:50.794] iteration 21324 : model1 loss : 0.142413 model2 loss : 0.223238
[23:53:51.123] iteration 21325 : model1 loss : 0.151663 model2 loss : 0.189059
[23:53:51.453] iteration 21326 : model1 loss : 0.225564 model2 loss : 0.217863
[23:53:51.782] iteration 21327 : model1 loss : 0.224053 model2 loss : 0.191045
[23:53:52.110] iteration 21328 : model1 loss : 0.279354 model2 loss : 0.309860
[23:53:52.439] iteration 21329 : model1 loss : 0.091240 model2 loss : 0.094958
[23:53:52.768] iteration 21330 : model1 loss : 0.184429 model2 loss : 0.243478
[23:53:53.096] iteration 21331 : model1 loss : 0.186434 model2 loss : 0.204574
[23:53:53.426] iteration 21332 : model1 loss : 0.200456 model2 loss : 0.211490
[23:53:53.754] iteration 21333 : model1 loss : 0.126872 model2 loss : 0.170830
[23:53:54.083] iteration 21334 : model1 loss : 0.193262 model2 loss : 0.226743
[23:53:54.412] iteration 21335 : model1 loss : 0.182683 model2 loss : 0.208450
[23:53:54.742] iteration 21336 : model1 loss : 0.162248 model2 loss : 0.163493
[23:53:55.071] iteration 21337 : model1 loss : 0.159781 model2 loss : 0.187836
[23:53:55.400] iteration 21338 : model1 loss : 0.278691 model2 loss : 0.301792
[23:53:55.729] iteration 21339 : model1 loss : 0.164651 model2 loss : 0.183584
[23:53:56.059] iteration 21340 : model1 loss : 0.239424 model2 loss : 0.286677
[23:53:56.390] iteration 21341 : model1 loss : 0.127609 model2 loss : 0.198326
[23:53:56.719] iteration 21342 : model1 loss : 0.167145 model2 loss : 0.191246
[23:53:57.047] iteration 21343 : model1 loss : 0.269290 model2 loss : 0.278804
[23:53:57.376] iteration 21344 : model1 loss : 0.177253 model2 loss : 0.203822
[23:53:57.705] iteration 21345 : model1 loss : 0.212685 model2 loss : 0.250293
[23:53:58.033] iteration 21346 : model1 loss : 0.251763 model2 loss : 0.269907
[23:53:58.362] iteration 21347 : model1 loss : 0.272844 model2 loss : 0.301350
[23:53:58.691] iteration 21348 : model1 loss : 0.165473 model2 loss : 0.213582
[23:53:59.027] iteration 21349 : model1 loss : 0.179893 model2 loss : 0.231117
[23:53:59.356] iteration 21350 : model1 loss : 0.284460 model2 loss : 0.268115
[23:53:59.915] iteration 21351 : model1 loss : 0.126797 model2 loss : 0.178721
[23:54:00.243] iteration 21352 : model1 loss : 0.217795 model2 loss : 0.286099
[23:54:00.574] iteration 21353 : model1 loss : 0.190179 model2 loss : 0.201797
[23:54:00.903] iteration 21354 : model1 loss : 0.247495 model2 loss : 0.274260
[23:54:01.232] iteration 21355 : model1 loss : 0.172003 model2 loss : 0.207254
[23:54:01.563] iteration 21356 : model1 loss : 0.255411 model2 loss : 0.250203
[23:54:01.892] iteration 21357 : model1 loss : 0.154219 model2 loss : 0.236558
[23:54:02.222] iteration 21358 : model1 loss : 0.201914 model2 loss : 0.236874
[23:54:02.549] iteration 21359 : model1 loss : 0.204321 model2 loss : 0.234302
[23:54:02.879] iteration 21360 : model1 loss : 0.260965 model2 loss : 0.298980
[23:54:03.207] iteration 21361 : model1 loss : 0.255537 model2 loss : 0.309631
[23:54:03.536] iteration 21362 : model1 loss : 0.117728 model2 loss : 0.187561
[23:54:03.866] iteration 21363 : model1 loss : 0.278476 model2 loss : 0.282486
[23:54:04.196] iteration 21364 : model1 loss : 0.271276 model2 loss : 0.290469
[23:54:04.524] iteration 21365 : model1 loss : 0.075948 model2 loss : 0.110153
[23:54:04.853] iteration 21366 : model1 loss : 0.108939 model2 loss : 0.134023
[23:54:05.182] iteration 21367 : model1 loss : 0.173724 model2 loss : 0.188746
[23:54:05.513] iteration 21368 : model1 loss : 0.226584 model2 loss : 0.209808
[23:54:05.843] iteration 21369 : model1 loss : 0.171967 model2 loss : 0.200884
[23:54:06.171] iteration 21370 : model1 loss : 0.100000 model2 loss : 0.132307
[23:54:06.500] iteration 21371 : model1 loss : 0.239072 model2 loss : 0.244333
[23:54:06.830] iteration 21372 : model1 loss : 0.160473 model2 loss : 0.169876
[23:54:07.158] iteration 21373 : model1 loss : 0.195512 model2 loss : 0.233599
[23:54:07.487] iteration 21374 : model1 loss : 0.245513 model2 loss : 0.253946
[23:54:07.815] iteration 21375 : model1 loss : 0.181013 model2 loss : 0.211785
[23:54:08.144] iteration 21376 : model1 loss : 0.172042 model2 loss : 0.193268
[23:54:08.472] iteration 21377 : model1 loss : 0.208445 model2 loss : 0.213109
[23:54:08.800] iteration 21378 : model1 loss : 0.086225 model2 loss : 0.120958
[23:54:09.130] iteration 21379 : model1 loss : 0.101813 model2 loss : 0.163885
[23:54:09.459] iteration 21380 : model1 loss : 0.217040 model2 loss : 0.247504
[23:54:09.788] iteration 21381 : model1 loss : 0.161515 model2 loss : 0.182825
[23:54:10.116] iteration 21382 : model1 loss : 0.165181 model2 loss : 0.188395
[23:54:10.446] iteration 21383 : model1 loss : 0.091421 model2 loss : 0.128087
[23:54:10.774] iteration 21384 : model1 loss : 0.191282 model2 loss : 0.205593
[23:54:11.104] iteration 21385 : model1 loss : 0.223186 model2 loss : 0.195649
[23:54:11.433] iteration 21386 : model1 loss : 0.233157 model2 loss : 0.307981
[23:54:11.762] iteration 21387 : model1 loss : 0.202823 model2 loss : 0.247948
[23:54:12.093] iteration 21388 : model1 loss : 0.174890 model2 loss : 0.221811
[23:54:12.422] iteration 21389 : model1 loss : 0.066882 model2 loss : 0.148284
[23:54:12.750] iteration 21390 : model1 loss : 0.262135 model2 loss : 0.295987
[23:54:13.078] iteration 21391 : model1 loss : 0.093093 model2 loss : 0.143360
[23:54:13.407] iteration 21392 : model1 loss : 0.266981 model2 loss : 0.294659
[23:54:13.738] iteration 21393 : model1 loss : 0.212512 model2 loss : 0.288569
[23:54:14.068] iteration 21394 : model1 loss : 0.227713 model2 loss : 0.208450
[23:54:14.398] iteration 21395 : model1 loss : 0.209008 model2 loss : 0.286383
[23:54:14.728] iteration 21396 : model1 loss : 0.240776 model2 loss : 0.296716
[23:54:15.057] iteration 21397 : model1 loss : 0.143819 model2 loss : 0.190213
[23:54:15.387] iteration 21398 : model1 loss : 0.204361 model2 loss : 0.233388
[23:54:15.716] iteration 21399 : model1 loss : 0.177966 model2 loss : 0.198913
[23:54:16.047] iteration 21400 : model1 loss : 0.243237 model2 loss : 0.252198
[23:54:16.602] iteration 21401 : model1 loss : 0.120063 model2 loss : 0.120389
[23:54:16.931] iteration 21402 : model1 loss : 0.143003 model2 loss : 0.188961
[23:54:17.259] iteration 21403 : model1 loss : 0.100091 model2 loss : 0.156183
[23:54:17.588] iteration 21404 : model1 loss : 0.196692 model2 loss : 0.211782
[23:54:17.917] iteration 21405 : model1 loss : 0.266270 model2 loss : 0.293017
[23:54:18.246] iteration 21406 : model1 loss : 0.109218 model2 loss : 0.148939
[23:54:18.574] iteration 21407 : model1 loss : 0.177348 model2 loss : 0.231100
[23:54:18.902] iteration 21408 : model1 loss : 0.242578 model2 loss : 0.272604
[23:54:19.231] iteration 21409 : model1 loss : 0.251061 model2 loss : 0.263961
[23:54:19.561] iteration 21410 : model1 loss : 0.262671 model2 loss : 0.297592
[23:54:19.891] iteration 21411 : model1 loss : 0.158605 model2 loss : 0.175778
[23:54:20.219] iteration 21412 : model1 loss : 0.274058 model2 loss : 0.284386
[23:54:20.549] iteration 21413 : model1 loss : 0.180243 model2 loss : 0.259645
[23:54:20.878] iteration 21414 : model1 loss : 0.244450 model2 loss : 0.266963
[23:54:21.207] iteration 21415 : model1 loss : 0.269349 model2 loss : 0.351510
[23:54:21.536] iteration 21416 : model1 loss : 0.306947 model2 loss : 0.402730
[23:54:21.865] iteration 21417 : model1 loss : 0.165304 model2 loss : 0.173013
[23:54:22.193] iteration 21418 : model1 loss : 0.117173 model2 loss : 0.143979
[23:54:22.526] iteration 21419 : model1 loss : 0.164614 model2 loss : 0.223385
[23:54:22.854] iteration 21420 : model1 loss : 0.170303 model2 loss : 0.202865
[23:54:23.182] iteration 21421 : model1 loss : 0.248958 model2 loss : 0.260652
[23:54:23.511] iteration 21422 : model1 loss : 0.197547 model2 loss : 0.239878
[23:54:23.840] iteration 21423 : model1 loss : 0.315426 model2 loss : 0.405690
[23:54:24.167] iteration 21424 : model1 loss : 0.181009 model2 loss : 0.245958
[23:54:24.498] iteration 21425 : model1 loss : 0.087426 model2 loss : 0.109465
[23:54:24.827] iteration 21426 : model1 loss : 0.265315 model2 loss : 0.334685
[23:54:25.159] iteration 21427 : model1 loss : 0.215132 model2 loss : 0.262651
[23:54:25.489] iteration 21428 : model1 loss : 0.072677 model2 loss : 0.098589
[23:54:25.818] iteration 21429 : model1 loss : 0.170875 model2 loss : 0.207512
[23:54:26.147] iteration 21430 : model1 loss : 0.250314 model2 loss : 0.278717
[23:54:26.475] iteration 21431 : model1 loss : 0.255323 model2 loss : 0.335118
[23:54:26.806] iteration 21432 : model1 loss : 0.176931 model2 loss : 0.234803
[23:54:27.134] iteration 21433 : model1 loss : 0.166145 model2 loss : 0.188366
[23:54:27.463] iteration 21434 : model1 loss : 0.166082 model2 loss : 0.185505
[23:54:27.791] iteration 21435 : model1 loss : 0.195562 model2 loss : 0.235828
[23:54:28.120] iteration 21436 : model1 loss : 0.252202 model2 loss : 0.277182
[23:54:28.452] iteration 21437 : model1 loss : 0.155770 model2 loss : 0.168135
[23:54:28.780] iteration 21438 : model1 loss : 0.096083 model2 loss : 0.127662
[23:54:29.109] iteration 21439 : model1 loss : 0.245425 model2 loss : 0.261451
[23:54:29.437] iteration 21440 : model1 loss : 0.072315 model2 loss : 0.094737
[23:54:29.766] iteration 21441 : model1 loss : 0.201276 model2 loss : 0.256055
[23:54:30.096] iteration 21442 : model1 loss : 0.123329 model2 loss : 0.146969
[23:54:30.427] iteration 21443 : model1 loss : 0.210984 model2 loss : 0.223681
[23:54:30.757] iteration 21444 : model1 loss : 0.176583 model2 loss : 0.219259
[23:54:31.086] iteration 21445 : model1 loss : 0.266637 model2 loss : 0.280893
[23:54:31.416] iteration 21446 : model1 loss : 0.163737 model2 loss : 0.203517
[23:54:31.744] iteration 21447 : model1 loss : 0.176529 model2 loss : 0.186798
[23:54:32.071] iteration 21448 : model1 loss : 0.266304 model2 loss : 0.293630
[23:54:32.400] iteration 21449 : model1 loss : 0.112180 model2 loss : 0.122136
[23:54:32.730] iteration 21450 : model1 loss : 0.197392 model2 loss : 0.180312
[23:54:33.263] iteration 21451 : model1 loss : 0.154228 model2 loss : 0.170570
[23:54:33.592] iteration 21452 : model1 loss : 0.203142 model2 loss : 0.243601
[23:54:33.921] iteration 21453 : model1 loss : 0.201452 model2 loss : 0.231563
[23:54:34.249] iteration 21454 : model1 loss : 0.075885 model2 loss : 0.088273
[23:54:34.577] iteration 21455 : model1 loss : 0.085794 model2 loss : 0.127108
[23:54:34.905] iteration 21456 : model1 loss : 0.275353 model2 loss : 0.385290
[23:54:35.234] iteration 21457 : model1 loss : 0.303021 model2 loss : 0.252799
[23:54:35.562] iteration 21458 : model1 loss : 0.196829 model2 loss : 0.221467
[23:54:35.891] iteration 21459 : model1 loss : 0.287222 model2 loss : 0.395737
[23:54:36.219] iteration 21460 : model1 loss : 0.249272 model2 loss : 0.260586
[23:54:36.548] iteration 21461 : model1 loss : 0.174810 model2 loss : 0.224197
[23:54:36.876] iteration 21462 : model1 loss : 0.174923 model2 loss : 0.213749
[23:54:37.204] iteration 21463 : model1 loss : 0.170429 model2 loss : 0.191452
[23:54:37.532] iteration 21464 : model1 loss : 0.203394 model2 loss : 0.228263
[23:54:37.863] iteration 21465 : model1 loss : 0.185135 model2 loss : 0.213318
[23:54:38.191] iteration 21466 : model1 loss : 0.230930 model2 loss : 0.200699
[23:54:38.519] iteration 21467 : model1 loss : 0.178686 model2 loss : 0.205202
[23:54:38.847] iteration 21468 : model1 loss : 0.120601 model2 loss : 0.173623
[23:54:39.180] iteration 21469 : model1 loss : 0.188647 model2 loss : 0.223761
[23:54:39.512] iteration 21470 : model1 loss : 0.173126 model2 loss : 0.174798
[23:54:39.839] iteration 21471 : model1 loss : 0.239103 model2 loss : 0.297480
[23:54:40.168] iteration 21472 : model1 loss : 0.181567 model2 loss : 0.192676
[23:54:40.499] iteration 21473 : model1 loss : 0.092145 model2 loss : 0.127650
[23:54:40.826] iteration 21474 : model1 loss : 0.262928 model2 loss : 0.294161
[23:54:41.155] iteration 21475 : model1 loss : 0.170314 model2 loss : 0.199818
[23:54:41.484] iteration 21476 : model1 loss : 0.264432 model2 loss : 0.283091
[23:54:41.814] iteration 21477 : model1 loss : 0.201385 model2 loss : 0.229915
[23:54:42.143] iteration 21478 : model1 loss : 0.319212 model2 loss : 0.327665
[23:54:42.473] iteration 21479 : model1 loss : 0.231215 model2 loss : 0.283208
[23:54:42.802] iteration 21480 : model1 loss : 0.094134 model2 loss : 0.109531
[23:54:43.133] iteration 21481 : model1 loss : 0.183940 model2 loss : 0.206286
[23:54:43.461] iteration 21482 : model1 loss : 0.114492 model2 loss : 0.162660
[23:54:43.789] iteration 21483 : model1 loss : 0.290089 model2 loss : 0.280330
[23:54:44.118] iteration 21484 : model1 loss : 0.184990 model2 loss : 0.270110
[23:54:44.448] iteration 21485 : model1 loss : 0.243778 model2 loss : 0.317369
[23:54:44.777] iteration 21486 : model1 loss : 0.186152 model2 loss : 0.329202
[23:54:45.107] iteration 21487 : model1 loss : 0.233833 model2 loss : 0.263739
[23:54:45.436] iteration 21488 : model1 loss : 0.059457 model2 loss : 0.082327
[23:54:45.765] iteration 21489 : model1 loss : 0.193116 model2 loss : 0.237593
[23:54:46.095] iteration 21490 : model1 loss : 0.265430 model2 loss : 0.272561
[23:54:46.423] iteration 21491 : model1 loss : 0.190202 model2 loss : 0.254527
[23:54:46.753] iteration 21492 : model1 loss : 0.249870 model2 loss : 0.284215
[23:54:47.082] iteration 21493 : model1 loss : 0.265831 model2 loss : 0.296453
[23:54:47.410] iteration 21494 : model1 loss : 0.183689 model2 loss : 0.308878
[23:54:47.739] iteration 21495 : model1 loss : 0.134091 model2 loss : 0.189771
[23:54:48.070] iteration 21496 : model1 loss : 0.172717 model2 loss : 0.185188
[23:54:48.400] iteration 21497 : model1 loss : 0.174986 model2 loss : 0.205465
[23:54:48.729] iteration 21498 : model1 loss : 0.238673 model2 loss : 0.274973
[23:54:49.058] iteration 21499 : model1 loss : 0.287995 model2 loss : 0.302267
[23:54:49.388] iteration 21500 : model1 loss : 0.172669 model2 loss : 0.204830
[23:54:49.962] iteration 21501 : model1 loss : 0.160923 model2 loss : 0.198530
[23:54:50.300] iteration 21502 : model1 loss : 0.255807 model2 loss : 0.300143
[23:54:50.641] iteration 21503 : model1 loss : 0.236499 model2 loss : 0.282866
[23:54:50.983] iteration 21504 : model1 loss : 0.181228 model2 loss : 0.237718
[23:54:51.320] iteration 21505 : model1 loss : 0.194521 model2 loss : 0.257746
[23:54:51.659] iteration 21506 : model1 loss : 0.238826 model2 loss : 0.264563
[23:54:51.999] iteration 21507 : model1 loss : 0.153972 model2 loss : 0.176016
[23:54:52.340] iteration 21508 : model1 loss : 0.151708 model2 loss : 0.277593
[23:54:52.678] iteration 21509 : model1 loss : 0.089491 model2 loss : 0.131398
[23:54:53.024] iteration 21510 : model1 loss : 0.073697 model2 loss : 0.113486
[23:54:53.365] iteration 21511 : model1 loss : 0.245228 model2 loss : 0.254914
[23:54:53.703] iteration 21512 : model1 loss : 0.142474 model2 loss : 0.192519
[23:54:54.039] iteration 21513 : model1 loss : 0.081755 model2 loss : 0.101978
[23:54:54.378] iteration 21514 : model1 loss : 0.253972 model2 loss : 0.278545
[23:54:54.715] iteration 21515 : model1 loss : 0.274843 model2 loss : 0.298901
[23:54:55.051] iteration 21516 : model1 loss : 0.282340 model2 loss : 0.319280
[23:54:55.393] iteration 21517 : model1 loss : 0.141098 model2 loss : 0.207145
[23:54:55.730] iteration 21518 : model1 loss : 0.176493 model2 loss : 0.214398
[23:54:56.065] iteration 21519 : model1 loss : 0.212164 model2 loss : 0.301147
[23:54:56.403] iteration 21520 : model1 loss : 0.208960 model2 loss : 0.271009
[23:54:56.741] iteration 21521 : model1 loss : 0.196849 model2 loss : 0.219239
[23:54:57.075] iteration 21522 : model1 loss : 0.130153 model2 loss : 0.137257
[23:54:57.414] iteration 21523 : model1 loss : 0.092408 model2 loss : 0.107073
[23:54:57.753] iteration 21524 : model1 loss : 0.264180 model2 loss : 0.298447
[23:54:58.090] iteration 21525 : model1 loss : 0.229890 model2 loss : 0.248746
[23:54:58.429] iteration 21526 : model1 loss : 0.172455 model2 loss : 0.204436
[23:54:58.766] iteration 21527 : model1 loss : 0.252096 model2 loss : 0.323225
[23:54:59.100] iteration 21528 : model1 loss : 0.192430 model2 loss : 0.200785
[23:54:59.436] iteration 21529 : model1 loss : 0.320132 model2 loss : 0.286284
[23:54:59.773] iteration 21530 : model1 loss : 0.153067 model2 loss : 0.196174
[23:55:00.110] iteration 21531 : model1 loss : 0.222932 model2 loss : 0.201163
[23:55:00.448] iteration 21532 : model1 loss : 0.230587 model2 loss : 0.285504
[23:55:00.788] iteration 21533 : model1 loss : 0.198850 model2 loss : 0.264183
[23:55:01.129] iteration 21534 : model1 loss : 0.137143 model2 loss : 0.220462
[23:55:01.470] iteration 21535 : model1 loss : 0.177468 model2 loss : 0.201735
[23:55:01.812] iteration 21536 : model1 loss : 0.171591 model2 loss : 0.201273
[23:55:02.152] iteration 21537 : model1 loss : 0.076342 model2 loss : 0.157482
[23:55:02.491] iteration 21538 : model1 loss : 0.179083 model2 loss : 0.190542
[23:55:02.828] iteration 21539 : model1 loss : 0.174085 model2 loss : 0.218603
[23:55:03.165] iteration 21540 : model1 loss : 0.258468 model2 loss : 0.308836
[23:55:03.508] iteration 21541 : model1 loss : 0.220159 model2 loss : 0.340383
[23:55:03.845] iteration 21542 : model1 loss : 0.285853 model2 loss : 0.280747
[23:55:04.183] iteration 21543 : model1 loss : 0.194168 model2 loss : 0.222002
[23:55:04.521] iteration 21544 : model1 loss : 0.280920 model2 loss : 0.260948
[23:55:04.867] iteration 21545 : model1 loss : 0.199884 model2 loss : 0.202846
[23:55:05.203] iteration 21546 : model1 loss : 0.281590 model2 loss : 0.355916
[23:55:05.542] iteration 21547 : model1 loss : 0.187365 model2 loss : 0.257040
[23:55:05.879] iteration 21548 : model1 loss : 0.152943 model2 loss : 0.205533
[23:55:06.217] iteration 21549 : model1 loss : 0.270888 model2 loss : 0.353811
[23:55:06.559] iteration 21550 : model1 loss : 0.125305 model2 loss : 0.149068
[23:55:07.204] iteration 21551 : model1 loss : 0.177447 model2 loss : 0.220551
[23:55:07.541] iteration 21552 : model1 loss : 0.127496 model2 loss : 0.127049
[23:55:07.879] iteration 21553 : model1 loss : 0.281858 model2 loss : 0.290309
[23:55:08.216] iteration 21554 : model1 loss : 0.223812 model2 loss : 0.266400
[23:55:08.555] iteration 21555 : model1 loss : 0.082555 model2 loss : 0.146009
[23:55:08.896] iteration 21556 : model1 loss : 0.164353 model2 loss : 0.212966
[23:55:09.233] iteration 21557 : model1 loss : 0.124643 model2 loss : 0.176880
[23:55:09.571] iteration 21558 : model1 loss : 0.306439 model2 loss : 0.406486
[23:55:09.908] iteration 21559 : model1 loss : 0.252038 model2 loss : 0.261209
[23:55:10.249] iteration 21560 : model1 loss : 0.257341 model2 loss : 0.192528
[23:55:10.587] iteration 21561 : model1 loss : 0.276935 model2 loss : 0.276131
[23:55:10.924] iteration 21562 : model1 loss : 0.162354 model2 loss : 0.182033
[23:55:11.261] iteration 21563 : model1 loss : 0.095098 model2 loss : 0.104017
[23:55:11.599] iteration 21564 : model1 loss : 0.253424 model2 loss : 0.304005
[23:55:11.940] iteration 21565 : model1 loss : 0.106748 model2 loss : 0.139406
[23:55:12.279] iteration 21566 : model1 loss : 0.166573 model2 loss : 0.184342
[23:55:12.618] iteration 21567 : model1 loss : 0.142430 model2 loss : 0.150976
[23:55:12.956] iteration 21568 : model1 loss : 0.203787 model2 loss : 0.227529
[23:55:13.293] iteration 21569 : model1 loss : 0.197177 model2 loss : 0.186947
[23:55:13.630] iteration 21570 : model1 loss : 0.183391 model2 loss : 0.240523
[23:55:13.970] iteration 21571 : model1 loss : 0.152433 model2 loss : 0.187775
[23:55:14.306] iteration 21572 : model1 loss : 0.077309 model2 loss : 0.083175
[23:55:14.644] iteration 21573 : model1 loss : 0.185750 model2 loss : 0.233247
[23:55:14.987] iteration 21574 : model1 loss : 0.096825 model2 loss : 0.156722
[23:55:15.329] iteration 21575 : model1 loss : 0.253713 model2 loss : 0.288317
[23:55:15.667] iteration 21576 : model1 loss : 0.172044 model2 loss : 0.187560
[23:55:16.004] iteration 21577 : model1 loss : 0.176657 model2 loss : 0.215700
[23:55:16.341] iteration 21578 : model1 loss : 0.134624 model2 loss : 0.184400
[23:55:16.679] iteration 21579 : model1 loss : 0.256998 model2 loss : 0.240852
[23:55:17.015] iteration 21580 : model1 loss : 0.244610 model2 loss : 0.234555
[23:55:17.356] iteration 21581 : model1 loss : 0.190324 model2 loss : 0.271852
[23:55:17.693] iteration 21582 : model1 loss : 0.101553 model2 loss : 0.082397
[23:55:18.031] iteration 21583 : model1 loss : 0.161507 model2 loss : 0.218494
[23:55:18.368] iteration 21584 : model1 loss : 0.253345 model2 loss : 0.313065
[23:55:18.705] iteration 21585 : model1 loss : 0.095993 model2 loss : 0.162791
[23:55:19.046] iteration 21586 : model1 loss : 0.131869 model2 loss : 0.179945
[23:55:19.382] iteration 21587 : model1 loss : 0.239007 model2 loss : 0.219152
[23:55:19.719] iteration 21588 : model1 loss : 0.251147 model2 loss : 0.298444
[23:55:20.060] iteration 21589 : model1 loss : 0.203031 model2 loss : 0.224635
[23:55:20.402] iteration 21590 : model1 loss : 0.127905 model2 loss : 0.240938
[23:55:20.738] iteration 21591 : model1 loss : 0.177607 model2 loss : 0.196872
[23:55:21.075] iteration 21592 : model1 loss : 0.116979 model2 loss : 0.201056
[23:55:21.412] iteration 21593 : model1 loss : 0.218537 model2 loss : 0.334078
[23:55:21.757] iteration 21594 : model1 loss : 0.246893 model2 loss : 0.251188
[23:55:22.097] iteration 21595 : model1 loss : 0.227890 model2 loss : 0.247810
[23:55:22.435] iteration 21596 : model1 loss : 0.090102 model2 loss : 0.106437
[23:55:22.771] iteration 21597 : model1 loss : 0.166609 model2 loss : 0.188407
[23:55:23.111] iteration 21598 : model1 loss : 0.155501 model2 loss : 0.171536
[23:55:23.447] iteration 21599 : model1 loss : 0.159204 model2 loss : 0.158748
[23:55:23.788] iteration 21600 : model1 loss : 0.268317 model2 loss : 0.269984
[23:55:24.446] iteration 21601 : model1 loss : 0.072916 model2 loss : 0.136996
[23:55:24.783] iteration 21602 : model1 loss : 0.242013 model2 loss : 0.273951
[23:55:25.122] iteration 21603 : model1 loss : 0.162662 model2 loss : 0.202763
[23:55:25.463] iteration 21604 : model1 loss : 0.173320 model2 loss : 0.197903
[23:55:25.800] iteration 21605 : model1 loss : 0.189825 model2 loss : 0.237194
[23:55:26.137] iteration 21606 : model1 loss : 0.089923 model2 loss : 0.145904
[23:55:26.473] iteration 21607 : model1 loss : 0.079033 model2 loss : 0.142313
[23:55:26.810] iteration 21608 : model1 loss : 0.201537 model2 loss : 0.276452
[23:55:27.147] iteration 21609 : model1 loss : 0.173616 model2 loss : 0.183727
[23:55:27.487] iteration 21610 : model1 loss : 0.147423 model2 loss : 0.172230
[23:55:27.828] iteration 21611 : model1 loss : 0.329060 model2 loss : 0.392740
[23:55:28.164] iteration 21612 : model1 loss : 0.162209 model2 loss : 0.179379
[23:55:28.501] iteration 21613 : model1 loss : 0.241614 model2 loss : 0.322795
[23:55:28.843] iteration 21614 : model1 loss : 0.236531 model2 loss : 0.257868
[23:55:29.180] iteration 21615 : model1 loss : 0.247926 model2 loss : 0.269803
[23:55:29.518] iteration 21616 : model1 loss : 0.158030 model2 loss : 0.249071
[23:55:29.854] iteration 21617 : model1 loss : 0.210955 model2 loss : 0.231321
[23:55:30.191] iteration 21618 : model1 loss : 0.175110 model2 loss : 0.205162
[23:55:30.528] iteration 21619 : model1 loss : 0.153394 model2 loss : 0.170233
[23:55:30.866] iteration 21620 : model1 loss : 0.099539 model2 loss : 0.132344
[23:55:31.202] iteration 21621 : model1 loss : 0.101498 model2 loss : 0.139776
[23:55:31.542] iteration 21622 : model1 loss : 0.100945 model2 loss : 0.154558
[23:55:31.879] iteration 21623 : model1 loss : 0.272484 model2 loss : 0.340570
[23:55:32.215] iteration 21624 : model1 loss : 0.084315 model2 loss : 0.210107
[23:55:32.552] iteration 21625 : model1 loss : 0.235673 model2 loss : 0.238564
[23:55:32.889] iteration 21626 : model1 loss : 0.203995 model2 loss : 0.149439
[23:55:33.225] iteration 21627 : model1 loss : 0.088853 model2 loss : 0.137945
[23:55:33.562] iteration 21628 : model1 loss : 0.172497 model2 loss : 0.204891
[23:55:33.903] iteration 21629 : model1 loss : 0.170601 model2 loss : 0.184873
[23:55:34.242] iteration 21630 : model1 loss : 0.149784 model2 loss : 0.202638
[23:55:34.579] iteration 21631 : model1 loss : 0.264391 model2 loss : 0.284263
[23:55:34.916] iteration 21632 : model1 loss : 0.220729 model2 loss : 0.233173
[23:55:35.254] iteration 21633 : model1 loss : 0.242808 model2 loss : 0.250669
[23:55:35.596] iteration 21634 : model1 loss : 0.168331 model2 loss : 0.196212
[23:55:35.933] iteration 21635 : model1 loss : 0.179455 model2 loss : 0.236872
[23:55:36.271] iteration 21636 : model1 loss : 0.170963 model2 loss : 0.171899
[23:55:36.609] iteration 21637 : model1 loss : 0.238469 model2 loss : 0.280085
[23:55:36.954] iteration 21638 : model1 loss : 0.190274 model2 loss : 0.187219
[23:55:37.291] iteration 21639 : model1 loss : 0.214919 model2 loss : 0.299343
[23:55:37.628] iteration 21640 : model1 loss : 0.223021 model2 loss : 0.247639
[23:55:37.966] iteration 21641 : model1 loss : 0.211301 model2 loss : 0.258765
[23:55:38.306] iteration 21642 : model1 loss : 0.167720 model2 loss : 0.167459
[23:55:38.643] iteration 21643 : model1 loss : 0.151107 model2 loss : 0.162582
[23:55:38.981] iteration 21644 : model1 loss : 0.117437 model2 loss : 0.125516
[23:55:39.321] iteration 21645 : model1 loss : 0.232861 model2 loss : 0.300328
[23:55:39.668] iteration 21646 : model1 loss : 0.188002 model2 loss : 0.216847
[23:55:40.004] iteration 21647 : model1 loss : 0.179818 model2 loss : 0.180485
[23:55:40.344] iteration 21648 : model1 loss : 0.200384 model2 loss : 0.252224
[23:55:40.683] iteration 21649 : model1 loss : 0.168998 model2 loss : 0.175929
[23:55:41.019] iteration 21650 : model1 loss : 0.274787 model2 loss : 0.224832
[23:55:41.659] iteration 21651 : model1 loss : 0.205839 model2 loss : 0.234641
[23:55:41.996] iteration 21652 : model1 loss : 0.193456 model2 loss : 0.248061
[23:55:42.332] iteration 21653 : model1 loss : 0.074357 model2 loss : 0.120910
[23:55:42.672] iteration 21654 : model1 loss : 0.178374 model2 loss : 0.296692
[23:55:43.011] iteration 21655 : model1 loss : 0.234580 model2 loss : 0.272807
[23:55:43.348] iteration 21656 : model1 loss : 0.178545 model2 loss : 0.215245
[23:55:43.688] iteration 21657 : model1 loss : 0.167955 model2 loss : 0.186367
[23:55:44.024] iteration 21658 : model1 loss : 0.192324 model2 loss : 0.228397
[23:55:44.362] iteration 21659 : model1 loss : 0.191279 model2 loss : 0.217152
[23:55:44.701] iteration 21660 : model1 loss : 0.096840 model2 loss : 0.174474
[23:55:45.037] iteration 21661 : model1 loss : 0.287459 model2 loss : 0.321997
[23:55:45.374] iteration 21662 : model1 loss : 0.245592 model2 loss : 0.267615
[23:55:45.710] iteration 21663 : model1 loss : 0.076534 model2 loss : 0.108488
[23:55:46.046] iteration 21664 : model1 loss : 0.258531 model2 loss : 0.276687
[23:55:46.384] iteration 21665 : model1 loss : 0.141669 model2 loss : 0.193704
[23:55:46.721] iteration 21666 : model1 loss : 0.173123 model2 loss : 0.175720
[23:55:47.058] iteration 21667 : model1 loss : 0.174311 model2 loss : 0.188204
[23:55:47.396] iteration 21668 : model1 loss : 0.230284 model2 loss : 0.258792
[23:55:47.737] iteration 21669 : model1 loss : 0.172747 model2 loss : 0.214698
[23:55:48.073] iteration 21670 : model1 loss : 0.278692 model2 loss : 0.277111
[23:55:48.413] iteration 21671 : model1 loss : 0.180265 model2 loss : 0.218537
[23:55:48.750] iteration 21672 : model1 loss : 0.157425 model2 loss : 0.154465
[23:55:49.090] iteration 21673 : model1 loss : 0.189605 model2 loss : 0.192253
[23:55:49.431] iteration 21674 : model1 loss : 0.216284 model2 loss : 0.263842
[23:55:49.768] iteration 21675 : model1 loss : 0.232081 model2 loss : 0.246583
[23:55:50.107] iteration 21676 : model1 loss : 0.183336 model2 loss : 0.272973
[23:55:50.444] iteration 21677 : model1 loss : 0.186642 model2 loss : 0.196709
[23:55:50.780] iteration 21678 : model1 loss : 0.260898 model2 loss : 0.265176
[23:55:51.119] iteration 21679 : model1 loss : 0.301243 model2 loss : 0.289027
[23:55:51.456] iteration 21680 : model1 loss : 0.185986 model2 loss : 0.206268
[23:55:51.794] iteration 21681 : model1 loss : 0.179794 model2 loss : 0.180962
[23:55:52.132] iteration 21682 : model1 loss : 0.075865 model2 loss : 0.088618
[23:55:52.468] iteration 21683 : model1 loss : 0.294237 model2 loss : 0.326471
[23:55:52.805] iteration 21684 : model1 loss : 0.290480 model2 loss : 0.283439
[23:55:53.143] iteration 21685 : model1 loss : 0.144072 model2 loss : 0.195469
[23:55:53.480] iteration 21686 : model1 loss : 0.314626 model2 loss : 0.330858
[23:55:53.816] iteration 21687 : model1 loss : 0.096758 model2 loss : 0.110603
[23:55:54.154] iteration 21688 : model1 loss : 0.104265 model2 loss : 0.189333
[23:55:54.491] iteration 21689 : model1 loss : 0.205254 model2 loss : 0.237593
[23:55:54.828] iteration 21690 : model1 loss : 0.260104 model2 loss : 0.279617
[23:55:55.166] iteration 21691 : model1 loss : 0.101735 model2 loss : 0.205976
[23:55:55.504] iteration 21692 : model1 loss : 0.241505 model2 loss : 0.282198
[23:55:55.843] iteration 21693 : model1 loss : 0.156955 model2 loss : 0.178181
[23:55:56.180] iteration 21694 : model1 loss : 0.149622 model2 loss : 0.183427
[23:55:56.517] iteration 21695 : model1 loss : 0.177991 model2 loss : 0.182339
[23:55:56.855] iteration 21696 : model1 loss : 0.169765 model2 loss : 0.176528
[23:55:57.195] iteration 21697 : model1 loss : 0.165096 model2 loss : 0.198343
[23:55:57.533] iteration 21698 : model1 loss : 0.248742 model2 loss : 0.262983
[23:55:57.870] iteration 21699 : model1 loss : 0.161723 model2 loss : 0.214669
[23:55:58.206] iteration 21700 : model1 loss : 0.193290 model2 loss : 0.216128
[23:55:58.866] iteration 21701 : model1 loss : 0.105648 model2 loss : 0.157744
[23:55:59.208] iteration 21702 : model1 loss : 0.254091 model2 loss : 0.272063
[23:55:59.546] iteration 21703 : model1 loss : 0.167049 model2 loss : 0.238116
[23:55:59.884] iteration 21704 : model1 loss : 0.269111 model2 loss : 0.308978
[23:56:00.221] iteration 21705 : model1 loss : 0.164191 model2 loss : 0.239976
[23:56:00.560] iteration 21706 : model1 loss : 0.122360 model2 loss : 0.243532
[23:56:00.898] iteration 21707 : model1 loss : 0.130079 model2 loss : 0.139859
[23:56:01.238] iteration 21708 : model1 loss : 0.077463 model2 loss : 0.122144
[23:56:01.574] iteration 21709 : model1 loss : 0.252343 model2 loss : 0.290630
[23:56:01.911] iteration 21710 : model1 loss : 0.243430 model2 loss : 0.279362
[23:56:02.248] iteration 21711 : model1 loss : 0.082353 model2 loss : 0.154884
[23:56:02.586] iteration 21712 : model1 loss : 0.231927 model2 loss : 0.267376
[23:56:02.923] iteration 21713 : model1 loss : 0.236196 model2 loss : 0.244108
[23:56:03.259] iteration 21714 : model1 loss : 0.253229 model2 loss : 0.270089
[23:56:03.595] iteration 21715 : model1 loss : 0.141831 model2 loss : 0.215891
[23:56:03.934] iteration 21716 : model1 loss : 0.303234 model2 loss : 0.404595
[23:56:04.270] iteration 21717 : model1 loss : 0.248443 model2 loss : 0.253297
[23:56:04.608] iteration 21718 : model1 loss : 0.190462 model2 loss : 0.206965
[23:56:04.945] iteration 21719 : model1 loss : 0.255022 model2 loss : 0.297627
[23:56:05.286] iteration 21720 : model1 loss : 0.278732 model2 loss : 0.270283
[23:56:05.622] iteration 21721 : model1 loss : 0.250993 model2 loss : 0.257002
[23:56:05.964] iteration 21722 : model1 loss : 0.106729 model2 loss : 0.151812
[23:56:06.301] iteration 21723 : model1 loss : 0.225775 model2 loss : 0.266574
[23:56:06.639] iteration 21724 : model1 loss : 0.261182 model2 loss : 0.274211
[23:56:06.979] iteration 21725 : model1 loss : 0.186678 model2 loss : 0.278710
[23:56:07.317] iteration 21726 : model1 loss : 0.167300 model2 loss : 0.194090
[23:56:07.655] iteration 21727 : model1 loss : 0.124486 model2 loss : 0.140496
[23:56:07.995] iteration 21728 : model1 loss : 0.173802 model2 loss : 0.204644
[23:56:08.336] iteration 21729 : model1 loss : 0.256624 model2 loss : 0.299789
[23:56:08.675] iteration 21730 : model1 loss : 0.156998 model2 loss : 0.211998
[23:56:09.012] iteration 21731 : model1 loss : 0.193811 model2 loss : 0.242266
[23:56:09.350] iteration 21732 : model1 loss : 0.106353 model2 loss : 0.094627
[23:56:09.688] iteration 21733 : model1 loss : 0.127118 model2 loss : 0.165446
[23:56:10.026] iteration 21734 : model1 loss : 0.279251 model2 loss : 0.304126
[23:56:10.364] iteration 21735 : model1 loss : 0.088306 model2 loss : 0.155447
[23:56:10.701] iteration 21736 : model1 loss : 0.093164 model2 loss : 0.164407
[23:56:11.038] iteration 21737 : model1 loss : 0.171280 model2 loss : 0.204728
[23:56:11.375] iteration 21738 : model1 loss : 0.259293 model2 loss : 0.271730
[23:56:11.711] iteration 21739 : model1 loss : 0.173837 model2 loss : 0.176483
[23:56:12.047] iteration 21740 : model1 loss : 0.250625 model2 loss : 0.256819
[23:56:12.384] iteration 21741 : model1 loss : 0.101080 model2 loss : 0.143300
[23:56:12.727] iteration 21742 : model1 loss : 0.194920 model2 loss : 0.243366
[23:56:13.064] iteration 21743 : model1 loss : 0.184385 model2 loss : 0.199910
[23:56:13.401] iteration 21744 : model1 loss : 0.321269 model2 loss : 0.339097
[23:56:13.740] iteration 21745 : model1 loss : 0.176153 model2 loss : 0.209742
[23:56:14.077] iteration 21746 : model1 loss : 0.173799 model2 loss : 0.186608
[23:56:14.415] iteration 21747 : model1 loss : 0.166827 model2 loss : 0.209614
[23:56:14.754] iteration 21748 : model1 loss : 0.164333 model2 loss : 0.173505
[23:56:15.098] iteration 21749 : model1 loss : 0.170737 model2 loss : 0.198174
[23:56:15.442] iteration 21750 : model1 loss : 0.103437 model2 loss : 0.153612
[23:56:16.101] iteration 21751 : model1 loss : 0.211021 model2 loss : 0.256595
[23:56:16.439] iteration 21752 : model1 loss : 0.208266 model2 loss : 0.219869
[23:56:16.776] iteration 21753 : model1 loss : 0.169349 model2 loss : 0.261024
[23:56:17.114] iteration 21754 : model1 loss : 0.187695 model2 loss : 0.197922
[23:56:17.450] iteration 21755 : model1 loss : 0.162745 model2 loss : 0.192406
[23:56:17.786] iteration 21756 : model1 loss : 0.182498 model2 loss : 0.204214
[23:56:18.127] iteration 21757 : model1 loss : 0.165389 model2 loss : 0.190658
[23:56:18.464] iteration 21758 : model1 loss : 0.151245 model2 loss : 0.182858
[23:56:18.804] iteration 21759 : model1 loss : 0.100193 model2 loss : 0.117148
[23:56:19.142] iteration 21760 : model1 loss : 0.235384 model2 loss : 0.276125
[23:56:19.483] iteration 21761 : model1 loss : 0.274547 model2 loss : 0.291174
[23:56:19.820] iteration 21762 : model1 loss : 0.258842 model2 loss : 0.294786
[23:56:20.158] iteration 21763 : model1 loss : 0.098355 model2 loss : 0.143851
[23:56:20.497] iteration 21764 : model1 loss : 0.181229 model2 loss : 0.184995
[23:56:20.835] iteration 21765 : model1 loss : 0.178952 model2 loss : 0.218883
[23:56:21.176] iteration 21766 : model1 loss : 0.108842 model2 loss : 0.139517
[23:56:21.513] iteration 21767 : model1 loss : 0.178836 model2 loss : 0.207022
[23:56:21.854] iteration 21768 : model1 loss : 0.268786 model2 loss : 0.300768
[23:56:22.196] iteration 21769 : model1 loss : 0.077637 model2 loss : 0.174193
[23:56:22.536] iteration 21770 : model1 loss : 0.253505 model2 loss : 0.323430
[23:56:22.874] iteration 21771 : model1 loss : 0.220562 model2 loss : 0.202478
[23:56:23.211] iteration 21772 : model1 loss : 0.105815 model2 loss : 0.165592
[23:56:23.548] iteration 21773 : model1 loss : 0.071563 model2 loss : 0.146152
[23:56:23.891] iteration 21774 : model1 loss : 0.185956 model2 loss : 0.309968
[23:56:24.228] iteration 21775 : model1 loss : 0.266690 model2 loss : 0.303706
[23:56:24.566] iteration 21776 : model1 loss : 0.266571 model2 loss : 0.299467
[23:56:24.905] iteration 21777 : model1 loss : 0.206474 model2 loss : 0.237795
[23:56:25.246] iteration 21778 : model1 loss : 0.094906 model2 loss : 0.118538
[23:56:25.583] iteration 21779 : model1 loss : 0.242538 model2 loss : 0.247050
[23:56:25.920] iteration 21780 : model1 loss : 0.268788 model2 loss : 0.320925
[23:56:26.257] iteration 21781 : model1 loss : 0.149135 model2 loss : 0.160904
[23:56:26.594] iteration 21782 : model1 loss : 0.275598 model2 loss : 0.429700
[23:56:26.931] iteration 21783 : model1 loss : 0.231829 model2 loss : 0.312324
[23:56:27.266] iteration 21784 : model1 loss : 0.173385 model2 loss : 0.183056
[23:56:27.603] iteration 21785 : model1 loss : 0.235030 model2 loss : 0.262371
[23:56:27.943] iteration 21786 : model1 loss : 0.199453 model2 loss : 0.215717
[23:56:28.279] iteration 21787 : model1 loss : 0.248436 model2 loss : 0.309877
[23:56:28.617] iteration 21788 : model1 loss : 0.093229 model2 loss : 0.130009
[23:56:28.954] iteration 21789 : model1 loss : 0.159158 model2 loss : 0.188061
[23:56:29.294] iteration 21790 : model1 loss : 0.323821 model2 loss : 0.323326
[23:56:29.631] iteration 21791 : model1 loss : 0.285353 model2 loss : 0.312299
[23:56:29.971] iteration 21792 : model1 loss : 0.157739 model2 loss : 0.181187
[23:56:30.309] iteration 21793 : model1 loss : 0.283809 model2 loss : 0.305943
[23:56:30.644] iteration 21794 : model1 loss : 0.139437 model2 loss : 0.157890
[23:56:30.981] iteration 21795 : model1 loss : 0.164265 model2 loss : 0.196343
[23:56:31.319] iteration 21796 : model1 loss : 0.089921 model2 loss : 0.162574
[23:56:31.654] iteration 21797 : model1 loss : 0.260844 model2 loss : 0.322818
[23:56:31.990] iteration 21798 : model1 loss : 0.201927 model2 loss : 0.246615
[23:56:32.324] iteration 21799 : model1 loss : 0.146322 model2 loss : 0.154262
[23:56:32.660] iteration 21800 : model1 loss : 0.177812 model2 loss : 0.213162
[23:56:34.083] iteration 21801 : model1 loss : 0.077598 model2 loss : 0.137954
[23:56:34.420] iteration 21802 : model1 loss : 0.254703 model2 loss : 0.270734
[23:56:34.756] iteration 21803 : model1 loss : 0.097729 model2 loss : 0.118665
[23:56:35.094] iteration 21804 : model1 loss : 0.175341 model2 loss : 0.185605
[23:56:35.430] iteration 21805 : model1 loss : 0.205670 model2 loss : 0.248696
[23:56:35.768] iteration 21806 : model1 loss : 0.088417 model2 loss : 0.188323
[23:56:36.109] iteration 21807 : model1 loss : 0.176182 model2 loss : 0.208923
[23:56:36.446] iteration 21808 : model1 loss : 0.165411 model2 loss : 0.217713
[23:56:36.786] iteration 21809 : model1 loss : 0.100157 model2 loss : 0.159265
[23:56:37.123] iteration 21810 : model1 loss : 0.165193 model2 loss : 0.179523
[23:56:37.459] iteration 21811 : model1 loss : 0.240584 model2 loss : 0.238155
[23:56:37.796] iteration 21812 : model1 loss : 0.154033 model2 loss : 0.224876
[23:56:38.134] iteration 21813 : model1 loss : 0.193153 model2 loss : 0.220310
[23:56:38.475] iteration 21814 : model1 loss : 0.084831 model2 loss : 0.142547
[23:56:38.813] iteration 21815 : model1 loss : 0.143250 model2 loss : 0.192954
[23:56:39.150] iteration 21816 : model1 loss : 0.152422 model2 loss : 0.222190
[23:56:39.493] iteration 21817 : model1 loss : 0.255407 model2 loss : 0.290619
[23:56:39.838] iteration 21818 : model1 loss : 0.183296 model2 loss : 0.224427
[23:56:40.174] iteration 21819 : model1 loss : 0.220678 model2 loss : 0.243089
[23:56:40.518] iteration 21820 : model1 loss : 0.078072 model2 loss : 0.083693
[23:56:40.854] iteration 21821 : model1 loss : 0.328278 model2 loss : 0.369114
[23:56:41.195] iteration 21822 : model1 loss : 0.178323 model2 loss : 0.188027
[23:56:41.531] iteration 21823 : model1 loss : 0.268573 model2 loss : 0.307026
[23:56:41.868] iteration 21824 : model1 loss : 0.203687 model2 loss : 0.338453
[23:56:42.203] iteration 21825 : model1 loss : 0.261867 model2 loss : 0.329247
[23:56:42.544] iteration 21826 : model1 loss : 0.197655 model2 loss : 0.223540
[23:56:42.881] iteration 21827 : model1 loss : 0.189058 model2 loss : 0.238925
[23:56:43.219] iteration 21828 : model1 loss : 0.129183 model2 loss : 0.219172
[23:56:43.555] iteration 21829 : model1 loss : 0.215608 model2 loss : 0.217674
[23:56:43.894] iteration 21830 : model1 loss : 0.265873 model2 loss : 0.302610
[23:56:44.231] iteration 21831 : model1 loss : 0.147160 model2 loss : 0.158764
[23:56:44.571] iteration 21832 : model1 loss : 0.266802 model2 loss : 0.278483
[23:56:44.908] iteration 21833 : model1 loss : 0.169825 model2 loss : 0.190520
[23:56:45.245] iteration 21834 : model1 loss : 0.189034 model2 loss : 0.212417
[23:56:45.583] iteration 21835 : model1 loss : 0.269001 model2 loss : 0.279605
[23:56:45.919] iteration 21836 : model1 loss : 0.344121 model2 loss : 0.355151
[23:56:46.260] iteration 21837 : model1 loss : 0.183325 model2 loss : 0.283892
[23:56:46.598] iteration 21838 : model1 loss : 0.172817 model2 loss : 0.197538
[23:56:46.939] iteration 21839 : model1 loss : 0.180969 model2 loss : 0.244274
[23:56:47.277] iteration 21840 : model1 loss : 0.201558 model2 loss : 0.224007
[23:56:47.619] iteration 21841 : model1 loss : 0.169829 model2 loss : 0.214085
[23:56:47.959] iteration 21842 : model1 loss : 0.112319 model2 loss : 0.153369
[23:56:48.304] iteration 21843 : model1 loss : 0.165108 model2 loss : 0.202099
[23:56:48.644] iteration 21844 : model1 loss : 0.193483 model2 loss : 0.249796
[23:56:48.980] iteration 21845 : model1 loss : 0.179154 model2 loss : 0.216223
[23:56:49.320] iteration 21846 : model1 loss : 0.258074 model2 loss : 0.262426
[23:56:49.660] iteration 21847 : model1 loss : 0.325338 model2 loss : 0.339351
[23:56:49.998] iteration 21848 : model1 loss : 0.159257 model2 loss : 0.197885
[23:56:50.335] iteration 21849 : model1 loss : 0.162664 model2 loss : 0.182490
[23:56:50.675] iteration 21850 : model1 loss : 0.189040 model2 loss : 0.238614
[23:56:51.340] iteration 21851 : model1 loss : 0.268303 model2 loss : 0.297177
[23:56:51.679] iteration 21852 : model1 loss : 0.172270 model2 loss : 0.179215
[23:56:52.018] iteration 21853 : model1 loss : 0.354945 model2 loss : 0.359258
[23:56:52.356] iteration 21854 : model1 loss : 0.090941 model2 loss : 0.140981
[23:56:52.694] iteration 21855 : model1 loss : 0.209197 model2 loss : 0.201322
[23:56:53.031] iteration 21856 : model1 loss : 0.179157 model2 loss : 0.233060
[23:56:53.375] iteration 21857 : model1 loss : 0.165164 model2 loss : 0.193389
[23:56:53.712] iteration 21858 : model1 loss : 0.125363 model2 loss : 0.187101
[23:56:54.049] iteration 21859 : model1 loss : 0.086820 model2 loss : 0.098852
[23:56:54.387] iteration 21860 : model1 loss : 0.200250 model2 loss : 0.190169
[23:56:54.726] iteration 21861 : model1 loss : 0.235759 model2 loss : 0.269980
[23:56:55.066] iteration 21862 : model1 loss : 0.165583 model2 loss : 0.176686
[23:56:55.410] iteration 21863 : model1 loss : 0.140505 model2 loss : 0.175389
[23:56:55.746] iteration 21864 : model1 loss : 0.203430 model2 loss : 0.206787
[23:56:56.083] iteration 21865 : model1 loss : 0.193918 model2 loss : 0.195632
[23:56:56.421] iteration 21866 : model1 loss : 0.171548 model2 loss : 0.232746
[23:56:56.759] iteration 21867 : model1 loss : 0.173585 model2 loss : 0.224423
[23:56:57.101] iteration 21868 : model1 loss : 0.183166 model2 loss : 0.266775
[23:56:57.438] iteration 21869 : model1 loss : 0.093063 model2 loss : 0.128293
[23:56:57.775] iteration 21870 : model1 loss : 0.193321 model2 loss : 0.236560
[23:56:58.111] iteration 21871 : model1 loss : 0.080919 model2 loss : 0.087010
[23:56:58.450] iteration 21872 : model1 loss : 0.251453 model2 loss : 0.264762
[23:56:58.786] iteration 21873 : model1 loss : 0.261318 model2 loss : 0.283598
[23:56:59.125] iteration 21874 : model1 loss : 0.266853 model2 loss : 0.321031
[23:56:59.462] iteration 21875 : model1 loss : 0.205177 model2 loss : 0.211531
[23:56:59.804] iteration 21876 : model1 loss : 0.200489 model2 loss : 0.212931
[23:57:00.142] iteration 21877 : model1 loss : 0.232688 model2 loss : 0.254035
[23:57:00.478] iteration 21878 : model1 loss : 0.172612 model2 loss : 0.193189
[23:57:00.818] iteration 21879 : model1 loss : 0.218517 model2 loss : 0.208709
[23:57:01.157] iteration 21880 : model1 loss : 0.081336 model2 loss : 0.141944
[23:57:01.494] iteration 21881 : model1 loss : 0.121688 model2 loss : 0.158006
[23:57:01.839] iteration 21882 : model1 loss : 0.251969 model2 loss : 0.300609
[23:57:02.178] iteration 21883 : model1 loss : 0.225015 model2 loss : 0.232694
[23:57:02.515] iteration 21884 : model1 loss : 0.231347 model2 loss : 0.253775
[23:57:02.855] iteration 21885 : model1 loss : 0.177303 model2 loss : 0.213337
[23:57:03.192] iteration 21886 : model1 loss : 0.107146 model2 loss : 0.199916
[23:57:03.530] iteration 21887 : model1 loss : 0.149726 model2 loss : 0.208045
[23:57:03.869] iteration 21888 : model1 loss : 0.132540 model2 loss : 0.185779
[23:57:04.208] iteration 21889 : model1 loss : 0.256198 model2 loss : 0.257215
[23:57:04.562] iteration 21890 : model1 loss : 0.275336 model2 loss : 0.315396
[23:57:04.899] iteration 21891 : model1 loss : 0.292483 model2 loss : 0.293908
[23:57:05.235] iteration 21892 : model1 loss : 0.268853 model2 loss : 0.380674
[23:57:05.576] iteration 21893 : model1 loss : 0.174385 model2 loss : 0.190288
[23:57:05.914] iteration 21894 : model1 loss : 0.155715 model2 loss : 0.168276
[23:57:06.250] iteration 21895 : model1 loss : 0.367902 model2 loss : 0.367454
[23:57:06.587] iteration 21896 : model1 loss : 0.172186 model2 loss : 0.177842
[23:57:06.931] iteration 21897 : model1 loss : 0.107179 model2 loss : 0.127526
[23:57:07.270] iteration 21898 : model1 loss : 0.096599 model2 loss : 0.098059
[23:57:07.607] iteration 21899 : model1 loss : 0.242622 model2 loss : 0.280057
[23:57:07.944] iteration 21900 : model1 loss : 0.077694 model2 loss : 0.117161
[23:57:08.599] iteration 21901 : model1 loss : 0.172889 model2 loss : 0.223739
[23:57:08.937] iteration 21902 : model1 loss : 0.098628 model2 loss : 0.150334
[23:57:09.276] iteration 21903 : model1 loss : 0.135587 model2 loss : 0.187680
[23:57:09.613] iteration 21904 : model1 loss : 0.092774 model2 loss : 0.129198
[23:57:09.950] iteration 21905 : model1 loss : 0.191715 model2 loss : 0.213579
[23:57:10.288] iteration 21906 : model1 loss : 0.225098 model2 loss : 0.260535
[23:57:10.630] iteration 21907 : model1 loss : 0.184551 model2 loss : 0.228349
[23:57:10.968] iteration 21908 : model1 loss : 0.182159 model2 loss : 0.253842
[23:57:11.309] iteration 21909 : model1 loss : 0.179800 model2 loss : 0.236448
[23:57:11.646] iteration 21910 : model1 loss : 0.248411 model2 loss : 0.270862
[23:57:11.983] iteration 21911 : model1 loss : 0.317581 model2 loss : 0.324165
[23:57:12.332] iteration 21912 : model1 loss : 0.097740 model2 loss : 0.166985
[23:57:12.669] iteration 21913 : model1 loss : 0.235361 model2 loss : 0.241334
[23:57:13.009] iteration 21914 : model1 loss : 0.258428 model2 loss : 0.284810
[23:57:13.348] iteration 21915 : model1 loss : 0.235458 model2 loss : 0.252608
[23:57:13.685] iteration 21916 : model1 loss : 0.267961 model2 loss : 0.268512
[23:57:14.023] iteration 21917 : model1 loss : 0.071027 model2 loss : 0.099714
[23:57:14.358] iteration 21918 : model1 loss : 0.149795 model2 loss : 0.166867
[23:57:14.694] iteration 21919 : model1 loss : 0.196557 model2 loss : 0.184212
[23:57:15.033] iteration 21920 : model1 loss : 0.146796 model2 loss : 0.165269
[23:57:15.375] iteration 21921 : model1 loss : 0.153758 model2 loss : 0.256356
[23:57:15.712] iteration 21922 : model1 loss : 0.169758 model2 loss : 0.227165
[23:57:16.049] iteration 21923 : model1 loss : 0.098273 model2 loss : 0.109215
[23:57:16.389] iteration 21924 : model1 loss : 0.261177 model2 loss : 0.279438
[23:57:16.726] iteration 21925 : model1 loss : 0.160546 model2 loss : 0.187356
[23:57:17.067] iteration 21926 : model1 loss : 0.282854 model2 loss : 0.315171
[23:57:17.402] iteration 21927 : model1 loss : 0.156622 model2 loss : 0.230508
[23:57:17.738] iteration 21928 : model1 loss : 0.098994 model2 loss : 0.134387
[23:57:18.076] iteration 21929 : model1 loss : 0.078692 model2 loss : 0.123456
[23:57:18.412] iteration 21930 : model1 loss : 0.238757 model2 loss : 0.249594
[23:57:18.748] iteration 21931 : model1 loss : 0.242721 model2 loss : 0.271373
[23:57:19.088] iteration 21932 : model1 loss : 0.111421 model2 loss : 0.122636
[23:57:19.423] iteration 21933 : model1 loss : 0.177679 model2 loss : 0.215524
[23:57:19.760] iteration 21934 : model1 loss : 0.165506 model2 loss : 0.194374
[23:57:20.098] iteration 21935 : model1 loss : 0.169299 model2 loss : 0.189406
[23:57:20.438] iteration 21936 : model1 loss : 0.311475 model2 loss : 0.343136
[23:57:20.775] iteration 21937 : model1 loss : 0.097475 model2 loss : 0.151720
[23:57:21.117] iteration 21938 : model1 loss : 0.159915 model2 loss : 0.149181
[23:57:21.457] iteration 21939 : model1 loss : 0.182433 model2 loss : 0.185786
[23:57:21.794] iteration 21940 : model1 loss : 0.169921 model2 loss : 0.209949
[23:57:22.129] iteration 21941 : model1 loss : 0.266055 model2 loss : 0.311761
[23:57:22.465] iteration 21942 : model1 loss : 0.201788 model2 loss : 0.250406
[23:57:22.802] iteration 21943 : model1 loss : 0.242348 model2 loss : 0.222079
[23:57:23.140] iteration 21944 : model1 loss : 0.189639 model2 loss : 0.208260
[23:57:23.479] iteration 21945 : model1 loss : 0.263269 model2 loss : 0.265991
[23:57:23.817] iteration 21946 : model1 loss : 0.104618 model2 loss : 0.131325
[23:57:24.152] iteration 21947 : model1 loss : 0.178610 model2 loss : 0.223785
[23:57:24.488] iteration 21948 : model1 loss : 0.172578 model2 loss : 0.180397
[23:57:24.824] iteration 21949 : model1 loss : 0.163000 model2 loss : 0.222489
[23:57:25.165] iteration 21950 : model1 loss : 0.078302 model2 loss : 0.105891
[23:57:25.804] iteration 21951 : model1 loss : 0.161335 model2 loss : 0.182361
[23:57:26.146] iteration 21952 : model1 loss : 0.302109 model2 loss : 0.334861
[23:57:26.485] iteration 21953 : model1 loss : 0.171264 model2 loss : 0.228588
[23:57:26.822] iteration 21954 : model1 loss : 0.239858 model2 loss : 0.311610
[23:57:27.157] iteration 21955 : model1 loss : 0.289335 model2 loss : 0.292089
[23:57:27.495] iteration 21956 : model1 loss : 0.086555 model2 loss : 0.114289
[23:57:27.832] iteration 21957 : model1 loss : 0.197926 model2 loss : 0.289591
[23:57:28.167] iteration 21958 : model1 loss : 0.175071 model2 loss : 0.247782
[23:57:28.506] iteration 21959 : model1 loss : 0.118965 model2 loss : 0.097233
[23:57:28.843] iteration 21960 : model1 loss : 0.209774 model2 loss : 0.187858
[23:57:29.179] iteration 21961 : model1 loss : 0.260643 model2 loss : 0.276146
[23:57:29.519] iteration 21962 : model1 loss : 0.176432 model2 loss : 0.239461
[23:57:29.855] iteration 21963 : model1 loss : 0.262703 model2 loss : 0.245826
[23:57:30.194] iteration 21964 : model1 loss : 0.123781 model2 loss : 0.103245
[23:57:30.532] iteration 21965 : model1 loss : 0.185460 model2 loss : 0.200148
[23:57:30.876] iteration 21966 : model1 loss : 0.203138 model2 loss : 0.186978
[23:57:31.214] iteration 21967 : model1 loss : 0.481953 model2 loss : 0.346358
[23:57:31.551] iteration 21968 : model1 loss : 0.170780 model2 loss : 0.153924
[23:57:31.892] iteration 21969 : model1 loss : 0.116105 model2 loss : 0.187489
[23:57:32.234] iteration 21970 : model1 loss : 0.074097 model2 loss : 0.109958
[23:57:32.570] iteration 21971 : model1 loss : 0.108493 model2 loss : 0.163468
[23:57:32.910] iteration 21972 : model1 loss : 0.215310 model2 loss : 0.191453
[23:57:33.246] iteration 21973 : model1 loss : 0.194666 model2 loss : 0.233423
[23:57:33.586] iteration 21974 : model1 loss : 0.183788 model2 loss : 0.214504
[23:57:33.927] iteration 21975 : model1 loss : 0.269320 model2 loss : 0.321137
[23:57:34.266] iteration 21976 : model1 loss : 0.199433 model2 loss : 0.268283
[23:57:34.609] iteration 21977 : model1 loss : 0.294614 model2 loss : 0.307082
[23:57:34.948] iteration 21978 : model1 loss : 0.192091 model2 loss : 0.207314
[23:57:35.291] iteration 21979 : model1 loss : 0.106638 model2 loss : 0.134341
[23:57:35.629] iteration 21980 : model1 loss : 0.181779 model2 loss : 0.191825
[23:57:35.969] iteration 21981 : model1 loss : 0.079468 model2 loss : 0.160203
[23:57:36.307] iteration 21982 : model1 loss : 0.183577 model2 loss : 0.203036
[23:57:36.648] iteration 21983 : model1 loss : 0.185061 model2 loss : 0.200509
[23:57:36.986] iteration 21984 : model1 loss : 0.176937 model2 loss : 0.211435
[23:57:37.328] iteration 21985 : model1 loss : 0.246034 model2 loss : 0.269749
[23:57:37.665] iteration 21986 : model1 loss : 0.084264 model2 loss : 0.149821
[23:57:38.002] iteration 21987 : model1 loss : 0.214266 model2 loss : 0.218465
[23:57:38.343] iteration 21988 : model1 loss : 0.319062 model2 loss : 0.326199
[23:57:38.685] iteration 21989 : model1 loss : 0.177148 model2 loss : 0.220893
[23:57:39.022] iteration 21990 : model1 loss : 0.287611 model2 loss : 0.189333
[23:57:39.362] iteration 21991 : model1 loss : 0.280378 model2 loss : 0.302824
[23:57:39.699] iteration 21992 : model1 loss : 0.174415 model2 loss : 0.205135
[23:57:40.037] iteration 21993 : model1 loss : 0.173040 model2 loss : 0.245675
[23:57:40.375] iteration 21994 : model1 loss : 0.068158 model2 loss : 0.178133
[23:57:40.712] iteration 21995 : model1 loss : 0.206730 model2 loss : 0.253389
[23:57:41.050] iteration 21996 : model1 loss : 0.277483 model2 loss : 0.289703
[23:57:41.386] iteration 21997 : model1 loss : 0.276171 model2 loss : 0.313062
[23:57:41.722] iteration 21998 : model1 loss : 0.070795 model2 loss : 0.097487
[23:57:42.059] iteration 21999 : model1 loss : 0.160295 model2 loss : 0.203552
[23:57:42.397] iteration 22000 : model1 loss : 0.066124 model2 loss : 0.089521
[23:57:43.025] iteration 22001 : model1 loss : 0.198855 model2 loss : 0.226726
[23:57:43.366] iteration 22002 : model1 loss : 0.205846 model2 loss : 0.245162
[23:57:43.705] iteration 22003 : model1 loss : 0.120112 model2 loss : 0.191612
[23:57:44.042] iteration 22004 : model1 loss : 0.287592 model2 loss : 0.373315
[23:57:44.378] iteration 22005 : model1 loss : 0.184675 model2 loss : 0.247173
[23:57:44.714] iteration 22006 : model1 loss : 0.176025 model2 loss : 0.173754
[23:57:45.052] iteration 22007 : model1 loss : 0.208519 model2 loss : 0.212499
[23:57:45.392] iteration 22008 : model1 loss : 0.265290 model2 loss : 0.327448
[23:57:45.731] iteration 22009 : model1 loss : 0.168642 model2 loss : 0.219190
[23:57:46.071] iteration 22010 : model1 loss : 0.178341 model2 loss : 0.194770
[23:57:46.408] iteration 22011 : model1 loss : 0.218348 model2 loss : 0.251714
[23:57:46.746] iteration 22012 : model1 loss : 0.273876 model2 loss : 0.302705
[23:57:47.092] iteration 22013 : model1 loss : 0.282374 model2 loss : 0.275925
[23:57:47.429] iteration 22014 : model1 loss : 0.187833 model2 loss : 0.219825
[23:57:47.766] iteration 22015 : model1 loss : 0.126820 model2 loss : 0.259847
[23:57:48.105] iteration 22016 : model1 loss : 0.251953 model2 loss : 0.273675
[23:57:48.442] iteration 22017 : model1 loss : 0.152874 model2 loss : 0.171399
[23:57:48.778] iteration 22018 : model1 loss : 0.204886 model2 loss : 0.186019
[23:57:49.116] iteration 22019 : model1 loss : 0.271464 model2 loss : 0.269714
[23:57:49.453] iteration 22020 : model1 loss : 0.225017 model2 loss : 0.256074
[23:57:49.793] iteration 22021 : model1 loss : 0.262578 model2 loss : 0.260464
[23:57:50.131] iteration 22022 : model1 loss : 0.062443 model2 loss : 0.121906
[23:57:50.467] iteration 22023 : model1 loss : 0.157325 model2 loss : 0.184049
[23:57:50.805] iteration 22024 : model1 loss : 0.094287 model2 loss : 0.127477
[23:57:51.142] iteration 22025 : model1 loss : 0.160561 model2 loss : 0.162746
[23:57:51.482] iteration 22026 : model1 loss : 0.158430 model2 loss : 0.202683
[23:57:51.818] iteration 22027 : model1 loss : 0.172897 model2 loss : 0.212576
[23:57:52.155] iteration 22028 : model1 loss : 0.095165 model2 loss : 0.129966
[23:57:52.496] iteration 22029 : model1 loss : 0.198519 model2 loss : 0.243907
[23:57:52.834] iteration 22030 : model1 loss : 0.276058 model2 loss : 0.259887
[23:57:53.175] iteration 22031 : model1 loss : 0.130131 model2 loss : 0.149397
[23:57:53.516] iteration 22032 : model1 loss : 0.190691 model2 loss : 0.223889
[23:57:53.859] iteration 22033 : model1 loss : 0.192386 model2 loss : 0.288517
[23:57:54.196] iteration 22034 : model1 loss : 0.205927 model2 loss : 0.235588
[23:57:54.534] iteration 22035 : model1 loss : 0.114645 model2 loss : 0.131313
[23:57:54.872] iteration 22036 : model1 loss : 0.209430 model2 loss : 0.236052
[23:57:55.212] iteration 22037 : model1 loss : 0.164917 model2 loss : 0.207651
[23:57:55.553] iteration 22038 : model1 loss : 0.092148 model2 loss : 0.158892
[23:57:55.894] iteration 22039 : model1 loss : 0.104509 model2 loss : 0.166076
[23:57:56.231] iteration 22040 : model1 loss : 0.343547 model2 loss : 0.404656
[23:57:56.568] iteration 22041 : model1 loss : 0.284086 model2 loss : 0.336196
[23:57:56.910] iteration 22042 : model1 loss : 0.099181 model2 loss : 0.126771
[23:57:57.249] iteration 22043 : model1 loss : 0.220254 model2 loss : 0.253520
[23:57:57.587] iteration 22044 : model1 loss : 0.173494 model2 loss : 0.167503
[23:57:57.928] iteration 22045 : model1 loss : 0.159117 model2 loss : 0.170487
[23:57:58.266] iteration 22046 : model1 loss : 0.164082 model2 loss : 0.194093
[23:57:58.602] iteration 22047 : model1 loss : 0.256077 model2 loss : 0.332529
[23:57:58.940] iteration 22048 : model1 loss : 0.084853 model2 loss : 0.140872
[23:57:59.280] iteration 22049 : model1 loss : 0.253639 model2 loss : 0.274840
[23:57:59.618] iteration 22050 : model1 loss : 0.220472 model2 loss : 0.234032
[23:58:00.309] iteration 22051 : model1 loss : 0.264627 model2 loss : 0.279996
[23:58:00.647] iteration 22052 : model1 loss : 0.084465 model2 loss : 0.245630
[23:58:00.985] iteration 22053 : model1 loss : 0.172288 model2 loss : 0.190430
[23:58:01.329] iteration 22054 : model1 loss : 0.240383 model2 loss : 0.302741
[23:58:01.669] iteration 22055 : model1 loss : 0.248884 model2 loss : 0.280851
[23:58:02.009] iteration 22056 : model1 loss : 0.322877 model2 loss : 0.339215
[23:58:02.346] iteration 22057 : model1 loss : 0.095897 model2 loss : 0.230913
[23:58:02.686] iteration 22058 : model1 loss : 0.099421 model2 loss : 0.142358
[23:58:03.023] iteration 22059 : model1 loss : 0.089019 model2 loss : 0.132891
[23:58:03.363] iteration 22060 : model1 loss : 0.173967 model2 loss : 0.205616
[23:58:03.702] iteration 22061 : model1 loss : 0.263813 model2 loss : 0.267463
[23:58:04.045] iteration 22062 : model1 loss : 0.178298 model2 loss : 0.264594
[23:58:04.382] iteration 22063 : model1 loss : 0.195986 model2 loss : 0.228118
[23:58:04.719] iteration 22064 : model1 loss : 0.130494 model2 loss : 0.202395
[23:58:05.056] iteration 22065 : model1 loss : 0.192796 model2 loss : 0.159030
[23:58:05.395] iteration 22066 : model1 loss : 0.186818 model2 loss : 0.204570
[23:58:05.731] iteration 22067 : model1 loss : 0.289756 model2 loss : 0.286213
[23:58:06.071] iteration 22068 : model1 loss : 0.209162 model2 loss : 0.237894
[23:58:06.410] iteration 22069 : model1 loss : 0.177804 model2 loss : 0.268381
[23:58:06.752] iteration 22070 : model1 loss : 0.105735 model2 loss : 0.122897
[23:58:07.089] iteration 22071 : model1 loss : 0.175522 model2 loss : 0.256753
[23:58:07.425] iteration 22072 : model1 loss : 0.167001 model2 loss : 0.232118
[23:58:07.761] iteration 22073 : model1 loss : 0.207933 model2 loss : 0.222948
[23:58:08.099] iteration 22074 : model1 loss : 0.187776 model2 loss : 0.196297
[23:58:08.436] iteration 22075 : model1 loss : 0.254155 model2 loss : 0.279535
[23:58:08.774] iteration 22076 : model1 loss : 0.165076 model2 loss : 0.178473
[23:58:09.115] iteration 22077 : model1 loss : 0.183108 model2 loss : 0.193204
[23:58:09.453] iteration 22078 : model1 loss : 0.191093 model2 loss : 0.211308
[23:58:09.790] iteration 22079 : model1 loss : 0.235721 model2 loss : 0.258561
[23:58:10.128] iteration 22080 : model1 loss : 0.182758 model2 loss : 0.218633
[23:58:10.466] iteration 22081 : model1 loss : 0.209269 model2 loss : 0.255883
[23:58:10.807] iteration 22082 : model1 loss : 0.165228 model2 loss : 0.210320
[23:58:11.146] iteration 22083 : model1 loss : 0.267094 model2 loss : 0.285178
[23:58:11.482] iteration 22084 : model1 loss : 0.081081 model2 loss : 0.133581
[23:58:11.820] iteration 22085 : model1 loss : 0.199477 model2 loss : 0.193135
[23:58:12.156] iteration 22086 : model1 loss : 0.184954 model2 loss : 0.251745
[23:58:12.493] iteration 22087 : model1 loss : 0.171509 model2 loss : 0.241106
[23:58:12.829] iteration 22088 : model1 loss : 0.230564 model2 loss : 0.351646
[23:58:13.170] iteration 22089 : model1 loss : 0.234081 model2 loss : 0.239497
[23:58:13.506] iteration 22090 : model1 loss : 0.160302 model2 loss : 0.210802
[23:58:13.845] iteration 22091 : model1 loss : 0.182631 model2 loss : 0.197644
[23:58:14.181] iteration 22092 : model1 loss : 0.199256 model2 loss : 0.233402
[23:58:14.522] iteration 22093 : model1 loss : 0.083343 model2 loss : 0.115931
[23:58:14.854] iteration 22094 : model1 loss : 0.091170 model2 loss : 0.138694
[23:58:15.191] iteration 22095 : model1 loss : 0.114435 model2 loss : 0.137994
[23:58:15.529] iteration 22096 : model1 loss : 0.223097 model2 loss : 0.222472
[23:58:15.866] iteration 22097 : model1 loss : 0.235881 model2 loss : 0.254212
[23:58:16.202] iteration 22098 : model1 loss : 0.216466 model2 loss : 0.265618
[23:58:16.535] iteration 22099 : model1 loss : 0.190051 model2 loss : 0.256407
[23:58:16.873] iteration 22100 : model1 loss : 0.249687 model2 loss : 0.130403
[23:58:17.513] iteration 22101 : model1 loss : 0.157873 model2 loss : 0.235013
[23:58:17.850] iteration 22102 : model1 loss : 0.200377 model2 loss : 0.211738
[23:58:18.188] iteration 22103 : model1 loss : 0.086598 model2 loss : 0.095253
[23:58:18.531] iteration 22104 : model1 loss : 0.256036 model2 loss : 0.291964
[23:58:18.866] iteration 22105 : model1 loss : 0.170236 model2 loss : 0.248779
[23:58:19.199] iteration 22106 : model1 loss : 0.194268 model2 loss : 0.198022
[23:58:19.538] iteration 22107 : model1 loss : 0.103716 model2 loss : 0.185163
[23:58:19.877] iteration 22108 : model1 loss : 0.187420 model2 loss : 0.252634
[23:58:20.213] iteration 22109 : model1 loss : 0.109745 model2 loss : 0.157583
[23:58:20.551] iteration 22110 : model1 loss : 0.197405 model2 loss : 0.191011
[23:58:20.891] iteration 22111 : model1 loss : 0.273877 model2 loss : 0.271477
[23:58:21.231] iteration 22112 : model1 loss : 0.221409 model2 loss : 0.126180
[23:58:21.568] iteration 22113 : model1 loss : 0.183269 model2 loss : 0.251809
[23:58:21.905] iteration 22114 : model1 loss : 0.093086 model2 loss : 0.120674
[23:58:22.242] iteration 22115 : model1 loss : 0.258758 model2 loss : 0.282072
[23:58:22.581] iteration 22116 : model1 loss : 0.209528 model2 loss : 0.179852
[23:58:22.914] iteration 22117 : model1 loss : 0.176302 model2 loss : 0.211900
[23:58:23.251] iteration 22118 : model1 loss : 0.308473 model2 loss : 0.326475
[23:58:23.589] iteration 22119 : model1 loss : 0.182679 model2 loss : 0.233102
[23:58:23.923] iteration 22120 : model1 loss : 0.194275 model2 loss : 0.248720
[23:58:24.263] iteration 22121 : model1 loss : 0.192454 model2 loss : 0.264967
[23:58:24.599] iteration 22122 : model1 loss : 0.271520 model2 loss : 0.277447
[23:58:24.934] iteration 22123 : model1 loss : 0.293432 model2 loss : 0.344480
[23:58:25.271] iteration 22124 : model1 loss : 0.202188 model2 loss : 0.235105
[23:58:25.610] iteration 22125 : model1 loss : 0.296599 model2 loss : 0.316090
[23:58:25.943] iteration 22126 : model1 loss : 0.268732 model2 loss : 0.255954
[23:58:26.280] iteration 22127 : model1 loss : 0.218592 model2 loss : 0.224336
[23:58:26.620] iteration 22128 : model1 loss : 0.101375 model2 loss : 0.199651
[23:58:26.959] iteration 22129 : model1 loss : 0.182378 model2 loss : 0.185494
[23:58:27.293] iteration 22130 : model1 loss : 0.186836 model2 loss : 0.191065
[23:58:27.631] iteration 22131 : model1 loss : 0.182086 model2 loss : 0.264020
[23:58:27.967] iteration 22132 : model1 loss : 0.202311 model2 loss : 0.281946
[23:58:28.304] iteration 22133 : model1 loss : 0.201440 model2 loss : 0.227667
[23:58:28.640] iteration 22134 : model1 loss : 0.179081 model2 loss : 0.183749
[23:58:28.978] iteration 22135 : model1 loss : 0.224027 model2 loss : 0.271258
[23:58:29.320] iteration 22136 : model1 loss : 0.096531 model2 loss : 0.116285
[23:58:29.660] iteration 22137 : model1 loss : 0.085690 model2 loss : 0.142165
[23:58:29.999] iteration 22138 : model1 loss : 0.183653 model2 loss : 0.215495
[23:58:30.340] iteration 22139 : model1 loss : 0.199807 model2 loss : 0.252344
[23:58:30.678] iteration 22140 : model1 loss : 0.234106 model2 loss : 0.240967
[23:58:31.018] iteration 22141 : model1 loss : 0.235941 model2 loss : 0.337194
[23:58:31.350] iteration 22142 : model1 loss : 0.125751 model2 loss : 0.181197
[23:58:31.688] iteration 22143 : model1 loss : 0.154679 model2 loss : 0.233314
[23:58:32.023] iteration 22144 : model1 loss : 0.120079 model2 loss : 0.160546
[23:58:32.358] iteration 22145 : model1 loss : 0.238227 model2 loss : 0.266728
[23:58:32.696] iteration 22146 : model1 loss : 0.314598 model2 loss : 0.304524
[23:58:33.033] iteration 22147 : model1 loss : 0.199032 model2 loss : 0.279523
[23:58:33.370] iteration 22148 : model1 loss : 0.120235 model2 loss : 0.134955
[23:58:33.708] iteration 22149 : model1 loss : 0.175622 model2 loss : 0.201296
[23:58:34.044] iteration 22150 : model1 loss : 0.240649 model2 loss : 0.216516
[23:58:34.690] iteration 22151 : model1 loss : 0.196107 model2 loss : 0.210173
[23:58:35.031] iteration 22152 : model1 loss : 0.208648 model2 loss : 0.275941
[23:58:35.370] iteration 22153 : model1 loss : 0.186023 model2 loss : 0.256133
[23:58:35.711] iteration 22154 : model1 loss : 0.175986 model2 loss : 0.188331
[23:58:36.048] iteration 22155 : model1 loss : 0.166673 model2 loss : 0.179808
[23:58:36.384] iteration 22156 : model1 loss : 0.192317 model2 loss : 0.241071
[23:58:36.722] iteration 22157 : model1 loss : 0.099239 model2 loss : 0.131393
[23:58:37.061] iteration 22158 : model1 loss : 0.271570 model2 loss : 0.229804
[23:58:37.399] iteration 22159 : model1 loss : 0.117395 model2 loss : 0.118433
[23:58:37.739] iteration 22160 : model1 loss : 0.160285 model2 loss : 0.192018
[23:58:38.078] iteration 22161 : model1 loss : 0.070698 model2 loss : 0.106654
[23:58:38.410] iteration 22162 : model1 loss : 0.263405 model2 loss : 0.290480
[23:58:38.748] iteration 22163 : model1 loss : 0.099785 model2 loss : 0.111929
[23:58:39.086] iteration 22164 : model1 loss : 0.326491 model2 loss : 0.388766
[23:58:39.422] iteration 22165 : model1 loss : 0.092919 model2 loss : 0.155883
[23:58:39.759] iteration 22166 : model1 loss : 0.079550 model2 loss : 0.167729
[23:58:40.100] iteration 22167 : model1 loss : 0.207809 model2 loss : 0.257982
[23:58:40.442] iteration 22168 : model1 loss : 0.175188 model2 loss : 0.196224
[23:58:40.780] iteration 22169 : model1 loss : 0.127386 model2 loss : 0.207339
[23:58:41.115] iteration 22170 : model1 loss : 0.175479 model2 loss : 0.203580
[23:58:41.806] iteration 22171 : model1 loss : 0.092443 model2 loss : 0.114148
[23:58:42.143] iteration 22172 : model1 loss : 0.200063 model2 loss : 0.216731
[23:58:42.482] iteration 22173 : model1 loss : 0.292296 model2 loss : 0.324741
[23:58:42.823] iteration 22174 : model1 loss : 0.206741 model2 loss : 0.222048
[23:58:43.161] iteration 22175 : model1 loss : 0.163577 model2 loss : 0.220427
[23:58:43.503] iteration 22176 : model1 loss : 0.261218 model2 loss : 0.275706
[23:58:43.838] iteration 22177 : model1 loss : 0.095378 model2 loss : 0.135080
[23:58:44.175] iteration 22178 : model1 loss : 0.223495 model2 loss : 0.257683
[23:58:44.513] iteration 22179 : model1 loss : 0.155148 model2 loss : 0.198134
[23:58:44.849] iteration 22180 : model1 loss : 0.281753 model2 loss : 0.311740
[23:58:45.191] iteration 22181 : model1 loss : 0.253429 model2 loss : 0.333331
[23:58:45.529] iteration 22182 : model1 loss : 0.183886 model2 loss : 0.211516
[23:58:45.868] iteration 22183 : model1 loss : 0.149634 model2 loss : 0.157511
[23:58:46.210] iteration 22184 : model1 loss : 0.205308 model2 loss : 0.231058
[23:58:46.542] iteration 22185 : model1 loss : 0.256343 model2 loss : 0.290710
[23:58:46.883] iteration 22186 : model1 loss : 0.271934 model2 loss : 0.279303
[23:58:47.219] iteration 22187 : model1 loss : 0.261449 model2 loss : 0.333266
[23:58:47.560] iteration 22188 : model1 loss : 0.175900 model2 loss : 0.190807
[23:58:47.900] iteration 22189 : model1 loss : 0.223809 model2 loss : 0.289822
[23:58:48.235] iteration 22190 : model1 loss : 0.171152 model2 loss : 0.196800
[23:58:48.574] iteration 22191 : model1 loss : 0.081209 model2 loss : 0.163942
[23:58:48.910] iteration 22192 : model1 loss : 0.091256 model2 loss : 0.107810
[23:58:49.242] iteration 22193 : model1 loss : 0.087126 model2 loss : 0.145530
[23:58:49.578] iteration 22194 : model1 loss : 0.215136 model2 loss : 0.247100
[23:58:49.916] iteration 22195 : model1 loss : 0.203388 model2 loss : 0.349535
[23:58:50.252] iteration 22196 : model1 loss : 0.162834 model2 loss : 0.200796
[23:58:50.590] iteration 22197 : model1 loss : 0.163175 model2 loss : 0.178180
[23:58:50.927] iteration 22198 : model1 loss : 0.166593 model2 loss : 0.226518
[23:58:51.262] iteration 22199 : model1 loss : 0.194847 model2 loss : 0.207277
[23:58:51.599] iteration 22200 : model1 loss : 0.116310 model2 loss : 0.174368
[23:58:52.251] iteration 22201 : model1 loss : 0.126942 model2 loss : 0.095329
[23:58:52.592] iteration 22202 : model1 loss : 0.233732 model2 loss : 0.241828
[23:58:52.932] iteration 22203 : model1 loss : 0.171027 model2 loss : 0.191286
[23:58:53.267] iteration 22204 : model1 loss : 0.241788 model2 loss : 0.260580
[23:58:53.604] iteration 22205 : model1 loss : 0.147986 model2 loss : 0.163783
[23:58:53.945] iteration 22206 : model1 loss : 0.128348 model2 loss : 0.128933
[23:58:54.281] iteration 22207 : model1 loss : 0.261481 model2 loss : 0.268262
[23:58:54.618] iteration 22208 : model1 loss : 0.166794 model2 loss : 0.218792
[23:58:54.954] iteration 22209 : model1 loss : 0.166290 model2 loss : 0.185416
[23:58:55.291] iteration 22210 : model1 loss : 0.176086 model2 loss : 0.216549
[23:58:55.631] iteration 22211 : model1 loss : 0.229104 model2 loss : 0.208312
[23:58:55.966] iteration 22212 : model1 loss : 0.159130 model2 loss : 0.186331
[23:58:56.303] iteration 22213 : model1 loss : 0.191859 model2 loss : 0.196090
[23:58:56.642] iteration 22214 : model1 loss : 0.107468 model2 loss : 0.110367
[23:58:56.977] iteration 22215 : model1 loss : 0.068351 model2 loss : 0.169423
[23:58:57.313] iteration 22216 : model1 loss : 0.174469 model2 loss : 0.225090
[23:58:57.652] iteration 22217 : model1 loss : 0.206869 model2 loss : 0.219683
[23:58:57.989] iteration 22218 : model1 loss : 0.178652 model2 loss : 0.223312
[23:58:58.326] iteration 22219 : model1 loss : 0.207980 model2 loss : 0.206081
[23:58:58.665] iteration 22220 : model1 loss : 0.171108 model2 loss : 0.209788
[23:58:59.005] iteration 22221 : model1 loss : 0.275571 model2 loss : 0.330357
[23:58:59.342] iteration 22222 : model1 loss : 0.245951 model2 loss : 0.281674
[23:58:59.678] iteration 22223 : model1 loss : 0.184666 model2 loss : 0.250783
[23:59:00.017] iteration 22224 : model1 loss : 0.209531 model2 loss : 0.238754
[23:59:00.355] iteration 22225 : model1 loss : 0.174313 model2 loss : 0.198596
[23:59:00.692] iteration 22226 : model1 loss : 0.173994 model2 loss : 0.148438
[23:59:01.030] iteration 22227 : model1 loss : 0.258390 model2 loss : 0.308318
[23:59:01.366] iteration 22228 : model1 loss : 0.189900 model2 loss : 0.279387
[23:59:01.704] iteration 22229 : model1 loss : 0.179684 model2 loss : 0.375886
[23:59:02.040] iteration 22230 : model1 loss : 0.186431 model2 loss : 0.224521
[23:59:02.377] iteration 22231 : model1 loss : 0.166767 model2 loss : 0.199068
[23:59:02.710] iteration 22232 : model1 loss : 0.163807 model2 loss : 0.158555
[23:59:03.042] iteration 22233 : model1 loss : 0.255575 model2 loss : 0.260043
[23:59:03.378] iteration 22234 : model1 loss : 0.195115 model2 loss : 0.185357
[23:59:03.715] iteration 22235 : model1 loss : 0.192620 model2 loss : 0.252330
[23:59:04.055] iteration 22236 : model1 loss : 0.076273 model2 loss : 0.119355
[23:59:04.389] iteration 22237 : model1 loss : 0.256559 model2 loss : 0.260194
[23:59:04.726] iteration 22238 : model1 loss : 0.248360 model2 loss : 0.249713
[23:59:05.067] iteration 22239 : model1 loss : 0.086508 model2 loss : 0.168224
[23:59:05.408] iteration 22240 : model1 loss : 0.252244 model2 loss : 0.288501
[23:59:05.745] iteration 22241 : model1 loss : 0.176104 model2 loss : 0.208648
[23:59:06.077] iteration 22242 : model1 loss : 0.174885 model2 loss : 0.194279
[23:59:06.420] iteration 22243 : model1 loss : 0.150766 model2 loss : 0.172147
[23:59:06.760] iteration 22244 : model1 loss : 0.169075 model2 loss : 0.197051
[23:59:07.095] iteration 22245 : model1 loss : 0.170100 model2 loss : 0.280125
[23:59:07.432] iteration 22246 : model1 loss : 0.258470 model2 loss : 0.312470
[23:59:07.770] iteration 22247 : model1 loss : 0.169191 model2 loss : 0.180867
[23:59:08.105] iteration 22248 : model1 loss : 0.190931 model2 loss : 0.244595
[23:59:08.441] iteration 22249 : model1 loss : 0.164531 model2 loss : 0.190237
[23:59:08.778] iteration 22250 : model1 loss : 0.240570 model2 loss : 0.244409
[23:59:09.447] iteration 22251 : model1 loss : 0.169418 model2 loss : 0.193448
[23:59:09.785] iteration 22252 : model1 loss : 0.305129 model2 loss : 0.430864
[23:59:10.123] iteration 22253 : model1 loss : 0.277351 model2 loss : 0.309257
[23:59:10.459] iteration 22254 : model1 loss : 0.198188 model2 loss : 0.199106
[23:59:10.795] iteration 22255 : model1 loss : 0.177785 model2 loss : 0.202634
[23:59:11.132] iteration 22256 : model1 loss : 0.094495 model2 loss : 0.161266
[23:59:11.471] iteration 22257 : model1 loss : 0.199825 model2 loss : 0.246525
[23:59:11.808] iteration 22258 : model1 loss : 0.251966 model2 loss : 0.261901
[23:59:12.145] iteration 22259 : model1 loss : 0.148705 model2 loss : 0.198895
[23:59:12.485] iteration 22260 : model1 loss : 0.160869 model2 loss : 0.177875
[23:59:12.830] iteration 22261 : model1 loss : 0.256693 model2 loss : 0.273371
[23:59:13.166] iteration 22262 : model1 loss : 0.159852 model2 loss : 0.224271
[23:59:13.498] iteration 22263 : model1 loss : 0.167692 model2 loss : 0.193060
[23:59:13.832] iteration 22264 : model1 loss : 0.220042 model2 loss : 0.258717
[23:59:14.169] iteration 22265 : model1 loss : 0.069905 model2 loss : 0.073288
[23:59:14.507] iteration 22266 : model1 loss : 0.164051 model2 loss : 0.206671
[23:59:14.847] iteration 22267 : model1 loss : 0.265816 model2 loss : 0.291430
[23:59:15.184] iteration 22268 : model1 loss : 0.276388 model2 loss : 0.274319
[23:59:15.520] iteration 22269 : model1 loss : 0.252251 model2 loss : 0.258374
[23:59:15.858] iteration 22270 : model1 loss : 0.137952 model2 loss : 0.133040
[23:59:16.199] iteration 22271 : model1 loss : 0.270308 model2 loss : 0.328715
[23:59:16.535] iteration 22272 : model1 loss : 0.256983 model2 loss : 0.253535
[23:59:16.868] iteration 22273 : model1 loss : 0.291588 model2 loss : 0.273804
[23:59:17.204] iteration 22274 : model1 loss : 0.103504 model2 loss : 0.138133
[23:59:17.537] iteration 22275 : model1 loss : 0.177775 model2 loss : 0.213558
[23:59:17.873] iteration 22276 : model1 loss : 0.271566 model2 loss : 0.286502
[23:59:18.208] iteration 22277 : model1 loss : 0.166631 model2 loss : 0.174959
[23:59:18.548] iteration 22278 : model1 loss : 0.249939 model2 loss : 0.194475
[23:59:18.885] iteration 22279 : model1 loss : 0.174242 model2 loss : 0.208363
[23:59:19.221] iteration 22280 : model1 loss : 0.103653 model2 loss : 0.157198
[23:59:19.561] iteration 22281 : model1 loss : 0.115143 model2 loss : 0.108584
[23:59:19.898] iteration 22282 : model1 loss : 0.181795 model2 loss : 0.248230
[23:59:20.234] iteration 22283 : model1 loss : 0.257457 model2 loss : 0.203870
[23:59:20.575] iteration 22284 : model1 loss : 0.081923 model2 loss : 0.182304
[23:59:20.910] iteration 22285 : model1 loss : 0.196263 model2 loss : 0.216847
[23:59:21.250] iteration 22286 : model1 loss : 0.206902 model2 loss : 0.239514
[23:59:21.587] iteration 22287 : model1 loss : 0.340687 model2 loss : 0.349495
[23:59:21.921] iteration 22288 : model1 loss : 0.271420 model2 loss : 0.256229
[23:59:22.258] iteration 22289 : model1 loss : 0.162269 model2 loss : 0.188067
[23:59:22.594] iteration 22290 : model1 loss : 0.141009 model2 loss : 0.186540
[23:59:22.931] iteration 22291 : model1 loss : 0.248682 model2 loss : 0.247356
[23:59:23.267] iteration 22292 : model1 loss : 0.228537 model2 loss : 0.257936
[23:59:23.604] iteration 22293 : model1 loss : 0.155581 model2 loss : 0.274197
[23:59:23.940] iteration 22294 : model1 loss : 0.247662 model2 loss : 0.252668
[23:59:24.279] iteration 22295 : model1 loss : 0.186575 model2 loss : 0.193594
[23:59:24.614] iteration 22296 : model1 loss : 0.230880 model2 loss : 0.230285
[23:59:24.949] iteration 22297 : model1 loss : 0.132366 model2 loss : 0.179088
[23:59:25.287] iteration 22298 : model1 loss : 0.178330 model2 loss : 0.213253
[23:59:25.625] iteration 22299 : model1 loss : 0.191726 model2 loss : 0.215198
[23:59:25.961] iteration 22300 : model1 loss : 0.153196 model2 loss : 0.130395
[23:59:26.633] iteration 22301 : model1 loss : 0.152861 model2 loss : 0.183128
[23:59:26.966] iteration 22302 : model1 loss : 0.148157 model2 loss : 0.147216
[23:59:27.298] iteration 22303 : model1 loss : 0.156872 model2 loss : 0.166147
[23:59:27.636] iteration 22304 : model1 loss : 0.076199 model2 loss : 0.095479
[23:59:27.975] iteration 22305 : model1 loss : 0.100499 model2 loss : 0.209357
[23:59:28.312] iteration 22306 : model1 loss : 0.241940 model2 loss : 0.276629
[23:59:28.649] iteration 22307 : model1 loss : 0.199420 model2 loss : 0.231061
[23:59:28.990] iteration 22308 : model1 loss : 0.185058 model2 loss : 0.187561
[23:59:29.323] iteration 22309 : model1 loss : 0.072320 model2 loss : 0.090025
[23:59:29.657] iteration 22310 : model1 loss : 0.177186 model2 loss : 0.191319
[23:59:29.994] iteration 22311 : model1 loss : 0.183397 model2 loss : 0.206692
[23:59:30.332] iteration 22312 : model1 loss : 0.193340 model2 loss : 0.182098
[23:59:30.669] iteration 22313 : model1 loss : 0.232993 model2 loss : 0.265002
[23:59:31.002] iteration 22314 : model1 loss : 0.178035 model2 loss : 0.184137
[23:59:31.339] iteration 22315 : model1 loss : 0.259715 model2 loss : 0.250544
[23:59:31.672] iteration 22316 : model1 loss : 0.187963 model2 loss : 0.224146
[23:59:32.010] iteration 22317 : model1 loss : 0.212864 model2 loss : 0.205948
[23:59:32.348] iteration 22318 : model1 loss : 0.244485 model2 loss : 0.249269
[23:59:32.686] iteration 22319 : model1 loss : 0.244557 model2 loss : 0.249031
[23:59:33.026] iteration 22320 : model1 loss : 0.201981 model2 loss : 0.246653
[23:59:33.368] iteration 22321 : model1 loss : 0.184941 model2 loss : 0.320444
[23:59:33.703] iteration 22322 : model1 loss : 0.101558 model2 loss : 0.105527
[23:59:34.039] iteration 22323 : model1 loss : 0.188707 model2 loss : 0.185496
[23:59:34.379] iteration 22324 : model1 loss : 0.235520 model2 loss : 0.232984
[23:59:34.711] iteration 22325 : model1 loss : 0.181146 model2 loss : 0.221388
[23:59:35.049] iteration 22326 : model1 loss : 0.179681 model2 loss : 0.215088
[23:59:35.384] iteration 22327 : model1 loss : 0.236335 model2 loss : 0.291757
[23:59:35.716] iteration 22328 : model1 loss : 0.178959 model2 loss : 0.203556
[23:59:36.054] iteration 22329 : model1 loss : 0.158874 model2 loss : 0.182686
[23:59:36.389] iteration 22330 : model1 loss : 0.186455 model2 loss : 0.197560
[23:59:36.726] iteration 22331 : model1 loss : 0.091351 model2 loss : 0.108080
[23:59:37.063] iteration 22332 : model1 loss : 0.165200 model2 loss : 0.311521
[23:59:37.395] iteration 22333 : model1 loss : 0.177878 model2 loss : 0.174773
[23:59:37.733] iteration 22334 : model1 loss : 0.179200 model2 loss : 0.238520
[23:59:38.069] iteration 22335 : model1 loss : 0.199757 model2 loss : 0.242532
[23:59:38.410] iteration 22336 : model1 loss : 0.307148 model2 loss : 0.343644
[23:59:38.743] iteration 22337 : model1 loss : 0.248161 model2 loss : 0.250039
[23:59:39.078] iteration 22338 : model1 loss : 0.284910 model2 loss : 0.362964
[23:59:39.414] iteration 22339 : model1 loss : 0.278393 model2 loss : 0.309740
[23:59:39.748] iteration 22340 : model1 loss : 0.156835 model2 loss : 0.170073
[23:59:40.080] iteration 22341 : model1 loss : 0.270019 model2 loss : 0.281609
[23:59:40.412] iteration 22342 : model1 loss : 0.083092 model2 loss : 0.110915
[23:59:40.745] iteration 22343 : model1 loss : 0.195368 model2 loss : 0.202170
[23:59:41.080] iteration 22344 : model1 loss : 0.150371 model2 loss : 0.183800
[23:59:41.414] iteration 22345 : model1 loss : 0.160192 model2 loss : 0.202140
[23:59:42.518] iteration 22346 : model1 loss : 0.158342 model2 loss : 0.193820
[23:59:42.850] iteration 22347 : model1 loss : 0.086898 model2 loss : 0.179426
[23:59:43.183] iteration 22348 : model1 loss : 0.243597 model2 loss : 0.272562
[23:59:43.523] iteration 22349 : model1 loss : 0.183883 model2 loss : 0.210804
[23:59:43.858] iteration 22350 : model1 loss : 0.113934 model2 loss : 0.142704
[23:59:44.506] iteration 22351 : model1 loss : 0.178054 model2 loss : 0.200587
[23:59:44.842] iteration 22352 : model1 loss : 0.241975 model2 loss : 0.280391
[23:59:45.179] iteration 22353 : model1 loss : 0.202127 model2 loss : 0.222359
[23:59:45.517] iteration 22354 : model1 loss : 0.270238 model2 loss : 0.262619
[23:59:45.855] iteration 22355 : model1 loss : 0.175608 model2 loss : 0.216854
[23:59:46.187] iteration 22356 : model1 loss : 0.168824 model2 loss : 0.228241
[23:59:46.528] iteration 22357 : model1 loss : 0.175559 model2 loss : 0.209191
[23:59:46.864] iteration 22358 : model1 loss : 0.147227 model2 loss : 0.155820
[23:59:47.201] iteration 22359 : model1 loss : 0.135388 model2 loss : 0.228239
[23:59:47.538] iteration 22360 : model1 loss : 0.186240 model2 loss : 0.189714
[23:59:47.874] iteration 22361 : model1 loss : 0.212381 model2 loss : 0.200605
[23:59:48.212] iteration 22362 : model1 loss : 0.242332 model2 loss : 0.251457
[23:59:48.551] iteration 22363 : model1 loss : 0.252126 model2 loss : 0.279918
[23:59:48.882] iteration 22364 : model1 loss : 0.174915 model2 loss : 0.258047
[23:59:49.218] iteration 22365 : model1 loss : 0.106740 model2 loss : 0.206719
[23:59:49.551] iteration 22366 : model1 loss : 0.198331 model2 loss : 0.328551
[23:59:49.888] iteration 22367 : model1 loss : 0.192030 model2 loss : 0.199307
[23:59:50.230] iteration 22368 : model1 loss : 0.277080 model2 loss : 0.271230
[23:59:50.567] iteration 22369 : model1 loss : 0.169254 model2 loss : 0.165014
[23:59:50.903] iteration 22370 : model1 loss : 0.106142 model2 loss : 0.134748
[23:59:51.241] iteration 22371 : model1 loss : 0.075859 model2 loss : 0.093531
[23:59:51.579] iteration 22372 : model1 loss : 0.103107 model2 loss : 0.116609
[23:59:51.919] iteration 22373 : model1 loss : 0.084401 model2 loss : 0.117038
[23:59:52.255] iteration 22374 : model1 loss : 0.103796 model2 loss : 0.163866
[23:59:52.588] iteration 22375 : model1 loss : 0.205867 model2 loss : 0.336669
[23:59:52.927] iteration 22376 : model1 loss : 0.110794 model2 loss : 0.121050
[23:59:53.262] iteration 22377 : model1 loss : 0.177513 model2 loss : 0.272165
[23:59:53.599] iteration 22378 : model1 loss : 0.275402 model2 loss : 0.301078
[23:59:53.938] iteration 22379 : model1 loss : 0.125685 model2 loss : 0.214200
[23:59:54.271] iteration 22380 : model1 loss : 0.171646 model2 loss : 0.179548
[23:59:54.613] iteration 22381 : model1 loss : 0.251476 model2 loss : 0.253484
[23:59:54.950] iteration 22382 : model1 loss : 0.218563 model2 loss : 0.207994
[23:59:55.284] iteration 22383 : model1 loss : 0.330053 model2 loss : 0.294521
[23:59:55.623] iteration 22384 : model1 loss : 0.169870 model2 loss : 0.190123
[23:59:55.964] iteration 22385 : model1 loss : 0.196806 model2 loss : 0.319396
[23:59:56.302] iteration 22386 : model1 loss : 0.180523 model2 loss : 0.211472
[23:59:56.650] iteration 22387 : model1 loss : 0.264771 model2 loss : 0.310361
[23:59:56.990] iteration 22388 : model1 loss : 0.177325 model2 loss : 0.175818
[23:59:57.326] iteration 22389 : model1 loss : 0.266029 model2 loss : 0.266116
[23:59:57.659] iteration 22390 : model1 loss : 0.178059 model2 loss : 0.194985
[23:59:57.997] iteration 22391 : model1 loss : 0.109320 model2 loss : 0.152205
[23:59:58.332] iteration 22392 : model1 loss : 0.171695 model2 loss : 0.235697
[23:59:58.667] iteration 22393 : model1 loss : 0.189690 model2 loss : 0.191038
[23:59:59.003] iteration 22394 : model1 loss : 0.318568 model2 loss : 0.355970
[23:59:59.341] iteration 22395 : model1 loss : 0.175916 model2 loss : 0.200190
[23:59:59.679] iteration 22396 : model1 loss : 0.242995 model2 loss : 0.266136
[00:00:00.026] iteration 22397 : model1 loss : 0.098559 model2 loss : 0.135232
[00:00:00.367] iteration 22398 : model1 loss : 0.180595 model2 loss : 0.190723
[00:00:00.708] iteration 22399 : model1 loss : 0.248275 model2 loss : 0.256395
[00:00:01.043] iteration 22400 : model1 loss : 0.163459 model2 loss : 0.230557
[00:00:01.668] iteration 22401 : model1 loss : 0.253816 model2 loss : 0.293072
[00:00:02.009] iteration 22402 : model1 loss : 0.081553 model2 loss : 0.142363
[00:00:02.344] iteration 22403 : model1 loss : 0.096104 model2 loss : 0.181161
[00:00:02.679] iteration 22404 : model1 loss : 0.172706 model2 loss : 0.240332
[00:00:03.016] iteration 22405 : model1 loss : 0.192205 model2 loss : 0.297353
[00:00:03.363] iteration 22406 : model1 loss : 0.353562 model2 loss : 0.384343
[00:00:03.706] iteration 22407 : model1 loss : 0.135221 model2 loss : 0.245066
[00:00:04.043] iteration 22408 : model1 loss : 0.195398 model2 loss : 0.235524
[00:00:04.382] iteration 22409 : model1 loss : 0.190013 model2 loss : 0.191301
[00:00:04.717] iteration 22410 : model1 loss : 0.266085 model2 loss : 0.285807
[00:00:05.051] iteration 22411 : model1 loss : 0.184624 model2 loss : 0.279453
[00:00:05.400] iteration 22412 : model1 loss : 0.089764 model2 loss : 0.119608
[00:00:05.736] iteration 22413 : model1 loss : 0.122585 model2 loss : 0.133001
[00:00:06.069] iteration 22414 : model1 loss : 0.172682 model2 loss : 0.192701
[00:00:06.410] iteration 22415 : model1 loss : 0.201323 model2 loss : 0.254250
[00:00:06.750] iteration 22416 : model1 loss : 0.235300 model2 loss : 0.250612
[00:00:07.089] iteration 22417 : model1 loss : 0.142831 model2 loss : 0.128817
[00:00:07.425] iteration 22418 : model1 loss : 0.150467 model2 loss : 0.160805
[00:00:07.758] iteration 22419 : model1 loss : 0.188703 model2 loss : 0.148514
[00:00:08.100] iteration 22420 : model1 loss : 0.178283 model2 loss : 0.210078
[00:00:08.442] iteration 22421 : model1 loss : 0.233016 model2 loss : 0.262408
[00:00:08.779] iteration 22422 : model1 loss : 0.266548 model2 loss : 0.287072
[00:00:09.116] iteration 22423 : model1 loss : 0.193903 model2 loss : 0.195117
[00:00:09.450] iteration 22424 : model1 loss : 0.253469 model2 loss : 0.292527
[00:00:09.785] iteration 22425 : model1 loss : 0.090430 model2 loss : 0.111638
[00:00:10.122] iteration 22426 : model1 loss : 0.119267 model2 loss : 0.143415
[00:00:10.464] iteration 22427 : model1 loss : 0.062724 model2 loss : 0.078604
[00:00:10.802] iteration 22428 : model1 loss : 0.148271 model2 loss : 0.160416
[00:00:11.138] iteration 22429 : model1 loss : 0.113617 model2 loss : 0.117021
[00:00:11.474] iteration 22430 : model1 loss : 0.173337 model2 loss : 0.197197
[00:00:11.806] iteration 22431 : model1 loss : 0.190069 model2 loss : 0.210121
[00:00:12.139] iteration 22432 : model1 loss : 0.209974 model2 loss : 0.172922
[00:00:12.472] iteration 22433 : model1 loss : 0.178167 model2 loss : 0.199610
[00:00:12.807] iteration 22434 : model1 loss : 0.183809 model2 loss : 0.205172
[00:00:13.147] iteration 22435 : model1 loss : 0.175695 model2 loss : 0.205835
[00:00:13.481] iteration 22436 : model1 loss : 0.237908 model2 loss : 0.240711
[00:00:13.814] iteration 22437 : model1 loss : 0.093674 model2 loss : 0.116033
[00:00:14.155] iteration 22438 : model1 loss : 0.209786 model2 loss : 0.213830
[00:00:14.490] iteration 22439 : model1 loss : 0.221234 model2 loss : 0.222060
[00:00:14.823] iteration 22440 : model1 loss : 0.161975 model2 loss : 0.172964
[00:00:15.161] iteration 22441 : model1 loss : 0.203513 model2 loss : 0.245558
[00:00:15.497] iteration 22442 : model1 loss : 0.151896 model2 loss : 0.188417
[00:00:15.835] iteration 22443 : model1 loss : 0.187755 model2 loss : 0.335722
[00:00:16.174] iteration 22444 : model1 loss : 0.142089 model2 loss : 0.151804
[00:00:16.511] iteration 22445 : model1 loss : 0.184474 model2 loss : 0.236491
[00:00:16.848] iteration 22446 : model1 loss : 0.252738 model2 loss : 0.280538
[00:00:17.185] iteration 22447 : model1 loss : 0.177572 model2 loss : 0.220785
[00:00:17.522] iteration 22448 : model1 loss : 0.161281 model2 loss : 0.224167
[00:00:17.862] iteration 22449 : model1 loss : 0.175316 model2 loss : 0.260546
[00:00:18.202] iteration 22450 : model1 loss : 0.126540 model2 loss : 0.227587
[00:00:18.899] iteration 22451 : model1 loss : 0.198209 model2 loss : 0.201821
[00:00:19.238] iteration 22452 : model1 loss : 0.169359 model2 loss : 0.175602
[00:00:19.574] iteration 22453 : model1 loss : 0.177984 model2 loss : 0.199966
[00:00:19.913] iteration 22454 : model1 loss : 0.169531 model2 loss : 0.180570
[00:00:20.251] iteration 22455 : model1 loss : 0.100781 model2 loss : 0.138469
[00:00:20.590] iteration 22456 : model1 loss : 0.181599 model2 loss : 0.202664
[00:00:20.926] iteration 22457 : model1 loss : 0.177247 model2 loss : 0.172294
[00:00:21.265] iteration 22458 : model1 loss : 0.176088 model2 loss : 0.197550
[00:00:21.606] iteration 22459 : model1 loss : 0.225594 model2 loss : 0.271181
[00:00:21.943] iteration 22460 : model1 loss : 0.321928 model2 loss : 0.340944
[00:00:22.279] iteration 22461 : model1 loss : 0.185136 model2 loss : 0.182780
[00:00:22.615] iteration 22462 : model1 loss : 0.174948 model2 loss : 0.193085
[00:00:22.953] iteration 22463 : model1 loss : 0.248580 model2 loss : 0.275635
[00:00:23.293] iteration 22464 : model1 loss : 0.258525 model2 loss : 0.303754
[00:00:23.634] iteration 22465 : model1 loss : 0.095534 model2 loss : 0.134166
[00:00:23.971] iteration 22466 : model1 loss : 0.172855 model2 loss : 0.213231
[00:00:24.307] iteration 22467 : model1 loss : 0.245364 model2 loss : 0.264831
[00:00:24.642] iteration 22468 : model1 loss : 0.086099 model2 loss : 0.131821
[00:00:24.979] iteration 22469 : model1 loss : 0.250908 model2 loss : 0.269978
[00:00:25.318] iteration 22470 : model1 loss : 0.258303 model2 loss : 0.257613
[00:00:25.653] iteration 22471 : model1 loss : 0.209218 model2 loss : 0.261564
[00:00:25.993] iteration 22472 : model1 loss : 0.201086 model2 loss : 0.229981
[00:00:26.325] iteration 22473 : model1 loss : 0.089256 model2 loss : 0.120078
[00:00:26.661] iteration 22474 : model1 loss : 0.188041 model2 loss : 0.181455
[00:00:26.997] iteration 22475 : model1 loss : 0.173016 model2 loss : 0.178135
[00:00:27.328] iteration 22476 : model1 loss : 0.256371 model2 loss : 0.267056
[00:00:27.659] iteration 22477 : model1 loss : 0.264843 model2 loss : 0.285709
[00:00:27.993] iteration 22478 : model1 loss : 0.278202 model2 loss : 0.287272
[00:00:28.324] iteration 22479 : model1 loss : 0.177843 model2 loss : 0.220629
[00:00:28.661] iteration 22480 : model1 loss : 0.257140 model2 loss : 0.275901
[00:00:28.997] iteration 22481 : model1 loss : 0.316397 model2 loss : 0.323953
[00:00:29.329] iteration 22482 : model1 loss : 0.188158 model2 loss : 0.214298
[00:00:29.667] iteration 22483 : model1 loss : 0.257139 model2 loss : 0.346712
[00:00:30.002] iteration 22484 : model1 loss : 0.162571 model2 loss : 0.201749
[00:00:30.337] iteration 22485 : model1 loss : 0.129166 model2 loss : 0.120159
[00:00:30.664] iteration 22486 : model1 loss : 0.194143 model2 loss : 0.205922
[00:00:30.991] iteration 22487 : model1 loss : 0.087012 model2 loss : 0.112109
[00:00:31.318] iteration 22488 : model1 loss : 0.265688 model2 loss : 0.330110
[00:00:31.645] iteration 22489 : model1 loss : 0.108061 model2 loss : 0.154277
[00:00:31.972] iteration 22490 : model1 loss : 0.277864 model2 loss : 0.307378
[00:00:32.295] iteration 22491 : model1 loss : 0.205388 model2 loss : 0.218622
[00:00:32.622] iteration 22492 : model1 loss : 0.189077 model2 loss : 0.211761
[00:00:32.951] iteration 22493 : model1 loss : 0.190542 model2 loss : 0.210334
[00:00:33.279] iteration 22494 : model1 loss : 0.269388 model2 loss : 0.291674
[00:00:33.607] iteration 22495 : model1 loss : 0.154991 model2 loss : 0.213245
[00:00:33.933] iteration 22496 : model1 loss : 0.194248 model2 loss : 0.244601
[00:00:34.259] iteration 22497 : model1 loss : 0.257614 model2 loss : 0.265000
[00:00:34.582] iteration 22498 : model1 loss : 0.254407 model2 loss : 0.255906
[00:00:34.911] iteration 22499 : model1 loss : 0.243880 model2 loss : 0.295033
[00:00:35.239] iteration 22500 : model1 loss : 0.081041 model2 loss : 0.134903
[00:00:35.824] iteration 22501 : model1 loss : 0.181619 model2 loss : 0.179370
[00:00:36.148] iteration 22502 : model1 loss : 0.080064 model2 loss : 0.095350
[00:00:36.476] iteration 22503 : model1 loss : 0.262882 model2 loss : 0.274661
[00:00:36.802] iteration 22504 : model1 loss : 0.248204 model2 loss : 0.256730
[00:00:37.125] iteration 22505 : model1 loss : 0.184303 model2 loss : 0.188118
[00:00:37.453] iteration 22506 : model1 loss : 0.167387 model2 loss : 0.214113
[00:00:37.779] iteration 22507 : model1 loss : 0.203390 model2 loss : 0.196454
[00:00:38.107] iteration 22508 : model1 loss : 0.201657 model2 loss : 0.236911
[00:00:38.431] iteration 22509 : model1 loss : 0.254377 model2 loss : 0.257703
[00:00:38.759] iteration 22510 : model1 loss : 0.162780 model2 loss : 0.211323
[00:00:39.086] iteration 22511 : model1 loss : 0.246927 model2 loss : 0.267825
[00:00:39.413] iteration 22512 : model1 loss : 0.247085 model2 loss : 0.284486
[00:00:39.736] iteration 22513 : model1 loss : 0.240584 model2 loss : 0.364309
[00:00:40.059] iteration 22514 : model1 loss : 0.119394 model2 loss : 0.160886
[00:00:40.388] iteration 22515 : model1 loss : 0.163274 model2 loss : 0.183727
[00:00:40.716] iteration 22516 : model1 loss : 0.203052 model2 loss : 0.302115
[00:00:41.045] iteration 22517 : model1 loss : 0.287884 model2 loss : 0.289715
[00:00:41.371] iteration 22518 : model1 loss : 0.313449 model2 loss : 0.317232
[00:00:41.698] iteration 22519 : model1 loss : 0.182973 model2 loss : 0.187261
[00:00:42.024] iteration 22520 : model1 loss : 0.244290 model2 loss : 0.253270
[00:00:42.352] iteration 22521 : model1 loss : 0.248767 model2 loss : 0.297247
[00:00:42.681] iteration 22522 : model1 loss : 0.241649 model2 loss : 0.305676
[00:00:43.007] iteration 22523 : model1 loss : 0.102665 model2 loss : 0.193779
[00:00:43.335] iteration 22524 : model1 loss : 0.190492 model2 loss : 0.210917
[00:00:43.663] iteration 22525 : model1 loss : 0.103240 model2 loss : 0.128329
[00:00:43.988] iteration 22526 : model1 loss : 0.193545 model2 loss : 0.201210
[00:00:44.314] iteration 22527 : model1 loss : 0.215270 model2 loss : 0.224415
[00:00:44.636] iteration 22528 : model1 loss : 0.108452 model2 loss : 0.119031
[00:00:44.960] iteration 22529 : model1 loss : 0.263603 model2 loss : 0.306477
[00:00:45.283] iteration 22530 : model1 loss : 0.249940 model2 loss : 0.279668
[00:00:45.608] iteration 22531 : model1 loss : 0.247709 model2 loss : 0.242302
[00:00:45.934] iteration 22532 : model1 loss : 0.250062 model2 loss : 0.296696
[00:00:46.259] iteration 22533 : model1 loss : 0.167766 model2 loss : 0.180102
[00:00:46.587] iteration 22534 : model1 loss : 0.115170 model2 loss : 0.119197
[00:00:46.921] iteration 22535 : model1 loss : 0.264347 model2 loss : 0.286666
[00:00:47.249] iteration 22536 : model1 loss : 0.193786 model2 loss : 0.214218
[00:00:47.575] iteration 22537 : model1 loss : 0.242050 model2 loss : 0.233691
[00:00:47.901] iteration 22538 : model1 loss : 0.180722 model2 loss : 0.197116
[00:00:48.228] iteration 22539 : model1 loss : 0.114698 model2 loss : 0.169407
[00:00:48.551] iteration 22540 : model1 loss : 0.108149 model2 loss : 0.147628
[00:00:48.874] iteration 22541 : model1 loss : 0.167269 model2 loss : 0.192513
[00:00:49.202] iteration 22542 : model1 loss : 0.219008 model2 loss : 0.286587
[00:00:49.529] iteration 22543 : model1 loss : 0.239405 model2 loss : 0.252778
[00:00:49.855] iteration 22544 : model1 loss : 0.196758 model2 loss : 0.225601
[00:00:50.182] iteration 22545 : model1 loss : 0.177674 model2 loss : 0.190895
[00:00:50.505] iteration 22546 : model1 loss : 0.168827 model2 loss : 0.182580
[00:00:50.827] iteration 22547 : model1 loss : 0.096699 model2 loss : 0.130602
[00:00:51.150] iteration 22548 : model1 loss : 0.173982 model2 loss : 0.217691
[00:00:51.474] iteration 22549 : model1 loss : 0.221890 model2 loss : 0.229334
[00:00:51.796] iteration 22550 : model1 loss : 0.163134 model2 loss : 0.191383
[00:00:52.333] iteration 22551 : model1 loss : 0.261197 model2 loss : 0.258140
[00:00:52.658] iteration 22552 : model1 loss : 0.243098 model2 loss : 0.243512
[00:00:52.981] iteration 22553 : model1 loss : 0.144358 model2 loss : 0.154381
[00:00:53.304] iteration 22554 : model1 loss : 0.156230 model2 loss : 0.266242
[00:00:53.629] iteration 22555 : model1 loss : 0.155739 model2 loss : 0.178257
[00:00:53.957] iteration 22556 : model1 loss : 0.113039 model2 loss : 0.226136
[00:00:54.283] iteration 22557 : model1 loss : 0.155909 model2 loss : 0.242938
[00:00:54.606] iteration 22558 : model1 loss : 0.256087 model2 loss : 0.274990
[00:00:54.934] iteration 22559 : model1 loss : 0.224361 model2 loss : 0.257182
[00:00:55.260] iteration 22560 : model1 loss : 0.181224 model2 loss : 0.192789
[00:00:55.586] iteration 22561 : model1 loss : 0.143578 model2 loss : 0.154960
[00:00:55.910] iteration 22562 : model1 loss : 0.252432 model2 loss : 0.288557
[00:00:56.238] iteration 22563 : model1 loss : 0.235024 model2 loss : 0.216279
[00:00:56.563] iteration 22564 : model1 loss : 0.245681 model2 loss : 0.271070
[00:00:56.890] iteration 22565 : model1 loss : 0.184730 model2 loss : 0.160499
[00:00:57.216] iteration 22566 : model1 loss : 0.275868 model2 loss : 0.288970
[00:00:57.539] iteration 22567 : model1 loss : 0.336713 model2 loss : 0.385416
[00:00:57.863] iteration 22568 : model1 loss : 0.106566 model2 loss : 0.161317
[00:00:58.186] iteration 22569 : model1 loss : 0.247718 model2 loss : 0.254992
[00:00:58.512] iteration 22570 : model1 loss : 0.182606 model2 loss : 0.200482
[00:00:58.840] iteration 22571 : model1 loss : 0.176073 model2 loss : 0.169701
[00:00:59.168] iteration 22572 : model1 loss : 0.245895 model2 loss : 0.247856
[00:00:59.491] iteration 22573 : model1 loss : 0.233173 model2 loss : 0.246344
[00:00:59.815] iteration 22574 : model1 loss : 0.154395 model2 loss : 0.148446
[00:01:00.143] iteration 22575 : model1 loss : 0.159425 model2 loss : 0.174620
[00:01:00.468] iteration 22576 : model1 loss : 0.263287 model2 loss : 0.258821
[00:01:00.791] iteration 22577 : model1 loss : 0.169841 model2 loss : 0.222739
[00:01:01.119] iteration 22578 : model1 loss : 0.178127 model2 loss : 0.258650
[00:01:01.446] iteration 22579 : model1 loss : 0.189859 model2 loss : 0.211603
[00:01:01.773] iteration 22580 : model1 loss : 0.265929 model2 loss : 0.318250
[00:01:02.098] iteration 22581 : model1 loss : 0.106486 model2 loss : 0.140908
[00:01:02.421] iteration 22582 : model1 loss : 0.101644 model2 loss : 0.146346
[00:01:02.745] iteration 22583 : model1 loss : 0.202290 model2 loss : 0.201237
[00:01:03.076] iteration 22584 : model1 loss : 0.113416 model2 loss : 0.136116
[00:01:03.404] iteration 22585 : model1 loss : 0.273753 model2 loss : 0.295817
[00:01:03.730] iteration 22586 : model1 loss : 0.173719 model2 loss : 0.159533
[00:01:04.053] iteration 22587 : model1 loss : 0.144781 model2 loss : 0.146209
[00:01:04.377] iteration 22588 : model1 loss : 0.177761 model2 loss : 0.246632
[00:01:04.699] iteration 22589 : model1 loss : 0.251116 model2 loss : 0.254379
[00:01:05.028] iteration 22590 : model1 loss : 0.134110 model2 loss : 0.126602
[00:01:05.354] iteration 22591 : model1 loss : 0.319116 model2 loss : 0.400179
[00:01:05.678] iteration 22592 : model1 loss : 0.274216 model2 loss : 0.327787
[00:01:06.005] iteration 22593 : model1 loss : 0.085608 model2 loss : 0.109398
[00:01:06.331] iteration 22594 : model1 loss : 0.191631 model2 loss : 0.212924
[00:01:06.654] iteration 22595 : model1 loss : 0.251359 model2 loss : 0.289949
[00:01:06.981] iteration 22596 : model1 loss : 0.064449 model2 loss : 0.094648
[00:01:07.308] iteration 22597 : model1 loss : 0.131580 model2 loss : 0.190709
[00:01:07.634] iteration 22598 : model1 loss : 0.172234 model2 loss : 0.198365
[00:01:07.961] iteration 22599 : model1 loss : 0.157371 model2 loss : 0.189153
[00:01:08.283] iteration 22600 : model1 loss : 0.081806 model2 loss : 0.087641
[00:01:08.824] iteration 22601 : model1 loss : 0.123204 model2 loss : 0.175163
[00:01:09.150] iteration 22602 : model1 loss : 0.195018 model2 loss : 0.296687
[00:01:09.476] iteration 22603 : model1 loss : 0.238434 model2 loss : 0.291099
[00:01:09.801] iteration 22604 : model1 loss : 0.416031 model2 loss : 0.412818
[00:01:10.129] iteration 22605 : model1 loss : 0.159079 model2 loss : 0.195932
[00:01:10.456] iteration 22606 : model1 loss : 0.086426 model2 loss : 0.104354
[00:01:10.784] iteration 22607 : model1 loss : 0.184881 model2 loss : 0.295481
[00:01:11.109] iteration 22608 : model1 loss : 0.168512 model2 loss : 0.156615
[00:01:11.434] iteration 22609 : model1 loss : 0.083076 model2 loss : 0.117373
[00:01:11.761] iteration 22610 : model1 loss : 0.167851 model2 loss : 0.231289
[00:01:12.087] iteration 22611 : model1 loss : 0.194750 model2 loss : 0.198986
[00:01:12.411] iteration 22612 : model1 loss : 0.191529 model2 loss : 0.282060
[00:01:12.734] iteration 22613 : model1 loss : 0.163968 model2 loss : 0.219793
[00:01:13.063] iteration 22614 : model1 loss : 0.143470 model2 loss : 0.164495
[00:01:13.390] iteration 22615 : model1 loss : 0.245143 model2 loss : 0.256471
[00:01:13.718] iteration 22616 : model1 loss : 0.177433 model2 loss : 0.190892
[00:01:14.047] iteration 22617 : model1 loss : 0.312112 model2 loss : 0.318763
[00:01:14.374] iteration 22618 : model1 loss : 0.234819 model2 loss : 0.259278
[00:01:14.700] iteration 22619 : model1 loss : 0.164953 model2 loss : 0.201254
[00:01:15.027] iteration 22620 : model1 loss : 0.197623 model2 loss : 0.240038
[00:01:15.353] iteration 22621 : model1 loss : 0.078845 model2 loss : 0.103845
[00:01:15.677] iteration 22622 : model1 loss : 0.243820 model2 loss : 0.273058
[00:01:16.002] iteration 22623 : model1 loss : 0.186003 model2 loss : 0.221164
[00:01:16.330] iteration 22624 : model1 loss : 0.275116 model2 loss : 0.325972
[00:01:16.655] iteration 22625 : model1 loss : 0.264325 model2 loss : 0.291245
[00:01:16.984] iteration 22626 : model1 loss : 0.173935 model2 loss : 0.191817
[00:01:17.307] iteration 22627 : model1 loss : 0.155303 model2 loss : 0.162392
[00:01:17.632] iteration 22628 : model1 loss : 0.146511 model2 loss : 0.191299
[00:01:17.955] iteration 22629 : model1 loss : 0.145676 model2 loss : 0.163787
[00:01:18.277] iteration 22630 : model1 loss : 0.181502 model2 loss : 0.262347
[00:01:18.600] iteration 22631 : model1 loss : 0.282788 model2 loss : 0.327908
[00:01:18.930] iteration 22632 : model1 loss : 0.184727 model2 loss : 0.223949
[00:01:19.256] iteration 22633 : model1 loss : 0.257563 model2 loss : 0.288937
[00:01:19.579] iteration 22634 : model1 loss : 0.186362 model2 loss : 0.200321
[00:01:19.907] iteration 22635 : model1 loss : 0.181074 model2 loss : 0.222390
[00:01:20.231] iteration 22636 : model1 loss : 0.182636 model2 loss : 0.207520
[00:01:20.561] iteration 22637 : model1 loss : 0.256143 model2 loss : 0.293352
[00:01:20.888] iteration 22638 : model1 loss : 0.073805 model2 loss : 0.118752
[00:01:21.211] iteration 22639 : model1 loss : 0.264797 model2 loss : 0.297175
[00:01:21.539] iteration 22640 : model1 loss : 0.176283 model2 loss : 0.198798
[00:01:21.867] iteration 22641 : model1 loss : 0.321194 model2 loss : 0.329894
[00:01:22.191] iteration 22642 : model1 loss : 0.191465 model2 loss : 0.208784
[00:01:22.514] iteration 22643 : model1 loss : 0.068605 model2 loss : 0.119619
[00:01:22.836] iteration 22644 : model1 loss : 0.116789 model2 loss : 0.184055
[00:01:23.170] iteration 22645 : model1 loss : 0.244988 model2 loss : 0.273416
[00:01:23.496] iteration 22646 : model1 loss : 0.184549 model2 loss : 0.205389
[00:01:23.819] iteration 22647 : model1 loss : 0.171652 model2 loss : 0.192550
[00:01:24.143] iteration 22648 : model1 loss : 0.201136 model2 loss : 0.272714
[00:01:24.472] iteration 22649 : model1 loss : 0.163022 model2 loss : 0.194556
[00:01:24.805] iteration 22650 : model1 loss : 0.129627 model2 loss : 0.171074
[00:01:25.368] iteration 22651 : model1 loss : 0.159774 model2 loss : 0.189743
[00:01:25.693] iteration 22652 : model1 loss : 0.190195 model2 loss : 0.194181
[00:01:26.020] iteration 22653 : model1 loss : 0.164912 model2 loss : 0.219654
[00:01:26.349] iteration 22654 : model1 loss : 0.185492 model2 loss : 0.286060
[00:01:26.674] iteration 22655 : model1 loss : 0.251667 model2 loss : 0.292981
[00:01:27.003] iteration 22656 : model1 loss : 0.140060 model2 loss : 0.126073
[00:01:27.330] iteration 22657 : model1 loss : 0.082481 model2 loss : 0.130225
[00:01:27.657] iteration 22658 : model1 loss : 0.183808 model2 loss : 0.244371
[00:01:27.988] iteration 22659 : model1 loss : 0.197559 model2 loss : 0.258334
[00:01:28.318] iteration 22660 : model1 loss : 0.212078 model2 loss : 0.252687
[00:01:28.646] iteration 22661 : model1 loss : 0.347488 model2 loss : 0.353123
[00:01:28.976] iteration 22662 : model1 loss : 0.221344 model2 loss : 0.250789
[00:01:29.304] iteration 22663 : model1 loss : 0.247921 model2 loss : 0.315077
[00:01:29.631] iteration 22664 : model1 loss : 0.164613 model2 loss : 0.177391
[00:01:29.959] iteration 22665 : model1 loss : 0.305314 model2 loss : 0.406340
[00:01:30.287] iteration 22666 : model1 loss : 0.146409 model2 loss : 0.195204
[00:01:30.621] iteration 22667 : model1 loss : 0.165423 model2 loss : 0.190296
[00:01:30.949] iteration 22668 : model1 loss : 0.317584 model2 loss : 0.342825
[00:01:31.278] iteration 22669 : model1 loss : 0.129544 model2 loss : 0.125219
[00:01:31.607] iteration 22670 : model1 loss : 0.188616 model2 loss : 0.188055
[00:01:31.936] iteration 22671 : model1 loss : 0.187947 model2 loss : 0.233753
[00:01:32.263] iteration 22672 : model1 loss : 0.297603 model2 loss : 0.322166
[00:01:32.592] iteration 22673 : model1 loss : 0.276258 model2 loss : 0.300713
[00:01:32.920] iteration 22674 : model1 loss : 0.274171 model2 loss : 0.299592
[00:01:33.248] iteration 22675 : model1 loss : 0.113415 model2 loss : 0.128071
[00:01:33.576] iteration 22676 : model1 loss : 0.354894 model2 loss : 0.377847
[00:01:33.905] iteration 22677 : model1 loss : 0.233752 model2 loss : 0.272817
[00:01:34.235] iteration 22678 : model1 loss : 0.176689 model2 loss : 0.206247
[00:01:34.564] iteration 22679 : model1 loss : 0.163403 model2 loss : 0.222451
[00:01:34.891] iteration 22680 : model1 loss : 0.197360 model2 loss : 0.268703
[00:01:35.219] iteration 22681 : model1 loss : 0.188185 model2 loss : 0.232790
[00:01:35.548] iteration 22682 : model1 loss : 0.169768 model2 loss : 0.169636
[00:01:35.875] iteration 22683 : model1 loss : 0.228557 model2 loss : 0.249114
[00:01:36.204] iteration 22684 : model1 loss : 0.164563 model2 loss : 0.208886
[00:01:36.532] iteration 22685 : model1 loss : 0.253306 model2 loss : 0.275916
[00:01:36.860] iteration 22686 : model1 loss : 0.191286 model2 loss : 0.194159
[00:01:37.190] iteration 22687 : model1 loss : 0.166007 model2 loss : 0.217911
[00:01:37.517] iteration 22688 : model1 loss : 0.156129 model2 loss : 0.131475
[00:01:37.845] iteration 22689 : model1 loss : 0.104920 model2 loss : 0.100985
[00:01:38.173] iteration 22690 : model1 loss : 0.332699 model2 loss : 0.298712
[00:01:38.501] iteration 22691 : model1 loss : 0.184717 model2 loss : 0.237817
[00:01:38.829] iteration 22692 : model1 loss : 0.167709 model2 loss : 0.212797
[00:01:39.157] iteration 22693 : model1 loss : 0.202327 model2 loss : 0.210756
[00:01:39.486] iteration 22694 : model1 loss : 0.305968 model2 loss : 0.410646
[00:01:39.814] iteration 22695 : model1 loss : 0.234158 model2 loss : 0.248789
[00:01:40.142] iteration 22696 : model1 loss : 0.219956 model2 loss : 0.256338
[00:01:40.470] iteration 22697 : model1 loss : 0.169492 model2 loss : 0.191655
[00:01:40.798] iteration 22698 : model1 loss : 0.183077 model2 loss : 0.206384
[00:01:41.126] iteration 22699 : model1 loss : 0.166518 model2 loss : 0.199937
[00:01:41.454] iteration 22700 : model1 loss : 0.208450 model2 loss : 0.204149
[00:01:42.021] iteration 22701 : model1 loss : 0.257985 model2 loss : 0.270515
[00:01:42.349] iteration 22702 : model1 loss : 0.091931 model2 loss : 0.127640
[00:01:42.679] iteration 22703 : model1 loss : 0.250728 model2 loss : 0.245196
[00:01:43.007] iteration 22704 : model1 loss : 0.113835 model2 loss : 0.165617
[00:01:43.336] iteration 22705 : model1 loss : 0.227481 model2 loss : 0.227963
[00:01:43.664] iteration 22706 : model1 loss : 0.223294 model2 loss : 0.249095
[00:01:43.992] iteration 22707 : model1 loss : 0.181259 model2 loss : 0.203058
[00:01:44.320] iteration 22708 : model1 loss : 0.192356 model2 loss : 0.240570
[00:01:44.649] iteration 22709 : model1 loss : 0.095032 model2 loss : 0.168253
[00:01:44.977] iteration 22710 : model1 loss : 0.149616 model2 loss : 0.116226
[00:01:45.306] iteration 22711 : model1 loss : 0.221712 model2 loss : 0.261760
[00:01:45.634] iteration 22712 : model1 loss : 0.183042 model2 loss : 0.197331
[00:01:45.963] iteration 22713 : model1 loss : 0.125821 model2 loss : 0.226482
[00:01:46.292] iteration 22714 : model1 loss : 0.236912 model2 loss : 0.258747
[00:01:46.622] iteration 22715 : model1 loss : 0.098844 model2 loss : 0.128187
[00:01:46.952] iteration 22716 : model1 loss : 0.166972 model2 loss : 0.309309
[00:01:47.282] iteration 22717 : model1 loss : 0.165853 model2 loss : 0.214362
[00:01:47.610] iteration 22718 : model1 loss : 0.103602 model2 loss : 0.143054
[00:01:47.939] iteration 22719 : model1 loss : 0.202691 model2 loss : 0.248884
[00:01:48.267] iteration 22720 : model1 loss : 0.228443 model2 loss : 0.236329
[00:01:48.595] iteration 22721 : model1 loss : 0.170010 model2 loss : 0.234758
[00:01:48.925] iteration 22722 : model1 loss : 0.091622 model2 loss : 0.217259
[00:01:49.254] iteration 22723 : model1 loss : 0.224112 model2 loss : 0.251796
[00:01:49.583] iteration 22724 : model1 loss : 0.162993 model2 loss : 0.186202
[00:01:49.912] iteration 22725 : model1 loss : 0.191900 model2 loss : 0.241623
[00:01:50.241] iteration 22726 : model1 loss : 0.200554 model2 loss : 0.262827
[00:01:50.572] iteration 22727 : model1 loss : 0.162289 model2 loss : 0.185670
[00:01:50.900] iteration 22728 : model1 loss : 0.259175 model2 loss : 0.273210
[00:01:51.230] iteration 22729 : model1 loss : 0.091959 model2 loss : 0.094508
[00:01:51.560] iteration 22730 : model1 loss : 0.086949 model2 loss : 0.179272
[00:01:51.896] iteration 22731 : model1 loss : 0.254542 model2 loss : 0.267246
[00:01:52.224] iteration 22732 : model1 loss : 0.281751 model2 loss : 0.310850
[00:01:52.557] iteration 22733 : model1 loss : 0.117130 model2 loss : 0.130567
[00:01:52.885] iteration 22734 : model1 loss : 0.164302 model2 loss : 0.177413
[00:01:53.213] iteration 22735 : model1 loss : 0.124310 model2 loss : 0.167426
[00:01:53.542] iteration 22736 : model1 loss : 0.161388 model2 loss : 0.234105
[00:01:53.870] iteration 22737 : model1 loss : 0.158018 model2 loss : 0.213464
[00:01:54.197] iteration 22738 : model1 loss : 0.236513 model2 loss : 0.324368
[00:01:54.527] iteration 22739 : model1 loss : 0.183568 model2 loss : 0.208440
[00:01:54.856] iteration 22740 : model1 loss : 0.153850 model2 loss : 0.206594
[00:01:55.184] iteration 22741 : model1 loss : 0.094498 model2 loss : 0.157933
[00:01:55.513] iteration 22742 : model1 loss : 0.160008 model2 loss : 0.280731
[00:01:55.845] iteration 22743 : model1 loss : 0.173224 model2 loss : 0.225849
[00:01:56.173] iteration 22744 : model1 loss : 0.263257 model2 loss : 0.305221
[00:01:56.501] iteration 22745 : model1 loss : 0.326905 model2 loss : 0.359583
[00:01:56.835] iteration 22746 : model1 loss : 0.164960 model2 loss : 0.164192
[00:01:57.163] iteration 22747 : model1 loss : 0.217447 model2 loss : 0.243546
[00:01:57.491] iteration 22748 : model1 loss : 0.228691 model2 loss : 0.192130
[00:01:57.820] iteration 22749 : model1 loss : 0.176944 model2 loss : 0.208808
[00:01:58.147] iteration 22750 : model1 loss : 0.130744 model2 loss : 0.198910
[00:01:58.703] iteration 22751 : model1 loss : 0.214702 model2 loss : 0.193542
[00:01:59.030] iteration 22752 : model1 loss : 0.123464 model2 loss : 0.154776
[00:01:59.358] iteration 22753 : model1 loss : 0.123174 model2 loss : 0.133415
[00:01:59.687] iteration 22754 : model1 loss : 0.177470 model2 loss : 0.233678
[00:02:00.016] iteration 22755 : model1 loss : 0.215467 model2 loss : 0.291370
[00:02:00.346] iteration 22756 : model1 loss : 0.182586 model2 loss : 0.214253
[00:02:00.675] iteration 22757 : model1 loss : 0.077808 model2 loss : 0.125821
[00:02:01.003] iteration 22758 : model1 loss : 0.066754 model2 loss : 0.093180
[00:02:01.334] iteration 22759 : model1 loss : 0.136442 model2 loss : 0.165501
[00:02:01.663] iteration 22760 : model1 loss : 0.182470 model2 loss : 0.209583
[00:02:01.993] iteration 22761 : model1 loss : 0.154390 model2 loss : 0.195016
[00:02:02.322] iteration 22762 : model1 loss : 0.168139 model2 loss : 0.244244
[00:02:02.653] iteration 22763 : model1 loss : 0.175299 model2 loss : 0.192802
[00:02:02.983] iteration 22764 : model1 loss : 0.288044 model2 loss : 0.321702
[00:02:03.313] iteration 22765 : model1 loss : 0.245237 model2 loss : 0.245369
[00:02:03.642] iteration 22766 : model1 loss : 0.196994 model2 loss : 0.211542
[00:02:03.971] iteration 22767 : model1 loss : 0.334079 model2 loss : 0.355051
[00:02:04.300] iteration 22768 : model1 loss : 0.175553 model2 loss : 0.198215
[00:02:04.630] iteration 22769 : model1 loss : 0.147902 model2 loss : 0.168954
[00:02:04.957] iteration 22770 : model1 loss : 0.074370 model2 loss : 0.155790
[00:02:05.286] iteration 22771 : model1 loss : 0.212841 model2 loss : 0.279211
[00:02:05.614] iteration 22772 : model1 loss : 0.119430 model2 loss : 0.093503
[00:02:05.943] iteration 22773 : model1 loss : 0.181025 model2 loss : 0.184340
[00:02:06.273] iteration 22774 : model1 loss : 0.114129 model2 loss : 0.177197
[00:02:06.603] iteration 22775 : model1 loss : 0.174784 model2 loss : 0.217549
[00:02:06.933] iteration 22776 : model1 loss : 0.177293 model2 loss : 0.178104
[00:02:07.263] iteration 22777 : model1 loss : 0.173354 model2 loss : 0.186282
[00:02:07.591] iteration 22778 : model1 loss : 0.243631 model2 loss : 0.277279
[00:02:07.920] iteration 22779 : model1 loss : 0.203477 model2 loss : 0.242922
[00:02:08.252] iteration 22780 : model1 loss : 0.143978 model2 loss : 0.142134
[00:02:08.580] iteration 22781 : model1 loss : 0.196504 model2 loss : 0.223208
[00:02:08.909] iteration 22782 : model1 loss : 0.183869 model2 loss : 0.177235
[00:02:09.237] iteration 22783 : model1 loss : 0.165166 model2 loss : 0.173947
[00:02:09.565] iteration 22784 : model1 loss : 0.205065 model2 loss : 0.201151
[00:02:09.895] iteration 22785 : model1 loss : 0.151819 model2 loss : 0.173748
[00:02:10.224] iteration 22786 : model1 loss : 0.136667 model2 loss : 0.157423
[00:02:10.552] iteration 22787 : model1 loss : 0.099324 model2 loss : 0.117336
[00:02:10.881] iteration 22788 : model1 loss : 0.185711 model2 loss : 0.252942
[00:02:11.209] iteration 22789 : model1 loss : 0.226815 model2 loss : 0.247936
[00:02:11.538] iteration 22790 : model1 loss : 0.099923 model2 loss : 0.142360
[00:02:11.877] iteration 22791 : model1 loss : 0.251306 model2 loss : 0.269562
[00:02:12.211] iteration 22792 : model1 loss : 0.163366 model2 loss : 0.232373
[00:02:12.541] iteration 22793 : model1 loss : 0.159768 model2 loss : 0.193156
[00:02:12.870] iteration 22794 : model1 loss : 0.148497 model2 loss : 0.161685
[00:02:13.198] iteration 22795 : model1 loss : 0.317446 model2 loss : 0.416810
[00:02:13.526] iteration 22796 : model1 loss : 0.232733 model2 loss : 0.248980
[00:02:13.854] iteration 22797 : model1 loss : 0.260354 model2 loss : 0.305381
[00:02:14.183] iteration 22798 : model1 loss : 0.294389 model2 loss : 0.270001
[00:02:14.511] iteration 22799 : model1 loss : 0.147705 model2 loss : 0.188079
[00:02:14.840] iteration 22800 : model1 loss : 0.293761 model2 loss : 0.296768
[00:02:15.378] iteration 22801 : model1 loss : 0.230866 model2 loss : 0.252026
[00:02:15.707] iteration 22802 : model1 loss : 0.125236 model2 loss : 0.155043
[00:02:16.034] iteration 22803 : model1 loss : 0.232849 model2 loss : 0.344746
[00:02:16.369] iteration 22804 : model1 loss : 0.183065 model2 loss : 0.224194
[00:02:16.697] iteration 22805 : model1 loss : 0.258032 model2 loss : 0.305467
[00:02:17.027] iteration 22806 : model1 loss : 0.257321 model2 loss : 0.311163
[00:02:17.355] iteration 22807 : model1 loss : 0.158570 model2 loss : 0.179233
[00:02:17.689] iteration 22808 : model1 loss : 0.099392 model2 loss : 0.170530
[00:02:18.017] iteration 22809 : model1 loss : 0.161919 model2 loss : 0.190156
[00:02:18.347] iteration 22810 : model1 loss : 0.193201 model2 loss : 0.208049
[00:02:18.675] iteration 22811 : model1 loss : 0.263575 model2 loss : 0.296048
[00:02:19.003] iteration 22812 : model1 loss : 0.095625 model2 loss : 0.106150
[00:02:19.330] iteration 22813 : model1 loss : 0.251455 model2 loss : 0.263231
[00:02:19.658] iteration 22814 : model1 loss : 0.237880 model2 loss : 0.292433
[00:02:19.986] iteration 22815 : model1 loss : 0.175647 model2 loss : 0.183192
[00:02:20.325] iteration 22816 : model1 loss : 0.256103 model2 loss : 0.289506
[00:02:20.656] iteration 22817 : model1 loss : 0.156919 model2 loss : 0.137395
[00:02:20.984] iteration 22818 : model1 loss : 0.254937 model2 loss : 0.218981
[00:02:21.312] iteration 22819 : model1 loss : 0.147053 model2 loss : 0.158590
[00:02:21.640] iteration 22820 : model1 loss : 0.308393 model2 loss : 0.315388
[00:02:21.968] iteration 22821 : model1 loss : 0.249798 model2 loss : 0.307036
[00:02:22.297] iteration 22822 : model1 loss : 0.164900 model2 loss : 0.196789
[00:02:22.626] iteration 22823 : model1 loss : 0.180122 model2 loss : 0.222106
[00:02:22.957] iteration 22824 : model1 loss : 0.189486 model2 loss : 0.238658
[00:02:23.287] iteration 22825 : model1 loss : 0.180956 model2 loss : 0.242969
[00:02:23.617] iteration 22826 : model1 loss : 0.285470 model2 loss : 0.323543
[00:02:23.943] iteration 22827 : model1 loss : 0.176104 model2 loss : 0.193277
[00:02:24.269] iteration 22828 : model1 loss : 0.182193 model2 loss : 0.201319
[00:02:24.592] iteration 22829 : model1 loss : 0.105580 model2 loss : 0.096910
[00:02:24.918] iteration 22830 : model1 loss : 0.070745 model2 loss : 0.100590
[00:02:25.247] iteration 22831 : model1 loss : 0.264975 model2 loss : 0.295439
[00:02:25.573] iteration 22832 : model1 loss : 0.180115 model2 loss : 0.193579
[00:02:25.899] iteration 22833 : model1 loss : 0.188896 model2 loss : 0.234153
[00:02:26.222] iteration 22834 : model1 loss : 0.176471 model2 loss : 0.193659
[00:02:26.554] iteration 22835 : model1 loss : 0.314416 model2 loss : 0.350865
[00:02:26.882] iteration 22836 : model1 loss : 0.267060 model2 loss : 0.302547
[00:02:27.208] iteration 22837 : model1 loss : 0.159045 model2 loss : 0.262176
[00:02:27.531] iteration 22838 : model1 loss : 0.239469 model2 loss : 0.285253
[00:02:27.859] iteration 22839 : model1 loss : 0.074894 model2 loss : 0.101739
[00:02:28.184] iteration 22840 : model1 loss : 0.183647 model2 loss : 0.184537
[00:02:28.513] iteration 22841 : model1 loss : 0.194553 model2 loss : 0.239276
[00:02:28.840] iteration 22842 : model1 loss : 0.173706 model2 loss : 0.239979
[00:02:29.162] iteration 22843 : model1 loss : 0.245384 model2 loss : 0.286108
[00:02:29.490] iteration 22844 : model1 loss : 0.215142 model2 loss : 0.232798
[00:02:29.817] iteration 22845 : model1 loss : 0.165728 model2 loss : 0.209051
[00:02:30.142] iteration 22846 : model1 loss : 0.177316 model2 loss : 0.217773
[00:02:30.466] iteration 22847 : model1 loss : 0.083087 model2 loss : 0.132392
[00:02:30.796] iteration 22848 : model1 loss : 0.250110 model2 loss : 0.257438
[00:02:31.122] iteration 22849 : model1 loss : 0.255479 model2 loss : 0.279202
[00:02:31.448] iteration 22850 : model1 loss : 0.120737 model2 loss : 0.177694
[00:02:31.993] iteration 22851 : model1 loss : 0.245677 model2 loss : 0.261494
[00:02:32.320] iteration 22852 : model1 loss : 0.117992 model2 loss : 0.126577
[00:02:32.643] iteration 22853 : model1 loss : 0.103411 model2 loss : 0.077909
[00:02:32.971] iteration 22854 : model1 loss : 0.082611 model2 loss : 0.164411
[00:02:33.296] iteration 22855 : model1 loss : 0.207538 model2 loss : 0.200227
[00:02:33.624] iteration 22856 : model1 loss : 0.097598 model2 loss : 0.144304
[00:02:33.950] iteration 22857 : model1 loss : 0.174246 model2 loss : 0.227103
[00:02:34.276] iteration 22858 : model1 loss : 0.170170 model2 loss : 0.197115
[00:02:34.602] iteration 22859 : model1 loss : 0.163525 model2 loss : 0.209456
[00:02:34.927] iteration 22860 : model1 loss : 0.255286 model2 loss : 0.261591
[00:02:35.255] iteration 22861 : model1 loss : 0.151678 model2 loss : 0.165709
[00:02:35.583] iteration 22862 : model1 loss : 0.130366 model2 loss : 0.206413
[00:02:35.911] iteration 22863 : model1 loss : 0.097276 model2 loss : 0.164437
[00:02:36.238] iteration 22864 : model1 loss : 0.188609 model2 loss : 0.224468
[00:02:36.565] iteration 22865 : model1 loss : 0.192522 model2 loss : 0.291513
[00:02:36.894] iteration 22866 : model1 loss : 0.100289 model2 loss : 0.127913
[00:02:37.220] iteration 22867 : model1 loss : 0.109842 model2 loss : 0.131152
[00:02:37.547] iteration 22868 : model1 loss : 0.237175 model2 loss : 0.271799
[00:02:37.873] iteration 22869 : model1 loss : 0.249021 model2 loss : 0.258810
[00:02:38.200] iteration 22870 : model1 loss : 0.166769 model2 loss : 0.183634
[00:02:38.535] iteration 22871 : model1 loss : 0.170361 model2 loss : 0.180074
[00:02:38.863] iteration 22872 : model1 loss : 0.195346 model2 loss : 0.183312
[00:02:39.191] iteration 22873 : model1 loss : 0.211392 model2 loss : 0.261794
[00:02:39.518] iteration 22874 : model1 loss : 0.256568 model2 loss : 0.271675
[00:02:39.846] iteration 22875 : model1 loss : 0.242472 model2 loss : 0.273214
[00:02:40.174] iteration 22876 : model1 loss : 0.254692 model2 loss : 0.295055
[00:02:40.501] iteration 22877 : model1 loss : 0.281252 model2 loss : 0.285334
[00:02:40.827] iteration 22878 : model1 loss : 0.147318 model2 loss : 0.191329
[00:02:41.154] iteration 22879 : model1 loss : 0.178045 model2 loss : 0.255840
[00:02:41.478] iteration 22880 : model1 loss : 0.070188 model2 loss : 0.132918
[00:02:41.801] iteration 22881 : model1 loss : 0.264468 model2 loss : 0.307400
[00:02:42.128] iteration 22882 : model1 loss : 0.249818 model2 loss : 0.275221
[00:02:42.457] iteration 22883 : model1 loss : 0.255317 model2 loss : 0.271412
[00:02:42.782] iteration 22884 : model1 loss : 0.177935 model2 loss : 0.170632
[00:02:43.104] iteration 22885 : model1 loss : 0.249545 model2 loss : 0.292005
[00:02:43.432] iteration 22886 : model1 loss : 0.324795 model2 loss : 0.330639
[00:02:43.757] iteration 22887 : model1 loss : 0.364732 model2 loss : 0.427665
[00:02:44.079] iteration 22888 : model1 loss : 0.232222 model2 loss : 0.262098
[00:02:44.407] iteration 22889 : model1 loss : 0.077418 model2 loss : 0.130334
[00:02:44.733] iteration 22890 : model1 loss : 0.172684 model2 loss : 0.247260
[00:02:45.736] iteration 22891 : model1 loss : 0.157302 model2 loss : 0.177120
[00:02:46.059] iteration 22892 : model1 loss : 0.170779 model2 loss : 0.197933
[00:02:46.388] iteration 22893 : model1 loss : 0.099919 model2 loss : 0.183347
[00:02:46.714] iteration 22894 : model1 loss : 0.168189 model2 loss : 0.193750
[00:02:47.047] iteration 22895 : model1 loss : 0.181328 model2 loss : 0.217042
[00:02:47.374] iteration 22896 : model1 loss : 0.135411 model2 loss : 0.161866
[00:02:47.702] iteration 22897 : model1 loss : 0.183036 model2 loss : 0.211839
[00:02:48.029] iteration 22898 : model1 loss : 0.212570 model2 loss : 0.193750
[00:02:48.358] iteration 22899 : model1 loss : 0.078690 model2 loss : 0.121395
[00:02:48.686] iteration 22900 : model1 loss : 0.246328 model2 loss : 0.279223
[00:02:49.247] iteration 22901 : model1 loss : 0.186312 model2 loss : 0.244705
[00:02:49.574] iteration 22902 : model1 loss : 0.186494 model2 loss : 0.203208
[00:02:49.902] iteration 22903 : model1 loss : 0.174033 model2 loss : 0.189022
[00:02:50.230] iteration 22904 : model1 loss : 0.174981 model2 loss : 0.244358
[00:02:50.558] iteration 22905 : model1 loss : 0.173728 model2 loss : 0.220560
[00:02:50.885] iteration 22906 : model1 loss : 0.166525 model2 loss : 0.205726
[00:02:51.214] iteration 22907 : model1 loss : 0.139982 model2 loss : 0.172978
[00:02:51.545] iteration 22908 : model1 loss : 0.210551 model2 loss : 0.297593
[00:02:51.873] iteration 22909 : model1 loss : 0.184826 model2 loss : 0.209981
[00:02:52.202] iteration 22910 : model1 loss : 0.143212 model2 loss : 0.158755
[00:02:52.530] iteration 22911 : model1 loss : 0.115974 model2 loss : 0.166615
[00:02:52.858] iteration 22912 : model1 loss : 0.120524 model2 loss : 0.153369
[00:02:53.187] iteration 22913 : model1 loss : 0.253126 model2 loss : 0.275552
[00:02:53.515] iteration 22914 : model1 loss : 0.086998 model2 loss : 0.107282
[00:02:53.843] iteration 22915 : model1 loss : 0.152696 model2 loss : 0.196226
[00:02:54.170] iteration 22916 : model1 loss : 0.248570 model2 loss : 0.269824
[00:02:54.499] iteration 22917 : model1 loss : 0.170366 model2 loss : 0.228717
[00:02:54.826] iteration 22918 : model1 loss : 0.097174 model2 loss : 0.149413
[00:02:55.153] iteration 22919 : model1 loss : 0.186807 model2 loss : 0.305345
[00:02:55.482] iteration 22920 : model1 loss : 0.187359 model2 loss : 0.235233
[00:02:55.810] iteration 22921 : model1 loss : 0.250519 model2 loss : 0.293093
[00:02:56.138] iteration 22922 : model1 loss : 0.228574 model2 loss : 0.225208
[00:02:56.465] iteration 22923 : model1 loss : 0.225935 model2 loss : 0.164633
[00:02:56.793] iteration 22924 : model1 loss : 0.212633 model2 loss : 0.326216
[00:02:57.121] iteration 22925 : model1 loss : 0.321329 model2 loss : 0.350080
[00:02:57.449] iteration 22926 : model1 loss : 0.163210 model2 loss : 0.204137
[00:02:57.777] iteration 22927 : model1 loss : 0.101143 model2 loss : 0.126610
[00:02:58.108] iteration 22928 : model1 loss : 0.175808 model2 loss : 0.228818
[00:02:58.437] iteration 22929 : model1 loss : 0.204445 model2 loss : 0.222903
[00:02:58.764] iteration 22930 : model1 loss : 0.173173 model2 loss : 0.248620
[00:02:59.095] iteration 22931 : model1 loss : 0.266778 model2 loss : 0.262675
[00:02:59.423] iteration 22932 : model1 loss : 0.192669 model2 loss : 0.232529
[00:02:59.751] iteration 22933 : model1 loss : 0.271050 model2 loss : 0.293967
[00:03:00.079] iteration 22934 : model1 loss : 0.193450 model2 loss : 0.221212
[00:03:00.407] iteration 22935 : model1 loss : 0.204123 model2 loss : 0.254567
[00:03:00.735] iteration 22936 : model1 loss : 0.250547 model2 loss : 0.306093
[00:03:01.063] iteration 22937 : model1 loss : 0.140075 model2 loss : 0.122565
[00:03:01.391] iteration 22938 : model1 loss : 0.214601 model2 loss : 0.238248
[00:03:01.718] iteration 22939 : model1 loss : 0.251268 model2 loss : 0.278398
[00:03:02.048] iteration 22940 : model1 loss : 0.346603 model2 loss : 0.405062
[00:03:02.376] iteration 22941 : model1 loss : 0.358955 model2 loss : 0.372854
[00:03:02.704] iteration 22942 : model1 loss : 0.294255 model2 loss : 0.306083
[00:03:03.032] iteration 22943 : model1 loss : 0.245458 model2 loss : 0.255033
[00:03:03.359] iteration 22944 : model1 loss : 0.283151 model2 loss : 0.316567
[00:03:03.687] iteration 22945 : model1 loss : 0.183993 model2 loss : 0.204486
[00:03:04.015] iteration 22946 : model1 loss : 0.240811 model2 loss : 0.293059
[00:03:04.342] iteration 22947 : model1 loss : 0.216976 model2 loss : 0.234462
[00:03:04.670] iteration 22948 : model1 loss : 0.221428 model2 loss : 0.217083
[00:03:04.997] iteration 22949 : model1 loss : 0.175336 model2 loss : 0.193325
[00:03:05.324] iteration 22950 : model1 loss : 0.341789 model2 loss : 0.299735
[00:03:05.853] iteration 22951 : model1 loss : 0.111016 model2 loss : 0.257664
[00:03:06.183] iteration 22952 : model1 loss : 0.201179 model2 loss : 0.265491
[00:03:06.510] iteration 22953 : model1 loss : 0.131065 model2 loss : 0.117924
[00:03:06.836] iteration 22954 : model1 loss : 0.273068 model2 loss : 0.265386
[00:03:07.161] iteration 22955 : model1 loss : 0.177725 model2 loss : 0.186210
[00:03:07.487] iteration 22956 : model1 loss : 0.094846 model2 loss : 0.147370
[00:03:07.827] iteration 22957 : model1 loss : 0.181312 model2 loss : 0.193797
[00:03:08.163] iteration 22958 : model1 loss : 0.167825 model2 loss : 0.188805
[00:03:08.499] iteration 22959 : model1 loss : 0.269925 model2 loss : 0.291470
[00:03:08.835] iteration 22960 : model1 loss : 0.094093 model2 loss : 0.137516
[00:03:09.171] iteration 22961 : model1 loss : 0.169750 model2 loss : 0.203718
[00:03:09.506] iteration 22962 : model1 loss : 0.086020 model2 loss : 0.204246
[00:03:09.843] iteration 22963 : model1 loss : 0.252602 model2 loss : 0.269284
[00:03:10.178] iteration 22964 : model1 loss : 0.271212 model2 loss : 0.290603
[00:03:10.515] iteration 22965 : model1 loss : 0.262745 model2 loss : 0.290527
[00:03:10.851] iteration 22966 : model1 loss : 0.233787 model2 loss : 0.257718
[00:03:11.186] iteration 22967 : model1 loss : 0.260203 model2 loss : 0.269173
[00:03:11.522] iteration 22968 : model1 loss : 0.157250 model2 loss : 0.188549
[00:03:11.859] iteration 22969 : model1 loss : 0.189674 model2 loss : 0.236116
[00:03:12.194] iteration 22970 : model1 loss : 0.248742 model2 loss : 0.283160
[00:03:12.530] iteration 22971 : model1 loss : 0.211589 model2 loss : 0.227983
[00:03:12.867] iteration 22972 : model1 loss : 0.271370 model2 loss : 0.298214
[00:03:13.202] iteration 22973 : model1 loss : 0.169266 model2 loss : 0.204454
[00:03:13.538] iteration 22974 : model1 loss : 0.081973 model2 loss : 0.128036
[00:03:13.874] iteration 22975 : model1 loss : 0.098983 model2 loss : 0.133104
[00:03:14.210] iteration 22976 : model1 loss : 0.232916 model2 loss : 0.247869
[00:03:14.546] iteration 22977 : model1 loss : 0.177145 model2 loss : 0.236903
[00:03:14.883] iteration 22978 : model1 loss : 0.203895 model2 loss : 0.235746
[00:03:15.218] iteration 22979 : model1 loss : 0.260877 model2 loss : 0.259643
[00:03:15.555] iteration 22980 : model1 loss : 0.105521 model2 loss : 0.144367
[00:03:15.891] iteration 22981 : model1 loss : 0.166683 model2 loss : 0.178036
[00:03:16.227] iteration 22982 : model1 loss : 0.171484 model2 loss : 0.201272
[00:03:16.563] iteration 22983 : model1 loss : 0.080153 model2 loss : 0.117363
[00:03:16.899] iteration 22984 : model1 loss : 0.257914 model2 loss : 0.360760
[00:03:17.236] iteration 22985 : model1 loss : 0.174090 model2 loss : 0.169746
[00:03:17.572] iteration 22986 : model1 loss : 0.242419 model2 loss : 0.277758
[00:03:17.908] iteration 22987 : model1 loss : 0.295275 model2 loss : 0.386042
[00:03:18.244] iteration 22988 : model1 loss : 0.099949 model2 loss : 0.137390
[00:03:18.580] iteration 22989 : model1 loss : 0.173015 model2 loss : 0.165479
[00:03:18.918] iteration 22990 : model1 loss : 0.241220 model2 loss : 0.303705
[00:03:19.255] iteration 22991 : model1 loss : 0.160728 model2 loss : 0.179455
[00:03:19.592] iteration 22992 : model1 loss : 0.206196 model2 loss : 0.230276
[00:03:19.930] iteration 22993 : model1 loss : 0.270320 model2 loss : 0.342112
[00:03:20.267] iteration 22994 : model1 loss : 0.252657 model2 loss : 0.266118
[00:03:20.603] iteration 22995 : model1 loss : 0.111584 model2 loss : 0.122305
[00:03:20.940] iteration 22996 : model1 loss : 0.193442 model2 loss : 0.218370
[00:03:21.280] iteration 22997 : model1 loss : 0.193899 model2 loss : 0.273319
[00:03:21.616] iteration 22998 : model1 loss : 0.283008 model2 loss : 0.317839
[00:03:21.952] iteration 22999 : model1 loss : 0.231675 model2 loss : 0.229458
[00:03:22.288] iteration 23000 : model1 loss : 0.152773 model2 loss : 0.153033
[00:03:22.896] iteration 23001 : model1 loss : 0.116625 model2 loss : 0.193115
[00:03:23.232] iteration 23002 : model1 loss : 0.258182 model2 loss : 0.229489
[00:03:23.569] iteration 23003 : model1 loss : 0.173477 model2 loss : 0.216610
[00:03:23.905] iteration 23004 : model1 loss : 0.184356 model2 loss : 0.190544
[00:03:24.241] iteration 23005 : model1 loss : 0.108588 model2 loss : 0.146399
[00:03:24.577] iteration 23006 : model1 loss : 0.305486 model2 loss : 0.406666
[00:03:24.913] iteration 23007 : model1 loss : 0.112996 model2 loss : 0.246323
[00:03:25.248] iteration 23008 : model1 loss : 0.170521 model2 loss : 0.164639
[00:03:25.585] iteration 23009 : model1 loss : 0.158454 model2 loss : 0.157435
[00:03:25.921] iteration 23010 : model1 loss : 0.077724 model2 loss : 0.116448
[00:03:26.257] iteration 23011 : model1 loss : 0.175700 model2 loss : 0.221459
[00:03:26.593] iteration 23012 : model1 loss : 0.097183 model2 loss : 0.238586
[00:03:26.929] iteration 23013 : model1 loss : 0.073673 model2 loss : 0.133496
[00:03:27.265] iteration 23014 : model1 loss : 0.108995 model2 loss : 0.142497
[00:03:27.600] iteration 23015 : model1 loss : 0.142165 model2 loss : 0.164638
[00:03:27.937] iteration 23016 : model1 loss : 0.164988 model2 loss : 0.204344
[00:03:28.273] iteration 23017 : model1 loss : 0.179103 model2 loss : 0.179563
[00:03:28.609] iteration 23018 : model1 loss : 0.176320 model2 loss : 0.190463
[00:03:28.945] iteration 23019 : model1 loss : 0.122603 model2 loss : 0.179029
[00:03:29.281] iteration 23020 : model1 loss : 0.165178 model2 loss : 0.162612
[00:03:29.617] iteration 23021 : model1 loss : 0.177416 model2 loss : 0.219932
[00:03:29.953] iteration 23022 : model1 loss : 0.134301 model2 loss : 0.249643
[00:03:30.292] iteration 23023 : model1 loss : 0.197108 model2 loss : 0.329472
[00:03:30.632] iteration 23024 : model1 loss : 0.189458 model2 loss : 0.220656
[00:03:30.969] iteration 23025 : model1 loss : 0.167571 model2 loss : 0.168847
[00:03:31.305] iteration 23026 : model1 loss : 0.266288 model2 loss : 0.308216
[00:03:31.641] iteration 23027 : model1 loss : 0.214806 model2 loss : 0.211090
[00:03:31.978] iteration 23028 : model1 loss : 0.185121 model2 loss : 0.217153
[00:03:32.314] iteration 23029 : model1 loss : 0.151752 model2 loss : 0.199917
[00:03:32.650] iteration 23030 : model1 loss : 0.163814 model2 loss : 0.178478
[00:03:32.985] iteration 23031 : model1 loss : 0.192709 model2 loss : 0.202015
[00:03:33.321] iteration 23032 : model1 loss : 0.248697 model2 loss : 0.299839
[00:03:33.658] iteration 23033 : model1 loss : 0.171898 model2 loss : 0.244344
[00:03:33.994] iteration 23034 : model1 loss : 0.149466 model2 loss : 0.181167
[00:03:34.329] iteration 23035 : model1 loss : 0.137443 model2 loss : 0.242171
[00:03:34.666] iteration 23036 : model1 loss : 0.141087 model2 loss : 0.204838
[00:03:35.002] iteration 23037 : model1 loss : 0.162055 model2 loss : 0.199306
[00:03:35.338] iteration 23038 : model1 loss : 0.267412 model2 loss : 0.269362
[00:03:35.674] iteration 23039 : model1 loss : 0.259766 model2 loss : 0.287942
[00:03:36.010] iteration 23040 : model1 loss : 0.131856 model2 loss : 0.261666
[00:03:36.346] iteration 23041 : model1 loss : 0.084935 model2 loss : 0.119901
[00:03:36.682] iteration 23042 : model1 loss : 0.225764 model2 loss : 0.256141
[00:03:37.018] iteration 23043 : model1 loss : 0.134516 model2 loss : 0.192166
[00:03:37.354] iteration 23044 : model1 loss : 0.095639 model2 loss : 0.145554
[00:03:37.690] iteration 23045 : model1 loss : 0.253755 model2 loss : 0.245886
[00:03:38.026] iteration 23046 : model1 loss : 0.193435 model2 loss : 0.259657
[00:03:38.362] iteration 23047 : model1 loss : 0.276607 model2 loss : 0.280779
[00:03:38.698] iteration 23048 : model1 loss : 0.180577 model2 loss : 0.214845
[00:03:39.034] iteration 23049 : model1 loss : 0.133042 model2 loss : 0.157626
[00:03:39.372] iteration 23050 : model1 loss : 0.168644 model2 loss : 0.214824
[00:03:40.008] iteration 23051 : model1 loss : 0.104485 model2 loss : 0.127954
[00:03:40.346] iteration 23052 : model1 loss : 0.079880 model2 loss : 0.097948
[00:03:40.686] iteration 23053 : model1 loss : 0.077626 model2 loss : 0.112889
[00:03:41.021] iteration 23054 : model1 loss : 0.161744 model2 loss : 0.197374
[00:03:41.358] iteration 23055 : model1 loss : 0.235554 model2 loss : 0.232529
[00:03:41.695] iteration 23056 : model1 loss : 0.239161 model2 loss : 0.259762
[00:03:42.034] iteration 23057 : model1 loss : 0.123507 model2 loss : 0.152944
[00:03:42.371] iteration 23058 : model1 loss : 0.198109 model2 loss : 0.214757
[00:03:42.709] iteration 23059 : model1 loss : 0.139084 model2 loss : 0.168677
[00:03:43.047] iteration 23060 : model1 loss : 0.111388 model2 loss : 0.183522
[00:03:43.385] iteration 23061 : model1 loss : 0.092201 model2 loss : 0.122902
[00:03:43.723] iteration 23062 : model1 loss : 0.251747 model2 loss : 0.259558
[00:03:44.060] iteration 23063 : model1 loss : 0.207847 model2 loss : 0.225609
[00:03:44.401] iteration 23064 : model1 loss : 0.181819 model2 loss : 0.154957
[00:03:44.743] iteration 23065 : model1 loss : 0.200571 model2 loss : 0.248500
[00:03:45.080] iteration 23066 : model1 loss : 0.142550 model2 loss : 0.203791
[00:03:45.420] iteration 23067 : model1 loss : 0.104222 model2 loss : 0.183015
[00:03:45.758] iteration 23068 : model1 loss : 0.128015 model2 loss : 0.133815
[00:03:46.095] iteration 23069 : model1 loss : 0.160035 model2 loss : 0.207142
[00:03:46.433] iteration 23070 : model1 loss : 0.199580 model2 loss : 0.195381
[00:03:46.770] iteration 23071 : model1 loss : 0.259103 model2 loss : 0.287914
[00:03:47.110] iteration 23072 : model1 loss : 0.298722 model2 loss : 0.280941
[00:03:47.452] iteration 23073 : model1 loss : 0.192463 model2 loss : 0.245456
[00:03:47.788] iteration 23074 : model1 loss : 0.318862 model2 loss : 0.313420
[00:03:48.124] iteration 23075 : model1 loss : 0.171173 model2 loss : 0.194645
[00:03:48.460] iteration 23076 : model1 loss : 0.231715 model2 loss : 0.215372
[00:03:48.800] iteration 23077 : model1 loss : 0.174103 model2 loss : 0.211430
[00:03:49.138] iteration 23078 : model1 loss : 0.119318 model2 loss : 0.215438
[00:03:49.478] iteration 23079 : model1 loss : 0.242814 model2 loss : 0.293732
[00:03:49.815] iteration 23080 : model1 loss : 0.168895 model2 loss : 0.210514
[00:03:50.154] iteration 23081 : model1 loss : 0.136498 model2 loss : 0.277836
[00:03:50.494] iteration 23082 : model1 loss : 0.195555 model2 loss : 0.251776
[00:03:50.831] iteration 23083 : model1 loss : 0.147597 model2 loss : 0.163306
[00:03:51.173] iteration 23084 : model1 loss : 0.170817 model2 loss : 0.185440
[00:03:51.512] iteration 23085 : model1 loss : 0.186666 model2 loss : 0.201638
[00:03:51.849] iteration 23086 : model1 loss : 0.269626 model2 loss : 0.276581
[00:03:52.186] iteration 23087 : model1 loss : 0.269443 model2 loss : 0.293321
[00:03:52.523] iteration 23088 : model1 loss : 0.274297 model2 loss : 0.377691
[00:03:52.860] iteration 23089 : model1 loss : 0.207937 model2 loss : 0.183099
[00:03:53.197] iteration 23090 : model1 loss : 0.214764 model2 loss : 0.215947
[00:03:53.535] iteration 23091 : model1 loss : 0.181341 model2 loss : 0.186886
[00:03:53.872] iteration 23092 : model1 loss : 0.157764 model2 loss : 0.191420
[00:03:54.209] iteration 23093 : model1 loss : 0.184721 model2 loss : 0.183359
[00:03:54.548] iteration 23094 : model1 loss : 0.236664 model2 loss : 0.219767
[00:03:54.885] iteration 23095 : model1 loss : 0.176944 model2 loss : 0.192459
[00:03:55.222] iteration 23096 : model1 loss : 0.206385 model2 loss : 0.247827
[00:03:55.567] iteration 23097 : model1 loss : 0.168076 model2 loss : 0.190721
[00:03:55.910] iteration 23098 : model1 loss : 0.157048 model2 loss : 0.200464
[00:03:56.246] iteration 23099 : model1 loss : 0.294216 model2 loss : 0.314904
[00:03:56.584] iteration 23100 : model1 loss : 0.316558 model2 loss : 0.324735
[00:03:57.206] iteration 23101 : model1 loss : 0.179309 model2 loss : 0.245403
[00:03:57.542] iteration 23102 : model1 loss : 0.246948 model2 loss : 0.281387
[00:03:57.880] iteration 23103 : model1 loss : 0.186069 model2 loss : 0.179125
[00:03:58.219] iteration 23104 : model1 loss : 0.176698 model2 loss : 0.219377
[00:03:58.558] iteration 23105 : model1 loss : 0.206550 model2 loss : 0.266285
[00:03:58.897] iteration 23106 : model1 loss : 0.289504 model2 loss : 0.294730
[00:03:59.237] iteration 23107 : model1 loss : 0.204535 model2 loss : 0.217794
[00:03:59.575] iteration 23108 : model1 loss : 0.211486 model2 loss : 0.216665
[00:03:59.917] iteration 23109 : model1 loss : 0.078977 model2 loss : 0.090285
[00:04:00.257] iteration 23110 : model1 loss : 0.155767 model2 loss : 0.166906
[00:04:00.595] iteration 23111 : model1 loss : 0.175658 model2 loss : 0.188311
[00:04:00.932] iteration 23112 : model1 loss : 0.285686 model2 loss : 0.249893
[00:04:01.270] iteration 23113 : model1 loss : 0.188764 model2 loss : 0.258968
[00:04:01.607] iteration 23114 : model1 loss : 0.312372 model2 loss : 0.270255
[00:04:01.943] iteration 23115 : model1 loss : 0.272384 model2 loss : 0.309798
[00:04:02.284] iteration 23116 : model1 loss : 0.097978 model2 loss : 0.134868
[00:04:02.623] iteration 23117 : model1 loss : 0.257160 model2 loss : 0.283170
[00:04:02.959] iteration 23118 : model1 loss : 0.275014 model2 loss : 0.288855
[00:04:03.296] iteration 23119 : model1 loss : 0.262929 model2 loss : 0.289923
[00:04:03.634] iteration 23120 : model1 loss : 0.253134 model2 loss : 0.253837
[00:04:03.967] iteration 23121 : model1 loss : 0.113338 model2 loss : 0.112807
[00:04:04.299] iteration 23122 : model1 loss : 0.164605 model2 loss : 0.193577
[00:04:04.637] iteration 23123 : model1 loss : 0.289972 model2 loss : 0.295459
[00:04:04.975] iteration 23124 : model1 loss : 0.116467 model2 loss : 0.259642
[00:04:05.310] iteration 23125 : model1 loss : 0.178411 model2 loss : 0.183681
[00:04:05.648] iteration 23126 : model1 loss : 0.096984 model2 loss : 0.111239
[00:04:05.985] iteration 23127 : model1 loss : 0.170896 model2 loss : 0.192466
[00:04:06.326] iteration 23128 : model1 loss : 0.252845 model2 loss : 0.270809
[00:04:06.662] iteration 23129 : model1 loss : 0.154719 model2 loss : 0.206971
[00:04:06.999] iteration 23130 : model1 loss : 0.186069 model2 loss : 0.238011
[00:04:07.337] iteration 23131 : model1 loss : 0.246347 model2 loss : 0.269390
[00:04:07.674] iteration 23132 : model1 loss : 0.195107 model2 loss : 0.226244
[00:04:08.010] iteration 23133 : model1 loss : 0.224163 model2 loss : 0.291572
[00:04:08.347] iteration 23134 : model1 loss : 0.275270 model2 loss : 0.245949
[00:04:08.686] iteration 23135 : model1 loss : 0.184740 model2 loss : 0.170598
[00:04:09.023] iteration 23136 : model1 loss : 0.183722 model2 loss : 0.234470
[00:04:09.357] iteration 23137 : model1 loss : 0.249122 model2 loss : 0.290495
[00:04:09.696] iteration 23138 : model1 loss : 0.083527 model2 loss : 0.106519
[00:04:10.034] iteration 23139 : model1 loss : 0.202906 model2 loss : 0.227173
[00:04:10.372] iteration 23140 : model1 loss : 0.181372 model2 loss : 0.201960
[00:04:10.708] iteration 23141 : model1 loss : 0.219026 model2 loss : 0.247403
[00:04:11.045] iteration 23142 : model1 loss : 0.246416 model2 loss : 0.293861
[00:04:11.381] iteration 23143 : model1 loss : 0.252538 model2 loss : 0.274470
[00:04:11.716] iteration 23144 : model1 loss : 0.194704 model2 loss : 0.200905
[00:04:12.055] iteration 23145 : model1 loss : 0.317952 model2 loss : 0.358467
[00:04:12.387] iteration 23146 : model1 loss : 0.180539 model2 loss : 0.209841
[00:04:12.726] iteration 23147 : model1 loss : 0.252371 model2 loss : 0.248742
[00:04:13.061] iteration 23148 : model1 loss : 0.164378 model2 loss : 0.188028
[00:04:13.397] iteration 23149 : model1 loss : 0.187120 model2 loss : 0.244625
[00:04:13.734] iteration 23150 : model1 loss : 0.182078 model2 loss : 0.173661
[00:04:14.369] iteration 23151 : model1 loss : 0.105309 model2 loss : 0.132009
[00:04:14.706] iteration 23152 : model1 loss : 0.165582 model2 loss : 0.233267
[00:04:15.039] iteration 23153 : model1 loss : 0.095382 model2 loss : 0.123417
[00:04:15.378] iteration 23154 : model1 loss : 0.255188 model2 loss : 0.279352
[00:04:15.716] iteration 23155 : model1 loss : 0.153143 model2 loss : 0.153483
[00:04:16.054] iteration 23156 : model1 loss : 0.160945 model2 loss : 0.162489
[00:04:16.391] iteration 23157 : model1 loss : 0.255892 model2 loss : 0.301576
[00:04:16.724] iteration 23158 : model1 loss : 0.134080 model2 loss : 0.200461
[00:04:17.061] iteration 23159 : model1 loss : 0.186526 model2 loss : 0.182502
[00:04:17.394] iteration 23160 : model1 loss : 0.270218 model2 loss : 0.302183
[00:04:17.732] iteration 23161 : model1 loss : 0.305508 model2 loss : 0.415836
[00:04:18.065] iteration 23162 : model1 loss : 0.094464 model2 loss : 0.244227
[00:04:18.401] iteration 23163 : model1 loss : 0.273429 model2 loss : 0.261555
[00:04:18.737] iteration 23164 : model1 loss : 0.088553 model2 loss : 0.145190
[00:04:19.074] iteration 23165 : model1 loss : 0.174321 model2 loss : 0.189052
[00:04:19.405] iteration 23166 : model1 loss : 0.164483 model2 loss : 0.208794
[00:04:19.743] iteration 23167 : model1 loss : 0.203772 model2 loss : 0.233904
[00:04:20.079] iteration 23168 : model1 loss : 0.292955 model2 loss : 0.314443
[00:04:20.412] iteration 23169 : model1 loss : 0.172130 model2 loss : 0.209801
[00:04:20.749] iteration 23170 : model1 loss : 0.209968 model2 loss : 0.273694
[00:04:21.084] iteration 23171 : model1 loss : 0.152323 model2 loss : 0.151904
[00:04:21.423] iteration 23172 : model1 loss : 0.121271 model2 loss : 0.130560
[00:04:21.765] iteration 23173 : model1 loss : 0.191456 model2 loss : 0.207914
[00:04:22.101] iteration 23174 : model1 loss : 0.256543 model2 loss : 0.282278
[00:04:22.435] iteration 23175 : model1 loss : 0.194171 model2 loss : 0.156315
[00:04:22.772] iteration 23176 : model1 loss : 0.279521 model2 loss : 0.265439
[00:04:23.108] iteration 23177 : model1 loss : 0.181654 model2 loss : 0.230548
[00:04:23.448] iteration 23178 : model1 loss : 0.064268 model2 loss : 0.084462
[00:04:23.787] iteration 23179 : model1 loss : 0.172238 model2 loss : 0.208364
[00:04:24.124] iteration 23180 : model1 loss : 0.170781 model2 loss : 0.171839
[00:04:24.459] iteration 23181 : model1 loss : 0.228588 model2 loss : 0.239130
[00:04:24.796] iteration 23182 : model1 loss : 0.059699 model2 loss : 0.118299
[00:04:25.133] iteration 23183 : model1 loss : 0.179812 model2 loss : 0.243689
[00:04:25.472] iteration 23184 : model1 loss : 0.267165 model2 loss : 0.295260
[00:04:25.811] iteration 23185 : model1 loss : 0.094406 model2 loss : 0.111318
[00:04:26.152] iteration 23186 : model1 loss : 0.087995 model2 loss : 0.143890
[00:04:26.488] iteration 23187 : model1 loss : 0.287232 model2 loss : 0.338507
[00:04:26.823] iteration 23188 : model1 loss : 0.306460 model2 loss : 0.411065
[00:04:27.158] iteration 23189 : model1 loss : 0.087092 model2 loss : 0.126692
[00:04:27.494] iteration 23190 : model1 loss : 0.103896 model2 loss : 0.204486
[00:04:27.831] iteration 23191 : model1 loss : 0.237717 model2 loss : 0.239167
[00:04:28.172] iteration 23192 : model1 loss : 0.104372 model2 loss : 0.123089
[00:04:28.508] iteration 23193 : model1 loss : 0.139930 model2 loss : 0.189326
[00:04:28.845] iteration 23194 : model1 loss : 0.185604 model2 loss : 0.227786
[00:04:29.178] iteration 23195 : model1 loss : 0.266470 model2 loss : 0.297954
[00:04:29.510] iteration 23196 : model1 loss : 0.273167 model2 loss : 0.332600
[00:04:29.847] iteration 23197 : model1 loss : 0.206690 model2 loss : 0.168881
[00:04:30.185] iteration 23198 : model1 loss : 0.183914 model2 loss : 0.204323
[00:04:30.524] iteration 23199 : model1 loss : 0.188857 model2 loss : 0.192286
[00:04:30.866] iteration 23200 : model1 loss : 0.258499 model2 loss : 0.285868
[00:04:31.518] iteration 23201 : model1 loss : 0.183896 model2 loss : 0.246300
[00:04:31.855] iteration 23202 : model1 loss : 0.173184 model2 loss : 0.183103
[00:04:32.190] iteration 23203 : model1 loss : 0.188544 model2 loss : 0.208997
[00:04:32.522] iteration 23204 : model1 loss : 0.099414 model2 loss : 0.129199
[00:04:32.863] iteration 23205 : model1 loss : 0.190886 model2 loss : 0.250611
[00:04:33.200] iteration 23206 : model1 loss : 0.091666 model2 loss : 0.059646
[00:04:33.532] iteration 23207 : model1 loss : 0.258873 model2 loss : 0.257828
[00:04:33.864] iteration 23208 : model1 loss : 0.252443 model2 loss : 0.259769
[00:04:34.197] iteration 23209 : model1 loss : 0.181819 model2 loss : 0.182110
[00:04:34.529] iteration 23210 : model1 loss : 0.195920 model2 loss : 0.219158
[00:04:34.864] iteration 23211 : model1 loss : 0.225463 model2 loss : 0.219428
[00:04:35.198] iteration 23212 : model1 loss : 0.166518 model2 loss : 0.208091
[00:04:35.530] iteration 23213 : model1 loss : 0.221961 model2 loss : 0.260192
[00:04:35.867] iteration 23214 : model1 loss : 0.099584 model2 loss : 0.140274
[00:04:36.204] iteration 23215 : model1 loss : 0.216801 model2 loss : 0.341002
[00:04:36.539] iteration 23216 : model1 loss : 0.205013 model2 loss : 0.225139
[00:04:36.872] iteration 23217 : model1 loss : 0.089769 model2 loss : 0.109555
[00:04:37.208] iteration 23218 : model1 loss : 0.258893 model2 loss : 0.274162
[00:04:37.544] iteration 23219 : model1 loss : 0.114895 model2 loss : 0.154621
[00:04:37.881] iteration 23220 : model1 loss : 0.212708 model2 loss : 0.277826
[00:04:38.220] iteration 23221 : model1 loss : 0.236628 model2 loss : 0.256527
[00:04:38.553] iteration 23222 : model1 loss : 0.191734 model2 loss : 0.265545
[00:04:38.885] iteration 23223 : model1 loss : 0.129051 model2 loss : 0.176874
[00:04:39.218] iteration 23224 : model1 loss : 0.181127 model2 loss : 0.257390
[00:04:39.550] iteration 23225 : model1 loss : 0.162660 model2 loss : 0.188638
[00:04:39.882] iteration 23226 : model1 loss : 0.303029 model2 loss : 0.408883
[00:04:40.214] iteration 23227 : model1 loss : 0.166627 model2 loss : 0.196611
[00:04:40.552] iteration 23228 : model1 loss : 0.255341 model2 loss : 0.263526
[00:04:40.887] iteration 23229 : model1 loss : 0.209111 model2 loss : 0.227748
[00:04:41.236] iteration 23230 : model1 loss : 0.193026 model2 loss : 0.207496
[00:04:41.575] iteration 23231 : model1 loss : 0.246717 model2 loss : 0.244390
[00:04:41.911] iteration 23232 : model1 loss : 0.071151 model2 loss : 0.109378
[00:04:42.251] iteration 23233 : model1 loss : 0.195517 model2 loss : 0.259760
[00:04:42.585] iteration 23234 : model1 loss : 0.069300 model2 loss : 0.112593
[00:04:42.927] iteration 23235 : model1 loss : 0.200273 model2 loss : 0.220255
[00:04:43.262] iteration 23236 : model1 loss : 0.170196 model2 loss : 0.196847
[00:04:43.607] iteration 23237 : model1 loss : 0.175985 model2 loss : 0.208063
[00:04:43.944] iteration 23238 : model1 loss : 0.230723 model2 loss : 0.220318
[00:04:44.270] iteration 23239 : model1 loss : 0.160057 model2 loss : 0.191715
[00:04:44.597] iteration 23240 : model1 loss : 0.214573 model2 loss : 0.237121
[00:04:44.923] iteration 23241 : model1 loss : 0.185729 model2 loss : 0.221170
[00:04:45.251] iteration 23242 : model1 loss : 0.357274 model2 loss : 0.334235
[00:04:45.581] iteration 23243 : model1 loss : 0.157596 model2 loss : 0.193704
[00:04:45.910] iteration 23244 : model1 loss : 0.174329 model2 loss : 0.202217
[00:04:46.240] iteration 23245 : model1 loss : 0.161729 model2 loss : 0.189775
[00:04:46.570] iteration 23246 : model1 loss : 0.194592 model2 loss : 0.238922
[00:04:46.897] iteration 23247 : model1 loss : 0.159582 model2 loss : 0.176310
[00:04:47.225] iteration 23248 : model1 loss : 0.239645 model2 loss : 0.247153
[00:04:47.554] iteration 23249 : model1 loss : 0.111204 model2 loss : 0.201918
[00:04:47.882] iteration 23250 : model1 loss : 0.117429 model2 loss : 0.139748
[00:04:48.451] iteration 23251 : model1 loss : 0.175304 model2 loss : 0.276904
[00:04:48.781] iteration 23252 : model1 loss : 0.078864 model2 loss : 0.125334
[00:04:49.109] iteration 23253 : model1 loss : 0.150371 model2 loss : 0.190521
[00:04:49.440] iteration 23254 : model1 loss : 0.178747 model2 loss : 0.226643
[00:04:49.770] iteration 23255 : model1 loss : 0.269411 model2 loss : 0.271140
[00:04:50.099] iteration 23256 : model1 loss : 0.225973 model2 loss : 0.261914
[00:04:50.428] iteration 23257 : model1 loss : 0.214036 model2 loss : 0.220739
[00:04:50.758] iteration 23258 : model1 loss : 0.317838 model2 loss : 0.333282
[00:04:51.086] iteration 23259 : model1 loss : 0.212043 model2 loss : 0.211025
[00:04:51.416] iteration 23260 : model1 loss : 0.098606 model2 loss : 0.121922
[00:04:51.746] iteration 23261 : model1 loss : 0.328038 model2 loss : 0.337315
[00:04:52.079] iteration 23262 : model1 loss : 0.239905 model2 loss : 0.285948
[00:04:52.407] iteration 23263 : model1 loss : 0.177143 model2 loss : 0.185561
[00:04:52.736] iteration 23264 : model1 loss : 0.082699 model2 loss : 0.091959
[00:04:53.065] iteration 23265 : model1 loss : 0.209609 model2 loss : 0.250194
[00:04:53.394] iteration 23266 : model1 loss : 0.264136 model2 loss : 0.266393
[00:04:53.724] iteration 23267 : model1 loss : 0.271034 model2 loss : 0.301097
[00:04:54.057] iteration 23268 : model1 loss : 0.243111 model2 loss : 0.258523
[00:04:54.386] iteration 23269 : model1 loss : 0.144398 model2 loss : 0.164161
[00:04:54.715] iteration 23270 : model1 loss : 0.157574 model2 loss : 0.176220
[00:04:55.046] iteration 23271 : model1 loss : 0.108765 model2 loss : 0.116532
[00:04:55.376] iteration 23272 : model1 loss : 0.239382 model2 loss : 0.263469
[00:04:55.705] iteration 23273 : model1 loss : 0.151180 model2 loss : 0.203998
[00:04:56.035] iteration 23274 : model1 loss : 0.184128 model2 loss : 0.192927
[00:04:56.366] iteration 23275 : model1 loss : 0.280033 model2 loss : 0.298027
[00:04:56.697] iteration 23276 : model1 loss : 0.112836 model2 loss : 0.104035
[00:04:57.026] iteration 23277 : model1 loss : 0.261647 model2 loss : 0.284622
[00:04:57.355] iteration 23278 : model1 loss : 0.162932 model2 loss : 0.190531
[00:04:57.685] iteration 23279 : model1 loss : 0.071731 model2 loss : 0.107784
[00:04:58.013] iteration 23280 : model1 loss : 0.282592 model2 loss : 0.327303
[00:04:58.341] iteration 23281 : model1 loss : 0.177939 model2 loss : 0.191503
[00:04:58.672] iteration 23282 : model1 loss : 0.190828 model2 loss : 0.224570
[00:04:59.001] iteration 23283 : model1 loss : 0.250938 model2 loss : 0.292386
[00:04:59.329] iteration 23284 : model1 loss : 0.072513 model2 loss : 0.110441
[00:04:59.658] iteration 23285 : model1 loss : 0.170874 model2 loss : 0.200064
[00:04:59.987] iteration 23286 : model1 loss : 0.206484 model2 loss : 0.226759
[00:05:00.318] iteration 23287 : model1 loss : 0.164418 model2 loss : 0.177623
[00:05:00.647] iteration 23288 : model1 loss : 0.131245 model2 loss : 0.200841
[00:05:00.975] iteration 23289 : model1 loss : 0.083965 model2 loss : 0.159644
[00:05:01.303] iteration 23290 : model1 loss : 0.274825 model2 loss : 0.285340
[00:05:01.634] iteration 23291 : model1 loss : 0.159333 model2 loss : 0.173894
[00:05:01.963] iteration 23292 : model1 loss : 0.247114 model2 loss : 0.272655
[00:05:02.291] iteration 23293 : model1 loss : 0.107087 model2 loss : 0.169198
[00:05:02.619] iteration 23294 : model1 loss : 0.272415 model2 loss : 0.328262
[00:05:02.947] iteration 23295 : model1 loss : 0.195811 model2 loss : 0.221622
[00:05:03.275] iteration 23296 : model1 loss : 0.105488 model2 loss : 0.165020
[00:05:03.604] iteration 23297 : model1 loss : 0.176178 model2 loss : 0.190477
[00:05:03.933] iteration 23298 : model1 loss : 0.192296 model2 loss : 0.193404
[00:05:04.261] iteration 23299 : model1 loss : 0.168637 model2 loss : 0.194526
[00:05:04.590] iteration 23300 : model1 loss : 0.103752 model2 loss : 0.193809
[00:05:05.156] iteration 23301 : model1 loss : 0.198731 model2 loss : 0.195891
[00:05:05.486] iteration 23302 : model1 loss : 0.165827 model2 loss : 0.256212
[00:05:05.814] iteration 23303 : model1 loss : 0.118031 model2 loss : 0.124407
[00:05:06.144] iteration 23304 : model1 loss : 0.177799 model2 loss : 0.154621
[00:05:06.472] iteration 23305 : model1 loss : 0.239928 model2 loss : 0.308162
[00:05:06.800] iteration 23306 : model1 loss : 0.172343 model2 loss : 0.208977
[00:05:07.130] iteration 23307 : model1 loss : 0.251534 model2 loss : 0.293218
[00:05:07.462] iteration 23308 : model1 loss : 0.172798 model2 loss : 0.185907
[00:05:07.792] iteration 23309 : model1 loss : 0.195917 model2 loss : 0.207923
[00:05:08.120] iteration 23310 : model1 loss : 0.307021 model2 loss : 0.312378
[00:05:08.452] iteration 23311 : model1 loss : 0.199672 model2 loss : 0.199708
[00:05:08.787] iteration 23312 : model1 loss : 0.262963 model2 loss : 0.282527
[00:05:09.115] iteration 23313 : model1 loss : 0.095889 model2 loss : 0.141247
[00:05:09.443] iteration 23314 : model1 loss : 0.169957 model2 loss : 0.222361
[00:05:09.772] iteration 23315 : model1 loss : 0.099684 model2 loss : 0.154573
[00:05:10.103] iteration 23316 : model1 loss : 0.163140 model2 loss : 0.192635
[00:05:10.432] iteration 23317 : model1 loss : 0.253530 model2 loss : 0.269654
[00:05:10.766] iteration 23318 : model1 loss : 0.082509 model2 loss : 0.101084
[00:05:11.094] iteration 23319 : model1 loss : 0.290489 model2 loss : 0.275496
[00:05:11.422] iteration 23320 : model1 loss : 0.174863 model2 loss : 0.246190
[00:05:11.754] iteration 23321 : model1 loss : 0.347385 model2 loss : 0.412740
[00:05:12.085] iteration 23322 : model1 loss : 0.241151 model2 loss : 0.258446
[00:05:12.414] iteration 23323 : model1 loss : 0.106695 model2 loss : 0.212046
[00:05:12.742] iteration 23324 : model1 loss : 0.215234 model2 loss : 0.234743
[00:05:13.071] iteration 23325 : model1 loss : 0.257009 model2 loss : 0.277877
[00:05:13.402] iteration 23326 : model1 loss : 0.191186 model2 loss : 0.206047
[00:05:13.730] iteration 23327 : model1 loss : 0.266225 model2 loss : 0.269388
[00:05:14.057] iteration 23328 : model1 loss : 0.167926 model2 loss : 0.225449
[00:05:14.386] iteration 23329 : model1 loss : 0.315568 model2 loss : 0.320432
[00:05:14.715] iteration 23330 : model1 loss : 0.176173 model2 loss : 0.181021
[00:05:15.043] iteration 23331 : model1 loss : 0.095769 model2 loss : 0.204764
[00:05:15.373] iteration 23332 : model1 loss : 0.163862 model2 loss : 0.177419
[00:05:15.704] iteration 23333 : model1 loss : 0.136782 model2 loss : 0.124040
[00:05:16.034] iteration 23334 : model1 loss : 0.156458 model2 loss : 0.234148
[00:05:16.363] iteration 23335 : model1 loss : 0.202489 model2 loss : 0.240892
[00:05:16.692] iteration 23336 : model1 loss : 0.251464 model2 loss : 0.336320
[00:05:17.028] iteration 23337 : model1 loss : 0.167735 model2 loss : 0.206678
[00:05:17.359] iteration 23338 : model1 loss : 0.246394 model2 loss : 0.254582
[00:05:17.687] iteration 23339 : model1 loss : 0.259449 model2 loss : 0.291494
[00:05:18.016] iteration 23340 : model1 loss : 0.259847 model2 loss : 0.299726
[00:05:18.345] iteration 23341 : model1 loss : 0.187546 model2 loss : 0.223186
[00:05:18.674] iteration 23342 : model1 loss : 0.188972 model2 loss : 0.205892
[00:05:19.002] iteration 23343 : model1 loss : 0.191103 model2 loss : 0.192046
[00:05:19.331] iteration 23344 : model1 loss : 0.174199 model2 loss : 0.212287
[00:05:19.662] iteration 23345 : model1 loss : 0.180406 model2 loss : 0.218883
[00:05:19.990] iteration 23346 : model1 loss : 0.252368 model2 loss : 0.272253
[00:05:20.319] iteration 23347 : model1 loss : 0.162293 model2 loss : 0.183990
[00:05:20.652] iteration 23348 : model1 loss : 0.186523 model2 loss : 0.194619
[00:05:20.980] iteration 23349 : model1 loss : 0.119481 model2 loss : 0.153233
[00:05:21.311] iteration 23350 : model1 loss : 0.168742 model2 loss : 0.248614
[00:05:21.871] iteration 23351 : model1 loss : 0.289098 model2 loss : 0.328696
[00:05:22.201] iteration 23352 : model1 loss : 0.183611 model2 loss : 0.196226
[00:05:22.533] iteration 23353 : model1 loss : 0.112561 model2 loss : 0.206300
[00:05:22.863] iteration 23354 : model1 loss : 0.200205 model2 loss : 0.253284
[00:05:23.193] iteration 23355 : model1 loss : 0.179020 model2 loss : 0.237088
[00:05:23.520] iteration 23356 : model1 loss : 0.164130 model2 loss : 0.220316
[00:05:23.850] iteration 23357 : model1 loss : 0.258786 model2 loss : 0.297371
[00:05:24.178] iteration 23358 : model1 loss : 0.111113 model2 loss : 0.183190
[00:05:24.517] iteration 23359 : model1 loss : 0.091453 model2 loss : 0.114711
[00:05:24.851] iteration 23360 : model1 loss : 0.075791 model2 loss : 0.183885
[00:05:25.187] iteration 23361 : model1 loss : 0.092894 model2 loss : 0.160666
[00:05:25.517] iteration 23362 : model1 loss : 0.171800 model2 loss : 0.199652
[00:05:25.849] iteration 23363 : model1 loss : 0.184138 model2 loss : 0.235227
[00:05:26.180] iteration 23364 : model1 loss : 0.282888 model2 loss : 0.289472
[00:05:26.509] iteration 23365 : model1 loss : 0.174622 model2 loss : 0.211761
[00:05:26.838] iteration 23366 : model1 loss : 0.209283 model2 loss : 0.250406
[00:05:27.167] iteration 23367 : model1 loss : 0.130900 model2 loss : 0.138686
[00:05:27.496] iteration 23368 : model1 loss : 0.303595 model2 loss : 0.408672
[00:05:27.826] iteration 23369 : model1 loss : 0.083587 model2 loss : 0.109868
[00:05:28.154] iteration 23370 : model1 loss : 0.172644 model2 loss : 0.194936
[00:05:28.482] iteration 23371 : model1 loss : 0.167889 model2 loss : 0.161562
[00:05:28.810] iteration 23372 : model1 loss : 0.259082 model2 loss : 0.304741
[00:05:29.137] iteration 23373 : model1 loss : 0.113347 model2 loss : 0.162582
[00:05:29.466] iteration 23374 : model1 loss : 0.176927 model2 loss : 0.195282
[00:05:29.794] iteration 23375 : model1 loss : 0.152384 model2 loss : 0.175676
[00:05:30.123] iteration 23376 : model1 loss : 0.179133 model2 loss : 0.263518
[00:05:30.453] iteration 23377 : model1 loss : 0.166936 model2 loss : 0.191061
[00:05:30.781] iteration 23378 : model1 loss : 0.181218 model2 loss : 0.234262
[00:05:31.110] iteration 23379 : model1 loss : 0.153072 model2 loss : 0.181969
[00:05:31.438] iteration 23380 : model1 loss : 0.151703 model2 loss : 0.188133
[00:05:31.766] iteration 23381 : model1 loss : 0.259243 model2 loss : 0.276905
[00:05:32.094] iteration 23382 : model1 loss : 0.095316 model2 loss : 0.113013
[00:05:32.422] iteration 23383 : model1 loss : 0.242695 model2 loss : 0.250657
[00:05:32.751] iteration 23384 : model1 loss : 0.161688 model2 loss : 0.179130
[00:05:33.082] iteration 23385 : model1 loss : 0.129753 model2 loss : 0.138767
[00:05:33.409] iteration 23386 : model1 loss : 0.246557 model2 loss : 0.263218
[00:05:33.737] iteration 23387 : model1 loss : 0.272264 model2 loss : 0.359955
[00:05:34.065] iteration 23388 : model1 loss : 0.225849 model2 loss : 0.252283
[00:05:34.393] iteration 23389 : model1 loss : 0.198073 model2 loss : 0.205919
[00:05:34.722] iteration 23390 : model1 loss : 0.193116 model2 loss : 0.207584
[00:05:35.056] iteration 23391 : model1 loss : 0.252864 model2 loss : 0.270193
[00:05:35.386] iteration 23392 : model1 loss : 0.259200 model2 loss : 0.246702
[00:05:35.717] iteration 23393 : model1 loss : 0.194232 model2 loss : 0.163097
[00:05:36.044] iteration 23394 : model1 loss : 0.183947 model2 loss : 0.181764
[00:05:36.373] iteration 23395 : model1 loss : 0.120137 model2 loss : 0.153182
[00:05:36.701] iteration 23396 : model1 loss : 0.261495 model2 loss : 0.300870
[00:05:37.029] iteration 23397 : model1 loss : 0.273574 model2 loss : 0.296810
[00:05:37.358] iteration 23398 : model1 loss : 0.256139 model2 loss : 0.277071
[00:05:37.686] iteration 23399 : model1 loss : 0.152724 model2 loss : 0.177056
[00:05:38.014] iteration 23400 : model1 loss : 0.163794 model2 loss : 0.207569
[00:05:38.552] iteration 23401 : model1 loss : 0.127517 model2 loss : 0.182050
[00:05:38.881] iteration 23402 : model1 loss : 0.159165 model2 loss : 0.202532
[00:05:39.209] iteration 23403 : model1 loss : 0.216712 model2 loss : 0.283184
[00:05:39.540] iteration 23404 : model1 loss : 0.090111 model2 loss : 0.134198
[00:05:39.870] iteration 23405 : model1 loss : 0.230094 model2 loss : 0.180326
[00:05:40.198] iteration 23406 : model1 loss : 0.144054 model2 loss : 0.201403
[00:05:40.527] iteration 23407 : model1 loss : 0.251534 model2 loss : 0.294267
[00:05:40.855] iteration 23408 : model1 loss : 0.206043 model2 loss : 0.182022
[00:05:41.186] iteration 23409 : model1 loss : 0.274725 model2 loss : 0.300408
[00:05:41.516] iteration 23410 : model1 loss : 0.094611 model2 loss : 0.102201
[00:05:41.845] iteration 23411 : model1 loss : 0.152302 model2 loss : 0.260167
[00:05:42.174] iteration 23412 : model1 loss : 0.275683 model2 loss : 0.305135
[00:05:42.505] iteration 23413 : model1 loss : 0.166011 model2 loss : 0.171406
[00:05:42.837] iteration 23414 : model1 loss : 0.146907 model2 loss : 0.164285
[00:05:43.172] iteration 23415 : model1 loss : 0.087651 model2 loss : 0.125327
[00:05:43.509] iteration 23416 : model1 loss : 0.268684 model2 loss : 0.260546
[00:05:43.837] iteration 23417 : model1 loss : 0.264310 model2 loss : 0.189582
[00:05:44.165] iteration 23418 : model1 loss : 0.257969 model2 loss : 0.267090
[00:05:44.664] iteration 23419 : model1 loss : 0.152562 model2 loss : 0.192470
[00:05:44.998] iteration 23420 : model1 loss : 0.246790 model2 loss : 0.263817
[00:05:45.327] iteration 23421 : model1 loss : 0.164582 model2 loss : 0.191157
[00:05:45.656] iteration 23422 : model1 loss : 0.173875 model2 loss : 0.204404
[00:05:45.984] iteration 23423 : model1 loss : 0.244920 model2 loss : 0.245528
[00:05:46.314] iteration 23424 : model1 loss : 0.234442 model2 loss : 0.253525
[00:05:46.642] iteration 23425 : model1 loss : 0.196096 model2 loss : 0.157540
[00:05:46.971] iteration 23426 : model1 loss : 0.193729 model2 loss : 0.200757
[00:05:47.298] iteration 23427 : model1 loss : 0.168604 model2 loss : 0.221390
[00:05:47.626] iteration 23428 : model1 loss : 0.250112 model2 loss : 0.291595
[00:05:47.953] iteration 23429 : model1 loss : 0.242468 model2 loss : 0.254140
[00:05:48.280] iteration 23430 : model1 loss : 0.260273 model2 loss : 0.285290
[00:05:48.609] iteration 23431 : model1 loss : 0.176419 model2 loss : 0.210941
[00:05:48.936] iteration 23432 : model1 loss : 0.152507 model2 loss : 0.195543
[00:05:49.262] iteration 23433 : model1 loss : 0.260897 model2 loss : 0.267186
[00:05:49.590] iteration 23434 : model1 loss : 0.284284 model2 loss : 0.286027
[00:05:49.917] iteration 23435 : model1 loss : 0.112410 model2 loss : 0.141286
[00:05:51.038] iteration 23436 : model1 loss : 0.160095 model2 loss : 0.215134
[00:05:51.367] iteration 23437 : model1 loss : 0.187216 model2 loss : 0.249462
[00:05:51.706] iteration 23438 : model1 loss : 0.121010 model2 loss : 0.138990
[00:05:52.042] iteration 23439 : model1 loss : 0.171930 model2 loss : 0.190649
[00:05:52.370] iteration 23440 : model1 loss : 0.335060 model2 loss : 0.365734
[00:05:52.697] iteration 23441 : model1 loss : 0.187319 model2 loss : 0.222612
[00:05:53.032] iteration 23442 : model1 loss : 0.136866 model2 loss : 0.138463
[00:05:53.362] iteration 23443 : model1 loss : 0.291635 model2 loss : 0.277816
[00:05:53.692] iteration 23444 : model1 loss : 0.149225 model2 loss : 0.216708
[00:05:54.019] iteration 23445 : model1 loss : 0.238497 model2 loss : 0.249232
[00:05:54.351] iteration 23446 : model1 loss : 0.152893 model2 loss : 0.198567
[00:05:54.680] iteration 23447 : model1 loss : 0.165014 model2 loss : 0.214360
[00:05:55.008] iteration 23448 : model1 loss : 0.157526 model2 loss : 0.218308
[00:05:55.338] iteration 23449 : model1 loss : 0.100821 model2 loss : 0.109357
[00:05:55.670] iteration 23450 : model1 loss : 0.129152 model2 loss : 0.256477
[00:05:56.268] iteration 23451 : model1 loss : 0.105393 model2 loss : 0.167938
[00:05:56.596] iteration 23452 : model1 loss : 0.167156 model2 loss : 0.198698
[00:05:56.924] iteration 23453 : model1 loss : 0.177982 model2 loss : 0.256751
[00:05:57.248] iteration 23454 : model1 loss : 0.231810 model2 loss : 0.266871
[00:05:57.582] iteration 23455 : model1 loss : 0.161968 model2 loss : 0.191809
[00:05:57.910] iteration 23456 : model1 loss : 0.110217 model2 loss : 0.141633
[00:05:58.240] iteration 23457 : model1 loss : 0.190616 model2 loss : 0.172262
[00:05:58.573] iteration 23458 : model1 loss : 0.172810 model2 loss : 0.171238
[00:05:58.901] iteration 23459 : model1 loss : 0.097892 model2 loss : 0.175894
[00:05:59.234] iteration 23460 : model1 loss : 0.089356 model2 loss : 0.112122
[00:05:59.562] iteration 23461 : model1 loss : 0.170060 model2 loss : 0.228333
[00:05:59.886] iteration 23462 : model1 loss : 0.173276 model2 loss : 0.215949
[00:06:00.214] iteration 23463 : model1 loss : 0.277494 model2 loss : 0.334415
[00:06:00.542] iteration 23464 : model1 loss : 0.094995 model2 loss : 0.196094
[00:06:00.871] iteration 23465 : model1 loss : 0.234401 model2 loss : 0.267959
[00:06:01.205] iteration 23466 : model1 loss : 0.274915 model2 loss : 0.314408
[00:06:01.537] iteration 23467 : model1 loss : 0.260232 model2 loss : 0.288913
[00:06:01.867] iteration 23468 : model1 loss : 0.196323 model2 loss : 0.284374
[00:06:02.195] iteration 23469 : model1 loss : 0.288286 model2 loss : 0.250800
[00:06:02.525] iteration 23470 : model1 loss : 0.131565 model2 loss : 0.224209
[00:06:02.852] iteration 23471 : model1 loss : 0.180330 model2 loss : 0.200341
[00:06:03.181] iteration 23472 : model1 loss : 0.263906 model2 loss : 0.304036
[00:06:03.509] iteration 23473 : model1 loss : 0.208574 model2 loss : 0.240514
[00:06:03.844] iteration 23474 : model1 loss : 0.179353 model2 loss : 0.216773
[00:06:04.176] iteration 23475 : model1 loss : 0.100686 model2 loss : 0.213509
[00:06:04.504] iteration 23476 : model1 loss : 0.232588 model2 loss : 0.240381
[00:06:04.832] iteration 23477 : model1 loss : 0.120211 model2 loss : 0.188449
[00:06:05.162] iteration 23478 : model1 loss : 0.098981 model2 loss : 0.126474
[00:06:05.491] iteration 23479 : model1 loss : 0.238112 model2 loss : 0.228594
[00:06:05.819] iteration 23480 : model1 loss : 0.105149 model2 loss : 0.151188
[00:06:06.147] iteration 23481 : model1 loss : 0.401521 model2 loss : 0.404352
[00:06:06.480] iteration 23482 : model1 loss : 0.243415 model2 loss : 0.288411
[00:06:06.819] iteration 23483 : model1 loss : 0.108136 model2 loss : 0.129046
[00:06:07.147] iteration 23484 : model1 loss : 0.281090 model2 loss : 0.328036
[00:06:07.476] iteration 23485 : model1 loss : 0.180609 model2 loss : 0.351876
[00:06:07.801] iteration 23486 : model1 loss : 0.090940 model2 loss : 0.150692
[00:06:08.129] iteration 23487 : model1 loss : 0.260306 model2 loss : 0.332620
[00:06:08.457] iteration 23488 : model1 loss : 0.141066 model2 loss : 0.230547
[00:06:08.786] iteration 23489 : model1 loss : 0.177013 model2 loss : 0.234532
[00:06:09.129] iteration 23490 : model1 loss : 0.268254 model2 loss : 0.268998
[00:06:09.461] iteration 23491 : model1 loss : 0.260524 model2 loss : 0.275849
[00:06:09.791] iteration 23492 : model1 loss : 0.133803 model2 loss : 0.150308
[00:06:10.119] iteration 23493 : model1 loss : 0.251165 model2 loss : 0.266215
[00:06:10.444] iteration 23494 : model1 loss : 0.310262 model2 loss : 0.344438
[00:06:10.775] iteration 23495 : model1 loss : 0.188035 model2 loss : 0.228736
[00:06:11.105] iteration 23496 : model1 loss : 0.196823 model2 loss : 0.205277
[00:06:11.433] iteration 23497 : model1 loss : 0.094607 model2 loss : 0.165249
[00:06:11.765] iteration 23498 : model1 loss : 0.081209 model2 loss : 0.139094
[00:06:12.096] iteration 23499 : model1 loss : 0.339068 model2 loss : 0.333131
[00:06:12.422] iteration 23500 : model1 loss : 0.275360 model2 loss : 0.283652
[00:06:12.978] iteration 23501 : model1 loss : 0.144249 model2 loss : 0.182880
[00:06:13.303] iteration 23502 : model1 loss : 0.147360 model2 loss : 0.193091
[00:06:13.634] iteration 23503 : model1 loss : 0.180561 model2 loss : 0.228790
[00:06:13.962] iteration 23504 : model1 loss : 0.204351 model2 loss : 0.228069
[00:06:14.289] iteration 23505 : model1 loss : 0.172721 model2 loss : 0.242073
[00:06:14.621] iteration 23506 : model1 loss : 0.211607 model2 loss : 0.188577
[00:06:14.951] iteration 23507 : model1 loss : 0.216460 model2 loss : 0.310379
[00:06:15.280] iteration 23508 : model1 loss : 0.234967 model2 loss : 0.267619
[00:06:15.607] iteration 23509 : model1 loss : 0.086831 model2 loss : 0.110339
[00:06:15.932] iteration 23510 : model1 loss : 0.163385 model2 loss : 0.177130
[00:06:16.262] iteration 23511 : model1 loss : 0.080819 model2 loss : 0.130910
[00:06:16.590] iteration 23512 : model1 loss : 0.243810 model2 loss : 0.246445
[00:06:16.918] iteration 23513 : model1 loss : 0.116489 model2 loss : 0.136172
[00:06:17.249] iteration 23514 : model1 loss : 0.247246 model2 loss : 0.276116
[00:06:17.579] iteration 23515 : model1 loss : 0.146138 model2 loss : 0.191811
[00:06:17.906] iteration 23516 : model1 loss : 0.159487 model2 loss : 0.186435
[00:06:18.234] iteration 23517 : model1 loss : 0.206238 model2 loss : 0.241350
[00:06:18.556] iteration 23518 : model1 loss : 0.125508 model2 loss : 0.123340
[00:06:18.883] iteration 23519 : model1 loss : 0.163085 model2 loss : 0.202691
[00:06:19.209] iteration 23520 : model1 loss : 0.188487 model2 loss : 0.191502
[00:06:19.534] iteration 23521 : model1 loss : 0.091508 model2 loss : 0.160279
[00:06:19.864] iteration 23522 : model1 loss : 0.098999 model2 loss : 0.137923
[00:06:20.192] iteration 23523 : model1 loss : 0.072822 model2 loss : 0.090189
[00:06:20.517] iteration 23524 : model1 loss : 0.172112 model2 loss : 0.204136
[00:06:20.843] iteration 23525 : model1 loss : 0.161778 model2 loss : 0.187797
[00:06:21.166] iteration 23526 : model1 loss : 0.156566 model2 loss : 0.167410
[00:06:21.499] iteration 23527 : model1 loss : 0.110825 model2 loss : 0.136372
[00:06:21.825] iteration 23528 : model1 loss : 0.158053 model2 loss : 0.200720
[00:06:22.150] iteration 23529 : model1 loss : 0.084265 model2 loss : 0.102005
[00:06:22.480] iteration 23530 : model1 loss : 0.332758 model2 loss : 0.370307
[00:06:22.808] iteration 23531 : model1 loss : 0.154081 model2 loss : 0.178269
[00:06:23.134] iteration 23532 : model1 loss : 0.089558 model2 loss : 0.138783
[00:06:23.459] iteration 23533 : model1 loss : 0.106238 model2 loss : 0.139498
[00:06:23.787] iteration 23534 : model1 loss : 0.158932 model2 loss : 0.193889
[00:06:24.114] iteration 23535 : model1 loss : 0.182553 model2 loss : 0.279643
[00:06:24.440] iteration 23536 : model1 loss : 0.223892 model2 loss : 0.239376
[00:06:24.766] iteration 23537 : model1 loss : 0.110360 model2 loss : 0.094113
[00:06:25.096] iteration 23538 : model1 loss : 0.256493 model2 loss : 0.275333
[00:06:25.425] iteration 23539 : model1 loss : 0.181369 model2 loss : 0.274289
[00:06:25.751] iteration 23540 : model1 loss : 0.197287 model2 loss : 0.245113
[00:06:26.079] iteration 23541 : model1 loss : 0.182478 model2 loss : 0.193383
[00:06:26.402] iteration 23542 : model1 loss : 0.111819 model2 loss : 0.161594
[00:06:26.731] iteration 23543 : model1 loss : 0.285200 model2 loss : 0.274361
[00:06:27.057] iteration 23544 : model1 loss : 0.168089 model2 loss : 0.305560
[00:06:27.384] iteration 23545 : model1 loss : 0.295464 model2 loss : 0.295512
[00:06:27.714] iteration 23546 : model1 loss : 0.201421 model2 loss : 0.216137
[00:06:28.042] iteration 23547 : model1 loss : 0.233625 model2 loss : 0.280799
[00:06:28.368] iteration 23548 : model1 loss : 0.151578 model2 loss : 0.180733
[00:06:28.694] iteration 23549 : model1 loss : 0.252409 model2 loss : 0.282122
[00:06:29.023] iteration 23550 : model1 loss : 0.102453 model2 loss : 0.138501
[00:06:29.513] iteration 23551 : model1 loss : 0.345198 model2 loss : 0.394548
[00:06:29.840] iteration 23552 : model1 loss : 0.189611 model2 loss : 0.242248
[00:06:30.166] iteration 23553 : model1 loss : 0.267799 model2 loss : 0.278552
[00:06:30.491] iteration 23554 : model1 loss : 0.198359 model2 loss : 0.221763
[00:06:30.819] iteration 23555 : model1 loss : 0.178654 model2 loss : 0.193728
[00:06:31.145] iteration 23556 : model1 loss : 0.159109 model2 loss : 0.190028
[00:06:31.471] iteration 23557 : model1 loss : 0.237396 model2 loss : 0.265567
[00:06:31.797] iteration 23558 : model1 loss : 0.161494 model2 loss : 0.261769
[00:06:32.126] iteration 23559 : model1 loss : 0.083960 model2 loss : 0.154562
[00:06:32.452] iteration 23560 : model1 loss : 0.186547 model2 loss : 0.173036
[00:06:32.777] iteration 23561 : model1 loss : 0.180499 model2 loss : 0.195035
[00:06:33.103] iteration 23562 : model1 loss : 0.085400 model2 loss : 0.225742
[00:06:33.430] iteration 23563 : model1 loss : 0.178333 model2 loss : 0.187243
[00:06:33.755] iteration 23564 : model1 loss : 0.176375 model2 loss : 0.313258
[00:06:34.081] iteration 23565 : model1 loss : 0.251227 model2 loss : 0.290052
[00:06:34.407] iteration 23566 : model1 loss : 0.177728 model2 loss : 0.199352
[00:06:34.734] iteration 23567 : model1 loss : 0.250154 model2 loss : 0.290255
[00:06:35.060] iteration 23568 : model1 loss : 0.169287 model2 loss : 0.236322
[00:06:35.385] iteration 23569 : model1 loss : 0.158781 model2 loss : 0.177168
[00:06:35.712] iteration 23570 : model1 loss : 0.065139 model2 loss : 0.106863
[00:06:36.040] iteration 23571 : model1 loss : 0.172492 model2 loss : 0.207168
[00:06:36.366] iteration 23572 : model1 loss : 0.174709 model2 loss : 0.194568
[00:06:36.692] iteration 23573 : model1 loss : 0.086991 model2 loss : 0.097989
[00:06:37.018] iteration 23574 : model1 loss : 0.166179 model2 loss : 0.184538
[00:06:37.347] iteration 23575 : model1 loss : 0.191238 model2 loss : 0.187134
[00:06:37.672] iteration 23576 : model1 loss : 0.158518 model2 loss : 0.176624
[00:06:37.998] iteration 23577 : model1 loss : 0.056557 model2 loss : 0.088406
[00:06:38.324] iteration 23578 : model1 loss : 0.159919 model2 loss : 0.178768
[00:06:38.651] iteration 23579 : model1 loss : 0.150212 model2 loss : 0.188165
[00:06:38.977] iteration 23580 : model1 loss : 0.160940 model2 loss : 0.188900
[00:06:39.303] iteration 23581 : model1 loss : 0.308741 model2 loss : 0.339663
[00:06:39.627] iteration 23582 : model1 loss : 0.088130 model2 loss : 0.174667
[00:06:39.955] iteration 23583 : model1 loss : 0.181410 model2 loss : 0.250753
[00:06:40.280] iteration 23584 : model1 loss : 0.187038 model2 loss : 0.248199
[00:06:40.606] iteration 23585 : model1 loss : 0.156238 model2 loss : 0.181734
[00:06:40.931] iteration 23586 : model1 loss : 0.083353 model2 loss : 0.127842
[00:06:41.258] iteration 23587 : model1 loss : 0.095143 model2 loss : 0.158276
[00:06:41.584] iteration 23588 : model1 loss : 0.171990 model2 loss : 0.196578
[00:06:41.910] iteration 23589 : model1 loss : 0.278804 model2 loss : 0.320739
[00:06:42.236] iteration 23590 : model1 loss : 0.080085 model2 loss : 0.099967
[00:06:42.563] iteration 23591 : model1 loss : 0.066311 model2 loss : 0.164207
[00:06:42.888] iteration 23592 : model1 loss : 0.165413 model2 loss : 0.177227
[00:06:43.213] iteration 23593 : model1 loss : 0.266768 model2 loss : 0.277106
[00:06:43.538] iteration 23594 : model1 loss : 0.179243 model2 loss : 0.178469
[00:06:43.866] iteration 23595 : model1 loss : 0.255269 model2 loss : 0.260014
[00:06:44.192] iteration 23596 : model1 loss : 0.188173 model2 loss : 0.238925
[00:06:44.518] iteration 23597 : model1 loss : 0.057227 model2 loss : 0.071489
[00:06:44.844] iteration 23598 : model1 loss : 0.200102 model2 loss : 0.229299
[00:06:45.172] iteration 23599 : model1 loss : 0.185365 model2 loss : 0.207245
[00:06:45.499] iteration 23600 : model1 loss : 0.090693 model2 loss : 0.136475
[00:06:46.012] iteration 23601 : model1 loss : 0.209419 model2 loss : 0.201566
[00:06:46.338] iteration 23602 : model1 loss : 0.240895 model2 loss : 0.279112
[00:06:46.667] iteration 23603 : model1 loss : 0.173160 model2 loss : 0.202334
[00:06:46.994] iteration 23604 : model1 loss : 0.116357 model2 loss : 0.175248
[00:06:47.319] iteration 23605 : model1 loss : 0.176163 model2 loss : 0.214364
[00:06:47.644] iteration 23606 : model1 loss : 0.168993 model2 loss : 0.176544
[00:06:47.973] iteration 23607 : model1 loss : 0.159157 model2 loss : 0.187580
[00:06:48.299] iteration 23608 : model1 loss : 0.091235 model2 loss : 0.181494
[00:06:48.625] iteration 23609 : model1 loss : 0.062416 model2 loss : 0.094954
[00:06:48.952] iteration 23610 : model1 loss : 0.192615 model2 loss : 0.213523
[00:06:49.280] iteration 23611 : model1 loss : 0.180283 model2 loss : 0.195514
[00:06:49.608] iteration 23612 : model1 loss : 0.181961 model2 loss : 0.324179
[00:06:49.933] iteration 23613 : model1 loss : 0.246617 model2 loss : 0.265822
[00:06:50.260] iteration 23614 : model1 loss : 0.134359 model2 loss : 0.149481
[00:06:50.587] iteration 23615 : model1 loss : 0.103130 model2 loss : 0.234241
[00:06:50.913] iteration 23616 : model1 loss : 0.074856 model2 loss : 0.117384
[00:06:51.239] iteration 23617 : model1 loss : 0.175674 model2 loss : 0.236236
[00:06:51.565] iteration 23618 : model1 loss : 0.186201 model2 loss : 0.278724
[00:06:51.892] iteration 23619 : model1 loss : 0.156177 model2 loss : 0.239291
[00:06:52.218] iteration 23620 : model1 loss : 0.164809 model2 loss : 0.183913
[00:06:52.543] iteration 23621 : model1 loss : 0.154273 model2 loss : 0.167635
[00:06:52.870] iteration 23622 : model1 loss : 0.083381 model2 loss : 0.105094
[00:06:53.198] iteration 23623 : model1 loss : 0.324905 model2 loss : 0.351140
[00:06:53.524] iteration 23624 : model1 loss : 0.177262 model2 loss : 0.250151
[00:06:53.850] iteration 23625 : model1 loss : 0.250838 model2 loss : 0.268061
[00:06:54.175] iteration 23626 : model1 loss : 0.097816 model2 loss : 0.171422
[00:06:54.503] iteration 23627 : model1 loss : 0.167206 model2 loss : 0.218100
[00:06:54.828] iteration 23628 : model1 loss : 0.064737 model2 loss : 0.104114
[00:06:55.153] iteration 23629 : model1 loss : 0.186278 model2 loss : 0.215735
[00:06:55.479] iteration 23630 : model1 loss : 0.087248 model2 loss : 0.131886
[00:06:55.805] iteration 23631 : model1 loss : 0.197235 model2 loss : 0.204606
[00:06:56.130] iteration 23632 : model1 loss : 0.229820 model2 loss : 0.238485
[00:06:56.455] iteration 23633 : model1 loss : 0.114919 model2 loss : 0.118648
[00:06:56.781] iteration 23634 : model1 loss : 0.242156 model2 loss : 0.241204
[00:06:57.107] iteration 23635 : model1 loss : 0.246282 model2 loss : 0.293138
[00:06:57.432] iteration 23636 : model1 loss : 0.247777 model2 loss : 0.278095
[00:06:57.757] iteration 23637 : model1 loss : 0.260671 model2 loss : 0.296618
[00:06:58.083] iteration 23638 : model1 loss : 0.104970 model2 loss : 0.160814
[00:06:58.409] iteration 23639 : model1 loss : 0.151919 model2 loss : 0.262757
[00:06:58.734] iteration 23640 : model1 loss : 0.238329 model2 loss : 0.362776
[00:06:59.058] iteration 23641 : model1 loss : 0.093715 model2 loss : 0.110676
[00:06:59.384] iteration 23642 : model1 loss : 0.187839 model2 loss : 0.210413
[00:06:59.710] iteration 23643 : model1 loss : 0.171909 model2 loss : 0.189632
[00:07:00.034] iteration 23644 : model1 loss : 0.247329 model2 loss : 0.275916
[00:07:00.361] iteration 23645 : model1 loss : 0.235587 model2 loss : 0.274722
[00:07:00.686] iteration 23646 : model1 loss : 0.089993 model2 loss : 0.173320
[00:07:01.014] iteration 23647 : model1 loss : 0.194253 model2 loss : 0.207905
[00:07:01.339] iteration 23648 : model1 loss : 0.096171 model2 loss : 0.173398
[00:07:01.664] iteration 23649 : model1 loss : 0.193956 model2 loss : 0.229969
[00:07:01.992] iteration 23650 : model1 loss : 0.155489 model2 loss : 0.169677
[00:07:02.517] iteration 23651 : model1 loss : 0.252368 model2 loss : 0.256164
[00:07:02.842] iteration 23652 : model1 loss : 0.184344 model2 loss : 0.240710
[00:07:03.167] iteration 23653 : model1 loss : 0.234349 model2 loss : 0.256166
[00:07:03.493] iteration 23654 : model1 loss : 0.076959 model2 loss : 0.103487
[00:07:03.821] iteration 23655 : model1 loss : 0.235190 model2 loss : 0.248015
[00:07:04.146] iteration 23656 : model1 loss : 0.062720 model2 loss : 0.109763
[00:07:04.471] iteration 23657 : model1 loss : 0.262503 model2 loss : 0.264354
[00:07:04.798] iteration 23658 : model1 loss : 0.176905 model2 loss : 0.225593
[00:07:05.126] iteration 23659 : model1 loss : 0.247314 model2 loss : 0.267076
[00:07:05.453] iteration 23660 : model1 loss : 0.277180 model2 loss : 0.291304
[00:07:05.778] iteration 23661 : model1 loss : 0.123652 model2 loss : 0.175522
[00:07:06.102] iteration 23662 : model1 loss : 0.174705 model2 loss : 0.206896
[00:07:06.429] iteration 23663 : model1 loss : 0.230762 model2 loss : 0.258755
[00:07:06.757] iteration 23664 : model1 loss : 0.156283 model2 loss : 0.167392
[00:07:07.083] iteration 23665 : model1 loss : 0.102802 model2 loss : 0.159913
[00:07:07.410] iteration 23666 : model1 loss : 0.112887 model2 loss : 0.243727
[00:07:07.737] iteration 23667 : model1 loss : 0.165343 model2 loss : 0.184489
[00:07:08.063] iteration 23668 : model1 loss : 0.266599 model2 loss : 0.312507
[00:07:08.389] iteration 23669 : model1 loss : 0.183390 model2 loss : 0.219334
[00:07:08.715] iteration 23670 : model1 loss : 0.135753 model2 loss : 0.165967
[00:07:09.042] iteration 23671 : model1 loss : 0.178899 model2 loss : 0.221417
[00:07:09.368] iteration 23672 : model1 loss : 0.198875 model2 loss : 0.305512
[00:07:09.694] iteration 23673 : model1 loss : 0.158360 model2 loss : 0.160854
[00:07:10.020] iteration 23674 : model1 loss : 0.174267 model2 loss : 0.173981
[00:07:10.349] iteration 23675 : model1 loss : 0.236121 model2 loss : 0.242156
[00:07:10.674] iteration 23676 : model1 loss : 0.085484 model2 loss : 0.110424
[00:07:11.000] iteration 23677 : model1 loss : 0.162981 model2 loss : 0.229544
[00:07:11.326] iteration 23678 : model1 loss : 0.080725 model2 loss : 0.148451
[00:07:11.654] iteration 23679 : model1 loss : 0.100317 model2 loss : 0.145570
[00:07:11.980] iteration 23680 : model1 loss : 0.190551 model2 loss : 0.201169
[00:07:12.306] iteration 23681 : model1 loss : 0.187733 model2 loss : 0.255424
[00:07:12.632] iteration 23682 : model1 loss : 0.199134 model2 loss : 0.197920
[00:07:12.959] iteration 23683 : model1 loss : 0.196549 model2 loss : 0.205187
[00:07:13.286] iteration 23684 : model1 loss : 0.168077 model2 loss : 0.202898
[00:07:13.612] iteration 23685 : model1 loss : 0.158966 model2 loss : 0.316058
[00:07:13.938] iteration 23686 : model1 loss : 0.106814 model2 loss : 0.116090
[00:07:14.265] iteration 23687 : model1 loss : 0.169250 model2 loss : 0.188562
[00:07:14.590] iteration 23688 : model1 loss : 0.241422 model2 loss : 0.254048
[00:07:14.917] iteration 23689 : model1 loss : 0.187349 model2 loss : 0.203886
[00:07:15.243] iteration 23690 : model1 loss : 0.073872 model2 loss : 0.127350
[00:07:15.571] iteration 23691 : model1 loss : 0.258253 model2 loss : 0.302851
[00:07:15.895] iteration 23692 : model1 loss : 0.087448 model2 loss : 0.120103
[00:07:16.221] iteration 23693 : model1 loss : 0.097496 model2 loss : 0.136160
[00:07:16.548] iteration 23694 : model1 loss : 0.227233 model2 loss : 0.274045
[00:07:16.876] iteration 23695 : model1 loss : 0.168669 model2 loss : 0.265359
[00:07:17.202] iteration 23696 : model1 loss : 0.149521 model2 loss : 0.160954
[00:07:17.528] iteration 23697 : model1 loss : 0.152429 model2 loss : 0.194791
[00:07:17.853] iteration 23698 : model1 loss : 0.159842 model2 loss : 0.175385
[00:07:18.181] iteration 23699 : model1 loss : 0.258709 model2 loss : 0.268688
[00:07:18.506] iteration 23700 : model1 loss : 0.209535 model2 loss : 0.287455
[00:07:19.016] iteration 23701 : model1 loss : 0.250037 model2 loss : 0.305927
[00:07:19.342] iteration 23702 : model1 loss : 0.076165 model2 loss : 0.155741
[00:07:19.669] iteration 23703 : model1 loss : 0.240795 model2 loss : 0.271662
[00:07:19.996] iteration 23704 : model1 loss : 0.168767 model2 loss : 0.257555
[00:07:20.322] iteration 23705 : model1 loss : 0.238420 model2 loss : 0.301852
[00:07:20.648] iteration 23706 : model1 loss : 0.146733 model2 loss : 0.242580
[00:07:20.975] iteration 23707 : model1 loss : 0.219226 model2 loss : 0.269499
[00:07:21.301] iteration 23708 : model1 loss : 0.273150 model2 loss : 0.362617
[00:07:21.626] iteration 23709 : model1 loss : 0.255062 model2 loss : 0.264872
[00:07:21.952] iteration 23710 : model1 loss : 0.393532 model2 loss : 0.391880
[00:07:22.280] iteration 23711 : model1 loss : 0.139083 model2 loss : 0.198697
[00:07:22.605] iteration 23712 : model1 loss : 0.092043 model2 loss : 0.161418
[00:07:22.930] iteration 23713 : model1 loss : 0.210938 model2 loss : 0.266270
[00:07:23.255] iteration 23714 : model1 loss : 0.273032 model2 loss : 0.307288
[00:07:23.582] iteration 23715 : model1 loss : 0.192356 model2 loss : 0.214991
[00:07:23.907] iteration 23716 : model1 loss : 0.139989 model2 loss : 0.295936
[00:07:24.233] iteration 23717 : model1 loss : 0.235979 model2 loss : 0.257809
[00:07:24.559] iteration 23718 : model1 loss : 0.116416 model2 loss : 0.167953
[00:07:24.887] iteration 23719 : model1 loss : 0.144015 model2 loss : 0.154231
[00:07:25.212] iteration 23720 : model1 loss : 0.197338 model2 loss : 0.228594
[00:07:25.538] iteration 23721 : model1 loss : 0.157602 model2 loss : 0.174051
[00:07:25.864] iteration 23722 : model1 loss : 0.175644 model2 loss : 0.193515
[00:07:26.192] iteration 23723 : model1 loss : 0.314895 model2 loss : 0.320149
[00:07:26.516] iteration 23724 : model1 loss : 0.143520 model2 loss : 0.170583
[00:07:26.842] iteration 23725 : model1 loss : 0.257592 model2 loss : 0.265244
[00:07:27.167] iteration 23726 : model1 loss : 0.253643 model2 loss : 0.279522
[00:07:27.495] iteration 23727 : model1 loss : 0.126441 model2 loss : 0.171280
[00:07:27.820] iteration 23728 : model1 loss : 0.261787 model2 loss : 0.253896
[00:07:28.145] iteration 23729 : model1 loss : 0.169502 model2 loss : 0.189896
[00:07:28.470] iteration 23730 : model1 loss : 0.187500 model2 loss : 0.272166
[00:07:28.798] iteration 23731 : model1 loss : 0.086315 model2 loss : 0.088481
[00:07:29.123] iteration 23732 : model1 loss : 0.241584 model2 loss : 0.277213
[00:07:29.450] iteration 23733 : model1 loss : 0.193623 model2 loss : 0.203280
[00:07:29.776] iteration 23734 : model1 loss : 0.092698 model2 loss : 0.137170
[00:07:30.103] iteration 23735 : model1 loss : 0.230000 model2 loss : 0.248363
[00:07:30.429] iteration 23736 : model1 loss : 0.173740 model2 loss : 0.241812
[00:07:30.755] iteration 23737 : model1 loss : 0.119906 model2 loss : 0.099007
[00:07:31.081] iteration 23738 : model1 loss : 0.140952 model2 loss : 0.175319
[00:07:31.408] iteration 23739 : model1 loss : 0.079095 model2 loss : 0.140285
[00:07:31.734] iteration 23740 : model1 loss : 0.209430 model2 loss : 0.274231
[00:07:32.059] iteration 23741 : model1 loss : 0.085738 model2 loss : 0.093499
[00:07:32.385] iteration 23742 : model1 loss : 0.255988 model2 loss : 0.260967
[00:07:32.712] iteration 23743 : model1 loss : 0.162390 model2 loss : 0.191775
[00:07:33.037] iteration 23744 : model1 loss : 0.205452 model2 loss : 0.233158
[00:07:33.363] iteration 23745 : model1 loss : 0.107719 model2 loss : 0.152452
[00:07:33.688] iteration 23746 : model1 loss : 0.196674 model2 loss : 0.243646
[00:07:34.017] iteration 23747 : model1 loss : 0.249475 model2 loss : 0.274459
[00:07:34.344] iteration 23748 : model1 loss : 0.173020 model2 loss : 0.273856
[00:07:34.669] iteration 23749 : model1 loss : 0.167094 model2 loss : 0.187341
[00:07:34.995] iteration 23750 : model1 loss : 0.315435 model2 loss : 0.321898
[00:07:35.504] iteration 23751 : model1 loss : 0.249273 model2 loss : 0.266742
[00:07:35.830] iteration 23752 : model1 loss : 0.247730 model2 loss : 0.252812
[00:07:36.158] iteration 23753 : model1 loss : 0.177089 model2 loss : 0.254496
[00:07:36.484] iteration 23754 : model1 loss : 0.248118 model2 loss : 0.279332
[00:07:36.812] iteration 23755 : model1 loss : 0.255117 model2 loss : 0.269929
[00:07:37.139] iteration 23756 : model1 loss : 0.266225 model2 loss : 0.292597
[00:07:37.465] iteration 23757 : model1 loss : 0.094258 model2 loss : 0.189260
[00:07:37.792] iteration 23758 : model1 loss : 0.214249 model2 loss : 0.252447
[00:07:38.120] iteration 23759 : model1 loss : 0.178194 model2 loss : 0.184231
[00:07:38.446] iteration 23760 : model1 loss : 0.170857 model2 loss : 0.214277
[00:07:38.772] iteration 23761 : model1 loss : 0.191273 model2 loss : 0.298332
[00:07:39.098] iteration 23762 : model1 loss : 0.077159 model2 loss : 0.083655
[00:07:39.426] iteration 23763 : model1 loss : 0.094610 model2 loss : 0.153783
[00:07:39.752] iteration 23764 : model1 loss : 0.257419 model2 loss : 0.338394
[00:07:40.078] iteration 23765 : model1 loss : 0.187818 model2 loss : 0.227856
[00:07:40.406] iteration 23766 : model1 loss : 0.158158 model2 loss : 0.184743
[00:07:40.733] iteration 23767 : model1 loss : 0.244670 model2 loss : 0.248226
[00:07:41.058] iteration 23768 : model1 loss : 0.268407 model2 loss : 0.290635
[00:07:41.385] iteration 23769 : model1 loss : 0.163189 model2 loss : 0.206469
[00:07:41.710] iteration 23770 : model1 loss : 0.171469 model2 loss : 0.200729
[00:07:42.036] iteration 23771 : model1 loss : 0.103210 model2 loss : 0.195247
[00:07:42.362] iteration 23772 : model1 loss : 0.168335 model2 loss : 0.250675
[00:07:42.687] iteration 23773 : model1 loss : 0.191814 model2 loss : 0.266581
[00:07:43.013] iteration 23774 : model1 loss : 0.178511 model2 loss : 0.225324
[00:07:43.339] iteration 23775 : model1 loss : 0.079341 model2 loss : 0.090243
[00:07:43.663] iteration 23776 : model1 loss : 0.186558 model2 loss : 0.221332
[00:07:43.989] iteration 23777 : model1 loss : 0.154439 model2 loss : 0.185625
[00:07:44.314] iteration 23778 : model1 loss : 0.173927 model2 loss : 0.237356
[00:07:44.640] iteration 23779 : model1 loss : 0.165452 model2 loss : 0.183563
[00:07:44.966] iteration 23780 : model1 loss : 0.182855 model2 loss : 0.197323
[00:07:45.293] iteration 23781 : model1 loss : 0.352564 model2 loss : 0.360257
[00:07:45.619] iteration 23782 : model1 loss : 0.206008 model2 loss : 0.229227
[00:07:45.944] iteration 23783 : model1 loss : 0.169028 model2 loss : 0.286211
[00:07:46.269] iteration 23784 : model1 loss : 0.246236 model2 loss : 0.282335
[00:07:46.595] iteration 23785 : model1 loss : 0.306474 model2 loss : 0.420068
[00:07:46.922] iteration 23786 : model1 loss : 0.153147 model2 loss : 0.176709
[00:07:47.247] iteration 23787 : model1 loss : 0.171088 model2 loss : 0.199278
[00:07:47.573] iteration 23788 : model1 loss : 0.259283 model2 loss : 0.280577
[00:07:47.898] iteration 23789 : model1 loss : 0.261382 model2 loss : 0.294978
[00:07:48.224] iteration 23790 : model1 loss : 0.135687 model2 loss : 0.172539
[00:07:48.550] iteration 23791 : model1 loss : 0.262066 model2 loss : 0.277895
[00:07:48.875] iteration 23792 : model1 loss : 0.180130 model2 loss : 0.183235
[00:07:49.201] iteration 23793 : model1 loss : 0.161996 model2 loss : 0.223105
[00:07:49.528] iteration 23794 : model1 loss : 0.175237 model2 loss : 0.198757
[00:07:49.854] iteration 23795 : model1 loss : 0.179655 model2 loss : 0.227502
[00:07:50.180] iteration 23796 : model1 loss : 0.164098 model2 loss : 0.207055
[00:07:50.505] iteration 23797 : model1 loss : 0.195374 model2 loss : 0.224199
[00:07:50.831] iteration 23798 : model1 loss : 0.242334 model2 loss : 0.265312
[00:07:51.158] iteration 23799 : model1 loss : 0.092375 model2 loss : 0.148245
[00:07:51.483] iteration 23800 : model1 loss : 0.238498 model2 loss : 0.253701
[00:07:52.010] iteration 23801 : model1 loss : 0.191426 model2 loss : 0.196469
[00:07:52.336] iteration 23802 : model1 loss : 0.314521 model2 loss : 0.307601
[00:07:52.663] iteration 23803 : model1 loss : 0.255501 model2 loss : 0.202883
[00:07:52.989] iteration 23804 : model1 loss : 0.204205 model2 loss : 0.227342
[00:07:53.315] iteration 23805 : model1 loss : 0.088972 model2 loss : 0.106289
[00:07:53.642] iteration 23806 : model1 loss : 0.169981 model2 loss : 0.204291
[00:07:53.969] iteration 23807 : model1 loss : 0.181341 model2 loss : 0.215238
[00:07:54.294] iteration 23808 : model1 loss : 0.072517 model2 loss : 0.107815
[00:07:54.620] iteration 23809 : model1 loss : 0.093689 model2 loss : 0.105452
[00:07:54.949] iteration 23810 : model1 loss : 0.304385 model2 loss : 0.408000
[00:07:55.277] iteration 23811 : model1 loss : 0.273663 model2 loss : 0.285304
[00:07:55.603] iteration 23812 : model1 loss : 0.293362 model2 loss : 0.302927
[00:07:55.929] iteration 23813 : model1 loss : 0.086137 model2 loss : 0.163574
[00:07:56.256] iteration 23814 : model1 loss : 0.118438 model2 loss : 0.164472
[00:07:56.582] iteration 23815 : model1 loss : 0.155811 model2 loss : 0.198604
[00:07:56.908] iteration 23816 : model1 loss : 0.186828 model2 loss : 0.247236
[00:07:57.243] iteration 23817 : model1 loss : 0.203173 model2 loss : 0.283858
[00:07:57.569] iteration 23818 : model1 loss : 0.183553 model2 loss : 0.187596
[00:07:57.896] iteration 23819 : model1 loss : 0.174029 model2 loss : 0.169650
[00:07:58.222] iteration 23820 : model1 loss : 0.103015 model2 loss : 0.154697
[00:07:58.548] iteration 23821 : model1 loss : 0.258572 model2 loss : 0.290514
[00:07:58.874] iteration 23822 : model1 loss : 0.177321 model2 loss : 0.201036
[00:07:59.199] iteration 23823 : model1 loss : 0.236831 model2 loss : 0.260666
[00:07:59.526] iteration 23824 : model1 loss : 0.261939 model2 loss : 0.302157
[00:07:59.852] iteration 23825 : model1 loss : 0.177040 model2 loss : 0.204428
[00:08:00.178] iteration 23826 : model1 loss : 0.238330 model2 loss : 0.222640
[00:08:00.504] iteration 23827 : model1 loss : 0.164164 model2 loss : 0.193854
[00:08:00.830] iteration 23828 : model1 loss : 0.198576 model2 loss : 0.348448
[00:08:01.156] iteration 23829 : model1 loss : 0.124898 model2 loss : 0.160704
[00:08:01.481] iteration 23830 : model1 loss : 0.292240 model2 loss : 0.298161
[00:08:01.806] iteration 23831 : model1 loss : 0.077065 model2 loss : 0.093747
[00:08:02.131] iteration 23832 : model1 loss : 0.171941 model2 loss : 0.214898
[00:08:02.457] iteration 23833 : model1 loss : 0.211725 model2 loss : 0.231237
[00:08:02.784] iteration 23834 : model1 loss : 0.099580 model2 loss : 0.158336
[00:08:03.109] iteration 23835 : model1 loss : 0.183140 model2 loss : 0.204896
[00:08:03.437] iteration 23836 : model1 loss : 0.112291 model2 loss : 0.111660
[00:08:03.770] iteration 23837 : model1 loss : 0.118394 model2 loss : 0.161417
[00:08:04.096] iteration 23838 : model1 loss : 0.170656 model2 loss : 0.228734
[00:08:04.422] iteration 23839 : model1 loss : 0.257736 model2 loss : 0.265299
[00:08:04.747] iteration 23840 : model1 loss : 0.207966 model2 loss : 0.211289
[00:08:05.074] iteration 23841 : model1 loss : 0.180506 model2 loss : 0.190504
[00:08:05.400] iteration 23842 : model1 loss : 0.251075 model2 loss : 0.296128
[00:08:05.726] iteration 23843 : model1 loss : 0.174345 model2 loss : 0.183961
[00:08:06.052] iteration 23844 : model1 loss : 0.235535 model2 loss : 0.251760
[00:08:06.378] iteration 23845 : model1 loss : 0.202016 model2 loss : 0.211367
[00:08:06.704] iteration 23846 : model1 loss : 0.200576 model2 loss : 0.210235
[00:08:07.029] iteration 23847 : model1 loss : 0.172479 model2 loss : 0.207977
[00:08:07.355] iteration 23848 : model1 loss : 0.132360 model2 loss : 0.168977
[00:08:07.681] iteration 23849 : model1 loss : 0.171507 model2 loss : 0.194325
[00:08:08.006] iteration 23850 : model1 loss : 0.257529 model2 loss : 0.265689
[00:08:08.519] iteration 23851 : model1 loss : 0.266116 model2 loss : 0.284092
[00:08:08.845] iteration 23852 : model1 loss : 0.265909 model2 loss : 0.282273
[00:08:09.173] iteration 23853 : model1 loss : 0.214582 model2 loss : 0.217594
[00:08:09.499] iteration 23854 : model1 loss : 0.131166 model2 loss : 0.184514
[00:08:09.824] iteration 23855 : model1 loss : 0.152709 model2 loss : 0.156572
[00:08:10.149] iteration 23856 : model1 loss : 0.155417 model2 loss : 0.177695
[00:08:10.476] iteration 23857 : model1 loss : 0.165913 model2 loss : 0.194007
[00:08:10.802] iteration 23858 : model1 loss : 0.263982 model2 loss : 0.306094
[00:08:11.127] iteration 23859 : model1 loss : 0.088966 model2 loss : 0.121908
[00:08:11.452] iteration 23860 : model1 loss : 0.109416 model2 loss : 0.122129
[00:08:11.778] iteration 23861 : model1 loss : 0.241532 model2 loss : 0.238571
[00:08:12.104] iteration 23862 : model1 loss : 0.158587 model2 loss : 0.173626
[00:08:12.431] iteration 23863 : model1 loss : 0.072921 model2 loss : 0.129043
[00:08:12.758] iteration 23864 : model1 loss : 0.265967 model2 loss : 0.288928
[00:08:13.084] iteration 23865 : model1 loss : 0.175677 model2 loss : 0.211229
[00:08:13.410] iteration 23866 : model1 loss : 0.171459 model2 loss : 0.231667
[00:08:13.736] iteration 23867 : model1 loss : 0.278030 model2 loss : 0.354414
[00:08:14.062] iteration 23868 : model1 loss : 0.242811 model2 loss : 0.275091
[00:08:14.388] iteration 23869 : model1 loss : 0.183101 model2 loss : 0.201896
[00:08:14.715] iteration 23870 : model1 loss : 0.316541 model2 loss : 0.322372
[00:08:15.041] iteration 23871 : model1 loss : 0.185186 model2 loss : 0.189263
[00:08:15.368] iteration 23872 : model1 loss : 0.206352 model2 loss : 0.211065
[00:08:15.694] iteration 23873 : model1 loss : 0.188824 model2 loss : 0.241358
[00:08:16.020] iteration 23874 : model1 loss : 0.169034 model2 loss : 0.195359
[00:08:16.346] iteration 23875 : model1 loss : 0.199850 model2 loss : 0.278065
[00:08:16.671] iteration 23876 : model1 loss : 0.244767 model2 loss : 0.261076
[00:08:16.996] iteration 23877 : model1 loss : 0.171904 model2 loss : 0.180079
[00:08:17.322] iteration 23878 : model1 loss : 0.100778 model2 loss : 0.135164
[00:08:17.649] iteration 23879 : model1 loss : 0.157966 model2 loss : 0.123877
[00:08:17.976] iteration 23880 : model1 loss : 0.271297 model2 loss : 0.206057
[00:08:18.302] iteration 23881 : model1 loss : 0.236526 model2 loss : 0.279499
[00:08:18.629] iteration 23882 : model1 loss : 0.188180 model2 loss : 0.209672
[00:08:18.955] iteration 23883 : model1 loss : 0.249046 model2 loss : 0.264507
[00:08:19.280] iteration 23884 : model1 loss : 0.247551 model2 loss : 0.299957
[00:08:19.606] iteration 23885 : model1 loss : 0.182269 model2 loss : 0.203794
[00:08:19.932] iteration 23886 : model1 loss : 0.158707 model2 loss : 0.200982
[00:08:20.259] iteration 23887 : model1 loss : 0.256894 model2 loss : 0.249021
[00:08:20.587] iteration 23888 : model1 loss : 0.151223 model2 loss : 0.252014
[00:08:20.913] iteration 23889 : model1 loss : 0.202965 model2 loss : 0.195467
[00:08:21.245] iteration 23890 : model1 loss : 0.152292 model2 loss : 0.157956
[00:08:21.571] iteration 23891 : model1 loss : 0.248428 model2 loss : 0.256239
[00:08:21.897] iteration 23892 : model1 loss : 0.097370 model2 loss : 0.155010
[00:08:22.223] iteration 23893 : model1 loss : 0.219980 model2 loss : 0.229212
[00:08:22.550] iteration 23894 : model1 loss : 0.238604 model2 loss : 0.283528
[00:08:22.876] iteration 23895 : model1 loss : 0.169266 model2 loss : 0.213184
[00:08:23.202] iteration 23896 : model1 loss : 0.169243 model2 loss : 0.295495
[00:08:23.529] iteration 23897 : model1 loss : 0.079892 model2 loss : 0.124676
[00:08:23.856] iteration 23898 : model1 loss : 0.226355 model2 loss : 0.248188
[00:08:24.181] iteration 23899 : model1 loss : 0.275470 model2 loss : 0.343850
[00:08:24.508] iteration 23900 : model1 loss : 0.254572 model2 loss : 0.242219
[00:08:25.024] iteration 23901 : model1 loss : 0.215224 model2 loss : 0.206714
[00:08:25.351] iteration 23902 : model1 loss : 0.153422 model2 loss : 0.171179
[00:08:25.678] iteration 23903 : model1 loss : 0.180520 model2 loss : 0.245256
[00:08:26.004] iteration 23904 : model1 loss : 0.279727 model2 loss : 0.230649
[00:08:26.330] iteration 23905 : model1 loss : 0.174970 model2 loss : 0.194487
[00:08:26.656] iteration 23906 : model1 loss : 0.164925 model2 loss : 0.261308
[00:08:26.981] iteration 23907 : model1 loss : 0.188295 model2 loss : 0.198933
[00:08:27.307] iteration 23908 : model1 loss : 0.169886 model2 loss : 0.168328
[00:08:27.634] iteration 23909 : model1 loss : 0.110231 model2 loss : 0.137136
[00:08:27.960] iteration 23910 : model1 loss : 0.125154 model2 loss : 0.155964
[00:08:28.286] iteration 23911 : model1 loss : 0.165032 model2 loss : 0.207146
[00:08:28.611] iteration 23912 : model1 loss : 0.288376 model2 loss : 0.280572
[00:08:28.936] iteration 23913 : model1 loss : 0.258824 model2 loss : 0.292962
[00:08:29.263] iteration 23914 : model1 loss : 0.235660 model2 loss : 0.293486
[00:08:29.589] iteration 23915 : model1 loss : 0.150483 model2 loss : 0.172805
[00:08:29.915] iteration 23916 : model1 loss : 0.160581 model2 loss : 0.226297
[00:08:30.240] iteration 23917 : model1 loss : 0.230473 model2 loss : 0.230435
[00:08:30.571] iteration 23918 : model1 loss : 0.155063 model2 loss : 0.194510
[00:08:30.895] iteration 23919 : model1 loss : 0.146300 model2 loss : 0.152785
[00:08:31.220] iteration 23920 : model1 loss : 0.173591 model2 loss : 0.180900
[00:08:31.556] iteration 23921 : model1 loss : 0.247006 model2 loss : 0.261831
[00:08:31.893] iteration 23922 : model1 loss : 0.186331 model2 loss : 0.191615
[00:08:32.226] iteration 23923 : model1 loss : 0.099432 model2 loss : 0.133893
[00:08:32.558] iteration 23924 : model1 loss : 0.262378 model2 loss : 0.266497
[00:08:32.888] iteration 23925 : model1 loss : 0.167683 model2 loss : 0.195365
[00:08:33.219] iteration 23926 : model1 loss : 0.224092 model2 loss : 0.277358
[00:08:33.553] iteration 23927 : model1 loss : 0.175553 model2 loss : 0.185321
[00:08:33.885] iteration 23928 : model1 loss : 0.060447 model2 loss : 0.067250
[00:08:34.218] iteration 23929 : model1 loss : 0.217109 model2 loss : 0.281105
[00:08:34.556] iteration 23930 : model1 loss : 0.161311 model2 loss : 0.246436
[00:08:34.893] iteration 23931 : model1 loss : 0.190620 model2 loss : 0.208587
[00:08:35.229] iteration 23932 : model1 loss : 0.162401 model2 loss : 0.189426
[00:08:35.566] iteration 23933 : model1 loss : 0.321244 model2 loss : 0.344007
[00:08:35.910] iteration 23934 : model1 loss : 0.257615 model2 loss : 0.270308
[00:08:36.245] iteration 23935 : model1 loss : 0.199693 model2 loss : 0.197305
[00:08:36.580] iteration 23936 : model1 loss : 0.269081 model2 loss : 0.283529
[00:08:36.915] iteration 23937 : model1 loss : 0.227571 model2 loss : 0.272856
[00:08:37.256] iteration 23938 : model1 loss : 0.241805 model2 loss : 0.317886
[00:08:37.591] iteration 23939 : model1 loss : 0.295346 model2 loss : 0.386506
[00:08:37.934] iteration 23940 : model1 loss : 0.161371 model2 loss : 0.218864
[00:08:38.286] iteration 23941 : model1 loss : 0.171721 model2 loss : 0.183930
[00:08:38.620] iteration 23942 : model1 loss : 0.110359 model2 loss : 0.133432
[00:08:38.957] iteration 23943 : model1 loss : 0.288263 model2 loss : 0.289511
[00:08:39.294] iteration 23944 : model1 loss : 0.174780 model2 loss : 0.186172
[00:08:39.630] iteration 23945 : model1 loss : 0.193784 model2 loss : 0.184034
[00:08:39.965] iteration 23946 : model1 loss : 0.255515 model2 loss : 0.293514
[00:08:40.301] iteration 23947 : model1 loss : 0.201689 model2 loss : 0.234666
[00:08:40.638] iteration 23948 : model1 loss : 0.094554 model2 loss : 0.175098
[00:08:40.974] iteration 23949 : model1 loss : 0.257907 model2 loss : 0.275859
[00:08:41.315] iteration 23950 : model1 loss : 0.163834 model2 loss : 0.193339
[00:08:41.960] iteration 23951 : model1 loss : 0.059561 model2 loss : 0.080370
[00:08:42.292] iteration 23952 : model1 loss : 0.321636 model2 loss : 0.349106
[00:08:42.630] iteration 23953 : model1 loss : 0.114338 model2 loss : 0.142204
[00:08:42.969] iteration 23954 : model1 loss : 0.144538 model2 loss : 0.157336
[00:08:43.301] iteration 23955 : model1 loss : 0.202958 model2 loss : 0.233827
[00:08:43.640] iteration 23956 : model1 loss : 0.064329 model2 loss : 0.088655
[00:08:43.980] iteration 23957 : model1 loss : 0.328212 model2 loss : 0.333663
[00:08:44.319] iteration 23958 : model1 loss : 0.176943 model2 loss : 0.231487
[00:08:44.656] iteration 23959 : model1 loss : 0.136007 model2 loss : 0.164195
[00:08:44.990] iteration 23960 : model1 loss : 0.091295 model2 loss : 0.151862
[00:08:45.322] iteration 23961 : model1 loss : 0.214547 model2 loss : 0.260745
[00:08:45.656] iteration 23962 : model1 loss : 0.177956 model2 loss : 0.137198
[00:08:45.991] iteration 23963 : model1 loss : 0.190753 model2 loss : 0.216321
[00:08:46.326] iteration 23964 : model1 loss : 0.114290 model2 loss : 0.143933
[00:08:46.667] iteration 23965 : model1 loss : 0.158363 model2 loss : 0.127994
[00:08:47.004] iteration 23966 : model1 loss : 0.162110 model2 loss : 0.180234
[00:08:47.344] iteration 23967 : model1 loss : 0.094014 model2 loss : 0.224832
[00:08:47.682] iteration 23968 : model1 loss : 0.305786 model2 loss : 0.367516
[00:08:48.022] iteration 23969 : model1 loss : 0.268531 model2 loss : 0.295941
[00:08:48.359] iteration 23970 : model1 loss : 0.158989 model2 loss : 0.195845
[00:08:48.694] iteration 23971 : model1 loss : 0.168801 model2 loss : 0.244284
[00:08:49.028] iteration 23972 : model1 loss : 0.336871 model2 loss : 0.338528
[00:08:49.363] iteration 23973 : model1 loss : 0.185152 model2 loss : 0.255405
[00:08:49.698] iteration 23974 : model1 loss : 0.177241 model2 loss : 0.261447
[00:08:50.035] iteration 23975 : model1 loss : 0.236734 model2 loss : 0.248436
[00:08:50.367] iteration 23976 : model1 loss : 0.176640 model2 loss : 0.246507
[00:08:50.706] iteration 23977 : model1 loss : 0.183135 model2 loss : 0.194515
[00:08:51.043] iteration 23978 : model1 loss : 0.149290 model2 loss : 0.166813
[00:08:51.378] iteration 23979 : model1 loss : 0.170939 model2 loss : 0.247937
[00:08:51.709] iteration 23980 : model1 loss : 0.067373 model2 loss : 0.156002
[00:08:52.766] iteration 23981 : model1 loss : 0.125187 model2 loss : 0.229542
[00:08:53.102] iteration 23982 : model1 loss : 0.189975 model2 loss : 0.237585
[00:08:53.444] iteration 23983 : model1 loss : 0.170966 model2 loss : 0.245797
[00:08:53.779] iteration 23984 : model1 loss : 0.116785 model2 loss : 0.141356
[00:08:54.119] iteration 23985 : model1 loss : 0.148794 model2 loss : 0.188198
[00:08:54.456] iteration 23986 : model1 loss : 0.280138 model2 loss : 0.293171
[00:08:54.793] iteration 23987 : model1 loss : 0.217303 model2 loss : 0.233490
[00:08:55.127] iteration 23988 : model1 loss : 0.170616 model2 loss : 0.208025
[00:08:55.459] iteration 23989 : model1 loss : 0.170956 model2 loss : 0.241846
[00:08:55.794] iteration 23990 : model1 loss : 0.248362 model2 loss : 0.299586
[00:08:56.127] iteration 23991 : model1 loss : 0.249544 model2 loss : 0.278358
[00:08:56.464] iteration 23992 : model1 loss : 0.080026 model2 loss : 0.109692
[00:08:56.804] iteration 23993 : model1 loss : 0.178451 model2 loss : 0.228875
[00:08:57.140] iteration 23994 : model1 loss : 0.321320 model2 loss : 0.326872
[00:08:57.478] iteration 23995 : model1 loss : 0.178688 model2 loss : 0.211955
[00:08:57.813] iteration 23996 : model1 loss : 0.190263 model2 loss : 0.275882
[00:08:58.149] iteration 23997 : model1 loss : 0.193084 model2 loss : 0.211435
[00:08:58.488] iteration 23998 : model1 loss : 0.162159 model2 loss : 0.224116
[00:08:58.825] iteration 23999 : model1 loss : 0.167931 model2 loss : 0.180005
[00:08:59.165] iteration 24000 : model1 loss : 0.241906 model2 loss : 0.261098
[00:09:32.435] iteration 24000 : model1_mean_dice : 0.792196 model1_mean_hd95 : 11.198166
[00:09:48.650] iteration 24000 : model2_mean_dice : 0.632453 model2_mean_hd95 : 12.043035
[00:09:48.737] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_24000.pth
[00:09:48.752] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_24000.pth
[00:09:49.085] iteration 24001 : model1 loss : 0.069800 model2 loss : 0.141723
[00:09:49.405] iteration 24002 : model1 loss : 0.073932 model2 loss : 0.093630
[00:09:49.730] iteration 24003 : model1 loss : 0.235100 model2 loss : 0.250034
[00:09:50.055] iteration 24004 : model1 loss : 0.103981 model2 loss : 0.113507
[00:09:50.381] iteration 24005 : model1 loss : 0.103026 model2 loss : 0.108182
[00:09:50.707] iteration 24006 : model1 loss : 0.206836 model2 loss : 0.223508
[00:09:51.031] iteration 24007 : model1 loss : 0.078984 model2 loss : 0.115254
[00:09:51.357] iteration 24008 : model1 loss : 0.267867 model2 loss : 0.326947
[00:09:51.682] iteration 24009 : model1 loss : 0.168909 model2 loss : 0.184213
[00:09:52.007] iteration 24010 : model1 loss : 0.185684 model2 loss : 0.226903
[00:09:52.332] iteration 24011 : model1 loss : 0.301011 model2 loss : 0.403133
[00:09:52.657] iteration 24012 : model1 loss : 0.176517 model2 loss : 0.223224
[00:09:52.983] iteration 24013 : model1 loss : 0.090989 model2 loss : 0.119861
[00:09:53.307] iteration 24014 : model1 loss : 0.176990 model2 loss : 0.197064
[00:09:53.632] iteration 24015 : model1 loss : 0.255191 model2 loss : 0.259085
[00:09:53.958] iteration 24016 : model1 loss : 0.179317 model2 loss : 0.222154
[00:09:54.283] iteration 24017 : model1 loss : 0.101470 model2 loss : 0.142030
[00:09:54.608] iteration 24018 : model1 loss : 0.320695 model2 loss : 0.338654
[00:09:54.933] iteration 24019 : model1 loss : 0.164630 model2 loss : 0.175977
[00:09:55.259] iteration 24020 : model1 loss : 0.152694 model2 loss : 0.176864
[00:09:55.584] iteration 24021 : model1 loss : 0.275156 model2 loss : 0.323842
[00:09:55.910] iteration 24022 : model1 loss : 0.226606 model2 loss : 0.276200
[00:09:56.235] iteration 24023 : model1 loss : 0.175697 model2 loss : 0.218914
[00:09:56.561] iteration 24024 : model1 loss : 0.214914 model2 loss : 0.232100
[00:09:56.885] iteration 24025 : model1 loss : 0.159520 model2 loss : 0.221537
[00:09:57.212] iteration 24026 : model1 loss : 0.155784 model2 loss : 0.183337
[00:09:57.537] iteration 24027 : model1 loss : 0.099480 model2 loss : 0.193259
[00:09:57.863] iteration 24028 : model1 loss : 0.090002 model2 loss : 0.149035
[00:09:58.189] iteration 24029 : model1 loss : 0.233058 model2 loss : 0.269869
[00:09:58.516] iteration 24030 : model1 loss : 0.172914 model2 loss : 0.203487
[00:09:58.841] iteration 24031 : model1 loss : 0.078618 model2 loss : 0.156900
[00:09:59.167] iteration 24032 : model1 loss : 0.170037 model2 loss : 0.167454
[00:09:59.492] iteration 24033 : model1 loss : 0.189426 model2 loss : 0.184539
[00:09:59.819] iteration 24034 : model1 loss : 0.081434 model2 loss : 0.097328
[00:10:00.145] iteration 24035 : model1 loss : 0.229506 model2 loss : 0.260660
[00:10:00.471] iteration 24036 : model1 loss : 0.114034 model2 loss : 0.205482
[00:10:00.796] iteration 24037 : model1 loss : 0.214885 model2 loss : 0.249567
[00:10:01.121] iteration 24038 : model1 loss : 0.263412 model2 loss : 0.313988
[00:10:01.446] iteration 24039 : model1 loss : 0.164084 model2 loss : 0.231220
[00:10:01.772] iteration 24040 : model1 loss : 0.261997 model2 loss : 0.321561
[00:10:02.098] iteration 24041 : model1 loss : 0.176765 model2 loss : 0.193424
[00:10:02.424] iteration 24042 : model1 loss : 0.123957 model2 loss : 0.207949
[00:10:02.749] iteration 24043 : model1 loss : 0.306029 model2 loss : 0.406765
[00:10:03.075] iteration 24044 : model1 loss : 0.173043 model2 loss : 0.243049
[00:10:03.400] iteration 24045 : model1 loss : 0.062733 model2 loss : 0.100942
[00:10:03.725] iteration 24046 : model1 loss : 0.158855 model2 loss : 0.162518
[00:10:04.050] iteration 24047 : model1 loss : 0.178233 model2 loss : 0.223529
[00:10:04.376] iteration 24048 : model1 loss : 0.117700 model2 loss : 0.163485
[00:10:04.701] iteration 24049 : model1 loss : 0.217665 model2 loss : 0.211765
[00:10:05.027] iteration 24050 : model1 loss : 0.096397 model2 loss : 0.132492
[00:10:05.551] iteration 24051 : model1 loss : 0.096112 model2 loss : 0.142945
[00:10:05.876] iteration 24052 : model1 loss : 0.160496 model2 loss : 0.161940
[00:10:06.202] iteration 24053 : model1 loss : 0.141521 model2 loss : 0.204358
[00:10:06.528] iteration 24054 : model1 loss : 0.200744 model2 loss : 0.231671
[00:10:06.853] iteration 24055 : model1 loss : 0.176820 model2 loss : 0.314629
[00:10:07.178] iteration 24056 : model1 loss : 0.152369 model2 loss : 0.242534
[00:10:07.505] iteration 24057 : model1 loss : 0.162534 model2 loss : 0.204288
[00:10:07.831] iteration 24058 : model1 loss : 0.088956 model2 loss : 0.147020
[00:10:08.156] iteration 24059 : model1 loss : 0.316437 model2 loss : 0.321474
[00:10:08.482] iteration 24060 : model1 loss : 0.182437 model2 loss : 0.180298
[00:10:08.807] iteration 24061 : model1 loss : 0.189456 model2 loss : 0.202991
[00:10:09.133] iteration 24062 : model1 loss : 0.258830 model2 loss : 0.309295
[00:10:09.458] iteration 24063 : model1 loss : 0.165523 model2 loss : 0.188829
[00:10:09.783] iteration 24064 : model1 loss : 0.250309 model2 loss : 0.266522
[00:10:10.108] iteration 24065 : model1 loss : 0.193196 model2 loss : 0.193360
[00:10:10.434] iteration 24066 : model1 loss : 0.272152 model2 loss : 0.291311
[00:10:10.759] iteration 24067 : model1 loss : 0.162828 model2 loss : 0.203811
[00:10:11.085] iteration 24068 : model1 loss : 0.150632 model2 loss : 0.198395
[00:10:11.411] iteration 24069 : model1 loss : 0.325128 model2 loss : 0.330410
[00:10:11.736] iteration 24070 : model1 loss : 0.162310 model2 loss : 0.177596
[00:10:12.060] iteration 24071 : model1 loss : 0.259160 model2 loss : 0.283431
[00:10:12.385] iteration 24072 : model1 loss : 0.108460 model2 loss : 0.120849
[00:10:12.710] iteration 24073 : model1 loss : 0.175143 model2 loss : 0.193154
[00:10:13.035] iteration 24074 : model1 loss : 0.234882 model2 loss : 0.242531
[00:10:13.361] iteration 24075 : model1 loss : 0.208445 model2 loss : 0.189241
[00:10:13.686] iteration 24076 : model1 loss : 0.286162 model2 loss : 0.307056
[00:10:14.011] iteration 24077 : model1 loss : 0.169533 model2 loss : 0.198551
[00:10:14.337] iteration 24078 : model1 loss : 0.117893 model2 loss : 0.241887
[00:10:14.662] iteration 24079 : model1 loss : 0.072345 model2 loss : 0.113403
[00:10:14.988] iteration 24080 : model1 loss : 0.268837 model2 loss : 0.294174
[00:10:15.314] iteration 24081 : model1 loss : 0.150761 model2 loss : 0.162946
[00:10:15.639] iteration 24082 : model1 loss : 0.167942 model2 loss : 0.197865
[00:10:15.964] iteration 24083 : model1 loss : 0.165289 model2 loss : 0.209617
[00:10:16.290] iteration 24084 : model1 loss : 0.255685 model2 loss : 0.262254
[00:10:16.615] iteration 24085 : model1 loss : 0.250833 model2 loss : 0.284048
[00:10:16.942] iteration 24086 : model1 loss : 0.327641 model2 loss : 0.401796
[00:10:17.270] iteration 24087 : model1 loss : 0.141071 model2 loss : 0.217149
[00:10:17.594] iteration 24088 : model1 loss : 0.173053 model2 loss : 0.251299
[00:10:17.920] iteration 24089 : model1 loss : 0.155044 model2 loss : 0.213094
[00:10:18.245] iteration 24090 : model1 loss : 0.266942 model2 loss : 0.339474
[00:10:18.570] iteration 24091 : model1 loss : 0.208617 model2 loss : 0.247234
[00:10:18.895] iteration 24092 : model1 loss : 0.184249 model2 loss : 0.188769
[00:10:19.221] iteration 24093 : model1 loss : 0.171522 model2 loss : 0.175761
[00:10:19.546] iteration 24094 : model1 loss : 0.233112 model2 loss : 0.257071
[00:10:19.871] iteration 24095 : model1 loss : 0.189647 model2 loss : 0.216398
[00:10:20.197] iteration 24096 : model1 loss : 0.202365 model2 loss : 0.226264
[00:10:20.519] iteration 24097 : model1 loss : 0.120441 model2 loss : 0.171274
[00:10:20.844] iteration 24098 : model1 loss : 0.261270 model2 loss : 0.294306
[00:10:21.169] iteration 24099 : model1 loss : 0.281293 model2 loss : 0.341353
[00:10:21.495] iteration 24100 : model1 loss : 0.147101 model2 loss : 0.152979
[00:10:22.022] iteration 24101 : model1 loss : 0.238574 model2 loss : 0.268817
[00:10:22.347] iteration 24102 : model1 loss : 0.154875 model2 loss : 0.167435
[00:10:22.671] iteration 24103 : model1 loss : 0.249011 model2 loss : 0.206174
[00:10:22.997] iteration 24104 : model1 loss : 0.148364 model2 loss : 0.178985
[00:10:23.323] iteration 24105 : model1 loss : 0.163807 model2 loss : 0.204869
[00:10:23.649] iteration 24106 : model1 loss : 0.169984 model2 loss : 0.220386
[00:10:23.974] iteration 24107 : model1 loss : 0.092088 model2 loss : 0.155874
[00:10:24.299] iteration 24108 : model1 loss : 0.230312 model2 loss : 0.288212
[00:10:24.624] iteration 24109 : model1 loss : 0.146694 model2 loss : 0.163788
[00:10:24.949] iteration 24110 : model1 loss : 0.240163 model2 loss : 0.268535
[00:10:25.274] iteration 24111 : model1 loss : 0.181771 model2 loss : 0.208898
[00:10:25.599] iteration 24112 : model1 loss : 0.273458 model2 loss : 0.302741
[00:10:25.925] iteration 24113 : model1 loss : 0.270901 model2 loss : 0.284969
[00:10:26.250] iteration 24114 : model1 loss : 0.253344 model2 loss : 0.245805
[00:10:26.576] iteration 24115 : model1 loss : 0.091217 model2 loss : 0.107305
[00:10:26.901] iteration 24116 : model1 loss : 0.101596 model2 loss : 0.096495
[00:10:27.226] iteration 24117 : model1 loss : 0.188803 model2 loss : 0.231476
[00:10:27.551] iteration 24118 : model1 loss : 0.252601 model2 loss : 0.265809
[00:10:27.876] iteration 24119 : model1 loss : 0.201565 model2 loss : 0.216324
[00:10:28.201] iteration 24120 : model1 loss : 0.173956 model2 loss : 0.190709
[00:10:28.526] iteration 24121 : model1 loss : 0.242917 model2 loss : 0.275525
[00:10:28.850] iteration 24122 : model1 loss : 0.266036 model2 loss : 0.285339
[00:10:29.175] iteration 24123 : model1 loss : 0.163533 model2 loss : 0.179203
[00:10:29.501] iteration 24124 : model1 loss : 0.321586 model2 loss : 0.387746
[00:10:29.828] iteration 24125 : model1 loss : 0.141945 model2 loss : 0.164394
[00:10:30.154] iteration 24126 : model1 loss : 0.165591 model2 loss : 0.191807
[00:10:30.481] iteration 24127 : model1 loss : 0.101214 model2 loss : 0.142656
[00:10:30.807] iteration 24128 : model1 loss : 0.163347 model2 loss : 0.178031
[00:10:31.133] iteration 24129 : model1 loss : 0.211575 model2 loss : 0.222663
[00:10:31.459] iteration 24130 : model1 loss : 0.076747 model2 loss : 0.124826
[00:10:31.786] iteration 24131 : model1 loss : 0.164433 model2 loss : 0.192200
[00:10:32.113] iteration 24132 : model1 loss : 0.245056 model2 loss : 0.279491
[00:10:32.439] iteration 24133 : model1 loss : 0.169203 model2 loss : 0.223189
[00:10:32.766] iteration 24134 : model1 loss : 0.305275 model2 loss : 0.423884
[00:10:33.092] iteration 24135 : model1 loss : 0.208174 model2 loss : 0.239259
[00:10:33.419] iteration 24136 : model1 loss : 0.157351 model2 loss : 0.188800
[00:10:33.744] iteration 24137 : model1 loss : 0.189408 model2 loss : 0.221226
[00:10:34.070] iteration 24138 : model1 loss : 0.259881 model2 loss : 0.284683
[00:10:34.398] iteration 24139 : model1 loss : 0.149644 model2 loss : 0.170597
[00:10:34.730] iteration 24140 : model1 loss : 0.323505 model2 loss : 0.356523
[00:10:35.058] iteration 24141 : model1 loss : 0.131450 model2 loss : 0.202170
[00:10:35.384] iteration 24142 : model1 loss : 0.125712 model2 loss : 0.147391
[00:10:35.711] iteration 24143 : model1 loss : 0.244236 model2 loss : 0.296986
[00:10:36.036] iteration 24144 : model1 loss : 0.163970 model2 loss : 0.272853
[00:10:36.363] iteration 24145 : model1 loss : 0.162501 model2 loss : 0.188869
[00:10:36.688] iteration 24146 : model1 loss : 0.088174 model2 loss : 0.143709
[00:10:37.014] iteration 24147 : model1 loss : 0.099287 model2 loss : 0.104210
[00:10:37.340] iteration 24148 : model1 loss : 0.191001 model2 loss : 0.233498
[00:10:37.666] iteration 24149 : model1 loss : 0.180208 model2 loss : 0.183608
[00:10:37.992] iteration 24150 : model1 loss : 0.168610 model2 loss : 0.188065
[00:10:38.479] iteration 24151 : model1 loss : 0.165202 model2 loss : 0.187143
[00:10:38.804] iteration 24152 : model1 loss : 0.114199 model2 loss : 0.100112
[00:10:39.130] iteration 24153 : model1 loss : 0.155808 model2 loss : 0.184065
[00:10:39.456] iteration 24154 : model1 loss : 0.208326 model2 loss : 0.212757
[00:10:39.783] iteration 24155 : model1 loss : 0.081568 model2 loss : 0.158224
[00:10:40.109] iteration 24156 : model1 loss : 0.227848 model2 loss : 0.327861
[00:10:40.439] iteration 24157 : model1 loss : 0.248920 model2 loss : 0.279595
[00:10:40.766] iteration 24158 : model1 loss : 0.251414 model2 loss : 0.249411
[00:10:41.092] iteration 24159 : model1 loss : 0.197954 model2 loss : 0.223751
[00:10:41.419] iteration 24160 : model1 loss : 0.322731 model2 loss : 0.344850
[00:10:41.746] iteration 24161 : model1 loss : 0.252865 model2 loss : 0.260996
[00:10:42.072] iteration 24162 : model1 loss : 0.193707 model2 loss : 0.220913
[00:10:42.399] iteration 24163 : model1 loss : 0.113987 model2 loss : 0.153790
[00:10:42.726] iteration 24164 : model1 loss : 0.269783 model2 loss : 0.288372
[00:10:43.056] iteration 24165 : model1 loss : 0.173153 model2 loss : 0.227407
[00:10:43.394] iteration 24166 : model1 loss : 0.200792 model2 loss : 0.193441
[00:10:43.731] iteration 24167 : model1 loss : 0.182670 model2 loss : 0.210723
[00:10:44.070] iteration 24168 : model1 loss : 0.083428 model2 loss : 0.102298
[00:10:44.408] iteration 24169 : model1 loss : 0.180276 model2 loss : 0.232695
[00:10:44.748] iteration 24170 : model1 loss : 0.087119 model2 loss : 0.177930
[00:10:45.085] iteration 24171 : model1 loss : 0.323327 model2 loss : 0.325481
[00:10:45.428] iteration 24172 : model1 loss : 0.105809 model2 loss : 0.179707
[00:10:45.765] iteration 24173 : model1 loss : 0.183271 model2 loss : 0.206211
[00:10:46.103] iteration 24174 : model1 loss : 0.101119 model2 loss : 0.110716
[00:10:46.440] iteration 24175 : model1 loss : 0.118133 model2 loss : 0.162781
[00:10:46.776] iteration 24176 : model1 loss : 0.096491 model2 loss : 0.242430
[00:10:47.115] iteration 24177 : model1 loss : 0.124123 model2 loss : 0.159624
[00:10:47.452] iteration 24178 : model1 loss : 0.178782 model2 loss : 0.197099
[00:10:47.788] iteration 24179 : model1 loss : 0.155009 model2 loss : 0.192192
[00:10:48.125] iteration 24180 : model1 loss : 0.110079 model2 loss : 0.125943
[00:10:48.462] iteration 24181 : model1 loss : 0.108798 model2 loss : 0.110242
[00:10:48.798] iteration 24182 : model1 loss : 0.125534 model2 loss : 0.146002
[00:10:49.135] iteration 24183 : model1 loss : 0.118645 model2 loss : 0.185917
[00:10:49.471] iteration 24184 : model1 loss : 0.288530 model2 loss : 0.356339
[00:10:49.809] iteration 24185 : model1 loss : 0.073537 model2 loss : 0.092718
[00:10:50.146] iteration 24186 : model1 loss : 0.147975 model2 loss : 0.135730
[00:10:50.482] iteration 24187 : model1 loss : 0.279412 model2 loss : 0.338517
[00:10:50.822] iteration 24188 : model1 loss : 0.235564 model2 loss : 0.245152
[00:10:51.158] iteration 24189 : model1 loss : 0.206585 model2 loss : 0.292470
[00:10:51.494] iteration 24190 : model1 loss : 0.263235 model2 loss : 0.272905
[00:10:51.831] iteration 24191 : model1 loss : 0.142587 model2 loss : 0.143265
[00:10:52.167] iteration 24192 : model1 loss : 0.262532 model2 loss : 0.259644
[00:10:52.504] iteration 24193 : model1 loss : 0.251843 model2 loss : 0.287274
[00:10:52.841] iteration 24194 : model1 loss : 0.194938 model2 loss : 0.199250
[00:10:53.178] iteration 24195 : model1 loss : 0.238187 model2 loss : 0.264048
[00:10:53.514] iteration 24196 : model1 loss : 0.092669 model2 loss : 0.175618
[00:10:53.851] iteration 24197 : model1 loss : 0.095145 model2 loss : 0.130187
[00:10:54.188] iteration 24198 : model1 loss : 0.249259 model2 loss : 0.269295
[00:10:54.524] iteration 24199 : model1 loss : 0.242582 model2 loss : 0.244119
[00:10:54.860] iteration 24200 : model1 loss : 0.166135 model2 loss : 0.211281
[00:10:55.464] iteration 24201 : model1 loss : 0.063692 model2 loss : 0.073509
[00:10:55.800] iteration 24202 : model1 loss : 0.190997 model2 loss : 0.245481
[00:10:56.137] iteration 24203 : model1 loss : 0.192021 model2 loss : 0.271149
[00:10:56.474] iteration 24204 : model1 loss : 0.180444 model2 loss : 0.210197
[00:10:56.812] iteration 24205 : model1 loss : 0.431192 model2 loss : 0.437015
[00:10:57.151] iteration 24206 : model1 loss : 0.318043 model2 loss : 0.331956
[00:10:57.487] iteration 24207 : model1 loss : 0.180498 model2 loss : 0.201951
[00:10:57.824] iteration 24208 : model1 loss : 0.207825 model2 loss : 0.215005
[00:10:58.165] iteration 24209 : model1 loss : 0.166327 model2 loss : 0.199327
[00:10:58.502] iteration 24210 : model1 loss : 0.262936 model2 loss : 0.265801
[00:10:58.838] iteration 24211 : model1 loss : 0.143675 model2 loss : 0.179448
[00:10:59.174] iteration 24212 : model1 loss : 0.154309 model2 loss : 0.151561
[00:10:59.511] iteration 24213 : model1 loss : 0.199093 model2 loss : 0.239359
[00:10:59.847] iteration 24214 : model1 loss : 0.175865 model2 loss : 0.208123
[00:11:00.187] iteration 24215 : model1 loss : 0.092572 model2 loss : 0.125137
[00:11:00.524] iteration 24216 : model1 loss : 0.196042 model2 loss : 0.211644
[00:11:00.861] iteration 24217 : model1 loss : 0.276339 model2 loss : 0.344677
[00:11:01.197] iteration 24218 : model1 loss : 0.214431 model2 loss : 0.215080
[00:11:01.536] iteration 24219 : model1 loss : 0.183362 model2 loss : 0.180835
[00:11:01.872] iteration 24220 : model1 loss : 0.253590 model2 loss : 0.266348
[00:11:02.209] iteration 24221 : model1 loss : 0.160897 model2 loss : 0.159406
[00:11:02.546] iteration 24222 : model1 loss : 0.070895 model2 loss : 0.136614
[00:11:02.885] iteration 24223 : model1 loss : 0.237439 model2 loss : 0.258502
[00:11:03.225] iteration 24224 : model1 loss : 0.184677 model2 loss : 0.197512
[00:11:03.562] iteration 24225 : model1 loss : 0.240217 model2 loss : 0.271965
[00:11:03.900] iteration 24226 : model1 loss : 0.160190 model2 loss : 0.204950
[00:11:04.237] iteration 24227 : model1 loss : 0.155201 model2 loss : 0.226438
[00:11:04.574] iteration 24228 : model1 loss : 0.180005 model2 loss : 0.303586
[00:11:04.912] iteration 24229 : model1 loss : 0.186621 model2 loss : 0.198654
[00:11:05.251] iteration 24230 : model1 loss : 0.196806 model2 loss : 0.215053
[00:11:05.588] iteration 24231 : model1 loss : 0.084971 model2 loss : 0.112768
[00:11:05.927] iteration 24232 : model1 loss : 0.258746 model2 loss : 0.314449
[00:11:06.266] iteration 24233 : model1 loss : 0.147986 model2 loss : 0.202305
[00:11:06.604] iteration 24234 : model1 loss : 0.188785 model2 loss : 0.260712
[00:11:06.941] iteration 24235 : model1 loss : 0.265444 model2 loss : 0.297411
[00:11:07.280] iteration 24236 : model1 loss : 0.184753 model2 loss : 0.242505
[00:11:07.617] iteration 24237 : model1 loss : 0.104033 model2 loss : 0.153938
[00:11:07.954] iteration 24238 : model1 loss : 0.173573 model2 loss : 0.214337
[00:11:08.292] iteration 24239 : model1 loss : 0.169799 model2 loss : 0.204446
[00:11:08.628] iteration 24240 : model1 loss : 0.156891 model2 loss : 0.156750
[00:11:08.965] iteration 24241 : model1 loss : 0.088841 model2 loss : 0.122024
[00:11:09.302] iteration 24242 : model1 loss : 0.194096 model2 loss : 0.187966
[00:11:09.638] iteration 24243 : model1 loss : 0.183837 model2 loss : 0.232850
[00:11:09.974] iteration 24244 : model1 loss : 0.150756 model2 loss : 0.179795
[00:11:10.311] iteration 24245 : model1 loss : 0.095483 model2 loss : 0.116938
[00:11:10.647] iteration 24246 : model1 loss : 0.090782 model2 loss : 0.181706
[00:11:10.983] iteration 24247 : model1 loss : 0.090205 model2 loss : 0.157285
[00:11:11.322] iteration 24248 : model1 loss : 0.157199 model2 loss : 0.208077
[00:11:11.658] iteration 24249 : model1 loss : 0.237435 model2 loss : 0.281508
[00:11:11.996] iteration 24250 : model1 loss : 0.089455 model2 loss : 0.131213
[00:11:12.640] iteration 24251 : model1 loss : 0.123689 model2 loss : 0.176888
[00:11:12.976] iteration 24252 : model1 loss : 0.220106 model2 loss : 0.345385
[00:11:13.319] iteration 24253 : model1 loss : 0.253914 model2 loss : 0.340636
[00:11:13.657] iteration 24254 : model1 loss : 0.099245 model2 loss : 0.126465
[00:11:13.994] iteration 24255 : model1 loss : 0.095047 model2 loss : 0.123933
[00:11:14.330] iteration 24256 : model1 loss : 0.069941 model2 loss : 0.083457
[00:11:14.666] iteration 24257 : model1 loss : 0.185068 model2 loss : 0.242490
[00:11:15.004] iteration 24258 : model1 loss : 0.255511 model2 loss : 0.293592
[00:11:15.341] iteration 24259 : model1 loss : 0.172031 model2 loss : 0.203921
[00:11:15.677] iteration 24260 : model1 loss : 0.189897 model2 loss : 0.194319
[00:11:16.014] iteration 24261 : model1 loss : 0.333852 model2 loss : 0.350538
[00:11:16.350] iteration 24262 : model1 loss : 0.287427 model2 loss : 0.318912
[00:11:16.689] iteration 24263 : model1 loss : 0.165847 model2 loss : 0.174339
[00:11:17.024] iteration 24264 : model1 loss : 0.293311 model2 loss : 0.283555
[00:11:17.360] iteration 24265 : model1 loss : 0.173246 model2 loss : 0.225857
[00:11:17.697] iteration 24266 : model1 loss : 0.242916 model2 loss : 0.259895
[00:11:18.033] iteration 24267 : model1 loss : 0.175438 model2 loss : 0.174088
[00:11:18.369] iteration 24268 : model1 loss : 0.162246 model2 loss : 0.216043
[00:11:18.705] iteration 24269 : model1 loss : 0.248626 model2 loss : 0.315870
[00:11:19.042] iteration 24270 : model1 loss : 0.172838 model2 loss : 0.237773
[00:11:19.378] iteration 24271 : model1 loss : 0.229823 model2 loss : 0.257323
[00:11:19.715] iteration 24272 : model1 loss : 0.242614 model2 loss : 0.260355
[00:11:20.053] iteration 24273 : model1 loss : 0.091370 model2 loss : 0.093978
[00:11:20.390] iteration 24274 : model1 loss : 0.154637 model2 loss : 0.234033
[00:11:20.726] iteration 24275 : model1 loss : 0.179455 model2 loss : 0.225496
[00:11:21.063] iteration 24276 : model1 loss : 0.245382 model2 loss : 0.236770
[00:11:21.399] iteration 24277 : model1 loss : 0.115588 model2 loss : 0.153304
[00:11:21.735] iteration 24278 : model1 loss : 0.085778 model2 loss : 0.086862
[00:11:22.073] iteration 24279 : model1 loss : 0.177406 model2 loss : 0.211965
[00:11:22.410] iteration 24280 : model1 loss : 0.237801 model2 loss : 0.262037
[00:11:22.747] iteration 24281 : model1 loss : 0.244712 model2 loss : 0.317994
[00:11:23.083] iteration 24282 : model1 loss : 0.182468 model2 loss : 0.275560
[00:11:23.420] iteration 24283 : model1 loss : 0.185339 model2 loss : 0.177892
[00:11:23.756] iteration 24284 : model1 loss : 0.253178 model2 loss : 0.297555
[00:11:24.092] iteration 24285 : model1 loss : 0.227063 model2 loss : 0.298662
[00:11:24.429] iteration 24286 : model1 loss : 0.074062 model2 loss : 0.107421
[00:11:24.765] iteration 24287 : model1 loss : 0.267978 model2 loss : 0.274616
[00:11:25.101] iteration 24288 : model1 loss : 0.186811 model2 loss : 0.262660
[00:11:25.438] iteration 24289 : model1 loss : 0.252947 model2 loss : 0.267013
[00:11:25.775] iteration 24290 : model1 loss : 0.265699 model2 loss : 0.322525
[00:11:26.111] iteration 24291 : model1 loss : 0.225442 model2 loss : 0.230707
[00:11:26.448] iteration 24292 : model1 loss : 0.209151 model2 loss : 0.212678
[00:11:26.781] iteration 24293 : model1 loss : 0.164623 model2 loss : 0.186497
[00:11:27.121] iteration 24294 : model1 loss : 0.267626 model2 loss : 0.323999
[00:11:27.457] iteration 24295 : model1 loss : 0.295415 model2 loss : 0.308867
[00:11:27.796] iteration 24296 : model1 loss : 0.275516 model2 loss : 0.291938
[00:11:28.151] iteration 24297 : model1 loss : 0.170565 model2 loss : 0.208511
[00:11:28.488] iteration 24298 : model1 loss : 0.171260 model2 loss : 0.194671
[00:11:28.826] iteration 24299 : model1 loss : 0.094405 model2 loss : 0.106905
[00:11:29.166] iteration 24300 : model1 loss : 0.198920 model2 loss : 0.194856
[00:11:29.807] iteration 24301 : model1 loss : 0.194516 model2 loss : 0.242960
[00:11:30.145] iteration 24302 : model1 loss : 0.167332 model2 loss : 0.198224
[00:11:30.482] iteration 24303 : model1 loss : 0.166194 model2 loss : 0.187565
[00:11:30.819] iteration 24304 : model1 loss : 0.206560 model2 loss : 0.254031
[00:11:31.156] iteration 24305 : model1 loss : 0.247435 model2 loss : 0.272864
[00:11:31.493] iteration 24306 : model1 loss : 0.225210 model2 loss : 0.244244
[00:11:31.829] iteration 24307 : model1 loss : 0.130461 model2 loss : 0.173378
[00:11:32.170] iteration 24308 : model1 loss : 0.248003 model2 loss : 0.290522
[00:11:32.512] iteration 24309 : model1 loss : 0.183990 model2 loss : 0.174894
[00:11:32.848] iteration 24310 : model1 loss : 0.088636 model2 loss : 0.086227
[00:11:33.186] iteration 24311 : model1 loss : 0.155472 model2 loss : 0.200700
[00:11:33.522] iteration 24312 : model1 loss : 0.114885 model2 loss : 0.095185
[00:11:33.859] iteration 24313 : model1 loss : 0.265694 model2 loss : 0.297178
[00:11:34.200] iteration 24314 : model1 loss : 0.176797 model2 loss : 0.174409
[00:11:34.538] iteration 24315 : model1 loss : 0.196990 model2 loss : 0.210799
[00:11:34.876] iteration 24316 : model1 loss : 0.323145 model2 loss : 0.346283
[00:11:35.214] iteration 24317 : model1 loss : 0.058368 model2 loss : 0.122379
[00:11:35.552] iteration 24318 : model1 loss : 0.174659 model2 loss : 0.203973
[00:11:35.890] iteration 24319 : model1 loss : 0.176893 model2 loss : 0.194096
[00:11:36.228] iteration 24320 : model1 loss : 0.323792 model2 loss : 0.334215
[00:11:36.566] iteration 24321 : model1 loss : 0.259807 model2 loss : 0.282954
[00:11:36.904] iteration 24322 : model1 loss : 0.202228 model2 loss : 0.231127
[00:11:37.242] iteration 24323 : model1 loss : 0.275041 model2 loss : 0.285843
[00:11:37.579] iteration 24324 : model1 loss : 0.198308 model2 loss : 0.264600
[00:11:37.917] iteration 24325 : model1 loss : 0.091654 model2 loss : 0.116929
[00:11:38.255] iteration 24326 : model1 loss : 0.242173 model2 loss : 0.263422
[00:11:38.592] iteration 24327 : model1 loss : 0.311993 model2 loss : 0.332316
[00:11:38.929] iteration 24328 : model1 loss : 0.069687 model2 loss : 0.126900
[00:11:39.267] iteration 24329 : model1 loss : 0.084174 model2 loss : 0.123820
[00:11:39.605] iteration 24330 : model1 loss : 0.242265 model2 loss : 0.291148
[00:11:39.944] iteration 24331 : model1 loss : 0.076638 model2 loss : 0.127218
[00:11:40.282] iteration 24332 : model1 loss : 0.147992 model2 loss : 0.152811
[00:11:40.620] iteration 24333 : model1 loss : 0.114582 model2 loss : 0.107760
[00:11:40.957] iteration 24334 : model1 loss : 0.172280 model2 loss : 0.212409
[00:11:41.295] iteration 24335 : model1 loss : 0.243538 model2 loss : 0.250258
[00:11:41.635] iteration 24336 : model1 loss : 0.232649 model2 loss : 0.282064
[00:11:41.973] iteration 24337 : model1 loss : 0.287739 model2 loss : 0.267623
[00:11:42.310] iteration 24338 : model1 loss : 0.168294 model2 loss : 0.187902
[00:11:42.650] iteration 24339 : model1 loss : 0.155459 model2 loss : 0.210380
[00:11:42.991] iteration 24340 : model1 loss : 0.184293 model2 loss : 0.204337
[00:11:43.329] iteration 24341 : model1 loss : 0.250627 model2 loss : 0.253435
[00:11:43.667] iteration 24342 : model1 loss : 0.175907 model2 loss : 0.189729
[00:11:44.003] iteration 24343 : model1 loss : 0.276347 model2 loss : 0.324962
[00:11:44.345] iteration 24344 : model1 loss : 0.093162 model2 loss : 0.099699
[00:11:44.681] iteration 24345 : model1 loss : 0.145769 model2 loss : 0.183586
[00:11:45.017] iteration 24346 : model1 loss : 0.132155 model2 loss : 0.164371
[00:11:45.356] iteration 24347 : model1 loss : 0.152461 model2 loss : 0.207136
[00:11:45.692] iteration 24348 : model1 loss : 0.257335 model2 loss : 0.278201
[00:11:46.029] iteration 24349 : model1 loss : 0.165126 model2 loss : 0.204290
[00:11:46.370] iteration 24350 : model1 loss : 0.167754 model2 loss : 0.172966
[00:11:47.057] iteration 24351 : model1 loss : 0.250640 model2 loss : 0.249241
[00:11:47.397] iteration 24352 : model1 loss : 0.191940 model2 loss : 0.317832
[00:11:47.733] iteration 24353 : model1 loss : 0.264573 model2 loss : 0.305264
[00:11:48.070] iteration 24354 : model1 loss : 0.299434 model2 loss : 0.405956
[00:11:48.410] iteration 24355 : model1 loss : 0.194122 model2 loss : 0.220851
[00:11:48.745] iteration 24356 : model1 loss : 0.249267 model2 loss : 0.286138
[00:11:49.084] iteration 24357 : model1 loss : 0.238885 model2 loss : 0.273382
[00:11:49.421] iteration 24358 : model1 loss : 0.245581 model2 loss : 0.276559
[00:11:49.761] iteration 24359 : model1 loss : 0.198440 model2 loss : 0.226392
[00:11:50.106] iteration 24360 : model1 loss : 0.172333 model2 loss : 0.215999
[00:11:50.448] iteration 24361 : model1 loss : 0.221253 model2 loss : 0.277546
[00:11:50.789] iteration 24362 : model1 loss : 0.185872 model2 loss : 0.201126
[00:11:51.126] iteration 24363 : model1 loss : 0.253892 model2 loss : 0.279978
[00:11:51.469] iteration 24364 : model1 loss : 0.245947 model2 loss : 0.285908
[00:11:51.803] iteration 24365 : model1 loss : 0.374874 model2 loss : 0.382568
[00:11:52.146] iteration 24366 : model1 loss : 0.081917 model2 loss : 0.119873
[00:11:52.488] iteration 24367 : model1 loss : 0.194286 model2 loss : 0.234909
[00:11:52.820] iteration 24368 : model1 loss : 0.265925 model2 loss : 0.294062
[00:11:53.154] iteration 24369 : model1 loss : 0.189346 model2 loss : 0.197190
[00:11:53.489] iteration 24370 : model1 loss : 0.162670 model2 loss : 0.240169
[00:11:53.826] iteration 24371 : model1 loss : 0.244346 model2 loss : 0.246938
[00:11:54.164] iteration 24372 : model1 loss : 0.112686 model2 loss : 0.136273
[00:11:54.506] iteration 24373 : model1 loss : 0.248954 model2 loss : 0.299013
[00:11:54.842] iteration 24374 : model1 loss : 0.258524 model2 loss : 0.293885
[00:11:55.175] iteration 24375 : model1 loss : 0.143147 model2 loss : 0.188341
[00:11:55.512] iteration 24376 : model1 loss : 0.168733 model2 loss : 0.194715
[00:11:55.850] iteration 24377 : model1 loss : 0.248157 model2 loss : 0.300553
[00:11:56.191] iteration 24378 : model1 loss : 0.228638 model2 loss : 0.253247
[00:11:56.526] iteration 24379 : model1 loss : 0.205231 model2 loss : 0.216785
[00:11:56.859] iteration 24380 : model1 loss : 0.111106 model2 loss : 0.164106
[00:11:57.195] iteration 24381 : model1 loss : 0.257739 model2 loss : 0.279211
[00:11:57.530] iteration 24382 : model1 loss : 0.262545 model2 loss : 0.339647
[00:11:57.864] iteration 24383 : model1 loss : 0.266923 model2 loss : 0.337664
[00:11:58.200] iteration 24384 : model1 loss : 0.276813 model2 loss : 0.299080
[00:11:58.538] iteration 24385 : model1 loss : 0.240613 model2 loss : 0.256503
[00:11:58.873] iteration 24386 : model1 loss : 0.156058 model2 loss : 0.202897
[00:11:59.204] iteration 24387 : model1 loss : 0.241097 model2 loss : 0.254486
[00:11:59.540] iteration 24388 : model1 loss : 0.192963 model2 loss : 0.182583
[00:11:59.879] iteration 24389 : model1 loss : 0.219326 model2 loss : 0.175550
[00:12:00.220] iteration 24390 : model1 loss : 0.242135 model2 loss : 0.289809
[00:12:00.557] iteration 24391 : model1 loss : 0.272969 model2 loss : 0.241590
[00:12:00.893] iteration 24392 : model1 loss : 0.115895 model2 loss : 0.140513
[00:12:01.226] iteration 24393 : model1 loss : 0.186781 model2 loss : 0.208919
[00:12:01.559] iteration 24394 : model1 loss : 0.130577 model2 loss : 0.128608
[00:12:01.891] iteration 24395 : model1 loss : 0.185495 model2 loss : 0.198611
[00:12:02.226] iteration 24396 : model1 loss : 0.261140 model2 loss : 0.255540
[00:12:02.560] iteration 24397 : model1 loss : 0.102025 model2 loss : 0.170791
[00:12:02.898] iteration 24398 : model1 loss : 0.076437 model2 loss : 0.113531
[00:12:03.235] iteration 24399 : model1 loss : 0.094037 model2 loss : 0.157619
[00:12:03.573] iteration 24400 : model1 loss : 0.117365 model2 loss : 0.197657
[00:12:04.216] iteration 24401 : model1 loss : 0.163090 model2 loss : 0.225799
[00:12:04.553] iteration 24402 : model1 loss : 0.166786 model2 loss : 0.187297
[00:12:04.890] iteration 24403 : model1 loss : 0.098925 model2 loss : 0.155211
[00:12:05.226] iteration 24404 : model1 loss : 0.166770 model2 loss : 0.200704
[00:12:05.561] iteration 24405 : model1 loss : 0.153323 model2 loss : 0.188438
[00:12:05.897] iteration 24406 : model1 loss : 0.158239 model2 loss : 0.172292
[00:12:06.237] iteration 24407 : model1 loss : 0.107899 model2 loss : 0.149198
[00:12:06.577] iteration 24408 : model1 loss : 0.259761 model2 loss : 0.275088
[00:12:06.914] iteration 24409 : model1 loss : 0.196864 model2 loss : 0.262441
[00:12:07.255] iteration 24410 : model1 loss : 0.088819 model2 loss : 0.215746
[00:12:07.590] iteration 24411 : model1 loss : 0.245753 model2 loss : 0.264963
[00:12:07.926] iteration 24412 : model1 loss : 0.064929 model2 loss : 0.090000
[00:12:08.264] iteration 24413 : model1 loss : 0.163482 model2 loss : 0.169099
[00:12:08.604] iteration 24414 : model1 loss : 0.082664 model2 loss : 0.121756
[00:12:08.942] iteration 24415 : model1 loss : 0.218636 model2 loss : 0.301119
[00:12:09.281] iteration 24416 : model1 loss : 0.104162 model2 loss : 0.108968
[00:12:09.617] iteration 24417 : model1 loss : 0.125830 model2 loss : 0.128856
[00:12:09.956] iteration 24418 : model1 loss : 0.269356 model2 loss : 0.282698
[00:12:10.293] iteration 24419 : model1 loss : 0.230465 model2 loss : 0.229312
[00:12:10.627] iteration 24420 : model1 loss : 0.154647 model2 loss : 0.170344
[00:12:10.965] iteration 24421 : model1 loss : 0.191959 model2 loss : 0.245573
[00:12:11.302] iteration 24422 : model1 loss : 0.174222 model2 loss : 0.208008
[00:12:11.639] iteration 24423 : model1 loss : 0.095184 model2 loss : 0.155654
[00:12:11.975] iteration 24424 : model1 loss : 0.244122 model2 loss : 0.232685
[00:12:12.312] iteration 24425 : model1 loss : 0.245147 model2 loss : 0.269824
[00:12:12.645] iteration 24426 : model1 loss : 0.179584 model2 loss : 0.152162
[00:12:12.982] iteration 24427 : model1 loss : 0.262894 model2 loss : 0.274980
[00:12:13.320] iteration 24428 : model1 loss : 0.091990 model2 loss : 0.101826
[00:12:13.654] iteration 24429 : model1 loss : 0.150265 model2 loss : 0.182296
[00:12:13.995] iteration 24430 : model1 loss : 0.231336 model2 loss : 0.268640
[00:12:14.333] iteration 24431 : model1 loss : 0.073555 model2 loss : 0.116047
[00:12:14.670] iteration 24432 : model1 loss : 0.142369 model2 loss : 0.181966
[00:12:15.012] iteration 24433 : model1 loss : 0.109162 model2 loss : 0.174468
[00:12:15.349] iteration 24434 : model1 loss : 0.280411 model2 loss : 0.352617
[00:12:15.691] iteration 24435 : model1 loss : 0.186567 model2 loss : 0.192590
[00:12:16.027] iteration 24436 : model1 loss : 0.291115 model2 loss : 0.332384
[00:12:16.365] iteration 24437 : model1 loss : 0.285751 model2 loss : 0.361264
[00:12:16.702] iteration 24438 : model1 loss : 0.199133 model2 loss : 0.235246
[00:12:17.039] iteration 24439 : model1 loss : 0.138376 model2 loss : 0.219098
[00:12:17.377] iteration 24440 : model1 loss : 0.189652 model2 loss : 0.223433
[00:12:17.714] iteration 24441 : model1 loss : 0.094608 model2 loss : 0.181930
[00:12:18.051] iteration 24442 : model1 loss : 0.262590 model2 loss : 0.265216
[00:12:18.389] iteration 24443 : model1 loss : 0.180562 model2 loss : 0.242876
[00:12:18.725] iteration 24444 : model1 loss : 0.158721 model2 loss : 0.150665
[00:12:19.058] iteration 24445 : model1 loss : 0.185035 model2 loss : 0.202586
[00:12:19.391] iteration 24446 : model1 loss : 0.230132 model2 loss : 0.242475
[00:12:19.724] iteration 24447 : model1 loss : 0.164878 model2 loss : 0.213607
[00:12:20.058] iteration 24448 : model1 loss : 0.264353 model2 loss : 0.277452
[00:12:20.391] iteration 24449 : model1 loss : 0.112294 model2 loss : 0.135519
[00:12:20.723] iteration 24450 : model1 loss : 0.177201 model2 loss : 0.242410
[00:12:21.416] iteration 24451 : model1 loss : 0.203071 model2 loss : 0.240539
[00:12:21.752] iteration 24452 : model1 loss : 0.280584 model2 loss : 0.288081
[00:12:22.085] iteration 24453 : model1 loss : 0.195718 model2 loss : 0.222665
[00:12:22.418] iteration 24454 : model1 loss : 0.080250 model2 loss : 0.146670
[00:12:22.755] iteration 24455 : model1 loss : 0.056111 model2 loss : 0.109182
[00:12:23.092] iteration 24456 : model1 loss : 0.324916 model2 loss : 0.249021
[00:12:23.431] iteration 24457 : model1 loss : 0.159135 model2 loss : 0.223403
[00:12:23.768] iteration 24458 : model1 loss : 0.155933 model2 loss : 0.260665
[00:12:24.108] iteration 24459 : model1 loss : 0.159746 model2 loss : 0.176786
[00:12:24.443] iteration 24460 : model1 loss : 0.168532 model2 loss : 0.184358
[00:12:24.776] iteration 24461 : model1 loss : 0.107088 model2 loss : 0.122645
[00:12:25.113] iteration 24462 : model1 loss : 0.171108 model2 loss : 0.185586
[00:12:25.449] iteration 24463 : model1 loss : 0.184496 model2 loss : 0.206688
[00:12:25.784] iteration 24464 : model1 loss : 0.276439 model2 loss : 0.291569
[00:12:26.121] iteration 24465 : model1 loss : 0.195143 model2 loss : 0.197006
[00:12:26.457] iteration 24466 : model1 loss : 0.165861 model2 loss : 0.192667
[00:12:26.792] iteration 24467 : model1 loss : 0.204218 model2 loss : 0.206676
[00:12:27.127] iteration 24468 : model1 loss : 0.077787 model2 loss : 0.093941
[00:12:27.458] iteration 24469 : model1 loss : 0.201366 model2 loss : 0.214534
[00:12:27.790] iteration 24470 : model1 loss : 0.085841 model2 loss : 0.150673
[00:12:28.122] iteration 24471 : model1 loss : 0.161657 model2 loss : 0.189671
[00:12:28.454] iteration 24472 : model1 loss : 0.165824 model2 loss : 0.239953
[00:12:28.790] iteration 24473 : model1 loss : 0.086009 model2 loss : 0.117716
[00:12:29.127] iteration 24474 : model1 loss : 0.174352 model2 loss : 0.223140
[00:12:29.463] iteration 24475 : model1 loss : 0.327477 model2 loss : 0.367632
[00:12:29.797] iteration 24476 : model1 loss : 0.272908 model2 loss : 0.310961
[00:12:30.133] iteration 24477 : model1 loss : 0.147801 model2 loss : 0.189150
[00:12:30.470] iteration 24478 : model1 loss : 0.179537 model2 loss : 0.223801
[00:12:30.806] iteration 24479 : model1 loss : 0.174736 model2 loss : 0.238626
[00:12:31.144] iteration 24480 : model1 loss : 0.106479 model2 loss : 0.163346
[00:12:31.480] iteration 24481 : model1 loss : 0.176344 model2 loss : 0.242421
[00:12:31.816] iteration 24482 : model1 loss : 0.098659 model2 loss : 0.115339
[00:12:32.152] iteration 24483 : model1 loss : 0.136873 model2 loss : 0.168493
[00:12:32.486] iteration 24484 : model1 loss : 0.260125 model2 loss : 0.293966
[00:12:32.820] iteration 24485 : model1 loss : 0.270592 model2 loss : 0.254728
[00:12:33.151] iteration 24486 : model1 loss : 0.161000 model2 loss : 0.231602
[00:12:33.482] iteration 24487 : model1 loss : 0.093048 model2 loss : 0.135983
[00:12:33.814] iteration 24488 : model1 loss : 0.260556 model2 loss : 0.252771
[00:12:34.150] iteration 24489 : model1 loss : 0.204322 model2 loss : 0.220836
[00:12:34.486] iteration 24490 : model1 loss : 0.179979 model2 loss : 0.236720
[00:12:34.820] iteration 24491 : model1 loss : 0.272654 model2 loss : 0.298039
[00:12:35.152] iteration 24492 : model1 loss : 0.164300 model2 loss : 0.226763
[00:12:35.488] iteration 24493 : model1 loss : 0.167919 model2 loss : 0.164732
[00:12:35.824] iteration 24494 : model1 loss : 0.277876 model2 loss : 0.275055
[00:12:36.160] iteration 24495 : model1 loss : 0.123018 model2 loss : 0.167913
[00:12:36.494] iteration 24496 : model1 loss : 0.397098 model2 loss : 0.425853
[00:12:36.831] iteration 24497 : model1 loss : 0.198981 model2 loss : 0.237261
[00:12:37.166] iteration 24498 : model1 loss : 0.104135 model2 loss : 0.137786
[00:12:37.502] iteration 24499 : model1 loss : 0.298742 model2 loss : 0.333592
[00:12:37.840] iteration 24500 : model1 loss : 0.217886 model2 loss : 0.288563
[00:12:38.494] iteration 24501 : model1 loss : 0.262223 model2 loss : 0.273550
[00:12:38.831] iteration 24502 : model1 loss : 0.157452 model2 loss : 0.226736
[00:12:39.166] iteration 24503 : model1 loss : 0.082323 model2 loss : 0.139489
[00:12:39.503] iteration 24504 : model1 loss : 0.193538 model2 loss : 0.212793
[00:12:39.839] iteration 24505 : model1 loss : 0.261166 model2 loss : 0.300634
[00:12:40.176] iteration 24506 : model1 loss : 0.103701 model2 loss : 0.144469
[00:12:40.513] iteration 24507 : model1 loss : 0.111624 model2 loss : 0.230409
[00:12:40.848] iteration 24508 : model1 loss : 0.259773 model2 loss : 0.266380
[00:12:41.184] iteration 24509 : model1 loss : 0.182208 model2 loss : 0.218850
[00:12:41.520] iteration 24510 : model1 loss : 0.256993 model2 loss : 0.281908
[00:12:41.857] iteration 24511 : model1 loss : 0.238113 model2 loss : 0.162272
[00:12:42.193] iteration 24512 : model1 loss : 0.248733 model2 loss : 0.290149
[00:12:42.527] iteration 24513 : model1 loss : 0.096646 model2 loss : 0.210639
[00:12:42.862] iteration 24514 : model1 loss : 0.172840 model2 loss : 0.206937
[00:12:43.197] iteration 24515 : model1 loss : 0.237291 model2 loss : 0.267359
[00:12:43.531] iteration 24516 : model1 loss : 0.164898 model2 loss : 0.220453
[00:12:43.867] iteration 24517 : model1 loss : 0.176887 model2 loss : 0.232802
[00:12:44.204] iteration 24518 : model1 loss : 0.083162 model2 loss : 0.169394
[00:12:44.538] iteration 24519 : model1 loss : 0.103246 model2 loss : 0.110988
[00:12:44.873] iteration 24520 : model1 loss : 0.243017 model2 loss : 0.271364
[00:12:45.209] iteration 24521 : model1 loss : 0.155021 model2 loss : 0.178974
[00:12:45.543] iteration 24522 : model1 loss : 0.161971 model2 loss : 0.235834
[00:12:45.873] iteration 24523 : model1 loss : 0.150640 model2 loss : 0.144452
[00:12:46.209] iteration 24524 : model1 loss : 0.184508 model2 loss : 0.195534
[00:12:46.544] iteration 24525 : model1 loss : 0.256715 model2 loss : 0.289607
[00:12:47.415] iteration 24526 : model1 loss : 0.175190 model2 loss : 0.199785
[00:12:47.747] iteration 24527 : model1 loss : 0.162742 model2 loss : 0.202567
[00:12:48.083] iteration 24528 : model1 loss : 0.210998 model2 loss : 0.290270
[00:12:48.419] iteration 24529 : model1 loss : 0.160921 model2 loss : 0.201100
[00:12:48.756] iteration 24530 : model1 loss : 0.246905 model2 loss : 0.273440
[00:12:49.092] iteration 24531 : model1 loss : 0.069100 model2 loss : 0.129279
[00:12:49.427] iteration 24532 : model1 loss : 0.109092 model2 loss : 0.156166
[00:12:49.764] iteration 24533 : model1 loss : 0.181145 model2 loss : 0.177298
[00:12:50.100] iteration 24534 : model1 loss : 0.085867 model2 loss : 0.096968
[00:12:50.436] iteration 24535 : model1 loss : 0.153612 model2 loss : 0.211886
[00:12:50.770] iteration 24536 : model1 loss : 0.271735 model2 loss : 0.295797
[00:12:51.102] iteration 24537 : model1 loss : 0.167253 model2 loss : 0.172588
[00:12:51.434] iteration 24538 : model1 loss : 0.250009 model2 loss : 0.314266
[00:12:51.765] iteration 24539 : model1 loss : 0.278343 model2 loss : 0.292086
[00:12:52.096] iteration 24540 : model1 loss : 0.168210 model2 loss : 0.204511
[00:12:52.432] iteration 24541 : model1 loss : 0.197298 model2 loss : 0.194478
[00:12:52.769] iteration 24542 : model1 loss : 0.209290 model2 loss : 0.172600
[00:12:53.104] iteration 24543 : model1 loss : 0.069130 model2 loss : 0.146994
[00:12:53.441] iteration 24544 : model1 loss : 0.159910 model2 loss : 0.170245
[00:12:53.776] iteration 24545 : model1 loss : 0.278546 model2 loss : 0.308621
[00:12:54.108] iteration 24546 : model1 loss : 0.263747 model2 loss : 0.276120
[00:12:54.462] iteration 24547 : model1 loss : 0.170077 model2 loss : 0.184063
[00:12:54.788] iteration 24548 : model1 loss : 0.273551 model2 loss : 0.273000
[00:12:55.114] iteration 24549 : model1 loss : 0.262544 model2 loss : 0.295496
[00:12:55.437] iteration 24550 : model1 loss : 0.154261 model2 loss : 0.167468
[00:12:55.987] iteration 24551 : model1 loss : 0.176974 model2 loss : 0.201106
[00:12:56.315] iteration 24552 : model1 loss : 0.201214 model2 loss : 0.235891
[00:12:56.641] iteration 24553 : model1 loss : 0.216670 model2 loss : 0.199807
[00:12:56.965] iteration 24554 : model1 loss : 0.185330 model2 loss : 0.211691
[00:12:57.289] iteration 24555 : model1 loss : 0.177066 model2 loss : 0.267381
[00:12:57.617] iteration 24556 : model1 loss : 0.187725 model2 loss : 0.218971
[00:12:57.943] iteration 24557 : model1 loss : 0.105583 model2 loss : 0.188951
[00:12:58.266] iteration 24558 : model1 loss : 0.186339 model2 loss : 0.184677
[00:12:58.589] iteration 24559 : model1 loss : 0.091122 model2 loss : 0.151026
[00:12:58.912] iteration 24560 : model1 loss : 0.200167 model2 loss : 0.218287
[00:12:59.236] iteration 24561 : model1 loss : 0.255804 model2 loss : 0.245475
[00:12:59.564] iteration 24562 : model1 loss : 0.209712 model2 loss : 0.252814
[00:12:59.890] iteration 24563 : model1 loss : 0.139570 model2 loss : 0.250919
[00:13:00.217] iteration 24564 : model1 loss : 0.157664 model2 loss : 0.240836
[00:13:00.544] iteration 24565 : model1 loss : 0.177075 model2 loss : 0.257037
[00:13:00.872] iteration 24566 : model1 loss : 0.111349 model2 loss : 0.164200
[00:13:01.200] iteration 24567 : model1 loss : 0.192903 model2 loss : 0.200944
[00:13:01.528] iteration 24568 : model1 loss : 0.169007 model2 loss : 0.211542
[00:13:01.854] iteration 24569 : model1 loss : 0.270956 model2 loss : 0.265169
[00:13:02.180] iteration 24570 : model1 loss : 0.108605 model2 loss : 0.171901
[00:13:02.507] iteration 24571 : model1 loss : 0.174426 model2 loss : 0.199301
[00:13:02.835] iteration 24572 : model1 loss : 0.246858 model2 loss : 0.254312
[00:13:03.166] iteration 24573 : model1 loss : 0.091067 model2 loss : 0.129014
[00:13:03.493] iteration 24574 : model1 loss : 0.116584 model2 loss : 0.226149
[00:13:03.821] iteration 24575 : model1 loss : 0.250148 model2 loss : 0.251655
[00:13:04.146] iteration 24576 : model1 loss : 0.246242 model2 loss : 0.294927
[00:13:04.471] iteration 24577 : model1 loss : 0.187580 model2 loss : 0.196897
[00:13:04.792] iteration 24578 : model1 loss : 0.216028 model2 loss : 0.240624
[00:13:05.119] iteration 24579 : model1 loss : 0.266782 model2 loss : 0.266261
[00:13:05.444] iteration 24580 : model1 loss : 0.295966 model2 loss : 0.287862
[00:13:05.765] iteration 24581 : model1 loss : 0.166807 model2 loss : 0.224820
[00:13:06.089] iteration 24582 : model1 loss : 0.183676 model2 loss : 0.201491
[00:13:06.417] iteration 24583 : model1 loss : 0.226695 model2 loss : 0.296976
[00:13:06.742] iteration 24584 : model1 loss : 0.189089 model2 loss : 0.215343
[00:13:07.067] iteration 24585 : model1 loss : 0.244047 model2 loss : 0.238703
[00:13:07.390] iteration 24586 : model1 loss : 0.181642 model2 loss : 0.255080
[00:13:07.716] iteration 24587 : model1 loss : 0.080676 model2 loss : 0.109574
[00:13:08.043] iteration 24588 : model1 loss : 0.168568 model2 loss : 0.196254
[00:13:08.369] iteration 24589 : model1 loss : 0.109416 model2 loss : 0.185294
[00:13:08.692] iteration 24590 : model1 loss : 0.194208 model2 loss : 0.209913
[00:13:09.014] iteration 24591 : model1 loss : 0.155792 model2 loss : 0.262538
[00:13:09.340] iteration 24592 : model1 loss : 0.079445 model2 loss : 0.124464
[00:13:09.666] iteration 24593 : model1 loss : 0.192173 model2 loss : 0.241727
[00:13:09.992] iteration 24594 : model1 loss : 0.209533 model2 loss : 0.285912
[00:13:10.313] iteration 24595 : model1 loss : 0.174011 model2 loss : 0.196408
[00:13:10.635] iteration 24596 : model1 loss : 0.168082 model2 loss : 0.209477
[00:13:10.959] iteration 24597 : model1 loss : 0.241032 model2 loss : 0.275904
[00:13:11.283] iteration 24598 : model1 loss : 0.202411 model2 loss : 0.196408
[00:13:11.608] iteration 24599 : model1 loss : 0.100808 model2 loss : 0.151914
[00:13:11.932] iteration 24600 : model1 loss : 0.178242 model2 loss : 0.228526
[00:13:12.461] iteration 24601 : model1 loss : 0.188778 model2 loss : 0.246352
[00:13:12.788] iteration 24602 : model1 loss : 0.205616 model2 loss : 0.246494
[00:13:13.114] iteration 24603 : model1 loss : 0.179696 model2 loss : 0.201319
[00:13:13.439] iteration 24604 : model1 loss : 0.234595 model2 loss : 0.219748
[00:13:13.761] iteration 24605 : model1 loss : 0.060680 model2 loss : 0.070757
[00:13:14.082] iteration 24606 : model1 loss : 0.179626 model2 loss : 0.245272
[00:13:14.409] iteration 24607 : model1 loss : 0.252458 model2 loss : 0.282429
[00:13:14.735] iteration 24608 : model1 loss : 0.276195 model2 loss : 0.329871
[00:13:15.061] iteration 24609 : model1 loss : 0.147440 model2 loss : 0.150023
[00:13:15.388] iteration 24610 : model1 loss : 0.238793 model2 loss : 0.264321
[00:13:15.715] iteration 24611 : model1 loss : 0.082374 model2 loss : 0.134636
[00:13:16.039] iteration 24612 : model1 loss : 0.271313 model2 loss : 0.303050
[00:13:16.365] iteration 24613 : model1 loss : 0.217129 model2 loss : 0.185432
[00:13:16.690] iteration 24614 : model1 loss : 0.173026 model2 loss : 0.192402
[00:13:17.012] iteration 24615 : model1 loss : 0.262156 model2 loss : 0.287454
[00:13:17.335] iteration 24616 : model1 loss : 0.281211 model2 loss : 0.265869
[00:13:17.661] iteration 24617 : model1 loss : 0.238231 model2 loss : 0.262436
[00:13:17.988] iteration 24618 : model1 loss : 0.177979 model2 loss : 0.212054
[00:13:18.314] iteration 24619 : model1 loss : 0.181587 model2 loss : 0.239381
[00:13:18.639] iteration 24620 : model1 loss : 0.259164 model2 loss : 0.324546
[00:13:18.966] iteration 24621 : model1 loss : 0.094329 model2 loss : 0.201415
[00:13:19.290] iteration 24622 : model1 loss : 0.253625 model2 loss : 0.281364
[00:13:19.617] iteration 24623 : model1 loss : 0.171639 model2 loss : 0.241055
[00:13:19.943] iteration 24624 : model1 loss : 0.098336 model2 loss : 0.158868
[00:13:20.267] iteration 24625 : model1 loss : 0.152296 model2 loss : 0.173119
[00:13:20.594] iteration 24626 : model1 loss : 0.171214 model2 loss : 0.225611
[00:13:20.925] iteration 24627 : model1 loss : 0.146719 model2 loss : 0.174822
[00:13:21.250] iteration 24628 : model1 loss : 0.251221 model2 loss : 0.265599
[00:13:21.577] iteration 24629 : model1 loss : 0.199679 model2 loss : 0.227760
[00:13:21.899] iteration 24630 : model1 loss : 0.092288 model2 loss : 0.154242
[00:13:22.220] iteration 24631 : model1 loss : 0.178328 model2 loss : 0.208307
[00:13:22.547] iteration 24632 : model1 loss : 0.079439 model2 loss : 0.138871
[00:13:22.873] iteration 24633 : model1 loss : 0.174580 model2 loss : 0.207657
[00:13:23.198] iteration 24634 : model1 loss : 0.171250 model2 loss : 0.197689
[00:13:23.521] iteration 24635 : model1 loss : 0.099641 model2 loss : 0.126958
[00:13:23.846] iteration 24636 : model1 loss : 0.317719 model2 loss : 0.314727
[00:13:24.172] iteration 24637 : model1 loss : 0.244668 model2 loss : 0.288730
[00:13:24.498] iteration 24638 : model1 loss : 0.258715 model2 loss : 0.274963
[00:13:24.823] iteration 24639 : model1 loss : 0.290032 model2 loss : 0.292993
[00:13:25.149] iteration 24640 : model1 loss : 0.203662 model2 loss : 0.235873
[00:13:25.474] iteration 24641 : model1 loss : 0.164238 model2 loss : 0.199470
[00:13:25.798] iteration 24642 : model1 loss : 0.248397 model2 loss : 0.254558
[00:13:26.124] iteration 24643 : model1 loss : 0.176633 model2 loss : 0.233905
[00:13:26.450] iteration 24644 : model1 loss : 0.223238 model2 loss : 0.256553
[00:13:26.776] iteration 24645 : model1 loss : 0.155716 model2 loss : 0.184661
[00:13:27.103] iteration 24646 : model1 loss : 0.103530 model2 loss : 0.161203
[00:13:27.429] iteration 24647 : model1 loss : 0.220106 model2 loss : 0.290692
[00:13:27.755] iteration 24648 : model1 loss : 0.181742 model2 loss : 0.210198
[00:13:28.080] iteration 24649 : model1 loss : 0.189865 model2 loss : 0.183276
[00:13:28.503] iteration 24650 : model1 loss : 0.246326 model2 loss : 0.312596
[00:13:29.017] iteration 24651 : model1 loss : 0.187186 model2 loss : 0.242111
[00:13:29.338] iteration 24652 : model1 loss : 0.195099 model2 loss : 0.197839
[00:13:29.666] iteration 24653 : model1 loss : 0.179220 model2 loss : 0.178229
[00:13:29.992] iteration 24654 : model1 loss : 0.268406 model2 loss : 0.287408
[00:13:30.318] iteration 24655 : model1 loss : 0.242504 model2 loss : 0.244792
[00:13:30.643] iteration 24656 : model1 loss : 0.276837 model2 loss : 0.292513
[00:13:30.969] iteration 24657 : model1 loss : 0.139357 model2 loss : 0.133115
[00:13:31.294] iteration 24658 : model1 loss : 0.160657 model2 loss : 0.186275
[00:13:31.620] iteration 24659 : model1 loss : 0.080570 model2 loss : 0.090201
[00:13:31.945] iteration 24660 : model1 loss : 0.172605 model2 loss : 0.167848
[00:13:32.269] iteration 24661 : model1 loss : 0.154886 model2 loss : 0.253609
[00:13:32.595] iteration 24662 : model1 loss : 0.097781 model2 loss : 0.130459
[00:13:32.917] iteration 24663 : model1 loss : 0.237237 model2 loss : 0.292468
[00:13:33.244] iteration 24664 : model1 loss : 0.180011 model2 loss : 0.207980
[00:13:33.570] iteration 24665 : model1 loss : 0.208910 model2 loss : 0.200220
[00:13:33.891] iteration 24666 : model1 loss : 0.175304 model2 loss : 0.235608
[00:13:34.217] iteration 24667 : model1 loss : 0.159009 model2 loss : 0.202885
[00:13:34.544] iteration 24668 : model1 loss : 0.347165 model2 loss : 0.363293
[00:13:34.867] iteration 24669 : model1 loss : 0.234980 model2 loss : 0.287479
[00:13:35.194] iteration 24670 : model1 loss : 0.098921 model2 loss : 0.224866
[00:13:35.521] iteration 24671 : model1 loss : 0.076692 model2 loss : 0.139878
[00:13:35.847] iteration 24672 : model1 loss : 0.086973 model2 loss : 0.093764
[00:13:36.173] iteration 24673 : model1 loss : 0.288943 model2 loss : 0.306553
[00:13:36.499] iteration 24674 : model1 loss : 0.179110 model2 loss : 0.251169
[00:13:36.825] iteration 24675 : model1 loss : 0.253669 model2 loss : 0.279467
[00:13:37.150] iteration 24676 : model1 loss : 0.216222 model2 loss : 0.254260
[00:13:37.474] iteration 24677 : model1 loss : 0.345094 model2 loss : 0.358585
[00:13:37.799] iteration 24678 : model1 loss : 0.095407 model2 loss : 0.156595
[00:13:38.126] iteration 24679 : model1 loss : 0.153266 model2 loss : 0.288241
[00:13:38.447] iteration 24680 : model1 loss : 0.078302 model2 loss : 0.122090
[00:13:38.772] iteration 24681 : model1 loss : 0.158057 model2 loss : 0.165952
[00:13:39.098] iteration 24682 : model1 loss : 0.266080 model2 loss : 0.305242
[00:13:39.424] iteration 24683 : model1 loss : 0.191228 model2 loss : 0.234798
[00:13:39.748] iteration 24684 : model1 loss : 0.245001 model2 loss : 0.265438
[00:13:40.071] iteration 24685 : model1 loss : 0.307534 model2 loss : 0.407510
[00:13:40.394] iteration 24686 : model1 loss : 0.215992 model2 loss : 0.181805
[00:13:40.717] iteration 24687 : model1 loss : 0.160522 model2 loss : 0.187374
[00:13:41.040] iteration 24688 : model1 loss : 0.110978 model2 loss : 0.224753
[00:13:41.363] iteration 24689 : model1 loss : 0.080390 model2 loss : 0.115955
[00:13:41.688] iteration 24690 : model1 loss : 0.169766 model2 loss : 0.189508
[00:13:42.016] iteration 24691 : model1 loss : 0.164336 model2 loss : 0.212034
[00:13:42.341] iteration 24692 : model1 loss : 0.151984 model2 loss : 0.158796
[00:13:42.661] iteration 24693 : model1 loss : 0.123100 model2 loss : 0.273714
[00:13:42.983] iteration 24694 : model1 loss : 0.234532 model2 loss : 0.267292
[00:13:43.305] iteration 24695 : model1 loss : 0.184870 model2 loss : 0.203452
[00:13:43.631] iteration 24696 : model1 loss : 0.174900 model2 loss : 0.241389
[00:13:43.955] iteration 24697 : model1 loss : 0.171701 model2 loss : 0.202173
[00:13:44.278] iteration 24698 : model1 loss : 0.186859 model2 loss : 0.188299
[00:13:44.599] iteration 24699 : model1 loss : 0.083427 model2 loss : 0.114004
[00:13:44.926] iteration 24700 : model1 loss : 0.193550 model2 loss : 0.234965
[00:13:45.483] iteration 24701 : model1 loss : 0.237537 model2 loss : 0.247665
[00:13:45.812] iteration 24702 : model1 loss : 0.185001 model2 loss : 0.214537
[00:13:46.138] iteration 24703 : model1 loss : 0.195863 model2 loss : 0.316105
[00:13:46.464] iteration 24704 : model1 loss : 0.260626 model2 loss : 0.271149
[00:13:46.790] iteration 24705 : model1 loss : 0.204657 model2 loss : 0.241420
[00:13:47.119] iteration 24706 : model1 loss : 0.170274 model2 loss : 0.179052
[00:13:47.448] iteration 24707 : model1 loss : 0.267748 model2 loss : 0.267406
[00:13:47.773] iteration 24708 : model1 loss : 0.150837 model2 loss : 0.179857
[00:13:48.099] iteration 24709 : model1 loss : 0.277891 model2 loss : 0.282578
[00:13:48.426] iteration 24710 : model1 loss : 0.284823 model2 loss : 0.301606
[00:13:48.752] iteration 24711 : model1 loss : 0.152055 model2 loss : 0.175933
[00:13:49.079] iteration 24712 : model1 loss : 0.173036 model2 loss : 0.231228
[00:13:49.406] iteration 24713 : model1 loss : 0.182494 model2 loss : 0.212010
[00:13:49.732] iteration 24714 : model1 loss : 0.159625 model2 loss : 0.181593
[00:13:50.059] iteration 24715 : model1 loss : 0.208884 model2 loss : 0.225494
[00:13:50.385] iteration 24716 : model1 loss : 0.154223 model2 loss : 0.156654
[00:13:50.711] iteration 24717 : model1 loss : 0.243061 model2 loss : 0.262528
[00:13:51.037] iteration 24718 : model1 loss : 0.169932 model2 loss : 0.209540
[00:13:51.364] iteration 24719 : model1 loss : 0.259516 model2 loss : 0.256139
[00:13:51.690] iteration 24720 : model1 loss : 0.093877 model2 loss : 0.129962
[00:13:52.016] iteration 24721 : model1 loss : 0.187865 model2 loss : 0.278080
[00:13:52.343] iteration 24722 : model1 loss : 0.180010 model2 loss : 0.220564
[00:13:52.669] iteration 24723 : model1 loss : 0.189173 model2 loss : 0.215065
[00:13:52.994] iteration 24724 : model1 loss : 0.237818 model2 loss : 0.251370
[00:13:53.320] iteration 24725 : model1 loss : 0.151910 model2 loss : 0.159397
[00:13:53.646] iteration 24726 : model1 loss : 0.091270 model2 loss : 0.105637
[00:13:53.972] iteration 24727 : model1 loss : 0.089217 model2 loss : 0.118674
[00:13:54.297] iteration 24728 : model1 loss : 0.218721 model2 loss : 0.284824
[00:13:54.624] iteration 24729 : model1 loss : 0.177151 model2 loss : 0.218449
[00:13:54.949] iteration 24730 : model1 loss : 0.264289 model2 loss : 0.275056
[00:13:55.275] iteration 24731 : model1 loss : 0.226695 model2 loss : 0.235719
[00:13:55.602] iteration 24732 : model1 loss : 0.169199 model2 loss : 0.149193
[00:13:55.929] iteration 24733 : model1 loss : 0.177936 model2 loss : 0.201096
[00:13:56.256] iteration 24734 : model1 loss : 0.188521 model2 loss : 0.233939
[00:13:56.582] iteration 24735 : model1 loss : 0.232170 model2 loss : 0.264943
[00:13:56.908] iteration 24736 : model1 loss : 0.166717 model2 loss : 0.199032
[00:13:57.234] iteration 24737 : model1 loss : 0.215978 model2 loss : 0.247130
[00:13:57.560] iteration 24738 : model1 loss : 0.260085 model2 loss : 0.268175
[00:13:57.887] iteration 24739 : model1 loss : 0.154525 model2 loss : 0.176283
[00:13:58.213] iteration 24740 : model1 loss : 0.157061 model2 loss : 0.199804
[00:13:58.540] iteration 24741 : model1 loss : 0.265814 model2 loss : 0.300653
[00:13:58.866] iteration 24742 : model1 loss : 0.212502 model2 loss : 0.219038
[00:13:59.192] iteration 24743 : model1 loss : 0.160005 model2 loss : 0.182780
[00:13:59.518] iteration 24744 : model1 loss : 0.113838 model2 loss : 0.146509
[00:13:59.844] iteration 24745 : model1 loss : 0.283436 model2 loss : 0.308515
[00:14:00.171] iteration 24746 : model1 loss : 0.061980 model2 loss : 0.103123
[00:14:00.498] iteration 24747 : model1 loss : 0.195556 model2 loss : 0.181207
[00:14:00.824] iteration 24748 : model1 loss : 0.102113 model2 loss : 0.139368
[00:14:01.149] iteration 24749 : model1 loss : 0.159076 model2 loss : 0.215005
[00:14:01.475] iteration 24750 : model1 loss : 0.177253 model2 loss : 0.200476
[00:14:02.003] iteration 24751 : model1 loss : 0.181511 model2 loss : 0.201534
[00:14:02.329] iteration 24752 : model1 loss : 0.248316 model2 loss : 0.282321
[00:14:02.655] iteration 24753 : model1 loss : 0.248488 model2 loss : 0.282186
[00:14:02.982] iteration 24754 : model1 loss : 0.229063 model2 loss : 0.254420
[00:14:03.307] iteration 24755 : model1 loss : 0.101713 model2 loss : 0.150300
[00:14:03.634] iteration 24756 : model1 loss : 0.180214 model2 loss : 0.199748
[00:14:03.960] iteration 24757 : model1 loss : 0.164846 model2 loss : 0.231179
[00:14:04.286] iteration 24758 : model1 loss : 0.125117 model2 loss : 0.175665
[00:14:04.612] iteration 24759 : model1 loss : 0.202602 model2 loss : 0.227744
[00:14:04.939] iteration 24760 : model1 loss : 0.092387 model2 loss : 0.112829
[00:14:05.265] iteration 24761 : model1 loss : 0.182058 model2 loss : 0.212239
[00:14:05.592] iteration 24762 : model1 loss : 0.180339 model2 loss : 0.204782
[00:14:05.919] iteration 24763 : model1 loss : 0.263690 model2 loss : 0.337530
[00:14:06.245] iteration 24764 : model1 loss : 0.181468 model2 loss : 0.193800
[00:14:06.571] iteration 24765 : model1 loss : 0.236902 model2 loss : 0.253813
[00:14:06.898] iteration 24766 : model1 loss : 0.163839 model2 loss : 0.190414
[00:14:07.224] iteration 24767 : model1 loss : 0.195484 model2 loss : 0.237113
[00:14:07.553] iteration 24768 : model1 loss : 0.154485 model2 loss : 0.192387
[00:14:07.879] iteration 24769 : model1 loss : 0.274987 model2 loss : 0.263770
[00:14:08.206] iteration 24770 : model1 loss : 0.152490 model2 loss : 0.206478
[00:14:08.533] iteration 24771 : model1 loss : 0.079824 model2 loss : 0.094180
[00:14:08.858] iteration 24772 : model1 loss : 0.321061 model2 loss : 0.333046
[00:14:09.184] iteration 24773 : model1 loss : 0.249771 model2 loss : 0.250825
[00:14:09.511] iteration 24774 : model1 loss : 0.071762 model2 loss : 0.107195
[00:14:09.838] iteration 24775 : model1 loss : 0.197325 model2 loss : 0.324219
[00:14:10.164] iteration 24776 : model1 loss : 0.150325 model2 loss : 0.187658
[00:14:10.491] iteration 24777 : model1 loss : 0.108222 model2 loss : 0.143838
[00:14:10.817] iteration 24778 : model1 loss : 0.188446 model2 loss : 0.217712
[00:14:11.143] iteration 24779 : model1 loss : 0.249491 model2 loss : 0.252207
[00:14:11.471] iteration 24780 : model1 loss : 0.175542 model2 loss : 0.222858
[00:14:11.798] iteration 24781 : model1 loss : 0.247317 model2 loss : 0.283474
[00:14:12.125] iteration 24782 : model1 loss : 0.132044 model2 loss : 0.198724
[00:14:12.451] iteration 24783 : model1 loss : 0.176187 model2 loss : 0.178919
[00:14:12.779] iteration 24784 : model1 loss : 0.159692 model2 loss : 0.170250
[00:14:13.106] iteration 24785 : model1 loss : 0.110953 model2 loss : 0.144878
[00:14:13.431] iteration 24786 : model1 loss : 0.181955 model2 loss : 0.197535
[00:14:13.758] iteration 24787 : model1 loss : 0.193827 model2 loss : 0.222483
[00:14:14.084] iteration 24788 : model1 loss : 0.183179 model2 loss : 0.184948
[00:14:14.411] iteration 24789 : model1 loss : 0.161418 model2 loss : 0.183776
[00:14:14.737] iteration 24790 : model1 loss : 0.271476 model2 loss : 0.312602
[00:14:15.063] iteration 24791 : model1 loss : 0.118487 model2 loss : 0.170996
[00:14:15.389] iteration 24792 : model1 loss : 0.161429 model2 loss : 0.177881
[00:14:15.716] iteration 24793 : model1 loss : 0.195792 model2 loss : 0.224066
[00:14:16.043] iteration 24794 : model1 loss : 0.273565 model2 loss : 0.276985
[00:14:16.370] iteration 24795 : model1 loss : 0.219274 model2 loss : 0.286628
[00:14:16.695] iteration 24796 : model1 loss : 0.256721 model2 loss : 0.274039
[00:14:17.021] iteration 24797 : model1 loss : 0.169070 model2 loss : 0.189328
[00:14:17.346] iteration 24798 : model1 loss : 0.128514 model2 loss : 0.193158
[00:14:17.673] iteration 24799 : model1 loss : 0.162474 model2 loss : 0.208121
[00:14:17.999] iteration 24800 : model1 loss : 0.152284 model2 loss : 0.179514
[00:14:18.538] iteration 24801 : model1 loss : 0.067256 model2 loss : 0.114813
[00:14:18.865] iteration 24802 : model1 loss : 0.106106 model2 loss : 0.138822
[00:14:19.191] iteration 24803 : model1 loss : 0.164177 model2 loss : 0.186616
[00:14:19.517] iteration 24804 : model1 loss : 0.168867 model2 loss : 0.181711
[00:14:19.843] iteration 24805 : model1 loss : 0.080571 model2 loss : 0.135032
[00:14:20.169] iteration 24806 : model1 loss : 0.155516 model2 loss : 0.180560
[00:14:20.495] iteration 24807 : model1 loss : 0.170368 model2 loss : 0.231970
[00:14:20.821] iteration 24808 : model1 loss : 0.163542 model2 loss : 0.214487
[00:14:21.146] iteration 24809 : model1 loss : 0.332449 model2 loss : 0.318006
[00:14:21.472] iteration 24810 : model1 loss : 0.223910 model2 loss : 0.250357
[00:14:21.798] iteration 24811 : model1 loss : 0.108937 model2 loss : 0.176951
[00:14:22.125] iteration 24812 : model1 loss : 0.247559 model2 loss : 0.276311
[00:14:22.451] iteration 24813 : model1 loss : 0.314106 model2 loss : 0.305255
[00:14:22.776] iteration 24814 : model1 loss : 0.202040 model2 loss : 0.293816
[00:14:23.103] iteration 24815 : model1 loss : 0.211535 model2 loss : 0.215960
[00:14:23.429] iteration 24816 : model1 loss : 0.156302 model2 loss : 0.187447
[00:14:23.755] iteration 24817 : model1 loss : 0.153203 model2 loss : 0.187142
[00:14:24.081] iteration 24818 : model1 loss : 0.261592 model2 loss : 0.279319
[00:14:24.406] iteration 24819 : model1 loss : 0.234286 model2 loss : 0.181575
[00:14:24.733] iteration 24820 : model1 loss : 0.159650 model2 loss : 0.180809
[00:14:25.059] iteration 24821 : model1 loss : 0.150986 model2 loss : 0.164220
[00:14:25.386] iteration 24822 : model1 loss : 0.192790 model2 loss : 0.221515
[00:14:25.713] iteration 24823 : model1 loss : 0.163769 model2 loss : 0.201277
[00:14:26.039] iteration 24824 : model1 loss : 0.178071 model2 loss : 0.221144
[00:14:26.364] iteration 24825 : model1 loss : 0.268090 model2 loss : 0.335158
[00:14:26.690] iteration 24826 : model1 loss : 0.165212 model2 loss : 0.179741
[00:14:27.016] iteration 24827 : model1 loss : 0.083561 model2 loss : 0.109890
[00:14:27.342] iteration 24828 : model1 loss : 0.097095 model2 loss : 0.114659
[00:14:27.669] iteration 24829 : model1 loss : 0.263863 model2 loss : 0.290114
[00:14:27.995] iteration 24830 : model1 loss : 0.181610 model2 loss : 0.194874
[00:14:28.321] iteration 24831 : model1 loss : 0.211483 model2 loss : 0.247400
[00:14:28.647] iteration 24832 : model1 loss : 0.250601 model2 loss : 0.271591
[00:14:28.972] iteration 24833 : model1 loss : 0.110131 model2 loss : 0.144584
[00:14:29.297] iteration 24834 : model1 loss : 0.174542 model2 loss : 0.283111
[00:14:29.624] iteration 24835 : model1 loss : 0.106074 model2 loss : 0.143236
[00:14:29.951] iteration 24836 : model1 loss : 0.203366 model2 loss : 0.210915
[00:14:30.277] iteration 24837 : model1 loss : 0.186543 model2 loss : 0.186125
[00:14:30.604] iteration 24838 : model1 loss : 0.211964 model2 loss : 0.308910
[00:14:30.930] iteration 24839 : model1 loss : 0.179289 model2 loss : 0.204446
[00:14:31.257] iteration 24840 : model1 loss : 0.098683 model2 loss : 0.162683
[00:14:31.584] iteration 24841 : model1 loss : 0.242606 model2 loss : 0.261337
[00:14:31.909] iteration 24842 : model1 loss : 0.196950 model2 loss : 0.263747
[00:14:32.236] iteration 24843 : model1 loss : 0.174157 model2 loss : 0.220306
[00:14:32.563] iteration 24844 : model1 loss : 0.182035 model2 loss : 0.203301
[00:14:32.890] iteration 24845 : model1 loss : 0.109429 model2 loss : 0.186674
[00:14:33.217] iteration 24846 : model1 loss : 0.181765 model2 loss : 0.196201
[00:14:33.544] iteration 24847 : model1 loss : 0.109611 model2 loss : 0.171511
[00:14:33.867] iteration 24848 : model1 loss : 0.237049 model2 loss : 0.278728
[00:14:34.193] iteration 24849 : model1 loss : 0.219324 model2 loss : 0.274371
[00:14:34.519] iteration 24850 : model1 loss : 0.175022 model2 loss : 0.218754
[00:14:35.055] iteration 24851 : model1 loss : 0.184755 model2 loss : 0.224611
[00:14:35.381] iteration 24852 : model1 loss : 0.177084 model2 loss : 0.232903
[00:14:35.707] iteration 24853 : model1 loss : 0.251059 model2 loss : 0.360616
[00:14:36.034] iteration 24854 : model1 loss : 0.144783 model2 loss : 0.178522
[00:14:36.360] iteration 24855 : model1 loss : 0.187678 model2 loss : 0.185240
[00:14:36.686] iteration 24856 : model1 loss : 0.189330 model2 loss : 0.194328
[00:14:37.012] iteration 24857 : model1 loss : 0.079458 model2 loss : 0.099800
[00:14:37.338] iteration 24858 : model1 loss : 0.246579 model2 loss : 0.260372
[00:14:37.666] iteration 24859 : model1 loss : 0.138490 model2 loss : 0.145714
[00:14:37.992] iteration 24860 : model1 loss : 0.222389 model2 loss : 0.221866
[00:14:38.318] iteration 24861 : model1 loss : 0.103600 model2 loss : 0.164374
[00:14:38.644] iteration 24862 : model1 loss : 0.206073 model2 loss : 0.245873
[00:14:38.970] iteration 24863 : model1 loss : 0.184544 model2 loss : 0.198968
[00:14:39.296] iteration 24864 : model1 loss : 0.201030 model2 loss : 0.346898
[00:14:39.623] iteration 24865 : model1 loss : 0.062452 model2 loss : 0.088016
[00:14:39.949] iteration 24866 : model1 loss : 0.185384 model2 loss : 0.209515
[00:14:40.276] iteration 24867 : model1 loss : 0.258695 model2 loss : 0.263095
[00:14:40.601] iteration 24868 : model1 loss : 0.279693 model2 loss : 0.274221
[00:14:40.928] iteration 24869 : model1 loss : 0.196227 model2 loss : 0.249280
[00:14:41.254] iteration 24870 : model1 loss : 0.121566 model2 loss : 0.165203
[00:14:41.580] iteration 24871 : model1 loss : 0.215265 model2 loss : 0.277782
[00:14:41.906] iteration 24872 : model1 loss : 0.215050 model2 loss : 0.238544
[00:14:42.232] iteration 24873 : model1 loss : 0.102348 model2 loss : 0.126427
[00:14:42.558] iteration 24874 : model1 loss : 0.243476 model2 loss : 0.253860
[00:14:42.883] iteration 24875 : model1 loss : 0.106104 model2 loss : 0.122780
[00:14:43.209] iteration 24876 : model1 loss : 0.153966 model2 loss : 0.231822
[00:14:43.535] iteration 24877 : model1 loss : 0.191269 model2 loss : 0.255687
[00:14:43.860] iteration 24878 : model1 loss : 0.174908 model2 loss : 0.189201
[00:14:44.186] iteration 24879 : model1 loss : 0.154436 model2 loss : 0.166157
[00:14:44.513] iteration 24880 : model1 loss : 0.088746 model2 loss : 0.127968
[00:14:44.840] iteration 24881 : model1 loss : 0.073703 model2 loss : 0.113349
[00:14:45.166] iteration 24882 : model1 loss : 0.135096 model2 loss : 0.174406
[00:14:45.492] iteration 24883 : model1 loss : 0.091925 model2 loss : 0.106653
[00:14:45.818] iteration 24884 : model1 loss : 0.238809 model2 loss : 0.280656
[00:14:46.144] iteration 24885 : model1 loss : 0.129263 model2 loss : 0.187549
[00:14:46.470] iteration 24886 : model1 loss : 0.341464 model2 loss : 0.329373
[00:14:46.796] iteration 24887 : model1 loss : 0.266987 model2 loss : 0.336529
[00:14:47.123] iteration 24888 : model1 loss : 0.100179 model2 loss : 0.115038
[00:14:47.449] iteration 24889 : model1 loss : 0.156054 model2 loss : 0.168343
[00:14:47.775] iteration 24890 : model1 loss : 0.259750 model2 loss : 0.263712
[00:14:48.102] iteration 24891 : model1 loss : 0.199324 model2 loss : 0.209753
[00:14:48.428] iteration 24892 : model1 loss : 0.174783 model2 loss : 0.218237
[00:14:48.754] iteration 24893 : model1 loss : 0.193206 model2 loss : 0.220320
[00:14:49.080] iteration 24894 : model1 loss : 0.167066 model2 loss : 0.173098
[00:14:49.406] iteration 24895 : model1 loss : 0.265823 model2 loss : 0.302324
[00:14:49.733] iteration 24896 : model1 loss : 0.090809 model2 loss : 0.113594
[00:14:50.060] iteration 24897 : model1 loss : 0.067481 model2 loss : 0.111128
[00:14:50.387] iteration 24898 : model1 loss : 0.147922 model2 loss : 0.154697
[00:14:50.713] iteration 24899 : model1 loss : 0.171565 model2 loss : 0.208848
[00:14:51.039] iteration 24900 : model1 loss : 0.091700 model2 loss : 0.113949
[00:14:51.588] iteration 24901 : model1 loss : 0.109729 model2 loss : 0.153820
[00:14:51.915] iteration 24902 : model1 loss : 0.327295 model2 loss : 0.351553
[00:14:52.241] iteration 24903 : model1 loss : 0.241662 model2 loss : 0.276582
[00:14:52.568] iteration 24904 : model1 loss : 0.242579 model2 loss : 0.234828
[00:14:52.894] iteration 24905 : model1 loss : 0.166971 model2 loss : 0.189176
[00:14:53.221] iteration 24906 : model1 loss : 0.330075 model2 loss : 0.359851
[00:14:53.547] iteration 24907 : model1 loss : 0.216140 model2 loss : 0.232311
[00:14:53.873] iteration 24908 : model1 loss : 0.272326 model2 loss : 0.290591
[00:14:54.201] iteration 24909 : model1 loss : 0.168123 model2 loss : 0.217307
[00:14:54.527] iteration 24910 : model1 loss : 0.278266 model2 loss : 0.312057
[00:14:54.853] iteration 24911 : model1 loss : 0.179311 model2 loss : 0.239998
[00:14:55.180] iteration 24912 : model1 loss : 0.172371 model2 loss : 0.253555
[00:14:55.506] iteration 24913 : model1 loss : 0.164542 model2 loss : 0.191790
[00:14:55.832] iteration 24914 : model1 loss : 0.102160 model2 loss : 0.138560
[00:14:56.159] iteration 24915 : model1 loss : 0.174891 model2 loss : 0.260403
[00:14:56.486] iteration 24916 : model1 loss : 0.192170 model2 loss : 0.217380
[00:14:56.812] iteration 24917 : model1 loss : 0.136644 model2 loss : 0.137617
[00:14:57.138] iteration 24918 : model1 loss : 0.318033 model2 loss : 0.327111
[00:14:57.465] iteration 24919 : model1 loss : 0.168400 model2 loss : 0.194205
[00:14:57.794] iteration 24920 : model1 loss : 0.263443 model2 loss : 0.288221
[00:14:58.121] iteration 24921 : model1 loss : 0.257265 model2 loss : 0.279252
[00:14:58.447] iteration 24922 : model1 loss : 0.097388 model2 loss : 0.126203
[00:14:58.773] iteration 24923 : model1 loss : 0.242820 model2 loss : 0.219231
[00:14:59.100] iteration 24924 : model1 loss : 0.260583 model2 loss : 0.294740
[00:14:59.425] iteration 24925 : model1 loss : 0.090830 model2 loss : 0.181924
[00:14:59.751] iteration 24926 : model1 loss : 0.219211 model2 loss : 0.248350
[00:15:00.078] iteration 24927 : model1 loss : 0.227494 model2 loss : 0.245181
[00:15:00.404] iteration 24928 : model1 loss : 0.171095 model2 loss : 0.224452
[00:15:00.730] iteration 24929 : model1 loss : 0.207108 model2 loss : 0.270588
[00:15:01.056] iteration 24930 : model1 loss : 0.180678 model2 loss : 0.215288
[00:15:01.381] iteration 24931 : model1 loss : 0.368087 model2 loss : 0.398324
[00:15:01.708] iteration 24932 : model1 loss : 0.257917 model2 loss : 0.283395
[00:15:02.033] iteration 24933 : model1 loss : 0.068065 model2 loss : 0.089309
[00:15:02.359] iteration 24934 : model1 loss : 0.087606 model2 loss : 0.229430
[00:15:02.686] iteration 24935 : model1 loss : 0.196939 model2 loss : 0.248416
[00:15:03.012] iteration 24936 : model1 loss : 0.273790 model2 loss : 0.266445
[00:15:03.337] iteration 24937 : model1 loss : 0.193920 model2 loss : 0.234055
[00:15:03.664] iteration 24938 : model1 loss : 0.255802 model2 loss : 0.263280
[00:15:03.990] iteration 24939 : model1 loss : 0.095097 model2 loss : 0.172818
[00:15:04.316] iteration 24940 : model1 loss : 0.248548 model2 loss : 0.264429
[00:15:04.642] iteration 24941 : model1 loss : 0.197611 model2 loss : 0.227771
[00:15:04.969] iteration 24942 : model1 loss : 0.265294 model2 loss : 0.273495
[00:15:05.295] iteration 24943 : model1 loss : 0.157021 model2 loss : 0.156931
[00:15:05.621] iteration 24944 : model1 loss : 0.220090 model2 loss : 0.279209
[00:15:05.947] iteration 24945 : model1 loss : 0.084773 model2 loss : 0.106412
[00:15:06.274] iteration 24946 : model1 loss : 0.176861 model2 loss : 0.213254
[00:15:06.600] iteration 24947 : model1 loss : 0.095464 model2 loss : 0.129852
[00:15:06.925] iteration 24948 : model1 loss : 0.280172 model2 loss : 0.321364
[00:15:07.251] iteration 24949 : model1 loss : 0.270171 model2 loss : 0.268162
[00:15:07.578] iteration 24950 : model1 loss : 0.097058 model2 loss : 0.150286
[00:15:08.091] iteration 24951 : model1 loss : 0.151965 model2 loss : 0.183523
[00:15:08.417] iteration 24952 : model1 loss : 0.163785 model2 loss : 0.219949
[00:15:08.743] iteration 24953 : model1 loss : 0.163315 model2 loss : 0.189506
[00:15:09.071] iteration 24954 : model1 loss : 0.198017 model2 loss : 0.235574
[00:15:09.397] iteration 24955 : model1 loss : 0.239231 model2 loss : 0.271409
[00:15:09.723] iteration 24956 : model1 loss : 0.097967 model2 loss : 0.100922
[00:15:10.051] iteration 24957 : model1 loss : 0.323857 model2 loss : 0.351029
[00:15:10.377] iteration 24958 : model1 loss : 0.104487 model2 loss : 0.152099
[00:15:10.704] iteration 24959 : model1 loss : 0.170883 model2 loss : 0.200646
[00:15:11.030] iteration 24960 : model1 loss : 0.253162 model2 loss : 0.283306
[00:15:11.358] iteration 24961 : model1 loss : 0.247854 model2 loss : 0.257698
[00:15:11.683] iteration 24962 : model1 loss : 0.111166 model2 loss : 0.145133
[00:15:12.009] iteration 24963 : model1 loss : 0.167637 model2 loss : 0.233180
[00:15:12.335] iteration 24964 : model1 loss : 0.249433 model2 loss : 0.291271
[00:15:12.662] iteration 24965 : model1 loss : 0.173975 model2 loss : 0.202104
[00:15:12.988] iteration 24966 : model1 loss : 0.185946 model2 loss : 0.184719
[00:15:13.315] iteration 24967 : model1 loss : 0.170415 model2 loss : 0.191309
[00:15:13.641] iteration 24968 : model1 loss : 0.089460 model2 loss : 0.076458
[00:15:13.968] iteration 24969 : model1 loss : 0.200645 model2 loss : 0.259905
[00:15:14.294] iteration 24970 : model1 loss : 0.276145 model2 loss : 0.256307
[00:15:14.620] iteration 24971 : model1 loss : 0.188985 model2 loss : 0.182012
[00:15:14.946] iteration 24972 : model1 loss : 0.181925 model2 loss : 0.229291
[00:15:15.272] iteration 24973 : model1 loss : 0.198144 model2 loss : 0.259395
[00:15:15.600] iteration 24974 : model1 loss : 0.176159 model2 loss : 0.184069
[00:15:15.926] iteration 24975 : model1 loss : 0.277265 model2 loss : 0.303934
[00:15:16.253] iteration 24976 : model1 loss : 0.061566 model2 loss : 0.085234
[00:15:16.579] iteration 24977 : model1 loss : 0.158737 model2 loss : 0.181688
[00:15:16.905] iteration 24978 : model1 loss : 0.147261 model2 loss : 0.162835
[00:15:17.233] iteration 24979 : model1 loss : 0.263983 model2 loss : 0.326671
[00:15:17.560] iteration 24980 : model1 loss : 0.153224 model2 loss : 0.173243
[00:15:17.886] iteration 24981 : model1 loss : 0.080116 model2 loss : 0.093131
[00:15:18.213] iteration 24982 : model1 loss : 0.151411 model2 loss : 0.168303
[00:15:18.541] iteration 24983 : model1 loss : 0.274904 model2 loss : 0.313040
[00:15:18.867] iteration 24984 : model1 loss : 0.182579 model2 loss : 0.209053
[00:15:19.193] iteration 24985 : model1 loss : 0.065647 model2 loss : 0.090598
[00:15:19.520] iteration 24986 : model1 loss : 0.155632 model2 loss : 0.202195
[00:15:19.847] iteration 24987 : model1 loss : 0.248629 model2 loss : 0.264402
[00:15:20.174] iteration 24988 : model1 loss : 0.136464 model2 loss : 0.133206
[00:15:20.501] iteration 24989 : model1 loss : 0.091108 model2 loss : 0.095709
[00:15:20.827] iteration 24990 : model1 loss : 0.205985 model2 loss : 0.263000
[00:15:21.153] iteration 24991 : model1 loss : 0.305682 model2 loss : 0.421440
[00:15:21.480] iteration 24992 : model1 loss : 0.084769 model2 loss : 0.088917
[00:15:21.806] iteration 24993 : model1 loss : 0.178197 model2 loss : 0.230859
[00:15:22.132] iteration 24994 : model1 loss : 0.181371 model2 loss : 0.209837
[00:15:22.458] iteration 24995 : model1 loss : 0.251637 model2 loss : 0.277338
[00:15:22.784] iteration 24996 : model1 loss : 0.183212 model2 loss : 0.233309
[00:15:23.111] iteration 24997 : model1 loss : 0.203962 model2 loss : 0.217189
[00:15:23.437] iteration 24998 : model1 loss : 0.156458 model2 loss : 0.179167
[00:15:23.763] iteration 24999 : model1 loss : 0.246566 model2 loss : 0.276523
[00:15:24.090] iteration 25000 : model1 loss : 0.100600 model2 loss : 0.173375
[00:15:24.620] iteration 25001 : model1 loss : 0.277245 model2 loss : 0.284418
[00:15:24.946] iteration 25002 : model1 loss : 0.111083 model2 loss : 0.130692
[00:15:25.273] iteration 25003 : model1 loss : 0.156218 model2 loss : 0.177933
[00:15:25.600] iteration 25004 : model1 loss : 0.177879 model2 loss : 0.180409
[00:15:25.927] iteration 25005 : model1 loss : 0.190692 model2 loss : 0.206892
[00:15:26.253] iteration 25006 : model1 loss : 0.290756 model2 loss : 0.276136
[00:15:26.579] iteration 25007 : model1 loss : 0.177976 model2 loss : 0.189934
[00:15:26.905] iteration 25008 : model1 loss : 0.173325 model2 loss : 0.210199
[00:15:27.231] iteration 25009 : model1 loss : 0.226642 model2 loss : 0.238325
[00:15:27.558] iteration 25010 : model1 loss : 0.160958 model2 loss : 0.209322
[00:15:27.883] iteration 25011 : model1 loss : 0.236352 model2 loss : 0.261770
[00:15:28.211] iteration 25012 : model1 loss : 0.170226 model2 loss : 0.206145
[00:15:28.536] iteration 25013 : model1 loss : 0.114143 model2 loss : 0.215140
[00:15:28.862] iteration 25014 : model1 loss : 0.239411 model2 loss : 0.275976
[00:15:29.188] iteration 25015 : model1 loss : 0.175924 model2 loss : 0.231737
[00:15:29.516] iteration 25016 : model1 loss : 0.240248 model2 loss : 0.290006
[00:15:29.842] iteration 25017 : model1 loss : 0.285843 model2 loss : 0.330677
[00:15:30.168] iteration 25018 : model1 loss : 0.317678 model2 loss : 0.319110
[00:15:30.495] iteration 25019 : model1 loss : 0.099418 model2 loss : 0.116644
[00:15:30.821] iteration 25020 : model1 loss : 0.151852 model2 loss : 0.158757
[00:15:31.148] iteration 25021 : model1 loss : 0.163553 model2 loss : 0.215980
[00:15:31.473] iteration 25022 : model1 loss : 0.156482 model2 loss : 0.168267
[00:15:31.799] iteration 25023 : model1 loss : 0.116388 model2 loss : 0.133138
[00:15:32.125] iteration 25024 : model1 loss : 0.260186 model2 loss : 0.282140
[00:15:32.451] iteration 25025 : model1 loss : 0.224968 model2 loss : 0.286496
[00:15:32.778] iteration 25026 : model1 loss : 0.159832 model2 loss : 0.184151
[00:15:33.104] iteration 25027 : model1 loss : 0.124463 model2 loss : 0.235990
[00:15:33.431] iteration 25028 : model1 loss : 0.242143 model2 loss : 0.244874
[00:15:33.756] iteration 25029 : model1 loss : 0.191806 model2 loss : 0.261001
[00:15:34.082] iteration 25030 : model1 loss : 0.082789 model2 loss : 0.129848
[00:15:34.408] iteration 25031 : model1 loss : 0.182175 model2 loss : 0.175068
[00:15:34.734] iteration 25032 : model1 loss : 0.214038 model2 loss : 0.193595
[00:15:35.060] iteration 25033 : model1 loss : 0.272684 model2 loss : 0.324603
[00:15:35.387] iteration 25034 : model1 loss : 0.162225 model2 loss : 0.240056
[00:15:35.714] iteration 25035 : model1 loss : 0.096619 model2 loss : 0.084987
[00:15:36.040] iteration 25036 : model1 loss : 0.193651 model2 loss : 0.218061
[00:15:36.366] iteration 25037 : model1 loss : 0.239408 model2 loss : 0.206235
[00:15:36.692] iteration 25038 : model1 loss : 0.118565 model2 loss : 0.221123
[00:15:37.018] iteration 25039 : model1 loss : 0.113561 model2 loss : 0.117639
[00:15:37.343] iteration 25040 : model1 loss : 0.234584 model2 loss : 0.251134
[00:15:37.669] iteration 25041 : model1 loss : 0.183321 model2 loss : 0.217234
[00:15:37.995] iteration 25042 : model1 loss : 0.298480 model2 loss : 0.412630
[00:15:38.321] iteration 25043 : model1 loss : 0.101341 model2 loss : 0.164521
[00:15:38.647] iteration 25044 : model1 loss : 0.181025 model2 loss : 0.273939
[00:15:38.973] iteration 25045 : model1 loss : 0.244522 model2 loss : 0.267755
[00:15:39.299] iteration 25046 : model1 loss : 0.179353 model2 loss : 0.207748
[00:15:39.625] iteration 25047 : model1 loss : 0.186834 model2 loss : 0.228127
[00:15:39.951] iteration 25048 : model1 loss : 0.186781 model2 loss : 0.232319
[00:15:40.278] iteration 25049 : model1 loss : 0.088991 model2 loss : 0.095450
[00:15:40.604] iteration 25050 : model1 loss : 0.186821 model2 loss : 0.212122
[00:15:41.138] iteration 25051 : model1 loss : 0.171120 model2 loss : 0.203708
[00:15:41.464] iteration 25052 : model1 loss : 0.200875 model2 loss : 0.239231
[00:15:41.790] iteration 25053 : model1 loss : 0.320842 model2 loss : 0.328329
[00:15:42.115] iteration 25054 : model1 loss : 0.176610 model2 loss : 0.214839
[00:15:42.441] iteration 25055 : model1 loss : 0.103014 model2 loss : 0.174758
[00:15:42.767] iteration 25056 : model1 loss : 0.209741 model2 loss : 0.247158
[00:15:43.093] iteration 25057 : model1 loss : 0.158458 model2 loss : 0.168504
[00:15:43.420] iteration 25058 : model1 loss : 0.234583 model2 loss : 0.257544
[00:15:43.746] iteration 25059 : model1 loss : 0.094141 model2 loss : 0.129463
[00:15:44.072] iteration 25060 : model1 loss : 0.229881 model2 loss : 0.256024
[00:15:44.398] iteration 25061 : model1 loss : 0.336968 model2 loss : 0.335676
[00:15:44.724] iteration 25062 : model1 loss : 0.200595 model2 loss : 0.251253
[00:15:45.050] iteration 25063 : model1 loss : 0.084642 model2 loss : 0.112496
[00:15:45.376] iteration 25064 : model1 loss : 0.157364 model2 loss : 0.169586
[00:15:45.701] iteration 25065 : model1 loss : 0.180645 model2 loss : 0.201562
[00:15:46.025] iteration 25066 : model1 loss : 0.274070 model2 loss : 0.275811
[00:15:46.350] iteration 25067 : model1 loss : 0.173379 model2 loss : 0.219922
[00:15:46.674] iteration 25068 : model1 loss : 0.258139 model2 loss : 0.262038
[00:15:46.998] iteration 25069 : model1 loss : 0.155519 model2 loss : 0.241367
[00:15:47.323] iteration 25070 : model1 loss : 0.310722 model2 loss : 0.318936
[00:15:48.270] iteration 25071 : model1 loss : 0.215927 model2 loss : 0.208111
[00:15:48.600] iteration 25072 : model1 loss : 0.197808 model2 loss : 0.198703
[00:15:48.939] iteration 25073 : model1 loss : 0.158856 model2 loss : 0.165568
[00:15:49.268] iteration 25074 : model1 loss : 0.188408 model2 loss : 0.217021
[00:15:49.607] iteration 25075 : model1 loss : 0.179109 model2 loss : 0.191081
[00:15:49.933] iteration 25076 : model1 loss : 0.270816 model2 loss : 0.330724
[00:15:50.260] iteration 25077 : model1 loss : 0.084066 model2 loss : 0.128514
[00:15:50.586] iteration 25078 : model1 loss : 0.229921 model2 loss : 0.324571
[00:15:50.912] iteration 25079 : model1 loss : 0.207071 model2 loss : 0.238678
[00:15:51.239] iteration 25080 : model1 loss : 0.236039 model2 loss : 0.243641
[00:15:51.565] iteration 25081 : model1 loss : 0.156165 model2 loss : 0.158288
[00:15:51.891] iteration 25082 : model1 loss : 0.293346 model2 loss : 0.309451
[00:15:52.217] iteration 25083 : model1 loss : 0.176196 model2 loss : 0.204318
[00:15:52.542] iteration 25084 : model1 loss : 0.094377 model2 loss : 0.145537
[00:15:52.868] iteration 25085 : model1 loss : 0.250115 model2 loss : 0.269527
[00:15:53.195] iteration 25086 : model1 loss : 0.163555 model2 loss : 0.193246
[00:15:53.521] iteration 25087 : model1 loss : 0.240579 model2 loss : 0.252843
[00:15:53.846] iteration 25088 : model1 loss : 0.210664 model2 loss : 0.237146
[00:15:54.172] iteration 25089 : model1 loss : 0.155070 model2 loss : 0.198701
[00:15:54.498] iteration 25090 : model1 loss : 0.079806 model2 loss : 0.105528
[00:15:54.823] iteration 25091 : model1 loss : 0.187434 model2 loss : 0.210270
[00:15:55.149] iteration 25092 : model1 loss : 0.217010 model2 loss : 0.243630
[00:15:55.476] iteration 25093 : model1 loss : 0.219484 model2 loss : 0.308613
[00:15:55.802] iteration 25094 : model1 loss : 0.083368 model2 loss : 0.123907
[00:15:56.128] iteration 25095 : model1 loss : 0.098978 model2 loss : 0.224461
[00:15:56.455] iteration 25096 : model1 loss : 0.110366 model2 loss : 0.130436
[00:15:56.781] iteration 25097 : model1 loss : 0.269409 model2 loss : 0.378457
[00:15:57.107] iteration 25098 : model1 loss : 0.159136 model2 loss : 0.188552
[00:15:57.432] iteration 25099 : model1 loss : 0.264037 model2 loss : 0.259970
[00:15:57.758] iteration 25100 : model1 loss : 0.283353 model2 loss : 0.324404
[00:15:58.293] iteration 25101 : model1 loss : 0.190731 model2 loss : 0.210466
[00:15:58.618] iteration 25102 : model1 loss : 0.228673 model2 loss : 0.276635
[00:15:58.940] iteration 25103 : model1 loss : 0.241386 model2 loss : 0.232503
[00:15:59.262] iteration 25104 : model1 loss : 0.129232 model2 loss : 0.181622
[00:15:59.589] iteration 25105 : model1 loss : 0.152592 model2 loss : 0.184077
[00:15:59.914] iteration 25106 : model1 loss : 0.174269 model2 loss : 0.218480
[00:16:00.235] iteration 25107 : model1 loss : 0.231842 model2 loss : 0.238304
[00:16:00.562] iteration 25108 : model1 loss : 0.188744 model2 loss : 0.256215
[00:16:00.885] iteration 25109 : model1 loss : 0.177404 model2 loss : 0.191708
[00:16:01.208] iteration 25110 : model1 loss : 0.108917 model2 loss : 0.134356
[00:16:01.531] iteration 25111 : model1 loss : 0.131009 model2 loss : 0.194325
[00:16:01.854] iteration 25112 : model1 loss : 0.170886 model2 loss : 0.192037
[00:16:02.181] iteration 25113 : model1 loss : 0.102267 model2 loss : 0.129993
[00:16:02.504] iteration 25114 : model1 loss : 0.097947 model2 loss : 0.116642
[00:16:02.831] iteration 25115 : model1 loss : 0.226264 model2 loss : 0.238945
[00:16:03.158] iteration 25116 : model1 loss : 0.210223 model2 loss : 0.221296
[00:16:03.482] iteration 25117 : model1 loss : 0.327399 model2 loss : 0.336200
[00:16:03.806] iteration 25118 : model1 loss : 0.075371 model2 loss : 0.101641
[00:16:04.131] iteration 25119 : model1 loss : 0.171884 model2 loss : 0.229361
[00:16:04.453] iteration 25120 : model1 loss : 0.157435 model2 loss : 0.197916
[00:16:04.780] iteration 25121 : model1 loss : 0.211630 model2 loss : 0.239354
[00:16:05.104] iteration 25122 : model1 loss : 0.197016 model2 loss : 0.241814
[00:16:05.430] iteration 25123 : model1 loss : 0.201331 model2 loss : 0.225850
[00:16:05.755] iteration 25124 : model1 loss : 0.170024 model2 loss : 0.189732
[00:16:06.077] iteration 25125 : model1 loss : 0.093823 model2 loss : 0.128931
[00:16:06.404] iteration 25126 : model1 loss : 0.260952 model2 loss : 0.278463
[00:16:06.731] iteration 25127 : model1 loss : 0.285501 model2 loss : 0.317746
[00:16:07.058] iteration 25128 : model1 loss : 0.180434 model2 loss : 0.190724
[00:16:07.384] iteration 25129 : model1 loss : 0.175966 model2 loss : 0.223546
[00:16:07.709] iteration 25130 : model1 loss : 0.284673 model2 loss : 0.306845
[00:16:08.036] iteration 25131 : model1 loss : 0.184099 model2 loss : 0.193236
[00:16:08.368] iteration 25132 : model1 loss : 0.263243 model2 loss : 0.305645
[00:16:08.697] iteration 25133 : model1 loss : 0.203022 model2 loss : 0.235235
[00:16:09.024] iteration 25134 : model1 loss : 0.084260 model2 loss : 0.101085
[00:16:09.349] iteration 25135 : model1 loss : 0.153036 model2 loss : 0.184398
[00:16:09.673] iteration 25136 : model1 loss : 0.166139 model2 loss : 0.235750
[00:16:09.998] iteration 25137 : model1 loss : 0.159032 model2 loss : 0.197893
[00:16:10.325] iteration 25138 : model1 loss : 0.254459 model2 loss : 0.269172
[00:16:10.651] iteration 25139 : model1 loss : 0.074836 model2 loss : 0.092043
[00:16:10.982] iteration 25140 : model1 loss : 0.256293 model2 loss : 0.263436
[00:16:11.312] iteration 25141 : model1 loss : 0.142308 model2 loss : 0.192023
[00:16:11.639] iteration 25142 : model1 loss : 0.154747 model2 loss : 0.291257
[00:16:11.964] iteration 25143 : model1 loss : 0.183765 model2 loss : 0.179370
[00:16:12.287] iteration 25144 : model1 loss : 0.162685 model2 loss : 0.178515
[00:16:12.613] iteration 25145 : model1 loss : 0.103045 model2 loss : 0.113743
[00:16:12.939] iteration 25146 : model1 loss : 0.207930 model2 loss : 0.180094
[00:16:13.270] iteration 25147 : model1 loss : 0.262426 model2 loss : 0.320596
[00:16:13.596] iteration 25148 : model1 loss : 0.155773 model2 loss : 0.247000
[00:16:13.925] iteration 25149 : model1 loss : 0.084467 model2 loss : 0.096196
[00:16:14.254] iteration 25150 : model1 loss : 0.244982 model2 loss : 0.305766
[00:16:14.785] iteration 25151 : model1 loss : 0.189722 model2 loss : 0.254956
[00:16:15.113] iteration 25152 : model1 loss : 0.168547 model2 loss : 0.183950
[00:16:15.442] iteration 25153 : model1 loss : 0.072817 model2 loss : 0.148989
[00:16:15.770] iteration 25154 : model1 loss : 0.188382 model2 loss : 0.195946
[00:16:16.098] iteration 25155 : model1 loss : 0.084202 model2 loss : 0.128441
[00:16:16.422] iteration 25156 : model1 loss : 0.073709 model2 loss : 0.156429
[00:16:16.751] iteration 25157 : model1 loss : 0.213924 model2 loss : 0.271526
[00:16:17.078] iteration 25158 : model1 loss : 0.151764 model2 loss : 0.163585
[00:16:17.406] iteration 25159 : model1 loss : 0.192684 model2 loss : 0.218697
[00:16:17.734] iteration 25160 : model1 loss : 0.214323 model2 loss : 0.240525
[00:16:18.061] iteration 25161 : model1 loss : 0.263428 model2 loss : 0.261894
[00:16:18.385] iteration 25162 : model1 loss : 0.247637 model2 loss : 0.317056
[00:16:18.711] iteration 25163 : model1 loss : 0.167585 model2 loss : 0.187736
[00:16:19.034] iteration 25164 : model1 loss : 0.092698 model2 loss : 0.177226
[00:16:19.355] iteration 25165 : model1 loss : 0.169447 model2 loss : 0.224664
[00:16:19.677] iteration 25166 : model1 loss : 0.228756 model2 loss : 0.277690
[00:16:19.999] iteration 25167 : model1 loss : 0.201528 model2 loss : 0.224329
[00:16:20.322] iteration 25168 : model1 loss : 0.198443 model2 loss : 0.213995
[00:16:20.644] iteration 25169 : model1 loss : 0.175960 model2 loss : 0.223205
[00:16:20.965] iteration 25170 : model1 loss : 0.250712 model2 loss : 0.266584
[00:16:21.287] iteration 25171 : model1 loss : 0.087489 model2 loss : 0.104615
[00:16:21.614] iteration 25172 : model1 loss : 0.086722 model2 loss : 0.093034
[00:16:21.937] iteration 25173 : model1 loss : 0.249492 model2 loss : 0.270418
[00:16:22.259] iteration 25174 : model1 loss : 0.099694 model2 loss : 0.183956
[00:16:22.581] iteration 25175 : model1 loss : 0.234635 model2 loss : 0.267851
[00:16:22.902] iteration 25176 : model1 loss : 0.150593 model2 loss : 0.155268
[00:16:23.223] iteration 25177 : model1 loss : 0.269435 model2 loss : 0.292474
[00:16:23.544] iteration 25178 : model1 loss : 0.245833 model2 loss : 0.270070
[00:16:23.879] iteration 25179 : model1 loss : 0.137718 model2 loss : 0.163508
[00:16:24.210] iteration 25180 : model1 loss : 0.225960 model2 loss : 0.238231
[00:16:24.539] iteration 25181 : model1 loss : 0.158518 model2 loss : 0.173325
[00:16:24.863] iteration 25182 : model1 loss : 0.262664 model2 loss : 0.276851
[00:16:25.187] iteration 25183 : model1 loss : 0.216868 model2 loss : 0.275938
[00:16:25.513] iteration 25184 : model1 loss : 0.164304 model2 loss : 0.197744
[00:16:25.838] iteration 25185 : model1 loss : 0.246234 model2 loss : 0.273749
[00:16:26.166] iteration 25186 : model1 loss : 0.242681 model2 loss : 0.256716
[00:16:26.492] iteration 25187 : model1 loss : 0.095803 model2 loss : 0.155960
[00:16:26.820] iteration 25188 : model1 loss : 0.284569 model2 loss : 0.285099
[00:16:27.147] iteration 25189 : model1 loss : 0.080998 model2 loss : 0.141874
[00:16:27.475] iteration 25190 : model1 loss : 0.285915 model2 loss : 0.286526
[00:16:27.802] iteration 25191 : model1 loss : 0.193058 model2 loss : 0.239859
[00:16:28.129] iteration 25192 : model1 loss : 0.188166 model2 loss : 0.211307
[00:16:28.456] iteration 25193 : model1 loss : 0.150998 model2 loss : 0.174730
[00:16:28.780] iteration 25194 : model1 loss : 0.172306 model2 loss : 0.213471
[00:16:29.105] iteration 25195 : model1 loss : 0.119347 model2 loss : 0.219998
[00:16:29.429] iteration 25196 : model1 loss : 0.173663 model2 loss : 0.257454
[00:16:29.753] iteration 25197 : model1 loss : 0.185805 model2 loss : 0.240092
[00:16:30.078] iteration 25198 : model1 loss : 0.154843 model2 loss : 0.176363
[00:16:30.405] iteration 25199 : model1 loss : 0.069954 model2 loss : 0.069173
[00:16:30.732] iteration 25200 : model1 loss : 0.076436 model2 loss : 0.084482
[00:16:31.268] iteration 25201 : model1 loss : 0.156179 model2 loss : 0.159804
[00:16:31.588] iteration 25202 : model1 loss : 0.236492 model2 loss : 0.242979
[00:16:31.915] iteration 25203 : model1 loss : 0.260062 model2 loss : 0.286501
[00:16:32.240] iteration 25204 : model1 loss : 0.192640 model2 loss : 0.206661
[00:16:32.561] iteration 25205 : model1 loss : 0.160478 model2 loss : 0.246812
[00:16:32.883] iteration 25206 : model1 loss : 0.165953 model2 loss : 0.231699
[00:16:33.204] iteration 25207 : model1 loss : 0.243893 model2 loss : 0.271460
[00:16:33.531] iteration 25208 : model1 loss : 0.313263 model2 loss : 0.357588
[00:16:33.856] iteration 25209 : model1 loss : 0.150645 model2 loss : 0.173200
[00:16:34.178] iteration 25210 : model1 loss : 0.074461 model2 loss : 0.119861
[00:16:34.503] iteration 25211 : model1 loss : 0.205007 model2 loss : 0.204800
[00:16:34.829] iteration 25212 : model1 loss : 0.265976 model2 loss : 0.271593
[00:16:35.152] iteration 25213 : model1 loss : 0.084376 model2 loss : 0.116317
[00:16:35.478] iteration 25214 : model1 loss : 0.238332 model2 loss : 0.241607
[00:16:35.800] iteration 25215 : model1 loss : 0.198192 model2 loss : 0.212145
[00:16:36.122] iteration 25216 : model1 loss : 0.174259 model2 loss : 0.243092
[00:16:36.443] iteration 25217 : model1 loss : 0.110123 model2 loss : 0.214439
[00:16:36.763] iteration 25218 : model1 loss : 0.254818 model2 loss : 0.292696
[00:16:37.085] iteration 25219 : model1 loss : 0.167140 model2 loss : 0.220246
[00:16:37.406] iteration 25220 : model1 loss : 0.187113 model2 loss : 0.213849
[00:16:37.733] iteration 25221 : model1 loss : 0.169106 model2 loss : 0.157221
[00:16:38.058] iteration 25222 : model1 loss : 0.256058 model2 loss : 0.264331
[00:16:38.382] iteration 25223 : model1 loss : 0.169746 model2 loss : 0.187348
[00:16:38.704] iteration 25224 : model1 loss : 0.257611 model2 loss : 0.264150
[00:16:39.026] iteration 25225 : model1 loss : 0.108158 model2 loss : 0.152559
[00:16:39.347] iteration 25226 : model1 loss : 0.066439 model2 loss : 0.111494
[00:16:39.673] iteration 25227 : model1 loss : 0.345201 model2 loss : 0.352342
[00:16:39.999] iteration 25228 : model1 loss : 0.329961 model2 loss : 0.344228
[00:16:40.327] iteration 25229 : model1 loss : 0.125357 model2 loss : 0.155404
[00:16:40.651] iteration 25230 : model1 loss : 0.089999 model2 loss : 0.135146
[00:16:40.972] iteration 25231 : model1 loss : 0.237047 model2 loss : 0.261152
[00:16:41.294] iteration 25232 : model1 loss : 0.113124 model2 loss : 0.162078
[00:16:41.618] iteration 25233 : model1 loss : 0.192750 model2 loss : 0.206500
[00:16:41.942] iteration 25234 : model1 loss : 0.243296 model2 loss : 0.334862
[00:16:42.268] iteration 25235 : model1 loss : 0.172706 model2 loss : 0.220169
[00:16:42.595] iteration 25236 : model1 loss : 0.184209 model2 loss : 0.204554
[00:16:42.919] iteration 25237 : model1 loss : 0.177671 model2 loss : 0.229778
[00:16:43.241] iteration 25238 : model1 loss : 0.160167 model2 loss : 0.165662
[00:16:43.563] iteration 25239 : model1 loss : 0.257012 model2 loss : 0.270067
[00:16:43.888] iteration 25240 : model1 loss : 0.101238 model2 loss : 0.294819
[00:16:44.212] iteration 25241 : model1 loss : 0.064619 model2 loss : 0.093059
[00:16:44.536] iteration 25242 : model1 loss : 0.166559 model2 loss : 0.170263
[00:16:44.862] iteration 25243 : model1 loss : 0.169712 model2 loss : 0.185705
[00:16:45.186] iteration 25244 : model1 loss : 0.232696 model2 loss : 0.245813
[00:16:45.506] iteration 25245 : model1 loss : 0.248487 model2 loss : 0.244293
[00:16:45.832] iteration 25246 : model1 loss : 0.078636 model2 loss : 0.096094
[00:16:46.159] iteration 25247 : model1 loss : 0.154800 model2 loss : 0.197225
[00:16:46.485] iteration 25248 : model1 loss : 0.113702 model2 loss : 0.177147
[00:16:46.811] iteration 25249 : model1 loss : 0.165940 model2 loss : 0.220321
[00:16:47.137] iteration 25250 : model1 loss : 0.168039 model2 loss : 0.216385
[00:16:47.664] iteration 25251 : model1 loss : 0.177603 model2 loss : 0.185210
[00:16:47.989] iteration 25252 : model1 loss : 0.069637 model2 loss : 0.133365
[00:16:48.310] iteration 25253 : model1 loss : 0.156940 model2 loss : 0.166000
[00:16:48.630] iteration 25254 : model1 loss : 0.176636 model2 loss : 0.204968
[00:16:48.956] iteration 25255 : model1 loss : 0.173929 model2 loss : 0.191237
[00:16:49.280] iteration 25256 : model1 loss : 0.160292 model2 loss : 0.191534
[00:16:49.601] iteration 25257 : model1 loss : 0.213343 model2 loss : 0.285618
[00:16:49.923] iteration 25258 : model1 loss : 0.245133 model2 loss : 0.268429
[00:16:50.250] iteration 25259 : model1 loss : 0.187664 model2 loss : 0.198255
[00:16:50.574] iteration 25260 : model1 loss : 0.251995 model2 loss : 0.242691
[00:16:50.899] iteration 25261 : model1 loss : 0.151455 model2 loss : 0.311408
[00:16:51.224] iteration 25262 : model1 loss : 0.175233 model2 loss : 0.191717
[00:16:51.548] iteration 25263 : model1 loss : 0.181792 model2 loss : 0.198443
[00:16:51.870] iteration 25264 : model1 loss : 0.164400 model2 loss : 0.195679
[00:16:52.198] iteration 25265 : model1 loss : 0.167776 model2 loss : 0.213410
[00:16:52.523] iteration 25266 : model1 loss : 0.147463 model2 loss : 0.187213
[00:16:52.848] iteration 25267 : model1 loss : 0.210438 model2 loss : 0.287120
[00:16:53.170] iteration 25268 : model1 loss : 0.106998 model2 loss : 0.197349
[00:16:53.494] iteration 25269 : model1 loss : 0.082658 model2 loss : 0.116920
[00:16:53.815] iteration 25270 : model1 loss : 0.177151 model2 loss : 0.186008
[00:16:54.136] iteration 25271 : model1 loss : 0.109858 model2 loss : 0.124029
[00:16:54.462] iteration 25272 : model1 loss : 0.178407 model2 loss : 0.258763
[00:16:54.788] iteration 25273 : model1 loss : 0.170626 model2 loss : 0.191984
[00:16:55.115] iteration 25274 : model1 loss : 0.293300 model2 loss : 0.339766
[00:16:55.440] iteration 25275 : model1 loss : 0.147810 model2 loss : 0.177349
[00:16:55.765] iteration 25276 : model1 loss : 0.071385 model2 loss : 0.127947
[00:16:56.088] iteration 25277 : model1 loss : 0.185385 model2 loss : 0.185228
[00:16:56.414] iteration 25278 : model1 loss : 0.137799 model2 loss : 0.194298
[00:16:56.738] iteration 25279 : model1 loss : 0.249909 model2 loss : 0.299471
[00:16:57.063] iteration 25280 : model1 loss : 0.327110 model2 loss : 0.336019
[00:16:57.391] iteration 25281 : model1 loss : 0.191475 model2 loss : 0.281851
[00:16:57.717] iteration 25282 : model1 loss : 0.081695 model2 loss : 0.084059
[00:16:58.041] iteration 25283 : model1 loss : 0.189081 model2 loss : 0.256674
[00:16:58.365] iteration 25284 : model1 loss : 0.183036 model2 loss : 0.190590
[00:16:58.687] iteration 25285 : model1 loss : 0.172298 model2 loss : 0.198833
[00:16:59.008] iteration 25286 : model1 loss : 0.294940 model2 loss : 0.299603
[00:16:59.330] iteration 25287 : model1 loss : 0.067880 model2 loss : 0.115311
[00:16:59.651] iteration 25288 : model1 loss : 0.168656 model2 loss : 0.169630
[00:16:59.974] iteration 25289 : model1 loss : 0.167688 model2 loss : 0.176035
[00:17:00.299] iteration 25290 : model1 loss : 0.247208 model2 loss : 0.265886
[00:17:00.623] iteration 25291 : model1 loss : 0.155419 model2 loss : 0.305190
[00:17:00.946] iteration 25292 : model1 loss : 0.147954 model2 loss : 0.203287
[00:17:01.276] iteration 25293 : model1 loss : 0.294583 model2 loss : 0.300494
[00:17:01.601] iteration 25294 : model1 loss : 0.081843 model2 loss : 0.120329
[00:17:01.927] iteration 25295 : model1 loss : 0.083764 model2 loss : 0.148795
[00:17:02.254] iteration 25296 : model1 loss : 0.170164 model2 loss : 0.246901
[00:17:02.579] iteration 25297 : model1 loss : 0.246965 model2 loss : 0.249835
[00:17:02.905] iteration 25298 : model1 loss : 0.173341 model2 loss : 0.198503
[00:17:03.229] iteration 25299 : model1 loss : 0.270964 model2 loss : 0.299211
[00:17:03.551] iteration 25300 : model1 loss : 0.216637 model2 loss : 0.248011
[00:17:04.047] iteration 25301 : model1 loss : 0.189879 model2 loss : 0.208527
[00:17:04.373] iteration 25302 : model1 loss : 0.163420 model2 loss : 0.186936
[00:17:04.699] iteration 25303 : model1 loss : 0.103809 model2 loss : 0.219493
[00:17:05.023] iteration 25304 : model1 loss : 0.181425 model2 loss : 0.249922
[00:17:05.346] iteration 25305 : model1 loss : 0.143176 model2 loss : 0.139362
[00:17:05.667] iteration 25306 : model1 loss : 0.152357 model2 loss : 0.211326
[00:17:05.993] iteration 25307 : model1 loss : 0.272872 model2 loss : 0.301048
[00:17:06.318] iteration 25308 : model1 loss : 0.194043 model2 loss : 0.203521
[00:17:06.641] iteration 25309 : model1 loss : 0.253175 model2 loss : 0.274109
[00:17:06.962] iteration 25310 : model1 loss : 0.162341 model2 loss : 0.205912
[00:17:07.284] iteration 25311 : model1 loss : 0.073182 model2 loss : 0.093177
[00:17:07.605] iteration 25312 : model1 loss : 0.192844 model2 loss : 0.294554
[00:17:07.928] iteration 25313 : model1 loss : 0.111428 model2 loss : 0.132410
[00:17:08.249] iteration 25314 : model1 loss : 0.188930 model2 loss : 0.215003
[00:17:08.577] iteration 25315 : model1 loss : 0.162815 model2 loss : 0.214704
[00:17:08.902] iteration 25316 : model1 loss : 0.080474 model2 loss : 0.108709
[00:17:09.226] iteration 25317 : model1 loss : 0.267353 model2 loss : 0.308822
[00:17:09.546] iteration 25318 : model1 loss : 0.256318 model2 loss : 0.263859
[00:17:09.867] iteration 25319 : model1 loss : 0.170379 model2 loss : 0.209763
[00:17:10.189] iteration 25320 : model1 loss : 0.068518 model2 loss : 0.167309
[00:17:10.518] iteration 25321 : model1 loss : 0.165273 model2 loss : 0.211642
[00:17:10.844] iteration 25322 : model1 loss : 0.185883 model2 loss : 0.207405
[00:17:11.168] iteration 25323 : model1 loss : 0.165314 model2 loss : 0.184067
[00:17:11.489] iteration 25324 : model1 loss : 0.238676 model2 loss : 0.292388
[00:17:11.817] iteration 25325 : model1 loss : 0.172964 model2 loss : 0.230917
[00:17:12.143] iteration 25326 : model1 loss : 0.253932 model2 loss : 0.262888
[00:17:12.469] iteration 25327 : model1 loss : 0.148553 model2 loss : 0.218918
[00:17:12.794] iteration 25328 : model1 loss : 0.265659 model2 loss : 0.303189
[00:17:13.122] iteration 25329 : model1 loss : 0.250194 model2 loss : 0.290403
[00:17:13.449] iteration 25330 : model1 loss : 0.185847 model2 loss : 0.195334
[00:17:13.775] iteration 25331 : model1 loss : 0.160971 model2 loss : 0.172730
[00:17:14.102] iteration 25332 : model1 loss : 0.249230 model2 loss : 0.269575
[00:17:14.431] iteration 25333 : model1 loss : 0.165955 model2 loss : 0.177172
[00:17:14.756] iteration 25334 : model1 loss : 0.155086 model2 loss : 0.164622
[00:17:15.083] iteration 25335 : model1 loss : 0.187712 model2 loss : 0.214978
[00:17:15.409] iteration 25336 : model1 loss : 0.083013 model2 loss : 0.193229
[00:17:15.736] iteration 25337 : model1 loss : 0.243630 model2 loss : 0.228386
[00:17:16.064] iteration 25338 : model1 loss : 0.161797 model2 loss : 0.289093
[00:17:16.390] iteration 25339 : model1 loss : 0.099828 model2 loss : 0.175484
[00:17:16.717] iteration 25340 : model1 loss : 0.170391 model2 loss : 0.224231
[00:17:17.046] iteration 25341 : model1 loss : 0.225361 model2 loss : 0.275744
[00:17:17.372] iteration 25342 : model1 loss : 0.154267 model2 loss : 0.174992
[00:17:17.698] iteration 25343 : model1 loss : 0.253639 model2 loss : 0.244305
[00:17:18.024] iteration 25344 : model1 loss : 0.090651 model2 loss : 0.126713
[00:17:18.351] iteration 25345 : model1 loss : 0.159315 model2 loss : 0.221249
[00:17:18.676] iteration 25346 : model1 loss : 0.218495 model2 loss : 0.254124
[00:17:19.002] iteration 25347 : model1 loss : 0.270953 model2 loss : 0.280227
[00:17:19.329] iteration 25348 : model1 loss : 0.238281 model2 loss : 0.311334
[00:17:19.655] iteration 25349 : model1 loss : 0.214104 model2 loss : 0.240166
[00:17:19.982] iteration 25350 : model1 loss : 0.230659 model2 loss : 0.233984
[00:17:20.517] iteration 25351 : model1 loss : 0.159243 model2 loss : 0.159399
[00:17:20.843] iteration 25352 : model1 loss : 0.169407 model2 loss : 0.260624
[00:17:21.171] iteration 25353 : model1 loss : 0.252698 model2 loss : 0.265061
[00:17:21.498] iteration 25354 : model1 loss : 0.208531 model2 loss : 0.214255
[00:17:21.824] iteration 25355 : model1 loss : 0.154952 model2 loss : 0.245854
[00:17:22.150] iteration 25356 : model1 loss : 0.239473 model2 loss : 0.321050
[00:17:22.477] iteration 25357 : model1 loss : 0.104687 model2 loss : 0.150837
[00:17:22.803] iteration 25358 : model1 loss : 0.096149 model2 loss : 0.127971
[00:17:23.129] iteration 25359 : model1 loss : 0.167324 model2 loss : 0.232964
[00:17:23.455] iteration 25360 : model1 loss : 0.232090 model2 loss : 0.249400
[00:17:23.781] iteration 25361 : model1 loss : 0.175802 model2 loss : 0.222810
[00:17:24.107] iteration 25362 : model1 loss : 0.255690 model2 loss : 0.263688
[00:17:24.433] iteration 25363 : model1 loss : 0.148726 model2 loss : 0.187654
[00:17:24.759] iteration 25364 : model1 loss : 0.314856 model2 loss : 0.338553
[00:17:25.083] iteration 25365 : model1 loss : 0.236427 model2 loss : 0.275940
[00:17:25.406] iteration 25366 : model1 loss : 0.146245 model2 loss : 0.211487
[00:17:25.728] iteration 25367 : model1 loss : 0.146320 model2 loss : 0.177216
[00:17:26.049] iteration 25368 : model1 loss : 0.225053 model2 loss : 0.188144
[00:17:26.370] iteration 25369 : model1 loss : 0.163172 model2 loss : 0.193896
[00:17:26.696] iteration 25370 : model1 loss : 0.167082 model2 loss : 0.210461
[00:17:27.022] iteration 25371 : model1 loss : 0.275941 model2 loss : 0.306179
[00:17:27.348] iteration 25372 : model1 loss : 0.212028 model2 loss : 0.220779
[00:17:27.673] iteration 25373 : model1 loss : 0.301685 model2 loss : 0.345552
[00:17:27.994] iteration 25374 : model1 loss : 0.247688 model2 loss : 0.270243
[00:17:28.314] iteration 25375 : model1 loss : 0.231463 model2 loss : 0.253577
[00:17:28.635] iteration 25376 : model1 loss : 0.268072 model2 loss : 0.292089
[00:17:28.962] iteration 25377 : model1 loss : 0.144043 model2 loss : 0.128476
[00:17:29.286] iteration 25378 : model1 loss : 0.166829 model2 loss : 0.204177
[00:17:29.613] iteration 25379 : model1 loss : 0.157301 model2 loss : 0.172812
[00:17:29.937] iteration 25380 : model1 loss : 0.320165 model2 loss : 0.326755
[00:17:30.259] iteration 25381 : model1 loss : 0.184823 model2 loss : 0.228263
[00:17:30.581] iteration 25382 : model1 loss : 0.194428 model2 loss : 0.182544
[00:17:30.906] iteration 25383 : model1 loss : 0.178736 model2 loss : 0.226919
[00:17:31.232] iteration 25384 : model1 loss : 0.196817 model2 loss : 0.256208
[00:17:31.556] iteration 25385 : model1 loss : 0.153723 model2 loss : 0.183034
[00:17:31.883] iteration 25386 : model1 loss : 0.073011 model2 loss : 0.095903
[00:17:32.204] iteration 25387 : model1 loss : 0.240323 model2 loss : 0.292031
[00:17:32.526] iteration 25388 : model1 loss : 0.175144 model2 loss : 0.224796
[00:17:32.847] iteration 25389 : model1 loss : 0.282681 model2 loss : 0.316837
[00:17:33.170] iteration 25390 : model1 loss : 0.260838 model2 loss : 0.289885
[00:17:33.496] iteration 25391 : model1 loss : 0.089993 model2 loss : 0.144352
[00:17:33.823] iteration 25392 : model1 loss : 0.237139 model2 loss : 0.253951
[00:17:34.149] iteration 25393 : model1 loss : 0.173574 model2 loss : 0.197185
[00:17:34.474] iteration 25394 : model1 loss : 0.187167 model2 loss : 0.288391
[00:17:34.800] iteration 25395 : model1 loss : 0.089477 model2 loss : 0.137300
[00:17:35.126] iteration 25396 : model1 loss : 0.156081 model2 loss : 0.190693
[00:17:35.453] iteration 25397 : model1 loss : 0.223565 model2 loss : 0.225644
[00:17:35.780] iteration 25398 : model1 loss : 0.167326 model2 loss : 0.216636
[00:17:36.106] iteration 25399 : model1 loss : 0.160369 model2 loss : 0.175232
[00:17:36.433] iteration 25400 : model1 loss : 0.178636 model2 loss : 0.199648
[00:17:36.945] iteration 25401 : model1 loss : 0.185661 model2 loss : 0.196605
[00:17:37.271] iteration 25402 : model1 loss : 0.293203 model2 loss : 0.404233
[00:17:37.598] iteration 25403 : model1 loss : 0.183216 model2 loss : 0.192283
[00:17:37.925] iteration 25404 : model1 loss : 0.100452 model2 loss : 0.204566
[00:17:38.250] iteration 25405 : model1 loss : 0.253651 model2 loss : 0.307792
[00:17:38.577] iteration 25406 : model1 loss : 0.088603 model2 loss : 0.111572
[00:17:38.900] iteration 25407 : model1 loss : 0.237212 model2 loss : 0.297038
[00:17:39.226] iteration 25408 : model1 loss : 0.275439 model2 loss : 0.261472
[00:17:39.552] iteration 25409 : model1 loss : 0.303271 model2 loss : 0.358118
[00:17:39.878] iteration 25410 : model1 loss : 0.253647 model2 loss : 0.268558
[00:17:40.203] iteration 25411 : model1 loss : 0.313001 model2 loss : 0.335541
[00:17:40.530] iteration 25412 : model1 loss : 0.215404 model2 loss : 0.274210
[00:17:40.857] iteration 25413 : model1 loss : 0.042957 model2 loss : 0.059476
[00:17:41.183] iteration 25414 : model1 loss : 0.212330 model2 loss : 0.272925
[00:17:41.511] iteration 25415 : model1 loss : 0.131743 model2 loss : 0.143008
[00:17:41.837] iteration 25416 : model1 loss : 0.069115 model2 loss : 0.122108
[00:17:42.165] iteration 25417 : model1 loss : 0.226909 model2 loss : 0.222709
[00:17:42.491] iteration 25418 : model1 loss : 0.161754 model2 loss : 0.216361
[00:17:42.819] iteration 25419 : model1 loss : 0.163383 model2 loss : 0.280073
[00:17:43.145] iteration 25420 : model1 loss : 0.184602 model2 loss : 0.194040
[00:17:43.471] iteration 25421 : model1 loss : 0.239332 model2 loss : 0.228411
[00:17:43.797] iteration 25422 : model1 loss : 0.166396 model2 loss : 0.202805
[00:17:44.124] iteration 25423 : model1 loss : 0.268490 model2 loss : 0.311940
[00:17:44.450] iteration 25424 : model1 loss : 0.245894 model2 loss : 0.298308
[00:17:44.776] iteration 25425 : model1 loss : 0.166166 model2 loss : 0.198693
[00:17:45.104] iteration 25426 : model1 loss : 0.181640 model2 loss : 0.183325
[00:17:45.432] iteration 25427 : model1 loss : 0.089138 model2 loss : 0.140217
[00:17:45.758] iteration 25428 : model1 loss : 0.195137 model2 loss : 0.247759
[00:17:46.083] iteration 25429 : model1 loss : 0.082899 model2 loss : 0.125988
[00:17:46.409] iteration 25430 : model1 loss : 0.178346 model2 loss : 0.276591
[00:17:46.737] iteration 25431 : model1 loss : 0.171646 model2 loss : 0.198236
[00:17:47.063] iteration 25432 : model1 loss : 0.177162 model2 loss : 0.166078
[00:17:47.389] iteration 25433 : model1 loss : 0.160911 model2 loss : 0.165697
[00:17:47.715] iteration 25434 : model1 loss : 0.171654 model2 loss : 0.192064
[00:17:48.043] iteration 25435 : model1 loss : 0.189009 model2 loss : 0.211436
[00:17:48.368] iteration 25436 : model1 loss : 0.191794 model2 loss : 0.258408
[00:17:48.694] iteration 25437 : model1 loss : 0.088425 model2 loss : 0.199595
[00:17:49.020] iteration 25438 : model1 loss : 0.153625 model2 loss : 0.143561
[00:17:49.348] iteration 25439 : model1 loss : 0.084671 model2 loss : 0.120026
[00:17:49.674] iteration 25440 : model1 loss : 0.173702 model2 loss : 0.181285
[00:17:50.000] iteration 25441 : model1 loss : 0.105771 model2 loss : 0.140690
[00:17:50.327] iteration 25442 : model1 loss : 0.151065 model2 loss : 0.200510
[00:17:50.655] iteration 25443 : model1 loss : 0.186801 model2 loss : 0.282104
[00:17:50.981] iteration 25444 : model1 loss : 0.188217 model2 loss : 0.219342
[00:17:51.307] iteration 25445 : model1 loss : 0.262235 model2 loss : 0.300226
[00:17:51.632] iteration 25446 : model1 loss : 0.268445 model2 loss : 0.295281
[00:17:51.962] iteration 25447 : model1 loss : 0.214831 model2 loss : 0.302610
[00:17:52.288] iteration 25448 : model1 loss : 0.112561 model2 loss : 0.177006
[00:17:52.614] iteration 25449 : model1 loss : 0.285785 model2 loss : 0.364019
[00:17:52.939] iteration 25450 : model1 loss : 0.173208 model2 loss : 0.279388
[00:17:53.465] iteration 25451 : model1 loss : 0.158056 model2 loss : 0.194694
[00:17:53.790] iteration 25452 : model1 loss : 0.083792 model2 loss : 0.113284
[00:17:54.116] iteration 25453 : model1 loss : 0.192896 model2 loss : 0.222059
[00:17:54.442] iteration 25454 : model1 loss : 0.173137 model2 loss : 0.131535
[00:17:54.770] iteration 25455 : model1 loss : 0.164436 model2 loss : 0.210136
[00:17:55.095] iteration 25456 : model1 loss : 0.198118 model2 loss : 0.250755
[00:17:55.421] iteration 25457 : model1 loss : 0.171160 model2 loss : 0.180935
[00:17:55.747] iteration 25458 : model1 loss : 0.261684 model2 loss : 0.258351
[00:17:56.076] iteration 25459 : model1 loss : 0.276294 model2 loss : 0.304849
[00:17:56.401] iteration 25460 : model1 loss : 0.062566 model2 loss : 0.116765
[00:17:56.728] iteration 25461 : model1 loss : 0.317907 model2 loss : 0.323100
[00:17:57.054] iteration 25462 : model1 loss : 0.233244 model2 loss : 0.281290
[00:17:57.382] iteration 25463 : model1 loss : 0.190234 model2 loss : 0.198531
[00:17:57.708] iteration 25464 : model1 loss : 0.153591 model2 loss : 0.186313
[00:17:58.034] iteration 25465 : model1 loss : 0.103192 model2 loss : 0.163597
[00:17:58.360] iteration 25466 : model1 loss : 0.228272 model2 loss : 0.217143
[00:17:58.688] iteration 25467 : model1 loss : 0.101972 model2 loss : 0.177970
[00:17:59.014] iteration 25468 : model1 loss : 0.170895 model2 loss : 0.223071
[00:17:59.340] iteration 25469 : model1 loss : 0.252172 model2 loss : 0.274594
[00:17:59.666] iteration 25470 : model1 loss : 0.072804 model2 loss : 0.112166
[00:17:59.994] iteration 25471 : model1 loss : 0.265325 model2 loss : 0.294211
[00:18:00.321] iteration 25472 : model1 loss : 0.204241 model2 loss : 0.211912
[00:18:00.648] iteration 25473 : model1 loss : 0.249079 model2 loss : 0.273781
[00:18:00.973] iteration 25474 : model1 loss : 0.084897 model2 loss : 0.085915
[00:18:01.302] iteration 25475 : model1 loss : 0.156404 model2 loss : 0.163445
[00:18:01.627] iteration 25476 : model1 loss : 0.097924 model2 loss : 0.133702
[00:18:01.953] iteration 25477 : model1 loss : 0.248803 model2 loss : 0.286536
[00:18:02.279] iteration 25478 : model1 loss : 0.262273 model2 loss : 0.289081
[00:18:02.606] iteration 25479 : model1 loss : 0.099786 model2 loss : 0.177186
[00:18:02.931] iteration 25480 : model1 loss : 0.157204 model2 loss : 0.167442
[00:18:03.257] iteration 25481 : model1 loss : 0.245164 model2 loss : 0.257222
[00:18:03.582] iteration 25482 : model1 loss : 0.093852 model2 loss : 0.100821
[00:18:03.910] iteration 25483 : model1 loss : 0.193917 model2 loss : 0.224725
[00:18:04.236] iteration 25484 : model1 loss : 0.166385 model2 loss : 0.185222
[00:18:04.562] iteration 25485 : model1 loss : 0.235984 model2 loss : 0.266823
[00:18:04.888] iteration 25486 : model1 loss : 0.109318 model2 loss : 0.185435
[00:18:05.215] iteration 25487 : model1 loss : 0.084860 model2 loss : 0.100965
[00:18:05.539] iteration 25488 : model1 loss : 0.124653 model2 loss : 0.138865
[00:18:05.866] iteration 25489 : model1 loss : 0.175602 model2 loss : 0.280311
[00:18:06.192] iteration 25490 : model1 loss : 0.182192 model2 loss : 0.185634
[00:18:06.520] iteration 25491 : model1 loss : 0.184606 model2 loss : 0.191117
[00:18:06.845] iteration 25492 : model1 loss : 0.156824 model2 loss : 0.212467
[00:18:07.171] iteration 25493 : model1 loss : 0.102091 model2 loss : 0.133447
[00:18:07.496] iteration 25494 : model1 loss : 0.177708 model2 loss : 0.183623
[00:18:07.825] iteration 25495 : model1 loss : 0.164346 model2 loss : 0.202494
[00:18:08.150] iteration 25496 : model1 loss : 0.070761 model2 loss : 0.160196
[00:18:08.477] iteration 25497 : model1 loss : 0.188469 model2 loss : 0.219834
[00:18:08.803] iteration 25498 : model1 loss : 0.188216 model2 loss : 0.234846
[00:18:09.130] iteration 25499 : model1 loss : 0.159839 model2 loss : 0.174352
[00:18:09.456] iteration 25500 : model1 loss : 0.320497 model2 loss : 0.356978
[00:18:09.970] iteration 25501 : model1 loss : 0.194875 model2 loss : 0.234595
[00:18:10.297] iteration 25502 : model1 loss : 0.257413 model2 loss : 0.248920
[00:18:10.626] iteration 25503 : model1 loss : 0.092866 model2 loss : 0.214187
[00:18:10.951] iteration 25504 : model1 loss : 0.270879 model2 loss : 0.287899
[00:18:11.276] iteration 25505 : model1 loss : 0.151669 model2 loss : 0.226791
[00:18:11.598] iteration 25506 : model1 loss : 0.082283 model2 loss : 0.154612
[00:18:11.920] iteration 25507 : model1 loss : 0.070183 model2 loss : 0.118435
[00:18:12.242] iteration 25508 : model1 loss : 0.141357 model2 loss : 0.157843
[00:18:12.565] iteration 25509 : model1 loss : 0.160898 model2 loss : 0.223553
[00:18:12.891] iteration 25510 : model1 loss : 0.183660 model2 loss : 0.189233
[00:18:13.219] iteration 25511 : model1 loss : 0.152708 model2 loss : 0.202634
[00:18:13.545] iteration 25512 : model1 loss : 0.182726 model2 loss : 0.180333
[00:18:13.869] iteration 25513 : model1 loss : 0.181327 model2 loss : 0.177639
[00:18:14.190] iteration 25514 : model1 loss : 0.191077 model2 loss : 0.223888
[00:18:14.514] iteration 25515 : model1 loss : 0.093901 model2 loss : 0.157953
[00:18:14.836] iteration 25516 : model1 loss : 0.104348 model2 loss : 0.140962
[00:18:15.162] iteration 25517 : model1 loss : 0.166090 model2 loss : 0.181382
[00:18:15.489] iteration 25518 : model1 loss : 0.120354 model2 loss : 0.172390
[00:18:15.817] iteration 25519 : model1 loss : 0.265430 model2 loss : 0.286268
[00:18:16.143] iteration 25520 : model1 loss : 0.160398 model2 loss : 0.191234
[00:18:16.468] iteration 25521 : model1 loss : 0.274662 model2 loss : 0.343469
[00:18:16.793] iteration 25522 : model1 loss : 0.155527 model2 loss : 0.213062
[00:18:17.123] iteration 25523 : model1 loss : 0.098364 model2 loss : 0.116937
[00:18:17.448] iteration 25524 : model1 loss : 0.200951 model2 loss : 0.217314
[00:18:17.769] iteration 25525 : model1 loss : 0.174904 model2 loss : 0.180975
[00:18:18.095] iteration 25526 : model1 loss : 0.276691 model2 loss : 0.377910
[00:18:18.422] iteration 25527 : model1 loss : 0.094670 model2 loss : 0.135708
[00:18:18.743] iteration 25528 : model1 loss : 0.264403 model2 loss : 0.304626
[00:18:19.066] iteration 25529 : model1 loss : 0.253976 model2 loss : 0.293337
[00:18:19.388] iteration 25530 : model1 loss : 0.233655 model2 loss : 0.273002
[00:18:19.714] iteration 25531 : model1 loss : 0.249552 model2 loss : 0.283631
[00:18:20.038] iteration 25532 : model1 loss : 0.101710 model2 loss : 0.121115
[00:18:20.364] iteration 25533 : model1 loss : 0.187868 model2 loss : 0.233715
[00:18:20.690] iteration 25534 : model1 loss : 0.196821 model2 loss : 0.251163
[00:18:21.018] iteration 25535 : model1 loss : 0.326063 model2 loss : 0.358393
[00:18:21.344] iteration 25536 : model1 loss : 0.245571 model2 loss : 0.257169
[00:18:21.668] iteration 25537 : model1 loss : 0.166169 model2 loss : 0.191337
[00:18:21.993] iteration 25538 : model1 loss : 0.279605 model2 loss : 0.314612
[00:18:22.321] iteration 25539 : model1 loss : 0.083636 model2 loss : 0.105738
[00:18:22.647] iteration 25540 : model1 loss : 0.257779 model2 loss : 0.280321
[00:18:22.972] iteration 25541 : model1 loss : 0.315918 model2 loss : 0.332174
[00:18:23.293] iteration 25542 : model1 loss : 0.123946 model2 loss : 0.114106
[00:18:23.616] iteration 25543 : model1 loss : 0.171103 model2 loss : 0.234056
[00:18:23.938] iteration 25544 : model1 loss : 0.079831 model2 loss : 0.100468
[00:18:24.262] iteration 25545 : model1 loss : 0.194535 model2 loss : 0.218675
[00:18:24.587] iteration 25546 : model1 loss : 0.183630 model2 loss : 0.222245
[00:18:24.914] iteration 25547 : model1 loss : 0.187582 model2 loss : 0.206970
[00:18:25.241] iteration 25548 : model1 loss : 0.173081 model2 loss : 0.177233
[00:18:25.567] iteration 25549 : model1 loss : 0.085154 model2 loss : 0.214986
[00:18:25.888] iteration 25550 : model1 loss : 0.248460 model2 loss : 0.253597
[00:18:26.398] iteration 25551 : model1 loss : 0.171814 model2 loss : 0.175282
[00:18:26.725] iteration 25552 : model1 loss : 0.181724 model2 loss : 0.278266
[00:18:27.050] iteration 25553 : model1 loss : 0.169146 model2 loss : 0.215863
[00:18:27.376] iteration 25554 : model1 loss : 0.175469 model2 loss : 0.329639
[00:18:27.701] iteration 25555 : model1 loss : 0.261361 model2 loss : 0.261780
[00:18:28.022] iteration 25556 : model1 loss : 0.093679 model2 loss : 0.142472
[00:18:28.343] iteration 25557 : model1 loss : 0.321505 model2 loss : 0.325375
[00:18:28.664] iteration 25558 : model1 loss : 0.157598 model2 loss : 0.212263
[00:18:28.990] iteration 25559 : model1 loss : 0.307385 model2 loss : 0.283310
[00:18:29.315] iteration 25560 : model1 loss : 0.195219 model2 loss : 0.180472
[00:18:29.642] iteration 25561 : model1 loss : 0.243557 model2 loss : 0.257239
[00:18:29.969] iteration 25562 : model1 loss : 0.171204 model2 loss : 0.197391
[00:18:30.297] iteration 25563 : model1 loss : 0.212788 model2 loss : 0.223535
[00:18:30.623] iteration 25564 : model1 loss : 0.207302 model2 loss : 0.261480
[00:18:30.950] iteration 25565 : model1 loss : 0.235731 model2 loss : 0.248724
[00:18:31.276] iteration 25566 : model1 loss : 0.281247 model2 loss : 0.402534
[00:18:31.604] iteration 25567 : model1 loss : 0.166810 model2 loss : 0.175291
[00:18:31.930] iteration 25568 : model1 loss : 0.079839 model2 loss : 0.099065
[00:18:32.255] iteration 25569 : model1 loss : 0.190619 model2 loss : 0.180824
[00:18:32.583] iteration 25570 : model1 loss : 0.211481 model2 loss : 0.232702
[00:18:32.910] iteration 25571 : model1 loss : 0.162514 model2 loss : 0.198638
[00:18:33.236] iteration 25572 : model1 loss : 0.238963 model2 loss : 0.267327
[00:18:33.560] iteration 25573 : model1 loss : 0.149796 model2 loss : 0.204839
[00:18:33.882] iteration 25574 : model1 loss : 0.171038 model2 loss : 0.188184
[00:18:34.209] iteration 25575 : model1 loss : 0.175252 model2 loss : 0.287785
[00:18:34.534] iteration 25576 : model1 loss : 0.260640 model2 loss : 0.294862
[00:18:34.859] iteration 25577 : model1 loss : 0.106428 model2 loss : 0.128296
[00:18:35.184] iteration 25578 : model1 loss : 0.281392 model2 loss : 0.292919
[00:18:35.512] iteration 25579 : model1 loss : 0.254236 model2 loss : 0.254899
[00:18:35.838] iteration 25580 : model1 loss : 0.186919 model2 loss : 0.260336
[00:18:36.163] iteration 25581 : model1 loss : 0.173303 model2 loss : 0.176623
[00:18:36.486] iteration 25582 : model1 loss : 0.241345 model2 loss : 0.286684
[00:18:36.814] iteration 25583 : model1 loss : 0.289703 model2 loss : 0.351583
[00:18:37.140] iteration 25584 : model1 loss : 0.232462 model2 loss : 0.197384
[00:18:37.466] iteration 25585 : model1 loss : 0.252253 model2 loss : 0.281561
[00:18:37.792] iteration 25586 : model1 loss : 0.173822 model2 loss : 0.229847
[00:18:38.121] iteration 25587 : model1 loss : 0.248450 model2 loss : 0.260600
[00:18:38.447] iteration 25588 : model1 loss : 0.178150 model2 loss : 0.214001
[00:18:38.771] iteration 25589 : model1 loss : 0.171512 model2 loss : 0.196179
[00:18:39.097] iteration 25590 : model1 loss : 0.149649 model2 loss : 0.162948
[00:18:39.420] iteration 25591 : model1 loss : 0.178396 model2 loss : 0.195374
[00:18:39.742] iteration 25592 : model1 loss : 0.156045 model2 loss : 0.247868
[00:18:40.069] iteration 25593 : model1 loss : 0.163640 model2 loss : 0.184569
[00:18:40.397] iteration 25594 : model1 loss : 0.104655 model2 loss : 0.085084
[00:18:40.723] iteration 25595 : model1 loss : 0.176951 model2 loss : 0.277917
[00:18:41.049] iteration 25596 : model1 loss : 0.150964 model2 loss : 0.168924
[00:18:41.375] iteration 25597 : model1 loss : 0.263722 model2 loss : 0.271336
[00:18:41.701] iteration 25598 : model1 loss : 0.082227 model2 loss : 0.164282
[00:18:42.027] iteration 25599 : model1 loss : 0.085280 model2 loss : 0.119468
[00:18:42.353] iteration 25600 : model1 loss : 0.190748 model2 loss : 0.221991
[00:18:42.911] iteration 25601 : model1 loss : 0.254732 model2 loss : 0.265884
[00:18:43.237] iteration 25602 : model1 loss : 0.173407 model2 loss : 0.196440
[00:18:43.563] iteration 25603 : model1 loss : 0.162651 model2 loss : 0.176273
[00:18:43.889] iteration 25604 : model1 loss : 0.236296 model2 loss : 0.253740
[00:18:44.214] iteration 25605 : model1 loss : 0.092544 model2 loss : 0.125042
[00:18:44.535] iteration 25606 : model1 loss : 0.234256 model2 loss : 0.259962
[00:18:44.856] iteration 25607 : model1 loss : 0.164858 model2 loss : 0.188213
[00:18:45.182] iteration 25608 : model1 loss : 0.183705 model2 loss : 0.205260
[00:18:45.504] iteration 25609 : model1 loss : 0.105639 model2 loss : 0.131290
[00:18:45.825] iteration 25610 : model1 loss : 0.173155 model2 loss : 0.206413
[00:18:46.150] iteration 25611 : model1 loss : 0.273268 model2 loss : 0.410496
[00:18:46.474] iteration 25612 : model1 loss : 0.086048 model2 loss : 0.087227
[00:18:46.801] iteration 25613 : model1 loss : 0.185376 model2 loss : 0.223323
[00:18:47.130] iteration 25614 : model1 loss : 0.185714 model2 loss : 0.204369
[00:18:47.454] iteration 25615 : model1 loss : 0.143528 model2 loss : 0.151741
[00:18:48.479] iteration 25616 : model1 loss : 0.093374 model2 loss : 0.097432
[00:18:48.805] iteration 25617 : model1 loss : 0.228407 model2 loss : 0.253291
[00:18:49.130] iteration 25618 : model1 loss : 0.269022 model2 loss : 0.245852
[00:18:49.455] iteration 25619 : model1 loss : 0.182547 model2 loss : 0.218412
[00:18:49.780] iteration 25620 : model1 loss : 0.208364 model2 loss : 0.204023
[00:18:50.105] iteration 25621 : model1 loss : 0.319146 model2 loss : 0.320207
[00:18:50.430] iteration 25622 : model1 loss : 0.201217 model2 loss : 0.277700
[00:18:50.754] iteration 25623 : model1 loss : 0.127396 model2 loss : 0.108999
[00:18:51.075] iteration 25624 : model1 loss : 0.118075 model2 loss : 0.151115
[00:18:51.401] iteration 25625 : model1 loss : 0.178631 model2 loss : 0.238229
[00:18:51.727] iteration 25626 : model1 loss : 0.196454 model2 loss : 0.234304
[00:18:52.053] iteration 25627 : model1 loss : 0.071069 model2 loss : 0.096525
[00:18:52.379] iteration 25628 : model1 loss : 0.259039 model2 loss : 0.317308
[00:18:52.704] iteration 25629 : model1 loss : 0.174060 model2 loss : 0.187462
[00:18:53.031] iteration 25630 : model1 loss : 0.184409 model2 loss : 0.191435
[00:18:53.357] iteration 25631 : model1 loss : 0.324242 model2 loss : 0.340309
[00:18:53.683] iteration 25632 : model1 loss : 0.260997 model2 loss : 0.284688
[00:18:54.008] iteration 25633 : model1 loss : 0.132212 model2 loss : 0.089900
[00:18:54.334] iteration 25634 : model1 loss : 0.244822 model2 loss : 0.280993
[00:18:54.660] iteration 25635 : model1 loss : 0.236876 model2 loss : 0.244613
[00:18:54.986] iteration 25636 : model1 loss : 0.100496 model2 loss : 0.149259
[00:18:55.312] iteration 25637 : model1 loss : 0.086529 model2 loss : 0.182026
[00:18:55.638] iteration 25638 : model1 loss : 0.265062 model2 loss : 0.289966
[00:18:55.964] iteration 25639 : model1 loss : 0.100338 model2 loss : 0.207041
[00:18:56.290] iteration 25640 : model1 loss : 0.156240 model2 loss : 0.198525
[00:18:56.616] iteration 25641 : model1 loss : 0.181311 model2 loss : 0.194895
[00:18:56.942] iteration 25642 : model1 loss : 0.239730 model2 loss : 0.254187
[00:18:57.268] iteration 25643 : model1 loss : 0.167789 model2 loss : 0.177916
[00:18:57.594] iteration 25644 : model1 loss : 0.098148 model2 loss : 0.165737
[00:18:57.919] iteration 25645 : model1 loss : 0.271942 model2 loss : 0.265819
[00:18:58.245] iteration 25646 : model1 loss : 0.175352 model2 loss : 0.200921
[00:18:58.571] iteration 25647 : model1 loss : 0.175573 model2 loss : 0.192737
[00:18:58.898] iteration 25648 : model1 loss : 0.163552 model2 loss : 0.197996
[00:18:59.223] iteration 25649 : model1 loss : 0.096945 model2 loss : 0.128861
[00:18:59.549] iteration 25650 : model1 loss : 0.255700 model2 loss : 0.277518
[00:19:00.081] iteration 25651 : model1 loss : 0.261541 model2 loss : 0.282943
[00:19:00.407] iteration 25652 : model1 loss : 0.194573 model2 loss : 0.239871
[00:19:00.734] iteration 25653 : model1 loss : 0.240404 model2 loss : 0.251312
[00:19:01.059] iteration 25654 : model1 loss : 0.146100 model2 loss : 0.189654
[00:19:01.386] iteration 25655 : model1 loss : 0.198107 model2 loss : 0.184755
[00:19:01.713] iteration 25656 : model1 loss : 0.093704 model2 loss : 0.088035
[00:19:02.039] iteration 25657 : model1 loss : 0.242663 model2 loss : 0.262152
[00:19:02.365] iteration 25658 : model1 loss : 0.163302 model2 loss : 0.176875
[00:19:02.691] iteration 25659 : model1 loss : 0.250147 model2 loss : 0.262426
[00:19:03.017] iteration 25660 : model1 loss : 0.197624 model2 loss : 0.207328
[00:19:03.343] iteration 25661 : model1 loss : 0.215977 model2 loss : 0.196971
[00:19:03.670] iteration 25662 : model1 loss : 0.063472 model2 loss : 0.086022
[00:19:03.996] iteration 25663 : model1 loss : 0.149271 model2 loss : 0.151868
[00:19:04.321] iteration 25664 : model1 loss : 0.186633 model2 loss : 0.260805
[00:19:04.643] iteration 25665 : model1 loss : 0.111074 model2 loss : 0.186166
[00:19:04.967] iteration 25666 : model1 loss : 0.116856 model2 loss : 0.189044
[00:19:05.293] iteration 25667 : model1 loss : 0.194049 model2 loss : 0.202919
[00:19:05.614] iteration 25668 : model1 loss : 0.205764 model2 loss : 0.192274
[00:19:05.936] iteration 25669 : model1 loss : 0.176353 model2 loss : 0.211798
[00:19:06.257] iteration 25670 : model1 loss : 0.111573 model2 loss : 0.152955
[00:19:06.583] iteration 25671 : model1 loss : 0.199071 model2 loss : 0.206403
[00:19:06.909] iteration 25672 : model1 loss : 0.325845 model2 loss : 0.335352
[00:19:07.235] iteration 25673 : model1 loss : 0.116477 model2 loss : 0.124184
[00:19:07.562] iteration 25674 : model1 loss : 0.168806 model2 loss : 0.257158
[00:19:07.886] iteration 25675 : model1 loss : 0.166390 model2 loss : 0.199676
[00:19:08.208] iteration 25676 : model1 loss : 0.195127 model2 loss : 0.214711
[00:19:08.535] iteration 25677 : model1 loss : 0.143850 model2 loss : 0.175805
[00:19:08.861] iteration 25678 : model1 loss : 0.236139 model2 loss : 0.254184
[00:19:09.182] iteration 25679 : model1 loss : 0.318878 model2 loss : 0.351237
[00:19:09.503] iteration 25680 : model1 loss : 0.268332 model2 loss : 0.297328
[00:19:09.830] iteration 25681 : model1 loss : 0.259709 model2 loss : 0.246808
[00:19:10.155] iteration 25682 : model1 loss : 0.153123 model2 loss : 0.214648
[00:19:10.479] iteration 25683 : model1 loss : 0.069684 model2 loss : 0.089700
[00:19:10.805] iteration 25684 : model1 loss : 0.079065 model2 loss : 0.122047
[00:19:11.130] iteration 25685 : model1 loss : 0.198858 model2 loss : 0.204595
[00:19:11.453] iteration 25686 : model1 loss : 0.258688 model2 loss : 0.262834
[00:19:11.779] iteration 25687 : model1 loss : 0.175533 model2 loss : 0.158420
[00:19:12.104] iteration 25688 : model1 loss : 0.172098 model2 loss : 0.202898
[00:19:12.429] iteration 25689 : model1 loss : 0.173065 model2 loss : 0.214652
[00:19:12.750] iteration 25690 : model1 loss : 0.204904 model2 loss : 0.224723
[00:19:13.072] iteration 25691 : model1 loss : 0.172839 model2 loss : 0.240970
[00:19:13.394] iteration 25692 : model1 loss : 0.257158 model2 loss : 0.255637
[00:19:13.715] iteration 25693 : model1 loss : 0.155927 model2 loss : 0.215455
[00:19:14.035] iteration 25694 : model1 loss : 0.109803 model2 loss : 0.175365
[00:19:14.356] iteration 25695 : model1 loss : 0.269131 model2 loss : 0.289469
[00:19:14.678] iteration 25696 : model1 loss : 0.265618 model2 loss : 0.320016
[00:19:15.005] iteration 25697 : model1 loss : 0.254479 model2 loss : 0.275406
[00:19:15.330] iteration 25698 : model1 loss : 0.251664 model2 loss : 0.299040
[00:19:15.651] iteration 25699 : model1 loss : 0.083381 model2 loss : 0.093686
[00:19:15.974] iteration 25700 : model1 loss : 0.164014 model2 loss : 0.244968
[00:19:16.499] iteration 25701 : model1 loss : 0.098382 model2 loss : 0.143359
[00:19:16.825] iteration 25702 : model1 loss : 0.217110 model2 loss : 0.194554
[00:19:17.152] iteration 25703 : model1 loss : 0.164798 model2 loss : 0.204295
[00:19:17.478] iteration 25704 : model1 loss : 0.151056 model2 loss : 0.179348
[00:19:17.804] iteration 25705 : model1 loss : 0.207132 model2 loss : 0.230306
[00:19:18.130] iteration 25706 : model1 loss : 0.267237 model2 loss : 0.312383
[00:19:18.456] iteration 25707 : model1 loss : 0.190360 model2 loss : 0.200818
[00:19:18.782] iteration 25708 : model1 loss : 0.183585 model2 loss : 0.213680
[00:19:19.108] iteration 25709 : model1 loss : 0.194912 model2 loss : 0.249201
[00:19:19.434] iteration 25710 : model1 loss : 0.153345 model2 loss : 0.166862
[00:19:19.760] iteration 25711 : model1 loss : 0.143720 model2 loss : 0.220589
[00:19:20.087] iteration 25712 : model1 loss : 0.189106 model2 loss : 0.232143
[00:19:20.412] iteration 25713 : model1 loss : 0.142804 model2 loss : 0.179838
[00:19:20.739] iteration 25714 : model1 loss : 0.162195 model2 loss : 0.202121
[00:19:21.066] iteration 25715 : model1 loss : 0.223802 model2 loss : 0.211818
[00:19:21.392] iteration 25716 : model1 loss : 0.189155 model2 loss : 0.192962
[00:19:21.719] iteration 25717 : model1 loss : 0.159087 model2 loss : 0.195421
[00:19:22.045] iteration 25718 : model1 loss : 0.167831 model2 loss : 0.202502
[00:19:22.371] iteration 25719 : model1 loss : 0.086419 model2 loss : 0.154022
[00:19:22.698] iteration 25720 : model1 loss : 0.095809 model2 loss : 0.138687
[00:19:23.024] iteration 25721 : model1 loss : 0.250484 model2 loss : 0.282378
[00:19:23.349] iteration 25722 : model1 loss : 0.236102 model2 loss : 0.279444
[00:19:23.675] iteration 25723 : model1 loss : 0.167401 model2 loss : 0.227977
[00:19:24.002] iteration 25724 : model1 loss : 0.181582 model2 loss : 0.226495
[00:19:24.327] iteration 25725 : model1 loss : 0.167020 model2 loss : 0.140582
[00:19:24.653] iteration 25726 : model1 loss : 0.123704 model2 loss : 0.229404
[00:19:24.979] iteration 25727 : model1 loss : 0.203482 model2 loss : 0.218312
[00:19:25.305] iteration 25728 : model1 loss : 0.079974 model2 loss : 0.104796
[00:19:25.632] iteration 25729 : model1 loss : 0.072218 model2 loss : 0.101295
[00:19:25.959] iteration 25730 : model1 loss : 0.239288 model2 loss : 0.243549
[00:19:26.286] iteration 25731 : model1 loss : 0.124187 model2 loss : 0.140193
[00:19:26.612] iteration 25732 : model1 loss : 0.237899 model2 loss : 0.236156
[00:19:26.938] iteration 25733 : model1 loss : 0.222809 model2 loss : 0.312533
[00:19:27.264] iteration 25734 : model1 loss : 0.280944 model2 loss : 0.330950
[00:19:27.590] iteration 25735 : model1 loss : 0.257892 model2 loss : 0.290499
[00:19:27.916] iteration 25736 : model1 loss : 0.081640 model2 loss : 0.125269
[00:19:28.242] iteration 25737 : model1 loss : 0.164187 model2 loss : 0.195782
[00:19:28.568] iteration 25738 : model1 loss : 0.099335 model2 loss : 0.150597
[00:19:28.895] iteration 25739 : model1 loss : 0.218163 model2 loss : 0.264396
[00:19:29.221] iteration 25740 : model1 loss : 0.257004 model2 loss : 0.264071
[00:19:29.546] iteration 25741 : model1 loss : 0.174227 model2 loss : 0.194660
[00:19:29.872] iteration 25742 : model1 loss : 0.089872 model2 loss : 0.151508
[00:19:30.199] iteration 25743 : model1 loss : 0.189229 model2 loss : 0.169221
[00:19:30.525] iteration 25744 : model1 loss : 0.090632 model2 loss : 0.106236
[00:19:30.851] iteration 25745 : model1 loss : 0.245144 model2 loss : 0.267857
[00:19:31.178] iteration 25746 : model1 loss : 0.179451 model2 loss : 0.213605
[00:19:31.504] iteration 25747 : model1 loss : 0.095828 model2 loss : 0.158428
[00:19:31.832] iteration 25748 : model1 loss : 0.173857 model2 loss : 0.213179
[00:19:32.158] iteration 25749 : model1 loss : 0.131236 model2 loss : 0.139516
[00:19:32.484] iteration 25750 : model1 loss : 0.242889 model2 loss : 0.249164
[00:19:33.010] iteration 25751 : model1 loss : 0.166738 model2 loss : 0.174795
[00:19:33.336] iteration 25752 : model1 loss : 0.087621 model2 loss : 0.104972
[00:19:33.663] iteration 25753 : model1 loss : 0.277467 model2 loss : 0.324043
[00:19:33.989] iteration 25754 : model1 loss : 0.167889 model2 loss : 0.171459
[00:19:34.316] iteration 25755 : model1 loss : 0.190326 model2 loss : 0.402662
[00:19:34.642] iteration 25756 : model1 loss : 0.179367 model2 loss : 0.192481
[00:19:34.968] iteration 25757 : model1 loss : 0.153566 model2 loss : 0.170920
[00:19:35.296] iteration 25758 : model1 loss : 0.083609 model2 loss : 0.153587
[00:19:35.622] iteration 25759 : model1 loss : 0.177147 model2 loss : 0.190384
[00:19:35.948] iteration 25760 : model1 loss : 0.176357 model2 loss : 0.261903
[00:19:36.275] iteration 25761 : model1 loss : 0.212035 model2 loss : 0.233650
[00:19:36.602] iteration 25762 : model1 loss : 0.273387 model2 loss : 0.297662
[00:19:36.928] iteration 25763 : model1 loss : 0.221877 model2 loss : 0.283347
[00:19:37.254] iteration 25764 : model1 loss : 0.200918 model2 loss : 0.263412
[00:19:37.580] iteration 25765 : model1 loss : 0.161847 model2 loss : 0.183818
[00:19:37.907] iteration 25766 : model1 loss : 0.171187 model2 loss : 0.288595
[00:19:38.233] iteration 25767 : model1 loss : 0.241341 model2 loss : 0.271525
[00:19:38.559] iteration 25768 : model1 loss : 0.189257 model2 loss : 0.198736
[00:19:38.886] iteration 25769 : model1 loss : 0.080684 model2 loss : 0.087746
[00:19:39.212] iteration 25770 : model1 loss : 0.161868 model2 loss : 0.251436
[00:19:39.538] iteration 25771 : model1 loss : 0.245633 model2 loss : 0.273018
[00:19:39.864] iteration 25772 : model1 loss : 0.212771 model2 loss : 0.234656
[00:19:40.191] iteration 25773 : model1 loss : 0.171412 model2 loss : 0.215896
[00:19:40.518] iteration 25774 : model1 loss : 0.119624 model2 loss : 0.151805
[00:19:40.845] iteration 25775 : model1 loss : 0.171140 model2 loss : 0.210750
[00:19:41.171] iteration 25776 : model1 loss : 0.152447 model2 loss : 0.230013
[00:19:41.498] iteration 25777 : model1 loss : 0.160040 model2 loss : 0.195320
[00:19:41.822] iteration 25778 : model1 loss : 0.253890 model2 loss : 0.280673
[00:19:42.150] iteration 25779 : model1 loss : 0.172047 model2 loss : 0.269297
[00:19:42.476] iteration 25780 : model1 loss : 0.218144 model2 loss : 0.277320
[00:19:42.803] iteration 25781 : model1 loss : 0.144233 model2 loss : 0.188102
[00:19:43.128] iteration 25782 : model1 loss : 0.302194 model2 loss : 0.335933
[00:19:43.454] iteration 25783 : model1 loss : 0.257010 model2 loss : 0.346668
[00:19:43.780] iteration 25784 : model1 loss : 0.087098 model2 loss : 0.110902
[00:19:44.106] iteration 25785 : model1 loss : 0.154779 model2 loss : 0.218814
[00:19:44.431] iteration 25786 : model1 loss : 0.294711 model2 loss : 0.275464
[00:19:44.756] iteration 25787 : model1 loss : 0.157017 model2 loss : 0.199833
[00:19:45.083] iteration 25788 : model1 loss : 0.343889 model2 loss : 0.378699
[00:19:45.410] iteration 25789 : model1 loss : 0.173707 model2 loss : 0.218624
[00:19:45.736] iteration 25790 : model1 loss : 0.095458 model2 loss : 0.127569
[00:19:46.062] iteration 25791 : model1 loss : 0.142858 model2 loss : 0.217884
[00:19:46.389] iteration 25792 : model1 loss : 0.188758 model2 loss : 0.250990
[00:19:46.714] iteration 25793 : model1 loss : 0.227278 model2 loss : 0.233062
[00:19:47.040] iteration 25794 : model1 loss : 0.433472 model2 loss : 0.438797
[00:19:47.365] iteration 25795 : model1 loss : 0.225895 model2 loss : 0.257912
[00:19:47.692] iteration 25796 : model1 loss : 0.177663 model2 loss : 0.193302
[00:19:48.018] iteration 25797 : model1 loss : 0.156496 model2 loss : 0.169454
[00:19:48.344] iteration 25798 : model1 loss : 0.150032 model2 loss : 0.206331
[00:19:48.670] iteration 25799 : model1 loss : 0.087252 model2 loss : 0.128803
[00:19:48.995] iteration 25800 : model1 loss : 0.163033 model2 loss : 0.195642
[00:19:49.526] iteration 25801 : model1 loss : 0.165365 model2 loss : 0.311838
[00:19:49.852] iteration 25802 : model1 loss : 0.194832 model2 loss : 0.252358
[00:19:50.178] iteration 25803 : model1 loss : 0.157553 model2 loss : 0.168106
[00:19:50.504] iteration 25804 : model1 loss : 0.284292 model2 loss : 0.281085
[00:19:50.830] iteration 25805 : model1 loss : 0.170876 model2 loss : 0.220778
[00:19:51.156] iteration 25806 : model1 loss : 0.271519 model2 loss : 0.282144
[00:19:51.483] iteration 25807 : model1 loss : 0.185263 model2 loss : 0.187791
[00:19:51.809] iteration 25808 : model1 loss : 0.173743 model2 loss : 0.180419
[00:19:52.135] iteration 25809 : model1 loss : 0.260667 model2 loss : 0.284782
[00:19:52.462] iteration 25810 : model1 loss : 0.171195 model2 loss : 0.205724
[00:19:52.787] iteration 25811 : model1 loss : 0.198822 model2 loss : 0.314258
[00:19:53.114] iteration 25812 : model1 loss : 0.253311 model2 loss : 0.257602
[00:19:53.441] iteration 25813 : model1 loss : 0.154551 model2 loss : 0.169680
[00:19:53.768] iteration 25814 : model1 loss : 0.235496 model2 loss : 0.206370
[00:19:54.095] iteration 25815 : model1 loss : 0.263809 model2 loss : 0.270573
[00:19:54.421] iteration 25816 : model1 loss : 0.248434 model2 loss : 0.272514
[00:19:54.747] iteration 25817 : model1 loss : 0.202904 model2 loss : 0.241180
[00:19:55.074] iteration 25818 : model1 loss : 0.174081 model2 loss : 0.178159
[00:19:55.401] iteration 25819 : model1 loss : 0.142706 model2 loss : 0.142426
[00:19:55.727] iteration 25820 : model1 loss : 0.265925 model2 loss : 0.287527
[00:19:56.054] iteration 25821 : model1 loss : 0.174067 model2 loss : 0.209469
[00:19:56.380] iteration 25822 : model1 loss : 0.090092 model2 loss : 0.091124
[00:19:56.706] iteration 25823 : model1 loss : 0.242689 model2 loss : 0.285244
[00:19:57.032] iteration 25824 : model1 loss : 0.181540 model2 loss : 0.181207
[00:19:57.358] iteration 25825 : model1 loss : 0.077052 model2 loss : 0.096313
[00:19:57.684] iteration 25826 : model1 loss : 0.235913 model2 loss : 0.252709
[00:19:58.010] iteration 25827 : model1 loss : 0.200928 model2 loss : 0.261218
[00:19:58.337] iteration 25828 : model1 loss : 0.154099 model2 loss : 0.193702
[00:19:58.663] iteration 25829 : model1 loss : 0.159141 model2 loss : 0.186114
[00:19:58.989] iteration 25830 : model1 loss : 0.181527 model2 loss : 0.193889
[00:19:59.315] iteration 25831 : model1 loss : 0.229295 model2 loss : 0.239448
[00:19:59.641] iteration 25832 : model1 loss : 0.078070 model2 loss : 0.079552
[00:19:59.967] iteration 25833 : model1 loss : 0.095271 model2 loss : 0.148370
[00:20:00.294] iteration 25834 : model1 loss : 0.151520 model2 loss : 0.180753
[00:20:00.620] iteration 25835 : model1 loss : 0.156068 model2 loss : 0.164684
[00:20:00.946] iteration 25836 : model1 loss : 0.169199 model2 loss : 0.187939
[00:20:01.272] iteration 25837 : model1 loss : 0.157273 model2 loss : 0.233419
[00:20:01.598] iteration 25838 : model1 loss : 0.093874 model2 loss : 0.112762
[00:20:01.925] iteration 25839 : model1 loss : 0.254920 model2 loss : 0.280211
[00:20:02.251] iteration 25840 : model1 loss : 0.178726 model2 loss : 0.208143
[00:20:02.578] iteration 25841 : model1 loss : 0.175928 model2 loss : 0.265225
[00:20:02.904] iteration 25842 : model1 loss : 0.175002 model2 loss : 0.221785
[00:20:03.230] iteration 25843 : model1 loss : 0.184220 model2 loss : 0.218844
[00:20:03.557] iteration 25844 : model1 loss : 0.180620 model2 loss : 0.219667
[00:20:03.884] iteration 25845 : model1 loss : 0.076166 model2 loss : 0.114239
[00:20:04.210] iteration 25846 : model1 loss : 0.218285 model2 loss : 0.234493
[00:20:04.536] iteration 25847 : model1 loss : 0.092503 model2 loss : 0.109806
[00:20:04.862] iteration 25848 : model1 loss : 0.091724 model2 loss : 0.211459
[00:20:05.188] iteration 25849 : model1 loss : 0.200456 model2 loss : 0.268749
[00:20:05.515] iteration 25850 : model1 loss : 0.217304 model2 loss : 0.227486
[00:20:06.066] iteration 25851 : model1 loss : 0.162243 model2 loss : 0.202732
[00:20:06.393] iteration 25852 : model1 loss : 0.100971 model2 loss : 0.100491
[00:20:06.720] iteration 25853 : model1 loss : 0.166918 model2 loss : 0.216403
[00:20:07.046] iteration 25854 : model1 loss : 0.174174 model2 loss : 0.193996
[00:20:07.371] iteration 25855 : model1 loss : 0.174626 model2 loss : 0.244499
[00:20:07.698] iteration 25856 : model1 loss : 0.152576 model2 loss : 0.175709
[00:20:08.023] iteration 25857 : model1 loss : 0.248286 model2 loss : 0.268762
[00:20:08.350] iteration 25858 : model1 loss : 0.182598 model2 loss : 0.251255
[00:20:08.676] iteration 25859 : model1 loss : 0.208192 model2 loss : 0.199802
[00:20:09.002] iteration 25860 : model1 loss : 0.189746 model2 loss : 0.188591
[00:20:09.328] iteration 25861 : model1 loss : 0.198120 model2 loss : 0.176266
[00:20:09.654] iteration 25862 : model1 loss : 0.253124 model2 loss : 0.268696
[00:20:09.979] iteration 25863 : model1 loss : 0.094737 model2 loss : 0.122662
[00:20:10.306] iteration 25864 : model1 loss : 0.225974 model2 loss : 0.231788
[00:20:10.632] iteration 25865 : model1 loss : 0.165213 model2 loss : 0.180609
[00:20:10.958] iteration 25866 : model1 loss : 0.159459 model2 loss : 0.196456
[00:20:11.284] iteration 25867 : model1 loss : 0.188575 model2 loss : 0.203221
[00:20:11.611] iteration 25868 : model1 loss : 0.190512 model2 loss : 0.277459
[00:20:11.937] iteration 25869 : model1 loss : 0.165420 model2 loss : 0.236808
[00:20:12.263] iteration 25870 : model1 loss : 0.240278 model2 loss : 0.240431
[00:20:12.590] iteration 25871 : model1 loss : 0.172574 model2 loss : 0.177406
[00:20:12.916] iteration 25872 : model1 loss : 0.073842 model2 loss : 0.129600
[00:20:13.242] iteration 25873 : model1 loss : 0.204238 model2 loss : 0.270999
[00:20:13.570] iteration 25874 : model1 loss : 0.184240 model2 loss : 0.217831
[00:20:13.897] iteration 25875 : model1 loss : 0.243528 model2 loss : 0.255757
[00:20:14.224] iteration 25876 : model1 loss : 0.264416 model2 loss : 0.285400
[00:20:14.551] iteration 25877 : model1 loss : 0.093230 model2 loss : 0.089295
[00:20:14.881] iteration 25878 : model1 loss : 0.170508 model2 loss : 0.202640
[00:20:15.207] iteration 25879 : model1 loss : 0.063558 model2 loss : 0.108117
[00:20:15.532] iteration 25880 : model1 loss : 0.181335 model2 loss : 0.190952
[00:20:15.859] iteration 25881 : model1 loss : 0.281120 model2 loss : 0.269087
[00:20:16.187] iteration 25882 : model1 loss : 0.131870 model2 loss : 0.213918
[00:20:16.515] iteration 25883 : model1 loss : 0.153785 model2 loss : 0.255636
[00:20:16.841] iteration 25884 : model1 loss : 0.237423 model2 loss : 0.248173
[00:20:17.170] iteration 25885 : model1 loss : 0.182749 model2 loss : 0.335529
[00:20:17.499] iteration 25886 : model1 loss : 0.116801 model2 loss : 0.159084
[00:20:17.824] iteration 25887 : model1 loss : 0.157386 model2 loss : 0.171539
[00:20:18.150] iteration 25888 : model1 loss : 0.107593 model2 loss : 0.135078
[00:20:18.478] iteration 25889 : model1 loss : 0.228842 model2 loss : 0.249714
[00:20:18.804] iteration 25890 : model1 loss : 0.185218 model2 loss : 0.212288
[00:20:19.130] iteration 25891 : model1 loss : 0.084047 model2 loss : 0.109110
[00:20:19.455] iteration 25892 : model1 loss : 0.063021 model2 loss : 0.087488
[00:20:19.780] iteration 25893 : model1 loss : 0.103477 model2 loss : 0.181072
[00:20:20.106] iteration 25894 : model1 loss : 0.247640 model2 loss : 0.260602
[00:20:20.433] iteration 25895 : model1 loss : 0.323092 model2 loss : 0.325856
[00:20:20.759] iteration 25896 : model1 loss : 0.155314 model2 loss : 0.203543
[00:20:21.085] iteration 25897 : model1 loss : 0.152576 model2 loss : 0.171214
[00:20:21.532] iteration 25898 : model1 loss : 0.171420 model2 loss : 0.197767
[00:20:21.857] iteration 25899 : model1 loss : 0.184932 model2 loss : 0.233712
[00:20:22.183] iteration 25900 : model1 loss : 0.164754 model2 loss : 0.177732
[00:20:22.704] iteration 25901 : model1 loss : 0.111732 model2 loss : 0.176626
[00:20:23.030] iteration 25902 : model1 loss : 0.161914 model2 loss : 0.194613
[00:20:23.356] iteration 25903 : model1 loss : 0.092208 model2 loss : 0.137205
[00:20:23.682] iteration 25904 : model1 loss : 0.247320 model2 loss : 0.260355
[00:20:24.008] iteration 25905 : model1 loss : 0.178188 model2 loss : 0.219483
[00:20:24.334] iteration 25906 : model1 loss : 0.086184 model2 loss : 0.123896
[00:20:24.660] iteration 25907 : model1 loss : 0.195420 model2 loss : 0.211225
[00:20:24.986] iteration 25908 : model1 loss : 0.255809 model2 loss : 0.269370
[00:20:25.313] iteration 25909 : model1 loss : 0.232206 model2 loss : 0.242372
[00:20:25.639] iteration 25910 : model1 loss : 0.094589 model2 loss : 0.247787
[00:20:25.965] iteration 25911 : model1 loss : 0.247452 model2 loss : 0.255974
[00:20:26.292] iteration 25912 : model1 loss : 0.160995 model2 loss : 0.190230
[00:20:26.619] iteration 25913 : model1 loss : 0.207337 model2 loss : 0.241627
[00:20:26.945] iteration 25914 : model1 loss : 0.168649 model2 loss : 0.210909
[00:20:27.270] iteration 25915 : model1 loss : 0.167689 model2 loss : 0.232605
[00:20:27.597] iteration 25916 : model1 loss : 0.116422 model2 loss : 0.120738
[00:20:27.923] iteration 25917 : model1 loss : 0.169354 model2 loss : 0.165776
[00:20:28.250] iteration 25918 : model1 loss : 0.186489 model2 loss : 0.236853
[00:20:28.576] iteration 25919 : model1 loss : 0.146428 model2 loss : 0.214330
[00:20:28.903] iteration 25920 : model1 loss : 0.134489 model2 loss : 0.140160
[00:20:29.229] iteration 25921 : model1 loss : 0.185254 model2 loss : 0.219294
[00:20:29.555] iteration 25922 : model1 loss : 0.235013 model2 loss : 0.235616
[00:20:29.881] iteration 25923 : model1 loss : 0.164610 model2 loss : 0.210149
[00:20:30.206] iteration 25924 : model1 loss : 0.240357 model2 loss : 0.261756
[00:20:30.532] iteration 25925 : model1 loss : 0.227304 model2 loss : 0.273966
[00:20:30.858] iteration 25926 : model1 loss : 0.277042 model2 loss : 0.285266
[00:20:31.184] iteration 25927 : model1 loss : 0.094301 model2 loss : 0.107175
[00:20:31.511] iteration 25928 : model1 loss : 0.119832 model2 loss : 0.209934
[00:20:31.837] iteration 25929 : model1 loss : 0.151529 model2 loss : 0.174809
[00:20:32.164] iteration 25930 : model1 loss : 0.260048 model2 loss : 0.259154
[00:20:32.490] iteration 25931 : model1 loss : 0.235913 model2 loss : 0.242777
[00:20:32.815] iteration 25932 : model1 loss : 0.188420 model2 loss : 0.223587
[00:20:33.142] iteration 25933 : model1 loss : 0.190817 model2 loss : 0.246108
[00:20:33.468] iteration 25934 : model1 loss : 0.100735 model2 loss : 0.145930
[00:20:33.795] iteration 25935 : model1 loss : 0.109270 model2 loss : 0.139167
[00:20:34.121] iteration 25936 : model1 loss : 0.179711 model2 loss : 0.180357
[00:20:34.446] iteration 25937 : model1 loss : 0.246882 model2 loss : 0.259558
[00:20:34.771] iteration 25938 : model1 loss : 0.167538 model2 loss : 0.152389
[00:20:35.097] iteration 25939 : model1 loss : 0.254508 model2 loss : 0.267733
[00:20:35.424] iteration 25940 : model1 loss : 0.195210 model2 loss : 0.246088
[00:20:35.750] iteration 25941 : model1 loss : 0.209883 model2 loss : 0.184932
[00:20:36.076] iteration 25942 : model1 loss : 0.162242 model2 loss : 0.188961
[00:20:36.402] iteration 25943 : model1 loss : 0.217682 model2 loss : 0.225951
[00:20:36.729] iteration 25944 : model1 loss : 0.177817 model2 loss : 0.202006
[00:20:37.055] iteration 25945 : model1 loss : 0.149686 model2 loss : 0.189693
[00:20:37.382] iteration 25946 : model1 loss : 0.326524 model2 loss : 0.332854
[00:20:37.707] iteration 25947 : model1 loss : 0.255671 model2 loss : 0.307576
[00:20:38.033] iteration 25948 : model1 loss : 0.178904 model2 loss : 0.253896
[00:20:38.361] iteration 25949 : model1 loss : 0.229740 model2 loss : 0.227632
[00:20:38.687] iteration 25950 : model1 loss : 0.239087 model2 loss : 0.249655
[00:20:39.194] iteration 25951 : model1 loss : 0.281600 model2 loss : 0.282660
[00:20:39.520] iteration 25952 : model1 loss : 0.165923 model2 loss : 0.168388
[00:20:39.846] iteration 25953 : model1 loss : 0.247945 model2 loss : 0.269511
[00:20:40.173] iteration 25954 : model1 loss : 0.177969 model2 loss : 0.211978
[00:20:40.500] iteration 25955 : model1 loss : 0.225141 model2 loss : 0.236524
[00:20:40.826] iteration 25956 : model1 loss : 0.252788 model2 loss : 0.280263
[00:20:41.152] iteration 25957 : model1 loss : 0.268507 model2 loss : 0.271135
[00:20:41.480] iteration 25958 : model1 loss : 0.263470 model2 loss : 0.259260
[00:20:41.806] iteration 25959 : model1 loss : 0.112119 model2 loss : 0.119866
[00:20:42.134] iteration 25960 : model1 loss : 0.160061 model2 loss : 0.192570
[00:20:42.461] iteration 25961 : model1 loss : 0.242857 model2 loss : 0.256823
[00:20:42.787] iteration 25962 : model1 loss : 0.171862 model2 loss : 0.224218
[00:20:43.114] iteration 25963 : model1 loss : 0.163013 model2 loss : 0.213374
[00:20:43.441] iteration 25964 : model1 loss : 0.192680 model2 loss : 0.216580
[00:20:43.768] iteration 25965 : model1 loss : 0.207342 model2 loss : 0.211434
[00:20:44.094] iteration 25966 : model1 loss : 0.173666 model2 loss : 0.231197
[00:20:44.422] iteration 25967 : model1 loss : 0.201185 model2 loss : 0.229591
[00:20:44.748] iteration 25968 : model1 loss : 0.252753 model2 loss : 0.265626
[00:20:45.074] iteration 25969 : model1 loss : 0.090143 model2 loss : 0.121682
[00:20:45.401] iteration 25970 : model1 loss : 0.235967 model2 loss : 0.271519
[00:20:45.726] iteration 25971 : model1 loss : 0.104911 model2 loss : 0.183064
[00:20:46.052] iteration 25972 : model1 loss : 0.156505 model2 loss : 0.138896
[00:20:46.379] iteration 25973 : model1 loss : 0.167865 model2 loss : 0.152777
[00:20:46.706] iteration 25974 : model1 loss : 0.102197 model2 loss : 0.139108
[00:20:47.032] iteration 25975 : model1 loss : 0.200908 model2 loss : 0.233312
[00:20:47.358] iteration 25976 : model1 loss : 0.081577 model2 loss : 0.138409
[00:20:47.685] iteration 25977 : model1 loss : 0.093042 model2 loss : 0.104195
[00:20:48.010] iteration 25978 : model1 loss : 0.098674 model2 loss : 0.128694
[00:20:48.336] iteration 25979 : model1 loss : 0.100802 model2 loss : 0.113996
[00:20:48.662] iteration 25980 : model1 loss : 0.153752 model2 loss : 0.194678
[00:20:48.988] iteration 25981 : model1 loss : 0.110098 model2 loss : 0.151638
[00:20:49.316] iteration 25982 : model1 loss : 0.181953 model2 loss : 0.227868
[00:20:49.642] iteration 25983 : model1 loss : 0.239112 model2 loss : 0.240535
[00:20:49.968] iteration 25984 : model1 loss : 0.268528 model2 loss : 0.312477
[00:20:50.294] iteration 25985 : model1 loss : 0.157441 model2 loss : 0.193951
[00:20:50.620] iteration 25986 : model1 loss : 0.235971 model2 loss : 0.249781
[00:20:50.947] iteration 25987 : model1 loss : 0.104129 model2 loss : 0.152976
[00:20:51.274] iteration 25988 : model1 loss : 0.255575 model2 loss : 0.283433
[00:20:51.599] iteration 25989 : model1 loss : 0.187801 model2 loss : 0.224203
[00:20:51.926] iteration 25990 : model1 loss : 0.240609 model2 loss : 0.247283
[00:20:52.253] iteration 25991 : model1 loss : 0.201502 model2 loss : 0.246955
[00:20:52.579] iteration 25992 : model1 loss : 0.274435 model2 loss : 0.291469
[00:20:52.905] iteration 25993 : model1 loss : 0.240942 model2 loss : 0.258383
[00:20:53.231] iteration 25994 : model1 loss : 0.229684 model2 loss : 0.242112
[00:20:53.558] iteration 25995 : model1 loss : 0.184544 model2 loss : 0.233307
[00:20:53.883] iteration 25996 : model1 loss : 0.184122 model2 loss : 0.225842
[00:20:54.210] iteration 25997 : model1 loss : 0.258569 model2 loss : 0.231373
[00:20:54.536] iteration 25998 : model1 loss : 0.207292 model2 loss : 0.209809
[00:20:54.862] iteration 25999 : model1 loss : 0.203147 model2 loss : 0.217727
[00:20:55.189] iteration 26000 : model1 loss : 0.181480 model2 loss : 0.205856
[00:20:55.733] iteration 26001 : model1 loss : 0.100892 model2 loss : 0.124322
[00:20:56.059] iteration 26002 : model1 loss : 0.157519 model2 loss : 0.202547
[00:20:56.385] iteration 26003 : model1 loss : 0.185677 model2 loss : 0.256125
[00:20:56.710] iteration 26004 : model1 loss : 0.083149 model2 loss : 0.086843
[00:20:57.037] iteration 26005 : model1 loss : 0.236293 model2 loss : 0.311747
[00:20:57.363] iteration 26006 : model1 loss : 0.315938 model2 loss : 0.320014
[00:20:57.690] iteration 26007 : model1 loss : 0.173123 model2 loss : 0.196975
[00:20:58.016] iteration 26008 : model1 loss : 0.073759 model2 loss : 0.124649
[00:20:58.342] iteration 26009 : model1 loss : 0.241153 model2 loss : 0.253685
[00:20:58.667] iteration 26010 : model1 loss : 0.225585 model2 loss : 0.244595
[00:20:58.994] iteration 26011 : model1 loss : 0.168417 model2 loss : 0.239878
[00:20:59.320] iteration 26012 : model1 loss : 0.115274 model2 loss : 0.134981
[00:20:59.647] iteration 26013 : model1 loss : 0.186298 model2 loss : 0.218538
[00:20:59.973] iteration 26014 : model1 loss : 0.156077 model2 loss : 0.257231
[00:21:00.300] iteration 26015 : model1 loss : 0.269241 model2 loss : 0.317736
[00:21:00.626] iteration 26016 : model1 loss : 0.097977 model2 loss : 0.116942
[00:21:00.953] iteration 26017 : model1 loss : 0.181790 model2 loss : 0.198145
[00:21:01.279] iteration 26018 : model1 loss : 0.092920 model2 loss : 0.175921
[00:21:01.606] iteration 26019 : model1 loss : 0.241092 model2 loss : 0.308042
[00:21:01.933] iteration 26020 : model1 loss : 0.066542 model2 loss : 0.072575
[00:21:02.260] iteration 26021 : model1 loss : 0.233084 model2 loss : 0.271044
[00:21:02.589] iteration 26022 : model1 loss : 0.304630 model2 loss : 0.320941
[00:21:02.927] iteration 26023 : model1 loss : 0.156990 model2 loss : 0.192156
[00:21:03.268] iteration 26024 : model1 loss : 0.177991 model2 loss : 0.231456
[00:21:03.606] iteration 26025 : model1 loss : 0.163029 model2 loss : 0.206912
[00:21:03.943] iteration 26026 : model1 loss : 0.173039 model2 loss : 0.206574
[00:21:04.281] iteration 26027 : model1 loss : 0.072509 model2 loss : 0.112567
[00:21:04.619] iteration 26028 : model1 loss : 0.173233 model2 loss : 0.171945
[00:21:04.961] iteration 26029 : model1 loss : 0.254620 model2 loss : 0.268523
[00:21:05.303] iteration 26030 : model1 loss : 0.173723 model2 loss : 0.214762
[00:21:05.641] iteration 26031 : model1 loss : 0.255996 model2 loss : 0.271409
[00:21:05.980] iteration 26032 : model1 loss : 0.161396 model2 loss : 0.234186
[00:21:06.317] iteration 26033 : model1 loss : 0.168850 model2 loss : 0.232940
[00:21:06.657] iteration 26034 : model1 loss : 0.315983 model2 loss : 0.325628
[00:21:06.987] iteration 26035 : model1 loss : 0.238622 model2 loss : 0.262255
[00:21:07.318] iteration 26036 : model1 loss : 0.192601 model2 loss : 0.207705
[00:21:07.647] iteration 26037 : model1 loss : 0.172799 model2 loss : 0.186066
[00:21:07.976] iteration 26038 : model1 loss : 0.087542 model2 loss : 0.129640
[00:21:08.305] iteration 26039 : model1 loss : 0.295513 model2 loss : 0.351491
[00:21:08.636] iteration 26040 : model1 loss : 0.158183 model2 loss : 0.201485
[00:21:08.966] iteration 26041 : model1 loss : 0.251181 model2 loss : 0.262095
[00:21:09.294] iteration 26042 : model1 loss : 0.192145 model2 loss : 0.231677
[00:21:09.626] iteration 26043 : model1 loss : 0.291899 model2 loss : 0.303969
[00:21:09.954] iteration 26044 : model1 loss : 0.099390 model2 loss : 0.144780
[00:21:10.285] iteration 26045 : model1 loss : 0.107133 model2 loss : 0.218679
[00:21:10.614] iteration 26046 : model1 loss : 0.180886 model2 loss : 0.246390
[00:21:10.946] iteration 26047 : model1 loss : 0.193538 model2 loss : 0.245725
[00:21:11.275] iteration 26048 : model1 loss : 0.323049 model2 loss : 0.337484
[00:21:11.604] iteration 26049 : model1 loss : 0.239805 model2 loss : 0.278204
[00:21:11.935] iteration 26050 : model1 loss : 0.191272 model2 loss : 0.229700
[00:21:12.485] iteration 26051 : model1 loss : 0.179386 model2 loss : 0.190093
[00:21:12.814] iteration 26052 : model1 loss : 0.207858 model2 loss : 0.203113
[00:21:13.144] iteration 26053 : model1 loss : 0.177497 model2 loss : 0.205763
[00:21:13.473] iteration 26054 : model1 loss : 0.078588 model2 loss : 0.087345
[00:21:13.802] iteration 26055 : model1 loss : 0.103781 model2 loss : 0.133599
[00:21:14.133] iteration 26056 : model1 loss : 0.248380 model2 loss : 0.310141
[00:21:14.463] iteration 26057 : model1 loss : 0.081246 model2 loss : 0.104308
[00:21:14.792] iteration 26058 : model1 loss : 0.102408 model2 loss : 0.123921
[00:21:15.121] iteration 26059 : model1 loss : 0.246221 model2 loss : 0.272841
[00:21:15.453] iteration 26060 : model1 loss : 0.115864 model2 loss : 0.115778
[00:21:15.792] iteration 26061 : model1 loss : 0.093318 model2 loss : 0.148990
[00:21:16.129] iteration 26062 : model1 loss : 0.227286 model2 loss : 0.237390
[00:21:16.466] iteration 26063 : model1 loss : 0.167650 model2 loss : 0.186043
[00:21:16.802] iteration 26064 : model1 loss : 0.098220 model2 loss : 0.195301
[00:21:17.139] iteration 26065 : model1 loss : 0.261129 model2 loss : 0.259551
[00:21:17.477] iteration 26066 : model1 loss : 0.229328 model2 loss : 0.245651
[00:21:17.816] iteration 26067 : model1 loss : 0.152136 model2 loss : 0.185966
[00:21:18.153] iteration 26068 : model1 loss : 0.201142 model2 loss : 0.273354
[00:21:18.490] iteration 26069 : model1 loss : 0.231858 model2 loss : 0.307095
[00:21:18.828] iteration 26070 : model1 loss : 0.163947 model2 loss : 0.185299
[00:21:19.166] iteration 26071 : model1 loss : 0.283439 model2 loss : 0.286632
[00:21:19.503] iteration 26072 : model1 loss : 0.188514 model2 loss : 0.245480
[00:21:19.841] iteration 26073 : model1 loss : 0.223633 model2 loss : 0.254806
[00:21:20.179] iteration 26074 : model1 loss : 0.115780 model2 loss : 0.130180
[00:21:20.517] iteration 26075 : model1 loss : 0.171708 model2 loss : 0.200907
[00:21:20.856] iteration 26076 : model1 loss : 0.173186 model2 loss : 0.189228
[00:21:21.198] iteration 26077 : model1 loss : 0.248734 model2 loss : 0.243670
[00:21:21.534] iteration 26078 : model1 loss : 0.099070 model2 loss : 0.112522
[00:21:21.873] iteration 26079 : model1 loss : 0.175995 model2 loss : 0.232860
[00:21:22.213] iteration 26080 : model1 loss : 0.218221 model2 loss : 0.277658
[00:21:22.550] iteration 26081 : model1 loss : 0.074218 model2 loss : 0.099282
[00:21:22.891] iteration 26082 : model1 loss : 0.129587 model2 loss : 0.102337
[00:21:23.231] iteration 26083 : model1 loss : 0.091879 model2 loss : 0.119771
[00:21:23.568] iteration 26084 : model1 loss : 0.250417 model2 loss : 0.278017
[00:21:23.905] iteration 26085 : model1 loss : 0.169113 model2 loss : 0.282305
[00:21:24.242] iteration 26086 : model1 loss : 0.170050 model2 loss : 0.207956
[00:21:24.579] iteration 26087 : model1 loss : 0.181309 model2 loss : 0.193641
[00:21:24.917] iteration 26088 : model1 loss : 0.263622 model2 loss : 0.279179
[00:21:25.255] iteration 26089 : model1 loss : 0.258090 model2 loss : 0.257656
[00:21:25.595] iteration 26090 : model1 loss : 0.062911 model2 loss : 0.097304
[00:21:25.933] iteration 26091 : model1 loss : 0.168623 model2 loss : 0.224310
[00:21:26.275] iteration 26092 : model1 loss : 0.177306 model2 loss : 0.188528
[00:21:26.612] iteration 26093 : model1 loss : 0.189656 model2 loss : 0.184406
[00:21:26.955] iteration 26094 : model1 loss : 0.176623 model2 loss : 0.184760
[00:21:27.293] iteration 26095 : model1 loss : 0.201531 model2 loss : 0.242441
[00:21:27.634] iteration 26096 : model1 loss : 0.161670 model2 loss : 0.180691
[00:21:27.972] iteration 26097 : model1 loss : 0.256471 model2 loss : 0.288383
[00:21:28.313] iteration 26098 : model1 loss : 0.236162 model2 loss : 0.256180
[00:21:28.651] iteration 26099 : model1 loss : 0.188533 model2 loss : 0.211469
[00:21:28.989] iteration 26100 : model1 loss : 0.315475 model2 loss : 0.317988
[00:21:29.579] iteration 26101 : model1 loss : 0.202023 model2 loss : 0.188429
[00:21:29.909] iteration 26102 : model1 loss : 0.261882 model2 loss : 0.286049
[00:21:30.239] iteration 26103 : model1 loss : 0.262367 model2 loss : 0.321647
[00:21:30.570] iteration 26104 : model1 loss : 0.168421 model2 loss : 0.184647
[00:21:30.900] iteration 26105 : model1 loss : 0.080416 model2 loss : 0.175325
[00:21:31.229] iteration 26106 : model1 loss : 0.165310 model2 loss : 0.209377
[00:21:31.560] iteration 26107 : model1 loss : 0.247347 model2 loss : 0.254199
[00:21:31.889] iteration 26108 : model1 loss : 0.163172 model2 loss : 0.184564
[00:21:32.219] iteration 26109 : model1 loss : 0.202939 model2 loss : 0.195702
[00:21:32.553] iteration 26110 : model1 loss : 0.255697 model2 loss : 0.299021
[00:21:32.881] iteration 26111 : model1 loss : 0.136769 model2 loss : 0.167704
[00:21:33.210] iteration 26112 : model1 loss : 0.100077 model2 loss : 0.134922
[00:21:33.538] iteration 26113 : model1 loss : 0.242270 model2 loss : 0.272658
[00:21:33.866] iteration 26114 : model1 loss : 0.269815 model2 loss : 0.273200
[00:21:34.195] iteration 26115 : model1 loss : 0.248978 model2 loss : 0.268783
[00:21:34.525] iteration 26116 : model1 loss : 0.172460 model2 loss : 0.225962
[00:21:34.856] iteration 26117 : model1 loss : 0.093836 model2 loss : 0.164646
[00:21:35.185] iteration 26118 : model1 loss : 0.167036 model2 loss : 0.194547
[00:21:35.515] iteration 26119 : model1 loss : 0.258630 model2 loss : 0.277097
[00:21:35.847] iteration 26120 : model1 loss : 0.200902 model2 loss : 0.239348
[00:21:36.176] iteration 26121 : model1 loss : 0.254161 model2 loss : 0.255269
[00:21:36.505] iteration 26122 : model1 loss : 0.166593 model2 loss : 0.198945
[00:21:36.836] iteration 26123 : model1 loss : 0.103125 model2 loss : 0.165481
[00:21:37.164] iteration 26124 : model1 loss : 0.181082 model2 loss : 0.216464
[00:21:37.491] iteration 26125 : model1 loss : 0.183765 model2 loss : 0.188473
[00:21:37.821] iteration 26126 : model1 loss : 0.140228 model2 loss : 0.257757
[00:21:38.151] iteration 26127 : model1 loss : 0.086866 model2 loss : 0.125041
[00:21:38.480] iteration 26128 : model1 loss : 0.252215 model2 loss : 0.269305
[00:21:38.810] iteration 26129 : model1 loss : 0.258718 model2 loss : 0.268166
[00:21:39.138] iteration 26130 : model1 loss : 0.112425 model2 loss : 0.186326
[00:21:39.467] iteration 26131 : model1 loss : 0.077402 model2 loss : 0.084657
[00:21:39.795] iteration 26132 : model1 loss : 0.179774 model2 loss : 0.240404
[00:21:40.124] iteration 26133 : model1 loss : 0.178160 model2 loss : 0.195351
[00:21:40.455] iteration 26134 : model1 loss : 0.224452 model2 loss : 0.285176
[00:21:40.785] iteration 26135 : model1 loss : 0.173747 model2 loss : 0.187139
[00:21:41.114] iteration 26136 : model1 loss : 0.268789 model2 loss : 0.324086
[00:21:41.442] iteration 26137 : model1 loss : 0.253699 model2 loss : 0.251910
[00:21:41.774] iteration 26138 : model1 loss : 0.174463 model2 loss : 0.235622
[00:21:42.102] iteration 26139 : model1 loss : 0.180557 model2 loss : 0.202056
[00:21:42.431] iteration 26140 : model1 loss : 0.098540 model2 loss : 0.148303
[00:21:42.761] iteration 26141 : model1 loss : 0.096317 model2 loss : 0.127901
[00:21:43.097] iteration 26142 : model1 loss : 0.239027 model2 loss : 0.263039
[00:21:43.428] iteration 26143 : model1 loss : 0.083939 model2 loss : 0.152508
[00:21:43.757] iteration 26144 : model1 loss : 0.246568 model2 loss : 0.278130
[00:21:44.085] iteration 26145 : model1 loss : 0.164844 model2 loss : 0.165728
[00:21:44.414] iteration 26146 : model1 loss : 0.191951 model2 loss : 0.222171
[00:21:44.742] iteration 26147 : model1 loss : 0.190188 model2 loss : 0.248296
[00:21:45.071] iteration 26148 : model1 loss : 0.268248 model2 loss : 0.282208
[00:21:45.408] iteration 26149 : model1 loss : 0.118061 model2 loss : 0.214213
[00:21:45.737] iteration 26150 : model1 loss : 0.113726 model2 loss : 0.190916
[00:21:46.274] iteration 26151 : model1 loss : 0.267209 model2 loss : 0.277112
[00:21:46.605] iteration 26152 : model1 loss : 0.178502 model2 loss : 0.168192
[00:21:46.933] iteration 26153 : model1 loss : 0.266326 model2 loss : 0.300075
[00:21:47.261] iteration 26154 : model1 loss : 0.230010 model2 loss : 0.240052
[00:21:47.590] iteration 26155 : model1 loss : 0.158980 model2 loss : 0.161211
[00:21:47.918] iteration 26156 : model1 loss : 0.246932 model2 loss : 0.268745
[00:21:48.246] iteration 26157 : model1 loss : 0.142085 model2 loss : 0.178899
[00:21:48.574] iteration 26158 : model1 loss : 0.253267 model2 loss : 0.297049
[00:21:48.902] iteration 26159 : model1 loss : 0.246304 model2 loss : 0.275357
[00:21:49.231] iteration 26160 : model1 loss : 0.104927 model2 loss : 0.129652
[00:21:50.318] iteration 26161 : model1 loss : 0.212940 model2 loss : 0.225302
[00:21:50.657] iteration 26162 : model1 loss : 0.264351 model2 loss : 0.303628
[00:21:51.002] iteration 26163 : model1 loss : 0.144306 model2 loss : 0.201362
[00:21:51.344] iteration 26164 : model1 loss : 0.165250 model2 loss : 0.194366
[00:21:51.682] iteration 26165 : model1 loss : 0.171266 model2 loss : 0.161679
[00:21:52.020] iteration 26166 : model1 loss : 0.243520 model2 loss : 0.263460
[00:21:52.358] iteration 26167 : model1 loss : 0.189394 model2 loss : 0.213158
[00:21:52.696] iteration 26168 : model1 loss : 0.178319 model2 loss : 0.214104
[00:21:53.039] iteration 26169 : model1 loss : 0.203694 model2 loss : 0.253709
[00:21:53.383] iteration 26170 : model1 loss : 0.087711 model2 loss : 0.083808
[00:21:53.720] iteration 26171 : model1 loss : 0.110545 model2 loss : 0.170108
[00:21:54.057] iteration 26172 : model1 loss : 0.152409 model2 loss : 0.179391
[00:21:54.395] iteration 26173 : model1 loss : 0.112020 model2 loss : 0.127935
[00:21:54.732] iteration 26174 : model1 loss : 0.061658 model2 loss : 0.085928
[00:21:55.069] iteration 26175 : model1 loss : 0.228428 model2 loss : 0.254002
[00:21:55.411] iteration 26176 : model1 loss : 0.094678 model2 loss : 0.157661
[00:21:55.751] iteration 26177 : model1 loss : 0.172478 model2 loss : 0.183063
[00:21:56.097] iteration 26178 : model1 loss : 0.062931 model2 loss : 0.090263
[00:21:56.434] iteration 26179 : model1 loss : 0.255617 model2 loss : 0.294295
[00:21:56.772] iteration 26180 : model1 loss : 0.190810 model2 loss : 0.232199
[00:21:57.110] iteration 26181 : model1 loss : 0.170325 model2 loss : 0.169676
[00:21:57.447] iteration 26182 : model1 loss : 0.206469 model2 loss : 0.187800
[00:21:57.786] iteration 26183 : model1 loss : 0.245358 model2 loss : 0.265270
[00:21:58.123] iteration 26184 : model1 loss : 0.179035 model2 loss : 0.204889
[00:21:58.460] iteration 26185 : model1 loss : 0.224293 model2 loss : 0.227625
[00:21:58.804] iteration 26186 : model1 loss : 0.168692 model2 loss : 0.212415
[00:21:59.147] iteration 26187 : model1 loss : 0.086164 model2 loss : 0.138459
[00:21:59.484] iteration 26188 : model1 loss : 0.231871 model2 loss : 0.268620
[00:21:59.821] iteration 26189 : model1 loss : 0.066889 model2 loss : 0.070253
[00:22:00.162] iteration 26190 : model1 loss : 0.167891 model2 loss : 0.242936
[00:22:00.500] iteration 26191 : model1 loss : 0.067080 model2 loss : 0.170722
[00:22:00.837] iteration 26192 : model1 loss : 0.188909 model2 loss : 0.203803
[00:22:01.175] iteration 26193 : model1 loss : 0.115810 model2 loss : 0.200514
[00:22:01.512] iteration 26194 : model1 loss : 0.202154 model2 loss : 0.273358
[00:22:01.850] iteration 26195 : model1 loss : 0.170527 model2 loss : 0.202366
[00:22:02.186] iteration 26196 : model1 loss : 0.322073 model2 loss : 0.338087
[00:22:02.526] iteration 26197 : model1 loss : 0.168285 model2 loss : 0.209408
[00:22:02.866] iteration 26198 : model1 loss : 0.259097 model2 loss : 0.293821
[00:22:03.204] iteration 26199 : model1 loss : 0.184924 model2 loss : 0.198778
[00:22:03.541] iteration 26200 : model1 loss : 0.252107 model2 loss : 0.273646
[00:22:04.192] iteration 26201 : model1 loss : 0.250289 model2 loss : 0.290461
[00:22:04.530] iteration 26202 : model1 loss : 0.163922 model2 loss : 0.191541
[00:22:04.867] iteration 26203 : model1 loss : 0.124284 model2 loss : 0.147878
[00:22:05.205] iteration 26204 : model1 loss : 0.075652 model2 loss : 0.095076
[00:22:05.541] iteration 26205 : model1 loss : 0.138263 model2 loss : 0.225005
[00:22:05.880] iteration 26206 : model1 loss : 0.068644 model2 loss : 0.078374
[00:22:06.219] iteration 26207 : model1 loss : 0.078633 model2 loss : 0.152996
[00:22:06.556] iteration 26208 : model1 loss : 0.285245 model2 loss : 0.245092
[00:22:06.896] iteration 26209 : model1 loss : 0.191337 model2 loss : 0.191887
[00:22:07.237] iteration 26210 : model1 loss : 0.118815 model2 loss : 0.152127
[00:22:07.574] iteration 26211 : model1 loss : 0.234232 model2 loss : 0.240059
[00:22:07.913] iteration 26212 : model1 loss : 0.116399 model2 loss : 0.177267
[00:22:08.250] iteration 26213 : model1 loss : 0.094604 model2 loss : 0.140742
[00:22:08.593] iteration 26214 : model1 loss : 0.262852 model2 loss : 0.304153
[00:22:08.931] iteration 26215 : model1 loss : 0.188085 model2 loss : 0.196197
[00:22:09.268] iteration 26216 : model1 loss : 0.236052 model2 loss : 0.265707
[00:22:09.610] iteration 26217 : model1 loss : 0.161066 model2 loss : 0.190482
[00:22:09.947] iteration 26218 : model1 loss : 0.237345 model2 loss : 0.241365
[00:22:10.284] iteration 26219 : model1 loss : 0.197794 model2 loss : 0.210534
[00:22:10.621] iteration 26220 : model1 loss : 0.169692 model2 loss : 0.187535
[00:22:10.958] iteration 26221 : model1 loss : 0.193909 model2 loss : 0.262080
[00:22:11.301] iteration 26222 : model1 loss : 0.174518 model2 loss : 0.202369
[00:22:11.640] iteration 26223 : model1 loss : 0.165632 model2 loss : 0.178171
[00:22:11.978] iteration 26224 : model1 loss : 0.190426 model2 loss : 0.192649
[00:22:12.320] iteration 26225 : model1 loss : 0.078047 model2 loss : 0.144819
[00:22:12.658] iteration 26226 : model1 loss : 0.312918 model2 loss : 0.361097
[00:22:12.998] iteration 26227 : model1 loss : 0.093305 model2 loss : 0.129368
[00:22:13.336] iteration 26228 : model1 loss : 0.177493 model2 loss : 0.232945
[00:22:13.674] iteration 26229 : model1 loss : 0.206226 model2 loss : 0.246667
[00:22:14.012] iteration 26230 : model1 loss : 0.248825 model2 loss : 0.287291
[00:22:14.351] iteration 26231 : model1 loss : 0.233147 model2 loss : 0.275085
[00:22:14.695] iteration 26232 : model1 loss : 0.243168 model2 loss : 0.263192
[00:22:15.034] iteration 26233 : model1 loss : 0.204851 model2 loss : 0.215993
[00:22:15.373] iteration 26234 : model1 loss : 0.262488 model2 loss : 0.286851
[00:22:15.711] iteration 26235 : model1 loss : 0.187684 model2 loss : 0.218277
[00:22:16.049] iteration 26236 : model1 loss : 0.176675 model2 loss : 0.237376
[00:22:16.390] iteration 26237 : model1 loss : 0.210232 model2 loss : 0.218888
[00:22:16.728] iteration 26238 : model1 loss : 0.221830 model2 loss : 0.297458
[00:22:17.068] iteration 26239 : model1 loss : 0.163264 model2 loss : 0.185555
[00:22:17.404] iteration 26240 : model1 loss : 0.183489 model2 loss : 0.195000
[00:22:17.741] iteration 26241 : model1 loss : 0.157415 model2 loss : 0.170545
[00:22:18.078] iteration 26242 : model1 loss : 0.171372 model2 loss : 0.186814
[00:22:18.417] iteration 26243 : model1 loss : 0.177893 model2 loss : 0.206049
[00:22:18.753] iteration 26244 : model1 loss : 0.179555 model2 loss : 0.225306
[00:22:19.090] iteration 26245 : model1 loss : 0.183819 model2 loss : 0.189871
[00:22:19.429] iteration 26246 : model1 loss : 0.170064 model2 loss : 0.173737
[00:22:19.768] iteration 26247 : model1 loss : 0.261650 model2 loss : 0.365365
[00:22:20.108] iteration 26248 : model1 loss : 0.180342 model2 loss : 0.218337
[00:22:20.450] iteration 26249 : model1 loss : 0.155660 model2 loss : 0.183258
[00:22:20.786] iteration 26250 : model1 loss : 0.266821 model2 loss : 0.294330
[00:22:21.450] iteration 26251 : model1 loss : 0.089964 model2 loss : 0.123679
[00:22:21.787] iteration 26252 : model1 loss : 0.183951 model2 loss : 0.237166
[00:22:22.130] iteration 26253 : model1 loss : 0.169642 model2 loss : 0.206394
[00:22:22.468] iteration 26254 : model1 loss : 0.191270 model2 loss : 0.220765
[00:22:22.806] iteration 26255 : model1 loss : 0.165795 model2 loss : 0.217412
[00:22:23.147] iteration 26256 : model1 loss : 0.257944 model2 loss : 0.298526
[00:22:23.488] iteration 26257 : model1 loss : 0.229659 model2 loss : 0.274803
[00:22:23.826] iteration 26258 : model1 loss : 0.120405 model2 loss : 0.150571
[00:22:24.164] iteration 26259 : model1 loss : 0.202445 model2 loss : 0.204792
[00:22:24.508] iteration 26260 : model1 loss : 0.306330 model2 loss : 0.324071
[00:22:24.846] iteration 26261 : model1 loss : 0.170539 model2 loss : 0.206156
[00:22:25.184] iteration 26262 : model1 loss : 0.192322 model2 loss : 0.258748
[00:22:25.522] iteration 26263 : model1 loss : 0.160975 model2 loss : 0.191287
[00:22:25.862] iteration 26264 : model1 loss : 0.122248 model2 loss : 0.268344
[00:22:26.198] iteration 26265 : model1 loss : 0.181989 model2 loss : 0.241835
[00:22:26.534] iteration 26266 : model1 loss : 0.256691 model2 loss : 0.278868
[00:22:26.872] iteration 26267 : model1 loss : 0.188984 model2 loss : 0.250917
[00:22:27.208] iteration 26268 : model1 loss : 0.197827 model2 loss : 0.214426
[00:22:27.544] iteration 26269 : model1 loss : 0.154408 model2 loss : 0.173271
[00:22:27.880] iteration 26270 : model1 loss : 0.195308 model2 loss : 0.188910
[00:22:28.217] iteration 26271 : model1 loss : 0.073317 model2 loss : 0.092768
[00:22:28.553] iteration 26272 : model1 loss : 0.157669 model2 loss : 0.176043
[00:22:28.890] iteration 26273 : model1 loss : 0.240167 model2 loss : 0.250689
[00:22:29.226] iteration 26274 : model1 loss : 0.158037 model2 loss : 0.172035
[00:22:29.562] iteration 26275 : model1 loss : 0.289081 model2 loss : 0.301369
[00:22:29.899] iteration 26276 : model1 loss : 0.261005 model2 loss : 0.285436
[00:22:30.236] iteration 26277 : model1 loss : 0.347599 model2 loss : 0.388554
[00:22:30.572] iteration 26278 : model1 loss : 0.092527 model2 loss : 0.086289
[00:22:30.909] iteration 26279 : model1 loss : 0.269406 model2 loss : 0.270483
[00:22:31.247] iteration 26280 : model1 loss : 0.087111 model2 loss : 0.157605
[00:22:31.586] iteration 26281 : model1 loss : 0.258789 model2 loss : 0.286352
[00:22:31.922] iteration 26282 : model1 loss : 0.070586 model2 loss : 0.121535
[00:22:32.259] iteration 26283 : model1 loss : 0.162541 model2 loss : 0.194890
[00:22:32.597] iteration 26284 : model1 loss : 0.230124 model2 loss : 0.254854
[00:22:32.933] iteration 26285 : model1 loss : 0.189621 model2 loss : 0.217207
[00:22:33.270] iteration 26286 : model1 loss : 0.171478 model2 loss : 0.217390
[00:22:33.607] iteration 26287 : model1 loss : 0.077073 model2 loss : 0.141405
[00:22:33.944] iteration 26288 : model1 loss : 0.162506 model2 loss : 0.199184
[00:22:34.280] iteration 26289 : model1 loss : 0.179790 model2 loss : 0.188332
[00:22:34.616] iteration 26290 : model1 loss : 0.330084 model2 loss : 0.340878
[00:22:34.954] iteration 26291 : model1 loss : 0.287195 model2 loss : 0.299113
[00:22:35.290] iteration 26292 : model1 loss : 0.156668 model2 loss : 0.174520
[00:22:35.628] iteration 26293 : model1 loss : 0.175572 model2 loss : 0.222062
[00:22:35.964] iteration 26294 : model1 loss : 0.175339 model2 loss : 0.255151
[00:22:36.301] iteration 26295 : model1 loss : 0.072594 model2 loss : 0.096129
[00:22:36.638] iteration 26296 : model1 loss : 0.140319 model2 loss : 0.216795
[00:22:36.974] iteration 26297 : model1 loss : 0.098103 model2 loss : 0.132303
[00:22:37.312] iteration 26298 : model1 loss : 0.314997 model2 loss : 0.317826
[00:22:37.651] iteration 26299 : model1 loss : 0.245225 model2 loss : 0.237418
[00:22:37.989] iteration 26300 : model1 loss : 0.085637 model2 loss : 0.109821
[00:22:38.627] iteration 26301 : model1 loss : 0.148761 model2 loss : 0.172946
[00:22:38.964] iteration 26302 : model1 loss : 0.245531 model2 loss : 0.244263
[00:22:39.300] iteration 26303 : model1 loss : 0.097328 model2 loss : 0.155414
[00:22:39.641] iteration 26304 : model1 loss : 0.134060 model2 loss : 0.128137
[00:22:39.976] iteration 26305 : model1 loss : 0.126055 model2 loss : 0.168463
[00:22:40.314] iteration 26306 : model1 loss : 0.200669 model2 loss : 0.204679
[00:22:40.650] iteration 26307 : model1 loss : 0.078850 model2 loss : 0.121643
[00:22:40.986] iteration 26308 : model1 loss : 0.214518 model2 loss : 0.247227
[00:22:41.322] iteration 26309 : model1 loss : 0.106329 model2 loss : 0.144597
[00:22:41.657] iteration 26310 : model1 loss : 0.186831 model2 loss : 0.231622
[00:22:41.994] iteration 26311 : model1 loss : 0.109228 model2 loss : 0.120932
[00:22:42.329] iteration 26312 : model1 loss : 0.181081 model2 loss : 0.213990
[00:22:42.665] iteration 26313 : model1 loss : 0.151266 model2 loss : 0.172664
[00:22:43.002] iteration 26314 : model1 loss : 0.176015 model2 loss : 0.223020
[00:22:43.340] iteration 26315 : model1 loss : 0.088152 model2 loss : 0.180870
[00:22:43.676] iteration 26316 : model1 loss : 0.075064 model2 loss : 0.102126
[00:22:44.013] iteration 26317 : model1 loss : 0.264580 model2 loss : 0.293253
[00:22:44.349] iteration 26318 : model1 loss : 0.244516 model2 loss : 0.278796
[00:22:44.685] iteration 26319 : model1 loss : 0.183329 model2 loss : 0.222412
[00:22:45.021] iteration 26320 : model1 loss : 0.161141 model2 loss : 0.171328
[00:22:45.358] iteration 26321 : model1 loss : 0.084275 model2 loss : 0.111780
[00:22:45.694] iteration 26322 : model1 loss : 0.183920 model2 loss : 0.193036
[00:22:46.030] iteration 26323 : model1 loss : 0.188045 model2 loss : 0.250300
[00:22:46.367] iteration 26324 : model1 loss : 0.224144 model2 loss : 0.228380
[00:22:46.703] iteration 26325 : model1 loss : 0.177860 model2 loss : 0.219603
[00:22:47.039] iteration 26326 : model1 loss : 0.202093 model2 loss : 0.188366
[00:22:47.377] iteration 26327 : model1 loss : 0.198178 model2 loss : 0.228374
[00:22:47.713] iteration 26328 : model1 loss : 0.166368 model2 loss : 0.205002
[00:22:48.049] iteration 26329 : model1 loss : 0.111381 model2 loss : 0.145053
[00:22:48.385] iteration 26330 : model1 loss : 0.153499 model2 loss : 0.227764
[00:22:48.723] iteration 26331 : model1 loss : 0.216734 model2 loss : 0.248233
[00:22:49.058] iteration 26332 : model1 loss : 0.190293 model2 loss : 0.201404
[00:22:49.394] iteration 26333 : model1 loss : 0.194939 model2 loss : 0.267062
[00:22:49.731] iteration 26334 : model1 loss : 0.176301 model2 loss : 0.218578
[00:22:50.068] iteration 26335 : model1 loss : 0.327692 model2 loss : 0.341635
[00:22:50.404] iteration 26336 : model1 loss : 0.230311 model2 loss : 0.240553
[00:22:50.740] iteration 26337 : model1 loss : 0.259062 model2 loss : 0.286667
[00:22:51.076] iteration 26338 : model1 loss : 0.168204 model2 loss : 0.253739
[00:22:51.412] iteration 26339 : model1 loss : 0.265723 model2 loss : 0.272203
[00:22:51.747] iteration 26340 : model1 loss : 0.210160 model2 loss : 0.234566
[00:22:52.083] iteration 26341 : model1 loss : 0.207362 model2 loss : 0.220465
[00:22:52.423] iteration 26342 : model1 loss : 0.194025 model2 loss : 0.229974
[00:22:52.759] iteration 26343 : model1 loss : 0.194815 model2 loss : 0.195963
[00:22:53.095] iteration 26344 : model1 loss : 0.256116 model2 loss : 0.277295
[00:22:53.431] iteration 26345 : model1 loss : 0.173773 model2 loss : 0.223036
[00:22:53.767] iteration 26346 : model1 loss : 0.263687 model2 loss : 0.311745
[00:22:54.103] iteration 26347 : model1 loss : 0.213989 model2 loss : 0.235170
[00:22:54.440] iteration 26348 : model1 loss : 0.248093 model2 loss : 0.259998
[00:22:54.776] iteration 26349 : model1 loss : 0.245469 model2 loss : 0.250632
[00:22:55.116] iteration 26350 : model1 loss : 0.105420 model2 loss : 0.117975
[00:22:55.806] iteration 26351 : model1 loss : 0.257283 model2 loss : 0.265278
[00:22:56.141] iteration 26352 : model1 loss : 0.106157 model2 loss : 0.142177
[00:22:56.477] iteration 26353 : model1 loss : 0.172853 model2 loss : 0.217316
[00:22:56.814] iteration 26354 : model1 loss : 0.173206 model2 loss : 0.182052
[00:22:57.152] iteration 26355 : model1 loss : 0.254272 model2 loss : 0.263045
[00:22:57.490] iteration 26356 : model1 loss : 0.246917 model2 loss : 0.267489
[00:22:57.826] iteration 26357 : model1 loss : 0.246441 model2 loss : 0.252326
[00:22:58.163] iteration 26358 : model1 loss : 0.196953 model2 loss : 0.243728
[00:22:58.499] iteration 26359 : model1 loss : 0.178513 model2 loss : 0.190640
[00:22:58.835] iteration 26360 : model1 loss : 0.178376 model2 loss : 0.208033
[00:22:59.172] iteration 26361 : model1 loss : 0.081336 model2 loss : 0.099665
[00:22:59.508] iteration 26362 : model1 loss : 0.209019 model2 loss : 0.288807
[00:22:59.846] iteration 26363 : model1 loss : 0.172528 model2 loss : 0.263500
[00:23:00.182] iteration 26364 : model1 loss : 0.163127 model2 loss : 0.153733
[00:23:00.519] iteration 26365 : model1 loss : 0.199797 model2 loss : 0.235796
[00:23:00.856] iteration 26366 : model1 loss : 0.317320 model2 loss : 0.323318
[00:23:01.193] iteration 26367 : model1 loss : 0.093813 model2 loss : 0.167382
[00:23:01.530] iteration 26368 : model1 loss : 0.111415 model2 loss : 0.100959
[00:23:01.866] iteration 26369 : model1 loss : 0.156880 model2 loss : 0.168481
[00:23:02.202] iteration 26370 : model1 loss : 0.158907 model2 loss : 0.178658
[00:23:02.539] iteration 26371 : model1 loss : 0.183537 model2 loss : 0.221748
[00:23:02.877] iteration 26372 : model1 loss : 0.164197 model2 loss : 0.217189
[00:23:03.213] iteration 26373 : model1 loss : 0.241024 model2 loss : 0.250468
[00:23:03.549] iteration 26374 : model1 loss : 0.161775 model2 loss : 0.205392
[00:23:03.887] iteration 26375 : model1 loss : 0.256144 model2 loss : 0.282724
[00:23:04.223] iteration 26376 : model1 loss : 0.323083 model2 loss : 0.426931
[00:23:04.559] iteration 26377 : model1 loss : 0.175124 model2 loss : 0.199563
[00:23:04.896] iteration 26378 : model1 loss : 0.253451 model2 loss : 0.262251
[00:23:05.232] iteration 26379 : model1 loss : 0.166140 model2 loss : 0.193585
[00:23:05.568] iteration 26380 : model1 loss : 0.104160 model2 loss : 0.167259
[00:23:05.904] iteration 26381 : model1 loss : 0.240776 model2 loss : 0.238510
[00:23:06.240] iteration 26382 : model1 loss : 0.177569 model2 loss : 0.216062
[00:23:06.578] iteration 26383 : model1 loss : 0.092597 model2 loss : 0.125972
[00:23:06.916] iteration 26384 : model1 loss : 0.172918 model2 loss : 0.236793
[00:23:07.252] iteration 26385 : model1 loss : 0.244880 model2 loss : 0.254346
[00:23:07.589] iteration 26386 : model1 loss : 0.257072 model2 loss : 0.285141
[00:23:07.925] iteration 26387 : model1 loss : 0.093625 model2 loss : 0.180405
[00:23:08.261] iteration 26388 : model1 loss : 0.161538 model2 loss : 0.283843
[00:23:08.598] iteration 26389 : model1 loss : 0.232463 model2 loss : 0.239233
[00:23:08.934] iteration 26390 : model1 loss : 0.320090 model2 loss : 0.325515
[00:23:09.270] iteration 26391 : model1 loss : 0.177689 model2 loss : 0.241570
[00:23:09.606] iteration 26392 : model1 loss : 0.238274 model2 loss : 0.251400
[00:23:09.943] iteration 26393 : model1 loss : 0.245517 model2 loss : 0.263023
[00:23:10.280] iteration 26394 : model1 loss : 0.094754 model2 loss : 0.108932
[00:23:10.618] iteration 26395 : model1 loss : 0.256267 model2 loss : 0.278741
[00:23:10.954] iteration 26396 : model1 loss : 0.282976 model2 loss : 0.283305
[00:23:11.290] iteration 26397 : model1 loss : 0.160985 model2 loss : 0.277861
[00:23:11.627] iteration 26398 : model1 loss : 0.154564 model2 loss : 0.194488
[00:23:11.964] iteration 26399 : model1 loss : 0.182128 model2 loss : 0.245504
[00:23:12.301] iteration 26400 : model1 loss : 0.099918 model2 loss : 0.087172
[00:23:12.920] iteration 26401 : model1 loss : 0.247389 model2 loss : 0.262340
[00:23:13.256] iteration 26402 : model1 loss : 0.169160 model2 loss : 0.250892
[00:23:13.593] iteration 26403 : model1 loss : 0.160768 model2 loss : 0.239250
[00:23:13.929] iteration 26404 : model1 loss : 0.185354 model2 loss : 0.220488
[00:23:14.265] iteration 26405 : model1 loss : 0.172143 model2 loss : 0.212757
[00:23:14.601] iteration 26406 : model1 loss : 0.162135 model2 loss : 0.203201
[00:23:14.938] iteration 26407 : model1 loss : 0.109853 model2 loss : 0.162803
[00:23:15.274] iteration 26408 : model1 loss : 0.330178 model2 loss : 0.337180
[00:23:15.610] iteration 26409 : model1 loss : 0.163302 model2 loss : 0.169746
[00:23:15.947] iteration 26410 : model1 loss : 0.144205 model2 loss : 0.205830
[00:23:16.283] iteration 26411 : model1 loss : 0.161831 model2 loss : 0.217893
[00:23:16.619] iteration 26412 : model1 loss : 0.087019 model2 loss : 0.109218
[00:23:16.956] iteration 26413 : model1 loss : 0.239978 model2 loss : 0.243210
[00:23:17.294] iteration 26414 : model1 loss : 0.243820 model2 loss : 0.247214
[00:23:17.630] iteration 26415 : model1 loss : 0.195676 model2 loss : 0.218537
[00:23:17.968] iteration 26416 : model1 loss : 0.246460 model2 loss : 0.281388
[00:23:18.304] iteration 26417 : model1 loss : 0.176509 model2 loss : 0.239329
[00:23:18.641] iteration 26418 : model1 loss : 0.238839 model2 loss : 0.244713
[00:23:18.978] iteration 26419 : model1 loss : 0.109774 model2 loss : 0.147844
[00:23:19.314] iteration 26420 : model1 loss : 0.098460 model2 loss : 0.113527
[00:23:19.650] iteration 26421 : model1 loss : 0.247226 model2 loss : 0.253343
[00:23:19.989] iteration 26422 : model1 loss : 0.153784 model2 loss : 0.168832
[00:23:20.325] iteration 26423 : model1 loss : 0.084212 model2 loss : 0.135989
[00:23:20.662] iteration 26424 : model1 loss : 0.100359 model2 loss : 0.089116
[00:23:20.998] iteration 26425 : model1 loss : 0.093753 model2 loss : 0.112924
[00:23:21.334] iteration 26426 : model1 loss : 0.216394 model2 loss : 0.196175
[00:23:21.670] iteration 26427 : model1 loss : 0.212932 model2 loss : 0.257916
[00:23:22.009] iteration 26428 : model1 loss : 0.162788 model2 loss : 0.201074
[00:23:22.346] iteration 26429 : model1 loss : 0.169104 model2 loss : 0.174985
[00:23:22.687] iteration 26430 : model1 loss : 0.198974 model2 loss : 0.275745
[00:23:23.024] iteration 26431 : model1 loss : 0.099689 model2 loss : 0.130994
[00:23:23.360] iteration 26432 : model1 loss : 0.102661 model2 loss : 0.106358
[00:23:23.696] iteration 26433 : model1 loss : 0.170902 model2 loss : 0.204315
[00:23:24.035] iteration 26434 : model1 loss : 0.198425 model2 loss : 0.269818
[00:23:24.371] iteration 26435 : model1 loss : 0.252657 model2 loss : 0.262057
[00:23:24.708] iteration 26436 : model1 loss : 0.162995 model2 loss : 0.185434
[00:23:25.043] iteration 26437 : model1 loss : 0.250686 model2 loss : 0.274398
[00:23:25.380] iteration 26438 : model1 loss : 0.321491 model2 loss : 0.338371
[00:23:25.717] iteration 26439 : model1 loss : 0.171553 model2 loss : 0.181195
[00:23:26.053] iteration 26440 : model1 loss : 0.200371 model2 loss : 0.185804
[00:23:26.389] iteration 26441 : model1 loss : 0.229096 model2 loss : 0.271195
[00:23:26.727] iteration 26442 : model1 loss : 0.244075 model2 loss : 0.240928
[00:23:27.064] iteration 26443 : model1 loss : 0.251569 model2 loss : 0.382886
[00:23:27.401] iteration 26444 : model1 loss : 0.185051 model2 loss : 0.209027
[00:23:27.738] iteration 26445 : model1 loss : 0.152763 model2 loss : 0.200665
[00:23:28.074] iteration 26446 : model1 loss : 0.239431 model2 loss : 0.241417
[00:23:28.410] iteration 26447 : model1 loss : 0.074166 model2 loss : 0.094413
[00:23:28.746] iteration 26448 : model1 loss : 0.187263 model2 loss : 0.179013
[00:23:29.082] iteration 26449 : model1 loss : 0.240675 model2 loss : 0.307868
[00:23:29.418] iteration 26450 : model1 loss : 0.234542 model2 loss : 0.237721
[00:23:30.032] iteration 26451 : model1 loss : 0.109792 model2 loss : 0.148778
[00:23:30.369] iteration 26452 : model1 loss : 0.166728 model2 loss : 0.197122
[00:23:30.707] iteration 26453 : model1 loss : 0.110297 model2 loss : 0.131244
[00:23:31.043] iteration 26454 : model1 loss : 0.199382 model2 loss : 0.245743
[00:23:31.379] iteration 26455 : model1 loss : 0.079296 model2 loss : 0.124617
[00:23:31.716] iteration 26456 : model1 loss : 0.166290 model2 loss : 0.163066
[00:23:32.053] iteration 26457 : model1 loss : 0.097452 model2 loss : 0.101463
[00:23:32.389] iteration 26458 : model1 loss : 0.168374 model2 loss : 0.214539
[00:23:32.728] iteration 26459 : model1 loss : 0.190094 model2 loss : 0.189434
[00:23:33.064] iteration 26460 : model1 loss : 0.108188 model2 loss : 0.180511
[00:23:33.400] iteration 26461 : model1 loss : 0.207989 model2 loss : 0.290151
[00:23:33.737] iteration 26462 : model1 loss : 0.095086 model2 loss : 0.109548
[00:23:34.073] iteration 26463 : model1 loss : 0.152257 model2 loss : 0.110525
[00:23:34.410] iteration 26464 : model1 loss : 0.270917 model2 loss : 0.288591
[00:23:34.746] iteration 26465 : model1 loss : 0.213027 model2 loss : 0.268368
[00:23:35.082] iteration 26466 : model1 loss : 0.271279 model2 loss : 0.269797
[00:23:35.419] iteration 26467 : model1 loss : 0.239666 model2 loss : 0.261878
[00:23:35.754] iteration 26468 : model1 loss : 0.193187 model2 loss : 0.214939
[00:23:36.091] iteration 26469 : model1 loss : 0.208706 model2 loss : 0.237916
[00:23:36.427] iteration 26470 : model1 loss : 0.238066 model2 loss : 0.236990
[00:23:36.763] iteration 26471 : model1 loss : 0.083269 model2 loss : 0.101001
[00:23:37.100] iteration 26472 : model1 loss : 0.061035 model2 loss : 0.076878
[00:23:37.436] iteration 26473 : model1 loss : 0.160226 model2 loss : 0.193004
[00:23:37.772] iteration 26474 : model1 loss : 0.138263 model2 loss : 0.230657
[00:23:38.108] iteration 26475 : model1 loss : 0.253077 model2 loss : 0.250059
[00:23:38.444] iteration 26476 : model1 loss : 0.265254 model2 loss : 0.294314
[00:23:38.780] iteration 26477 : model1 loss : 0.180166 model2 loss : 0.210986
[00:23:39.117] iteration 26478 : model1 loss : 0.328424 model2 loss : 0.351519
[00:23:39.453] iteration 26479 : model1 loss : 0.158658 model2 loss : 0.187117
[00:23:39.791] iteration 26480 : model1 loss : 0.243915 model2 loss : 0.274644
[00:23:40.128] iteration 26481 : model1 loss : 0.068633 model2 loss : 0.095984
[00:23:40.470] iteration 26482 : model1 loss : 0.178808 model2 loss : 0.228043
[00:23:40.807] iteration 26483 : model1 loss : 0.238265 model2 loss : 0.238151
[00:23:41.145] iteration 26484 : model1 loss : 0.333885 model2 loss : 0.334812
[00:23:41.482] iteration 26485 : model1 loss : 0.162825 model2 loss : 0.173607
[00:23:41.823] iteration 26486 : model1 loss : 0.240263 model2 loss : 0.272148
[00:23:42.160] iteration 26487 : model1 loss : 0.161046 model2 loss : 0.200343
[00:23:42.502] iteration 26488 : model1 loss : 0.290523 model2 loss : 0.355676
[00:23:42.839] iteration 26489 : model1 loss : 0.179215 model2 loss : 0.187788
[00:23:43.178] iteration 26490 : model1 loss : 0.252149 model2 loss : 0.281511
[00:23:43.524] iteration 26491 : model1 loss : 0.157687 model2 loss : 0.172391
[00:23:43.862] iteration 26492 : model1 loss : 0.187645 model2 loss : 0.228959
[00:23:44.199] iteration 26493 : model1 loss : 0.162805 model2 loss : 0.194154
[00:23:44.540] iteration 26494 : model1 loss : 0.316231 model2 loss : 0.321028
[00:23:44.879] iteration 26495 : model1 loss : 0.206761 model2 loss : 0.213035
[00:23:45.225] iteration 26496 : model1 loss : 0.254046 model2 loss : 0.212479
[00:23:45.566] iteration 26497 : model1 loss : 0.248722 model2 loss : 0.246193
[00:23:45.910] iteration 26498 : model1 loss : 0.154333 model2 loss : 0.157476
[00:23:46.259] iteration 26499 : model1 loss : 0.100186 model2 loss : 0.137698
[00:23:46.600] iteration 26500 : model1 loss : 0.118660 model2 loss : 0.106487
[00:23:47.238] iteration 26501 : model1 loss : 0.241167 model2 loss : 0.257467
[00:23:47.575] iteration 26502 : model1 loss : 0.231848 model2 loss : 0.244048
[00:23:47.918] iteration 26503 : model1 loss : 0.098348 model2 loss : 0.124792
[00:23:48.254] iteration 26504 : model1 loss : 0.205810 model2 loss : 0.192694
[00:23:48.587] iteration 26505 : model1 loss : 0.158232 model2 loss : 0.174366
[00:23:48.924] iteration 26506 : model1 loss : 0.176155 model2 loss : 0.207417
[00:23:49.264] iteration 26507 : model1 loss : 0.178594 model2 loss : 0.196786
[00:23:49.604] iteration 26508 : model1 loss : 0.248671 model2 loss : 0.334249
[00:23:49.938] iteration 26509 : model1 loss : 0.080411 model2 loss : 0.103987
[00:23:50.276] iteration 26510 : model1 loss : 0.243221 model2 loss : 0.261786
[00:23:50.617] iteration 26511 : model1 loss : 0.246054 model2 loss : 0.261336
[00:23:50.953] iteration 26512 : model1 loss : 0.231056 model2 loss : 0.265630
[00:23:51.291] iteration 26513 : model1 loss : 0.338435 model2 loss : 0.359224
[00:23:51.629] iteration 26514 : model1 loss : 0.077920 model2 loss : 0.091827
[00:23:51.966] iteration 26515 : model1 loss : 0.161123 model2 loss : 0.190165
[00:23:52.300] iteration 26516 : model1 loss : 0.265330 model2 loss : 0.294176
[00:23:52.637] iteration 26517 : model1 loss : 0.269356 model2 loss : 0.303218
[00:23:52.971] iteration 26518 : model1 loss : 0.128327 model2 loss : 0.290708
[00:23:53.306] iteration 26519 : model1 loss : 0.116033 model2 loss : 0.142694
[00:23:53.640] iteration 26520 : model1 loss : 0.401705 model2 loss : 0.421471
[00:23:53.980] iteration 26521 : model1 loss : 0.262090 model2 loss : 0.305715
[00:23:54.323] iteration 26522 : model1 loss : 0.170301 model2 loss : 0.215909
[00:23:54.659] iteration 26523 : model1 loss : 0.088520 model2 loss : 0.113331
[00:23:54.997] iteration 26524 : model1 loss : 0.147485 model2 loss : 0.105122
[00:23:55.333] iteration 26525 : model1 loss : 0.056537 model2 loss : 0.119429
[00:23:55.670] iteration 26526 : model1 loss : 0.319807 model2 loss : 0.330677
[00:23:56.005] iteration 26527 : model1 loss : 0.165149 model2 loss : 0.185628
[00:23:56.338] iteration 26528 : model1 loss : 0.164140 model2 loss : 0.178999
[00:23:56.670] iteration 26529 : model1 loss : 0.250476 model2 loss : 0.276038
[00:23:57.003] iteration 26530 : model1 loss : 0.249848 model2 loss : 0.237427
[00:23:57.340] iteration 26531 : model1 loss : 0.327249 model2 loss : 0.332325
[00:23:57.680] iteration 26532 : model1 loss : 0.164784 model2 loss : 0.261553
[00:23:58.017] iteration 26533 : model1 loss : 0.176139 model2 loss : 0.176531
[00:23:58.350] iteration 26534 : model1 loss : 0.209173 model2 loss : 0.212712
[00:23:58.686] iteration 26535 : model1 loss : 0.182559 model2 loss : 0.413869
[00:23:59.018] iteration 26536 : model1 loss : 0.112321 model2 loss : 0.110797
[00:23:59.350] iteration 26537 : model1 loss : 0.211921 model2 loss : 0.257687
[00:23:59.685] iteration 26538 : model1 loss : 0.268662 model2 loss : 0.273915
[00:24:00.019] iteration 26539 : model1 loss : 0.166789 model2 loss : 0.183534
[00:24:00.353] iteration 26540 : model1 loss : 0.271256 model2 loss : 0.309834
[00:24:00.685] iteration 26541 : model1 loss : 0.162088 model2 loss : 0.192614
[00:24:01.021] iteration 26542 : model1 loss : 0.133675 model2 loss : 0.190961
[00:24:01.361] iteration 26543 : model1 loss : 0.146908 model2 loss : 0.192156
[00:24:01.694] iteration 26544 : model1 loss : 0.231097 model2 loss : 0.266883
[00:24:02.030] iteration 26545 : model1 loss : 0.266119 model2 loss : 0.265785
[00:24:02.370] iteration 26546 : model1 loss : 0.256008 model2 loss : 0.321648
[00:24:02.710] iteration 26547 : model1 loss : 0.246190 model2 loss : 0.263552
[00:24:03.050] iteration 26548 : model1 loss : 0.230177 model2 loss : 0.263561
[00:24:03.391] iteration 26549 : model1 loss : 0.161162 model2 loss : 0.191963
[00:24:03.728] iteration 26550 : model1 loss : 0.177679 model2 loss : 0.240052
[00:24:04.381] iteration 26551 : model1 loss : 0.307236 model2 loss : 0.351480
[00:24:04.719] iteration 26552 : model1 loss : 0.166888 model2 loss : 0.161726
[00:24:05.054] iteration 26553 : model1 loss : 0.184707 model2 loss : 0.205874
[00:24:05.390] iteration 26554 : model1 loss : 0.084247 model2 loss : 0.118453
[00:24:05.731] iteration 26555 : model1 loss : 0.190989 model2 loss : 0.211036
[00:24:06.070] iteration 26556 : model1 loss : 0.247168 model2 loss : 0.268782
[00:24:06.410] iteration 26557 : model1 loss : 0.176624 model2 loss : 0.215520
[00:24:06.742] iteration 26558 : model1 loss : 0.278266 model2 loss : 0.274131
[00:24:07.080] iteration 26559 : model1 loss : 0.149778 model2 loss : 0.293895
[00:24:07.413] iteration 26560 : model1 loss : 0.109126 model2 loss : 0.155507
[00:24:07.746] iteration 26561 : model1 loss : 0.249026 model2 loss : 0.274470
[00:24:08.082] iteration 26562 : model1 loss : 0.175473 model2 loss : 0.192021
[00:24:08.420] iteration 26563 : model1 loss : 0.155889 model2 loss : 0.170932
[00:24:08.761] iteration 26564 : model1 loss : 0.239983 model2 loss : 0.242694
[00:24:09.099] iteration 26565 : model1 loss : 0.073151 model2 loss : 0.082879
[00:24:09.434] iteration 26566 : model1 loss : 0.177385 model2 loss : 0.195364
[00:24:09.768] iteration 26567 : model1 loss : 0.142756 model2 loss : 0.168787
[00:24:10.104] iteration 26568 : model1 loss : 0.280382 model2 loss : 0.316257
[00:24:10.450] iteration 26569 : model1 loss : 0.204754 model2 loss : 0.228400
[00:24:10.787] iteration 26570 : model1 loss : 0.263400 model2 loss : 0.284769
[00:24:11.124] iteration 26571 : model1 loss : 0.232630 model2 loss : 0.269607
[00:24:11.461] iteration 26572 : model1 loss : 0.286869 model2 loss : 0.302635
[00:24:11.795] iteration 26573 : model1 loss : 0.223506 model2 loss : 0.252431
[00:24:12.135] iteration 26574 : model1 loss : 0.114789 model2 loss : 0.158381
[00:24:12.468] iteration 26575 : model1 loss : 0.263704 model2 loss : 0.292583
[00:24:12.800] iteration 26576 : model1 loss : 0.257257 model2 loss : 0.269048
[00:24:13.138] iteration 26577 : model1 loss : 0.156465 model2 loss : 0.163448
[00:24:13.474] iteration 26578 : model1 loss : 0.172416 model2 loss : 0.192984
[00:24:13.809] iteration 26579 : model1 loss : 0.171224 model2 loss : 0.211761
[00:24:14.144] iteration 26580 : model1 loss : 0.169938 model2 loss : 0.201816
[00:24:14.478] iteration 26581 : model1 loss : 0.237897 model2 loss : 0.302671
[00:24:14.811] iteration 26582 : model1 loss : 0.066245 model2 loss : 0.098085
[00:24:15.146] iteration 26583 : model1 loss : 0.110884 model2 loss : 0.095501
[00:24:15.486] iteration 26584 : model1 loss : 0.093209 model2 loss : 0.127633
[00:24:15.818] iteration 26585 : model1 loss : 0.233803 model2 loss : 0.268854
[00:24:16.156] iteration 26586 : model1 loss : 0.164819 model2 loss : 0.221852
[00:24:16.496] iteration 26587 : model1 loss : 0.097023 model2 loss : 0.110062
[00:24:16.832] iteration 26588 : model1 loss : 0.119557 model2 loss : 0.109769
[00:24:17.166] iteration 26589 : model1 loss : 0.158936 model2 loss : 0.179120
[00:24:17.500] iteration 26590 : model1 loss : 0.234542 model2 loss : 0.265208
[00:24:17.838] iteration 26591 : model1 loss : 0.204721 model2 loss : 0.235805
[00:24:18.174] iteration 26592 : model1 loss : 0.173705 model2 loss : 0.213763
[00:24:18.506] iteration 26593 : model1 loss : 0.133691 model2 loss : 0.157903
[00:24:18.838] iteration 26594 : model1 loss : 0.369198 model2 loss : 0.355423
[00:24:19.178] iteration 26595 : model1 loss : 0.162014 model2 loss : 0.206387
[00:24:19.513] iteration 26596 : model1 loss : 0.074882 model2 loss : 0.117337
[00:24:19.845] iteration 26597 : model1 loss : 0.172662 model2 loss : 0.169830
[00:24:20.178] iteration 26598 : model1 loss : 0.237911 model2 loss : 0.247711
[00:24:20.510] iteration 26599 : model1 loss : 0.248579 model2 loss : 0.273227
[00:24:20.846] iteration 26600 : model1 loss : 0.258746 model2 loss : 0.285679
[00:24:21.473] iteration 26601 : model1 loss : 0.260985 model2 loss : 0.322243
[00:24:21.805] iteration 26602 : model1 loss : 0.184887 model2 loss : 0.194596
[00:24:22.141] iteration 26603 : model1 loss : 0.173510 model2 loss : 0.215307
[00:24:22.476] iteration 26604 : model1 loss : 0.237856 model2 loss : 0.240511
[00:24:22.808] iteration 26605 : model1 loss : 0.252580 model2 loss : 0.252510
[00:24:23.146] iteration 26606 : model1 loss : 0.123126 model2 loss : 0.122535
[00:24:23.484] iteration 26607 : model1 loss : 0.251796 model2 loss : 0.264929
[00:24:23.821] iteration 26608 : model1 loss : 0.189231 model2 loss : 0.232040
[00:24:24.155] iteration 26609 : model1 loss : 0.191905 model2 loss : 0.212913
[00:24:24.487] iteration 26610 : model1 loss : 0.152069 model2 loss : 0.149638
[00:24:24.819] iteration 26611 : model1 loss : 0.254440 model2 loss : 0.251602
[00:24:25.153] iteration 26612 : model1 loss : 0.177586 model2 loss : 0.232120
[00:24:25.485] iteration 26613 : model1 loss : 0.157013 model2 loss : 0.164578
[00:24:25.817] iteration 26614 : model1 loss : 0.215840 model2 loss : 0.332570
[00:24:26.152] iteration 26615 : model1 loss : 0.218378 model2 loss : 0.228059
[00:24:26.484] iteration 26616 : model1 loss : 0.160904 model2 loss : 0.205505
[00:24:26.826] iteration 26617 : model1 loss : 0.159782 model2 loss : 0.224256
[00:24:27.163] iteration 26618 : model1 loss : 0.276791 model2 loss : 0.276994
[00:24:27.495] iteration 26619 : model1 loss : 0.171806 model2 loss : 0.191806
[00:24:27.826] iteration 26620 : model1 loss : 0.161944 model2 loss : 0.199951
[00:24:28.160] iteration 26621 : model1 loss : 0.186559 model2 loss : 0.207263
[00:24:28.492] iteration 26622 : model1 loss : 0.279344 model2 loss : 0.387906
[00:24:28.826] iteration 26623 : model1 loss : 0.120638 model2 loss : 0.141911
[00:24:29.163] iteration 26624 : model1 loss : 0.111713 model2 loss : 0.101851
[00:24:29.498] iteration 26625 : model1 loss : 0.198341 model2 loss : 0.239738
[00:24:29.835] iteration 26626 : model1 loss : 0.183851 model2 loss : 0.197804
[00:24:30.172] iteration 26627 : model1 loss : 0.169294 model2 loss : 0.195302
[00:24:30.511] iteration 26628 : model1 loss : 0.211027 model2 loss : 0.210273
[00:24:30.845] iteration 26629 : model1 loss : 0.218664 model2 loss : 0.280436
[00:24:31.184] iteration 26630 : model1 loss : 0.270683 model2 loss : 0.283429
[00:24:31.523] iteration 26631 : model1 loss : 0.284876 model2 loss : 0.313478
[00:24:31.882] iteration 26632 : model1 loss : 0.249901 model2 loss : 0.261442
[00:24:32.214] iteration 26633 : model1 loss : 0.158604 model2 loss : 0.160384
[00:24:32.546] iteration 26634 : model1 loss : 0.171666 model2 loss : 0.175843
[00:24:32.883] iteration 26635 : model1 loss : 0.170307 model2 loss : 0.166669
[00:24:33.216] iteration 26636 : model1 loss : 0.240828 model2 loss : 0.300650
[00:24:33.550] iteration 26637 : model1 loss : 0.065633 model2 loss : 0.081775
[00:24:33.882] iteration 26638 : model1 loss : 0.066448 model2 loss : 0.122766
[00:24:34.214] iteration 26639 : model1 loss : 0.065812 model2 loss : 0.115337
[00:24:34.549] iteration 26640 : model1 loss : 0.173185 model2 loss : 0.186375
[00:24:34.882] iteration 26641 : model1 loss : 0.177933 model2 loss : 0.231287
[00:24:35.215] iteration 26642 : model1 loss : 0.095202 model2 loss : 0.109426
[00:24:35.547] iteration 26643 : model1 loss : 0.158617 model2 loss : 0.284122
[00:24:35.879] iteration 26644 : model1 loss : 0.177019 model2 loss : 0.205337
[00:24:36.218] iteration 26645 : model1 loss : 0.132140 model2 loss : 0.412274
[00:24:36.550] iteration 26646 : model1 loss : 0.166343 model2 loss : 0.187107
[00:24:36.888] iteration 26647 : model1 loss : 0.222865 model2 loss : 0.179747
[00:24:37.223] iteration 26648 : model1 loss : 0.064224 model2 loss : 0.098037
[00:24:37.559] iteration 26649 : model1 loss : 0.120894 model2 loss : 0.183040
[00:24:37.896] iteration 26650 : model1 loss : 0.085446 model2 loss : 0.102302
[00:24:38.573] iteration 26651 : model1 loss : 0.297419 model2 loss : 0.332913
[00:24:38.912] iteration 26652 : model1 loss : 0.157405 model2 loss : 0.192657
[00:24:39.244] iteration 26653 : model1 loss : 0.254211 model2 loss : 0.264319
[00:24:39.583] iteration 26654 : model1 loss : 0.248080 model2 loss : 0.274003
[00:24:39.922] iteration 26655 : model1 loss : 0.171937 model2 loss : 0.213420
[00:24:40.254] iteration 26656 : model1 loss : 0.168483 model2 loss : 0.128574
[00:24:40.588] iteration 26657 : model1 loss : 0.242755 model2 loss : 0.261850
[00:24:40.926] iteration 26658 : model1 loss : 0.183756 model2 loss : 0.256397
[00:24:41.258] iteration 26659 : model1 loss : 0.096315 model2 loss : 0.156533
[00:24:41.591] iteration 26660 : model1 loss : 0.179711 model2 loss : 0.203086
[00:24:41.923] iteration 26661 : model1 loss : 0.196040 model2 loss : 0.210637
[00:24:42.259] iteration 26662 : model1 loss : 0.087603 model2 loss : 0.144957
[00:24:42.591] iteration 26663 : model1 loss : 0.193561 model2 loss : 0.225843
[00:24:42.926] iteration 26664 : model1 loss : 0.229886 model2 loss : 0.262460
[00:24:43.266] iteration 26665 : model1 loss : 0.104742 model2 loss : 0.112628
[00:24:43.600] iteration 26666 : model1 loss : 0.269419 model2 loss : 0.287835
[00:24:43.937] iteration 26667 : model1 loss : 0.103224 model2 loss : 0.114504
[00:24:44.273] iteration 26668 : model1 loss : 0.170749 model2 loss : 0.197131
[00:24:44.605] iteration 26669 : model1 loss : 0.259591 model2 loss : 0.268696
[00:24:44.944] iteration 26670 : model1 loss : 0.077155 model2 loss : 0.082806
[00:24:45.282] iteration 26671 : model1 loss : 0.183275 model2 loss : 0.214800
[00:24:45.615] iteration 26672 : model1 loss : 0.175081 model2 loss : 0.229055
[00:24:45.948] iteration 26673 : model1 loss : 0.240095 model2 loss : 0.279435
[00:24:46.282] iteration 26674 : model1 loss : 0.098804 model2 loss : 0.095529
[00:24:46.614] iteration 26675 : model1 loss : 0.445501 model2 loss : 0.202773
[00:24:46.948] iteration 26676 : model1 loss : 0.245245 model2 loss : 0.303688
[00:24:47.279] iteration 26677 : model1 loss : 0.254021 model2 loss : 0.298057
[00:24:47.611] iteration 26678 : model1 loss : 0.075497 model2 loss : 0.095789
[00:24:47.952] iteration 26679 : model1 loss : 0.179505 model2 loss : 0.190255
[00:24:48.285] iteration 26680 : model1 loss : 0.172490 model2 loss : 0.203862
[00:24:48.619] iteration 26681 : model1 loss : 0.202011 model2 loss : 0.217980
[00:24:48.952] iteration 26682 : model1 loss : 0.084650 model2 loss : 0.128806
[00:24:49.286] iteration 26683 : model1 loss : 0.143070 model2 loss : 0.169268
[00:24:49.624] iteration 26684 : model1 loss : 0.192089 model2 loss : 0.197627
[00:24:49.963] iteration 26685 : model1 loss : 0.257269 model2 loss : 0.324870
[00:24:50.299] iteration 26686 : model1 loss : 0.156894 model2 loss : 0.193826
[00:24:50.635] iteration 26687 : model1 loss : 0.249803 model2 loss : 0.264425
[00:24:50.971] iteration 26688 : model1 loss : 0.238979 model2 loss : 0.234535
[00:24:51.306] iteration 26689 : model1 loss : 0.179911 model2 loss : 0.209866
[00:24:51.638] iteration 26690 : model1 loss : 0.226486 model2 loss : 0.166310
[00:24:51.975] iteration 26691 : model1 loss : 0.162927 model2 loss : 0.275120
[00:24:52.312] iteration 26692 : model1 loss : 0.105890 model2 loss : 0.127876
[00:24:52.656] iteration 26693 : model1 loss : 0.179812 model2 loss : 0.230878
[00:24:52.989] iteration 26694 : model1 loss : 0.192254 model2 loss : 0.202459
[00:24:53.325] iteration 26695 : model1 loss : 0.190505 model2 loss : 0.212825
[00:24:53.660] iteration 26696 : model1 loss : 0.245545 model2 loss : 0.243300
[00:24:53.994] iteration 26697 : model1 loss : 0.093630 model2 loss : 0.212587
[00:24:54.326] iteration 26698 : model1 loss : 0.160846 model2 loss : 0.182724
[00:24:54.657] iteration 26699 : model1 loss : 0.073276 model2 loss : 0.096116
[00:24:54.989] iteration 26700 : model1 loss : 0.185413 model2 loss : 0.235562
[00:24:55.626] iteration 26701 : model1 loss : 0.188797 model2 loss : 0.221968
[00:24:55.960] iteration 26702 : model1 loss : 0.267687 model2 loss : 0.396810
[00:24:56.295] iteration 26703 : model1 loss : 0.229343 model2 loss : 0.271301
[00:24:56.627] iteration 26704 : model1 loss : 0.171970 model2 loss : 0.193072
[00:24:56.959] iteration 26705 : model1 loss : 0.232450 model2 loss : 0.261907
[00:24:58.101] iteration 26706 : model1 loss : 0.127447 model2 loss : 0.168688
[00:24:58.438] iteration 26707 : model1 loss : 0.186634 model2 loss : 0.235582
[00:24:58.778] iteration 26708 : model1 loss : 0.176204 model2 loss : 0.214959
[00:24:59.113] iteration 26709 : model1 loss : 0.092213 model2 loss : 0.262383
[00:24:59.451] iteration 26710 : model1 loss : 0.190654 model2 loss : 0.194879
[00:24:59.785] iteration 26711 : model1 loss : 0.264736 model2 loss : 0.291862
[00:25:00.122] iteration 26712 : model1 loss : 0.252213 model2 loss : 0.281075
[00:25:00.461] iteration 26713 : model1 loss : 0.122352 model2 loss : 0.168667
[00:25:00.796] iteration 26714 : model1 loss : 0.157040 model2 loss : 0.215801
[00:25:01.133] iteration 26715 : model1 loss : 0.072985 model2 loss : 0.099434
[00:25:01.468] iteration 26716 : model1 loss : 0.114925 model2 loss : 0.124624
[00:25:01.800] iteration 26717 : model1 loss : 0.277897 model2 loss : 0.277274
[00:25:02.136] iteration 26718 : model1 loss : 0.261670 model2 loss : 0.276547
[00:25:02.472] iteration 26719 : model1 loss : 0.150565 model2 loss : 0.180557
[00:25:02.809] iteration 26720 : model1 loss : 0.204674 model2 loss : 0.180082
[00:25:03.146] iteration 26721 : model1 loss : 0.203753 model2 loss : 0.273164
[00:25:03.480] iteration 26722 : model1 loss : 0.182408 model2 loss : 0.206762
[00:25:03.815] iteration 26723 : model1 loss : 0.079095 model2 loss : 0.114001
[00:25:04.150] iteration 26724 : model1 loss : 0.174454 model2 loss : 0.176974
[00:25:04.483] iteration 26725 : model1 loss : 0.098660 model2 loss : 0.112638
[00:25:04.817] iteration 26726 : model1 loss : 0.131323 model2 loss : 0.192338
[00:25:05.155] iteration 26727 : model1 loss : 0.328095 model2 loss : 0.344865
[00:25:05.494] iteration 26728 : model1 loss : 0.247297 model2 loss : 0.243826
[00:25:05.827] iteration 26729 : model1 loss : 0.253729 model2 loss : 0.325271
[00:25:06.166] iteration 26730 : model1 loss : 0.157419 model2 loss : 0.175409
[00:25:06.498] iteration 26731 : model1 loss : 0.238344 model2 loss : 0.285819
[00:25:06.831] iteration 26732 : model1 loss : 0.090403 model2 loss : 0.124365
[00:25:07.168] iteration 26733 : model1 loss : 0.253778 model2 loss : 0.255832
[00:25:07.503] iteration 26734 : model1 loss : 0.243849 model2 loss : 0.254141
[00:25:07.843] iteration 26735 : model1 loss : 0.165828 model2 loss : 0.191928
[00:25:08.179] iteration 26736 : model1 loss : 0.166172 model2 loss : 0.188031
[00:25:08.512] iteration 26737 : model1 loss : 0.178164 model2 loss : 0.227176
[00:25:08.844] iteration 26738 : model1 loss : 0.261762 model2 loss : 0.264673
[00:25:09.183] iteration 26739 : model1 loss : 0.321824 model2 loss : 0.323926
[00:25:09.516] iteration 26740 : model1 loss : 0.212206 model2 loss : 0.200668
[00:25:09.850] iteration 26741 : model1 loss : 0.263534 model2 loss : 0.286423
[00:25:10.186] iteration 26742 : model1 loss : 0.106937 model2 loss : 0.111464
[00:25:10.520] iteration 26743 : model1 loss : 0.191483 model2 loss : 0.193999
[00:25:10.852] iteration 26744 : model1 loss : 0.140483 model2 loss : 0.161454
[00:25:11.189] iteration 26745 : model1 loss : 0.166123 model2 loss : 0.183300
[00:25:11.523] iteration 26746 : model1 loss : 0.163470 model2 loss : 0.203945
[00:25:11.855] iteration 26747 : model1 loss : 0.105161 model2 loss : 0.126337
[00:25:12.190] iteration 26748 : model1 loss : 0.142121 model2 loss : 0.150608
[00:25:12.522] iteration 26749 : model1 loss : 0.274771 model2 loss : 0.288245
[00:25:12.859] iteration 26750 : model1 loss : 0.102288 model2 loss : 0.129514
[00:25:13.516] iteration 26751 : model1 loss : 0.057577 model2 loss : 0.069447
[00:25:13.852] iteration 26752 : model1 loss : 0.247765 model2 loss : 0.281858
[00:25:14.190] iteration 26753 : model1 loss : 0.094209 model2 loss : 0.133304
[00:25:14.530] iteration 26754 : model1 loss : 0.235426 model2 loss : 0.254009
[00:25:14.865] iteration 26755 : model1 loss : 0.242012 model2 loss : 0.264890
[00:25:15.201] iteration 26756 : model1 loss : 0.216463 model2 loss : 0.222303
[00:25:15.534] iteration 26757 : model1 loss : 0.168704 model2 loss : 0.180722
[00:25:15.870] iteration 26758 : model1 loss : 0.183947 model2 loss : 0.209184
[00:25:16.212] iteration 26759 : model1 loss : 0.162190 model2 loss : 0.183931
[00:25:16.548] iteration 26760 : model1 loss : 0.080472 model2 loss : 0.105085
[00:25:16.886] iteration 26761 : model1 loss : 0.255831 model2 loss : 0.268767
[00:25:17.224] iteration 26762 : model1 loss : 0.268865 model2 loss : 0.261234
[00:25:17.560] iteration 26763 : model1 loss : 0.248117 model2 loss : 0.257022
[00:25:17.896] iteration 26764 : model1 loss : 0.125609 model2 loss : 0.206264
[00:25:18.234] iteration 26765 : model1 loss : 0.205034 model2 loss : 0.296547
[00:25:18.575] iteration 26766 : model1 loss : 0.240027 model2 loss : 0.251047
[00:25:18.912] iteration 26767 : model1 loss : 0.153547 model2 loss : 0.165823
[00:25:19.246] iteration 26768 : model1 loss : 0.174762 model2 loss : 0.196827
[00:25:19.579] iteration 26769 : model1 loss : 0.298668 model2 loss : 0.332231
[00:25:19.922] iteration 26770 : model1 loss : 0.266988 model2 loss : 0.283353
[00:25:20.259] iteration 26771 : model1 loss : 0.183669 model2 loss : 0.204187
[00:25:20.594] iteration 26772 : model1 loss : 0.190578 model2 loss : 0.189644
[00:25:20.934] iteration 26773 : model1 loss : 0.198616 model2 loss : 0.184796
[00:25:21.270] iteration 26774 : model1 loss : 0.177679 model2 loss : 0.262090
[00:25:21.603] iteration 26775 : model1 loss : 0.086802 model2 loss : 0.120889
[00:25:21.939] iteration 26776 : model1 loss : 0.142963 model2 loss : 0.180468
[00:25:22.275] iteration 26777 : model1 loss : 0.280529 model2 loss : 0.313168
[00:25:22.608] iteration 26778 : model1 loss : 0.129218 model2 loss : 0.200955
[00:25:22.942] iteration 26779 : model1 loss : 0.181004 model2 loss : 0.220252
[00:25:23.282] iteration 26780 : model1 loss : 0.135908 model2 loss : 0.416729
[00:25:23.615] iteration 26781 : model1 loss : 0.239739 model2 loss : 0.286845
[00:25:23.957] iteration 26782 : model1 loss : 0.248301 model2 loss : 0.285858
[00:25:24.291] iteration 26783 : model1 loss : 0.287840 model2 loss : 0.411314
[00:25:24.631] iteration 26784 : model1 loss : 0.114109 model2 loss : 0.126970
[00:25:24.963] iteration 26785 : model1 loss : 0.091930 model2 loss : 0.147249
[00:25:25.302] iteration 26786 : model1 loss : 0.153162 model2 loss : 0.185783
[00:25:25.638] iteration 26787 : model1 loss : 0.234619 model2 loss : 0.240578
[00:25:25.974] iteration 26788 : model1 loss : 0.072750 model2 loss : 0.090049
[00:25:26.311] iteration 26789 : model1 loss : 0.231610 model2 loss : 0.240216
[00:25:26.643] iteration 26790 : model1 loss : 0.180987 model2 loss : 0.180946
[00:25:26.975] iteration 26791 : model1 loss : 0.171678 model2 loss : 0.214885
[00:25:27.311] iteration 26792 : model1 loss : 0.085475 model2 loss : 0.104505
[00:25:27.647] iteration 26793 : model1 loss : 0.159691 model2 loss : 0.177431
[00:25:27.981] iteration 26794 : model1 loss : 0.317119 model2 loss : 0.323958
[00:25:28.319] iteration 26795 : model1 loss : 0.168530 model2 loss : 0.180971
[00:25:28.653] iteration 26796 : model1 loss : 0.104683 model2 loss : 0.132561
[00:25:28.986] iteration 26797 : model1 loss : 0.237473 model2 loss : 0.341196
[00:25:29.326] iteration 26798 : model1 loss : 0.170024 model2 loss : 0.231494
[00:25:29.662] iteration 26799 : model1 loss : 0.212664 model2 loss : 0.212602
[00:25:29.998] iteration 26800 : model1 loss : 0.192422 model2 loss : 0.211659
[00:25:30.629] iteration 26801 : model1 loss : 0.167946 model2 loss : 0.187072
[00:25:30.967] iteration 26802 : model1 loss : 0.151284 model2 loss : 0.158277
[00:25:31.302] iteration 26803 : model1 loss : 0.163715 model2 loss : 0.199863
[00:25:31.634] iteration 26804 : model1 loss : 0.250192 model2 loss : 0.288138
[00:25:31.970] iteration 26805 : model1 loss : 0.151653 model2 loss : 0.185924
[00:25:32.306] iteration 26806 : model1 loss : 0.174197 model2 loss : 0.224239
[00:25:32.639] iteration 26807 : model1 loss : 0.119765 model2 loss : 0.119526
[00:25:32.976] iteration 26808 : model1 loss : 0.156784 model2 loss : 0.171610
[00:25:33.313] iteration 26809 : model1 loss : 0.177206 model2 loss : 0.182441
[00:25:33.649] iteration 26810 : model1 loss : 0.251126 model2 loss : 0.301501
[00:25:33.984] iteration 26811 : model1 loss : 0.207585 model2 loss : 0.270037
[00:25:34.320] iteration 26812 : model1 loss : 0.285454 model2 loss : 0.319460
[00:25:34.653] iteration 26813 : model1 loss : 0.187135 model2 loss : 0.294516
[00:25:34.986] iteration 26814 : model1 loss : 0.175380 model2 loss : 0.192330
[00:25:35.327] iteration 26815 : model1 loss : 0.192065 model2 loss : 0.217778
[00:25:35.662] iteration 26816 : model1 loss : 0.177559 model2 loss : 0.193178
[00:25:35.998] iteration 26817 : model1 loss : 0.242196 model2 loss : 0.251572
[00:25:36.338] iteration 26818 : model1 loss : 0.229911 model2 loss : 0.263080
[00:25:36.669] iteration 26819 : model1 loss : 0.222091 model2 loss : 0.232937
[00:25:37.006] iteration 26820 : model1 loss : 0.178401 model2 loss : 0.184611
[00:25:37.345] iteration 26821 : model1 loss : 0.093035 model2 loss : 0.123492
[00:25:37.687] iteration 26822 : model1 loss : 0.190518 model2 loss : 0.205123
[00:25:38.025] iteration 26823 : model1 loss : 0.175301 model2 loss : 0.181403
[00:25:38.358] iteration 26824 : model1 loss : 0.119332 model2 loss : 0.150543
[00:25:38.697] iteration 26825 : model1 loss : 0.236089 model2 loss : 0.249923
[00:25:39.033] iteration 26826 : model1 loss : 0.089062 model2 loss : 0.103820
[00:25:39.365] iteration 26827 : model1 loss : 0.269865 model2 loss : 0.281195
[00:25:39.704] iteration 26828 : model1 loss : 0.076199 model2 loss : 0.110400
[00:25:40.037] iteration 26829 : model1 loss : 0.240123 model2 loss : 0.259422
[00:25:40.374] iteration 26830 : model1 loss : 0.119970 model2 loss : 0.175911
[00:25:40.715] iteration 26831 : model1 loss : 0.162508 model2 loss : 0.189036
[00:25:41.051] iteration 26832 : model1 loss : 0.134661 model2 loss : 0.174824
[00:25:41.388] iteration 26833 : model1 loss : 0.183766 model2 loss : 0.184683
[00:25:41.729] iteration 26834 : model1 loss : 0.237472 model2 loss : 0.251365
[00:25:42.062] iteration 26835 : model1 loss : 0.117319 model2 loss : 0.129213
[00:25:42.395] iteration 26836 : model1 loss : 0.185309 model2 loss : 0.214373
[00:25:42.731] iteration 26837 : model1 loss : 0.178668 model2 loss : 0.214258
[00:25:43.072] iteration 26838 : model1 loss : 0.161429 model2 loss : 0.205361
[00:25:43.407] iteration 26839 : model1 loss : 0.175531 model2 loss : 0.191782
[00:25:43.747] iteration 26840 : model1 loss : 0.147858 model2 loss : 0.192264
[00:25:44.091] iteration 26841 : model1 loss : 0.121922 model2 loss : 0.154765
[00:25:44.428] iteration 26842 : model1 loss : 0.161225 model2 loss : 0.171616
[00:25:44.766] iteration 26843 : model1 loss : 0.088153 model2 loss : 0.110670
[00:25:45.106] iteration 26844 : model1 loss : 0.173532 model2 loss : 0.281690
[00:25:45.447] iteration 26845 : model1 loss : 0.184632 model2 loss : 0.230363
[00:25:45.783] iteration 26846 : model1 loss : 0.160468 model2 loss : 0.206325
[00:25:46.115] iteration 26847 : model1 loss : 0.158876 model2 loss : 0.195843
[00:25:46.451] iteration 26848 : model1 loss : 0.124384 model2 loss : 0.165076
[00:25:46.784] iteration 26849 : model1 loss : 0.190291 model2 loss : 0.176237
[00:25:47.126] iteration 26850 : model1 loss : 0.109660 model2 loss : 0.203454
[00:25:47.771] iteration 26851 : model1 loss : 0.266512 model2 loss : 0.310039
[00:25:48.102] iteration 26852 : model1 loss : 0.101207 model2 loss : 0.158199
[00:25:48.435] iteration 26853 : model1 loss : 0.179605 model2 loss : 0.219165
[00:25:48.767] iteration 26854 : model1 loss : 0.162671 model2 loss : 0.185334
[00:25:49.099] iteration 26855 : model1 loss : 0.172648 model2 loss : 0.202692
[00:25:49.433] iteration 26856 : model1 loss : 0.232507 model2 loss : 0.252930
[00:25:49.770] iteration 26857 : model1 loss : 0.076347 model2 loss : 0.135620
[00:25:50.107] iteration 26858 : model1 loss : 0.178634 model2 loss : 0.203558
[00:25:50.443] iteration 26859 : model1 loss : 0.231088 model2 loss : 0.244853
[00:25:50.779] iteration 26860 : model1 loss : 0.074640 model2 loss : 0.072093
[00:25:51.114] iteration 26861 : model1 loss : 0.145624 model2 loss : 0.187333
[00:25:51.453] iteration 26862 : model1 loss : 0.191487 model2 loss : 0.211931
[00:25:51.790] iteration 26863 : model1 loss : 0.250589 model2 loss : 0.260902
[00:25:52.127] iteration 26864 : model1 loss : 0.322169 model2 loss : 0.321376
[00:25:52.458] iteration 26865 : model1 loss : 0.145744 model2 loss : 0.159444
[00:25:52.797] iteration 26866 : model1 loss : 0.194264 model2 loss : 0.233689
[00:25:53.136] iteration 26867 : model1 loss : 0.095383 model2 loss : 0.112578
[00:25:53.468] iteration 26868 : model1 loss : 0.161898 model2 loss : 0.189725
[00:25:53.806] iteration 26869 : model1 loss : 0.188712 model2 loss : 0.210175
[00:25:54.138] iteration 26870 : model1 loss : 0.199326 model2 loss : 0.247154
[00:25:54.474] iteration 26871 : model1 loss : 0.080290 model2 loss : 0.102381
[00:25:54.810] iteration 26872 : model1 loss : 0.267083 model2 loss : 0.296012
[00:25:55.150] iteration 26873 : model1 loss : 0.258058 model2 loss : 0.273626
[00:25:55.491] iteration 26874 : model1 loss : 0.145598 model2 loss : 0.192324
[00:25:55.826] iteration 26875 : model1 loss : 0.158877 model2 loss : 0.202095
[00:25:56.164] iteration 26876 : model1 loss : 0.279749 model2 loss : 0.303120
[00:25:56.499] iteration 26877 : model1 loss : 0.081225 model2 loss : 0.097632
[00:25:56.835] iteration 26878 : model1 loss : 0.078649 model2 loss : 0.144105
[00:25:57.172] iteration 26879 : model1 loss : 0.079923 model2 loss : 0.104609
[00:25:57.509] iteration 26880 : model1 loss : 0.247147 model2 loss : 0.264620
[00:25:57.845] iteration 26881 : model1 loss : 0.088789 model2 loss : 0.096208
[00:25:58.181] iteration 26882 : model1 loss : 0.182194 model2 loss : 0.228310
[00:25:58.517] iteration 26883 : model1 loss : 0.094094 model2 loss : 0.123091
[00:25:58.852] iteration 26884 : model1 loss : 0.101916 model2 loss : 0.126080
[00:25:59.192] iteration 26885 : model1 loss : 0.186960 model2 loss : 0.238803
[00:25:59.532] iteration 26886 : model1 loss : 0.309848 model2 loss : 0.401079
[00:25:59.869] iteration 26887 : model1 loss : 0.174426 model2 loss : 0.213100
[00:26:00.206] iteration 26888 : model1 loss : 0.181587 model2 loss : 0.265396
[00:26:00.538] iteration 26889 : model1 loss : 0.163051 model2 loss : 0.234279
[00:26:00.874] iteration 26890 : model1 loss : 0.193978 model2 loss : 0.204678
[00:26:01.206] iteration 26891 : model1 loss : 0.228045 model2 loss : 0.244752
[00:26:01.542] iteration 26892 : model1 loss : 0.262234 model2 loss : 0.305469
[00:26:01.878] iteration 26893 : model1 loss : 0.229273 model2 loss : 0.251797
[00:26:02.212] iteration 26894 : model1 loss : 0.157378 model2 loss : 0.180076
[00:26:02.545] iteration 26895 : model1 loss : 0.156222 model2 loss : 0.155112
[00:26:02.879] iteration 26896 : model1 loss : 0.179333 model2 loss : 0.226388
[00:26:03.214] iteration 26897 : model1 loss : 0.256657 model2 loss : 0.309313
[00:26:03.555] iteration 26898 : model1 loss : 0.331753 model2 loss : 0.373003
[00:26:03.894] iteration 26899 : model1 loss : 0.181472 model2 loss : 0.253997
[00:26:04.257] iteration 26900 : model1 loss : 0.172613 model2 loss : 0.194620
[00:26:04.914] iteration 26901 : model1 loss : 0.156821 model2 loss : 0.246505
[00:26:05.252] iteration 26902 : model1 loss : 0.140841 model2 loss : 0.142544
[00:26:05.593] iteration 26903 : model1 loss : 0.173050 model2 loss : 0.204052
[00:26:05.931] iteration 26904 : model1 loss : 0.170064 model2 loss : 0.179541
[00:26:06.266] iteration 26905 : model1 loss : 0.058172 model2 loss : 0.099473
[00:26:06.607] iteration 26906 : model1 loss : 0.122597 model2 loss : 0.132831
[00:26:06.945] iteration 26907 : model1 loss : 0.151602 model2 loss : 0.163611
[00:26:07.287] iteration 26908 : model1 loss : 0.079151 model2 loss : 0.087704
[00:26:07.629] iteration 26909 : model1 loss : 0.090105 model2 loss : 0.139424
[00:26:07.965] iteration 26910 : model1 loss : 0.118376 model2 loss : 0.168669
[00:26:08.299] iteration 26911 : model1 loss : 0.176427 model2 loss : 0.172354
[00:26:08.634] iteration 26912 : model1 loss : 0.173035 model2 loss : 0.202143
[00:26:08.966] iteration 26913 : model1 loss : 0.187996 model2 loss : 0.208301
[00:26:09.303] iteration 26914 : model1 loss : 0.331384 model2 loss : 0.356675
[00:26:09.640] iteration 26915 : model1 loss : 0.244227 model2 loss : 0.265143
[00:26:09.978] iteration 26916 : model1 loss : 0.237692 model2 loss : 0.255158
[00:26:10.321] iteration 26917 : model1 loss : 0.164088 model2 loss : 0.219992
[00:26:10.658] iteration 26918 : model1 loss : 0.153649 model2 loss : 0.188048
[00:26:10.991] iteration 26919 : model1 loss : 0.171467 model2 loss : 0.175193
[00:26:11.327] iteration 26920 : model1 loss : 0.170650 model2 loss : 0.191388
[00:26:11.664] iteration 26921 : model1 loss : 0.203796 model2 loss : 0.273545
[00:26:12.002] iteration 26922 : model1 loss : 0.181557 model2 loss : 0.169130
[00:26:12.336] iteration 26923 : model1 loss : 0.268297 model2 loss : 0.276418
[00:26:12.670] iteration 26924 : model1 loss : 0.174236 model2 loss : 0.168057
[00:26:13.003] iteration 26925 : model1 loss : 0.234961 model2 loss : 0.299848
[00:26:13.339] iteration 26926 : model1 loss : 0.248603 model2 loss : 0.253085
[00:26:13.677] iteration 26927 : model1 loss : 0.197823 model2 loss : 0.201997
[00:26:14.018] iteration 26928 : model1 loss : 0.152906 model2 loss : 0.175371
[00:26:14.359] iteration 26929 : model1 loss : 0.173842 model2 loss : 0.203757
[00:26:14.695] iteration 26930 : model1 loss : 0.173081 model2 loss : 0.169050
[00:26:15.038] iteration 26931 : model1 loss : 0.161938 model2 loss : 0.195895
[00:26:15.376] iteration 26932 : model1 loss : 0.099675 model2 loss : 0.164266
[00:26:15.715] iteration 26933 : model1 loss : 0.183089 model2 loss : 0.194604
[00:26:16.058] iteration 26934 : model1 loss : 0.174002 model2 loss : 0.193265
[00:26:16.401] iteration 26935 : model1 loss : 0.192236 model2 loss : 0.264619
[00:26:16.739] iteration 26936 : model1 loss : 0.244660 model2 loss : 0.265764
[00:26:17.077] iteration 26937 : model1 loss : 0.069799 model2 loss : 0.112591
[00:26:17.416] iteration 26938 : model1 loss : 0.164833 model2 loss : 0.172769
[00:26:17.760] iteration 26939 : model1 loss : 0.095154 model2 loss : 0.179753
[00:26:18.103] iteration 26940 : model1 loss : 0.174721 model2 loss : 0.176334
[00:26:18.439] iteration 26941 : model1 loss : 0.177737 model2 loss : 0.213413
[00:26:18.779] iteration 26942 : model1 loss : 0.086114 model2 loss : 0.109629
[00:26:19.120] iteration 26943 : model1 loss : 0.096558 model2 loss : 0.116847
[00:26:19.458] iteration 26944 : model1 loss : 0.093996 model2 loss : 0.124838
[00:26:19.795] iteration 26945 : model1 loss : 0.063955 model2 loss : 0.123610
[00:26:20.133] iteration 26946 : model1 loss : 0.247536 model2 loss : 0.270116
[00:26:20.472] iteration 26947 : model1 loss : 0.164391 model2 loss : 0.194149
[00:26:20.812] iteration 26948 : model1 loss : 0.088072 model2 loss : 0.120811
[00:26:21.150] iteration 26949 : model1 loss : 0.162527 model2 loss : 0.149708
[00:26:21.492] iteration 26950 : model1 loss : 0.168819 model2 loss : 0.213256
[00:26:22.110] iteration 26951 : model1 loss : 0.083539 model2 loss : 0.146821
[00:26:22.449] iteration 26952 : model1 loss : 0.078991 model2 loss : 0.112643
[00:26:22.787] iteration 26953 : model1 loss : 0.295284 model2 loss : 0.302965
[00:26:23.125] iteration 26954 : model1 loss : 0.315640 model2 loss : 0.332425
[00:26:23.462] iteration 26955 : model1 loss : 0.165212 model2 loss : 0.179342
[00:26:23.803] iteration 26956 : model1 loss : 0.158251 model2 loss : 0.186729
[00:26:24.141] iteration 26957 : model1 loss : 0.150063 model2 loss : 0.186320
[00:26:24.479] iteration 26958 : model1 loss : 0.067855 model2 loss : 0.170351
[00:26:24.816] iteration 26959 : model1 loss : 0.180998 model2 loss : 0.230718
[00:26:25.154] iteration 26960 : model1 loss : 0.150287 model2 loss : 0.167273
[00:26:25.496] iteration 26961 : model1 loss : 0.161021 model2 loss : 0.195345
[00:26:25.833] iteration 26962 : model1 loss : 0.262918 model2 loss : 0.279027
[00:26:26.169] iteration 26963 : model1 loss : 0.156962 model2 loss : 0.202430
[00:26:26.510] iteration 26964 : model1 loss : 0.094138 model2 loss : 0.176652
[00:26:26.848] iteration 26965 : model1 loss : 0.227410 model2 loss : 0.228055
[00:26:27.187] iteration 26966 : model1 loss : 0.169926 model2 loss : 0.210847
[00:26:27.532] iteration 26967 : model1 loss : 0.151160 model2 loss : 0.179147
[00:26:27.874] iteration 26968 : model1 loss : 0.188706 model2 loss : 0.212620
[00:26:28.219] iteration 26969 : model1 loss : 0.156585 model2 loss : 0.172792
[00:26:28.560] iteration 26970 : model1 loss : 0.258189 model2 loss : 0.282810
[00:26:28.897] iteration 26971 : model1 loss : 0.194863 model2 loss : 0.220254
[00:26:29.236] iteration 26972 : model1 loss : 0.163140 model2 loss : 0.201519
[00:26:29.580] iteration 26973 : model1 loss : 0.245353 model2 loss : 0.286714
[00:26:29.918] iteration 26974 : model1 loss : 0.207975 model2 loss : 0.198350
[00:26:30.257] iteration 26975 : model1 loss : 0.166549 model2 loss : 0.199759
[00:26:30.594] iteration 26976 : model1 loss : 0.261607 model2 loss : 0.270879
[00:26:30.931] iteration 26977 : model1 loss : 0.236439 model2 loss : 0.254542
[00:26:31.272] iteration 26978 : model1 loss : 0.209281 model2 loss : 0.249736
[00:26:31.609] iteration 26979 : model1 loss : 0.245135 model2 loss : 0.254636
[00:26:31.948] iteration 26980 : model1 loss : 0.106507 model2 loss : 0.196909
[00:26:32.286] iteration 26981 : model1 loss : 0.182582 model2 loss : 0.196903
[00:26:32.624] iteration 26982 : model1 loss : 0.256283 model2 loss : 0.283855
[00:26:32.966] iteration 26983 : model1 loss : 0.176028 model2 loss : 0.201791
[00:26:33.303] iteration 26984 : model1 loss : 0.232359 model2 loss : 0.250249
[00:26:33.639] iteration 26985 : model1 loss : 0.160955 model2 loss : 0.185736
[00:26:33.979] iteration 26986 : model1 loss : 0.169475 model2 loss : 0.217923
[00:26:34.317] iteration 26987 : model1 loss : 0.180537 model2 loss : 0.190171
[00:26:34.656] iteration 26988 : model1 loss : 0.089148 model2 loss : 0.132940
[00:26:34.993] iteration 26989 : model1 loss : 0.134741 model2 loss : 0.167173
[00:26:35.336] iteration 26990 : model1 loss : 0.177174 model2 loss : 0.237506
[00:26:35.679] iteration 26991 : model1 loss : 0.180812 model2 loss : 0.193204
[00:26:36.017] iteration 26992 : model1 loss : 0.266820 model2 loss : 0.284042
[00:26:36.354] iteration 26993 : model1 loss : 0.105309 model2 loss : 0.141068
[00:26:36.692] iteration 26994 : model1 loss : 0.171078 model2 loss : 0.168475
[00:26:37.030] iteration 26995 : model1 loss : 0.155484 model2 loss : 0.169056
[00:26:37.371] iteration 26996 : model1 loss : 0.183823 model2 loss : 0.180592
[00:26:37.712] iteration 26997 : model1 loss : 0.263413 model2 loss : 0.321256
[00:26:38.052] iteration 26998 : model1 loss : 0.091254 model2 loss : 0.163827
[00:26:38.393] iteration 26999 : model1 loss : 0.311300 model2 loss : 0.293946
[00:26:38.736] iteration 27000 : model1 loss : 0.119338 model2 loss : 0.179242
[00:27:48.875] iteration 27000 : model1_mean_dice : 0.786020 model1_mean_hd95 : 10.895728
[00:28:40.471] iteration 27000 : model2_mean_dice : 0.664868 model2_mean_hd95 : 12.622538
[00:28:40.585] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_27000.pth
[00:28:40.605] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_27000.pth
[00:28:40.942] iteration 27001 : model1 loss : 0.059404 model2 loss : 0.086748
[00:28:41.268] iteration 27002 : model1 loss : 0.119521 model2 loss : 0.165797
[00:28:41.596] iteration 27003 : model1 loss : 0.257289 model2 loss : 0.260085
[00:28:41.923] iteration 27004 : model1 loss : 0.179396 model2 loss : 0.187110
[00:28:42.249] iteration 27005 : model1 loss : 0.274801 model2 loss : 0.278161
[00:28:42.577] iteration 27006 : model1 loss : 0.192639 model2 loss : 0.218495
[00:28:42.903] iteration 27007 : model1 loss : 0.080276 model2 loss : 0.181748
[00:28:43.237] iteration 27008 : model1 loss : 0.203013 model2 loss : 0.243334
[00:28:43.570] iteration 27009 : model1 loss : 0.113176 model2 loss : 0.141621
[00:28:43.896] iteration 27010 : model1 loss : 0.168116 model2 loss : 0.234309
[00:28:44.222] iteration 27011 : model1 loss : 0.214571 model2 loss : 0.206194
[00:28:44.549] iteration 27012 : model1 loss : 0.112474 model2 loss : 0.168982
[00:28:44.876] iteration 27013 : model1 loss : 0.304248 model2 loss : 0.308881
[00:28:45.203] iteration 27014 : model1 loss : 0.110669 model2 loss : 0.152828
[00:28:45.529] iteration 27015 : model1 loss : 0.259789 model2 loss : 0.329542
[00:28:45.855] iteration 27016 : model1 loss : 0.154175 model2 loss : 0.191062
[00:28:46.182] iteration 27017 : model1 loss : 0.146379 model2 loss : 0.181474
[00:28:46.509] iteration 27018 : model1 loss : 0.121443 model2 loss : 0.404480
[00:28:46.836] iteration 27019 : model1 loss : 0.163032 model2 loss : 0.234136
[00:28:47.162] iteration 27020 : model1 loss : 0.161298 model2 loss : 0.166872
[00:28:47.490] iteration 27021 : model1 loss : 0.264054 model2 loss : 0.285368
[00:28:47.817] iteration 27022 : model1 loss : 0.068159 model2 loss : 0.093834
[00:28:48.144] iteration 27023 : model1 loss : 0.200446 model2 loss : 0.209939
[00:28:48.472] iteration 27024 : model1 loss : 0.196412 model2 loss : 0.212987
[00:28:48.800] iteration 27025 : model1 loss : 0.105131 model2 loss : 0.147688
[00:28:49.127] iteration 27026 : model1 loss : 0.170098 model2 loss : 0.190709
[00:28:49.454] iteration 27027 : model1 loss : 0.231493 model2 loss : 0.233204
[00:28:49.781] iteration 27028 : model1 loss : 0.382400 model2 loss : 0.386866
[00:28:50.108] iteration 27029 : model1 loss : 0.291920 model2 loss : 0.302688
[00:28:50.436] iteration 27030 : model1 loss : 0.279211 model2 loss : 0.333076
[00:28:50.763] iteration 27031 : model1 loss : 0.184709 model2 loss : 0.307651
[00:28:51.091] iteration 27032 : model1 loss : 0.244026 model2 loss : 0.277991
[00:28:51.418] iteration 27033 : model1 loss : 0.103639 model2 loss : 0.133075
[00:28:51.746] iteration 27034 : model1 loss : 0.179110 model2 loss : 0.185569
[00:28:52.072] iteration 27035 : model1 loss : 0.163806 model2 loss : 0.189911
[00:28:52.401] iteration 27036 : model1 loss : 0.150410 model2 loss : 0.181655
[00:28:52.728] iteration 27037 : model1 loss : 0.195035 model2 loss : 0.220811
[00:28:53.056] iteration 27038 : model1 loss : 0.240317 model2 loss : 0.277241
[00:28:53.385] iteration 27039 : model1 loss : 0.063941 model2 loss : 0.064522
[00:28:53.711] iteration 27040 : model1 loss : 0.098209 model2 loss : 0.079499
[00:28:54.039] iteration 27041 : model1 loss : 0.193346 model2 loss : 0.203917
[00:28:54.367] iteration 27042 : model1 loss : 0.185948 model2 loss : 0.193135
[00:28:54.695] iteration 27043 : model1 loss : 0.137659 model2 loss : 0.176252
[00:28:55.022] iteration 27044 : model1 loss : 0.183375 model2 loss : 0.187519
[00:28:55.350] iteration 27045 : model1 loss : 0.084818 model2 loss : 0.117413
[00:28:55.677] iteration 27046 : model1 loss : 0.250693 model2 loss : 0.255572
[00:28:56.004] iteration 27047 : model1 loss : 0.083687 model2 loss : 0.078159
[00:28:56.332] iteration 27048 : model1 loss : 0.256197 model2 loss : 0.263173
[00:28:56.659] iteration 27049 : model1 loss : 0.197284 model2 loss : 0.266561
[00:28:56.993] iteration 27050 : model1 loss : 0.186862 model2 loss : 0.166043
[00:28:57.552] iteration 27051 : model1 loss : 0.174101 model2 loss : 0.228875
[00:28:57.879] iteration 27052 : model1 loss : 0.160351 model2 loss : 0.183639
[00:28:58.206] iteration 27053 : model1 loss : 0.239527 model2 loss : 0.283423
[00:28:58.533] iteration 27054 : model1 loss : 0.195727 model2 loss : 0.171600
[00:28:58.860] iteration 27055 : model1 loss : 0.244295 model2 loss : 0.249169
[00:28:59.187] iteration 27056 : model1 loss : 0.213970 model2 loss : 0.306900
[00:28:59.515] iteration 27057 : model1 loss : 0.191566 model2 loss : 0.215845
[00:28:59.842] iteration 27058 : model1 loss : 0.084073 model2 loss : 0.114601
[00:29:00.170] iteration 27059 : model1 loss : 0.275294 model2 loss : 0.313377
[00:29:00.496] iteration 27060 : model1 loss : 0.091022 model2 loss : 0.153232
[00:29:00.824] iteration 27061 : model1 loss : 0.081666 model2 loss : 0.124848
[00:29:01.151] iteration 27062 : model1 loss : 0.104107 model2 loss : 0.129858
[00:29:01.478] iteration 27063 : model1 loss : 0.113978 model2 loss : 0.412151
[00:29:01.805] iteration 27064 : model1 loss : 0.137642 model2 loss : 0.107563
[00:29:02.132] iteration 27065 : model1 loss : 0.130696 model2 loss : 0.218618
[00:29:02.460] iteration 27066 : model1 loss : 0.175284 model2 loss : 0.225878
[00:29:02.788] iteration 27067 : model1 loss : 0.194144 model2 loss : 0.235235
[00:29:03.115] iteration 27068 : model1 loss : 0.242252 model2 loss : 0.270364
[00:29:03.443] iteration 27069 : model1 loss : 0.121540 model2 loss : 0.159790
[00:29:03.770] iteration 27070 : model1 loss : 0.081595 model2 loss : 0.088379
[00:29:04.097] iteration 27071 : model1 loss : 0.164628 model2 loss : 0.177258
[00:29:04.425] iteration 27072 : model1 loss : 0.144382 model2 loss : 0.221368
[00:29:04.752] iteration 27073 : model1 loss : 0.240328 model2 loss : 0.304938
[00:29:05.080] iteration 27074 : model1 loss : 0.073691 model2 loss : 0.105928
[00:29:05.407] iteration 27075 : model1 loss : 0.096214 model2 loss : 0.162929
[00:29:05.735] iteration 27076 : model1 loss : 0.106491 model2 loss : 0.096886
[00:29:06.063] iteration 27077 : model1 loss : 0.174841 model2 loss : 0.251147
[00:29:06.391] iteration 27078 : model1 loss : 0.262946 model2 loss : 0.296993
[00:29:06.718] iteration 27079 : model1 loss : 0.178326 model2 loss : 0.173540
[00:29:07.046] iteration 27080 : model1 loss : 0.151463 model2 loss : 0.166184
[00:29:07.374] iteration 27081 : model1 loss : 0.174991 model2 loss : 0.196591
[00:29:07.706] iteration 27082 : model1 loss : 0.292309 model2 loss : 0.344908
[00:29:08.033] iteration 27083 : model1 loss : 0.102191 model2 loss : 0.098473
[00:29:08.361] iteration 27084 : model1 loss : 0.255352 model2 loss : 0.277862
[00:29:08.688] iteration 27085 : model1 loss : 0.164289 model2 loss : 0.196391
[00:29:09.016] iteration 27086 : model1 loss : 0.198161 model2 loss : 0.212483
[00:29:09.347] iteration 27087 : model1 loss : 0.183748 model2 loss : 0.207746
[00:29:09.674] iteration 27088 : model1 loss : 0.101541 model2 loss : 0.235164
[00:29:10.007] iteration 27089 : model1 loss : 0.186860 model2 loss : 0.262442
[00:29:10.335] iteration 27090 : model1 loss : 0.243827 model2 loss : 0.268654
[00:29:10.663] iteration 27091 : model1 loss : 0.204030 model2 loss : 0.193795
[00:29:10.990] iteration 27092 : model1 loss : 0.264026 model2 loss : 0.302221
[00:29:11.318] iteration 27093 : model1 loss : 0.173301 model2 loss : 0.203788
[00:29:11.646] iteration 27094 : model1 loss : 0.204063 model2 loss : 0.216653
[00:29:11.974] iteration 27095 : model1 loss : 0.166908 model2 loss : 0.196753
[00:29:12.302] iteration 27096 : model1 loss : 0.097223 model2 loss : 0.138776
[00:29:12.630] iteration 27097 : model1 loss : 0.159702 model2 loss : 0.171470
[00:29:12.957] iteration 27098 : model1 loss : 0.185256 model2 loss : 0.277345
[00:29:13.292] iteration 27099 : model1 loss : 0.192825 model2 loss : 0.191392
[00:29:13.627] iteration 27100 : model1 loss : 0.107741 model2 loss : 0.404731
[00:29:14.161] iteration 27101 : model1 loss : 0.171741 model2 loss : 0.228375
[00:29:14.489] iteration 27102 : model1 loss : 0.228382 model2 loss : 0.236735
[00:29:14.822] iteration 27103 : model1 loss : 0.200318 model2 loss : 0.213577
[00:29:15.150] iteration 27104 : model1 loss : 0.203622 model2 loss : 0.290882
[00:29:15.478] iteration 27105 : model1 loss : 0.163128 model2 loss : 0.205780
[00:29:15.806] iteration 27106 : model1 loss : 0.234736 model2 loss : 0.278387
[00:29:16.134] iteration 27107 : model1 loss : 0.244200 model2 loss : 0.255453
[00:29:16.462] iteration 27108 : model1 loss : 0.249343 model2 loss : 0.273090
[00:29:16.790] iteration 27109 : model1 loss : 0.181660 model2 loss : 0.206453
[00:29:17.118] iteration 27110 : model1 loss : 0.234686 model2 loss : 0.248340
[00:29:17.444] iteration 27111 : model1 loss : 0.249738 model2 loss : 0.268415
[00:29:17.772] iteration 27112 : model1 loss : 0.269745 model2 loss : 0.280964
[00:29:18.099] iteration 27113 : model1 loss : 0.328333 model2 loss : 0.327799
[00:29:18.426] iteration 27114 : model1 loss : 0.161979 model2 loss : 0.162790
[00:29:18.753] iteration 27115 : model1 loss : 0.181191 model2 loss : 0.210514
[00:29:19.081] iteration 27116 : model1 loss : 0.153227 model2 loss : 0.146253
[00:29:19.412] iteration 27117 : model1 loss : 0.129614 model2 loss : 0.202908
[00:29:19.740] iteration 27118 : model1 loss : 0.315729 model2 loss : 0.342788
[00:29:20.068] iteration 27119 : model1 loss : 0.097574 model2 loss : 0.150720
[00:29:20.395] iteration 27120 : model1 loss : 0.090944 model2 loss : 0.100578
[00:29:20.722] iteration 27121 : model1 loss : 0.129093 model2 loss : 0.202538
[00:29:21.051] iteration 27122 : model1 loss : 0.165218 model2 loss : 0.182439
[00:29:21.378] iteration 27123 : model1 loss : 0.153519 model2 loss : 0.183094
[00:29:21.706] iteration 27124 : model1 loss : 0.113069 model2 loss : 0.417633
[00:29:22.033] iteration 27125 : model1 loss : 0.253913 model2 loss : 0.288031
[00:29:22.361] iteration 27126 : model1 loss : 0.201180 model2 loss : 0.217208
[00:29:22.688] iteration 27127 : model1 loss : 0.247506 model2 loss : 0.297653
[00:29:23.015] iteration 27128 : model1 loss : 0.154481 model2 loss : 0.213101
[00:29:23.342] iteration 27129 : model1 loss : 0.152261 model2 loss : 0.155436
[00:29:23.669] iteration 27130 : model1 loss : 0.163541 model2 loss : 0.217665
[00:29:23.996] iteration 27131 : model1 loss : 0.175129 model2 loss : 0.199498
[00:29:24.326] iteration 27132 : model1 loss : 0.167194 model2 loss : 0.199359
[00:29:24.654] iteration 27133 : model1 loss : 0.313493 model2 loss : 0.301798
[00:29:24.982] iteration 27134 : model1 loss : 0.190767 model2 loss : 0.190794
[00:29:25.309] iteration 27135 : model1 loss : 0.085822 model2 loss : 0.096364
[00:29:25.636] iteration 27136 : model1 loss : 0.101505 model2 loss : 0.170829
[00:29:25.963] iteration 27137 : model1 loss : 0.248065 model2 loss : 0.274703
[00:29:26.290] iteration 27138 : model1 loss : 0.136165 model2 loss : 0.164509
[00:29:26.618] iteration 27139 : model1 loss : 0.269450 model2 loss : 0.296613
[00:29:26.950] iteration 27140 : model1 loss : 0.154466 model2 loss : 0.220917
[00:29:27.277] iteration 27141 : model1 loss : 0.169702 model2 loss : 0.187973
[00:29:27.605] iteration 27142 : model1 loss : 0.163766 model2 loss : 0.201176
[00:29:27.932] iteration 27143 : model1 loss : 0.269883 model2 loss : 0.283165
[00:29:28.260] iteration 27144 : model1 loss : 0.084339 model2 loss : 0.133119
[00:29:28.741] iteration 27145 : model1 loss : 0.265184 model2 loss : 0.282712
[00:29:29.068] iteration 27146 : model1 loss : 0.263039 model2 loss : 0.280647
[00:29:29.395] iteration 27147 : model1 loss : 0.175687 model2 loss : 0.183529
[00:29:29.723] iteration 27148 : model1 loss : 0.184756 model2 loss : 0.187522
[00:29:30.053] iteration 27149 : model1 loss : 0.072882 model2 loss : 0.091155
[00:29:30.381] iteration 27150 : model1 loss : 0.163203 model2 loss : 0.178356
[00:29:30.966] iteration 27151 : model1 loss : 0.129698 model2 loss : 0.147745
[00:29:31.299] iteration 27152 : model1 loss : 0.165502 model2 loss : 0.185740
[00:29:31.627] iteration 27153 : model1 loss : 0.072814 model2 loss : 0.154110
[00:29:31.954] iteration 27154 : model1 loss : 0.134583 model2 loss : 0.139883
[00:29:32.281] iteration 27155 : model1 loss : 0.156040 model2 loss : 0.188431
[00:29:32.609] iteration 27156 : model1 loss : 0.105699 model2 loss : 0.112116
[00:29:32.936] iteration 27157 : model1 loss : 0.175034 model2 loss : 0.186297
[00:29:33.264] iteration 27158 : model1 loss : 0.171533 model2 loss : 0.230281
[00:29:33.594] iteration 27159 : model1 loss : 0.157422 model2 loss : 0.174429
[00:29:33.922] iteration 27160 : model1 loss : 0.287381 model2 loss : 0.319955
[00:29:34.252] iteration 27161 : model1 loss : 0.195494 model2 loss : 0.249482
[00:29:34.580] iteration 27162 : model1 loss : 0.175089 model2 loss : 0.180118
[00:29:34.908] iteration 27163 : model1 loss : 0.092285 model2 loss : 0.119237
[00:29:35.236] iteration 27164 : model1 loss : 0.148281 model2 loss : 0.165122
[00:29:35.565] iteration 27165 : model1 loss : 0.271416 model2 loss : 0.312269
[00:29:35.893] iteration 27166 : model1 loss : 0.247708 model2 loss : 0.295122
[00:29:36.221] iteration 27167 : model1 loss : 0.187751 model2 loss : 0.215014
[00:29:36.550] iteration 27168 : model1 loss : 0.199383 model2 loss : 0.280524
[00:29:36.878] iteration 27169 : model1 loss : 0.185170 model2 loss : 0.200817
[00:29:37.206] iteration 27170 : model1 loss : 0.073388 model2 loss : 0.127468
[00:29:37.535] iteration 27171 : model1 loss : 0.132392 model2 loss : 0.131699
[00:29:37.863] iteration 27172 : model1 loss : 0.319079 model2 loss : 0.329852
[00:29:38.191] iteration 27173 : model1 loss : 0.182224 model2 loss : 0.275470
[00:29:38.520] iteration 27174 : model1 loss : 0.151449 model2 loss : 0.145548
[00:29:38.848] iteration 27175 : model1 loss : 0.174610 model2 loss : 0.242110
[00:29:39.176] iteration 27176 : model1 loss : 0.245766 model2 loss : 0.251916
[00:29:39.503] iteration 27177 : model1 loss : 0.184363 model2 loss : 0.195095
[00:29:39.833] iteration 27178 : model1 loss : 0.275368 model2 loss : 0.315872
[00:29:40.161] iteration 27179 : model1 loss : 0.164423 model2 loss : 0.185713
[00:29:40.489] iteration 27180 : model1 loss : 0.244501 model2 loss : 0.318040
[00:29:40.817] iteration 27181 : model1 loss : 0.316809 model2 loss : 0.326799
[00:29:41.145] iteration 27182 : model1 loss : 0.254544 model2 loss : 0.280637
[00:29:41.474] iteration 27183 : model1 loss : 0.177461 model2 loss : 0.202167
[00:29:41.802] iteration 27184 : model1 loss : 0.178599 model2 loss : 0.214334
[00:29:42.130] iteration 27185 : model1 loss : 0.197793 model2 loss : 0.182473
[00:29:42.458] iteration 27186 : model1 loss : 0.250309 model2 loss : 0.267702
[00:29:42.786] iteration 27187 : model1 loss : 0.183445 model2 loss : 0.233026
[00:29:43.114] iteration 27188 : model1 loss : 0.063921 model2 loss : 0.058238
[00:29:43.443] iteration 27189 : model1 loss : 0.159922 model2 loss : 0.154046
[00:29:43.771] iteration 27190 : model1 loss : 0.186385 model2 loss : 0.207541
[00:29:44.097] iteration 27191 : model1 loss : 0.193712 model2 loss : 0.186231
[00:29:44.424] iteration 27192 : model1 loss : 0.134046 model2 loss : 0.130251
[00:29:44.751] iteration 27193 : model1 loss : 0.161437 model2 loss : 0.179253
[00:29:45.078] iteration 27194 : model1 loss : 0.163453 model2 loss : 0.185450
[00:29:45.406] iteration 27195 : model1 loss : 0.199395 model2 loss : 0.248004
[00:29:45.733] iteration 27196 : model1 loss : 0.141416 model2 loss : 0.186356
[00:29:46.058] iteration 27197 : model1 loss : 0.083827 model2 loss : 0.129770
[00:29:46.385] iteration 27198 : model1 loss : 0.173306 model2 loss : 0.171310
[00:29:46.716] iteration 27199 : model1 loss : 0.067999 model2 loss : 0.096024
[00:29:47.044] iteration 27200 : model1 loss : 0.166029 model2 loss : 0.216793
[00:29:47.603] iteration 27201 : model1 loss : 0.251879 model2 loss : 0.258097
[00:29:47.931] iteration 27202 : model1 loss : 0.286012 model2 loss : 0.312454
[00:29:48.259] iteration 27203 : model1 loss : 0.143852 model2 loss : 0.169299
[00:29:48.588] iteration 27204 : model1 loss : 0.164545 model2 loss : 0.187886
[00:29:48.918] iteration 27205 : model1 loss : 0.235989 model2 loss : 0.233071
[00:29:49.247] iteration 27206 : model1 loss : 0.173554 model2 loss : 0.218708
[00:29:49.576] iteration 27207 : model1 loss : 0.274039 model2 loss : 0.253893
[00:29:49.909] iteration 27208 : model1 loss : 0.153422 model2 loss : 0.192674
[00:29:50.237] iteration 27209 : model1 loss : 0.153696 model2 loss : 0.157179
[00:29:50.565] iteration 27210 : model1 loss : 0.190029 model2 loss : 0.224007
[00:29:50.892] iteration 27211 : model1 loss : 0.150349 model2 loss : 0.159303
[00:29:51.220] iteration 27212 : model1 loss : 0.166571 model2 loss : 0.217662
[00:29:51.548] iteration 27213 : model1 loss : 0.166062 model2 loss : 0.187446
[00:29:51.877] iteration 27214 : model1 loss : 0.154412 model2 loss : 0.176525
[00:29:52.206] iteration 27215 : model1 loss : 0.260285 model2 loss : 0.278883
[00:29:52.533] iteration 27216 : model1 loss : 0.189286 model2 loss : 0.338107
[00:29:52.862] iteration 27217 : model1 loss : 0.164489 model2 loss : 0.200851
[00:29:53.190] iteration 27218 : model1 loss : 0.265753 model2 loss : 0.260314
[00:29:53.515] iteration 27219 : model1 loss : 0.157770 model2 loss : 0.171215
[00:29:53.842] iteration 27220 : model1 loss : 0.260323 model2 loss : 0.255261
[00:29:54.167] iteration 27221 : model1 loss : 0.066682 model2 loss : 0.103216
[00:29:54.494] iteration 27222 : model1 loss : 0.265832 model2 loss : 0.283653
[00:29:54.819] iteration 27223 : model1 loss : 0.069763 model2 loss : 0.095308
[00:29:55.145] iteration 27224 : model1 loss : 0.242239 model2 loss : 0.250708
[00:29:55.471] iteration 27225 : model1 loss : 0.183239 model2 loss : 0.216793
[00:29:55.797] iteration 27226 : model1 loss : 0.235714 model2 loss : 0.243238
[00:29:56.122] iteration 27227 : model1 loss : 0.230496 model2 loss : 0.306619
[00:29:56.448] iteration 27228 : model1 loss : 0.111688 model2 loss : 0.149090
[00:29:56.774] iteration 27229 : model1 loss : 0.236905 model2 loss : 0.240060
[00:29:57.100] iteration 27230 : model1 loss : 0.187425 model2 loss : 0.282554
[00:29:57.426] iteration 27231 : model1 loss : 0.097756 model2 loss : 0.152851
[00:29:57.752] iteration 27232 : model1 loss : 0.219089 model2 loss : 0.217943
[00:29:58.078] iteration 27233 : model1 loss : 0.256919 model2 loss : 0.291171
[00:29:58.407] iteration 27234 : model1 loss : 0.096678 model2 loss : 0.122264
[00:29:58.738] iteration 27235 : model1 loss : 0.088364 model2 loss : 0.116104
[00:29:59.067] iteration 27236 : model1 loss : 0.090657 model2 loss : 0.120222
[00:29:59.396] iteration 27237 : model1 loss : 0.096319 model2 loss : 0.117808
[00:29:59.726] iteration 27238 : model1 loss : 0.229561 model2 loss : 0.262116
[00:30:00.054] iteration 27239 : model1 loss : 0.259474 model2 loss : 0.275271
[00:30:00.383] iteration 27240 : model1 loss : 0.125084 model2 loss : 0.116021
[00:30:00.712] iteration 27241 : model1 loss : 0.166128 model2 loss : 0.241130
[00:30:01.041] iteration 27242 : model1 loss : 0.226373 model2 loss : 0.244209
[00:30:01.370] iteration 27243 : model1 loss : 0.162069 model2 loss : 0.216025
[00:30:01.697] iteration 27244 : model1 loss : 0.345260 model2 loss : 0.355212
[00:30:02.027] iteration 27245 : model1 loss : 0.200691 model2 loss : 0.224272
[00:30:02.355] iteration 27246 : model1 loss : 0.172233 model2 loss : 0.182499
[00:30:02.682] iteration 27247 : model1 loss : 0.164104 model2 loss : 0.192431
[00:30:03.009] iteration 27248 : model1 loss : 0.078378 model2 loss : 0.119912
[00:30:03.337] iteration 27249 : model1 loss : 0.185899 model2 loss : 0.234737
[00:30:03.665] iteration 27250 : model1 loss : 0.092239 model2 loss : 0.124506
[00:30:04.909] iteration 27251 : model1 loss : 0.138091 model2 loss : 0.170718
[00:30:05.237] iteration 27252 : model1 loss : 0.266819 model2 loss : 0.286372
[00:30:05.565] iteration 27253 : model1 loss : 0.070863 model2 loss : 0.108330
[00:30:05.894] iteration 27254 : model1 loss : 0.227690 model2 loss : 0.290971
[00:30:06.222] iteration 27255 : model1 loss : 0.254355 model2 loss : 0.277855
[00:30:06.551] iteration 27256 : model1 loss : 0.257537 model2 loss : 0.270800
[00:30:06.880] iteration 27257 : model1 loss : 0.061759 model2 loss : 0.099302
[00:30:07.209] iteration 27258 : model1 loss : 0.193594 model2 loss : 0.315620
[00:30:07.538] iteration 27259 : model1 loss : 0.251030 model2 loss : 0.265846
[00:30:07.866] iteration 27260 : model1 loss : 0.261240 model2 loss : 0.274843
[00:30:08.195] iteration 27261 : model1 loss : 0.162858 model2 loss : 0.166344
[00:30:08.523] iteration 27262 : model1 loss : 0.075847 model2 loss : 0.176617
[00:30:08.853] iteration 27263 : model1 loss : 0.096699 model2 loss : 0.115187
[00:30:09.183] iteration 27264 : model1 loss : 0.094286 model2 loss : 0.120972
[00:30:09.511] iteration 27265 : model1 loss : 0.098132 model2 loss : 0.149347
[00:30:09.839] iteration 27266 : model1 loss : 0.107812 model2 loss : 0.127918
[00:30:10.167] iteration 27267 : model1 loss : 0.058716 model2 loss : 0.091401
[00:30:10.493] iteration 27268 : model1 loss : 0.193872 model2 loss : 0.204674
[00:30:10.819] iteration 27269 : model1 loss : 0.274280 model2 loss : 0.266254
[00:30:11.144] iteration 27270 : model1 loss : 0.074517 model2 loss : 0.106766
[00:30:11.470] iteration 27271 : model1 loss : 0.111712 model2 loss : 0.160814
[00:30:11.800] iteration 27272 : model1 loss : 0.251745 model2 loss : 0.330969
[00:30:12.123] iteration 27273 : model1 loss : 0.261405 model2 loss : 0.274239
[00:30:12.448] iteration 27274 : model1 loss : 0.175873 model2 loss : 0.213164
[00:30:12.775] iteration 27275 : model1 loss : 0.176827 model2 loss : 0.182701
[00:30:13.100] iteration 27276 : model1 loss : 0.158909 model2 loss : 0.184448
[00:30:13.426] iteration 27277 : model1 loss : 0.122999 model2 loss : 0.145609
[00:30:13.752] iteration 27278 : model1 loss : 0.405856 model2 loss : 0.431475
[00:30:14.078] iteration 27279 : model1 loss : 0.260926 model2 loss : 0.287477
[00:30:14.403] iteration 27280 : model1 loss : 0.247323 model2 loss : 0.288830
[00:30:14.729] iteration 27281 : model1 loss : 0.161533 model2 loss : 0.173142
[00:30:15.055] iteration 27282 : model1 loss : 0.205345 model2 loss : 0.230940
[00:30:15.381] iteration 27283 : model1 loss : 0.169309 model2 loss : 0.184198
[00:30:15.706] iteration 27284 : model1 loss : 0.119800 model2 loss : 0.133278
[00:30:16.032] iteration 27285 : model1 loss : 0.247538 model2 loss : 0.300845
[00:30:16.359] iteration 27286 : model1 loss : 0.280766 model2 loss : 0.292844
[00:30:16.685] iteration 27287 : model1 loss : 0.191892 model2 loss : 0.270407
[00:30:17.012] iteration 27288 : model1 loss : 0.181255 model2 loss : 0.210148
[00:30:17.338] iteration 27289 : model1 loss : 0.152987 model2 loss : 0.163452
[00:30:17.663] iteration 27290 : model1 loss : 0.249149 model2 loss : 0.271132
[00:30:17.989] iteration 27291 : model1 loss : 0.191199 model2 loss : 0.216701
[00:30:18.315] iteration 27292 : model1 loss : 0.254388 model2 loss : 0.258917
[00:30:18.640] iteration 27293 : model1 loss : 0.171136 model2 loss : 0.191343
[00:30:18.966] iteration 27294 : model1 loss : 0.103297 model2 loss : 0.134275
[00:30:19.294] iteration 27295 : model1 loss : 0.176374 model2 loss : 0.235605
[00:30:19.621] iteration 27296 : model1 loss : 0.250922 model2 loss : 0.281394
[00:30:19.947] iteration 27297 : model1 loss : 0.091859 model2 loss : 0.114445
[00:30:20.273] iteration 27298 : model1 loss : 0.088064 model2 loss : 0.109847
[00:30:20.599] iteration 27299 : model1 loss : 0.330510 model2 loss : 0.308981
[00:30:20.926] iteration 27300 : model1 loss : 0.150778 model2 loss : 0.184956
[00:30:21.453] iteration 27301 : model1 loss : 0.323130 model2 loss : 0.342915
[00:30:21.779] iteration 27302 : model1 loss : 0.095691 model2 loss : 0.127993
[00:30:22.105] iteration 27303 : model1 loss : 0.146127 model2 loss : 0.187950
[00:30:22.432] iteration 27304 : model1 loss : 0.260595 model2 loss : 0.269348
[00:30:22.758] iteration 27305 : model1 loss : 0.163852 model2 loss : 0.236943
[00:30:23.084] iteration 27306 : model1 loss : 0.158559 model2 loss : 0.153518
[00:30:23.411] iteration 27307 : model1 loss : 0.262991 model2 loss : 0.237530
[00:30:23.737] iteration 27308 : model1 loss : 0.261011 model2 loss : 0.300291
[00:30:24.063] iteration 27309 : model1 loss : 0.263604 model2 loss : 0.261651
[00:30:24.391] iteration 27310 : model1 loss : 0.195849 model2 loss : 0.232620
[00:30:24.716] iteration 27311 : model1 loss : 0.212895 model2 loss : 0.235452
[00:30:25.046] iteration 27312 : model1 loss : 0.231961 model2 loss : 0.262848
[00:30:25.371] iteration 27313 : model1 loss : 0.235012 model2 loss : 0.239120
[00:30:25.697] iteration 27314 : model1 loss : 0.084015 model2 loss : 0.189880
[00:30:26.023] iteration 27315 : model1 loss : 0.159792 model2 loss : 0.121743
[00:30:26.349] iteration 27316 : model1 loss : 0.103431 model2 loss : 0.137273
[00:30:26.675] iteration 27317 : model1 loss : 0.068621 model2 loss : 0.091584
[00:30:27.002] iteration 27318 : model1 loss : 0.265309 model2 loss : 0.282422
[00:30:27.327] iteration 27319 : model1 loss : 0.205542 model2 loss : 0.209166
[00:30:27.652] iteration 27320 : model1 loss : 0.169634 model2 loss : 0.290529
[00:30:27.979] iteration 27321 : model1 loss : 0.253876 model2 loss : 0.300602
[00:30:28.305] iteration 27322 : model1 loss : 0.182533 model2 loss : 0.243878
[00:30:28.631] iteration 27323 : model1 loss : 0.168185 model2 loss : 0.212980
[00:30:28.957] iteration 27324 : model1 loss : 0.090535 model2 loss : 0.182068
[00:30:29.283] iteration 27325 : model1 loss : 0.149121 model2 loss : 0.194123
[00:30:29.608] iteration 27326 : model1 loss : 0.157476 model2 loss : 0.249477
[00:30:29.934] iteration 27327 : model1 loss : 0.095321 model2 loss : 0.116221
[00:30:30.260] iteration 27328 : model1 loss : 0.091269 model2 loss : 0.155617
[00:30:30.587] iteration 27329 : model1 loss : 0.156973 model2 loss : 0.176581
[00:30:30.913] iteration 27330 : model1 loss : 0.271468 model2 loss : 0.263608
[00:30:31.237] iteration 27331 : model1 loss : 0.077406 model2 loss : 0.088895
[00:30:31.564] iteration 27332 : model1 loss : 0.183661 model2 loss : 0.176648
[00:30:31.890] iteration 27333 : model1 loss : 0.167987 model2 loss : 0.197654
[00:30:32.215] iteration 27334 : model1 loss : 0.151891 model2 loss : 0.167931
[00:30:32.542] iteration 27335 : model1 loss : 0.181845 model2 loss : 0.185003
[00:30:32.867] iteration 27336 : model1 loss : 0.074984 model2 loss : 0.107650
[00:30:33.193] iteration 27337 : model1 loss : 0.163878 model2 loss : 0.213152
[00:30:33.518] iteration 27338 : model1 loss : 0.171357 model2 loss : 0.212691
[00:30:33.845] iteration 27339 : model1 loss : 0.188833 model2 loss : 0.194968
[00:30:34.170] iteration 27340 : model1 loss : 0.090607 model2 loss : 0.157056
[00:30:34.496] iteration 27341 : model1 loss : 0.189872 model2 loss : 0.203553
[00:30:34.822] iteration 27342 : model1 loss : 0.276513 model2 loss : 0.298420
[00:30:35.148] iteration 27343 : model1 loss : 0.183770 model2 loss : 0.213500
[00:30:35.474] iteration 27344 : model1 loss : 0.154220 model2 loss : 0.183873
[00:30:35.801] iteration 27345 : model1 loss : 0.147976 model2 loss : 0.195779
[00:30:36.126] iteration 27346 : model1 loss : 0.150873 model2 loss : 0.222315
[00:30:36.452] iteration 27347 : model1 loss : 0.191532 model2 loss : 0.299091
[00:30:36.778] iteration 27348 : model1 loss : 0.292016 model2 loss : 0.222562
[00:30:37.104] iteration 27349 : model1 loss : 0.176893 model2 loss : 0.196401
[00:30:37.430] iteration 27350 : model1 loss : 0.236858 model2 loss : 0.268273
[00:30:37.937] iteration 27351 : model1 loss : 0.250785 model2 loss : 0.282283
[00:30:38.263] iteration 27352 : model1 loss : 0.274420 model2 loss : 0.288055
[00:30:38.589] iteration 27353 : model1 loss : 0.263559 model2 loss : 0.274747
[00:30:38.915] iteration 27354 : model1 loss : 0.180669 model2 loss : 0.237726
[00:30:39.240] iteration 27355 : model1 loss : 0.209725 model2 loss : 0.239202
[00:30:39.566] iteration 27356 : model1 loss : 0.181353 model2 loss : 0.154735
[00:30:39.895] iteration 27357 : model1 loss : 0.259970 model2 loss : 0.323307
[00:30:40.220] iteration 27358 : model1 loss : 0.180230 model2 loss : 0.253217
[00:30:40.547] iteration 27359 : model1 loss : 0.236714 model2 loss : 0.255417
[00:30:40.872] iteration 27360 : model1 loss : 0.071626 model2 loss : 0.106667
[00:30:41.198] iteration 27361 : model1 loss : 0.234975 model2 loss : 0.242193
[00:30:41.525] iteration 27362 : model1 loss : 0.245809 model2 loss : 0.248805
[00:30:41.850] iteration 27363 : model1 loss : 0.184583 model2 loss : 0.213922
[00:30:42.176] iteration 27364 : model1 loss : 0.157308 model2 loss : 0.162722
[00:30:42.503] iteration 27365 : model1 loss : 0.176494 model2 loss : 0.231669
[00:30:42.829] iteration 27366 : model1 loss : 0.177596 model2 loss : 0.208469
[00:30:43.156] iteration 27367 : model1 loss : 0.143744 model2 loss : 0.180908
[00:30:43.482] iteration 27368 : model1 loss : 0.176383 model2 loss : 0.262510
[00:30:43.808] iteration 27369 : model1 loss : 0.169556 model2 loss : 0.197207
[00:30:44.134] iteration 27370 : model1 loss : 0.238556 model2 loss : 0.254239
[00:30:44.460] iteration 27371 : model1 loss : 0.191468 model2 loss : 0.198245
[00:30:44.787] iteration 27372 : model1 loss : 0.162171 model2 loss : 0.172108
[00:30:45.114] iteration 27373 : model1 loss : 0.168257 model2 loss : 0.211165
[00:30:45.440] iteration 27374 : model1 loss : 0.240126 model2 loss : 0.245332
[00:30:45.766] iteration 27375 : model1 loss : 0.237990 model2 loss : 0.267906
[00:30:46.093] iteration 27376 : model1 loss : 0.195477 model2 loss : 0.203605
[00:30:46.419] iteration 27377 : model1 loss : 0.193501 model2 loss : 0.220109
[00:30:46.748] iteration 27378 : model1 loss : 0.196288 model2 loss : 0.192828
[00:30:47.074] iteration 27379 : model1 loss : 0.322102 model2 loss : 0.328178
[00:30:47.403] iteration 27380 : model1 loss : 0.147404 model2 loss : 0.157913
[00:30:47.729] iteration 27381 : model1 loss : 0.148575 model2 loss : 0.173512
[00:30:48.055] iteration 27382 : model1 loss : 0.155850 model2 loss : 0.160499
[00:30:48.381] iteration 27383 : model1 loss : 0.319105 model2 loss : 0.332929
[00:30:48.707] iteration 27384 : model1 loss : 0.195279 model2 loss : 0.210460
[00:30:49.033] iteration 27385 : model1 loss : 0.251511 model2 loss : 0.267861
[00:30:49.359] iteration 27386 : model1 loss : 0.116661 model2 loss : 0.118715
[00:30:49.684] iteration 27387 : model1 loss : 0.171418 model2 loss : 0.172248
[00:30:50.010] iteration 27388 : model1 loss : 0.180481 model2 loss : 0.206975
[00:30:50.338] iteration 27389 : model1 loss : 0.083852 model2 loss : 0.124158
[00:30:50.664] iteration 27390 : model1 loss : 0.151522 model2 loss : 0.174558
[00:30:50.991] iteration 27391 : model1 loss : 0.162800 model2 loss : 0.218143
[00:30:51.316] iteration 27392 : model1 loss : 0.245464 model2 loss : 0.254565
[00:30:51.643] iteration 27393 : model1 loss : 0.256669 model2 loss : 0.289314
[00:30:51.969] iteration 27394 : model1 loss : 0.155895 model2 loss : 0.162145
[00:30:52.295] iteration 27395 : model1 loss : 0.113328 model2 loss : 0.122567
[00:30:52.621] iteration 27396 : model1 loss : 0.160582 model2 loss : 0.276185
[00:30:52.946] iteration 27397 : model1 loss : 0.170716 model2 loss : 0.189185
[00:30:53.273] iteration 27398 : model1 loss : 0.165207 model2 loss : 0.186251
[00:30:53.599] iteration 27399 : model1 loss : 0.203360 model2 loss : 0.298433
[00:30:53.925] iteration 27400 : model1 loss : 0.183884 model2 loss : 0.220031
[00:30:54.427] iteration 27401 : model1 loss : 0.252742 model2 loss : 0.280873
[00:30:54.753] iteration 27402 : model1 loss : 0.077984 model2 loss : 0.177045
[00:30:55.080] iteration 27403 : model1 loss : 0.317351 model2 loss : 0.324970
[00:30:55.405] iteration 27404 : model1 loss : 0.207286 model2 loss : 0.216381
[00:30:55.731] iteration 27405 : model1 loss : 0.098876 model2 loss : 0.157899
[00:30:56.058] iteration 27406 : model1 loss : 0.173574 model2 loss : 0.169214
[00:30:56.383] iteration 27407 : model1 loss : 0.202807 model2 loss : 0.222316
[00:30:56.709] iteration 27408 : model1 loss : 0.080222 model2 loss : 0.156021
[00:30:57.035] iteration 27409 : model1 loss : 0.270974 model2 loss : 0.335654
[00:30:57.361] iteration 27410 : model1 loss : 0.185361 model2 loss : 0.195880
[00:30:57.687] iteration 27411 : model1 loss : 0.090423 model2 loss : 0.153596
[00:30:58.013] iteration 27412 : model1 loss : 0.094023 model2 loss : 0.135816
[00:30:58.338] iteration 27413 : model1 loss : 0.207971 model2 loss : 0.240588
[00:30:58.665] iteration 27414 : model1 loss : 0.094962 model2 loss : 0.136969
[00:30:58.991] iteration 27415 : model1 loss : 0.259086 model2 loss : 0.264563
[00:30:59.317] iteration 27416 : model1 loss : 0.187292 model2 loss : 0.246957
[00:30:59.643] iteration 27417 : model1 loss : 0.162033 model2 loss : 0.186896
[00:30:59.969] iteration 27418 : model1 loss : 0.169134 model2 loss : 0.195884
[00:31:00.296] iteration 27419 : model1 loss : 0.200448 model2 loss : 0.252932
[00:31:00.622] iteration 27420 : model1 loss : 0.183792 model2 loss : 0.185957
[00:31:00.948] iteration 27421 : model1 loss : 0.177460 model2 loss : 0.193502
[00:31:01.273] iteration 27422 : model1 loss : 0.090760 model2 loss : 0.121545
[00:31:01.600] iteration 27423 : model1 loss : 0.256292 model2 loss : 0.276587
[00:31:01.926] iteration 27424 : model1 loss : 0.158942 model2 loss : 0.185399
[00:31:02.252] iteration 27425 : model1 loss : 0.165652 model2 loss : 0.236478
[00:31:02.578] iteration 27426 : model1 loss : 0.209599 model2 loss : 0.231348
[00:31:02.904] iteration 27427 : model1 loss : 0.336715 model2 loss : 0.359181
[00:31:03.229] iteration 27428 : model1 loss : 0.167928 model2 loss : 0.182611
[00:31:03.555] iteration 27429 : model1 loss : 0.181886 model2 loss : 0.186341
[00:31:03.881] iteration 27430 : model1 loss : 0.198053 model2 loss : 0.244908
[00:31:04.206] iteration 27431 : model1 loss : 0.104252 model2 loss : 0.105848
[00:31:04.533] iteration 27432 : model1 loss : 0.253751 model2 loss : 0.283319
[00:31:04.859] iteration 27433 : model1 loss : 0.174560 model2 loss : 0.199423
[00:31:05.185] iteration 27434 : model1 loss : 0.089717 model2 loss : 0.126266
[00:31:05.512] iteration 27435 : model1 loss : 0.253250 model2 loss : 0.240620
[00:31:05.838] iteration 27436 : model1 loss : 0.086539 model2 loss : 0.083595
[00:31:06.165] iteration 27437 : model1 loss : 0.192430 model2 loss : 0.212228
[00:31:06.492] iteration 27438 : model1 loss : 0.174628 model2 loss : 0.188114
[00:31:06.817] iteration 27439 : model1 loss : 0.236329 model2 loss : 0.255974
[00:31:07.143] iteration 27440 : model1 loss : 0.266034 model2 loss : 0.339660
[00:31:07.469] iteration 27441 : model1 loss : 0.073316 model2 loss : 0.083153
[00:31:07.796] iteration 27442 : model1 loss : 0.073013 model2 loss : 0.109515
[00:31:08.121] iteration 27443 : model1 loss : 0.263620 model2 loss : 0.269395
[00:31:08.448] iteration 27444 : model1 loss : 0.152080 model2 loss : 0.169403
[00:31:08.775] iteration 27445 : model1 loss : 0.261228 model2 loss : 0.289225
[00:31:09.101] iteration 27446 : model1 loss : 0.236106 model2 loss : 0.243611
[00:31:09.427] iteration 27447 : model1 loss : 0.243010 model2 loss : 0.260808
[00:31:09.753] iteration 27448 : model1 loss : 0.058987 model2 loss : 0.068867
[00:31:10.080] iteration 27449 : model1 loss : 0.164782 model2 loss : 0.188907
[00:31:10.406] iteration 27450 : model1 loss : 0.077958 model2 loss : 0.113976
[00:31:10.910] iteration 27451 : model1 loss : 0.203428 model2 loss : 0.240906
[00:31:11.236] iteration 27452 : model1 loss : 0.083709 model2 loss : 0.102430
[00:31:11.562] iteration 27453 : model1 loss : 0.063084 model2 loss : 0.101391
[00:31:11.888] iteration 27454 : model1 loss : 0.266034 model2 loss : 0.210108
[00:31:12.214] iteration 27455 : model1 loss : 0.260316 model2 loss : 0.299243
[00:31:12.540] iteration 27456 : model1 loss : 0.254165 model2 loss : 0.269546
[00:31:12.865] iteration 27457 : model1 loss : 0.241383 model2 loss : 0.256602
[00:31:13.195] iteration 27458 : model1 loss : 0.188518 model2 loss : 0.210552
[00:31:13.520] iteration 27459 : model1 loss : 0.260958 model2 loss : 0.289189
[00:31:13.846] iteration 27460 : model1 loss : 0.071652 model2 loss : 0.085455
[00:31:14.171] iteration 27461 : model1 loss : 0.098771 model2 loss : 0.170148
[00:31:14.498] iteration 27462 : model1 loss : 0.273696 model2 loss : 0.350785
[00:31:14.824] iteration 27463 : model1 loss : 0.153549 model2 loss : 0.162417
[00:31:15.149] iteration 27464 : model1 loss : 0.164703 model2 loss : 0.209417
[00:31:15.476] iteration 27465 : model1 loss : 0.177591 model2 loss : 0.214797
[00:31:15.802] iteration 27466 : model1 loss : 0.162234 model2 loss : 0.194611
[00:31:16.128] iteration 27467 : model1 loss : 0.222177 model2 loss : 0.255783
[00:31:16.454] iteration 27468 : model1 loss : 0.167540 model2 loss : 0.191288
[00:31:16.779] iteration 27469 : model1 loss : 0.246016 model2 loss : 0.283037
[00:31:17.105] iteration 27470 : model1 loss : 0.184532 model2 loss : 0.190140
[00:31:17.432] iteration 27471 : model1 loss : 0.247380 model2 loss : 0.275557
[00:31:17.758] iteration 27472 : model1 loss : 0.182193 model2 loss : 0.250207
[00:31:18.084] iteration 27473 : model1 loss : 0.186869 model2 loss : 0.208490
[00:31:18.411] iteration 27474 : model1 loss : 0.186823 model2 loss : 0.210280
[00:31:18.736] iteration 27475 : model1 loss : 0.093737 model2 loss : 0.105015
[00:31:19.063] iteration 27476 : model1 loss : 0.162359 model2 loss : 0.207494
[00:31:19.389] iteration 27477 : model1 loss : 0.234015 model2 loss : 0.249078
[00:31:19.714] iteration 27478 : model1 loss : 0.153890 model2 loss : 0.176573
[00:31:20.041] iteration 27479 : model1 loss : 0.263234 model2 loss : 0.287113
[00:31:20.367] iteration 27480 : model1 loss : 0.250450 model2 loss : 0.276914
[00:31:20.694] iteration 27481 : model1 loss : 0.160993 model2 loss : 0.199781
[00:31:21.020] iteration 27482 : model1 loss : 0.251357 model2 loss : 0.258768
[00:31:21.346] iteration 27483 : model1 loss : 0.103601 model2 loss : 0.159610
[00:31:21.673] iteration 27484 : model1 loss : 0.103212 model2 loss : 0.206079
[00:31:21.999] iteration 27485 : model1 loss : 0.244027 model2 loss : 0.265842
[00:31:22.325] iteration 27486 : model1 loss : 0.178557 model2 loss : 0.204464
[00:31:22.651] iteration 27487 : model1 loss : 0.228638 model2 loss : 0.217373
[00:31:22.976] iteration 27488 : model1 loss : 0.105130 model2 loss : 0.134875
[00:31:23.302] iteration 27489 : model1 loss : 0.162270 model2 loss : 0.174278
[00:31:23.628] iteration 27490 : model1 loss : 0.179998 model2 loss : 0.252441
[00:31:23.953] iteration 27491 : model1 loss : 0.192669 model2 loss : 0.218923
[00:31:24.278] iteration 27492 : model1 loss : 0.192319 model2 loss : 0.231330
[00:31:24.605] iteration 27493 : model1 loss : 0.161848 model2 loss : 0.183742
[00:31:24.931] iteration 27494 : model1 loss : 0.157762 model2 loss : 0.218012
[00:31:25.258] iteration 27495 : model1 loss : 0.142532 model2 loss : 0.186164
[00:31:25.586] iteration 27496 : model1 loss : 0.240493 model2 loss : 0.309046
[00:31:25.912] iteration 27497 : model1 loss : 0.100902 model2 loss : 0.131975
[00:31:26.237] iteration 27498 : model1 loss : 0.074633 model2 loss : 0.106088
[00:31:26.564] iteration 27499 : model1 loss : 0.117048 model2 loss : 0.201590
[00:31:26.890] iteration 27500 : model1 loss : 0.277926 model2 loss : 0.295417
[00:31:27.428] iteration 27501 : model1 loss : 0.281581 model2 loss : 0.301873
[00:31:27.754] iteration 27502 : model1 loss : 0.274987 model2 loss : 0.351300
[00:31:28.081] iteration 27503 : model1 loss : 0.076226 model2 loss : 0.087815
[00:31:28.408] iteration 27504 : model1 loss : 0.195071 model2 loss : 0.303748
[00:31:28.733] iteration 27505 : model1 loss : 0.155633 model2 loss : 0.217270
[00:31:29.060] iteration 27506 : model1 loss : 0.083946 model2 loss : 0.098146
[00:31:29.385] iteration 27507 : model1 loss : 0.075994 model2 loss : 0.089726
[00:31:29.711] iteration 27508 : model1 loss : 0.241078 model2 loss : 0.246239
[00:31:30.038] iteration 27509 : model1 loss : 0.173763 model2 loss : 0.225219
[00:31:30.365] iteration 27510 : model1 loss : 0.160631 model2 loss : 0.191301
[00:31:30.691] iteration 27511 : model1 loss : 0.173639 model2 loss : 0.196442
[00:31:31.018] iteration 27512 : model1 loss : 0.249001 model2 loss : 0.267624
[00:31:31.345] iteration 27513 : model1 loss : 0.247338 model2 loss : 0.265695
[00:31:31.671] iteration 27514 : model1 loss : 0.216178 model2 loss : 0.255634
[00:31:31.997] iteration 27515 : model1 loss : 0.097718 model2 loss : 0.102836
[00:31:32.325] iteration 27516 : model1 loss : 0.117772 model2 loss : 0.147528
[00:31:32.652] iteration 27517 : model1 loss : 0.074235 model2 loss : 0.149588
[00:31:32.978] iteration 27518 : model1 loss : 0.156414 model2 loss : 0.156271
[00:31:33.304] iteration 27519 : model1 loss : 0.171352 model2 loss : 0.201498
[00:31:33.632] iteration 27520 : model1 loss : 0.158513 model2 loss : 0.233371
[00:31:33.959] iteration 27521 : model1 loss : 0.238885 model2 loss : 0.272227
[00:31:34.284] iteration 27522 : model1 loss : 0.230238 model2 loss : 0.250213
[00:31:34.611] iteration 27523 : model1 loss : 0.156309 model2 loss : 0.199023
[00:31:34.938] iteration 27524 : model1 loss : 0.165163 model2 loss : 0.185853
[00:31:35.266] iteration 27525 : model1 loss : 0.165094 model2 loss : 0.194374
[00:31:35.591] iteration 27526 : model1 loss : 0.081191 model2 loss : 0.177431
[00:31:35.918] iteration 27527 : model1 loss : 0.173161 model2 loss : 0.157852
[00:31:36.243] iteration 27528 : model1 loss : 0.124765 model2 loss : 0.294337
[00:31:36.569] iteration 27529 : model1 loss : 0.172061 model2 loss : 0.205260
[00:31:36.895] iteration 27530 : model1 loss : 0.156750 model2 loss : 0.160524
[00:31:37.221] iteration 27531 : model1 loss : 0.163791 model2 loss : 0.220462
[00:31:37.547] iteration 27532 : model1 loss : 0.116497 model2 loss : 0.178668
[00:31:37.873] iteration 27533 : model1 loss : 0.176229 model2 loss : 0.179514
[00:31:38.200] iteration 27534 : model1 loss : 0.112821 model2 loss : 0.204500
[00:31:38.526] iteration 27535 : model1 loss : 0.158209 model2 loss : 0.167738
[00:31:38.852] iteration 27536 : model1 loss : 0.149645 model2 loss : 0.203461
[00:31:39.178] iteration 27537 : model1 loss : 0.184644 model2 loss : 0.206259
[00:31:39.503] iteration 27538 : model1 loss : 0.189973 model2 loss : 0.205097
[00:31:39.829] iteration 27539 : model1 loss : 0.243538 model2 loss : 0.268640
[00:31:40.156] iteration 27540 : model1 loss : 0.054666 model2 loss : 0.083566
[00:31:40.483] iteration 27541 : model1 loss : 0.209336 model2 loss : 0.284720
[00:31:40.809] iteration 27542 : model1 loss : 0.175965 model2 loss : 0.233208
[00:31:41.134] iteration 27543 : model1 loss : 0.248120 model2 loss : 0.268837
[00:31:41.460] iteration 27544 : model1 loss : 0.191908 model2 loss : 0.266396
[00:31:41.787] iteration 27545 : model1 loss : 0.252055 model2 loss : 0.285213
[00:31:42.113] iteration 27546 : model1 loss : 0.092283 model2 loss : 0.103271
[00:31:42.439] iteration 27547 : model1 loss : 0.077684 model2 loss : 0.074803
[00:31:42.764] iteration 27548 : model1 loss : 0.158086 model2 loss : 0.182990
[00:31:43.092] iteration 27549 : model1 loss : 0.104702 model2 loss : 0.236797
[00:31:43.418] iteration 27550 : model1 loss : 0.068749 model2 loss : 0.111353
[00:31:43.950] iteration 27551 : model1 loss : 0.153043 model2 loss : 0.168764
[00:31:44.275] iteration 27552 : model1 loss : 0.175858 model2 loss : 0.186023
[00:31:44.601] iteration 27553 : model1 loss : 0.194338 model2 loss : 0.248236
[00:31:44.927] iteration 27554 : model1 loss : 0.276883 model2 loss : 0.314856
[00:31:45.254] iteration 27555 : model1 loss : 0.190343 model2 loss : 0.227496
[00:31:45.580] iteration 27556 : model1 loss : 0.113971 model2 loss : 0.163765
[00:31:45.906] iteration 27557 : model1 loss : 0.117607 model2 loss : 0.158463
[00:31:46.232] iteration 27558 : model1 loss : 0.095910 model2 loss : 0.175670
[00:31:46.558] iteration 27559 : model1 loss : 0.223360 model2 loss : 0.294549
[00:31:46.884] iteration 27560 : model1 loss : 0.262545 model2 loss : 0.302032
[00:31:47.210] iteration 27561 : model1 loss : 0.176285 model2 loss : 0.255573
[00:31:47.535] iteration 27562 : model1 loss : 0.106070 model2 loss : 0.110330
[00:31:47.861] iteration 27563 : model1 loss : 0.088943 model2 loss : 0.178942
[00:31:48.187] iteration 27564 : model1 loss : 0.173701 model2 loss : 0.247964
[00:31:48.514] iteration 27565 : model1 loss : 0.196835 model2 loss : 0.231382
[00:31:48.841] iteration 27566 : model1 loss : 0.286294 model2 loss : 0.261725
[00:31:49.166] iteration 27567 : model1 loss : 0.157271 model2 loss : 0.168356
[00:31:49.494] iteration 27568 : model1 loss : 0.112750 model2 loss : 0.136962
[00:31:49.820] iteration 27569 : model1 loss : 0.167324 model2 loss : 0.192722
[00:31:50.146] iteration 27570 : model1 loss : 0.263204 model2 loss : 0.290297
[00:31:50.471] iteration 27571 : model1 loss : 0.392155 model2 loss : 0.336475
[00:31:50.797] iteration 27572 : model1 loss : 0.234600 model2 loss : 0.232110
[00:31:51.124] iteration 27573 : model1 loss : 0.070400 model2 loss : 0.119072
[00:31:51.450] iteration 27574 : model1 loss : 0.173695 model2 loss : 0.201821
[00:31:51.776] iteration 27575 : model1 loss : 0.241144 model2 loss : 0.259515
[00:31:52.102] iteration 27576 : model1 loss : 0.204801 model2 loss : 0.218701
[00:31:52.429] iteration 27577 : model1 loss : 0.158326 model2 loss : 0.173722
[00:31:52.756] iteration 27578 : model1 loss : 0.095374 model2 loss : 0.097883
[00:31:53.082] iteration 27579 : model1 loss : 0.065799 model2 loss : 0.167785
[00:31:53.408] iteration 27580 : model1 loss : 0.171104 model2 loss : 0.188223
[00:31:53.732] iteration 27581 : model1 loss : 0.090104 model2 loss : 0.204125
[00:31:54.058] iteration 27582 : model1 loss : 0.153201 model2 loss : 0.207158
[00:31:54.385] iteration 27583 : model1 loss : 0.238674 model2 loss : 0.252981
[00:31:54.711] iteration 27584 : model1 loss : 0.082033 model2 loss : 0.105625
[00:31:55.037] iteration 27585 : model1 loss : 0.165757 model2 loss : 0.189950
[00:31:55.364] iteration 27586 : model1 loss : 0.196328 model2 loss : 0.224847
[00:31:55.689] iteration 27587 : model1 loss : 0.190662 model2 loss : 0.233315
[00:31:56.016] iteration 27588 : model1 loss : 0.146965 model2 loss : 0.186818
[00:31:56.342] iteration 27589 : model1 loss : 0.088790 model2 loss : 0.112418
[00:31:56.668] iteration 27590 : model1 loss : 0.156930 model2 loss : 0.170397
[00:31:56.994] iteration 27591 : model1 loss : 0.261052 model2 loss : 0.290149
[00:31:57.319] iteration 27592 : model1 loss : 0.095325 model2 loss : 0.140218
[00:31:57.645] iteration 27593 : model1 loss : 0.190661 model2 loss : 0.193303
[00:31:57.971] iteration 27594 : model1 loss : 0.274918 model2 loss : 0.322444
[00:31:58.296] iteration 27595 : model1 loss : 0.264509 model2 loss : 0.286589
[00:31:58.622] iteration 27596 : model1 loss : 0.247789 model2 loss : 0.258129
[00:31:58.947] iteration 27597 : model1 loss : 0.258388 model2 loss : 0.279762
[00:31:59.273] iteration 27598 : model1 loss : 0.145247 model2 loss : 0.265079
[00:31:59.599] iteration 27599 : model1 loss : 0.226941 model2 loss : 0.237639
[00:31:59.924] iteration 27600 : model1 loss : 0.080715 model2 loss : 0.164042
[00:32:00.450] iteration 27601 : model1 loss : 0.103788 model2 loss : 0.141488
[00:32:00.775] iteration 27602 : model1 loss : 0.266062 model2 loss : 0.336501
[00:32:01.103] iteration 27603 : model1 loss : 0.168136 model2 loss : 0.224177
[00:32:01.428] iteration 27604 : model1 loss : 0.273130 model2 loss : 0.299845
[00:32:01.753] iteration 27605 : model1 loss : 0.198554 model2 loss : 0.220354
[00:32:02.079] iteration 27606 : model1 loss : 0.103975 model2 loss : 0.183413
[00:32:02.405] iteration 27607 : model1 loss : 0.249112 model2 loss : 0.264412
[00:32:02.731] iteration 27608 : model1 loss : 0.162500 model2 loss : 0.175300
[00:32:03.057] iteration 27609 : model1 loss : 0.175622 model2 loss : 0.207633
[00:32:03.384] iteration 27610 : model1 loss : 0.171926 model2 loss : 0.201252
[00:32:03.710] iteration 27611 : model1 loss : 0.158091 model2 loss : 0.179404
[00:32:04.036] iteration 27612 : model1 loss : 0.171364 model2 loss : 0.204980
[00:32:04.363] iteration 27613 : model1 loss : 0.141749 model2 loss : 0.162647
[00:32:04.688] iteration 27614 : model1 loss : 0.253481 model2 loss : 0.272119
[00:32:05.016] iteration 27615 : model1 loss : 0.241828 model2 loss : 0.258188
[00:32:05.342] iteration 27616 : model1 loss : 0.163419 model2 loss : 0.161039
[00:32:05.668] iteration 27617 : model1 loss : 0.107322 model2 loss : 0.117290
[00:32:05.994] iteration 27618 : model1 loss : 0.118570 model2 loss : 0.127056
[00:32:06.319] iteration 27619 : model1 loss : 0.199764 model2 loss : 0.287823
[00:32:06.646] iteration 27620 : model1 loss : 0.158061 model2 loss : 0.172596
[00:32:06.971] iteration 27621 : model1 loss : 0.172002 model2 loss : 0.174539
[00:32:07.297] iteration 27622 : model1 loss : 0.178637 model2 loss : 0.206480
[00:32:07.622] iteration 27623 : model1 loss : 0.257494 model2 loss : 0.278374
[00:32:07.950] iteration 27624 : model1 loss : 0.177823 model2 loss : 0.192658
[00:32:08.290] iteration 27625 : model1 loss : 0.093154 model2 loss : 0.104949
[00:32:08.628] iteration 27626 : model1 loss : 0.151980 model2 loss : 0.205134
[00:32:08.964] iteration 27627 : model1 loss : 0.243005 model2 loss : 0.289279
[00:32:09.299] iteration 27628 : model1 loss : 0.163438 model2 loss : 0.178440
[00:32:09.632] iteration 27629 : model1 loss : 0.223666 model2 loss : 0.216720
[00:32:09.965] iteration 27630 : model1 loss : 0.258055 model2 loss : 0.306686
[00:32:10.298] iteration 27631 : model1 loss : 0.109960 model2 loss : 0.117248
[00:32:10.631] iteration 27632 : model1 loss : 0.185729 model2 loss : 0.191084
[00:32:10.968] iteration 27633 : model1 loss : 0.247313 model2 loss : 0.265797
[00:32:11.303] iteration 27634 : model1 loss : 0.127746 model2 loss : 0.166830
[00:32:11.640] iteration 27635 : model1 loss : 0.165410 model2 loss : 0.191862
[00:32:11.976] iteration 27636 : model1 loss : 0.173405 model2 loss : 0.169402
[00:32:12.309] iteration 27637 : model1 loss : 0.182084 model2 loss : 0.223749
[00:32:12.641] iteration 27638 : model1 loss : 0.263341 model2 loss : 0.276973
[00:32:12.973] iteration 27639 : model1 loss : 0.245838 model2 loss : 0.265422
[00:32:13.307] iteration 27640 : model1 loss : 0.182807 model2 loss : 0.199322
[00:32:13.640] iteration 27641 : model1 loss : 0.164878 model2 loss : 0.193378
[00:32:13.972] iteration 27642 : model1 loss : 0.155168 model2 loss : 0.208445
[00:32:14.308] iteration 27643 : model1 loss : 0.152334 model2 loss : 0.163216
[00:32:14.641] iteration 27644 : model1 loss : 0.267551 model2 loss : 0.304750
[00:32:14.978] iteration 27645 : model1 loss : 0.261339 model2 loss : 0.377576
[00:32:15.314] iteration 27646 : model1 loss : 0.178147 model2 loss : 0.225995
[00:32:15.653] iteration 27647 : model1 loss : 0.254033 model2 loss : 0.254510
[00:32:15.994] iteration 27648 : model1 loss : 0.236237 model2 loss : 0.302245
[00:32:16.331] iteration 27649 : model1 loss : 0.182204 model2 loss : 0.207273
[00:32:16.663] iteration 27650 : model1 loss : 0.173673 model2 loss : 0.242257
[00:32:17.328] iteration 27651 : model1 loss : 0.162706 model2 loss : 0.162633
[00:32:17.662] iteration 27652 : model1 loss : 0.239789 model2 loss : 0.279681
[00:32:17.995] iteration 27653 : model1 loss : 0.162619 model2 loss : 0.209590
[00:32:18.333] iteration 27654 : model1 loss : 0.239480 model2 loss : 0.256762
[00:32:18.669] iteration 27655 : model1 loss : 0.199091 model2 loss : 0.182368
[00:32:19.008] iteration 27656 : model1 loss : 0.082114 model2 loss : 0.126057
[00:32:19.350] iteration 27657 : model1 loss : 0.163791 model2 loss : 0.190283
[00:32:19.683] iteration 27658 : model1 loss : 0.167630 model2 loss : 0.174561
[00:32:20.021] iteration 27659 : model1 loss : 0.134958 model2 loss : 0.137305
[00:32:20.362] iteration 27660 : model1 loss : 0.166712 model2 loss : 0.181430
[00:32:20.696] iteration 27661 : model1 loss : 0.261552 model2 loss : 0.280097
[00:32:21.021] iteration 27662 : model1 loss : 0.196925 model2 loss : 0.195881
[00:32:21.349] iteration 27663 : model1 loss : 0.072541 model2 loss : 0.075248
[00:32:21.673] iteration 27664 : model1 loss : 0.249444 model2 loss : 0.269031
[00:32:21.996] iteration 27665 : model1 loss : 0.100473 model2 loss : 0.115188
[00:32:22.320] iteration 27666 : model1 loss : 0.085180 model2 loss : 0.138093
[00:32:22.646] iteration 27667 : model1 loss : 0.256886 model2 loss : 0.288007
[00:32:22.972] iteration 27668 : model1 loss : 0.325646 model2 loss : 0.332750
[00:32:23.296] iteration 27669 : model1 loss : 0.152382 model2 loss : 0.171646
[00:32:23.621] iteration 27670 : model1 loss : 0.259682 model2 loss : 0.290566
[00:32:23.947] iteration 27671 : model1 loss : 0.262435 model2 loss : 0.263287
[00:32:24.272] iteration 27672 : model1 loss : 0.149110 model2 loss : 0.161867
[00:32:24.595] iteration 27673 : model1 loss : 0.102779 model2 loss : 0.121466
[00:32:24.918] iteration 27674 : model1 loss : 0.080874 model2 loss : 0.109263
[00:32:25.243] iteration 27675 : model1 loss : 0.184428 model2 loss : 0.210769
[00:32:25.564] iteration 27676 : model1 loss : 0.261655 model2 loss : 0.286221
[00:32:25.885] iteration 27677 : model1 loss : 0.175697 model2 loss : 0.282534
[00:32:26.207] iteration 27678 : model1 loss : 0.163476 model2 loss : 0.183972
[00:32:26.529] iteration 27679 : model1 loss : 0.247488 model2 loss : 0.318573
[00:32:26.851] iteration 27680 : model1 loss : 0.244269 model2 loss : 0.252311
[00:32:27.176] iteration 27681 : model1 loss : 0.167795 model2 loss : 0.172923
[00:32:27.501] iteration 27682 : model1 loss : 0.192328 model2 loss : 0.196056
[00:32:27.826] iteration 27683 : model1 loss : 0.187135 model2 loss : 0.216231
[00:32:28.149] iteration 27684 : model1 loss : 0.222248 model2 loss : 0.229860
[00:32:28.470] iteration 27685 : model1 loss : 0.156382 model2 loss : 0.172396
[00:32:28.796] iteration 27686 : model1 loss : 0.270909 model2 loss : 0.283870
[00:32:29.121] iteration 27687 : model1 loss : 0.090995 model2 loss : 0.136399
[00:32:29.446] iteration 27688 : model1 loss : 0.156205 model2 loss : 0.099915
[00:32:29.767] iteration 27689 : model1 loss : 0.186614 model2 loss : 0.184873
[00:32:30.088] iteration 27690 : model1 loss : 0.192636 model2 loss : 0.190319
[00:32:30.409] iteration 27691 : model1 loss : 0.255658 model2 loss : 0.265439
[00:32:30.731] iteration 27692 : model1 loss : 0.168039 model2 loss : 0.188736
[00:32:31.052] iteration 27693 : model1 loss : 0.190448 model2 loss : 0.212252
[00:32:31.374] iteration 27694 : model1 loss : 0.160627 model2 loss : 0.201553
[00:32:31.698] iteration 27695 : model1 loss : 0.164621 model2 loss : 0.211959
[00:32:32.019] iteration 27696 : model1 loss : 0.157602 model2 loss : 0.185645
[00:32:32.340] iteration 27697 : model1 loss : 0.117016 model2 loss : 0.134557
[00:32:32.660] iteration 27698 : model1 loss : 0.177241 model2 loss : 0.235106
[00:32:32.983] iteration 27699 : model1 loss : 0.075224 model2 loss : 0.087598
[00:32:33.308] iteration 27700 : model1 loss : 0.083121 model2 loss : 0.103690
[00:32:33.784] iteration 27701 : model1 loss : 0.161269 model2 loss : 0.196720
[00:32:34.106] iteration 27702 : model1 loss : 0.274300 model2 loss : 0.288795
[00:32:34.428] iteration 27703 : model1 loss : 0.091025 model2 loss : 0.223469
[00:32:34.752] iteration 27704 : model1 loss : 0.183839 model2 loss : 0.206223
[00:32:35.074] iteration 27705 : model1 loss : 0.163079 model2 loss : 0.196905
[00:32:35.396] iteration 27706 : model1 loss : 0.171881 model2 loss : 0.202324
[00:32:35.716] iteration 27707 : model1 loss : 0.194387 model2 loss : 0.224494
[00:32:36.038] iteration 27708 : model1 loss : 0.318195 model2 loss : 0.282689
[00:32:36.363] iteration 27709 : model1 loss : 0.051910 model2 loss : 0.086505
[00:32:36.685] iteration 27710 : model1 loss : 0.147145 model2 loss : 0.189843
[00:32:37.007] iteration 27711 : model1 loss : 0.247184 model2 loss : 0.282865
[00:32:37.331] iteration 27712 : model1 loss : 0.095802 model2 loss : 0.136352
[00:32:37.655] iteration 27713 : model1 loss : 0.207474 model2 loss : 0.264462
[00:32:37.980] iteration 27714 : model1 loss : 0.219798 model2 loss : 0.270787
[00:32:38.305] iteration 27715 : model1 loss : 0.162211 model2 loss : 0.184052
[00:32:38.627] iteration 27716 : model1 loss : 0.163948 model2 loss : 0.243286
[00:32:38.952] iteration 27717 : model1 loss : 0.238470 model2 loss : 0.290964
[00:32:39.278] iteration 27718 : model1 loss : 0.154126 model2 loss : 0.126767
[00:32:39.600] iteration 27719 : model1 loss : 0.167752 model2 loss : 0.210289
[00:32:39.921] iteration 27720 : model1 loss : 0.184157 model2 loss : 0.220292
[00:32:40.246] iteration 27721 : model1 loss : 0.184151 model2 loss : 0.219843
[00:32:40.567] iteration 27722 : model1 loss : 0.151423 model2 loss : 0.163215
[00:32:40.889] iteration 27723 : model1 loss : 0.104419 model2 loss : 0.117971
[00:32:41.214] iteration 27724 : model1 loss : 0.179563 model2 loss : 0.208472
[00:32:41.537] iteration 27725 : model1 loss : 0.268524 model2 loss : 0.277589
[00:32:41.861] iteration 27726 : model1 loss : 0.080418 model2 loss : 0.237568
[00:32:42.185] iteration 27727 : model1 loss : 0.265449 model2 loss : 0.288955
[00:32:42.510] iteration 27728 : model1 loss : 0.233134 model2 loss : 0.276145
[00:32:42.832] iteration 27729 : model1 loss : 0.182256 model2 loss : 0.188070
[00:32:43.154] iteration 27730 : model1 loss : 0.186656 model2 loss : 0.190655
[00:32:43.476] iteration 27731 : model1 loss : 0.159785 model2 loss : 0.183154
[00:32:43.797] iteration 27732 : model1 loss : 0.172678 model2 loss : 0.181043
[00:32:44.118] iteration 27733 : model1 loss : 0.153283 model2 loss : 0.179624
[00:32:44.439] iteration 27734 : model1 loss : 0.201874 model2 loss : 0.227581
[00:32:44.761] iteration 27735 : model1 loss : 0.113793 model2 loss : 0.180818
[00:32:45.082] iteration 27736 : model1 loss : 0.228510 model2 loss : 0.175253
[00:32:45.404] iteration 27737 : model1 loss : 0.231000 model2 loss : 0.233056
[00:32:45.725] iteration 27738 : model1 loss : 0.083985 model2 loss : 0.105943
[00:32:46.046] iteration 27739 : model1 loss : 0.176522 model2 loss : 0.187152
[00:32:46.368] iteration 27740 : model1 loss : 0.196998 model2 loss : 0.252278
[00:32:46.693] iteration 27741 : model1 loss : 0.243428 model2 loss : 0.285833
[00:32:47.014] iteration 27742 : model1 loss : 0.237847 model2 loss : 0.268133
[00:32:47.336] iteration 27743 : model1 loss : 0.246323 model2 loss : 0.265983
[00:32:47.658] iteration 27744 : model1 loss : 0.093861 model2 loss : 0.151310
[00:32:47.982] iteration 27745 : model1 loss : 0.179191 model2 loss : 0.298088
[00:32:48.304] iteration 27746 : model1 loss : 0.091885 model2 loss : 0.108904
[00:32:48.625] iteration 27747 : model1 loss : 0.159575 model2 loss : 0.187223
[00:32:48.947] iteration 27748 : model1 loss : 0.171994 model2 loss : 0.286685
[00:32:49.274] iteration 27749 : model1 loss : 0.108149 model2 loss : 0.180154
[00:32:49.606] iteration 27750 : model1 loss : 0.321826 model2 loss : 0.352134
[00:32:50.278] iteration 27751 : model1 loss : 0.150255 model2 loss : 0.170799
[00:32:50.611] iteration 27752 : model1 loss : 0.160750 model2 loss : 0.287636
[00:32:50.942] iteration 27753 : model1 loss : 0.245219 model2 loss : 0.268367
[00:32:51.274] iteration 27754 : model1 loss : 0.114596 model2 loss : 0.107355
[00:32:51.606] iteration 27755 : model1 loss : 0.163266 model2 loss : 0.185118
[00:32:51.937] iteration 27756 : model1 loss : 0.105111 model2 loss : 0.095703
[00:32:52.269] iteration 27757 : model1 loss : 0.195762 model2 loss : 0.189132
[00:32:52.599] iteration 27758 : model1 loss : 0.105565 model2 loss : 0.143726
[00:32:52.931] iteration 27759 : model1 loss : 0.177317 model2 loss : 0.194647
[00:32:53.262] iteration 27760 : model1 loss : 0.083323 model2 loss : 0.161206
[00:32:53.592] iteration 27761 : model1 loss : 0.176088 model2 loss : 0.251241
[00:32:53.923] iteration 27762 : model1 loss : 0.245608 model2 loss : 0.235078
[00:32:54.253] iteration 27763 : model1 loss : 0.079202 model2 loss : 0.144598
[00:32:54.585] iteration 27764 : model1 loss : 0.109425 model2 loss : 0.192586
[00:32:54.916] iteration 27765 : model1 loss : 0.080925 model2 loss : 0.105185
[00:32:55.247] iteration 27766 : model1 loss : 0.162318 model2 loss : 0.205841
[00:32:55.577] iteration 27767 : model1 loss : 0.178773 model2 loss : 0.282704
[00:32:55.908] iteration 27768 : model1 loss : 0.162781 model2 loss : 0.159172
[00:32:56.241] iteration 27769 : model1 loss : 0.115492 model2 loss : 0.122923
[00:32:56.571] iteration 27770 : model1 loss : 0.098385 model2 loss : 0.123620
[00:32:56.902] iteration 27771 : model1 loss : 0.070244 model2 loss : 0.106432
[00:32:57.225] iteration 27772 : model1 loss : 0.241121 model2 loss : 0.276321
[00:32:57.547] iteration 27773 : model1 loss : 0.084660 model2 loss : 0.103214
[00:32:57.870] iteration 27774 : model1 loss : 0.162880 model2 loss : 0.205069
[00:32:58.191] iteration 27775 : model1 loss : 0.158454 model2 loss : 0.247096
[00:32:58.514] iteration 27776 : model1 loss : 0.174837 model2 loss : 0.228495
[00:32:58.836] iteration 27777 : model1 loss : 0.233047 model2 loss : 0.270493
[00:32:59.160] iteration 27778 : model1 loss : 0.140290 model2 loss : 0.167971
[00:32:59.486] iteration 27779 : model1 loss : 0.071818 model2 loss : 0.096718
[00:32:59.808] iteration 27780 : model1 loss : 0.198788 model2 loss : 0.195944
[00:33:00.130] iteration 27781 : model1 loss : 0.243487 model2 loss : 0.259472
[00:33:00.452] iteration 27782 : model1 loss : 0.251239 model2 loss : 0.273757
[00:33:00.775] iteration 27783 : model1 loss : 0.245939 model2 loss : 0.246920
[00:33:01.098] iteration 27784 : model1 loss : 0.106769 model2 loss : 0.127323
[00:33:01.420] iteration 27785 : model1 loss : 0.178236 model2 loss : 0.233939
[00:33:01.742] iteration 27786 : model1 loss : 0.164844 model2 loss : 0.181763
[00:33:02.065] iteration 27787 : model1 loss : 0.143906 model2 loss : 0.153913
[00:33:02.392] iteration 27788 : model1 loss : 0.255254 model2 loss : 0.266489
[00:33:02.713] iteration 27789 : model1 loss : 0.200572 model2 loss : 0.245013
[00:33:03.040] iteration 27790 : model1 loss : 0.191729 model2 loss : 0.191298
[00:33:03.361] iteration 27791 : model1 loss : 0.269052 model2 loss : 0.282317
[00:33:03.682] iteration 27792 : model1 loss : 0.249878 model2 loss : 0.263922
[00:33:04.003] iteration 27793 : model1 loss : 0.186759 model2 loss : 0.166695
[00:33:04.324] iteration 27794 : model1 loss : 0.191447 model2 loss : 0.234128
[00:33:04.649] iteration 27795 : model1 loss : 0.172655 model2 loss : 0.193317
[00:33:05.592] iteration 27796 : model1 loss : 0.173467 model2 loss : 0.189984
[00:33:05.917] iteration 27797 : model1 loss : 0.112204 model2 loss : 0.124010
[00:33:06.240] iteration 27798 : model1 loss : 0.178315 model2 loss : 0.235133
[00:33:06.563] iteration 27799 : model1 loss : 0.231534 model2 loss : 0.264541
[00:33:06.890] iteration 27800 : model1 loss : 0.183325 model2 loss : 0.217824
[00:33:07.428] iteration 27801 : model1 loss : 0.162318 model2 loss : 0.186280
[00:33:07.752] iteration 27802 : model1 loss : 0.246743 model2 loss : 0.263079
[00:33:08.075] iteration 27803 : model1 loss : 0.251800 model2 loss : 0.277047
[00:33:08.398] iteration 27804 : model1 loss : 0.173340 model2 loss : 0.274832
[00:33:08.721] iteration 27805 : model1 loss : 0.152955 model2 loss : 0.161995
[00:33:09.044] iteration 27806 : model1 loss : 0.155248 model2 loss : 0.171897
[00:33:09.370] iteration 27807 : model1 loss : 0.069668 model2 loss : 0.087195
[00:33:09.697] iteration 27808 : model1 loss : 0.154478 model2 loss : 0.173951
[00:33:10.019] iteration 27809 : model1 loss : 0.240871 model2 loss : 0.250367
[00:33:10.347] iteration 27810 : model1 loss : 0.231268 model2 loss : 0.243798
[00:33:10.672] iteration 27811 : model1 loss : 0.164281 model2 loss : 0.168433
[00:33:11.000] iteration 27812 : model1 loss : 0.228386 model2 loss : 0.244439
[00:33:11.322] iteration 27813 : model1 loss : 0.084908 model2 loss : 0.135034
[00:33:11.646] iteration 27814 : model1 loss : 0.241738 model2 loss : 0.260018
[00:33:11.973] iteration 27815 : model1 loss : 0.110798 model2 loss : 0.121609
[00:33:12.299] iteration 27816 : model1 loss : 0.159013 model2 loss : 0.191628
[00:33:12.622] iteration 27817 : model1 loss : 0.103553 model2 loss : 0.196915
[00:33:12.945] iteration 27818 : model1 loss : 0.173711 model2 loss : 0.200718
[00:33:13.269] iteration 27819 : model1 loss : 0.276732 model2 loss : 0.317959
[00:33:13.591] iteration 27820 : model1 loss : 0.106760 model2 loss : 0.165016
[00:33:13.915] iteration 27821 : model1 loss : 0.118248 model2 loss : 0.187574
[00:33:14.238] iteration 27822 : model1 loss : 0.149309 model2 loss : 0.173378
[00:33:14.561] iteration 27823 : model1 loss : 0.178234 model2 loss : 0.195097
[00:33:14.884] iteration 27824 : model1 loss : 0.240171 model2 loss : 0.256912
[00:33:15.218] iteration 27825 : model1 loss : 0.186601 model2 loss : 0.331934
[00:33:15.554] iteration 27826 : model1 loss : 0.206631 model2 loss : 0.240350
[00:33:15.886] iteration 27827 : model1 loss : 0.160688 model2 loss : 0.168421
[00:33:16.217] iteration 27828 : model1 loss : 0.255176 model2 loss : 0.299387
[00:33:16.552] iteration 27829 : model1 loss : 0.277319 model2 loss : 0.281607
[00:33:16.884] iteration 27830 : model1 loss : 0.176770 model2 loss : 0.205232
[00:33:17.216] iteration 27831 : model1 loss : 0.254571 model2 loss : 0.298882
[00:33:17.546] iteration 27832 : model1 loss : 0.182110 model2 loss : 0.219036
[00:33:17.878] iteration 27833 : model1 loss : 0.281082 model2 loss : 0.307506
[00:33:18.209] iteration 27834 : model1 loss : 0.149510 model2 loss : 0.162536
[00:33:18.542] iteration 27835 : model1 loss : 0.242236 model2 loss : 0.247793
[00:33:18.873] iteration 27836 : model1 loss : 0.177068 model2 loss : 0.202891
[00:33:19.207] iteration 27837 : model1 loss : 0.173209 model2 loss : 0.197611
[00:33:19.541] iteration 27838 : model1 loss : 0.184941 model2 loss : 0.197033
[00:33:19.878] iteration 27839 : model1 loss : 0.242878 model2 loss : 0.258952
[00:33:20.210] iteration 27840 : model1 loss : 0.071534 model2 loss : 0.087168
[00:33:20.542] iteration 27841 : model1 loss : 0.171793 model2 loss : 0.196693
[00:33:20.875] iteration 27842 : model1 loss : 0.204754 model2 loss : 0.224842
[00:33:21.211] iteration 27843 : model1 loss : 0.173892 model2 loss : 0.188829
[00:33:21.544] iteration 27844 : model1 loss : 0.248780 model2 loss : 0.236270
[00:33:21.877] iteration 27845 : model1 loss : 0.193127 model2 loss : 0.196764
[00:33:22.208] iteration 27846 : model1 loss : 0.254722 model2 loss : 0.271146
[00:33:22.540] iteration 27847 : model1 loss : 0.186626 model2 loss : 0.249094
[00:33:22.873] iteration 27848 : model1 loss : 0.102269 model2 loss : 0.130199
[00:33:23.206] iteration 27849 : model1 loss : 0.210193 model2 loss : 0.276032
[00:33:23.538] iteration 27850 : model1 loss : 0.168805 model2 loss : 0.207499
[00:33:24.161] iteration 27851 : model1 loss : 0.247590 model2 loss : 0.259474
[00:33:24.493] iteration 27852 : model1 loss : 0.244314 model2 loss : 0.270092
[00:33:24.828] iteration 27853 : model1 loss : 0.178198 model2 loss : 0.208485
[00:33:25.160] iteration 27854 : model1 loss : 0.116202 model2 loss : 0.135045
[00:33:25.487] iteration 27855 : model1 loss : 0.182849 model2 loss : 0.250131
[00:33:25.821] iteration 27856 : model1 loss : 0.154966 model2 loss : 0.175619
[00:33:26.157] iteration 27857 : model1 loss : 0.220906 model2 loss : 0.204975
[00:33:26.489] iteration 27858 : model1 loss : 0.171255 model2 loss : 0.218229
[00:33:26.816] iteration 27859 : model1 loss : 0.201499 model2 loss : 0.215743
[00:33:27.150] iteration 27860 : model1 loss : 0.281237 model2 loss : 0.299883
[00:33:27.481] iteration 27861 : model1 loss : 0.248382 model2 loss : 0.280408
[00:33:27.814] iteration 27862 : model1 loss : 0.184662 model2 loss : 0.166090
[00:33:28.144] iteration 27863 : model1 loss : 0.083362 model2 loss : 0.132021
[00:33:28.476] iteration 27864 : model1 loss : 0.239885 model2 loss : 0.264598
[00:33:28.810] iteration 27865 : model1 loss : 0.083309 model2 loss : 0.133940
[00:33:29.142] iteration 27866 : model1 loss : 0.287488 model2 loss : 0.276706
[00:33:29.469] iteration 27867 : model1 loss : 0.184363 model2 loss : 0.197141
[00:33:29.800] iteration 27868 : model1 loss : 0.181363 model2 loss : 0.187496
[00:33:30.133] iteration 27869 : model1 loss : 0.091643 model2 loss : 0.112069
[00:33:30.465] iteration 27870 : model1 loss : 0.263095 model2 loss : 0.279713
[00:33:30.796] iteration 27871 : model1 loss : 0.266949 model2 loss : 0.324454
[00:33:31.132] iteration 27872 : model1 loss : 0.077065 model2 loss : 0.074602
[00:33:31.466] iteration 27873 : model1 loss : 0.086226 model2 loss : 0.132709
[00:33:31.798] iteration 27874 : model1 loss : 0.274601 model2 loss : 0.337405
[00:33:32.128] iteration 27875 : model1 loss : 0.090254 model2 loss : 0.087761
[00:33:32.459] iteration 27876 : model1 loss : 0.100478 model2 loss : 0.165149
[00:33:32.791] iteration 27877 : model1 loss : 0.249447 model2 loss : 0.265467
[00:33:33.122] iteration 27878 : model1 loss : 0.147588 model2 loss : 0.158417
[00:33:33.453] iteration 27879 : model1 loss : 0.166500 model2 loss : 0.249578
[00:33:33.788] iteration 27880 : model1 loss : 0.178970 model2 loss : 0.184934
[00:33:34.125] iteration 27881 : model1 loss : 0.177254 model2 loss : 0.208437
[00:33:34.460] iteration 27882 : model1 loss : 0.084574 model2 loss : 0.114762
[00:33:34.790] iteration 27883 : model1 loss : 0.166032 model2 loss : 0.228503
[00:33:35.125] iteration 27884 : model1 loss : 0.182251 model2 loss : 0.210895
[00:33:35.460] iteration 27885 : model1 loss : 0.075955 model2 loss : 0.131388
[00:33:35.792] iteration 27886 : model1 loss : 0.202553 model2 loss : 0.238364
[00:33:36.118] iteration 27887 : model1 loss : 0.193031 model2 loss : 0.247495
[00:33:36.449] iteration 27888 : model1 loss : 0.100772 model2 loss : 0.160430
[00:33:36.781] iteration 27889 : model1 loss : 0.088408 model2 loss : 0.170108
[00:33:37.118] iteration 27890 : model1 loss : 0.186471 model2 loss : 0.216833
[00:33:37.444] iteration 27891 : model1 loss : 0.145464 model2 loss : 0.197321
[00:33:37.776] iteration 27892 : model1 loss : 0.198278 model2 loss : 0.281203
[00:33:38.110] iteration 27893 : model1 loss : 0.159566 model2 loss : 0.177690
[00:33:38.443] iteration 27894 : model1 loss : 0.313786 model2 loss : 0.313987
[00:33:38.769] iteration 27895 : model1 loss : 0.156567 model2 loss : 0.196890
[00:33:39.100] iteration 27896 : model1 loss : 0.265794 model2 loss : 0.286904
[00:33:39.436] iteration 27897 : model1 loss : 0.169915 model2 loss : 0.204373
[00:33:39.780] iteration 27898 : model1 loss : 0.250382 model2 loss : 0.277447
[00:33:40.105] iteration 27899 : model1 loss : 0.179154 model2 loss : 0.199938
[00:33:40.440] iteration 27900 : model1 loss : 0.184006 model2 loss : 0.191105
[00:33:41.019] iteration 27901 : model1 loss : 0.177484 model2 loss : 0.238600
[00:33:41.345] iteration 27902 : model1 loss : 0.112278 model2 loss : 0.156509
[00:33:41.670] iteration 27903 : model1 loss : 0.121963 model2 loss : 0.171292
[00:33:41.994] iteration 27904 : model1 loss : 0.319331 model2 loss : 0.321037
[00:33:42.318] iteration 27905 : model1 loss : 0.079939 model2 loss : 0.135548
[00:33:42.647] iteration 27906 : model1 loss : 0.109018 model2 loss : 0.097250
[00:33:42.975] iteration 27907 : model1 loss : 0.269524 model2 loss : 0.290467
[00:33:43.299] iteration 27908 : model1 loss : 0.128360 model2 loss : 0.146885
[00:33:43.624] iteration 27909 : model1 loss : 0.164068 model2 loss : 0.224338
[00:33:43.954] iteration 27910 : model1 loss : 0.096371 model2 loss : 0.115879
[00:33:44.281] iteration 27911 : model1 loss : 0.109273 model2 loss : 0.142653
[00:33:44.609] iteration 27912 : model1 loss : 0.173895 model2 loss : 0.226730
[00:33:44.933] iteration 27913 : model1 loss : 0.174636 model2 loss : 0.202644
[00:33:45.261] iteration 27914 : model1 loss : 0.223994 model2 loss : 0.241588
[00:33:45.588] iteration 27915 : model1 loss : 0.234165 model2 loss : 0.257038
[00:33:45.911] iteration 27916 : model1 loss : 0.201222 model2 loss : 0.196252
[00:33:46.236] iteration 27917 : model1 loss : 0.115909 model2 loss : 0.154866
[00:33:46.560] iteration 27918 : model1 loss : 0.264062 model2 loss : 0.275052
[00:33:46.886] iteration 27919 : model1 loss : 0.179001 model2 loss : 0.261238
[00:33:47.211] iteration 27920 : model1 loss : 0.069975 model2 loss : 0.111481
[00:33:47.535] iteration 27921 : model1 loss : 0.181879 model2 loss : 0.236281
[00:33:47.859] iteration 27922 : model1 loss : 0.183174 model2 loss : 0.177837
[00:33:48.189] iteration 27923 : model1 loss : 0.169073 model2 loss : 0.187573
[00:33:48.518] iteration 27924 : model1 loss : 0.173997 model2 loss : 0.214468
[00:33:48.844] iteration 27925 : model1 loss : 0.073816 model2 loss : 0.105916
[00:33:49.171] iteration 27926 : model1 loss : 0.170114 model2 loss : 0.192260
[00:33:49.496] iteration 27927 : model1 loss : 0.175299 model2 loss : 0.224355
[00:33:49.822] iteration 27928 : model1 loss : 0.213378 model2 loss : 0.241896
[00:33:50.150] iteration 27929 : model1 loss : 0.163288 model2 loss : 0.176163
[00:33:50.481] iteration 27930 : model1 loss : 0.156628 model2 loss : 0.168012
[00:33:50.806] iteration 27931 : model1 loss : 0.091309 model2 loss : 0.106061
[00:33:51.132] iteration 27932 : model1 loss : 0.317154 model2 loss : 0.319599
[00:33:51.459] iteration 27933 : model1 loss : 0.180536 model2 loss : 0.223219
[00:33:51.785] iteration 27934 : model1 loss : 0.085350 model2 loss : 0.127409
[00:33:52.110] iteration 27935 : model1 loss : 0.143562 model2 loss : 0.162856
[00:33:52.434] iteration 27936 : model1 loss : 0.169444 model2 loss : 0.185295
[00:33:52.762] iteration 27937 : model1 loss : 0.157725 model2 loss : 0.165144
[00:33:53.088] iteration 27938 : model1 loss : 0.287120 model2 loss : 0.290332
[00:33:53.414] iteration 27939 : model1 loss : 0.223599 model2 loss : 0.288601
[00:33:53.751] iteration 27940 : model1 loss : 0.190521 model2 loss : 0.280176
[00:33:54.084] iteration 27941 : model1 loss : 0.238652 model2 loss : 0.248033
[00:33:54.419] iteration 27942 : model1 loss : 0.203322 model2 loss : 0.257163
[00:33:54.753] iteration 27943 : model1 loss : 0.183634 model2 loss : 0.349445
[00:33:55.090] iteration 27944 : model1 loss : 0.181287 model2 loss : 0.180001
[00:33:55.434] iteration 27945 : model1 loss : 0.163833 model2 loss : 0.170763
[00:33:55.767] iteration 27946 : model1 loss : 0.157594 model2 loss : 0.176925
[00:33:56.107] iteration 27947 : model1 loss : 0.087673 model2 loss : 0.243690
[00:33:56.444] iteration 27948 : model1 loss : 0.243199 model2 loss : 0.265697
[00:33:56.778] iteration 27949 : model1 loss : 0.184169 model2 loss : 0.244256
[00:33:57.111] iteration 27950 : model1 loss : 0.069462 model2 loss : 0.095804
[00:33:57.787] iteration 27951 : model1 loss : 0.088070 model2 loss : 0.092846
[00:33:58.124] iteration 27952 : model1 loss : 0.116678 model2 loss : 0.178523
[00:33:58.460] iteration 27953 : model1 loss : 0.169738 model2 loss : 0.234306
[00:33:58.802] iteration 27954 : model1 loss : 0.249408 model2 loss : 0.270673
[00:33:59.142] iteration 27955 : model1 loss : 0.227662 model2 loss : 0.188585
[00:33:59.475] iteration 27956 : model1 loss : 0.093527 model2 loss : 0.155622
[00:33:59.809] iteration 27957 : model1 loss : 0.169650 model2 loss : 0.223054
[00:34:00.142] iteration 27958 : model1 loss : 0.087027 model2 loss : 0.115032
[00:34:00.483] iteration 27959 : model1 loss : 0.240679 model2 loss : 0.269030
[00:34:00.817] iteration 27960 : model1 loss : 0.249636 model2 loss : 0.246917
[00:34:01.150] iteration 27961 : model1 loss : 0.189102 model2 loss : 0.165470
[00:34:01.485] iteration 27962 : model1 loss : 0.151298 model2 loss : 0.173232
[00:34:01.826] iteration 27963 : model1 loss : 0.247399 model2 loss : 0.205663
[00:34:02.164] iteration 27964 : model1 loss : 0.317929 model2 loss : 0.330705
[00:34:02.505] iteration 27965 : model1 loss : 0.190335 model2 loss : 0.253367
[00:34:02.842] iteration 27966 : model1 loss : 0.259321 model2 loss : 0.344058
[00:34:03.176] iteration 27967 : model1 loss : 0.079216 model2 loss : 0.129708
[00:34:03.512] iteration 27968 : model1 loss : 0.087060 model2 loss : 0.125055
[00:34:03.846] iteration 27969 : model1 loss : 0.242031 model2 loss : 0.277597
[00:34:04.179] iteration 27970 : model1 loss : 0.191689 model2 loss : 0.186734
[00:34:04.513] iteration 27971 : model1 loss : 0.102098 model2 loss : 0.215938
[00:34:04.852] iteration 27972 : model1 loss : 0.232717 model2 loss : 0.252079
[00:34:05.191] iteration 27973 : model1 loss : 0.253640 model2 loss : 0.275041
[00:34:05.532] iteration 27974 : model1 loss : 0.178686 model2 loss : 0.208011
[00:34:05.865] iteration 27975 : model1 loss : 0.170019 model2 loss : 0.229912
[00:34:06.201] iteration 27976 : model1 loss : 0.197331 model2 loss : 0.216061
[00:34:06.540] iteration 27977 : model1 loss : 0.075812 model2 loss : 0.089453
[00:34:06.874] iteration 27978 : model1 loss : 0.239658 model2 loss : 0.258142
[00:34:07.206] iteration 27979 : model1 loss : 0.089991 model2 loss : 0.133263
[00:34:07.540] iteration 27980 : model1 loss : 0.269918 model2 loss : 0.314231
[00:34:07.878] iteration 27981 : model1 loss : 0.175610 model2 loss : 0.226467
[00:34:08.217] iteration 27982 : model1 loss : 0.183422 model2 loss : 0.234295
[00:34:08.553] iteration 27983 : model1 loss : 0.236013 model2 loss : 0.282266
[00:34:08.890] iteration 27984 : model1 loss : 0.148606 model2 loss : 0.171717
[00:34:09.230] iteration 27985 : model1 loss : 0.184899 model2 loss : 0.215495
[00:34:09.563] iteration 27986 : model1 loss : 0.086447 model2 loss : 0.130828
[00:34:09.903] iteration 27987 : model1 loss : 0.270748 model2 loss : 0.323874
[00:34:10.241] iteration 27988 : model1 loss : 0.182259 model2 loss : 0.192506
[00:34:10.584] iteration 27989 : model1 loss : 0.076177 model2 loss : 0.088966
[00:34:10.918] iteration 27990 : model1 loss : 0.180611 model2 loss : 0.206291
[00:34:11.254] iteration 27991 : model1 loss : 0.182436 model2 loss : 0.170255
[00:34:11.589] iteration 27992 : model1 loss : 0.264123 model2 loss : 0.283820
[00:34:11.923] iteration 27993 : model1 loss : 0.219938 model2 loss : 0.244030
[00:34:12.258] iteration 27994 : model1 loss : 0.063953 model2 loss : 0.106666
[00:34:12.594] iteration 27995 : model1 loss : 0.155476 model2 loss : 0.181903
[00:34:12.932] iteration 27996 : model1 loss : 0.181771 model2 loss : 0.210741
[00:34:13.272] iteration 27997 : model1 loss : 0.160543 model2 loss : 0.182725
[00:34:13.607] iteration 27998 : model1 loss : 0.180492 model2 loss : 0.203792
[00:34:13.949] iteration 27999 : model1 loss : 0.172685 model2 loss : 0.174611
[00:34:14.287] iteration 28000 : model1 loss : 0.086897 model2 loss : 0.101973
[00:34:14.964] iteration 28001 : model1 loss : 0.255677 model2 loss : 0.265043
[00:34:15.301] iteration 28002 : model1 loss : 0.159764 model2 loss : 0.174255
[00:34:15.639] iteration 28003 : model1 loss : 0.240808 model2 loss : 0.243949
[00:34:15.971] iteration 28004 : model1 loss : 0.211533 model2 loss : 0.197714
[00:34:16.305] iteration 28005 : model1 loss : 0.177534 model2 loss : 0.234288
[00:34:16.640] iteration 28006 : model1 loss : 0.153624 model2 loss : 0.175866
[00:34:16.983] iteration 28007 : model1 loss : 0.265512 model2 loss : 0.297735
[00:34:17.316] iteration 28008 : model1 loss : 0.091801 model2 loss : 0.140536
[00:34:17.652] iteration 28009 : model1 loss : 0.146600 model2 loss : 0.174079
[00:34:17.987] iteration 28010 : model1 loss : 0.187384 model2 loss : 0.199883
[00:34:18.324] iteration 28011 : model1 loss : 0.268495 model2 loss : 0.290122
[00:34:18.662] iteration 28012 : model1 loss : 0.231364 model2 loss : 0.272427
[00:34:18.999] iteration 28013 : model1 loss : 0.158957 model2 loss : 0.255728
[00:34:19.338] iteration 28014 : model1 loss : 0.163415 model2 loss : 0.108859
[00:34:19.675] iteration 28015 : model1 loss : 0.162663 model2 loss : 0.205010
[00:34:20.012] iteration 28016 : model1 loss : 0.177604 model2 loss : 0.220530
[00:34:20.350] iteration 28017 : model1 loss : 0.249293 model2 loss : 0.243861
[00:34:20.686] iteration 28018 : model1 loss : 0.145865 model2 loss : 0.176392
[00:34:21.020] iteration 28019 : model1 loss : 0.156459 model2 loss : 0.169816
[00:34:21.352] iteration 28020 : model1 loss : 0.243384 model2 loss : 0.267664
[00:34:21.686] iteration 28021 : model1 loss : 0.178312 model2 loss : 0.186892
[00:34:22.019] iteration 28022 : model1 loss : 0.107457 model2 loss : 0.115695
[00:34:22.356] iteration 28023 : model1 loss : 0.165113 model2 loss : 0.193959
[00:34:22.693] iteration 28024 : model1 loss : 0.244601 model2 loss : 0.256937
[00:34:23.027] iteration 28025 : model1 loss : 0.189075 model2 loss : 0.211306
[00:34:23.361] iteration 28026 : model1 loss : 0.119722 model2 loss : 0.158456
[00:34:23.698] iteration 28027 : model1 loss : 0.250998 model2 loss : 0.261893
[00:34:24.029] iteration 28028 : model1 loss : 0.184630 model2 loss : 0.200858
[00:34:24.362] iteration 28029 : model1 loss : 0.148857 model2 loss : 0.226929
[00:34:24.699] iteration 28030 : model1 loss : 0.166409 model2 loss : 0.249963
[00:34:25.036] iteration 28031 : model1 loss : 0.175504 model2 loss : 0.240308
[00:34:25.372] iteration 28032 : model1 loss : 0.162690 model2 loss : 0.183050
[00:34:25.710] iteration 28033 : model1 loss : 0.147983 model2 loss : 0.163625
[00:34:26.045] iteration 28034 : model1 loss : 0.093747 model2 loss : 0.176975
[00:34:26.379] iteration 28035 : model1 loss : 0.172494 model2 loss : 0.206177
[00:34:26.711] iteration 28036 : model1 loss : 0.077414 model2 loss : 0.119006
[00:34:27.048] iteration 28037 : model1 loss : 0.165701 model2 loss : 0.228148
[00:34:27.387] iteration 28038 : model1 loss : 0.091610 model2 loss : 0.146296
[00:34:27.725] iteration 28039 : model1 loss : 0.177232 model2 loss : 0.213410
[00:34:28.058] iteration 28040 : model1 loss : 0.269502 model2 loss : 0.297028
[00:34:28.391] iteration 28041 : model1 loss : 0.258258 model2 loss : 0.257042
[00:34:28.724] iteration 28042 : model1 loss : 0.170797 model2 loss : 0.277538
[00:34:29.057] iteration 28043 : model1 loss : 0.225355 model2 loss : 0.290561
[00:34:29.390] iteration 28044 : model1 loss : 0.282482 model2 loss : 0.272577
[00:34:29.723] iteration 28045 : model1 loss : 0.098161 model2 loss : 0.214203
[00:34:30.057] iteration 28046 : model1 loss : 0.099458 model2 loss : 0.111273
[00:34:30.397] iteration 28047 : model1 loss : 0.156652 model2 loss : 0.176458
[00:34:30.732] iteration 28048 : model1 loss : 0.180878 model2 loss : 0.222912
[00:34:31.065] iteration 28049 : model1 loss : 0.186980 model2 loss : 0.197143
[00:34:31.399] iteration 28050 : model1 loss : 0.165591 model2 loss : 0.179482
[00:34:32.086] iteration 28051 : model1 loss : 0.167358 model2 loss : 0.196992
[00:34:32.419] iteration 28052 : model1 loss : 0.155474 model2 loss : 0.187266
[00:34:32.752] iteration 28053 : model1 loss : 0.270246 model2 loss : 0.270207
[00:34:33.090] iteration 28054 : model1 loss : 0.243444 model2 loss : 0.295557
[00:34:33.427] iteration 28055 : model1 loss : 0.312563 model2 loss : 0.314046
[00:34:33.766] iteration 28056 : model1 loss : 0.091695 model2 loss : 0.118304
[00:34:34.103] iteration 28057 : model1 loss : 0.077321 model2 loss : 0.115746
[00:34:34.442] iteration 28058 : model1 loss : 0.147354 model2 loss : 0.187054
[00:34:34.774] iteration 28059 : model1 loss : 0.205907 model2 loss : 0.241663
[00:34:35.116] iteration 28060 : model1 loss : 0.166851 model2 loss : 0.196637
[00:34:35.452] iteration 28061 : model1 loss : 0.165030 model2 loss : 0.157543
[00:34:35.786] iteration 28062 : model1 loss : 0.092484 model2 loss : 0.100032
[00:34:36.119] iteration 28063 : model1 loss : 0.190509 model2 loss : 0.182703
[00:34:36.455] iteration 28064 : model1 loss : 0.226794 model2 loss : 0.233497
[00:34:36.787] iteration 28065 : model1 loss : 0.243780 model2 loss : 0.274069
[00:34:37.129] iteration 28066 : model1 loss : 0.269656 model2 loss : 0.304538
[00:34:37.465] iteration 28067 : model1 loss : 0.087828 model2 loss : 0.139501
[00:34:37.801] iteration 28068 : model1 loss : 0.161418 model2 loss : 0.230713
[00:34:38.133] iteration 28069 : model1 loss : 0.173952 model2 loss : 0.230771
[00:34:38.466] iteration 28070 : model1 loss : 0.261830 model2 loss : 0.345701
[00:34:38.808] iteration 28071 : model1 loss : 0.081390 model2 loss : 0.084999
[00:34:39.145] iteration 28072 : model1 loss : 0.203823 model2 loss : 0.213358
[00:34:39.478] iteration 28073 : model1 loss : 0.302929 model2 loss : 0.303427
[00:34:39.814] iteration 28074 : model1 loss : 0.089678 model2 loss : 0.112827
[00:34:40.150] iteration 28075 : model1 loss : 0.245170 model2 loss : 0.255806
[00:34:40.483] iteration 28076 : model1 loss : 0.158453 model2 loss : 0.171138
[00:34:40.815] iteration 28077 : model1 loss : 0.260606 model2 loss : 0.266983
[00:34:41.150] iteration 28078 : model1 loss : 0.162987 model2 loss : 0.179992
[00:34:41.483] iteration 28079 : model1 loss : 0.164281 model2 loss : 0.179702
[00:34:41.824] iteration 28080 : model1 loss : 0.258952 model2 loss : 0.274929
[00:34:42.157] iteration 28081 : model1 loss : 0.171741 model2 loss : 0.181727
[00:34:42.490] iteration 28082 : model1 loss : 0.152891 model2 loss : 0.254479
[00:34:42.821] iteration 28083 : model1 loss : 0.253128 model2 loss : 0.250807
[00:34:43.161] iteration 28084 : model1 loss : 0.324362 model2 loss : 0.344014
[00:34:43.494] iteration 28085 : model1 loss : 0.083235 model2 loss : 0.114129
[00:34:43.830] iteration 28086 : model1 loss : 0.074831 model2 loss : 0.129900
[00:34:44.171] iteration 28087 : model1 loss : 0.326622 model2 loss : 0.337714
[00:34:44.507] iteration 28088 : model1 loss : 0.160376 model2 loss : 0.180210
[00:34:44.844] iteration 28089 : model1 loss : 0.239689 model2 loss : 0.247657
[00:34:45.180] iteration 28090 : model1 loss : 0.079636 model2 loss : 0.162125
[00:34:45.521] iteration 28091 : model1 loss : 0.218573 model2 loss : 0.229770
[00:34:45.859] iteration 28092 : model1 loss : 0.162517 model2 loss : 0.183120
[00:34:46.199] iteration 28093 : model1 loss : 0.186146 model2 loss : 0.240226
[00:34:46.539] iteration 28094 : model1 loss : 0.167197 model2 loss : 0.182656
[00:34:46.879] iteration 28095 : model1 loss : 0.197076 model2 loss : 0.255757
[00:34:47.211] iteration 28096 : model1 loss : 0.154131 model2 loss : 0.181687
[00:34:47.546] iteration 28097 : model1 loss : 0.244635 model2 loss : 0.253136
[00:34:47.879] iteration 28098 : model1 loss : 0.086716 model2 loss : 0.108814
[00:34:48.211] iteration 28099 : model1 loss : 0.080667 model2 loss : 0.091313
[00:34:48.550] iteration 28100 : model1 loss : 0.080067 model2 loss : 0.141599
[00:34:49.192] iteration 28101 : model1 loss : 0.106738 model2 loss : 0.146829
[00:34:49.528] iteration 28102 : model1 loss : 0.077982 model2 loss : 0.107430
[00:34:49.863] iteration 28103 : model1 loss : 0.241209 model2 loss : 0.236002
[00:34:50.199] iteration 28104 : model1 loss : 0.191831 model2 loss : 0.250920
[00:34:50.538] iteration 28105 : model1 loss : 0.166640 model2 loss : 0.185435
[00:34:50.872] iteration 28106 : model1 loss : 0.068138 model2 loss : 0.117558
[00:34:51.205] iteration 28107 : model1 loss : 0.260442 model2 loss : 0.282679
[00:34:51.539] iteration 28108 : model1 loss : 0.239849 model2 loss : 0.258660
[00:34:51.879] iteration 28109 : model1 loss : 0.262657 model2 loss : 0.285487
[00:34:52.219] iteration 28110 : model1 loss : 0.267122 model2 loss : 0.263185
[00:34:52.554] iteration 28111 : model1 loss : 0.091459 model2 loss : 0.149712
[00:34:52.892] iteration 28112 : model1 loss : 0.085819 model2 loss : 0.124737
[00:34:53.226] iteration 28113 : model1 loss : 0.253657 model2 loss : 0.282214
[00:34:53.564] iteration 28114 : model1 loss : 0.180096 model2 loss : 0.209873
[00:34:53.898] iteration 28115 : model1 loss : 0.189949 model2 loss : 0.202455
[00:34:54.231] iteration 28116 : model1 loss : 0.166544 model2 loss : 0.190045
[00:34:54.567] iteration 28117 : model1 loss : 0.095594 model2 loss : 0.091898
[00:34:54.906] iteration 28118 : model1 loss : 0.160932 model2 loss : 0.172156
[00:34:55.239] iteration 28119 : model1 loss : 0.192433 model2 loss : 0.239809
[00:34:55.576] iteration 28120 : model1 loss : 0.148852 model2 loss : 0.166148
[00:34:55.910] iteration 28121 : model1 loss : 0.185814 model2 loss : 0.209723
[00:34:56.242] iteration 28122 : model1 loss : 0.248096 model2 loss : 0.294773
[00:34:56.582] iteration 28123 : model1 loss : 0.155995 model2 loss : 0.168050
[00:34:56.922] iteration 28124 : model1 loss : 0.248072 model2 loss : 0.262485
[00:34:57.260] iteration 28125 : model1 loss : 0.188896 model2 loss : 0.226005
[00:34:57.596] iteration 28126 : model1 loss : 0.073543 model2 loss : 0.103503
[00:34:57.936] iteration 28127 : model1 loss : 0.115942 model2 loss : 0.141174
[00:34:58.273] iteration 28128 : model1 loss : 0.134774 model2 loss : 0.229826
[00:34:58.607] iteration 28129 : model1 loss : 0.266375 model2 loss : 0.259195
[00:34:58.943] iteration 28130 : model1 loss : 0.250855 model2 loss : 0.295377
[00:34:59.280] iteration 28131 : model1 loss : 0.269822 model2 loss : 0.329561
[00:34:59.618] iteration 28132 : model1 loss : 0.153178 model2 loss : 0.178356
[00:34:59.955] iteration 28133 : model1 loss : 0.201549 model2 loss : 0.266150
[00:35:00.291] iteration 28134 : model1 loss : 0.066354 model2 loss : 0.125920
[00:35:00.626] iteration 28135 : model1 loss : 0.174423 model2 loss : 0.186115
[00:35:00.964] iteration 28136 : model1 loss : 0.144763 model2 loss : 0.240080
[00:35:01.300] iteration 28137 : model1 loss : 0.187528 model2 loss : 0.288220
[00:35:01.635] iteration 28138 : model1 loss : 0.199515 model2 loss : 0.237890
[00:35:01.974] iteration 28139 : model1 loss : 0.179744 model2 loss : 0.205860
[00:35:02.313] iteration 28140 : model1 loss : 0.096658 model2 loss : 0.093296
[00:35:02.650] iteration 28141 : model1 loss : 0.240099 model2 loss : 0.261907
[00:35:02.983] iteration 28142 : model1 loss : 0.110466 model2 loss : 0.123580
[00:35:03.315] iteration 28143 : model1 loss : 0.150816 model2 loss : 0.163558
[00:35:03.652] iteration 28144 : model1 loss : 0.156606 model2 loss : 0.192892
[00:35:03.986] iteration 28145 : model1 loss : 0.120309 model2 loss : 0.174422
[00:35:04.319] iteration 28146 : model1 loss : 0.206143 model2 loss : 0.191658
[00:35:04.654] iteration 28147 : model1 loss : 0.112991 model2 loss : 0.414016
[00:35:04.986] iteration 28148 : model1 loss : 0.217877 model2 loss : 0.175374
[00:35:05.319] iteration 28149 : model1 loss : 0.271304 model2 loss : 0.299342
[00:35:05.653] iteration 28150 : model1 loss : 0.156940 model2 loss : 0.190310
[00:35:06.302] iteration 28151 : model1 loss : 0.098065 model2 loss : 0.184396
[00:35:06.638] iteration 28152 : model1 loss : 0.165192 model2 loss : 0.173431
[00:35:06.972] iteration 28153 : model1 loss : 0.146488 model2 loss : 0.161667
[00:35:07.307] iteration 28154 : model1 loss : 0.255509 model2 loss : 0.284290
[00:35:07.641] iteration 28155 : model1 loss : 0.183173 model2 loss : 0.230622
[00:35:07.975] iteration 28156 : model1 loss : 0.238146 model2 loss : 0.222487
[00:35:08.312] iteration 28157 : model1 loss : 0.173967 model2 loss : 0.207815
[00:35:08.649] iteration 28158 : model1 loss : 0.165487 model2 loss : 0.177155
[00:35:08.981] iteration 28159 : model1 loss : 0.092464 model2 loss : 0.210949
[00:35:09.314] iteration 28160 : model1 loss : 0.069482 model2 loss : 0.149632
[00:35:09.647] iteration 28161 : model1 loss : 0.188560 model2 loss : 0.293007
[00:35:09.981] iteration 28162 : model1 loss : 0.154587 model2 loss : 0.169884
[00:35:10.313] iteration 28163 : model1 loss : 0.173457 model2 loss : 0.212741
[00:35:10.646] iteration 28164 : model1 loss : 0.367448 model2 loss : 0.367448
[00:35:10.979] iteration 28165 : model1 loss : 0.114371 model2 loss : 0.118959
[00:35:11.313] iteration 28166 : model1 loss : 0.087764 model2 loss : 0.158112
[00:35:11.645] iteration 28167 : model1 loss : 0.166604 model2 loss : 0.213684
[00:35:11.978] iteration 28168 : model1 loss : 0.095143 model2 loss : 0.404586
[00:35:12.318] iteration 28169 : model1 loss : 0.103081 model2 loss : 0.103600
[00:35:12.655] iteration 28170 : model1 loss : 0.176432 model2 loss : 0.187375
[00:35:12.996] iteration 28171 : model1 loss : 0.086876 model2 loss : 0.108757
[00:35:13.331] iteration 28172 : model1 loss : 0.158359 model2 loss : 0.181248
[00:35:13.666] iteration 28173 : model1 loss : 0.278281 model2 loss : 0.306516
[00:35:13.999] iteration 28174 : model1 loss : 0.276699 model2 loss : 0.302071
[00:35:14.335] iteration 28175 : model1 loss : 0.090204 model2 loss : 0.132953
[00:35:14.669] iteration 28176 : model1 loss : 0.173075 model2 loss : 0.206347
[00:35:15.002] iteration 28177 : model1 loss : 0.077940 model2 loss : 0.119934
[00:35:15.346] iteration 28178 : model1 loss : 0.066873 model2 loss : 0.081455
[00:35:15.687] iteration 28179 : model1 loss : 0.060107 model2 loss : 0.072493
[00:35:16.024] iteration 28180 : model1 loss : 0.257321 model2 loss : 0.288160
[00:35:16.362] iteration 28181 : model1 loss : 0.170478 model2 loss : 0.197509
[00:35:16.699] iteration 28182 : model1 loss : 0.234636 model2 loss : 0.270926
[00:35:17.034] iteration 28183 : model1 loss : 0.150480 model2 loss : 0.163985
[00:35:17.368] iteration 28184 : model1 loss : 0.077549 model2 loss : 0.120331
[00:35:17.705] iteration 28185 : model1 loss : 0.186833 model2 loss : 0.228468
[00:35:18.046] iteration 28186 : model1 loss : 0.184512 model2 loss : 0.213244
[00:35:18.381] iteration 28187 : model1 loss : 0.129549 model2 loss : 0.153181
[00:35:18.717] iteration 28188 : model1 loss : 0.316240 model2 loss : 0.323217
[00:35:19.050] iteration 28189 : model1 loss : 0.277718 model2 loss : 0.292486
[00:35:19.382] iteration 28190 : model1 loss : 0.325425 model2 loss : 0.340613
[00:35:19.714] iteration 28191 : model1 loss : 0.170895 model2 loss : 0.195517
[00:35:20.050] iteration 28192 : model1 loss : 0.313781 model2 loss : 0.315127
[00:35:20.386] iteration 28193 : model1 loss : 0.245661 model2 loss : 0.256008
[00:35:20.724] iteration 28194 : model1 loss : 0.184748 model2 loss : 0.197787
[00:35:21.062] iteration 28195 : model1 loss : 0.169666 model2 loss : 0.197827
[00:35:21.400] iteration 28196 : model1 loss : 0.184765 model2 loss : 0.156565
[00:35:21.738] iteration 28197 : model1 loss : 0.155973 model2 loss : 0.160742
[00:35:22.075] iteration 28198 : model1 loss : 0.162348 model2 loss : 0.219307
[00:35:22.413] iteration 28199 : model1 loss : 0.093908 model2 loss : 0.115426
[00:35:22.751] iteration 28200 : model1 loss : 0.186763 model2 loss : 0.202914
[00:35:23.410] iteration 28201 : model1 loss : 0.269331 model2 loss : 0.334029
[00:35:23.751] iteration 28202 : model1 loss : 0.067075 model2 loss : 0.074332
[00:35:24.096] iteration 28203 : model1 loss : 0.219819 model2 loss : 0.263485
[00:35:24.434] iteration 28204 : model1 loss : 0.240533 model2 loss : 0.243206
[00:35:24.772] iteration 28205 : model1 loss : 0.164834 model2 loss : 0.176270
[00:35:25.111] iteration 28206 : model1 loss : 0.148994 model2 loss : 0.170272
[00:35:25.453] iteration 28207 : model1 loss : 0.240674 model2 loss : 0.256717
[00:35:25.791] iteration 28208 : model1 loss : 0.359044 model2 loss : 0.366364
[00:35:26.128] iteration 28209 : model1 loss : 0.201255 model2 loss : 0.224488
[00:35:26.466] iteration 28210 : model1 loss : 0.098591 model2 loss : 0.195053
[00:35:26.806] iteration 28211 : model1 loss : 0.193106 model2 loss : 0.195669
[00:35:27.144] iteration 28212 : model1 loss : 0.253900 model2 loss : 0.288374
[00:35:27.481] iteration 28213 : model1 loss : 0.166738 model2 loss : 0.218605
[00:35:27.817] iteration 28214 : model1 loss : 0.164964 model2 loss : 0.206243
[00:35:28.160] iteration 28215 : model1 loss : 0.098036 model2 loss : 0.096866
[00:35:28.498] iteration 28216 : model1 loss : 0.251199 model2 loss : 0.249767
[00:35:28.834] iteration 28217 : model1 loss : 0.075723 model2 loss : 0.099134
[00:35:29.171] iteration 28218 : model1 loss : 0.159825 model2 loss : 0.270489
[00:35:29.507] iteration 28219 : model1 loss : 0.228064 model2 loss : 0.240343
[00:35:29.847] iteration 28220 : model1 loss : 0.110305 model2 loss : 0.189700
[00:35:30.184] iteration 28221 : model1 loss : 0.157494 model2 loss : 0.189773
[00:35:30.524] iteration 28222 : model1 loss : 0.148087 model2 loss : 0.165360
[00:35:30.867] iteration 28223 : model1 loss : 0.290486 model2 loss : 0.264180
[00:35:31.204] iteration 28224 : model1 loss : 0.231777 model2 loss : 0.245746
[00:35:31.543] iteration 28225 : model1 loss : 0.243697 model2 loss : 0.247356
[00:35:31.880] iteration 28226 : model1 loss : 0.084596 model2 loss : 0.098931
[00:35:32.218] iteration 28227 : model1 loss : 0.312855 model2 loss : 0.315672
[00:35:32.555] iteration 28228 : model1 loss : 0.193099 model2 loss : 0.231158
[00:35:32.893] iteration 28229 : model1 loss : 0.096284 model2 loss : 0.138808
[00:35:33.233] iteration 28230 : model1 loss : 0.202472 model2 loss : 0.259298
[00:35:33.572] iteration 28231 : model1 loss : 0.171472 model2 loss : 0.176210
[00:35:33.912] iteration 28232 : model1 loss : 0.157111 model2 loss : 0.181788
[00:35:34.249] iteration 28233 : model1 loss : 0.106223 model2 loss : 0.087294
[00:35:34.588] iteration 28234 : model1 loss : 0.092901 model2 loss : 0.408138
[00:35:34.926] iteration 28235 : model1 loss : 0.163117 model2 loss : 0.198110
[00:35:35.262] iteration 28236 : model1 loss : 0.116832 model2 loss : 0.212311
[00:35:35.599] iteration 28237 : model1 loss : 0.094893 model2 loss : 0.123089
[00:35:35.938] iteration 28238 : model1 loss : 0.160410 model2 loss : 0.231530
[00:35:36.278] iteration 28239 : model1 loss : 0.062117 model2 loss : 0.105617
[00:35:36.614] iteration 28240 : model1 loss : 0.069464 model2 loss : 0.110235
[00:35:36.947] iteration 28241 : model1 loss : 0.318222 model2 loss : 0.325621
[00:35:37.279] iteration 28242 : model1 loss : 0.172391 model2 loss : 0.195409
[00:35:37.614] iteration 28243 : model1 loss : 0.249155 model2 loss : 0.272727
[00:35:37.946] iteration 28244 : model1 loss : 0.243337 model2 loss : 0.310535
[00:35:38.278] iteration 28245 : model1 loss : 0.175759 model2 loss : 0.188837
[00:35:38.616] iteration 28246 : model1 loss : 0.141290 model2 loss : 0.156890
[00:35:38.954] iteration 28247 : model1 loss : 0.126183 model2 loss : 0.217900
[00:35:39.290] iteration 28248 : model1 loss : 0.077730 model2 loss : 0.106298
[00:35:39.629] iteration 28249 : model1 loss : 0.181923 model2 loss : 0.229690
[00:35:39.962] iteration 28250 : model1 loss : 0.328241 model2 loss : 0.338802
[00:35:40.625] iteration 28251 : model1 loss : 0.256364 model2 loss : 0.288919
[00:35:40.958] iteration 28252 : model1 loss : 0.177552 model2 loss : 0.230860
[00:35:41.295] iteration 28253 : model1 loss : 0.251963 model2 loss : 0.314988
[00:35:41.636] iteration 28254 : model1 loss : 0.309506 model2 loss : 0.329383
[00:35:41.967] iteration 28255 : model1 loss : 0.166801 model2 loss : 0.174968
[00:35:42.301] iteration 28256 : model1 loss : 0.178488 model2 loss : 0.188830
[00:35:42.635] iteration 28257 : model1 loss : 0.170568 model2 loss : 0.166016
[00:35:42.967] iteration 28258 : model1 loss : 0.128076 model2 loss : 0.156540
[00:35:43.299] iteration 28259 : model1 loss : 0.094804 model2 loss : 0.110959
[00:35:43.643] iteration 28260 : model1 loss : 0.074509 model2 loss : 0.167073
[00:35:43.981] iteration 28261 : model1 loss : 0.189197 model2 loss : 0.216082
[00:35:44.316] iteration 28262 : model1 loss : 0.325927 model2 loss : 0.339233
[00:35:44.652] iteration 28263 : model1 loss : 0.277952 model2 loss : 0.301763
[00:35:44.990] iteration 28264 : model1 loss : 0.312012 model2 loss : 0.340141
[00:35:45.324] iteration 28265 : model1 loss : 0.195886 model2 loss : 0.184642
[00:35:45.657] iteration 28266 : model1 loss : 0.149982 model2 loss : 0.175928
[00:35:45.994] iteration 28267 : model1 loss : 0.072982 model2 loss : 0.093435
[00:35:46.333] iteration 28268 : model1 loss : 0.168835 model2 loss : 0.222164
[00:35:46.671] iteration 28269 : model1 loss : 0.182782 model2 loss : 0.196229
[00:35:47.005] iteration 28270 : model1 loss : 0.296106 model2 loss : 0.340830
[00:35:47.346] iteration 28271 : model1 loss : 0.157290 model2 loss : 0.190386
[00:35:47.709] iteration 28272 : model1 loss : 0.122952 model2 loss : 0.265295
[00:35:48.046] iteration 28273 : model1 loss : 0.258895 model2 loss : 0.266108
[00:35:48.378] iteration 28274 : model1 loss : 0.170542 model2 loss : 0.215038
[00:35:48.715] iteration 28275 : model1 loss : 0.084053 model2 loss : 0.131329
[00:35:49.054] iteration 28276 : model1 loss : 0.248008 model2 loss : 0.208671
[00:35:49.386] iteration 28277 : model1 loss : 0.070096 model2 loss : 0.122739
[00:35:49.726] iteration 28278 : model1 loss : 0.151525 model2 loss : 0.176853
[00:35:50.062] iteration 28279 : model1 loss : 0.087356 model2 loss : 0.107802
[00:35:50.404] iteration 28280 : model1 loss : 0.154947 model2 loss : 0.184746
[00:35:50.740] iteration 28281 : model1 loss : 0.265179 model2 loss : 0.256126
[00:35:51.077] iteration 28282 : model1 loss : 0.148623 model2 loss : 0.156617
[00:35:51.417] iteration 28283 : model1 loss : 0.079810 model2 loss : 0.096533
[00:35:51.754] iteration 28284 : model1 loss : 0.090209 model2 loss : 0.218163
[00:35:52.088] iteration 28285 : model1 loss : 0.265664 model2 loss : 0.274836
[00:35:52.419] iteration 28286 : model1 loss : 0.321358 model2 loss : 0.333745
[00:35:52.752] iteration 28287 : model1 loss : 0.272574 model2 loss : 0.298673
[00:35:53.084] iteration 28288 : model1 loss : 0.142127 model2 loss : 0.177196
[00:35:53.417] iteration 28289 : model1 loss : 0.152552 model2 loss : 0.169683
[00:35:53.755] iteration 28290 : model1 loss : 0.246176 model2 loss : 0.299640
[00:35:54.091] iteration 28291 : model1 loss : 0.267299 model2 loss : 0.261424
[00:35:54.430] iteration 28292 : model1 loss : 0.173389 model2 loss : 0.198647
[00:35:54.762] iteration 28293 : model1 loss : 0.172355 model2 loss : 0.205087
[00:35:55.100] iteration 28294 : model1 loss : 0.319700 model2 loss : 0.344444
[00:35:55.439] iteration 28295 : model1 loss : 0.159134 model2 loss : 0.187514
[00:35:55.771] iteration 28296 : model1 loss : 0.175189 model2 loss : 0.162499
[00:35:56.104] iteration 28297 : model1 loss : 0.199592 model2 loss : 0.202630
[00:35:56.442] iteration 28298 : model1 loss : 0.256281 model2 loss : 0.303959
[00:35:56.783] iteration 28299 : model1 loss : 0.245156 model2 loss : 0.298317
[00:35:57.122] iteration 28300 : model1 loss : 0.099674 model2 loss : 0.150418
[00:35:57.778] iteration 28301 : model1 loss : 0.281734 model2 loss : 0.298130
[00:35:58.111] iteration 28302 : model1 loss : 0.262074 model2 loss : 0.242500
[00:35:58.444] iteration 28303 : model1 loss : 0.203902 model2 loss : 0.229457
[00:35:58.776] iteration 28304 : model1 loss : 0.155753 model2 loss : 0.162447
[00:35:59.125] iteration 28305 : model1 loss : 0.246171 model2 loss : 0.257711
[00:35:59.460] iteration 28306 : model1 loss : 0.250139 model2 loss : 0.268250
[00:35:59.793] iteration 28307 : model1 loss : 0.064144 model2 loss : 0.097745
[00:36:00.125] iteration 28308 : model1 loss : 0.243077 model2 loss : 0.258118
[00:36:00.463] iteration 28309 : model1 loss : 0.168313 model2 loss : 0.179547
[00:36:00.795] iteration 28310 : model1 loss : 0.189971 model2 loss : 0.235212
[00:36:01.132] iteration 28311 : model1 loss : 0.318509 model2 loss : 0.321685
[00:36:01.467] iteration 28312 : model1 loss : 0.249999 model2 loss : 0.274531
[00:36:01.804] iteration 28313 : model1 loss : 0.183104 model2 loss : 0.199262
[00:36:02.140] iteration 28314 : model1 loss : 0.168406 model2 loss : 0.180439
[00:36:02.478] iteration 28315 : model1 loss : 0.165059 model2 loss : 0.182142
[00:36:02.811] iteration 28316 : model1 loss : 0.083015 model2 loss : 0.089225
[00:36:03.149] iteration 28317 : model1 loss : 0.069089 model2 loss : 0.116758
[00:36:03.485] iteration 28318 : model1 loss : 0.328012 model2 loss : 0.358537
[00:36:03.821] iteration 28319 : model1 loss : 0.177654 model2 loss : 0.208542
[00:36:04.154] iteration 28320 : model1 loss : 0.163086 model2 loss : 0.194259
[00:36:04.490] iteration 28321 : model1 loss : 0.166581 model2 loss : 0.172165
[00:36:04.828] iteration 28322 : model1 loss : 0.096496 model2 loss : 0.120910
[00:36:05.159] iteration 28323 : model1 loss : 0.246067 model2 loss : 0.279440
[00:36:05.496] iteration 28324 : model1 loss : 0.167892 model2 loss : 0.175043
[00:36:05.832] iteration 28325 : model1 loss : 0.255074 model2 loss : 0.282137
[00:36:06.170] iteration 28326 : model1 loss : 0.149877 model2 loss : 0.151115
[00:36:06.507] iteration 28327 : model1 loss : 0.080355 model2 loss : 0.093507
[00:36:06.844] iteration 28328 : model1 loss : 0.075290 model2 loss : 0.099009
[00:36:07.184] iteration 28329 : model1 loss : 0.193436 model2 loss : 0.219264
[00:36:07.517] iteration 28330 : model1 loss : 0.175013 model2 loss : 0.195291
[00:36:07.854] iteration 28331 : model1 loss : 0.145960 model2 loss : 0.155778
[00:36:08.186] iteration 28332 : model1 loss : 0.178007 model2 loss : 0.250720
[00:36:08.519] iteration 28333 : model1 loss : 0.066660 model2 loss : 0.116147
[00:36:08.852] iteration 28334 : model1 loss : 0.087166 model2 loss : 0.121441
[00:36:09.184] iteration 28335 : model1 loss : 0.144270 model2 loss : 0.155277
[00:36:09.518] iteration 28336 : model1 loss : 0.162876 model2 loss : 0.171148
[00:36:09.851] iteration 28337 : model1 loss : 0.167021 model2 loss : 0.178572
[00:36:10.182] iteration 28338 : model1 loss : 0.111252 model2 loss : 0.150403
[00:36:10.516] iteration 28339 : model1 loss : 0.273937 model2 loss : 0.277641
[00:36:10.847] iteration 28340 : model1 loss : 0.242274 model2 loss : 0.250793
[00:36:11.957] iteration 28341 : model1 loss : 0.415152 model2 loss : 0.423356
[00:36:12.298] iteration 28342 : model1 loss : 0.208657 model2 loss : 0.254400
[00:36:12.633] iteration 28343 : model1 loss : 0.198728 model2 loss : 0.208788
[00:36:12.970] iteration 28344 : model1 loss : 0.164782 model2 loss : 0.160915
[00:36:13.306] iteration 28345 : model1 loss : 0.193825 model2 loss : 0.258356
[00:36:13.638] iteration 28346 : model1 loss : 0.244195 model2 loss : 0.260464
[00:36:13.970] iteration 28347 : model1 loss : 0.244270 model2 loss : 0.256185
[00:36:14.303] iteration 28348 : model1 loss : 0.167999 model2 loss : 0.230861
[00:36:14.640] iteration 28349 : model1 loss : 0.093562 model2 loss : 0.138330
[00:36:14.978] iteration 28350 : model1 loss : 0.053250 model2 loss : 0.058761
[00:36:15.641] iteration 28351 : model1 loss : 0.231925 model2 loss : 0.265736
[00:36:15.975] iteration 28352 : model1 loss : 0.159138 model2 loss : 0.185879
[00:36:16.312] iteration 28353 : model1 loss : 0.178901 model2 loss : 0.197402
[00:36:16.645] iteration 28354 : model1 loss : 0.153510 model2 loss : 0.158783
[00:36:16.981] iteration 28355 : model1 loss : 0.159163 model2 loss : 0.231649
[00:36:17.315] iteration 28356 : model1 loss : 0.256065 model2 loss : 0.341413
[00:36:17.649] iteration 28357 : model1 loss : 0.173450 model2 loss : 0.215651
[00:36:17.991] iteration 28358 : model1 loss : 0.163535 model2 loss : 0.209632
[00:36:18.324] iteration 28359 : model1 loss : 0.245508 model2 loss : 0.278103
[00:36:18.661] iteration 28360 : model1 loss : 0.259503 model2 loss : 0.291174
[00:36:18.997] iteration 28361 : model1 loss : 0.166215 model2 loss : 0.197176
[00:36:19.331] iteration 28362 : model1 loss : 0.109625 model2 loss : 0.125238
[00:36:19.664] iteration 28363 : model1 loss : 0.109248 model2 loss : 0.188747
[00:36:20.001] iteration 28364 : model1 loss : 0.177885 model2 loss : 0.242525
[00:36:20.343] iteration 28365 : model1 loss : 0.175868 model2 loss : 0.192266
[00:36:20.677] iteration 28366 : model1 loss : 0.222540 model2 loss : 0.243439
[00:36:21.011] iteration 28367 : model1 loss : 0.161123 model2 loss : 0.181626
[00:36:21.357] iteration 28368 : model1 loss : 0.178423 model2 loss : 0.241724
[00:36:21.694] iteration 28369 : model1 loss : 0.233423 model2 loss : 0.260381
[00:36:22.030] iteration 28370 : model1 loss : 0.150677 model2 loss : 0.193294
[00:36:22.364] iteration 28371 : model1 loss : 0.163084 model2 loss : 0.421744
[00:36:22.698] iteration 28372 : model1 loss : 0.315685 model2 loss : 0.368137
[00:36:23.038] iteration 28373 : model1 loss : 0.076684 model2 loss : 0.096127
[00:36:23.376] iteration 28374 : model1 loss : 0.163311 model2 loss : 0.214239
[00:36:23.709] iteration 28375 : model1 loss : 0.078692 model2 loss : 0.124927
[00:36:24.041] iteration 28376 : model1 loss : 0.182188 model2 loss : 0.188061
[00:36:24.377] iteration 28377 : model1 loss : 0.191990 model2 loss : 0.219873
[00:36:24.711] iteration 28378 : model1 loss : 0.075385 model2 loss : 0.191194
[00:36:25.043] iteration 28379 : model1 loss : 0.240102 model2 loss : 0.261227
[00:36:25.385] iteration 28380 : model1 loss : 0.237555 model2 loss : 0.248211
[00:36:25.721] iteration 28381 : model1 loss : 0.230525 model2 loss : 0.241257
[00:36:26.055] iteration 28382 : model1 loss : 0.099933 model2 loss : 0.121579
[00:36:26.390] iteration 28383 : model1 loss : 0.327015 model2 loss : 0.325641
[00:36:26.726] iteration 28384 : model1 loss : 0.175867 model2 loss : 0.190107
[00:36:27.063] iteration 28385 : model1 loss : 0.230175 model2 loss : 0.241382
[00:36:27.406] iteration 28386 : model1 loss : 0.137994 model2 loss : 0.184139
[00:36:27.742] iteration 28387 : model1 loss : 0.185909 model2 loss : 0.176979
[00:36:28.080] iteration 28388 : model1 loss : 0.108257 model2 loss : 0.125276
[00:36:28.415] iteration 28389 : model1 loss : 0.069373 model2 loss : 0.075249
[00:36:28.751] iteration 28390 : model1 loss : 0.250475 model2 loss : 0.271984
[00:36:29.083] iteration 28391 : model1 loss : 0.239387 model2 loss : 0.242661
[00:36:29.415] iteration 28392 : model1 loss : 0.241278 model2 loss : 0.251693
[00:36:29.750] iteration 28393 : model1 loss : 0.283639 model2 loss : 0.339564
[00:36:30.094] iteration 28394 : model1 loss : 0.171567 model2 loss : 0.167327
[00:36:30.428] iteration 28395 : model1 loss : 0.075658 model2 loss : 0.090463
[00:36:30.766] iteration 28396 : model1 loss : 0.273133 model2 loss : 0.281622
[00:36:31.467] iteration 28397 : model1 loss : 0.107041 model2 loss : 0.150673
[00:36:31.801] iteration 28398 : model1 loss : 0.068164 model2 loss : 0.145820
[00:36:32.138] iteration 28399 : model1 loss : 0.151550 model2 loss : 0.179647
[00:36:32.473] iteration 28400 : model1 loss : 0.242683 model2 loss : 0.285457
[00:36:33.137] iteration 28401 : model1 loss : 0.239821 model2 loss : 0.280661
[00:36:33.478] iteration 28402 : model1 loss : 0.198534 model2 loss : 0.244773
[00:36:33.816] iteration 28403 : model1 loss : 0.180309 model2 loss : 0.211706
[00:36:34.157] iteration 28404 : model1 loss : 0.187572 model2 loss : 0.186318
[00:36:34.497] iteration 28405 : model1 loss : 0.181201 model2 loss : 0.195624
[00:36:34.833] iteration 28406 : model1 loss : 0.074385 model2 loss : 0.119610
[00:36:35.170] iteration 28407 : model1 loss : 0.253757 model2 loss : 0.262231
[00:36:35.505] iteration 28408 : model1 loss : 0.245979 model2 loss : 0.260225
[00:36:35.840] iteration 28409 : model1 loss : 0.240811 model2 loss : 0.271014
[00:36:36.177] iteration 28410 : model1 loss : 0.238175 model2 loss : 0.255240
[00:36:36.511] iteration 28411 : model1 loss : 0.205862 model2 loss : 0.263260
[00:36:36.847] iteration 28412 : model1 loss : 0.179778 model2 loss : 0.184442
[00:36:37.181] iteration 28413 : model1 loss : 0.186271 model2 loss : 0.208149
[00:36:37.516] iteration 28414 : model1 loss : 0.209125 model2 loss : 0.231785
[00:36:37.849] iteration 28415 : model1 loss : 0.143603 model2 loss : 0.162296
[00:36:38.183] iteration 28416 : model1 loss : 0.104198 model2 loss : 0.116107
[00:36:38.523] iteration 28417 : model1 loss : 0.248595 model2 loss : 0.269502
[00:36:38.856] iteration 28418 : model1 loss : 0.093423 model2 loss : 0.116553
[00:36:39.190] iteration 28419 : model1 loss : 0.138335 model2 loss : 0.149886
[00:36:39.526] iteration 28420 : model1 loss : 0.248964 model2 loss : 0.274542
[00:36:39.858] iteration 28421 : model1 loss : 0.173217 model2 loss : 0.223522
[00:36:40.196] iteration 28422 : model1 loss : 0.327801 model2 loss : 0.331270
[00:36:40.531] iteration 28423 : model1 loss : 0.196663 model2 loss : 0.238453
[00:36:40.865] iteration 28424 : model1 loss : 0.187828 model2 loss : 0.200750
[00:36:41.198] iteration 28425 : model1 loss : 0.176367 model2 loss : 0.194579
[00:36:41.532] iteration 28426 : model1 loss : 0.158277 model2 loss : 0.170417
[00:36:41.867] iteration 28427 : model1 loss : 0.151122 model2 loss : 0.186990
[00:36:42.200] iteration 28428 : model1 loss : 0.174160 model2 loss : 0.193093
[00:36:42.537] iteration 28429 : model1 loss : 0.259127 model2 loss : 0.265603
[00:36:42.871] iteration 28430 : model1 loss : 0.179642 model2 loss : 0.237923
[00:36:43.210] iteration 28431 : model1 loss : 0.228579 model2 loss : 0.268609
[00:36:43.550] iteration 28432 : model1 loss : 0.236350 model2 loss : 0.241135
[00:36:43.888] iteration 28433 : model1 loss : 0.244606 model2 loss : 0.297434
[00:36:44.229] iteration 28434 : model1 loss : 0.241764 model2 loss : 0.267604
[00:36:44.564] iteration 28435 : model1 loss : 0.240529 model2 loss : 0.280707
[00:36:44.901] iteration 28436 : model1 loss : 0.181931 model2 loss : 0.189668
[00:36:45.243] iteration 28437 : model1 loss : 0.098186 model2 loss : 0.181912
[00:36:45.583] iteration 28438 : model1 loss : 0.187020 model2 loss : 0.211775
[00:36:45.926] iteration 28439 : model1 loss : 0.104530 model2 loss : 0.404669
[00:36:46.262] iteration 28440 : model1 loss : 0.096517 model2 loss : 0.111048
[00:36:46.600] iteration 28441 : model1 loss : 0.159511 model2 loss : 0.161767
[00:36:46.934] iteration 28442 : model1 loss : 0.158036 model2 loss : 0.177267
[00:36:47.276] iteration 28443 : model1 loss : 0.242213 model2 loss : 0.282002
[00:36:47.615] iteration 28444 : model1 loss : 0.161015 model2 loss : 0.202909
[00:36:47.951] iteration 28445 : model1 loss : 0.214462 model2 loss : 0.245180
[00:36:48.291] iteration 28446 : model1 loss : 0.086045 model2 loss : 0.216490
[00:36:48.625] iteration 28447 : model1 loss : 0.210583 model2 loss : 0.231166
[00:36:48.962] iteration 28448 : model1 loss : 0.155936 model2 loss : 0.175745
[00:36:49.297] iteration 28449 : model1 loss : 0.182410 model2 loss : 0.234384
[00:36:49.631] iteration 28450 : model1 loss : 0.064251 model2 loss : 0.100209
[00:36:50.284] iteration 28451 : model1 loss : 0.105383 model2 loss : 0.125558
[00:36:50.619] iteration 28452 : model1 loss : 0.241201 model2 loss : 0.256337
[00:36:50.957] iteration 28453 : model1 loss : 0.094941 model2 loss : 0.173014
[00:36:51.293] iteration 28454 : model1 loss : 0.240289 model2 loss : 0.239784
[00:36:51.629] iteration 28455 : model1 loss : 0.162945 model2 loss : 0.192081
[00:36:51.965] iteration 28456 : model1 loss : 0.173653 model2 loss : 0.102205
[00:36:52.298] iteration 28457 : model1 loss : 0.267520 model2 loss : 0.282854
[00:36:52.637] iteration 28458 : model1 loss : 0.222462 model2 loss : 0.333233
[00:36:52.972] iteration 28459 : model1 loss : 0.095006 model2 loss : 0.193822
[00:36:53.308] iteration 28460 : model1 loss : 0.268095 model2 loss : 0.291093
[00:36:53.646] iteration 28461 : model1 loss : 0.068159 model2 loss : 0.085901
[00:36:53.981] iteration 28462 : model1 loss : 0.110849 model2 loss : 0.167628
[00:36:54.313] iteration 28463 : model1 loss : 0.151428 model2 loss : 0.177272
[00:36:54.649] iteration 28464 : model1 loss : 0.071175 model2 loss : 0.099162
[00:36:54.982] iteration 28465 : model1 loss : 0.084313 model2 loss : 0.110494
[00:36:55.318] iteration 28466 : model1 loss : 0.176193 model2 loss : 0.184973
[00:36:55.653] iteration 28467 : model1 loss : 0.128559 model2 loss : 0.135949
[00:36:55.993] iteration 28468 : model1 loss : 0.238885 model2 loss : 0.261800
[00:36:56.336] iteration 28469 : model1 loss : 0.055794 model2 loss : 0.073377
[00:36:56.674] iteration 28470 : model1 loss : 0.172998 model2 loss : 0.243038
[00:36:57.008] iteration 28471 : model1 loss : 0.190559 model2 loss : 0.194871
[00:36:57.359] iteration 28472 : model1 loss : 0.082935 model2 loss : 0.136405
[00:36:57.695] iteration 28473 : model1 loss : 0.282604 model2 loss : 0.271624
[00:36:58.035] iteration 28474 : model1 loss : 0.068361 model2 loss : 0.094815
[00:36:58.372] iteration 28475 : model1 loss : 0.135594 model2 loss : 0.145210
[00:36:58.703] iteration 28476 : model1 loss : 0.081557 model2 loss : 0.122478
[00:36:59.032] iteration 28477 : model1 loss : 0.299040 model2 loss : 0.296466
[00:36:59.364] iteration 28478 : model1 loss : 0.239696 model2 loss : 0.250806
[00:36:59.691] iteration 28479 : model1 loss : 0.163494 model2 loss : 0.172420
[00:37:00.019] iteration 28480 : model1 loss : 0.242313 model2 loss : 0.343253
[00:37:00.350] iteration 28481 : model1 loss : 0.272813 model2 loss : 0.302045
[00:37:00.684] iteration 28482 : model1 loss : 0.185039 model2 loss : 0.231187
[00:37:01.011] iteration 28483 : model1 loss : 0.220549 model2 loss : 0.288644
[00:37:01.340] iteration 28484 : model1 loss : 0.140442 model2 loss : 0.157240
[00:37:01.667] iteration 28485 : model1 loss : 0.279583 model2 loss : 0.292914
[00:37:01.996] iteration 28486 : model1 loss : 0.244476 model2 loss : 0.277502
[00:37:02.325] iteration 28487 : model1 loss : 0.246686 model2 loss : 0.269420
[00:37:02.652] iteration 28488 : model1 loss : 0.147381 model2 loss : 0.164673
[00:37:02.979] iteration 28489 : model1 loss : 0.186060 model2 loss : 0.184054
[00:37:03.311] iteration 28490 : model1 loss : 0.188633 model2 loss : 0.249167
[00:37:03.640] iteration 28491 : model1 loss : 0.195469 model2 loss : 0.262982
[00:37:03.966] iteration 28492 : model1 loss : 0.182153 model2 loss : 0.224476
[00:37:04.292] iteration 28493 : model1 loss : 0.256044 model2 loss : 0.312906
[00:37:04.619] iteration 28494 : model1 loss : 0.172898 model2 loss : 0.204568
[00:37:04.945] iteration 28495 : model1 loss : 0.123969 model2 loss : 0.151661
[00:37:05.272] iteration 28496 : model1 loss : 0.156882 model2 loss : 0.152040
[00:37:05.597] iteration 28497 : model1 loss : 0.169648 model2 loss : 0.178673
[00:37:05.924] iteration 28498 : model1 loss : 0.159795 model2 loss : 0.258670
[00:37:06.250] iteration 28499 : model1 loss : 0.272722 model2 loss : 0.273466
[00:37:06.575] iteration 28500 : model1 loss : 0.244416 model2 loss : 0.254739
[00:37:07.074] iteration 28501 : model1 loss : 0.160042 model2 loss : 0.204377
[00:37:07.401] iteration 28502 : model1 loss : 0.257024 model2 loss : 0.283364
[00:37:07.726] iteration 28503 : model1 loss : 0.077088 model2 loss : 0.088559
[00:37:08.053] iteration 28504 : model1 loss : 0.230448 model2 loss : 0.295266
[00:37:08.378] iteration 28505 : model1 loss : 0.205134 model2 loss : 0.254633
[00:37:08.706] iteration 28506 : model1 loss : 0.215020 model2 loss : 0.249291
[00:37:09.032] iteration 28507 : model1 loss : 0.257854 model2 loss : 0.263941
[00:37:09.357] iteration 28508 : model1 loss : 0.154215 model2 loss : 0.184443
[00:37:09.683] iteration 28509 : model1 loss : 0.282652 model2 loss : 0.283777
[00:37:10.011] iteration 28510 : model1 loss : 0.179985 model2 loss : 0.214537
[00:37:10.337] iteration 28511 : model1 loss : 0.183205 model2 loss : 0.182800
[00:37:10.662] iteration 28512 : model1 loss : 0.162936 model2 loss : 0.208896
[00:37:10.988] iteration 28513 : model1 loss : 0.244034 model2 loss : 0.277776
[00:37:11.317] iteration 28514 : model1 loss : 0.178879 model2 loss : 0.208843
[00:37:11.642] iteration 28515 : model1 loss : 0.255407 model2 loss : 0.287191
[00:37:11.968] iteration 28516 : model1 loss : 0.108240 model2 loss : 0.106845
[00:37:12.293] iteration 28517 : model1 loss : 0.263487 model2 loss : 0.276011
[00:37:12.621] iteration 28518 : model1 loss : 0.248374 model2 loss : 0.269091
[00:37:12.946] iteration 28519 : model1 loss : 0.099387 model2 loss : 0.126916
[00:37:13.271] iteration 28520 : model1 loss : 0.060464 model2 loss : 0.104978
[00:37:13.597] iteration 28521 : model1 loss : 0.095779 model2 loss : 0.115657
[00:37:13.925] iteration 28522 : model1 loss : 0.150603 model2 loss : 0.178231
[00:37:14.250] iteration 28523 : model1 loss : 0.235645 model2 loss : 0.243353
[00:37:14.576] iteration 28524 : model1 loss : 0.247207 model2 loss : 0.274207
[00:37:14.902] iteration 28525 : model1 loss : 0.165926 model2 loss : 0.179431
[00:37:15.228] iteration 28526 : model1 loss : 0.122983 model2 loss : 0.114747
[00:37:15.554] iteration 28527 : model1 loss : 0.236145 model2 loss : 0.266477
[00:37:15.879] iteration 28528 : model1 loss : 0.165768 model2 loss : 0.198967
[00:37:16.205] iteration 28529 : model1 loss : 0.256050 model2 loss : 0.293439
[00:37:16.532] iteration 28530 : model1 loss : 0.240897 model2 loss : 0.268302
[00:37:16.858] iteration 28531 : model1 loss : 0.106705 model2 loss : 0.140626
[00:37:17.186] iteration 28532 : model1 loss : 0.159778 model2 loss : 0.183203
[00:37:17.511] iteration 28533 : model1 loss : 0.188511 model2 loss : 0.237530
[00:37:17.840] iteration 28534 : model1 loss : 0.206489 model2 loss : 0.273277
[00:37:18.165] iteration 28535 : model1 loss : 0.168456 model2 loss : 0.190390
[00:37:18.491] iteration 28536 : model1 loss : 0.234086 model2 loss : 0.254384
[00:37:18.818] iteration 28537 : model1 loss : 0.177229 model2 loss : 0.199637
[00:37:19.146] iteration 28538 : model1 loss : 0.087711 model2 loss : 0.080565
[00:37:19.471] iteration 28539 : model1 loss : 0.297966 model2 loss : 0.272493
[00:37:19.797] iteration 28540 : model1 loss : 0.078364 model2 loss : 0.115485
[00:37:20.123] iteration 28541 : model1 loss : 0.184622 model2 loss : 0.208019
[00:37:20.450] iteration 28542 : model1 loss : 0.111441 model2 loss : 0.137285
[00:37:20.776] iteration 28543 : model1 loss : 0.261035 model2 loss : 0.267173
[00:37:21.102] iteration 28544 : model1 loss : 0.094970 model2 loss : 0.154413
[00:37:21.427] iteration 28545 : model1 loss : 0.114679 model2 loss : 0.140422
[00:37:21.756] iteration 28546 : model1 loss : 0.114306 model2 loss : 0.116047
[00:37:22.082] iteration 28547 : model1 loss : 0.077830 model2 loss : 0.128141
[00:37:22.409] iteration 28548 : model1 loss : 0.230193 model2 loss : 0.301579
[00:37:22.734] iteration 28549 : model1 loss : 0.171907 model2 loss : 0.256221
[00:37:23.062] iteration 28550 : model1 loss : 0.195816 model2 loss : 0.206831
[00:37:23.568] iteration 28551 : model1 loss : 0.152818 model2 loss : 0.196001
[00:37:23.893] iteration 28552 : model1 loss : 0.241755 model2 loss : 0.260646
[00:37:24.219] iteration 28553 : model1 loss : 0.152902 model2 loss : 0.169590
[00:37:24.546] iteration 28554 : model1 loss : 0.162749 model2 loss : 0.175778
[00:37:24.871] iteration 28555 : model1 loss : 0.264633 model2 loss : 0.295172
[00:37:25.197] iteration 28556 : model1 loss : 0.256749 model2 loss : 0.269904
[00:37:25.524] iteration 28557 : model1 loss : 0.189959 model2 loss : 0.223948
[00:37:25.851] iteration 28558 : model1 loss : 0.236245 model2 loss : 0.272655
[00:37:26.177] iteration 28559 : model1 loss : 0.154756 model2 loss : 0.184734
[00:37:26.502] iteration 28560 : model1 loss : 0.170651 model2 loss : 0.243611
[00:37:26.828] iteration 28561 : model1 loss : 0.146688 model2 loss : 0.166987
[00:37:27.155] iteration 28562 : model1 loss : 0.121412 model2 loss : 0.183687
[00:37:27.481] iteration 28563 : model1 loss : 0.140635 model2 loss : 0.155674
[00:37:27.808] iteration 28564 : model1 loss : 0.247226 model2 loss : 0.270436
[00:37:28.132] iteration 28565 : model1 loss : 0.260087 model2 loss : 0.258444
[00:37:28.461] iteration 28566 : model1 loss : 0.245252 model2 loss : 0.273079
[00:37:28.787] iteration 28567 : model1 loss : 0.170618 model2 loss : 0.188555
[00:37:29.114] iteration 28568 : model1 loss : 0.174265 model2 loss : 0.210032
[00:37:29.440] iteration 28569 : model1 loss : 0.089956 model2 loss : 0.110842
[00:37:29.768] iteration 28570 : model1 loss : 0.149230 model2 loss : 0.154129
[00:37:30.094] iteration 28571 : model1 loss : 0.161301 model2 loss : 0.198485
[00:37:30.419] iteration 28572 : model1 loss : 0.226497 model2 loss : 0.288432
[00:37:30.744] iteration 28573 : model1 loss : 0.255520 model2 loss : 0.260213
[00:37:31.072] iteration 28574 : model1 loss : 0.242526 model2 loss : 0.258473
[00:37:31.397] iteration 28575 : model1 loss : 0.286674 model2 loss : 0.296685
[00:37:31.723] iteration 28576 : model1 loss : 0.168583 model2 loss : 0.218367
[00:37:32.049] iteration 28577 : model1 loss : 0.190396 model2 loss : 0.273147
[00:37:32.376] iteration 28578 : model1 loss : 0.164345 model2 loss : 0.167600
[00:37:32.702] iteration 28579 : model1 loss : 0.141503 model2 loss : 0.238793
[00:37:33.027] iteration 28580 : model1 loss : 0.162909 model2 loss : 0.185341
[00:37:33.353] iteration 28581 : model1 loss : 0.245492 model2 loss : 0.256223
[00:37:33.682] iteration 28582 : model1 loss : 0.253126 model2 loss : 0.261401
[00:37:34.007] iteration 28583 : model1 loss : 0.192044 model2 loss : 0.235333
[00:37:34.333] iteration 28584 : model1 loss : 0.074100 model2 loss : 0.099405
[00:37:34.659] iteration 28585 : model1 loss : 0.169055 model2 loss : 0.183064
[00:37:34.986] iteration 28586 : model1 loss : 0.094619 model2 loss : 0.115767
[00:37:35.312] iteration 28587 : model1 loss : 0.148601 model2 loss : 0.180701
[00:37:35.638] iteration 28588 : model1 loss : 0.233204 model2 loss : 0.271546
[00:37:35.966] iteration 28589 : model1 loss : 0.159586 model2 loss : 0.152287
[00:37:36.293] iteration 28590 : model1 loss : 0.176749 model2 loss : 0.220076
[00:37:36.619] iteration 28591 : model1 loss : 0.158216 model2 loss : 0.214297
[00:37:36.944] iteration 28592 : model1 loss : 0.094560 model2 loss : 0.131983
[00:37:37.271] iteration 28593 : model1 loss : 0.094539 model2 loss : 0.125720
[00:37:37.599] iteration 28594 : model1 loss : 0.165568 model2 loss : 0.181270
[00:37:37.924] iteration 28595 : model1 loss : 0.147716 model2 loss : 0.174127
[00:37:38.250] iteration 28596 : model1 loss : 0.166769 model2 loss : 0.179846
[00:37:38.577] iteration 28597 : model1 loss : 0.150362 model2 loss : 0.166545
[00:37:38.905] iteration 28598 : model1 loss : 0.169537 model2 loss : 0.204153
[00:37:39.231] iteration 28599 : model1 loss : 0.141114 model2 loss : 0.172935
[00:37:39.557] iteration 28600 : model1 loss : 0.209380 model2 loss : 0.203615
[00:37:40.077] iteration 28601 : model1 loss : 0.130827 model2 loss : 0.133748
[00:37:40.404] iteration 28602 : model1 loss : 0.175197 model2 loss : 0.269172
[00:37:40.730] iteration 28603 : model1 loss : 0.169901 model2 loss : 0.183265
[00:37:41.056] iteration 28604 : model1 loss : 0.100864 model2 loss : 0.118277
[00:37:41.383] iteration 28605 : model1 loss : 0.076686 model2 loss : 0.092500
[00:37:41.710] iteration 28606 : model1 loss : 0.079420 model2 loss : 0.113649
[00:37:42.036] iteration 28607 : model1 loss : 0.154879 model2 loss : 0.162928
[00:37:42.362] iteration 28608 : model1 loss : 0.113771 model2 loss : 0.132729
[00:37:42.688] iteration 28609 : model1 loss : 0.165298 model2 loss : 0.158541
[00:37:43.017] iteration 28610 : model1 loss : 0.250416 model2 loss : 0.320646
[00:37:43.342] iteration 28611 : model1 loss : 0.156943 model2 loss : 0.167798
[00:37:43.668] iteration 28612 : model1 loss : 0.107508 model2 loss : 0.130345
[00:37:43.993] iteration 28613 : model1 loss : 0.213207 model2 loss : 0.212322
[00:37:44.321] iteration 28614 : model1 loss : 0.176994 model2 loss : 0.202198
[00:37:44.648] iteration 28615 : model1 loss : 0.176810 model2 loss : 0.264980
[00:37:44.974] iteration 28616 : model1 loss : 0.164295 model2 loss : 0.199785
[00:37:45.300] iteration 28617 : model1 loss : 0.241752 model2 loss : 0.252560
[00:37:45.628] iteration 28618 : model1 loss : 0.189991 model2 loss : 0.223389
[00:37:45.954] iteration 28619 : model1 loss : 0.263317 model2 loss : 0.304717
[00:37:46.280] iteration 28620 : model1 loss : 0.054612 model2 loss : 0.068233
[00:37:46.607] iteration 28621 : model1 loss : 0.156855 model2 loss : 0.164746
[00:37:46.933] iteration 28622 : model1 loss : 0.141317 model2 loss : 0.146853
[00:37:47.258] iteration 28623 : model1 loss : 0.253235 model2 loss : 0.269149
[00:37:47.583] iteration 28624 : model1 loss : 0.267891 model2 loss : 0.278557
[00:37:47.910] iteration 28625 : model1 loss : 0.094766 model2 loss : 0.176210
[00:37:48.238] iteration 28626 : model1 loss : 0.234621 model2 loss : 0.253642
[00:37:48.564] iteration 28627 : model1 loss : 0.168619 model2 loss : 0.190844
[00:37:48.891] iteration 28628 : model1 loss : 0.266263 model2 loss : 0.288244
[00:37:49.217] iteration 28629 : model1 loss : 0.194559 model2 loss : 0.265866
[00:37:49.544] iteration 28630 : model1 loss : 0.112787 model2 loss : 0.194713
[00:37:49.869] iteration 28631 : model1 loss : 0.235159 model2 loss : 0.266508
[00:37:50.195] iteration 28632 : model1 loss : 0.172357 model2 loss : 0.197276
[00:37:50.520] iteration 28633 : model1 loss : 0.233199 model2 loss : 0.266042
[00:37:50.848] iteration 28634 : model1 loss : 0.203901 model2 loss : 0.231816
[00:37:51.173] iteration 28635 : model1 loss : 0.267656 model2 loss : 0.332262
[00:37:51.500] iteration 28636 : model1 loss : 0.096628 model2 loss : 0.168121
[00:37:51.826] iteration 28637 : model1 loss : 0.327074 model2 loss : 0.338787
[00:37:52.153] iteration 28638 : model1 loss : 0.152969 model2 loss : 0.190016
[00:37:52.479] iteration 28639 : model1 loss : 0.083090 model2 loss : 0.144781
[00:37:52.805] iteration 28640 : model1 loss : 0.153020 model2 loss : 0.167157
[00:37:53.131] iteration 28641 : model1 loss : 0.270627 model2 loss : 0.249340
[00:37:53.458] iteration 28642 : model1 loss : 0.172689 model2 loss : 0.183287
[00:37:53.784] iteration 28643 : model1 loss : 0.083346 model2 loss : 0.113964
[00:37:54.110] iteration 28644 : model1 loss : 0.097056 model2 loss : 0.139542
[00:37:54.436] iteration 28645 : model1 loss : 0.259869 model2 loss : 0.265289
[00:37:54.763] iteration 28646 : model1 loss : 0.086488 model2 loss : 0.116332
[00:37:55.089] iteration 28647 : model1 loss : 0.191747 model2 loss : 0.200823
[00:37:55.415] iteration 28648 : model1 loss : 0.135933 model2 loss : 0.199519
[00:37:55.741] iteration 28649 : model1 loss : 0.150536 model2 loss : 0.205724
[00:37:56.070] iteration 28650 : model1 loss : 0.070908 model2 loss : 0.195225
[00:37:56.623] iteration 28651 : model1 loss : 0.145934 model2 loss : 0.153139
[00:37:56.949] iteration 28652 : model1 loss : 0.165738 model2 loss : 0.127438
[00:37:57.275] iteration 28653 : model1 loss : 0.163320 model2 loss : 0.194343
[00:37:57.603] iteration 28654 : model1 loss : 0.147649 model2 loss : 0.207515
[00:37:57.929] iteration 28655 : model1 loss : 0.077075 model2 loss : 0.143421
[00:37:58.254] iteration 28656 : model1 loss : 0.090619 model2 loss : 0.219633
[00:37:58.580] iteration 28657 : model1 loss : 0.160043 model2 loss : 0.190353
[00:37:58.911] iteration 28658 : model1 loss : 0.167011 model2 loss : 0.243418
[00:37:59.237] iteration 28659 : model1 loss : 0.164779 model2 loss : 0.147119
[00:37:59.563] iteration 28660 : model1 loss : 0.198681 model2 loss : 0.222800
[00:37:59.888] iteration 28661 : model1 loss : 0.099669 model2 loss : 0.125024
[00:38:00.215] iteration 28662 : model1 loss : 0.241381 model2 loss : 0.260023
[00:38:00.541] iteration 28663 : model1 loss : 0.284869 model2 loss : 0.302019
[00:38:00.867] iteration 28664 : model1 loss : 0.198267 model2 loss : 0.210746
[00:38:01.193] iteration 28665 : model1 loss : 0.158230 model2 loss : 0.171128
[00:38:01.520] iteration 28666 : model1 loss : 0.149082 model2 loss : 0.190475
[00:38:01.846] iteration 28667 : model1 loss : 0.272982 model2 loss : 0.266035
[00:38:02.173] iteration 28668 : model1 loss : 0.088765 model2 loss : 0.101885
[00:38:02.498] iteration 28669 : model1 loss : 0.094669 model2 loss : 0.165325
[00:38:02.826] iteration 28670 : model1 loss : 0.269809 model2 loss : 0.294045
[00:38:03.152] iteration 28671 : model1 loss : 0.274107 model2 loss : 0.290736
[00:38:03.477] iteration 28672 : model1 loss : 0.317590 model2 loss : 0.334167
[00:38:03.804] iteration 28673 : model1 loss : 0.225400 model2 loss : 0.232038
[00:38:04.130] iteration 28674 : model1 loss : 0.182565 model2 loss : 0.207500
[00:38:04.456] iteration 28675 : model1 loss : 0.171109 model2 loss : 0.174388
[00:38:04.782] iteration 28676 : model1 loss : 0.248028 model2 loss : 0.322681
[00:38:05.107] iteration 28677 : model1 loss : 0.156503 model2 loss : 0.194099
[00:38:05.435] iteration 28678 : model1 loss : 0.087231 model2 loss : 0.149325
[00:38:05.761] iteration 28679 : model1 loss : 0.246424 model2 loss : 0.276646
[00:38:06.082] iteration 28680 : model1 loss : 0.203118 model2 loss : 0.225365
[00:38:06.408] iteration 28681 : model1 loss : 0.177764 model2 loss : 0.208383
[00:38:06.731] iteration 28682 : model1 loss : 0.161793 model2 loss : 0.176942
[00:38:07.054] iteration 28683 : model1 loss : 0.076058 model2 loss : 0.098948
[00:38:07.378] iteration 28684 : model1 loss : 0.194997 model2 loss : 0.193964
[00:38:07.701] iteration 28685 : model1 loss : 0.083430 model2 loss : 0.179156
[00:38:08.028] iteration 28686 : model1 loss : 0.280701 model2 loss : 0.280352
[00:38:08.349] iteration 28687 : model1 loss : 0.090824 model2 loss : 0.135912
[00:38:08.670] iteration 28688 : model1 loss : 0.081687 model2 loss : 0.098781
[00:38:08.991] iteration 28689 : model1 loss : 0.232772 model2 loss : 0.278479
[00:38:09.314] iteration 28690 : model1 loss : 0.155737 model2 loss : 0.184584
[00:38:09.635] iteration 28691 : model1 loss : 0.289538 model2 loss : 0.320600
[00:38:09.956] iteration 28692 : model1 loss : 0.179805 model2 loss : 0.214859
[00:38:10.281] iteration 28693 : model1 loss : 0.298766 model2 loss : 0.309147
[00:38:10.604] iteration 28694 : model1 loss : 0.168081 model2 loss : 0.173381
[00:38:10.924] iteration 28695 : model1 loss : 0.237784 model2 loss : 0.269884
[00:38:11.246] iteration 28696 : model1 loss : 0.239902 model2 loss : 0.245444
[00:38:11.571] iteration 28697 : model1 loss : 0.173532 model2 loss : 0.186081
[00:38:11.896] iteration 28698 : model1 loss : 0.169264 model2 loss : 0.174024
[00:38:12.216] iteration 28699 : model1 loss : 0.064245 model2 loss : 0.110648
[00:38:12.538] iteration 28700 : model1 loss : 0.165598 model2 loss : 0.190369
[00:38:13.087] iteration 28701 : model1 loss : 0.151497 model2 loss : 0.163866
[00:38:13.411] iteration 28702 : model1 loss : 0.260985 model2 loss : 0.274222
[00:38:13.737] iteration 28703 : model1 loss : 0.298344 model2 loss : 0.337799
[00:38:14.060] iteration 28704 : model1 loss : 0.177482 model2 loss : 0.183267
[00:38:14.381] iteration 28705 : model1 loss : 0.336421 model2 loss : 0.401990
[00:38:14.703] iteration 28706 : model1 loss : 0.062043 model2 loss : 0.084463
[00:38:15.023] iteration 28707 : model1 loss : 0.252574 model2 loss : 0.294958
[00:38:15.345] iteration 28708 : model1 loss : 0.180537 model2 loss : 0.225134
[00:38:15.666] iteration 28709 : model1 loss : 0.243573 model2 loss : 0.284655
[00:38:15.988] iteration 28710 : model1 loss : 0.246463 model2 loss : 0.270689
[00:38:16.309] iteration 28711 : model1 loss : 0.089908 model2 loss : 0.154071
[00:38:16.632] iteration 28712 : model1 loss : 0.115199 model2 loss : 0.137470
[00:38:16.952] iteration 28713 : model1 loss : 0.181890 model2 loss : 0.221077
[00:38:17.275] iteration 28714 : model1 loss : 0.161949 model2 loss : 0.176115
[00:38:17.596] iteration 28715 : model1 loss : 0.072989 model2 loss : 0.096928
[00:38:17.917] iteration 28716 : model1 loss : 0.244357 model2 loss : 0.235492
[00:38:18.238] iteration 28717 : model1 loss : 0.189831 model2 loss : 0.241891
[00:38:18.565] iteration 28718 : model1 loss : 0.110970 model2 loss : 0.129544
[00:38:18.891] iteration 28719 : model1 loss : 0.267189 model2 loss : 0.312450
[00:38:19.214] iteration 28720 : model1 loss : 0.243492 model2 loss : 0.286807
[00:38:19.536] iteration 28721 : model1 loss : 0.230772 model2 loss : 0.276666
[00:38:19.858] iteration 28722 : model1 loss : 0.150586 model2 loss : 0.216556
[00:38:20.179] iteration 28723 : model1 loss : 0.266006 model2 loss : 0.282418
[00:38:20.502] iteration 28724 : model1 loss : 0.304843 model2 loss : 0.230723
[00:38:20.823] iteration 28725 : model1 loss : 0.213022 model2 loss : 0.214020
[00:38:21.144] iteration 28726 : model1 loss : 0.123492 model2 loss : 0.134965
[00:38:21.468] iteration 28727 : model1 loss : 0.174451 model2 loss : 0.184154
[00:38:21.793] iteration 28728 : model1 loss : 0.147256 model2 loss : 0.186559
[00:38:22.114] iteration 28729 : model1 loss : 0.260357 model2 loss : 0.271293
[00:38:22.437] iteration 28730 : model1 loss : 0.261635 model2 loss : 0.277529
[00:38:22.759] iteration 28731 : model1 loss : 0.163190 model2 loss : 0.173820
[00:38:23.083] iteration 28732 : model1 loss : 0.095245 model2 loss : 0.122945
[00:38:23.404] iteration 28733 : model1 loss : 0.223955 model2 loss : 0.249819
[00:38:23.728] iteration 28734 : model1 loss : 0.166107 model2 loss : 0.188170
[00:38:24.049] iteration 28735 : model1 loss : 0.282115 model2 loss : 0.314266
[00:38:24.374] iteration 28736 : model1 loss : 0.112194 model2 loss : 0.123168
[00:38:24.698] iteration 28737 : model1 loss : 0.177117 model2 loss : 0.239385
[00:38:25.020] iteration 28738 : model1 loss : 0.241698 model2 loss : 0.251589
[00:38:25.341] iteration 28739 : model1 loss : 0.195657 model2 loss : 0.232766
[00:38:25.662] iteration 28740 : model1 loss : 0.179040 model2 loss : 0.204621
[00:38:25.983] iteration 28741 : model1 loss : 0.157627 model2 loss : 0.264501
[00:38:26.307] iteration 28742 : model1 loss : 0.105089 model2 loss : 0.129106
[00:38:26.632] iteration 28743 : model1 loss : 0.257559 model2 loss : 0.259937
[00:38:26.954] iteration 28744 : model1 loss : 0.147413 model2 loss : 0.157954
[00:38:27.279] iteration 28745 : model1 loss : 0.092608 model2 loss : 0.097542
[00:38:27.605] iteration 28746 : model1 loss : 0.102031 model2 loss : 0.165580
[00:38:27.931] iteration 28747 : model1 loss : 0.086898 model2 loss : 0.121292
[00:38:28.257] iteration 28748 : model1 loss : 0.149985 model2 loss : 0.155825
[00:38:28.582] iteration 28749 : model1 loss : 0.353579 model2 loss : 0.418945
[00:38:28.910] iteration 28750 : model1 loss : 0.246540 model2 loss : 0.265886
[00:38:29.413] iteration 28751 : model1 loss : 0.169096 model2 loss : 0.190357
[00:38:29.734] iteration 28752 : model1 loss : 0.086692 model2 loss : 0.142459
[00:38:30.059] iteration 28753 : model1 loss : 0.179613 model2 loss : 0.204825
[00:38:30.386] iteration 28754 : model1 loss : 0.191896 model2 loss : 0.237390
[00:38:30.709] iteration 28755 : model1 loss : 0.222355 model2 loss : 0.248669
[00:38:31.030] iteration 28756 : model1 loss : 0.183048 model2 loss : 0.221620
[00:38:31.357] iteration 28757 : model1 loss : 0.240286 model2 loss : 0.251892
[00:38:31.684] iteration 28758 : model1 loss : 0.165775 model2 loss : 0.175708
[00:38:32.005] iteration 28759 : model1 loss : 0.267645 model2 loss : 0.261018
[00:38:32.326] iteration 28760 : model1 loss : 0.189003 model2 loss : 0.234720
[00:38:32.647] iteration 28761 : model1 loss : 0.091936 model2 loss : 0.117894
[00:38:32.970] iteration 28762 : model1 loss : 0.206071 model2 loss : 0.192795
[00:38:33.293] iteration 28763 : model1 loss : 0.175930 model2 loss : 0.198791
[00:38:33.615] iteration 28764 : model1 loss : 0.327620 model2 loss : 0.326254
[00:38:33.936] iteration 28765 : model1 loss : 0.258228 model2 loss : 0.303934
[00:38:34.258] iteration 28766 : model1 loss : 0.169323 model2 loss : 0.183377
[00:38:34.579] iteration 28767 : model1 loss : 0.089962 model2 loss : 0.153228
[00:38:34.900] iteration 28768 : model1 loss : 0.150113 model2 loss : 0.159502
[00:38:35.222] iteration 28769 : model1 loss : 0.157198 model2 loss : 0.182046
[00:38:35.544] iteration 28770 : model1 loss : 0.179939 model2 loss : 0.198693
[00:38:35.866] iteration 28771 : model1 loss : 0.239399 model2 loss : 0.255237
[00:38:36.187] iteration 28772 : model1 loss : 0.175023 model2 loss : 0.200794
[00:38:36.509] iteration 28773 : model1 loss : 0.255467 model2 loss : 0.279769
[00:38:36.831] iteration 28774 : model1 loss : 0.262353 model2 loss : 0.297703
[00:38:37.152] iteration 28775 : model1 loss : 0.151890 model2 loss : 0.171403
[00:38:37.474] iteration 28776 : model1 loss : 0.063400 model2 loss : 0.097307
[00:38:37.796] iteration 28777 : model1 loss : 0.252552 model2 loss : 0.262346
[00:38:38.119] iteration 28778 : model1 loss : 0.315544 model2 loss : 0.322261
[00:38:38.440] iteration 28779 : model1 loss : 0.156492 model2 loss : 0.180942
[00:38:38.761] iteration 28780 : model1 loss : 0.244125 model2 loss : 0.270091
[00:38:39.082] iteration 28781 : model1 loss : 0.082809 model2 loss : 0.123610
[00:38:39.404] iteration 28782 : model1 loss : 0.186243 model2 loss : 0.202211
[00:38:39.726] iteration 28783 : model1 loss : 0.174371 model2 loss : 0.304787
[00:38:40.047] iteration 28784 : model1 loss : 0.073710 model2 loss : 0.128421
[00:38:40.368] iteration 28785 : model1 loss : 0.320669 model2 loss : 0.328209
[00:38:40.692] iteration 28786 : model1 loss : 0.329523 model2 loss : 0.339560
[00:38:41.013] iteration 28787 : model1 loss : 0.256889 model2 loss : 0.282152
[00:38:41.334] iteration 28788 : model1 loss : 0.147455 model2 loss : 0.238887
[00:38:41.655] iteration 28789 : model1 loss : 0.075029 model2 loss : 0.079381
[00:38:41.977] iteration 28790 : model1 loss : 0.099759 model2 loss : 0.134785
[00:38:42.298] iteration 28791 : model1 loss : 0.152590 model2 loss : 0.164063
[00:38:42.619] iteration 28792 : model1 loss : 0.263049 model2 loss : 0.298153
[00:38:42.943] iteration 28793 : model1 loss : 0.093413 model2 loss : 0.128305
[00:38:43.266] iteration 28794 : model1 loss : 0.084011 model2 loss : 0.114549
[00:38:43.590] iteration 28795 : model1 loss : 0.201301 model2 loss : 0.246110
[00:38:43.911] iteration 28796 : model1 loss : 0.223647 model2 loss : 0.264852
[00:38:44.237] iteration 28797 : model1 loss : 0.090914 model2 loss : 0.123092
[00:38:44.559] iteration 28798 : model1 loss : 0.168805 model2 loss : 0.192053
[00:38:44.883] iteration 28799 : model1 loss : 0.169317 model2 loss : 0.217328
[00:38:45.205] iteration 28800 : model1 loss : 0.176702 model2 loss : 0.209503
[00:38:45.736] iteration 28801 : model1 loss : 0.226226 model2 loss : 0.232971
[00:38:46.061] iteration 28802 : model1 loss : 0.095610 model2 loss : 0.119528
[00:38:46.381] iteration 28803 : model1 loss : 0.261264 model2 loss : 0.275800
[00:38:46.707] iteration 28804 : model1 loss : 0.061392 model2 loss : 0.100320
[00:38:47.031] iteration 28805 : model1 loss : 0.197527 model2 loss : 0.210317
[00:38:47.359] iteration 28806 : model1 loss : 0.194235 model2 loss : 0.200274
[00:38:47.684] iteration 28807 : model1 loss : 0.149940 model2 loss : 0.173695
[00:38:48.010] iteration 28808 : model1 loss : 0.255740 model2 loss : 0.280225
[00:38:48.331] iteration 28809 : model1 loss : 0.191425 model2 loss : 0.207890
[00:38:48.655] iteration 28810 : model1 loss : 0.170668 model2 loss : 0.180727
[00:38:48.975] iteration 28811 : model1 loss : 0.104050 model2 loss : 0.129804
[00:38:49.301] iteration 28812 : model1 loss : 0.157575 model2 loss : 0.168546
[00:38:49.622] iteration 28813 : model1 loss : 0.160271 model2 loss : 0.192845
[00:38:49.945] iteration 28814 : model1 loss : 0.249763 model2 loss : 0.243444
[00:38:50.272] iteration 28815 : model1 loss : 0.316116 model2 loss : 0.317519
[00:38:50.597] iteration 28816 : model1 loss : 0.275727 model2 loss : 0.258615
[00:38:50.922] iteration 28817 : model1 loss : 0.168740 model2 loss : 0.219593
[00:38:51.248] iteration 28818 : model1 loss : 0.178844 model2 loss : 0.186061
[00:38:51.573] iteration 28819 : model1 loss : 0.167681 model2 loss : 0.245538
[00:38:51.895] iteration 28820 : model1 loss : 0.173067 model2 loss : 0.216537
[00:38:52.216] iteration 28821 : model1 loss : 0.205486 model2 loss : 0.224212
[00:38:52.540] iteration 28822 : model1 loss : 0.168919 model2 loss : 0.197587
[00:38:52.860] iteration 28823 : model1 loss : 0.171311 model2 loss : 0.179173
[00:38:53.181] iteration 28824 : model1 loss : 0.141608 model2 loss : 0.145143
[00:38:53.502] iteration 28825 : model1 loss : 0.085596 model2 loss : 0.137610
[00:38:53.826] iteration 28826 : model1 loss : 0.183827 model2 loss : 0.167171
[00:38:54.147] iteration 28827 : model1 loss : 0.163510 model2 loss : 0.187462
[00:38:54.468] iteration 28828 : model1 loss : 0.148812 model2 loss : 0.167995
[00:38:54.789] iteration 28829 : model1 loss : 0.253334 model2 loss : 0.264949
[00:38:55.112] iteration 28830 : model1 loss : 0.087941 model2 loss : 0.103838
[00:38:55.438] iteration 28831 : model1 loss : 0.314663 model2 loss : 0.327305
[00:38:55.762] iteration 28832 : model1 loss : 0.236622 model2 loss : 0.265134
[00:38:56.082] iteration 28833 : model1 loss : 0.149997 model2 loss : 0.154738
[00:38:56.405] iteration 28834 : model1 loss : 0.173044 model2 loss : 0.169322
[00:38:56.727] iteration 28835 : model1 loss : 0.171874 model2 loss : 0.178781
[00:38:57.048] iteration 28836 : model1 loss : 0.091188 model2 loss : 0.084522
[00:38:57.368] iteration 28837 : model1 loss : 0.247314 model2 loss : 0.301671
[00:38:57.691] iteration 28838 : model1 loss : 0.250168 model2 loss : 0.261833
[00:38:58.012] iteration 28839 : model1 loss : 0.086339 model2 loss : 0.109712
[00:38:58.334] iteration 28840 : model1 loss : 0.267779 model2 loss : 0.322597
[00:38:58.656] iteration 28841 : model1 loss : 0.157281 model2 loss : 0.217805
[00:38:58.981] iteration 28842 : model1 loss : 0.174499 model2 loss : 0.195608
[00:38:59.303] iteration 28843 : model1 loss : 0.232455 model2 loss : 0.234546
[00:38:59.625] iteration 28844 : model1 loss : 0.085051 model2 loss : 0.142782
[00:38:59.947] iteration 28845 : model1 loss : 0.167221 model2 loss : 0.155552
[00:39:00.275] iteration 28846 : model1 loss : 0.372528 model2 loss : 0.428158
[00:39:00.597] iteration 28847 : model1 loss : 0.166447 model2 loss : 0.180428
[00:39:00.918] iteration 28848 : model1 loss : 0.163648 model2 loss : 0.181254
[00:39:01.241] iteration 28849 : model1 loss : 0.174827 model2 loss : 0.200708
[00:39:01.565] iteration 28850 : model1 loss : 0.169726 model2 loss : 0.188281
[00:39:02.116] iteration 28851 : model1 loss : 0.090550 model2 loss : 0.134674
[00:39:02.438] iteration 28852 : model1 loss : 0.211391 model2 loss : 0.209982
[00:39:02.759] iteration 28853 : model1 loss : 0.161239 model2 loss : 0.178485
[00:39:03.083] iteration 28854 : model1 loss : 0.150262 model2 loss : 0.151321
[00:39:03.404] iteration 28855 : model1 loss : 0.257892 model2 loss : 0.298970
[00:39:03.725] iteration 28856 : model1 loss : 0.233172 model2 loss : 0.263954
[00:39:04.049] iteration 28857 : model1 loss : 0.184282 model2 loss : 0.211981
[00:39:04.375] iteration 28858 : model1 loss : 0.177648 model2 loss : 0.210971
[00:39:04.696] iteration 28859 : model1 loss : 0.157111 model2 loss : 0.209524
[00:39:05.019] iteration 28860 : model1 loss : 0.272631 model2 loss : 0.302140
[00:39:05.345] iteration 28861 : model1 loss : 0.183561 model2 loss : 0.206740
[00:39:05.666] iteration 28862 : model1 loss : 0.188978 model2 loss : 0.270374
[00:39:05.991] iteration 28863 : model1 loss : 0.097269 model2 loss : 0.127791
[00:39:06.316] iteration 28864 : model1 loss : 0.159904 model2 loss : 0.195021
[00:39:06.640] iteration 28865 : model1 loss : 0.194942 model2 loss : 0.205421
[00:39:06.970] iteration 28866 : model1 loss : 0.166998 model2 loss : 0.240971
[00:39:07.295] iteration 28867 : model1 loss : 0.074524 model2 loss : 0.076709
[00:39:07.622] iteration 28868 : model1 loss : 0.246295 model2 loss : 0.259938
[00:39:07.948] iteration 28869 : model1 loss : 0.077341 model2 loss : 0.109474
[00:39:08.276] iteration 28870 : model1 loss : 0.243883 model2 loss : 0.253590
[00:39:08.602] iteration 28871 : model1 loss : 0.165356 model2 loss : 0.197019
[00:39:08.928] iteration 28872 : model1 loss : 0.078020 model2 loss : 0.117829
[00:39:09.254] iteration 28873 : model1 loss : 0.163627 model2 loss : 0.187940
[00:39:09.583] iteration 28874 : model1 loss : 0.158268 model2 loss : 0.229416
[00:39:09.909] iteration 28875 : model1 loss : 0.078280 model2 loss : 0.088434
[00:39:10.234] iteration 28876 : model1 loss : 0.217818 model2 loss : 0.266790
[00:39:10.560] iteration 28877 : model1 loss : 0.204699 model2 loss : 0.225350
[00:39:10.885] iteration 28878 : model1 loss : 0.224088 model2 loss : 0.198292
[00:39:11.212] iteration 28879 : model1 loss : 0.248369 model2 loss : 0.266077
[00:39:11.536] iteration 28880 : model1 loss : 0.110773 model2 loss : 0.238443
[00:39:11.861] iteration 28881 : model1 loss : 0.100672 model2 loss : 0.140242
[00:39:12.187] iteration 28882 : model1 loss : 0.160988 model2 loss : 0.193201
[00:39:12.511] iteration 28883 : model1 loss : 0.162757 model2 loss : 0.216542
[00:39:12.837] iteration 28884 : model1 loss : 0.184000 model2 loss : 0.214254
[00:39:13.162] iteration 28885 : model1 loss : 0.142948 model2 loss : 0.155573
[00:39:14.048] iteration 28886 : model1 loss : 0.146225 model2 loss : 0.218601
[00:39:14.384] iteration 28887 : model1 loss : 0.180407 model2 loss : 0.188617
[00:39:14.721] iteration 28888 : model1 loss : 0.140863 model2 loss : 0.284812
[00:39:15.060] iteration 28889 : model1 loss : 0.094118 model2 loss : 0.122225
[00:39:15.403] iteration 28890 : model1 loss : 0.233263 model2 loss : 0.251582
[00:39:15.743] iteration 28891 : model1 loss : 0.152823 model2 loss : 0.174381
[00:39:16.086] iteration 28892 : model1 loss : 0.105439 model2 loss : 0.158503
[00:39:16.429] iteration 28893 : model1 loss : 0.170907 model2 loss : 0.212434
[00:39:16.769] iteration 28894 : model1 loss : 0.088051 model2 loss : 0.116051
[00:39:17.107] iteration 28895 : model1 loss : 0.182811 model2 loss : 0.182407
[00:39:17.448] iteration 28896 : model1 loss : 0.235949 model2 loss : 0.274715
[00:39:17.790] iteration 28897 : model1 loss : 0.085369 model2 loss : 0.123119
[00:39:18.128] iteration 28898 : model1 loss : 0.125356 model2 loss : 0.127711
[00:39:18.461] iteration 28899 : model1 loss : 0.188043 model2 loss : 0.181720
[00:39:18.797] iteration 28900 : model1 loss : 0.205819 model2 loss : 0.233730
[00:39:19.481] iteration 28901 : model1 loss : 0.232226 model2 loss : 0.260927
[00:39:19.823] iteration 28902 : model1 loss : 0.250856 model2 loss : 0.265238
[00:39:20.166] iteration 28903 : model1 loss : 0.267129 model2 loss : 0.280040
[00:39:20.508] iteration 28904 : model1 loss : 0.178177 model2 loss : 0.230843
[00:39:20.846] iteration 28905 : model1 loss : 0.165586 model2 loss : 0.174781
[00:39:21.189] iteration 28906 : model1 loss : 0.136397 model2 loss : 0.159562
[00:39:21.522] iteration 28907 : model1 loss : 0.166972 model2 loss : 0.184712
[00:39:21.859] iteration 28908 : model1 loss : 0.187076 model2 loss : 0.191308
[00:39:22.198] iteration 28909 : model1 loss : 0.079203 model2 loss : 0.148561
[00:39:22.539] iteration 28910 : model1 loss : 0.181962 model2 loss : 0.215150
[00:39:22.872] iteration 28911 : model1 loss : 0.169622 model2 loss : 0.259945
[00:39:23.213] iteration 28912 : model1 loss : 0.182029 model2 loss : 0.184377
[00:39:23.550] iteration 28913 : model1 loss : 0.099431 model2 loss : 0.143656
[00:39:23.888] iteration 28914 : model1 loss : 0.102523 model2 loss : 0.132733
[00:39:24.222] iteration 28915 : model1 loss : 0.067244 model2 loss : 0.116344
[00:39:24.558] iteration 28916 : model1 loss : 0.154549 model2 loss : 0.187105
[00:39:24.896] iteration 28917 : model1 loss : 0.251094 model2 loss : 0.258365
[00:39:25.233] iteration 28918 : model1 loss : 0.253810 model2 loss : 0.271821
[00:39:25.568] iteration 28919 : model1 loss : 0.202108 model2 loss : 0.230334
[00:39:25.909] iteration 28920 : model1 loss : 0.090793 model2 loss : 0.198497
[00:39:26.249] iteration 28921 : model1 loss : 0.237069 model2 loss : 0.207707
[00:39:26.586] iteration 28922 : model1 loss : 0.127393 model2 loss : 0.137937
[00:39:26.924] iteration 28923 : model1 loss : 0.160600 model2 loss : 0.192254
[00:39:27.261] iteration 28924 : model1 loss : 0.175539 model2 loss : 0.189342
[00:39:27.601] iteration 28925 : model1 loss : 0.195986 model2 loss : 0.208445
[00:39:27.939] iteration 28926 : model1 loss : 0.235461 model2 loss : 0.241988
[00:39:28.272] iteration 28927 : model1 loss : 0.237467 model2 loss : 0.244443
[00:39:28.608] iteration 28928 : model1 loss : 0.209879 model2 loss : 0.306309
[00:39:28.946] iteration 28929 : model1 loss : 0.158716 model2 loss : 0.224632
[00:39:29.286] iteration 28930 : model1 loss : 0.161117 model2 loss : 0.204546
[00:39:29.619] iteration 28931 : model1 loss : 0.090605 model2 loss : 0.134367
[00:39:29.961] iteration 28932 : model1 loss : 0.082449 model2 loss : 0.168856
[00:39:30.300] iteration 28933 : model1 loss : 0.175291 model2 loss : 0.191082
[00:39:30.638] iteration 28934 : model1 loss : 0.175173 model2 loss : 0.231189
[00:39:30.979] iteration 28935 : model1 loss : 0.283497 model2 loss : 0.296260
[00:39:31.319] iteration 28936 : model1 loss : 0.161931 model2 loss : 0.180783
[00:39:31.660] iteration 28937 : model1 loss : 0.256175 model2 loss : 0.278031
[00:39:31.998] iteration 28938 : model1 loss : 0.097031 model2 loss : 0.104098
[00:39:32.332] iteration 28939 : model1 loss : 0.171820 model2 loss : 0.163820
[00:39:32.674] iteration 28940 : model1 loss : 0.165200 model2 loss : 0.186098
[00:39:33.012] iteration 28941 : model1 loss : 0.199112 model2 loss : 0.213684
[00:39:33.353] iteration 28942 : model1 loss : 0.154641 model2 loss : 0.166904
[00:39:33.690] iteration 28943 : model1 loss : 0.181904 model2 loss : 0.252697
[00:39:34.032] iteration 28944 : model1 loss : 0.245936 model2 loss : 0.267452
[00:39:34.372] iteration 28945 : model1 loss : 0.185649 model2 loss : 0.209987
[00:39:34.712] iteration 28946 : model1 loss : 0.219015 model2 loss : 0.273122
[00:39:35.052] iteration 28947 : model1 loss : 0.166877 model2 loss : 0.186665
[00:39:35.390] iteration 28948 : model1 loss : 0.197619 model2 loss : 0.229648
[00:39:35.726] iteration 28949 : model1 loss : 0.230919 model2 loss : 0.239414
[00:39:36.067] iteration 28950 : model1 loss : 0.168376 model2 loss : 0.176359
[00:39:36.717] iteration 28951 : model1 loss : 0.316021 model2 loss : 0.321517
[00:39:37.055] iteration 28952 : model1 loss : 0.246264 model2 loss : 0.262376
[00:39:37.396] iteration 28953 : model1 loss : 0.158845 model2 loss : 0.173686
[00:39:37.733] iteration 28954 : model1 loss : 0.234353 model2 loss : 0.250503
[00:39:38.070] iteration 28955 : model1 loss : 0.174728 model2 loss : 0.183438
[00:39:38.411] iteration 28956 : model1 loss : 0.196822 model2 loss : 0.279259
[00:39:38.746] iteration 28957 : model1 loss : 0.244314 model2 loss : 0.310386
[00:39:39.080] iteration 28958 : model1 loss : 0.249255 model2 loss : 0.269516
[00:39:39.418] iteration 28959 : model1 loss : 0.093858 model2 loss : 0.122851
[00:39:39.758] iteration 28960 : model1 loss : 0.191667 model2 loss : 0.223168
[00:39:40.095] iteration 28961 : model1 loss : 0.070375 model2 loss : 0.136633
[00:39:40.435] iteration 28962 : model1 loss : 0.153080 model2 loss : 0.174907
[00:39:40.762] iteration 28963 : model1 loss : 0.189803 model2 loss : 0.234365
[00:39:41.090] iteration 28964 : model1 loss : 0.156672 model2 loss : 0.136318
[00:39:41.418] iteration 28965 : model1 loss : 0.183537 model2 loss : 0.222255
[00:39:41.744] iteration 28966 : model1 loss : 0.172911 model2 loss : 0.201230
[00:39:42.071] iteration 28967 : model1 loss : 0.113860 model2 loss : 0.116493
[00:39:42.397] iteration 28968 : model1 loss : 0.068767 model2 loss : 0.100508
[00:39:42.724] iteration 28969 : model1 loss : 0.165623 model2 loss : 0.213522
[00:39:43.054] iteration 28970 : model1 loss : 0.169561 model2 loss : 0.175174
[00:39:43.381] iteration 28971 : model1 loss : 0.175572 model2 loss : 0.207728
[00:39:43.707] iteration 28972 : model1 loss : 0.240538 model2 loss : 0.245977
[00:39:44.036] iteration 28973 : model1 loss : 0.186840 model2 loss : 0.263915
[00:39:44.365] iteration 28974 : model1 loss : 0.209105 model2 loss : 0.221236
[00:39:44.694] iteration 28975 : model1 loss : 0.129447 model2 loss : 0.122231
[00:39:45.022] iteration 28976 : model1 loss : 0.183582 model2 loss : 0.241634
[00:39:45.351] iteration 28977 : model1 loss : 0.243894 model2 loss : 0.257608
[00:39:45.679] iteration 28978 : model1 loss : 0.197356 model2 loss : 0.243948
[00:39:46.004] iteration 28979 : model1 loss : 0.083036 model2 loss : 0.134349
[00:39:46.331] iteration 28980 : model1 loss : 0.147642 model2 loss : 0.219459
[00:39:46.656] iteration 28981 : model1 loss : 0.230471 model2 loss : 0.260571
[00:39:46.981] iteration 28982 : model1 loss : 0.245027 model2 loss : 0.243621
[00:39:47.303] iteration 28983 : model1 loss : 0.118075 model2 loss : 0.359391
[00:39:47.623] iteration 28984 : model1 loss : 0.115042 model2 loss : 0.134031
[00:39:47.944] iteration 28985 : model1 loss : 0.254135 model2 loss : 0.269984
[00:39:48.266] iteration 28986 : model1 loss : 0.166253 model2 loss : 0.181103
[00:39:48.588] iteration 28987 : model1 loss : 0.217848 model2 loss : 0.300551
[00:39:48.908] iteration 28988 : model1 loss : 0.330383 model2 loss : 0.360323
[00:39:49.229] iteration 28989 : model1 loss : 0.168508 model2 loss : 0.201932
[00:39:49.550] iteration 28990 : model1 loss : 0.181032 model2 loss : 0.212101
[00:39:49.871] iteration 28991 : model1 loss : 0.257943 model2 loss : 0.330291
[00:39:50.192] iteration 28992 : model1 loss : 0.235175 model2 loss : 0.260765
[00:39:50.521] iteration 28993 : model1 loss : 0.146600 model2 loss : 0.175501
[00:39:50.842] iteration 28994 : model1 loss : 0.241378 model2 loss : 0.252729
[00:39:51.167] iteration 28995 : model1 loss : 0.084228 model2 loss : 0.103998
[00:39:51.492] iteration 28996 : model1 loss : 0.080411 model2 loss : 0.102395
[00:39:51.815] iteration 28997 : model1 loss : 0.070876 model2 loss : 0.101629
[00:39:52.136] iteration 28998 : model1 loss : 0.173201 model2 loss : 0.244147
[00:39:52.457] iteration 28999 : model1 loss : 0.149810 model2 loss : 0.179524
[00:39:52.778] iteration 29000 : model1 loss : 0.092558 model2 loss : 0.411931
[00:39:53.288] iteration 29001 : model1 loss : 0.176894 model2 loss : 0.274856
[00:39:53.614] iteration 29002 : model1 loss : 0.249034 model2 loss : 0.288282
[00:39:53.938] iteration 29003 : model1 loss : 0.172426 model2 loss : 0.190127
[00:39:54.262] iteration 29004 : model1 loss : 0.165840 model2 loss : 0.238765
[00:39:54.585] iteration 29005 : model1 loss : 0.178179 model2 loss : 0.211789
[00:39:54.909] iteration 29006 : model1 loss : 0.162424 model2 loss : 0.196504
[00:39:55.234] iteration 29007 : model1 loss : 0.077664 model2 loss : 0.087137
[00:39:55.559] iteration 29008 : model1 loss : 0.167971 model2 loss : 0.178085
[00:39:55.884] iteration 29009 : model1 loss : 0.194429 model2 loss : 0.214544
[00:39:56.209] iteration 29010 : model1 loss : 0.174008 model2 loss : 0.216422
[00:39:56.536] iteration 29011 : model1 loss : 0.166469 model2 loss : 0.182986
[00:39:56.860] iteration 29012 : model1 loss : 0.192682 model2 loss : 0.229474
[00:39:57.184] iteration 29013 : model1 loss : 0.286813 model2 loss : 0.367423
[00:39:57.509] iteration 29014 : model1 loss : 0.249919 model2 loss : 0.251023
[00:39:57.835] iteration 29015 : model1 loss : 0.144837 model2 loss : 0.157111
[00:39:58.161] iteration 29016 : model1 loss : 0.165674 model2 loss : 0.186358
[00:39:58.487] iteration 29017 : model1 loss : 0.079995 model2 loss : 0.098615
[00:39:58.816] iteration 29018 : model1 loss : 0.181602 model2 loss : 0.165097
[00:39:59.153] iteration 29019 : model1 loss : 0.167708 model2 loss : 0.176997
[00:39:59.494] iteration 29020 : model1 loss : 0.118730 model2 loss : 0.151256
[00:39:59.828] iteration 29021 : model1 loss : 0.251850 model2 loss : 0.287234
[00:40:00.167] iteration 29022 : model1 loss : 0.081445 model2 loss : 0.118007
[00:40:00.509] iteration 29023 : model1 loss : 0.135394 model2 loss : 0.102354
[00:40:00.849] iteration 29024 : model1 loss : 0.155188 model2 loss : 0.175355
[00:40:01.186] iteration 29025 : model1 loss : 0.196764 model2 loss : 0.209640
[00:40:01.523] iteration 29026 : model1 loss : 0.184604 model2 loss : 0.151493
[00:40:01.856] iteration 29027 : model1 loss : 0.234278 model2 loss : 0.255945
[00:40:02.189] iteration 29028 : model1 loss : 0.288349 model2 loss : 0.322903
[00:40:02.528] iteration 29029 : model1 loss : 0.091445 model2 loss : 0.097852
[00:40:02.866] iteration 29030 : model1 loss : 0.221891 model2 loss : 0.279202
[00:40:03.200] iteration 29031 : model1 loss : 0.167650 model2 loss : 0.178683
[00:40:03.538] iteration 29032 : model1 loss : 0.238508 model2 loss : 0.243423
[00:40:03.875] iteration 29033 : model1 loss : 0.166008 model2 loss : 0.183540
[00:40:04.214] iteration 29034 : model1 loss : 0.164927 model2 loss : 0.202930
[00:40:04.554] iteration 29035 : model1 loss : 0.218014 model2 loss : 0.252311
[00:40:04.886] iteration 29036 : model1 loss : 0.171351 model2 loss : 0.189274
[00:40:05.211] iteration 29037 : model1 loss : 0.234172 model2 loss : 0.214328
[00:40:05.540] iteration 29038 : model1 loss : 0.211894 model2 loss : 0.219425
[00:40:05.863] iteration 29039 : model1 loss : 0.161798 model2 loss : 0.207845
[00:40:06.186] iteration 29040 : model1 loss : 0.154833 model2 loss : 0.164156
[00:40:06.511] iteration 29041 : model1 loss : 0.087985 model2 loss : 0.414975
[00:40:06.837] iteration 29042 : model1 loss : 0.155942 model2 loss : 0.193049
[00:40:07.160] iteration 29043 : model1 loss : 0.080922 model2 loss : 0.135863
[00:40:07.489] iteration 29044 : model1 loss : 0.068011 model2 loss : 0.077827
[00:40:07.814] iteration 29045 : model1 loss : 0.160417 model2 loss : 0.166447
[00:40:08.138] iteration 29046 : model1 loss : 0.177115 model2 loss : 0.208658
[00:40:08.468] iteration 29047 : model1 loss : 0.089350 model2 loss : 0.123663
[00:40:08.796] iteration 29048 : model1 loss : 0.234103 model2 loss : 0.247590
[00:40:09.122] iteration 29049 : model1 loss : 0.175257 model2 loss : 0.225172
[00:40:09.451] iteration 29050 : model1 loss : 0.175335 model2 loss : 0.206250
[00:40:09.997] iteration 29051 : model1 loss : 0.086183 model2 loss : 0.085000
[00:40:10.324] iteration 29052 : model1 loss : 0.221636 model2 loss : 0.218324
[00:40:10.647] iteration 29053 : model1 loss : 0.108312 model2 loss : 0.135428
[00:40:10.978] iteration 29054 : model1 loss : 0.257592 model2 loss : 0.245294
[00:40:11.306] iteration 29055 : model1 loss : 0.194994 model2 loss : 0.224744
[00:40:11.634] iteration 29056 : model1 loss : 0.233430 model2 loss : 0.251603
[00:40:11.962] iteration 29057 : model1 loss : 0.084066 model2 loss : 0.099961
[00:40:12.286] iteration 29058 : model1 loss : 0.074560 model2 loss : 0.192118
[00:40:12.610] iteration 29059 : model1 loss : 0.263173 model2 loss : 0.269587
[00:40:12.936] iteration 29060 : model1 loss : 0.067004 model2 loss : 0.164945
[00:40:13.262] iteration 29061 : model1 loss : 0.171338 model2 loss : 0.201289
[00:40:13.596] iteration 29062 : model1 loss : 0.183724 model2 loss : 0.230553
[00:40:13.923] iteration 29063 : model1 loss : 0.106627 model2 loss : 0.100749
[00:40:14.250] iteration 29064 : model1 loss : 0.161618 model2 loss : 0.181638
[00:40:14.574] iteration 29065 : model1 loss : 0.200930 model2 loss : 0.250093
[00:40:14.898] iteration 29066 : model1 loss : 0.184068 model2 loss : 0.186811
[00:40:15.220] iteration 29067 : model1 loss : 0.139511 model2 loss : 0.154479
[00:40:15.545] iteration 29068 : model1 loss : 0.072322 model2 loss : 0.229784
[00:40:15.869] iteration 29069 : model1 loss : 0.160765 model2 loss : 0.187394
[00:40:16.191] iteration 29070 : model1 loss : 0.170558 model2 loss : 0.174571
[00:40:16.512] iteration 29071 : model1 loss : 0.192689 model2 loss : 0.158303
[00:40:16.838] iteration 29072 : model1 loss : 0.173262 model2 loss : 0.257771
[00:40:17.162] iteration 29073 : model1 loss : 0.165058 model2 loss : 0.169516
[00:40:17.487] iteration 29074 : model1 loss : 0.246938 model2 loss : 0.251940
[00:40:17.810] iteration 29075 : model1 loss : 0.170588 model2 loss : 0.186880
[00:40:18.132] iteration 29076 : model1 loss : 0.179457 model2 loss : 0.212767
[00:40:18.454] iteration 29077 : model1 loss : 0.171532 model2 loss : 0.222872
[00:40:18.777] iteration 29078 : model1 loss : 0.176148 model2 loss : 0.201634
[00:40:19.098] iteration 29079 : model1 loss : 0.222920 model2 loss : 0.222764
[00:40:19.424] iteration 29080 : model1 loss : 0.188078 model2 loss : 0.228210
[00:40:19.746] iteration 29081 : model1 loss : 0.286303 model2 loss : 0.278896
[00:40:20.068] iteration 29082 : model1 loss : 0.141568 model2 loss : 0.149530
[00:40:20.393] iteration 29083 : model1 loss : 0.226376 model2 loss : 0.320423
[00:40:20.715] iteration 29084 : model1 loss : 0.143371 model2 loss : 0.171363
[00:40:21.037] iteration 29085 : model1 loss : 0.149536 model2 loss : 0.173515
[00:40:21.361] iteration 29086 : model1 loss : 0.172034 model2 loss : 0.171520
[00:40:21.687] iteration 29087 : model1 loss : 0.242304 model2 loss : 0.266040
[00:40:22.011] iteration 29088 : model1 loss : 0.253295 model2 loss : 0.264821
[00:40:22.336] iteration 29089 : model1 loss : 0.252830 model2 loss : 0.249065
[00:40:22.658] iteration 29090 : model1 loss : 0.135211 model2 loss : 0.141768
[00:40:22.979] iteration 29091 : model1 loss : 0.232662 model2 loss : 0.204059
[00:40:23.304] iteration 29092 : model1 loss : 0.186772 model2 loss : 0.195473
[00:40:23.628] iteration 29093 : model1 loss : 0.317568 model2 loss : 0.335998
[00:40:23.951] iteration 29094 : model1 loss : 0.192485 model2 loss : 0.184005
[00:40:24.277] iteration 29095 : model1 loss : 0.085793 model2 loss : 0.153219
[00:40:24.604] iteration 29096 : model1 loss : 0.269549 model2 loss : 0.300915
[00:40:24.931] iteration 29097 : model1 loss : 0.164515 model2 loss : 0.204763
[00:40:25.257] iteration 29098 : model1 loss : 0.081814 model2 loss : 0.098072
[00:40:25.584] iteration 29099 : model1 loss : 0.184379 model2 loss : 0.185172
[00:40:25.909] iteration 29100 : model1 loss : 0.198063 model2 loss : 0.166744
[00:40:26.422] iteration 29101 : model1 loss : 0.240703 model2 loss : 0.262761
[00:40:26.749] iteration 29102 : model1 loss : 0.264540 model2 loss : 0.288609
[00:40:27.074] iteration 29103 : model1 loss : 0.261828 model2 loss : 0.272231
[00:40:27.401] iteration 29104 : model1 loss : 0.323106 model2 loss : 0.374783
[00:40:27.727] iteration 29105 : model1 loss : 0.236788 model2 loss : 0.237933
[00:40:28.054] iteration 29106 : model1 loss : 0.071107 model2 loss : 0.121889
[00:40:28.381] iteration 29107 : model1 loss : 0.245590 model2 loss : 0.247849
[00:40:28.708] iteration 29108 : model1 loss : 0.160163 model2 loss : 0.235508
[00:40:29.035] iteration 29109 : model1 loss : 0.261017 model2 loss : 0.290438
[00:40:29.362] iteration 29110 : model1 loss : 0.182836 model2 loss : 0.183320
[00:40:29.690] iteration 29111 : model1 loss : 0.191034 model2 loss : 0.223897
[00:40:30.016] iteration 29112 : model1 loss : 0.159642 model2 loss : 0.202837
[00:40:30.343] iteration 29113 : model1 loss : 0.174876 model2 loss : 0.203067
[00:40:30.671] iteration 29114 : model1 loss : 0.157226 model2 loss : 0.192027
[00:40:30.996] iteration 29115 : model1 loss : 0.403095 model2 loss : 0.414247
[00:40:31.323] iteration 29116 : model1 loss : 0.084799 model2 loss : 0.102258
[00:40:31.650] iteration 29117 : model1 loss : 0.094828 model2 loss : 0.138904
[00:40:31.976] iteration 29118 : model1 loss : 0.244110 model2 loss : 0.258152
[00:40:32.303] iteration 29119 : model1 loss : 0.183225 model2 loss : 0.234508
[00:40:32.630] iteration 29120 : model1 loss : 0.080201 model2 loss : 0.163489
[00:40:32.955] iteration 29121 : model1 loss : 0.073021 model2 loss : 0.190790
[00:40:33.284] iteration 29122 : model1 loss : 0.250988 model2 loss : 0.293413
[00:40:33.610] iteration 29123 : model1 loss : 0.191597 model2 loss : 0.204106
[00:40:33.937] iteration 29124 : model1 loss : 0.317798 model2 loss : 0.361456
[00:40:34.263] iteration 29125 : model1 loss : 0.243134 model2 loss : 0.250047
[00:40:34.591] iteration 29126 : model1 loss : 0.066092 model2 loss : 0.098750
[00:40:34.918] iteration 29127 : model1 loss : 0.087306 model2 loss : 0.138867
[00:40:35.244] iteration 29128 : model1 loss : 0.083749 model2 loss : 0.096549
[00:40:35.572] iteration 29129 : model1 loss : 0.169322 model2 loss : 0.177464
[00:40:35.899] iteration 29130 : model1 loss : 0.215857 model2 loss : 0.241403
[00:40:36.226] iteration 29131 : model1 loss : 0.194332 model2 loss : 0.243627
[00:40:36.553] iteration 29132 : model1 loss : 0.186655 model2 loss : 0.233387
[00:40:36.883] iteration 29133 : model1 loss : 0.233412 model2 loss : 0.233334
[00:40:37.215] iteration 29134 : model1 loss : 0.149555 model2 loss : 0.182968
[00:40:37.542] iteration 29135 : model1 loss : 0.111789 model2 loss : 0.125793
[00:40:37.869] iteration 29136 : model1 loss : 0.240938 model2 loss : 0.279179
[00:40:38.198] iteration 29137 : model1 loss : 0.127341 model2 loss : 0.141065
[00:40:38.528] iteration 29138 : model1 loss : 0.073895 model2 loss : 0.076769
[00:40:38.860] iteration 29139 : model1 loss : 0.078125 model2 loss : 0.099555
[00:40:39.192] iteration 29140 : model1 loss : 0.072393 model2 loss : 0.091759
[00:40:39.519] iteration 29141 : model1 loss : 0.163379 model2 loss : 0.180288
[00:40:39.845] iteration 29142 : model1 loss : 0.153222 model2 loss : 0.162066
[00:40:40.174] iteration 29143 : model1 loss : 0.067944 model2 loss : 0.084162
[00:40:40.503] iteration 29144 : model1 loss : 0.242513 model2 loss : 0.239485
[00:40:40.854] iteration 29145 : model1 loss : 0.158665 model2 loss : 0.184819
[00:40:41.198] iteration 29146 : model1 loss : 0.176025 model2 loss : 0.241483
[00:40:41.542] iteration 29147 : model1 loss : 0.176386 model2 loss : 0.202727
[00:40:41.880] iteration 29148 : model1 loss : 0.244693 model2 loss : 0.268039
[00:40:42.216] iteration 29149 : model1 loss : 0.167063 model2 loss : 0.187883
[00:40:42.557] iteration 29150 : model1 loss : 0.246367 model2 loss : 0.274479
[00:40:43.214] iteration 29151 : model1 loss : 0.237689 model2 loss : 0.265949
[00:40:43.558] iteration 29152 : model1 loss : 0.082076 model2 loss : 0.104172
[00:40:43.899] iteration 29153 : model1 loss : 0.079371 model2 loss : 0.137467
[00:40:44.244] iteration 29154 : model1 loss : 0.100730 model2 loss : 0.122851
[00:40:44.585] iteration 29155 : model1 loss : 0.198357 model2 loss : 0.196688
[00:40:44.935] iteration 29156 : model1 loss : 0.181514 model2 loss : 0.188775
[00:40:45.278] iteration 29157 : model1 loss : 0.142324 model2 loss : 0.166082
[00:40:45.612] iteration 29158 : model1 loss : 0.179911 model2 loss : 0.203199
[00:40:45.950] iteration 29159 : model1 loss : 0.245458 model2 loss : 0.248494
[00:40:46.286] iteration 29160 : model1 loss : 0.253372 model2 loss : 0.273349
[00:40:46.621] iteration 29161 : model1 loss : 0.182997 model2 loss : 0.206936
[00:40:46.956] iteration 29162 : model1 loss : 0.090702 model2 loss : 0.117667
[00:40:47.305] iteration 29163 : model1 loss : 0.317422 model2 loss : 0.334268
[00:40:47.647] iteration 29164 : model1 loss : 0.180944 model2 loss : 0.206159
[00:40:47.985] iteration 29165 : model1 loss : 0.084256 model2 loss : 0.146003
[00:40:48.326] iteration 29166 : model1 loss : 0.239448 model2 loss : 0.244746
[00:40:48.671] iteration 29167 : model1 loss : 0.075633 model2 loss : 0.411663
[00:40:49.010] iteration 29168 : model1 loss : 0.144702 model2 loss : 0.188731
[00:40:49.347] iteration 29169 : model1 loss : 0.116639 model2 loss : 0.108328
[00:40:49.686] iteration 29170 : model1 loss : 0.170464 model2 loss : 0.200887
[00:40:50.026] iteration 29171 : model1 loss : 0.070747 model2 loss : 0.116323
[00:40:50.361] iteration 29172 : model1 loss : 0.236043 model2 loss : 0.247293
[00:40:50.695] iteration 29173 : model1 loss : 0.078678 model2 loss : 0.106816
[00:40:51.031] iteration 29174 : model1 loss : 0.165110 model2 loss : 0.207279
[00:40:51.367] iteration 29175 : model1 loss : 0.237757 model2 loss : 0.241556
[00:40:51.702] iteration 29176 : model1 loss : 0.298594 model2 loss : 0.273153
[00:40:52.035] iteration 29177 : model1 loss : 0.259444 model2 loss : 0.274357
[00:40:52.373] iteration 29178 : model1 loss : 0.133815 model2 loss : 0.153536
[00:40:52.708] iteration 29179 : model1 loss : 0.205945 model2 loss : 0.223077
[00:40:53.040] iteration 29180 : model1 loss : 0.060384 model2 loss : 0.134586
[00:40:53.378] iteration 29181 : model1 loss : 0.171029 model2 loss : 0.195860
[00:40:53.709] iteration 29182 : model1 loss : 0.280442 model2 loss : 0.247952
[00:40:54.042] iteration 29183 : model1 loss : 0.094380 model2 loss : 0.156259
[00:40:54.378] iteration 29184 : model1 loss : 0.205992 model2 loss : 0.271492
[00:40:54.714] iteration 29185 : model1 loss : 0.249522 model2 loss : 0.268475
[00:40:55.048] iteration 29186 : model1 loss : 0.146849 model2 loss : 0.164666
[00:40:55.381] iteration 29187 : model1 loss : 0.121671 model2 loss : 0.133684
[00:40:55.715] iteration 29188 : model1 loss : 0.156344 model2 loss : 0.184124
[00:40:56.047] iteration 29189 : model1 loss : 0.253978 model2 loss : 0.284065
[00:40:56.381] iteration 29190 : model1 loss : 0.099343 model2 loss : 0.215710
[00:40:56.718] iteration 29191 : model1 loss : 0.234889 model2 loss : 0.254888
[00:40:57.055] iteration 29192 : model1 loss : 0.177882 model2 loss : 0.226409
[00:40:57.393] iteration 29193 : model1 loss : 0.241013 model2 loss : 0.242050
[00:40:57.733] iteration 29194 : model1 loss : 0.165906 model2 loss : 0.180848
[00:40:58.066] iteration 29195 : model1 loss : 0.112854 model2 loss : 0.136924
[00:40:58.399] iteration 29196 : model1 loss : 0.116761 model2 loss : 0.203003
[00:40:58.737] iteration 29197 : model1 loss : 0.271072 model2 loss : 0.274682
[00:40:59.068] iteration 29198 : model1 loss : 0.193689 model2 loss : 0.236746
[00:40:59.403] iteration 29199 : model1 loss : 0.233030 model2 loss : 0.208691
[00:40:59.744] iteration 29200 : model1 loss : 0.129038 model2 loss : 0.182527
[00:41:00.377] iteration 29201 : model1 loss : 0.249178 model2 loss : 0.247190
[00:41:00.718] iteration 29202 : model1 loss : 0.176826 model2 loss : 0.204144
[00:41:01.052] iteration 29203 : model1 loss : 0.211875 model2 loss : 0.197801
[00:41:01.387] iteration 29204 : model1 loss : 0.091135 model2 loss : 0.116469
[00:41:01.720] iteration 29205 : model1 loss : 0.156615 model2 loss : 0.206507
[00:41:02.058] iteration 29206 : model1 loss : 0.183759 model2 loss : 0.182190
[00:41:02.396] iteration 29207 : model1 loss : 0.178656 model2 loss : 0.228678
[00:41:02.736] iteration 29208 : model1 loss : 0.256805 model2 loss : 0.304152
[00:41:03.070] iteration 29209 : model1 loss : 0.213908 model2 loss : 0.232366
[00:41:03.403] iteration 29210 : model1 loss : 0.217047 model2 loss : 0.239687
[00:41:03.741] iteration 29211 : model1 loss : 0.197883 model2 loss : 0.192083
[00:41:04.074] iteration 29212 : model1 loss : 0.163046 model2 loss : 0.167573
[00:41:04.408] iteration 29213 : model1 loss : 0.249203 model2 loss : 0.250307
[00:41:04.744] iteration 29214 : model1 loss : 0.159143 model2 loss : 0.189883
[00:41:05.085] iteration 29215 : model1 loss : 0.117017 model2 loss : 0.152295
[00:41:05.420] iteration 29216 : model1 loss : 0.146271 model2 loss : 0.148542
[00:41:05.755] iteration 29217 : model1 loss : 0.170930 model2 loss : 0.190728
[00:41:06.091] iteration 29218 : model1 loss : 0.153129 model2 loss : 0.197272
[00:41:06.430] iteration 29219 : model1 loss : 0.241054 model2 loss : 0.294949
[00:41:06.765] iteration 29220 : model1 loss : 0.102582 model2 loss : 0.097401
[00:41:07.100] iteration 29221 : model1 loss : 0.067192 model2 loss : 0.093054
[00:41:07.433] iteration 29222 : model1 loss : 0.159821 model2 loss : 0.181691
[00:41:07.767] iteration 29223 : model1 loss : 0.200636 model2 loss : 0.191079
[00:41:08.099] iteration 29224 : model1 loss : 0.062255 model2 loss : 0.080236
[00:41:08.434] iteration 29225 : model1 loss : 0.142901 model2 loss : 0.187706
[00:41:08.770] iteration 29226 : model1 loss : 0.114357 model2 loss : 0.119281
[00:41:09.103] iteration 29227 : model1 loss : 0.067812 model2 loss : 0.071968
[00:41:09.436] iteration 29228 : model1 loss : 0.242217 model2 loss : 0.292685
[00:41:09.778] iteration 29229 : model1 loss : 0.234707 model2 loss : 0.250388
[00:41:10.111] iteration 29230 : model1 loss : 0.288039 model2 loss : 0.408112
[00:41:10.450] iteration 29231 : model1 loss : 0.238954 model2 loss : 0.245950
[00:41:10.790] iteration 29232 : model1 loss : 0.196109 model2 loss : 0.272300
[00:41:11.128] iteration 29233 : model1 loss : 0.253233 model2 loss : 0.291336
[00:41:11.463] iteration 29234 : model1 loss : 0.240001 model2 loss : 0.245202
[00:41:11.795] iteration 29235 : model1 loss : 0.164947 model2 loss : 0.206254
[00:41:12.130] iteration 29236 : model1 loss : 0.085464 model2 loss : 0.133865
[00:41:12.464] iteration 29237 : model1 loss : 0.337051 model2 loss : 0.370694
[00:41:12.801] iteration 29238 : model1 loss : 0.255194 model2 loss : 0.269994
[00:41:13.134] iteration 29239 : model1 loss : 0.058807 model2 loss : 0.079569
[00:41:13.471] iteration 29240 : model1 loss : 0.167733 model2 loss : 0.240196
[00:41:13.806] iteration 29241 : model1 loss : 0.184359 model2 loss : 0.183673
[00:41:14.142] iteration 29242 : model1 loss : 0.173151 model2 loss : 0.202078
[00:41:14.475] iteration 29243 : model1 loss : 0.099931 model2 loss : 0.128519
[00:41:14.811] iteration 29244 : model1 loss : 0.252591 model2 loss : 0.264306
[00:41:15.147] iteration 29245 : model1 loss : 0.257192 model2 loss : 0.276796
[00:41:15.485] iteration 29246 : model1 loss : 0.081378 model2 loss : 0.118248
[00:41:15.820] iteration 29247 : model1 loss : 0.159851 model2 loss : 0.214470
[00:41:16.152] iteration 29248 : model1 loss : 0.163268 model2 loss : 0.195267
[00:41:16.487] iteration 29249 : model1 loss : 0.171953 model2 loss : 0.242370
[00:41:16.819] iteration 29250 : model1 loss : 0.074213 model2 loss : 0.116961
[00:41:17.467] iteration 29251 : model1 loss : 0.191643 model2 loss : 0.192741
[00:41:17.803] iteration 29252 : model1 loss : 0.221351 model2 loss : 0.226906
[00:41:18.140] iteration 29253 : model1 loss : 0.173289 model2 loss : 0.201873
[00:41:18.477] iteration 29254 : model1 loss : 0.169205 model2 loss : 0.203010
[00:41:18.818] iteration 29255 : model1 loss : 0.091757 model2 loss : 0.121443
[00:41:19.156] iteration 29256 : model1 loss : 0.102006 model2 loss : 0.184910
[00:41:19.489] iteration 29257 : model1 loss : 0.174197 model2 loss : 0.193371
[00:41:19.822] iteration 29258 : model1 loss : 0.138278 model2 loss : 0.193081
[00:41:20.156] iteration 29259 : model1 loss : 0.179566 model2 loss : 0.263008
[00:41:20.496] iteration 29260 : model1 loss : 0.152576 model2 loss : 0.186915
[00:41:20.836] iteration 29261 : model1 loss : 0.151995 model2 loss : 0.217702
[00:41:21.172] iteration 29262 : model1 loss : 0.183401 model2 loss : 0.192092
[00:41:21.506] iteration 29263 : model1 loss : 0.170458 model2 loss : 0.192011
[00:41:21.843] iteration 29264 : model1 loss : 0.173945 model2 loss : 0.219996
[00:41:22.179] iteration 29265 : model1 loss : 0.096849 model2 loss : 0.226070
[00:41:22.512] iteration 29266 : model1 loss : 0.255698 model2 loss : 0.263954
[00:41:22.848] iteration 29267 : model1 loss : 0.152585 model2 loss : 0.169312
[00:41:23.184] iteration 29268 : model1 loss : 0.241520 model2 loss : 0.241307
[00:41:23.517] iteration 29269 : model1 loss : 0.072088 model2 loss : 0.115953
[00:41:23.858] iteration 29270 : model1 loss : 0.267167 model2 loss : 0.299524
[00:41:24.193] iteration 29271 : model1 loss : 0.184671 model2 loss : 0.206553
[00:41:24.527] iteration 29272 : model1 loss : 0.183067 model2 loss : 0.289550
[00:41:24.867] iteration 29273 : model1 loss : 0.114464 model2 loss : 0.117105
[00:41:25.211] iteration 29274 : model1 loss : 0.194997 model2 loss : 0.199049
[00:41:25.548] iteration 29275 : model1 loss : 0.173351 model2 loss : 0.200421
[00:41:25.886] iteration 29276 : model1 loss : 0.262628 model2 loss : 0.282918
[00:41:26.223] iteration 29277 : model1 loss : 0.177729 model2 loss : 0.183088
[00:41:26.558] iteration 29278 : model1 loss : 0.091426 model2 loss : 0.097015
[00:41:26.895] iteration 29279 : model1 loss : 0.185945 model2 loss : 0.184254
[00:41:27.232] iteration 29280 : model1 loss : 0.325181 model2 loss : 0.364315
[00:41:27.565] iteration 29281 : model1 loss : 0.263191 model2 loss : 0.268500
[00:41:27.898] iteration 29282 : model1 loss : 0.154529 model2 loss : 0.167975
[00:41:28.235] iteration 29283 : model1 loss : 0.174831 model2 loss : 0.189567
[00:41:28.575] iteration 29284 : model1 loss : 0.240617 model2 loss : 0.276206
[00:41:28.909] iteration 29285 : model1 loss : 0.100188 model2 loss : 0.119432
[00:41:29.246] iteration 29286 : model1 loss : 0.160987 model2 loss : 0.193301
[00:41:29.583] iteration 29287 : model1 loss : 0.236016 model2 loss : 0.281703
[00:41:29.915] iteration 29288 : model1 loss : 0.264917 model2 loss : 0.257447
[00:41:30.254] iteration 29289 : model1 loss : 0.187133 model2 loss : 0.213277
[00:41:30.592] iteration 29290 : model1 loss : 0.180810 model2 loss : 0.270435
[00:41:30.928] iteration 29291 : model1 loss : 0.240085 model2 loss : 0.302514
[00:41:31.259] iteration 29292 : model1 loss : 0.169417 model2 loss : 0.249544
[00:41:31.594] iteration 29293 : model1 loss : 0.175683 model2 loss : 0.206625
[00:41:31.930] iteration 29294 : model1 loss : 0.097737 model2 loss : 0.196846
[00:41:32.266] iteration 29295 : model1 loss : 0.085634 model2 loss : 0.138977
[00:41:32.599] iteration 29296 : model1 loss : 0.225204 model2 loss : 0.226469
[00:41:32.933] iteration 29297 : model1 loss : 0.235593 model2 loss : 0.246932
[00:41:33.267] iteration 29298 : model1 loss : 0.160978 model2 loss : 0.210318
[00:41:33.608] iteration 29299 : model1 loss : 0.186418 model2 loss : 0.236575
[00:41:33.943] iteration 29300 : model1 loss : 0.247163 model2 loss : 0.283513
[00:41:34.558] iteration 29301 : model1 loss : 0.064432 model2 loss : 0.114733
[00:41:34.897] iteration 29302 : model1 loss : 0.167850 model2 loss : 0.220420
[00:41:35.232] iteration 29303 : model1 loss : 0.092108 model2 loss : 0.119040
[00:41:35.570] iteration 29304 : model1 loss : 0.242377 model2 loss : 0.247357
[00:41:35.904] iteration 29305 : model1 loss : 0.235363 model2 loss : 0.242016
[00:41:36.244] iteration 29306 : model1 loss : 0.149206 model2 loss : 0.165786
[00:41:36.575] iteration 29307 : model1 loss : 0.154493 model2 loss : 0.208756
[00:41:36.911] iteration 29308 : model1 loss : 0.168426 model2 loss : 0.207048
[00:41:37.244] iteration 29309 : model1 loss : 0.253023 model2 loss : 0.276431
[00:41:37.578] iteration 29310 : model1 loss : 0.119376 model2 loss : 0.106992
[00:41:37.911] iteration 29311 : model1 loss : 0.193133 model2 loss : 0.220475
[00:41:38.247] iteration 29312 : model1 loss : 0.094117 model2 loss : 0.133191
[00:41:38.583] iteration 29313 : model1 loss : 0.230800 model2 loss : 0.262634
[00:41:38.920] iteration 29314 : model1 loss : 0.231570 model2 loss : 0.230595
[00:41:39.256] iteration 29315 : model1 loss : 0.190390 model2 loss : 0.201464
[00:41:39.592] iteration 29316 : model1 loss : 0.091990 model2 loss : 0.120281
[00:41:39.925] iteration 29317 : model1 loss : 0.154249 model2 loss : 0.234776
[00:41:40.261] iteration 29318 : model1 loss : 0.238715 model2 loss : 0.248862
[00:41:40.600] iteration 29319 : model1 loss : 0.089902 model2 loss : 0.175770
[00:41:40.934] iteration 29320 : model1 loss : 0.172627 model2 loss : 0.220575
[00:41:41.270] iteration 29321 : model1 loss : 0.094676 model2 loss : 0.127666
[00:41:41.608] iteration 29322 : model1 loss : 0.255151 model2 loss : 0.287685
[00:41:41.940] iteration 29323 : model1 loss : 0.096776 model2 loss : 0.112172
[00:41:42.277] iteration 29324 : model1 loss : 0.167341 model2 loss : 0.165255
[00:41:42.613] iteration 29325 : model1 loss : 0.165953 model2 loss : 0.171902
[00:41:42.946] iteration 29326 : model1 loss : 0.180330 model2 loss : 0.225643
[00:41:43.278] iteration 29327 : model1 loss : 0.183598 model2 loss : 0.184547
[00:41:43.612] iteration 29328 : model1 loss : 0.085671 model2 loss : 0.080828
[00:41:43.946] iteration 29329 : model1 loss : 0.180803 model2 loss : 0.238114
[00:41:44.282] iteration 29330 : model1 loss : 0.118292 model2 loss : 0.172308
[00:41:44.614] iteration 29331 : model1 loss : 0.155876 model2 loss : 0.239963
[00:41:44.947] iteration 29332 : model1 loss : 0.156049 model2 loss : 0.149675
[00:41:45.279] iteration 29333 : model1 loss : 0.234586 model2 loss : 0.227888
[00:41:45.615] iteration 29334 : model1 loss : 0.185870 model2 loss : 0.192042
[00:41:45.947] iteration 29335 : model1 loss : 0.156493 model2 loss : 0.173250
[00:41:46.284] iteration 29336 : model1 loss : 0.070505 model2 loss : 0.083738
[00:41:46.617] iteration 29337 : model1 loss : 0.267258 model2 loss : 0.301692
[00:41:46.955] iteration 29338 : model1 loss : 0.257355 model2 loss : 0.261143
[00:41:47.287] iteration 29339 : model1 loss : 0.187523 model2 loss : 0.220803
[00:41:47.624] iteration 29340 : model1 loss : 0.249200 model2 loss : 0.343679
[00:41:47.965] iteration 29341 : model1 loss : 0.267677 model2 loss : 0.293925
[00:41:48.298] iteration 29342 : model1 loss : 0.285571 model2 loss : 0.311525
[00:41:48.628] iteration 29343 : model1 loss : 0.165236 model2 loss : 0.185522
[00:41:48.966] iteration 29344 : model1 loss : 0.183128 model2 loss : 0.213237
[00:41:49.303] iteration 29345 : model1 loss : 0.165858 model2 loss : 0.219412
[00:41:49.641] iteration 29346 : model1 loss : 0.227933 model2 loss : 0.271445
[00:41:49.978] iteration 29347 : model1 loss : 0.185600 model2 loss : 0.213439
[00:41:50.320] iteration 29348 : model1 loss : 0.249661 model2 loss : 0.265604
[00:41:50.655] iteration 29349 : model1 loss : 0.174114 model2 loss : 0.172001
[00:41:50.988] iteration 29350 : model1 loss : 0.254255 model2 loss : 0.266173
[00:41:51.627] iteration 29351 : model1 loss : 0.255244 model2 loss : 0.268948
[00:41:51.963] iteration 29352 : model1 loss : 0.091438 model2 loss : 0.149688
[00:41:52.297] iteration 29353 : model1 loss : 0.106509 model2 loss : 0.280767
[00:41:52.630] iteration 29354 : model1 loss : 0.084258 model2 loss : 0.084443
[00:41:52.962] iteration 29355 : model1 loss : 0.179416 model2 loss : 0.247027
[00:41:53.303] iteration 29356 : model1 loss : 0.155551 model2 loss : 0.226722
[00:41:53.637] iteration 29357 : model1 loss : 0.240489 model2 loss : 0.250722
[00:41:53.973] iteration 29358 : model1 loss : 0.272215 model2 loss : 0.302808
[00:41:54.307] iteration 29359 : model1 loss : 0.159408 model2 loss : 0.178983
[00:41:54.641] iteration 29360 : model1 loss : 0.179222 model2 loss : 0.196000
[00:41:54.973] iteration 29361 : model1 loss : 0.195005 model2 loss : 0.208450
[00:41:55.306] iteration 29362 : model1 loss : 0.198167 model2 loss : 0.214556
[00:41:55.643] iteration 29363 : model1 loss : 0.076797 model2 loss : 0.092416
[00:41:55.983] iteration 29364 : model1 loss : 0.147477 model2 loss : 0.167780
[00:41:56.318] iteration 29365 : model1 loss : 0.313322 model2 loss : 0.320286
[00:41:56.652] iteration 29366 : model1 loss : 0.391196 model2 loss : 0.454696
[00:41:56.984] iteration 29367 : model1 loss : 0.243706 model2 loss : 0.258041
[00:41:57.316] iteration 29368 : model1 loss : 0.099871 model2 loss : 0.103419
[00:41:57.648] iteration 29369 : model1 loss : 0.176368 model2 loss : 0.209877
[00:41:57.982] iteration 29370 : model1 loss : 0.236248 model2 loss : 0.241959
[00:41:58.319] iteration 29371 : model1 loss : 0.106116 model2 loss : 0.165815
[00:41:58.657] iteration 29372 : model1 loss : 0.142660 model2 loss : 0.205728
[00:41:58.991] iteration 29373 : model1 loss : 0.271019 model2 loss : 0.262369
[00:41:59.327] iteration 29374 : model1 loss : 0.239411 model2 loss : 0.250004
[00:41:59.659] iteration 29375 : model1 loss : 0.236914 model2 loss : 0.265605
[00:41:59.992] iteration 29376 : model1 loss : 0.077329 model2 loss : 0.074917
[00:42:00.329] iteration 29377 : model1 loss : 0.190795 model2 loss : 0.221135
[00:42:00.664] iteration 29378 : model1 loss : 0.072560 model2 loss : 0.137813
[00:42:00.997] iteration 29379 : model1 loss : 0.317244 model2 loss : 0.340910
[00:42:01.335] iteration 29380 : model1 loss : 0.247325 model2 loss : 0.245407
[00:42:01.670] iteration 29381 : model1 loss : 0.167314 model2 loss : 0.191756
[00:42:02.003] iteration 29382 : model1 loss : 0.184231 model2 loss : 0.213092
[00:42:02.343] iteration 29383 : model1 loss : 0.152333 model2 loss : 0.174824
[00:42:02.683] iteration 29384 : model1 loss : 0.154933 model2 loss : 0.185784
[00:42:03.017] iteration 29385 : model1 loss : 0.256466 model2 loss : 0.363966
[00:42:03.351] iteration 29386 : model1 loss : 0.102873 model2 loss : 0.153312
[00:42:03.683] iteration 29387 : model1 loss : 0.106420 model2 loss : 0.126017
[00:42:04.017] iteration 29388 : model1 loss : 0.094735 model2 loss : 0.101828
[00:42:04.354] iteration 29389 : model1 loss : 0.316611 model2 loss : 0.333970
[00:42:04.703] iteration 29390 : model1 loss : 0.096119 model2 loss : 0.107529
[00:42:05.037] iteration 29391 : model1 loss : 0.105071 model2 loss : 0.105295
[00:42:05.379] iteration 29392 : model1 loss : 0.277395 model2 loss : 0.295354
[00:42:05.713] iteration 29393 : model1 loss : 0.162339 model2 loss : 0.171697
[00:42:06.046] iteration 29394 : model1 loss : 0.092074 model2 loss : 0.144791
[00:42:06.378] iteration 29395 : model1 loss : 0.159419 model2 loss : 0.183733
[00:42:06.712] iteration 29396 : model1 loss : 0.193565 model2 loss : 0.213907
[00:42:07.048] iteration 29397 : model1 loss : 0.069537 model2 loss : 0.124784
[00:42:07.380] iteration 29398 : model1 loss : 0.266490 model2 loss : 0.288653
[00:42:07.716] iteration 29399 : model1 loss : 0.172459 model2 loss : 0.218301
[00:42:08.055] iteration 29400 : model1 loss : 0.147475 model2 loss : 0.176630
[00:42:08.683] iteration 29401 : model1 loss : 0.157490 model2 loss : 0.193896
[00:42:09.016] iteration 29402 : model1 loss : 0.159081 model2 loss : 0.181454
[00:42:09.351] iteration 29403 : model1 loss : 0.416227 model2 loss : 0.413661
[00:42:09.684] iteration 29404 : model1 loss : 0.192439 model2 loss : 0.194338
[00:42:10.016] iteration 29405 : model1 loss : 0.248815 model2 loss : 0.252808
[00:42:10.352] iteration 29406 : model1 loss : 0.074630 model2 loss : 0.107906
[00:42:10.684] iteration 29407 : model1 loss : 0.171992 model2 loss : 0.194824
[00:42:11.019] iteration 29408 : model1 loss : 0.176705 model2 loss : 0.260007
[00:42:11.351] iteration 29409 : model1 loss : 0.320800 model2 loss : 0.319599
[00:42:11.683] iteration 29410 : model1 loss : 0.167213 model2 loss : 0.181628
[00:42:12.016] iteration 29411 : model1 loss : 0.215394 model2 loss : 0.280078
[00:42:12.354] iteration 29412 : model1 loss : 0.057718 model2 loss : 0.403218
[00:42:12.689] iteration 29413 : model1 loss : 0.177980 model2 loss : 0.226184
[00:42:13.026] iteration 29414 : model1 loss : 0.187427 model2 loss : 0.195553
[00:42:13.367] iteration 29415 : model1 loss : 0.155409 model2 loss : 0.161213
[00:42:13.707] iteration 29416 : model1 loss : 0.150861 model2 loss : 0.183014
[00:42:14.041] iteration 29417 : model1 loss : 0.105100 model2 loss : 0.209365
[00:42:14.374] iteration 29418 : model1 loss : 0.063817 model2 loss : 0.109095
[00:42:14.731] iteration 29419 : model1 loss : 0.163310 model2 loss : 0.183667
[00:42:15.064] iteration 29420 : model1 loss : 0.166945 model2 loss : 0.178898
[00:42:15.404] iteration 29421 : model1 loss : 0.191358 model2 loss : 0.210173
[00:42:15.740] iteration 29422 : model1 loss : 0.075594 model2 loss : 0.100779
[00:42:16.072] iteration 29423 : model1 loss : 0.190064 model2 loss : 0.202076
[00:42:16.409] iteration 29424 : model1 loss : 0.167527 model2 loss : 0.214153
[00:42:16.743] iteration 29425 : model1 loss : 0.247337 model2 loss : 0.254197
[00:42:17.074] iteration 29426 : model1 loss : 0.151384 model2 loss : 0.160557
[00:42:17.413] iteration 29427 : model1 loss : 0.159299 model2 loss : 0.190481
[00:42:17.744] iteration 29428 : model1 loss : 0.076170 model2 loss : 0.112022
[00:42:18.077] iteration 29429 : model1 loss : 0.298887 model2 loss : 0.303861
[00:42:18.408] iteration 29430 : model1 loss : 0.158063 model2 loss : 0.216024
[00:42:19.540] iteration 29431 : model1 loss : 0.155718 model2 loss : 0.225655
[00:42:19.877] iteration 29432 : model1 loss : 0.207469 model2 loss : 0.210762
[00:42:20.214] iteration 29433 : model1 loss : 0.277670 model2 loss : 0.319265
[00:42:20.551] iteration 29434 : model1 loss : 0.175544 model2 loss : 0.175839
[00:42:20.890] iteration 29435 : model1 loss : 0.094782 model2 loss : 0.210607
[00:42:21.234] iteration 29436 : model1 loss : 0.056835 model2 loss : 0.088307
[00:42:21.567] iteration 29437 : model1 loss : 0.174519 model2 loss : 0.204035
[00:42:21.902] iteration 29438 : model1 loss : 0.227933 model2 loss : 0.268599
[00:42:22.243] iteration 29439 : model1 loss : 0.246390 model2 loss : 0.318597
[00:42:22.578] iteration 29440 : model1 loss : 0.154133 model2 loss : 0.219178
[00:42:22.912] iteration 29441 : model1 loss : 0.165759 model2 loss : 0.171075
[00:42:23.250] iteration 29442 : model1 loss : 0.112519 model2 loss : 0.130388
[00:42:23.584] iteration 29443 : model1 loss : 0.178007 model2 loss : 0.194195
[00:42:23.920] iteration 29444 : model1 loss : 0.085231 model2 loss : 0.091618
[00:42:24.256] iteration 29445 : model1 loss : 0.086052 model2 loss : 0.117578
[00:42:24.589] iteration 29446 : model1 loss : 0.078037 model2 loss : 0.121609
[00:42:24.926] iteration 29447 : model1 loss : 0.182048 model2 loss : 0.194540
[00:42:25.270] iteration 29448 : model1 loss : 0.169703 model2 loss : 0.222592
[00:42:25.606] iteration 29449 : model1 loss : 0.171384 model2 loss : 0.203507
[00:42:25.941] iteration 29450 : model1 loss : 0.175942 model2 loss : 0.223759
[00:42:26.575] iteration 29451 : model1 loss : 0.261022 model2 loss : 0.268645
[00:42:26.906] iteration 29452 : model1 loss : 0.147819 model2 loss : 0.167028
[00:42:27.238] iteration 29453 : model1 loss : 0.088918 model2 loss : 0.136127
[00:42:27.569] iteration 29454 : model1 loss : 0.175508 model2 loss : 0.185641
[00:42:27.906] iteration 29455 : model1 loss : 0.285214 model2 loss : 0.320740
[00:42:28.241] iteration 29456 : model1 loss : 0.153766 model2 loss : 0.173551
[00:42:28.572] iteration 29457 : model1 loss : 0.162051 model2 loss : 0.205252
[00:42:28.905] iteration 29458 : model1 loss : 0.247182 model2 loss : 0.295147
[00:42:29.237] iteration 29459 : model1 loss : 0.168100 model2 loss : 0.177577
[00:42:29.573] iteration 29460 : model1 loss : 0.129343 model2 loss : 0.175679
[00:42:29.904] iteration 29461 : model1 loss : 0.169455 model2 loss : 0.206078
[00:42:30.236] iteration 29462 : model1 loss : 0.206533 model2 loss : 0.224322
[00:42:30.568] iteration 29463 : model1 loss : 0.216734 model2 loss : 0.239702
[00:42:30.899] iteration 29464 : model1 loss : 0.262174 model2 loss : 0.269854
[00:42:31.231] iteration 29465 : model1 loss : 0.165892 model2 loss : 0.196365
[00:42:31.562] iteration 29466 : model1 loss : 0.074608 model2 loss : 0.132518
[00:42:31.893] iteration 29467 : model1 loss : 0.242920 model2 loss : 0.260778
[00:42:32.225] iteration 29468 : model1 loss : 0.101344 model2 loss : 0.144728
[00:42:32.557] iteration 29469 : model1 loss : 0.316129 model2 loss : 0.317692
[00:42:32.894] iteration 29470 : model1 loss : 0.076168 model2 loss : 0.084240
[00:42:33.227] iteration 29471 : model1 loss : 0.265498 model2 loss : 0.284668
[00:42:33.562] iteration 29472 : model1 loss : 0.196056 model2 loss : 0.225580
[00:42:33.893] iteration 29473 : model1 loss : 0.320601 model2 loss : 0.325280
[00:42:34.225] iteration 29474 : model1 loss : 0.126322 model2 loss : 0.171778
[00:42:34.556] iteration 29475 : model1 loss : 0.149751 model2 loss : 0.180297
[00:42:34.887] iteration 29476 : model1 loss : 0.085126 model2 loss : 0.135655
[00:42:35.220] iteration 29477 : model1 loss : 0.158935 model2 loss : 0.194074
[00:42:35.552] iteration 29478 : model1 loss : 0.085513 model2 loss : 0.094355
[00:42:35.883] iteration 29479 : model1 loss : 0.182093 model2 loss : 0.231869
[00:42:36.218] iteration 29480 : model1 loss : 0.266099 model2 loss : 0.279974
[00:42:36.553] iteration 29481 : model1 loss : 0.239965 model2 loss : 0.305815
[00:42:36.887] iteration 29482 : model1 loss : 0.224911 model2 loss : 0.239176
[00:42:37.219] iteration 29483 : model1 loss : 0.159336 model2 loss : 0.180405
[00:42:37.551] iteration 29484 : model1 loss : 0.103089 model2 loss : 0.129389
[00:42:37.885] iteration 29485 : model1 loss : 0.100395 model2 loss : 0.145544
[00:42:38.217] iteration 29486 : model1 loss : 0.191435 model2 loss : 0.220677
[00:42:38.554] iteration 29487 : model1 loss : 0.202184 model2 loss : 0.225018
[00:42:38.886] iteration 29488 : model1 loss : 0.160592 model2 loss : 0.185664
[00:42:39.217] iteration 29489 : model1 loss : 0.120110 model2 loss : 0.100092
[00:42:39.552] iteration 29490 : model1 loss : 0.178092 model2 loss : 0.200789
[00:42:39.886] iteration 29491 : model1 loss : 0.157090 model2 loss : 0.205306
[00:42:40.222] iteration 29492 : model1 loss : 0.248704 model2 loss : 0.249243
[00:42:40.553] iteration 29493 : model1 loss : 0.221617 model2 loss : 0.240261
[00:42:40.886] iteration 29494 : model1 loss : 0.190566 model2 loss : 0.198590
[00:42:41.224] iteration 29495 : model1 loss : 0.234680 model2 loss : 0.280358
[00:42:41.559] iteration 29496 : model1 loss : 0.263161 model2 loss : 0.347945
[00:42:41.891] iteration 29497 : model1 loss : 0.095967 model2 loss : 0.135964
[00:42:42.223] iteration 29498 : model1 loss : 0.188036 model2 loss : 0.211530
[00:42:42.554] iteration 29499 : model1 loss : 0.115706 model2 loss : 0.171855
[00:42:42.886] iteration 29500 : model1 loss : 0.103126 model2 loss : 0.132599
[00:42:43.491] iteration 29501 : model1 loss : 0.154746 model2 loss : 0.169679
[00:42:43.829] iteration 29502 : model1 loss : 0.262456 model2 loss : 0.293841
[00:42:44.164] iteration 29503 : model1 loss : 0.224025 model2 loss : 0.237095
[00:42:44.500] iteration 29504 : model1 loss : 0.243919 model2 loss : 0.252258
[00:42:44.832] iteration 29505 : model1 loss : 0.160727 model2 loss : 0.182998
[00:42:45.169] iteration 29506 : model1 loss : 0.254857 model2 loss : 0.300254
[00:42:45.506] iteration 29507 : model1 loss : 0.089867 model2 loss : 0.155948
[00:42:45.842] iteration 29508 : model1 loss : 0.341316 model2 loss : 0.355127
[00:42:46.183] iteration 29509 : model1 loss : 0.218520 model2 loss : 0.235668
[00:42:46.521] iteration 29510 : model1 loss : 0.256714 model2 loss : 0.250064
[00:42:46.853] iteration 29511 : model1 loss : 0.094290 model2 loss : 0.125488
[00:42:47.188] iteration 29512 : model1 loss : 0.154279 model2 loss : 0.181966
[00:42:47.522] iteration 29513 : model1 loss : 0.201141 model2 loss : 0.240334
[00:42:47.857] iteration 29514 : model1 loss : 0.166846 model2 loss : 0.174222
[00:42:48.188] iteration 29515 : model1 loss : 0.350575 model2 loss : 0.345943
[00:42:48.519] iteration 29516 : model1 loss : 0.173752 model2 loss : 0.181401
[00:42:48.855] iteration 29517 : model1 loss : 0.182135 model2 loss : 0.169520
[00:42:49.189] iteration 29518 : model1 loss : 0.236828 model2 loss : 0.216780
[00:42:49.522] iteration 29519 : model1 loss : 0.148477 model2 loss : 0.160395
[00:42:49.854] iteration 29520 : model1 loss : 0.144788 model2 loss : 0.186584
[00:42:50.189] iteration 29521 : model1 loss : 0.289611 model2 loss : 0.317810
[00:42:50.531] iteration 29522 : model1 loss : 0.132892 model2 loss : 0.205698
[00:42:50.868] iteration 29523 : model1 loss : 0.092465 model2 loss : 0.144443
[00:42:51.201] iteration 29524 : model1 loss : 0.200414 model2 loss : 0.269203
[00:42:51.532] iteration 29525 : model1 loss : 0.096537 model2 loss : 0.105199
[00:42:51.864] iteration 29526 : model1 loss : 0.313373 model2 loss : 0.316542
[00:42:52.195] iteration 29527 : model1 loss : 0.203386 model2 loss : 0.218736
[00:42:52.530] iteration 29528 : model1 loss : 0.084678 model2 loss : 0.109406
[00:42:52.866] iteration 29529 : model1 loss : 0.171981 model2 loss : 0.192674
[00:42:53.205] iteration 29530 : model1 loss : 0.174945 model2 loss : 0.180106
[00:42:53.540] iteration 29531 : model1 loss : 0.213178 model2 loss : 0.224328
[00:42:53.872] iteration 29532 : model1 loss : 0.120499 model2 loss : 0.115671
[00:42:54.207] iteration 29533 : model1 loss : 0.237389 model2 loss : 0.295205
[00:42:54.539] iteration 29534 : model1 loss : 0.182706 model2 loss : 0.203920
[00:42:54.876] iteration 29535 : model1 loss : 0.092426 model2 loss : 0.127528
[00:42:55.218] iteration 29536 : model1 loss : 0.170050 model2 loss : 0.214216
[00:42:55.556] iteration 29537 : model1 loss : 0.097281 model2 loss : 0.220364
[00:42:55.889] iteration 29538 : model1 loss : 0.149621 model2 loss : 0.191546
[00:42:56.225] iteration 29539 : model1 loss : 0.151858 model2 loss : 0.159608
[00:42:56.560] iteration 29540 : model1 loss : 0.163361 model2 loss : 0.248056
[00:42:56.895] iteration 29541 : model1 loss : 0.250525 model2 loss : 0.240549
[00:42:57.231] iteration 29542 : model1 loss : 0.257915 model2 loss : 0.267631
[00:42:57.563] iteration 29543 : model1 loss : 0.173672 model2 loss : 0.185394
[00:42:57.898] iteration 29544 : model1 loss : 0.158250 model2 loss : 0.228079
[00:42:58.230] iteration 29545 : model1 loss : 0.102912 model2 loss : 0.091966
[00:42:58.565] iteration 29546 : model1 loss : 0.185873 model2 loss : 0.211007
[00:42:58.900] iteration 29547 : model1 loss : 0.174460 model2 loss : 0.205773
[00:42:59.234] iteration 29548 : model1 loss : 0.169805 model2 loss : 0.191812
[00:42:59.566] iteration 29549 : model1 loss : 0.155985 model2 loss : 0.164912
[00:42:59.898] iteration 29550 : model1 loss : 0.255210 model2 loss : 0.294346
[00:43:00.509] iteration 29551 : model1 loss : 0.055032 model2 loss : 0.109657
[00:43:00.844] iteration 29552 : model1 loss : 0.117969 model2 loss : 0.159780
[00:43:01.177] iteration 29553 : model1 loss : 0.138126 model2 loss : 0.160790
[00:43:01.510] iteration 29554 : model1 loss : 0.096835 model2 loss : 0.172261
[00:43:01.841] iteration 29555 : model1 loss : 0.148634 model2 loss : 0.163950
[00:43:02.176] iteration 29556 : model1 loss : 0.210780 model2 loss : 0.271631
[00:43:02.508] iteration 29557 : model1 loss : 0.201601 model2 loss : 0.211805
[00:43:02.845] iteration 29558 : model1 loss : 0.144908 model2 loss : 0.169832
[00:43:03.182] iteration 29559 : model1 loss : 0.167568 model2 loss : 0.195838
[00:43:03.514] iteration 29560 : model1 loss : 0.174296 model2 loss : 0.239466
[00:43:03.849] iteration 29561 : model1 loss : 0.101898 model2 loss : 0.121878
[00:43:04.185] iteration 29562 : model1 loss : 0.189142 model2 loss : 0.240238
[00:43:04.522] iteration 29563 : model1 loss : 0.060276 model2 loss : 0.086851
[00:43:04.862] iteration 29564 : model1 loss : 0.278621 model2 loss : 0.320137
[00:43:05.197] iteration 29565 : model1 loss : 0.068723 model2 loss : 0.094989
[00:43:05.533] iteration 29566 : model1 loss : 0.262864 model2 loss : 0.285656
[00:43:05.872] iteration 29567 : model1 loss : 0.160103 model2 loss : 0.180408
[00:43:06.208] iteration 29568 : model1 loss : 0.242628 model2 loss : 0.260566
[00:43:06.541] iteration 29569 : model1 loss : 0.161348 model2 loss : 0.169360
[00:43:06.878] iteration 29570 : model1 loss : 0.147100 model2 loss : 0.144157
[00:43:07.214] iteration 29571 : model1 loss : 0.193841 model2 loss : 0.303597
[00:43:07.553] iteration 29572 : model1 loss : 0.102451 model2 loss : 0.120235
[00:43:07.889] iteration 29573 : model1 loss : 0.153337 model2 loss : 0.177500
[00:43:08.228] iteration 29574 : model1 loss : 0.241934 model2 loss : 0.262054
[00:43:08.564] iteration 29575 : model1 loss : 0.155930 model2 loss : 0.175677
[00:43:08.900] iteration 29576 : model1 loss : 0.153554 model2 loss : 0.175473
[00:43:09.232] iteration 29577 : model1 loss : 0.081250 model2 loss : 0.090206
[00:43:09.565] iteration 29578 : model1 loss : 0.172109 model2 loss : 0.185774
[00:43:09.900] iteration 29579 : model1 loss : 0.270933 model2 loss : 0.283010
[00:43:10.234] iteration 29580 : model1 loss : 0.250776 model2 loss : 0.282019
[00:43:10.569] iteration 29581 : model1 loss : 0.314799 model2 loss : 0.329823
[00:43:10.906] iteration 29582 : model1 loss : 0.149278 model2 loss : 0.172761
[00:43:11.239] iteration 29583 : model1 loss : 0.234486 model2 loss : 0.247624
[00:43:11.570] iteration 29584 : model1 loss : 0.090385 model2 loss : 0.094388
[00:43:11.902] iteration 29585 : model1 loss : 0.188002 model2 loss : 0.218840
[00:43:12.238] iteration 29586 : model1 loss : 0.079679 model2 loss : 0.148231
[00:43:12.571] iteration 29587 : model1 loss : 0.196071 model2 loss : 0.180286
[00:43:12.906] iteration 29588 : model1 loss : 0.103361 model2 loss : 0.127102
[00:43:13.241] iteration 29589 : model1 loss : 0.078242 model2 loss : 0.076061
[00:43:13.576] iteration 29590 : model1 loss : 0.276213 model2 loss : 0.310787
[00:43:13.909] iteration 29591 : model1 loss : 0.160672 model2 loss : 0.198069
[00:43:14.240] iteration 29592 : model1 loss : 0.129391 model2 loss : 0.133771
[00:43:14.572] iteration 29593 : model1 loss : 0.181872 model2 loss : 0.220089
[00:43:14.908] iteration 29594 : model1 loss : 0.163083 model2 loss : 0.163129
[00:43:15.240] iteration 29595 : model1 loss : 0.291913 model2 loss : 0.309522
[00:43:15.572] iteration 29596 : model1 loss : 0.175962 model2 loss : 0.168531
[00:43:15.907] iteration 29597 : model1 loss : 0.148445 model2 loss : 0.162206
[00:43:16.245] iteration 29598 : model1 loss : 0.121069 model2 loss : 0.158073
[00:43:16.576] iteration 29599 : model1 loss : 0.188139 model2 loss : 0.206685
[00:43:16.908] iteration 29600 : model1 loss : 0.226898 model2 loss : 0.235520
[00:43:17.554] iteration 29601 : model1 loss : 0.147693 model2 loss : 0.185437
[00:43:17.889] iteration 29602 : model1 loss : 0.152070 model2 loss : 0.181021
[00:43:18.222] iteration 29603 : model1 loss : 0.088525 model2 loss : 0.131717
[00:43:18.556] iteration 29604 : model1 loss : 0.155059 model2 loss : 0.186144
[00:43:18.892] iteration 29605 : model1 loss : 0.262990 model2 loss : 0.299694
[00:43:19.226] iteration 29606 : model1 loss : 0.238582 model2 loss : 0.243874
[00:43:19.559] iteration 29607 : model1 loss : 0.254530 model2 loss : 0.257336
[00:43:19.891] iteration 29608 : model1 loss : 0.207880 model2 loss : 0.268327
[00:43:20.222] iteration 29609 : model1 loss : 0.187127 model2 loss : 0.219817
[00:43:20.554] iteration 29610 : model1 loss : 0.160160 model2 loss : 0.200172
[00:43:20.890] iteration 29611 : model1 loss : 0.268572 model2 loss : 0.312599
[00:43:21.225] iteration 29612 : model1 loss : 0.115911 model2 loss : 0.111607
[00:43:21.556] iteration 29613 : model1 loss : 0.090617 model2 loss : 0.112796
[00:43:21.890] iteration 29614 : model1 loss : 0.217450 model2 loss : 0.254803
[00:43:22.222] iteration 29615 : model1 loss : 0.176075 model2 loss : 0.217253
[00:43:22.553] iteration 29616 : model1 loss : 0.265227 model2 loss : 0.274543
[00:43:22.885] iteration 29617 : model1 loss : 0.247783 model2 loss : 0.268973
[00:43:23.221] iteration 29618 : model1 loss : 0.238907 model2 loss : 0.240138
[00:43:23.553] iteration 29619 : model1 loss : 0.249383 model2 loss : 0.261365
[00:43:23.888] iteration 29620 : model1 loss : 0.213685 model2 loss : 0.244444
[00:43:24.224] iteration 29621 : model1 loss : 0.174853 model2 loss : 0.199198
[00:43:24.557] iteration 29622 : model1 loss : 0.229355 model2 loss : 0.243327
[00:43:24.892] iteration 29623 : model1 loss : 0.191543 model2 loss : 0.207468
[00:43:25.225] iteration 29624 : model1 loss : 0.267831 model2 loss : 0.262124
[00:43:25.558] iteration 29625 : model1 loss : 0.096204 model2 loss : 0.124217
[00:43:25.889] iteration 29626 : model1 loss : 0.143184 model2 loss : 0.145377
[00:43:26.225] iteration 29627 : model1 loss : 0.167575 model2 loss : 0.186843
[00:43:26.560] iteration 29628 : model1 loss : 0.234723 model2 loss : 0.260234
[00:43:26.893] iteration 29629 : model1 loss : 0.100420 model2 loss : 0.089612
[00:43:27.226] iteration 29630 : model1 loss : 0.177186 model2 loss : 0.181112
[00:43:27.557] iteration 29631 : model1 loss : 0.145649 model2 loss : 0.225234
[00:43:27.894] iteration 29632 : model1 loss : 0.086652 model2 loss : 0.137185
[00:43:28.225] iteration 29633 : model1 loss : 0.163840 model2 loss : 0.175356
[00:43:28.564] iteration 29634 : model1 loss : 0.245863 model2 loss : 0.258378
[00:43:28.889] iteration 29635 : model1 loss : 0.168791 model2 loss : 0.199159
[00:43:29.216] iteration 29636 : model1 loss : 0.324333 model2 loss : 0.363114
[00:43:29.542] iteration 29637 : model1 loss : 0.160055 model2 loss : 0.188236
[00:43:29.873] iteration 29638 : model1 loss : 0.175758 model2 loss : 0.215766
[00:43:30.197] iteration 29639 : model1 loss : 0.084582 model2 loss : 0.133988
[00:43:30.522] iteration 29640 : model1 loss : 0.127365 model2 loss : 0.157397
[00:43:30.852] iteration 29641 : model1 loss : 0.106704 model2 loss : 0.114686
[00:43:31.177] iteration 29642 : model1 loss : 0.324191 model2 loss : 0.351690
[00:43:31.504] iteration 29643 : model1 loss : 0.162436 model2 loss : 0.237077
[00:43:31.831] iteration 29644 : model1 loss : 0.099832 model2 loss : 0.116066
[00:43:32.316] iteration 29645 : model1 loss : 0.128015 model2 loss : 0.140808
[00:43:32.642] iteration 29646 : model1 loss : 0.161520 model2 loss : 0.211129
[00:43:32.967] iteration 29647 : model1 loss : 0.154388 model2 loss : 0.177277
[00:43:33.291] iteration 29648 : model1 loss : 0.149142 model2 loss : 0.164975
[00:43:33.613] iteration 29649 : model1 loss : 0.176298 model2 loss : 0.182899
[00:43:33.940] iteration 29650 : model1 loss : 0.242735 model2 loss : 0.308301
[00:43:34.472] iteration 29651 : model1 loss : 0.139408 model2 loss : 0.189392
[00:43:34.796] iteration 29652 : model1 loss : 0.215477 model2 loss : 0.269373
[00:43:35.119] iteration 29653 : model1 loss : 0.156585 model2 loss : 0.183150
[00:43:35.446] iteration 29654 : model1 loss : 0.133704 model2 loss : 0.148625
[00:43:35.769] iteration 29655 : model1 loss : 0.095735 model2 loss : 0.158366
[00:43:36.092] iteration 29656 : model1 loss : 0.096577 model2 loss : 0.146858
[00:43:36.419] iteration 29657 : model1 loss : 0.173665 model2 loss : 0.180070
[00:43:36.742] iteration 29658 : model1 loss : 0.168380 model2 loss : 0.192568
[00:43:37.069] iteration 29659 : model1 loss : 0.122681 model2 loss : 0.237591
[00:43:37.392] iteration 29660 : model1 loss : 0.101945 model2 loss : 0.121056
[00:43:37.715] iteration 29661 : model1 loss : 0.159976 model2 loss : 0.188858
[00:43:38.042] iteration 29662 : model1 loss : 0.244920 model2 loss : 0.252808
[00:43:38.369] iteration 29663 : model1 loss : 0.099618 model2 loss : 0.225331
[00:43:38.692] iteration 29664 : model1 loss : 0.234590 model2 loss : 0.264848
[00:43:39.014] iteration 29665 : model1 loss : 0.280144 model2 loss : 0.306996
[00:43:39.338] iteration 29666 : model1 loss : 0.152640 model2 loss : 0.194741
[00:43:39.666] iteration 29667 : model1 loss : 0.084957 model2 loss : 0.118610
[00:43:39.993] iteration 29668 : model1 loss : 0.227504 model2 loss : 0.241803
[00:43:40.317] iteration 29669 : model1 loss : 0.156264 model2 loss : 0.181328
[00:43:40.645] iteration 29670 : model1 loss : 0.164380 model2 loss : 0.181992
[00:43:40.970] iteration 29671 : model1 loss : 0.066188 model2 loss : 0.085383
[00:43:41.294] iteration 29672 : model1 loss : 0.192962 model2 loss : 0.222059
[00:43:41.617] iteration 29673 : model1 loss : 0.176269 model2 loss : 0.182012
[00:43:41.950] iteration 29674 : model1 loss : 0.175109 model2 loss : 0.192523
[00:43:42.281] iteration 29675 : model1 loss : 0.150073 model2 loss : 0.160109
[00:43:42.613] iteration 29676 : model1 loss : 0.163376 model2 loss : 0.164807
[00:43:42.946] iteration 29677 : model1 loss : 0.079243 model2 loss : 0.146323
[00:43:43.286] iteration 29678 : model1 loss : 0.181224 model2 loss : 0.241840
[00:43:43.621] iteration 29679 : model1 loss : 0.268911 model2 loss : 0.287534
[00:43:43.957] iteration 29680 : model1 loss : 0.251762 model2 loss : 0.261633
[00:43:44.290] iteration 29681 : model1 loss : 0.117659 model2 loss : 0.140499
[00:43:44.623] iteration 29682 : model1 loss : 0.239662 model2 loss : 0.248495
[00:43:44.961] iteration 29683 : model1 loss : 0.082925 model2 loss : 0.093288
[00:43:45.295] iteration 29684 : model1 loss : 0.174762 model2 loss : 0.225677
[00:43:45.629] iteration 29685 : model1 loss : 0.240137 model2 loss : 0.259594
[00:43:45.967] iteration 29686 : model1 loss : 0.168104 model2 loss : 0.194649
[00:43:46.304] iteration 29687 : model1 loss : 0.183601 model2 loss : 0.187306
[00:43:46.639] iteration 29688 : model1 loss : 0.186957 model2 loss : 0.199744
[00:43:46.975] iteration 29689 : model1 loss : 0.102689 model2 loss : 0.143707
[00:43:47.309] iteration 29690 : model1 loss : 0.102362 model2 loss : 0.162805
[00:43:47.642] iteration 29691 : model1 loss : 0.055489 model2 loss : 0.407808
[00:43:47.982] iteration 29692 : model1 loss : 0.157671 model2 loss : 0.195807
[00:43:48.316] iteration 29693 : model1 loss : 0.158076 model2 loss : 0.169424
[00:43:48.652] iteration 29694 : model1 loss : 0.170332 model2 loss : 0.183837
[00:43:48.985] iteration 29695 : model1 loss : 0.185601 model2 loss : 0.201756
[00:43:49.323] iteration 29696 : model1 loss : 0.221633 model2 loss : 0.234578
[00:43:49.657] iteration 29697 : model1 loss : 0.070799 model2 loss : 0.158086
[00:43:49.995] iteration 29698 : model1 loss : 0.249031 model2 loss : 0.283899
[00:43:50.339] iteration 29699 : model1 loss : 0.166320 model2 loss : 0.181406
[00:43:50.679] iteration 29700 : model1 loss : 0.142333 model2 loss : 0.206135
[00:43:51.338] iteration 29701 : model1 loss : 0.175582 model2 loss : 0.199319
[00:43:51.674] iteration 29702 : model1 loss : 0.246890 model2 loss : 0.253887
[00:43:52.011] iteration 29703 : model1 loss : 0.252148 model2 loss : 0.286891
[00:43:52.349] iteration 29704 : model1 loss : 0.139260 model2 loss : 0.166439
[00:43:52.686] iteration 29705 : model1 loss : 0.163475 model2 loss : 0.200280
[00:43:53.023] iteration 29706 : model1 loss : 0.092950 model2 loss : 0.188288
[00:43:53.361] iteration 29707 : model1 loss : 0.185135 model2 loss : 0.204607
[00:43:53.703] iteration 29708 : model1 loss : 0.138388 model2 loss : 0.263092
[00:43:54.046] iteration 29709 : model1 loss : 0.237203 model2 loss : 0.244679
[00:43:54.381] iteration 29710 : model1 loss : 0.234525 model2 loss : 0.253616
[00:43:54.718] iteration 29711 : model1 loss : 0.193296 model2 loss : 0.220057
[00:43:55.052] iteration 29712 : model1 loss : 0.149206 model2 loss : 0.181060
[00:43:55.395] iteration 29713 : model1 loss : 0.253747 model2 loss : 0.272955
[00:43:55.729] iteration 29714 : model1 loss : 0.161058 model2 loss : 0.166434
[00:43:56.069] iteration 29715 : model1 loss : 0.265068 model2 loss : 0.314306
[00:43:56.406] iteration 29716 : model1 loss : 0.248243 model2 loss : 0.264717
[00:43:56.742] iteration 29717 : model1 loss : 0.192255 model2 loss : 0.200691
[00:43:57.079] iteration 29718 : model1 loss : 0.082096 model2 loss : 0.114369
[00:43:57.417] iteration 29719 : model1 loss : 0.242754 model2 loss : 0.266129
[00:43:57.749] iteration 29720 : model1 loss : 0.162866 model2 loss : 0.174875
[00:43:58.086] iteration 29721 : model1 loss : 0.165514 model2 loss : 0.191928
[00:43:58.423] iteration 29722 : model1 loss : 0.147878 model2 loss : 0.187615
[00:43:58.761] iteration 29723 : model1 loss : 0.222932 model2 loss : 0.228237
[00:43:59.094] iteration 29724 : model1 loss : 0.089197 model2 loss : 0.117299
[00:43:59.431] iteration 29725 : model1 loss : 0.178859 model2 loss : 0.154501
[00:43:59.769] iteration 29726 : model1 loss : 0.236552 model2 loss : 0.260616
[00:44:00.108] iteration 29727 : model1 loss : 0.261959 model2 loss : 0.270100
[00:44:00.445] iteration 29728 : model1 loss : 0.154609 model2 loss : 0.160112
[00:44:00.782] iteration 29729 : model1 loss : 0.065962 model2 loss : 0.105446
[00:44:01.128] iteration 29730 : model1 loss : 0.169890 model2 loss : 0.202344
[00:44:01.465] iteration 29731 : model1 loss : 0.245280 model2 loss : 0.248959
[00:44:01.798] iteration 29732 : model1 loss : 0.183661 model2 loss : 0.193173
[00:44:02.132] iteration 29733 : model1 loss : 0.176178 model2 loss : 0.214463
[00:44:02.471] iteration 29734 : model1 loss : 0.161525 model2 loss : 0.201232
[00:44:02.807] iteration 29735 : model1 loss : 0.069952 model2 loss : 0.100947
[00:44:03.146] iteration 29736 : model1 loss : 0.173136 model2 loss : 0.185793
[00:44:03.483] iteration 29737 : model1 loss : 0.078610 model2 loss : 0.146191
[00:44:03.824] iteration 29738 : model1 loss : 0.194739 model2 loss : 0.245544
[00:44:04.157] iteration 29739 : model1 loss : 0.155939 model2 loss : 0.187122
[00:44:04.489] iteration 29740 : model1 loss : 0.076354 model2 loss : 0.117885
[00:44:04.826] iteration 29741 : model1 loss : 0.233625 model2 loss : 0.246440
[00:44:05.159] iteration 29742 : model1 loss : 0.257836 model2 loss : 0.278662
[00:44:05.496] iteration 29743 : model1 loss : 0.160468 model2 loss : 0.235478
[00:44:05.832] iteration 29744 : model1 loss : 0.245492 model2 loss : 0.269838
[00:44:06.169] iteration 29745 : model1 loss : 0.108914 model2 loss : 0.115141
[00:44:06.506] iteration 29746 : model1 loss : 0.164153 model2 loss : 0.209935
[00:44:06.846] iteration 29747 : model1 loss : 0.067087 model2 loss : 0.104310
[00:44:07.180] iteration 29748 : model1 loss : 0.080948 model2 loss : 0.185919
[00:44:07.514] iteration 29749 : model1 loss : 0.239641 model2 loss : 0.253363
[00:44:07.858] iteration 29750 : model1 loss : 0.247056 model2 loss : 0.284319
[00:44:08.495] iteration 29751 : model1 loss : 0.100989 model2 loss : 0.101686
[00:44:08.831] iteration 29752 : model1 loss : 0.122315 model2 loss : 0.118900
[00:44:09.165] iteration 29753 : model1 loss : 0.079492 model2 loss : 0.095586
[00:44:09.502] iteration 29754 : model1 loss : 0.072435 model2 loss : 0.106537
[00:44:09.842] iteration 29755 : model1 loss : 0.109561 model2 loss : 0.196436
[00:44:10.179] iteration 29756 : model1 loss : 0.149318 model2 loss : 0.171901
[00:44:10.514] iteration 29757 : model1 loss : 0.275284 model2 loss : 0.270366
[00:44:10.858] iteration 29758 : model1 loss : 0.234617 model2 loss : 0.257180
[00:44:11.193] iteration 29759 : model1 loss : 0.152627 model2 loss : 0.286157
[00:44:11.528] iteration 29760 : model1 loss : 0.153922 model2 loss : 0.174167
[00:44:11.871] iteration 29761 : model1 loss : 0.175881 model2 loss : 0.211201
[00:44:12.206] iteration 29762 : model1 loss : 0.166981 model2 loss : 0.207543
[00:44:12.540] iteration 29763 : model1 loss : 0.261993 model2 loss : 0.309537
[00:44:12.879] iteration 29764 : model1 loss : 0.249874 model2 loss : 0.280770
[00:44:13.211] iteration 29765 : model1 loss : 0.172772 model2 loss : 0.227370
[00:44:13.547] iteration 29766 : model1 loss : 0.074364 model2 loss : 0.112890
[00:44:13.887] iteration 29767 : model1 loss : 0.229563 model2 loss : 0.267512
[00:44:14.230] iteration 29768 : model1 loss : 0.237517 model2 loss : 0.266423
[00:44:14.563] iteration 29769 : model1 loss : 0.097821 model2 loss : 0.187407
[00:44:14.901] iteration 29770 : model1 loss : 0.057961 model2 loss : 0.082358
[00:44:15.237] iteration 29771 : model1 loss : 0.163495 model2 loss : 0.080154
[00:44:15.575] iteration 29772 : model1 loss : 0.161574 model2 loss : 0.202244
[00:44:15.910] iteration 29773 : model1 loss : 0.108590 model2 loss : 0.107005
[00:44:16.235] iteration 29774 : model1 loss : 0.182661 model2 loss : 0.260809
[00:44:16.564] iteration 29775 : model1 loss : 0.248564 model2 loss : 0.274029
[00:44:16.894] iteration 29776 : model1 loss : 0.177664 model2 loss : 0.219158
[00:44:17.220] iteration 29777 : model1 loss : 0.342441 model2 loss : 0.391807
[00:44:17.543] iteration 29778 : model1 loss : 0.262162 model2 loss : 0.275991
[00:44:17.868] iteration 29779 : model1 loss : 0.233539 model2 loss : 0.251221
[00:44:18.192] iteration 29780 : model1 loss : 0.234698 model2 loss : 0.277420
[00:44:18.518] iteration 29781 : model1 loss : 0.178703 model2 loss : 0.204374
[00:44:18.850] iteration 29782 : model1 loss : 0.193747 model2 loss : 0.181707
[00:44:19.178] iteration 29783 : model1 loss : 0.317103 model2 loss : 0.327703
[00:44:19.503] iteration 29784 : model1 loss : 0.243293 model2 loss : 0.276979
[00:44:19.827] iteration 29785 : model1 loss : 0.162886 model2 loss : 0.171700
[00:44:20.152] iteration 29786 : model1 loss : 0.168943 model2 loss : 0.187773
[00:44:20.480] iteration 29787 : model1 loss : 0.148790 model2 loss : 0.168890
[00:44:20.806] iteration 29788 : model1 loss : 0.089994 model2 loss : 0.123046
[00:44:21.129] iteration 29789 : model1 loss : 0.198210 model2 loss : 0.172688
[00:44:21.458] iteration 29790 : model1 loss : 0.110469 model2 loss : 0.164396
[00:44:21.785] iteration 29791 : model1 loss : 0.228159 model2 loss : 0.270348
[00:44:22.114] iteration 29792 : model1 loss : 0.113718 model2 loss : 0.132216
[00:44:22.441] iteration 29793 : model1 loss : 0.259221 model2 loss : 0.325380
[00:44:22.764] iteration 29794 : model1 loss : 0.181219 model2 loss : 0.203996
[00:44:23.087] iteration 29795 : model1 loss : 0.128033 model2 loss : 0.157015
[00:44:23.412] iteration 29796 : model1 loss : 0.290828 model2 loss : 0.312088
[00:44:23.737] iteration 29797 : model1 loss : 0.175947 model2 loss : 0.213364
[00:44:24.057] iteration 29798 : model1 loss : 0.169326 model2 loss : 0.210779
[00:44:24.383] iteration 29799 : model1 loss : 0.167263 model2 loss : 0.181293
[00:44:24.708] iteration 29800 : model1 loss : 0.267878 model2 loss : 0.316671
[00:44:25.233] iteration 29801 : model1 loss : 0.201354 model2 loss : 0.223198
[00:44:25.569] iteration 29802 : model1 loss : 0.236630 model2 loss : 0.233294
[00:44:25.894] iteration 29803 : model1 loss : 0.173677 model2 loss : 0.206190
[00:44:26.219] iteration 29804 : model1 loss : 0.156803 model2 loss : 0.181881
[00:44:26.546] iteration 29805 : model1 loss : 0.164909 model2 loss : 0.195724
[00:44:26.877] iteration 29806 : model1 loss : 0.157696 model2 loss : 0.167669
[00:44:27.201] iteration 29807 : model1 loss : 0.208082 model2 loss : 0.221179
[00:44:27.527] iteration 29808 : model1 loss : 0.252746 model2 loss : 0.273433
[00:44:27.854] iteration 29809 : model1 loss : 0.184628 model2 loss : 0.217312
[00:44:28.180] iteration 29810 : model1 loss : 0.249621 model2 loss : 0.278609
[00:44:28.504] iteration 29811 : model1 loss : 0.198589 model2 loss : 0.415259
[00:44:28.827] iteration 29812 : model1 loss : 0.164000 model2 loss : 0.218894
[00:44:29.150] iteration 29813 : model1 loss : 0.162672 model2 loss : 0.178373
[00:44:29.475] iteration 29814 : model1 loss : 0.143237 model2 loss : 0.149577
[00:44:29.799] iteration 29815 : model1 loss : 0.247643 model2 loss : 0.245408
[00:44:30.126] iteration 29816 : model1 loss : 0.088814 model2 loss : 0.110757
[00:44:30.450] iteration 29817 : model1 loss : 0.160611 model2 loss : 0.240875
[00:44:30.776] iteration 29818 : model1 loss : 0.165622 model2 loss : 0.195885
[00:44:31.102] iteration 29819 : model1 loss : 0.138090 model2 loss : 0.146412
[00:44:31.426] iteration 29820 : model1 loss : 0.168802 model2 loss : 0.153293
[00:44:31.750] iteration 29821 : model1 loss : 0.111475 model2 loss : 0.081858
[00:44:32.080] iteration 29822 : model1 loss : 0.238768 model2 loss : 0.256742
[00:44:32.403] iteration 29823 : model1 loss : 0.325891 model2 loss : 0.351445
[00:44:32.727] iteration 29824 : model1 loss : 0.154412 model2 loss : 0.164460
[00:44:33.051] iteration 29825 : model1 loss : 0.283630 model2 loss : 0.264057
[00:44:33.378] iteration 29826 : model1 loss : 0.259912 model2 loss : 0.282602
[00:44:33.702] iteration 29827 : model1 loss : 0.284779 model2 loss : 0.291682
[00:44:34.030] iteration 29828 : model1 loss : 0.254363 model2 loss : 0.280747
[00:44:34.357] iteration 29829 : model1 loss : 0.206404 model2 loss : 0.156336
[00:44:34.683] iteration 29830 : model1 loss : 0.228664 model2 loss : 0.255861
[00:44:35.012] iteration 29831 : model1 loss : 0.249915 model2 loss : 0.252380
[00:44:35.339] iteration 29832 : model1 loss : 0.257898 model2 loss : 0.264257
[00:44:35.662] iteration 29833 : model1 loss : 0.089958 model2 loss : 0.175270
[00:44:35.989] iteration 29834 : model1 loss : 0.180828 model2 loss : 0.211641
[00:44:36.313] iteration 29835 : model1 loss : 0.186949 model2 loss : 0.224972
[00:44:36.639] iteration 29836 : model1 loss : 0.283934 model2 loss : 0.301062
[00:44:36.966] iteration 29837 : model1 loss : 0.344732 model2 loss : 0.359153
[00:44:37.294] iteration 29838 : model1 loss : 0.082350 model2 loss : 0.114744
[00:44:37.623] iteration 29839 : model1 loss : 0.165687 model2 loss : 0.225733
[00:44:37.954] iteration 29840 : model1 loss : 0.157158 model2 loss : 0.264282
[00:44:38.282] iteration 29841 : model1 loss : 0.146781 model2 loss : 0.174422
[00:44:38.612] iteration 29842 : model1 loss : 0.153971 model2 loss : 0.162012
[00:44:38.943] iteration 29843 : model1 loss : 0.201912 model2 loss : 0.215728
[00:44:39.273] iteration 29844 : model1 loss : 0.071224 model2 loss : 0.095562
[00:44:39.601] iteration 29845 : model1 loss : 0.183778 model2 loss : 0.223880
[00:44:39.931] iteration 29846 : model1 loss : 0.163755 model2 loss : 0.182644
[00:44:40.260] iteration 29847 : model1 loss : 0.239572 model2 loss : 0.287045
[00:44:40.588] iteration 29848 : model1 loss : 0.142254 model2 loss : 0.160025
[00:44:40.916] iteration 29849 : model1 loss : 0.261561 model2 loss : 0.292445
[00:44:41.244] iteration 29850 : model1 loss : 0.263171 model2 loss : 0.258667
[00:44:41.800] iteration 29851 : model1 loss : 0.169916 model2 loss : 0.196512
[00:44:42.131] iteration 29852 : model1 loss : 0.105167 model2 loss : 0.099844
[00:44:42.459] iteration 29853 : model1 loss : 0.291808 model2 loss : 0.245441
[00:44:42.786] iteration 29854 : model1 loss : 0.166433 model2 loss : 0.176395
[00:44:43.115] iteration 29855 : model1 loss : 0.079679 model2 loss : 0.125940
[00:44:43.442] iteration 29856 : model1 loss : 0.085508 model2 loss : 0.122916
[00:44:43.775] iteration 29857 : model1 loss : 0.172779 model2 loss : 0.164869
[00:44:44.106] iteration 29858 : model1 loss : 0.187849 model2 loss : 0.209238
[00:44:44.433] iteration 29859 : model1 loss : 0.258500 model2 loss : 0.318280
[00:44:44.763] iteration 29860 : model1 loss : 0.180695 model2 loss : 0.180065
[00:44:45.092] iteration 29861 : model1 loss : 0.206524 model2 loss : 0.195182
[00:44:45.423] iteration 29862 : model1 loss : 0.232692 model2 loss : 0.239193
[00:44:45.750] iteration 29863 : model1 loss : 0.097913 model2 loss : 0.118041
[00:44:46.079] iteration 29864 : model1 loss : 0.155161 model2 loss : 0.190746
[00:44:46.410] iteration 29865 : model1 loss : 0.183739 model2 loss : 0.217216
[00:44:46.738] iteration 29866 : model1 loss : 0.249397 model2 loss : 0.248549
[00:44:47.064] iteration 29867 : model1 loss : 0.166338 model2 loss : 0.171486
[00:44:47.392] iteration 29868 : model1 loss : 0.185584 model2 loss : 0.214051
[00:44:47.723] iteration 29869 : model1 loss : 0.151005 model2 loss : 0.160654
[00:44:48.052] iteration 29870 : model1 loss : 0.149969 model2 loss : 0.206565
[00:44:48.379] iteration 29871 : model1 loss : 0.242569 model2 loss : 0.331739
[00:44:48.709] iteration 29872 : model1 loss : 0.171894 model2 loss : 0.196094
[00:44:49.038] iteration 29873 : model1 loss : 0.183739 model2 loss : 0.219108
[00:44:49.363] iteration 29874 : model1 loss : 0.255336 model2 loss : 0.264750
[00:44:49.690] iteration 29875 : model1 loss : 0.149826 model2 loss : 0.175816
[00:44:50.023] iteration 29876 : model1 loss : 0.167676 model2 loss : 0.206181
[00:44:50.353] iteration 29877 : model1 loss : 0.144427 model2 loss : 0.168461
[00:44:50.681] iteration 29878 : model1 loss : 0.185099 model2 loss : 0.249370
[00:44:51.010] iteration 29879 : model1 loss : 0.140997 model2 loss : 0.228958
[00:44:51.338] iteration 29880 : model1 loss : 0.169785 model2 loss : 0.192060
[00:44:51.663] iteration 29881 : model1 loss : 0.218613 model2 loss : 0.256642
[00:44:51.992] iteration 29882 : model1 loss : 0.165832 model2 loss : 0.206613
[00:44:52.320] iteration 29883 : model1 loss : 0.064105 model2 loss : 0.079218
[00:44:52.652] iteration 29884 : model1 loss : 0.161645 model2 loss : 0.222180
[00:44:52.982] iteration 29885 : model1 loss : 0.255637 model2 loss : 0.260977
[00:44:53.309] iteration 29886 : model1 loss : 0.189470 model2 loss : 0.217720
[00:44:53.637] iteration 29887 : model1 loss : 0.188879 model2 loss : 0.201076
[00:44:53.965] iteration 29888 : model1 loss : 0.095515 model2 loss : 0.136633
[00:44:54.294] iteration 29889 : model1 loss : 0.249949 model2 loss : 0.243925
[00:44:54.619] iteration 29890 : model1 loss : 0.158742 model2 loss : 0.190575
[00:44:54.947] iteration 29891 : model1 loss : 0.203705 model2 loss : 0.229135
[00:44:55.272] iteration 29892 : model1 loss : 0.181157 model2 loss : 0.187116
[00:44:55.598] iteration 29893 : model1 loss : 0.157394 model2 loss : 0.191996
[00:44:55.929] iteration 29894 : model1 loss : 0.081702 model2 loss : 0.090588
[00:44:56.259] iteration 29895 : model1 loss : 0.169530 model2 loss : 0.226597
[00:44:56.586] iteration 29896 : model1 loss : 0.096021 model2 loss : 0.097570
[00:44:56.916] iteration 29897 : model1 loss : 0.241971 model2 loss : 0.264799
[00:44:57.240] iteration 29898 : model1 loss : 0.142050 model2 loss : 0.163124
[00:44:57.567] iteration 29899 : model1 loss : 0.169741 model2 loss : 0.188387
[00:44:57.901] iteration 29900 : model1 loss : 0.170058 model2 loss : 0.210379
[00:44:58.542] iteration 29901 : model1 loss : 0.256541 model2 loss : 0.311752
[00:44:58.867] iteration 29902 : model1 loss : 0.075346 model2 loss : 0.087215
[00:44:59.195] iteration 29903 : model1 loss : 0.248586 model2 loss : 0.286315
[00:44:59.523] iteration 29904 : model1 loss : 0.236927 model2 loss : 0.286617
[00:44:59.847] iteration 29905 : model1 loss : 0.150993 model2 loss : 0.194714
[00:45:00.172] iteration 29906 : model1 loss : 0.247662 model2 loss : 0.257836
[00:45:00.498] iteration 29907 : model1 loss : 0.103876 model2 loss : 0.146748
[00:45:00.830] iteration 29908 : model1 loss : 0.121303 model2 loss : 0.252225
[00:45:01.162] iteration 29909 : model1 loss : 0.140783 model2 loss : 0.157663
[00:45:01.493] iteration 29910 : model1 loss : 0.239558 model2 loss : 0.270439
[00:45:01.821] iteration 29911 : model1 loss : 0.077083 model2 loss : 0.084932
[00:45:02.152] iteration 29912 : model1 loss : 0.148005 model2 loss : 0.162400
[00:45:02.480] iteration 29913 : model1 loss : 0.079945 model2 loss : 0.141527
[00:45:02.818] iteration 29914 : model1 loss : 0.301175 model2 loss : 0.316103
[00:45:03.153] iteration 29915 : model1 loss : 0.258455 model2 loss : 0.280205
[00:45:03.493] iteration 29916 : model1 loss : 0.251634 model2 loss : 0.283303
[00:45:03.831] iteration 29917 : model1 loss : 0.201146 model2 loss : 0.191858
[00:45:04.169] iteration 29918 : model1 loss : 0.176241 model2 loss : 0.220369
[00:45:04.503] iteration 29919 : model1 loss : 0.242318 model2 loss : 0.316010
[00:45:04.838] iteration 29920 : model1 loss : 0.186549 model2 loss : 0.231397
[00:45:05.172] iteration 29921 : model1 loss : 0.325724 model2 loss : 0.337350
[00:45:05.514] iteration 29922 : model1 loss : 0.159576 model2 loss : 0.166131
[00:45:05.849] iteration 29923 : model1 loss : 0.239463 model2 loss : 0.259000
[00:45:06.189] iteration 29924 : model1 loss : 0.093328 model2 loss : 0.129380
[00:45:06.528] iteration 29925 : model1 loss : 0.073139 model2 loss : 0.141471
[00:45:06.865] iteration 29926 : model1 loss : 0.315251 model2 loss : 0.317176
[00:45:07.204] iteration 29927 : model1 loss : 0.174852 model2 loss : 0.170983
[00:45:07.543] iteration 29928 : model1 loss : 0.133652 model2 loss : 0.106159
[00:45:07.884] iteration 29929 : model1 loss : 0.173713 model2 loss : 0.174801
[00:45:08.223] iteration 29930 : model1 loss : 0.133065 model2 loss : 0.160315
[00:45:08.560] iteration 29931 : model1 loss : 0.203777 model2 loss : 0.217130
[00:45:08.899] iteration 29932 : model1 loss : 0.156870 model2 loss : 0.184785
[00:45:09.238] iteration 29933 : model1 loss : 0.143112 model2 loss : 0.182288
[00:45:09.579] iteration 29934 : model1 loss : 0.174136 model2 loss : 0.221974
[00:45:09.919] iteration 29935 : model1 loss : 0.143034 model2 loss : 0.162616
[00:45:10.257] iteration 29936 : model1 loss : 0.238368 model2 loss : 0.257813
[00:45:10.596] iteration 29937 : model1 loss : 0.127711 model2 loss : 0.193752
[00:45:10.932] iteration 29938 : model1 loss : 0.163689 model2 loss : 0.178519
[00:45:11.276] iteration 29939 : model1 loss : 0.145784 model2 loss : 0.240743
[00:45:11.613] iteration 29940 : model1 loss : 0.190844 model2 loss : 0.201175
[00:45:11.948] iteration 29941 : model1 loss : 0.164885 model2 loss : 0.192397
[00:45:12.283] iteration 29942 : model1 loss : 0.314240 model2 loss : 0.320099
[00:45:12.619] iteration 29943 : model1 loss : 0.181334 model2 loss : 0.188967
[00:45:12.953] iteration 29944 : model1 loss : 0.176020 model2 loss : 0.170476
[00:45:13.290] iteration 29945 : model1 loss : 0.103418 model2 loss : 0.110139
[00:45:13.631] iteration 29946 : model1 loss : 0.058886 model2 loss : 0.076969
[00:45:13.973] iteration 29947 : model1 loss : 0.250676 model2 loss : 0.266563
[00:45:14.310] iteration 29948 : model1 loss : 0.310287 model2 loss : 0.321202
[00:45:14.646] iteration 29949 : model1 loss : 0.165480 model2 loss : 0.241835
[00:45:14.983] iteration 29950 : model1 loss : 0.256086 model2 loss : 0.274372
[00:45:15.649] iteration 29951 : model1 loss : 0.172972 model2 loss : 0.205817
[00:45:15.987] iteration 29952 : model1 loss : 0.328920 model2 loss : 0.363354
[00:45:16.317] iteration 29953 : model1 loss : 0.242451 model2 loss : 0.254971
[00:45:16.644] iteration 29954 : model1 loss : 0.183739 model2 loss : 0.217049
[00:45:16.973] iteration 29955 : model1 loss : 0.112590 model2 loss : 0.119042
[00:45:17.301] iteration 29956 : model1 loss : 0.156101 model2 loss : 0.176391
[00:45:17.629] iteration 29957 : model1 loss : 0.248680 model2 loss : 0.270959
[00:45:17.956] iteration 29958 : model1 loss : 0.098238 model2 loss : 0.145250
[00:45:18.287] iteration 29959 : model1 loss : 0.238270 model2 loss : 0.267171
[00:45:18.617] iteration 29960 : model1 loss : 0.179050 model2 loss : 0.194172
[00:45:18.945] iteration 29961 : model1 loss : 0.091246 model2 loss : 0.124561
[00:45:19.274] iteration 29962 : model1 loss : 0.168990 model2 loss : 0.190522
[00:45:19.599] iteration 29963 : model1 loss : 0.063547 model2 loss : 0.071819
[00:45:19.938] iteration 29964 : model1 loss : 0.079975 model2 loss : 0.119518
[00:45:20.275] iteration 29965 : model1 loss : 0.102468 model2 loss : 0.127295
[00:45:20.613] iteration 29966 : model1 loss : 0.229019 model2 loss : 0.244202
[00:45:20.952] iteration 29967 : model1 loss : 0.143854 model2 loss : 0.160583
[00:45:21.289] iteration 29968 : model1 loss : 0.092215 model2 loss : 0.116924
[00:45:21.626] iteration 29969 : model1 loss : 0.241140 model2 loss : 0.261641
[00:45:21.961] iteration 29970 : model1 loss : 0.077677 model2 loss : 0.099769
[00:45:22.299] iteration 29971 : model1 loss : 0.295966 model2 loss : 0.260914
[00:45:22.634] iteration 29972 : model1 loss : 0.264245 model2 loss : 0.281306
[00:45:22.973] iteration 29973 : model1 loss : 0.100035 model2 loss : 0.097323
[00:45:23.310] iteration 29974 : model1 loss : 0.209741 model2 loss : 0.225226
[00:45:23.643] iteration 29975 : model1 loss : 0.251843 model2 loss : 0.262877
[00:45:24.784] iteration 29976 : model1 loss : 0.157739 model2 loss : 0.194283
[00:45:25.123] iteration 29977 : model1 loss : 0.093072 model2 loss : 0.149583
[00:45:25.462] iteration 29978 : model1 loss : 0.161509 model2 loss : 0.154791
[00:45:25.801] iteration 29979 : model1 loss : 0.075567 model2 loss : 0.407758
[00:45:26.127] iteration 29980 : model1 loss : 0.234134 model2 loss : 0.245573
[00:45:26.451] iteration 29981 : model1 loss : 0.337332 model2 loss : 0.332512
[00:45:26.779] iteration 29982 : model1 loss : 0.077408 model2 loss : 0.078959
[00:45:27.105] iteration 29983 : model1 loss : 0.097482 model2 loss : 0.138820
[00:45:27.429] iteration 29984 : model1 loss : 0.168731 model2 loss : 0.171829
[00:45:27.755] iteration 29985 : model1 loss : 0.154411 model2 loss : 0.160336
[00:45:28.085] iteration 29986 : model1 loss : 0.103600 model2 loss : 0.127739
[00:45:28.414] iteration 29987 : model1 loss : 0.174512 model2 loss : 0.200593
[00:45:28.742] iteration 29988 : model1 loss : 0.178611 model2 loss : 0.204521
[00:45:29.069] iteration 29989 : model1 loss : 0.080998 model2 loss : 0.102872
[00:45:29.395] iteration 29990 : model1 loss : 0.164899 model2 loss : 0.198534
[00:45:29.720] iteration 29991 : model1 loss : 0.157225 model2 loss : 0.194065
[00:45:30.049] iteration 29992 : model1 loss : 0.157502 model2 loss : 0.187021
[00:45:30.374] iteration 29993 : model1 loss : 0.152781 model2 loss : 0.229741
[00:45:30.700] iteration 29994 : model1 loss : 0.233146 model2 loss : 0.251270
[00:45:31.029] iteration 29995 : model1 loss : 0.239830 model2 loss : 0.242451
[00:45:31.357] iteration 29996 : model1 loss : 0.256737 model2 loss : 0.285307
[00:45:31.683] iteration 29997 : model1 loss : 0.254470 model2 loss : 0.233422
[00:45:32.010] iteration 29998 : model1 loss : 0.213324 model2 loss : 0.195776
[00:45:32.349] iteration 29999 : model1 loss : 0.231353 model2 loss : 0.291456
[00:45:32.687] iteration 30000 : model1 loss : 0.251794 model2 loss : 0.258655
[00:46:42.460] iteration 30000 : model1_mean_dice : 0.795322 model1_mean_hd95 : 10.229581
[00:47:36.926] iteration 30000 : model2_mean_dice : 0.692952 model2_mean_hd95 : 12.225038
[00:47:37.152] save model1 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model1_iter_30000.pth
[00:47:37.174] save model2 to ../model/ACDC/Semi_Mamba_UNet_3/mambaunet/model2_iter_30000.pth
